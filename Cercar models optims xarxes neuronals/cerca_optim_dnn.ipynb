{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cercador model òptim de DNN "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "lMCuRV3SJK6w"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dj_kr\\anaconda3\\lib\\site-packages\\statsmodels\\tools\\_testing.py:19: FutureWarning: pandas.util.testing is deprecated. Use the functions in the public API at pandas.testing instead.\n",
      "  import pandas.util.testing as tm\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow.compat.v2 as tf\n",
    "tf.enable_v2_behavior()\n",
    "import pandas as pd\n",
    "from tensorflow import keras\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from matplotlib import pyplot\n",
    "import plotly.graph_objects as go\n",
    "import math\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from time import time\n",
    "\n",
    "np.random.seed(2)\n",
    "tf.random.set_seed(2)\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, LSTM, GRU, Dropout, RepeatVector, TimeDistributed\n",
    "from tensorflow.keras import backend"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9d9z8yxsJK6x"
   },
   "source": [
    "## Càrrega de les dades"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 72,
     "resources": {
      "http://localhost:8080/nbextensions/google.colab/files.js": {
       "data": "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",
       "headers": [
        [
         "content-type",
         "application/javascript"
        ]
       ],
       "ok": true,
       "status": 200,
       "status_text": ""
      }
     }
    },
    "id": "seq5Q3gjJK6y",
    "outputId": "72e82bf7-9c19-4d0d-da4a-42c4aff349b3"
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/SentDATA.csv')\n",
    "\n",
    "df.reset_index(inplace=True)\n",
    "df['Time'] = pd.to_datetime(df['Time'])\n",
    "df = df.set_index('Time')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WSvxlfJ5JK6y"
   },
   "source": [
    "## Anàlisis estadístic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4VLv_DJhJK6y"
   },
   "source": [
    "## Transformació de dades"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "NUx3mg0RJK6y"
   },
   "outputs": [],
   "source": [
    "columns = ['PM1','PM25','PM10','PM1ATM','PM25ATM','PM10ATM']\n",
    "\n",
    "df1 = df.copy();\n",
    "\n",
    "df1 = df1.rename(columns={\"PM 1\":\"PM1\",\"PM 2.5\":\"PM25\",\"PM 10\":\"PM10\",\"PM 1 ATM\":\"PM1ATM\",\"PM 2.5 ATM\":\"PM25ATM\",\"PM 10 ATM\":\"PM10ATM\"})\n",
    "\n",
    "df1['PM1'] = df['PM 1'].astype(np.float32)\n",
    "df1['PM25'] = df['PM 2.5'].astype(np.float32)\n",
    "df1['PM10'] = df['PM 10'].astype(np.float32)\n",
    "df1['PM1ATM'] = df['PM 1 ATM'].astype(np.float32)\n",
    "df1['PM25ATM'] = df['PM 2.5 ATM'].astype(np.float32)\n",
    "df1['PM10ATM'] = df['PM 10 ATM'].astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "eh0Xz9k-IHtg"
   },
   "outputs": [],
   "source": [
    "df2 = df1.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nLJVxlmlJK6z"
   },
   "source": [
    "## Crear dades d'entrenament i de test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "U1Dwm-E9JK6z",
    "outputId": "620f3cbe-6354-40b1-88c3-a80206b571f0"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((3991, 7), (998, 7))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_size = int(len(df2) * 0.8)\n",
    "test_size = len(df2) - train_size\n",
    "train, test = df2.iloc[0:train_size], df2.iloc[train_size:len(df2)]\n",
    "train.shape, test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JuMi9G1LJK6z"
   },
   "source": [
    "## Normalitzar les dades d'entrenament"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "cqcC5lWvJK6z",
    "outputId": "ca0f0c98-e1f3-4e86-dc5f-65dcb992a209"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-6-c8a1383fd1da>:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  train[col] = scaler.fit_transform(train[[col]])\n",
      "<ipython-input-6-c8a1383fd1da>:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  train[col] = scaler.fit_transform(train[[col]])\n",
      "<ipython-input-6-c8a1383fd1da>:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  train[col] = scaler.fit_transform(train[[col]])\n",
      "<ipython-input-6-c8a1383fd1da>:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  train[col] = scaler.fit_transform(train[[col]])\n",
      "<ipython-input-6-c8a1383fd1da>:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  train[col] = scaler.fit_transform(train[[col]])\n",
      "<ipython-input-6-c8a1383fd1da>:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  train[col] = scaler.fit_transform(train[[col]])\n"
     ]
    }
   ],
   "source": [
    "#Standardize the data\n",
    "for col in columns:\n",
    "    scaler = MinMaxScaler()\n",
    "    train[col] = scaler.fit_transform(train[[col]])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7LsNLCHSJK6z"
   },
   "source": [
    "## Crear finestra de temps PM 2.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "nEH4EmxcJK6z",
    "outputId": "b8c5f2c4-adca-47ef-fb6b-c734f0160dcb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train1h shape: (3847, 144, 1)\n",
      "X_train3d shape: (3973, 18, 1)\n",
      "X_train6h shape: (3955, 36, 1)\n",
      "X_train12h shape: (3919, 72, 1)\n",
      "X_train1d shape: (3847, 144, 1)\n",
      "X_train3d shape: (3559, 432, 1)\n",
      "X_train7d shape: (2983, 1008, 1)\n"
     ]
    }
   ],
   "source": [
    "TIME_STEPS=144 #6 registres hora x 24h x 3 --> equival a una finestra d'un dia\n",
    "\n",
    "def create_sequences(X, y, time_steps=TIME_STEPS):\n",
    "    Xs, ys = [], []\n",
    "    for i in range(len(X)-time_steps):\n",
    "        Xs.append(X.iloc[i:(i+time_steps)].values)\n",
    "        ys.append(y.iloc[i+time_steps])\n",
    "    \n",
    "    return np.array(Xs), np.array(ys)\n",
    "\n",
    "X_train1h, y_train1h = create_sequences(train[[columns[1]]], train[columns[1]], 6) #1 hour\n",
    "\n",
    "X_train3h, y_train3h = create_sequences(train[[columns[1]]], train[columns[1]], 18) #3 hours\n",
    "\n",
    "X_train6h, y_train6h = create_sequences(train[[columns[1]]], train[columns[1]], 36) #6 hours\n",
    "\n",
    "X_train12h, y_train12h = create_sequences(train[[columns[1]]], train[columns[1]], 72) #12 hours\n",
    "\n",
    "X_train1d, y_train1d = create_sequences(train[[columns[1]]], train[columns[1]], 144) #1 day\n",
    "\n",
    "X_train3d, y_train3d = create_sequences(train[[columns[1]]], train[columns[1]], 432) #3 days\n",
    "\n",
    "X_train7d, y_train7d = create_sequences(train[[columns[1]]], train[columns[1]], 1008) #7 days\n",
    "#X_test, y_test = create_sequences(test[[columns[1]]], test[columns[1]])\n",
    "\n",
    "print(f'X_train1h shape: {X_train1d.shape}')\n",
    "print(f'X_train3d shape: {X_train3h.shape}')\n",
    "print(f'X_train6h shape: {X_train6h.shape}')\n",
    "print(f'X_train12h shape: {X_train12h.shape}')\n",
    "print(f'X_train1d shape: {X_train1d.shape}')\n",
    "print(f'X_train3d shape: {X_train3d.shape}')\n",
    "print(f'X_train7d shape: {X_train7d.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_prediction(predictions, actual, model_name):\n",
    "    errors = predictions - actual\n",
    "    mse = np.square(errors).mean()\n",
    "    rmse = np.sqrt(mse)\n",
    "    mae = np.abs(errors).mean()\n",
    "\n",
    "    print(model_name + ':')\n",
    "    print('Mean Absolute Error: {:.4f}'.format(mae))\n",
    "    print('Root Mean Square Error: {:.4f}'.format(rmse))\n",
    "    print('Mean Square Error: {:.4f}'.format(mse))\n",
    "    print('')\n",
    "    return mae,rmse,mse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "e9caadjyJK6z"
   },
   "source": [
    "## Cerca dels models òptims"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "7znr_i72OjVb",
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "###########################\n",
      "\n",
      "MODEL:  DNN\n",
      "sequence:  1h\n",
      "units:  87\n",
      "dropout1:  0.40519643149940265\n",
      "optimizer: adam\n",
      "activationDense: tanh\n",
      "epochs: 80\n",
      "batchsize: 31\n",
      "validation_split: 0.1\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 6, 87)             174       \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 6, 16)             1408      \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 6, 16)             0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 6, 1)              17        \n",
      "=================================================================\n",
      "Total params: 1,599\n",
      "Trainable params: 1,599\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/80\n",
      "116/116 [==============================] - 0s 4ms/step - loss: 0.2079 - val_loss: 0.0340\n",
      "Epoch 2/80\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.0899 - val_loss: 0.0164\n",
      "Epoch 3/80\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.0754 - val_loss: 0.0086\n",
      "Epoch 4/80\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.0591 - val_loss: 0.0058\n",
      "Epoch 5/80\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.0441 - val_loss: 0.0131\n",
      "Epoch 6/80\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.0337 - val_loss: 0.0187\n",
      "Epoch 7/80\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.0282 - val_loss: 0.0224\n",
      "Epoch 8/80\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.0282 - val_loss: 0.0101\n",
      "Epoch 9/80\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.0286 - val_loss: 0.0105\n",
      "Epoch 10/80\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.0288 - val_loss: 0.0115\n",
      "Epoch 11/80\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.0285 - val_loss: 0.0109\n",
      "Epoch 12/80\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.0286 - val_loss: 0.0116\n",
      "Epoch 13/80\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.0285 - val_loss: 0.0098\n",
      "Epoch 14/80\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.0287 - val_loss: 0.0110\n",
      "Epoch 15/80\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.0285 - val_loss: 0.0107\n",
      "Epoch 16/80\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.0283 - val_loss: 0.0106\n",
      "Epoch 17/80\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.0271 - val_loss: 0.0109\n",
      "Epoch 18/80\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.0281 - val_loss: 0.0113\n",
      "Epoch 19/80\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.0279 - val_loss: 0.0105\n",
      "Epoch 20/80\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.0280 - val_loss: 0.0108\n",
      "Epoch 21/80\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.0276 - val_loss: 0.0107\n",
      "Epoch 22/80\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.0275 - val_loss: 0.0113\n",
      "Epoch 23/80\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.0263 - val_loss: 0.0129\n",
      "Epoch 24/80\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.0257 - val_loss: 0.0107\n",
      "Epoch 25/80\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.0251 - val_loss: 0.0136\n",
      "Epoch 26/80\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.0237 - val_loss: 0.0117\n",
      "Epoch 27/80\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.0230 - val_loss: 0.0129\n",
      "Epoch 28/80\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.0217 - val_loss: 0.0105\n",
      "Epoch 29/80\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.0196 - val_loss: 0.0114\n",
      "Epoch 30/80\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.0177 - val_loss: 0.0134\n",
      "Epoch 31/80\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.0183 - val_loss: 0.0117\n",
      "Epoch 32/80\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.0175 - val_loss: 0.0144\n",
      "Epoch 33/80\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.0159 - val_loss: 0.0143\n",
      "Epoch 34/80\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.0156 - val_loss: 0.0153\n",
      "Epoch 35/80\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.0156 - val_loss: 0.0145\n",
      "Epoch 36/80\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.0153 - val_loss: 0.0149\n",
      "Epoch 37/80\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.0157 - val_loss: 0.0131\n",
      "Epoch 38/80\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.0157 - val_loss: 0.0138\n",
      "Epoch 39/80\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.0152 - val_loss: 0.0162\n",
      "Epoch 40/80\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.0156 - val_loss: 0.0137\n",
      "Epoch 41/80\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.0152 - val_loss: 0.0149\n",
      "Epoch 42/80\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.0154 - val_loss: 0.0145\n",
      "Epoch 43/80\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.0146 - val_loss: 0.0120\n",
      "Epoch 44/80\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.0153 - val_loss: 0.0135\n",
      "Epoch 45/80\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.0156 - val_loss: 0.0139\n",
      "Epoch 46/80\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.0153 - val_loss: 0.0155\n",
      "Epoch 47/80\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.0150 - val_loss: 0.0134\n",
      "Epoch 48/80\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.0154 - val_loss: 0.0166\n",
      "Epoch 49/80\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.0153 - val_loss: 0.0156\n",
      "Epoch 50/80\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.0153 - val_loss: 0.0155\n",
      "Epoch 51/80\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.0148 - val_loss: 0.0152\n",
      "Epoch 52/80\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.0148 - val_loss: 0.0132\n",
      "Epoch 53/80\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.0149 - val_loss: 0.0120\n",
      "Epoch 54/80\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.0155 - val_loss: 0.0145\n",
      "Epoch 55/80\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.0159 - val_loss: 0.0146\n",
      "Epoch 56/80\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.0155 - val_loss: 0.0148\n",
      "Epoch 57/80\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.0151 - val_loss: 0.0165\n",
      "Epoch 58/80\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.0152 - val_loss: 0.0159\n",
      "Epoch 59/80\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.0149 - val_loss: 0.0156\n",
      "Epoch 60/80\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.0150 - val_loss: 0.0145\n",
      "Epoch 61/80\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.0147 - val_loss: 0.0125\n",
      "Epoch 62/80\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.0150 - val_loss: 0.0135\n",
      "Epoch 63/80\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.0154 - val_loss: 0.0159\n",
      "Epoch 64/80\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.0153 - val_loss: 0.0162\n",
      "Epoch 65/80\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.0150 - val_loss: 0.0150\n",
      "Epoch 66/80\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.0154 - val_loss: 0.0172\n",
      "Epoch 67/80\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.0155 - val_loss: 0.0137\n",
      "Epoch 68/80\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.0147 - val_loss: 0.0134\n",
      "Epoch 69/80\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.0149 - val_loss: 0.0127\n",
      "Epoch 70/80\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.0151 - val_loss: 0.0145\n",
      "Epoch 71/80\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "116/116 [==============================] - 0s 2ms/step - loss: 0.0149 - val_loss: 0.0134\n",
      "Epoch 72/80\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.0161 - val_loss: 0.0158\n",
      "Epoch 73/80\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.0167 - val_loss: 0.0130\n",
      "Epoch 74/80\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.0169 - val_loss: 0.0136\n",
      "Epoch 75/80\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.0164 - val_loss: 0.0154\n",
      "Epoch 76/80\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.0161 - val_loss: 0.0149\n",
      "Epoch 77/80\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.0154 - val_loss: 0.0172\n",
      "Epoch 78/80\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.0153 - val_loss: 0.0156\n",
      "Epoch 79/80\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.0154 - val_loss: 0.0173\n",
      "Epoch 80/80\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.0159 - val_loss: 0.0149\n",
      "Execution time:  17.23777174949646\n",
      "DNN:\n",
      "Mean Absolute Error: 0.0099\n",
      "Root Mean Square Error: 0.0192\n",
      "Mean Square Error: 0.0004\n",
      "\n",
      "Train RMSE: 0.019\n",
      "Train MSE: 0.000\n",
      "Train MAE: 0.010\n",
      "###########################\n",
      "\n",
      "MODEL:  DNN\n",
      "sequence:  1h\n",
      "units:  80\n",
      "dropout1:  0.11814836227952394\n",
      "optimizer: adam\n",
      "activationDense: tanh\n",
      "epochs: 90\n",
      "batchsize: 25\n",
      "validation_split: 0.1\n",
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_3 (Dense)              (None, 6, 80)             160       \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 6, 16)             1296      \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 6, 16)             0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 6, 1)              17        \n",
      "=================================================================\n",
      "Total params: 1,473\n",
      "Trainable params: 1,473\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/90\n",
      "144/144 [==============================] - 0s 3ms/step - loss: 0.0633 - val_loss: 0.0033\n",
      "Epoch 2/90\n",
      "144/144 [==============================] - 0s 2ms/step - loss: 0.0395 - val_loss: 0.0105\n",
      "Epoch 3/90\n",
      "144/144 [==============================] - 0s 1ms/step - loss: 0.0366 - val_loss: 0.0035\n",
      "Epoch 4/90\n",
      "144/144 [==============================] - 0s 2ms/step - loss: 0.0335 - val_loss: 0.0041\n",
      "Epoch 5/90\n",
      "144/144 [==============================] - 0s 2ms/step - loss: 0.0312 - val_loss: 0.0045\n",
      "Epoch 6/90\n",
      "144/144 [==============================] - 0s 2ms/step - loss: 0.0290 - val_loss: 0.0042\n",
      "Epoch 7/90\n",
      "144/144 [==============================] - 0s 2ms/step - loss: 0.0269 - val_loss: 0.0051\n",
      "Epoch 8/90\n",
      "144/144 [==============================] - 0s 2ms/step - loss: 0.0256 - val_loss: 0.0034\n",
      "Epoch 9/90\n",
      "144/144 [==============================] - 0s 2ms/step - loss: 0.0234 - val_loss: 0.0039\n",
      "Epoch 10/90\n",
      "144/144 [==============================] - 0s 2ms/step - loss: 0.0225 - val_loss: 0.0042\n",
      "Epoch 11/90\n",
      "144/144 [==============================] - 0s 1ms/step - loss: 0.0217 - val_loss: 0.0041\n",
      "Epoch 12/90\n",
      "144/144 [==============================] - 0s 2ms/step - loss: 0.0208 - val_loss: 0.0054\n",
      "Epoch 13/90\n",
      "144/144 [==============================] - 0s 2ms/step - loss: 0.0197 - val_loss: 0.0065\n",
      "Epoch 14/90\n",
      "144/144 [==============================] - 0s 2ms/step - loss: 0.0192 - val_loss: 0.0062\n",
      "Epoch 15/90\n",
      "144/144 [==============================] - 0s 2ms/step - loss: 0.0195 - val_loss: 0.0144\n",
      "Epoch 16/90\n",
      "144/144 [==============================] - 0s 2ms/step - loss: 0.0190 - val_loss: 0.0176\n",
      "Epoch 17/90\n",
      "144/144 [==============================] - 0s 2ms/step - loss: 0.0182 - val_loss: 0.0181\n",
      "Epoch 18/90\n",
      "144/144 [==============================] - 0s 2ms/step - loss: 0.0185 - val_loss: 0.0171\n",
      "Epoch 19/90\n",
      "144/144 [==============================] - 0s 1ms/step - loss: 0.0182 - val_loss: 0.0202\n",
      "Epoch 20/90\n",
      "144/144 [==============================] - 0s 2ms/step - loss: 0.0183 - val_loss: 0.0215\n",
      "Epoch 21/90\n",
      "144/144 [==============================] - 0s 2ms/step - loss: 0.0201 - val_loss: 0.0166\n",
      "Epoch 22/90\n",
      "144/144 [==============================] - 0s 2ms/step - loss: 0.0190 - val_loss: 0.0188\n",
      "Epoch 23/90\n",
      "144/144 [==============================] - 0s 1ms/step - loss: 0.0182 - val_loss: 0.0194\n",
      "Epoch 24/90\n",
      "144/144 [==============================] - 0s 2ms/step - loss: 0.0177 - val_loss: 0.0191\n",
      "Epoch 25/90\n",
      "144/144 [==============================] - 0s 1ms/step - loss: 0.0180 - val_loss: 0.0184\n",
      "Epoch 26/90\n",
      "144/144 [==============================] - 0s 1ms/step - loss: 0.0174 - val_loss: 0.0183\n",
      "Epoch 27/90\n",
      "144/144 [==============================] - 0s 1ms/step - loss: 0.0164 - val_loss: 0.0185\n",
      "Epoch 28/90\n",
      "144/144 [==============================] - 0s 1ms/step - loss: 0.0170 - val_loss: 0.0172\n",
      "Epoch 29/90\n",
      "144/144 [==============================] - 0s 1ms/step - loss: 0.0169 - val_loss: 0.0182\n",
      "Epoch 30/90\n",
      "144/144 [==============================] - 0s 2ms/step - loss: 0.0172 - val_loss: 0.0172\n",
      "Epoch 31/90\n",
      "144/144 [==============================] - 0s 2ms/step - loss: 0.0167 - val_loss: 0.0178\n",
      "Epoch 32/90\n",
      "144/144 [==============================] - 0s 2ms/step - loss: 0.0158 - val_loss: 0.0185\n",
      "Epoch 33/90\n",
      "144/144 [==============================] - 0s 2ms/step - loss: 0.0160 - val_loss: 0.0177\n",
      "Epoch 34/90\n",
      "144/144 [==============================] - 0s 2ms/step - loss: 0.0163 - val_loss: 0.0180\n",
      "Epoch 35/90\n",
      "144/144 [==============================] - 0s 2ms/step - loss: 0.0163 - val_loss: 0.0167\n",
      "Epoch 36/90\n",
      "144/144 [==============================] - 0s 2ms/step - loss: 0.0154 - val_loss: 0.0183\n",
      "Epoch 37/90\n",
      "144/144 [==============================] - 0s 1ms/step - loss: 0.0162 - val_loss: 0.0167\n",
      "Epoch 38/90\n",
      "144/144 [==============================] - 0s 2ms/step - loss: 0.0165 - val_loss: 0.0166\n",
      "Epoch 39/90\n",
      "144/144 [==============================] - 0s 1ms/step - loss: 0.0155 - val_loss: 0.0185\n",
      "Epoch 40/90\n",
      "144/144 [==============================] - 0s 1ms/step - loss: 0.0153 - val_loss: 0.0185\n",
      "Epoch 41/90\n",
      "144/144 [==============================] - 0s 2ms/step - loss: 0.0156 - val_loss: 0.0179\n",
      "Epoch 42/90\n",
      "144/144 [==============================] - 0s 2ms/step - loss: 0.0154 - val_loss: 0.0174\n",
      "Epoch 43/90\n",
      "144/144 [==============================] - 0s 2ms/step - loss: 0.0155 - val_loss: 0.0175\n",
      "Epoch 44/90\n",
      "144/144 [==============================] - 0s 2ms/step - loss: 0.0148 - val_loss: 0.0166\n",
      "Epoch 45/90\n",
      "144/144 [==============================] - 0s 1ms/step - loss: 0.0153 - val_loss: 0.0180\n",
      "Epoch 46/90\n",
      "144/144 [==============================] - 0s 2ms/step - loss: 0.0144 - val_loss: 0.0174\n",
      "Epoch 47/90\n",
      "144/144 [==============================] - 0s 2ms/step - loss: 0.0111 - val_loss: 0.0127\n",
      "Epoch 48/90\n",
      "144/144 [==============================] - 0s 1ms/step - loss: 0.0107 - val_loss: 0.0116\n",
      "Epoch 49/90\n",
      "144/144 [==============================] - 0s 2ms/step - loss: 0.0112 - val_loss: 0.0129\n",
      "Epoch 50/90\n",
      "144/144 [==============================] - 0s 1ms/step - loss: 0.0113 - val_loss: 0.0158\n",
      "Epoch 51/90\n",
      "144/144 [==============================] - 0s 1ms/step - loss: 0.0110 - val_loss: 0.0139\n",
      "Epoch 52/90\n",
      "144/144 [==============================] - 0s 1ms/step - loss: 0.0110 - val_loss: 0.0139\n",
      "Epoch 53/90\n",
      "144/144 [==============================] - 0s 1ms/step - loss: 0.0110 - val_loss: 0.0121\n",
      "Epoch 54/90\n",
      "144/144 [==============================] - 0s 1ms/step - loss: 0.0110 - val_loss: 0.0122\n",
      "Epoch 55/90\n",
      "144/144 [==============================] - 0s 1ms/step - loss: 0.0106 - val_loss: 0.0108\n",
      "Epoch 56/90\n",
      "144/144 [==============================] - 0s 2ms/step - loss: 0.0109 - val_loss: 0.0112\n",
      "Epoch 57/90\n",
      "144/144 [==============================] - 0s 2ms/step - loss: 0.0109 - val_loss: 0.0110\n",
      "Epoch 58/90\n",
      "144/144 [==============================] - 0s 2ms/step - loss: 0.0109 - val_loss: 0.0120\n",
      "Epoch 59/90\n",
      "144/144 [==============================] - 0s 2ms/step - loss: 0.0108 - val_loss: 0.0112\n",
      "Epoch 60/90\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "144/144 [==============================] - 0s 2ms/step - loss: 0.0109 - val_loss: 0.0149\n",
      "Epoch 61/90\n",
      "144/144 [==============================] - 0s 2ms/step - loss: 0.0107 - val_loss: 0.0124\n",
      "Epoch 62/90\n",
      "144/144 [==============================] - 0s 2ms/step - loss: 0.0111 - val_loss: 0.0147\n",
      "Epoch 63/90\n",
      "144/144 [==============================] - 0s 2ms/step - loss: 0.0110 - val_loss: 0.0141\n",
      "Epoch 64/90\n",
      "144/144 [==============================] - 0s 2ms/step - loss: 0.0105 - val_loss: 0.0122\n",
      "Epoch 65/90\n",
      "144/144 [==============================] - 0s 1ms/step - loss: 0.0109 - val_loss: 0.0104\n",
      "Epoch 66/90\n",
      "144/144 [==============================] - 0s 2ms/step - loss: 0.0112 - val_loss: 0.0104\n",
      "Epoch 67/90\n",
      "144/144 [==============================] - 0s 2ms/step - loss: 0.0110 - val_loss: 0.0120\n",
      "Epoch 68/90\n",
      "144/144 [==============================] - 0s 2ms/step - loss: 0.0109 - val_loss: 0.0146\n",
      "Epoch 69/90\n",
      "144/144 [==============================] - 0s 2ms/step - loss: 0.0108 - val_loss: 0.0126\n",
      "Epoch 70/90\n",
      "144/144 [==============================] - 0s 2ms/step - loss: 0.0109 - val_loss: 0.0139\n",
      "Epoch 71/90\n",
      "144/144 [==============================] - 0s 1ms/step - loss: 0.0109 - val_loss: 0.0142\n",
      "Epoch 72/90\n",
      "144/144 [==============================] - 0s 2ms/step - loss: 0.0111 - val_loss: 0.0156\n",
      "Epoch 73/90\n",
      "144/144 [==============================] - 0s 2ms/step - loss: 0.0108 - val_loss: 0.0148\n",
      "Epoch 74/90\n",
      "144/144 [==============================] - 0s 2ms/step - loss: 0.0107 - val_loss: 0.0144\n",
      "Epoch 75/90\n",
      "144/144 [==============================] - 0s 2ms/step - loss: 0.0109 - val_loss: 0.0146\n",
      "Epoch 76/90\n",
      "144/144 [==============================] - 0s 2ms/step - loss: 0.0108 - val_loss: 0.0122\n",
      "Epoch 77/90\n",
      "144/144 [==============================] - 0s 2ms/step - loss: 0.0106 - val_loss: 0.0119\n",
      "Epoch 78/90\n",
      "144/144 [==============================] - 0s 2ms/step - loss: 0.0108 - val_loss: 0.0132\n",
      "Epoch 79/90\n",
      "144/144 [==============================] - 0s 2ms/step - loss: 0.0106 - val_loss: 0.0122\n",
      "Epoch 80/90\n",
      "144/144 [==============================] - 0s 2ms/step - loss: 0.0107 - val_loss: 0.0126\n",
      "Epoch 81/90\n",
      "144/144 [==============================] - 0s 2ms/step - loss: 0.0106 - val_loss: 0.0109\n",
      "Epoch 82/90\n",
      "144/144 [==============================] - 0s 2ms/step - loss: 0.0107 - val_loss: 0.0110\n",
      "Epoch 83/90\n",
      "144/144 [==============================] - 0s 2ms/step - loss: 0.0108 - val_loss: 0.0119\n",
      "Epoch 84/90\n",
      "144/144 [==============================] - 0s 1ms/step - loss: 0.0108 - val_loss: 0.0116\n",
      "Epoch 85/90\n",
      "144/144 [==============================] - 0s 2ms/step - loss: 0.0106 - val_loss: 0.0124\n",
      "Epoch 86/90\n",
      "144/144 [==============================] - 0s 2ms/step - loss: 0.0108 - val_loss: 0.0142\n",
      "Epoch 87/90\n",
      "144/144 [==============================] - 0s 2ms/step - loss: 0.0104 - val_loss: 0.0118\n",
      "Epoch 88/90\n",
      "144/144 [==============================] - 0s 1ms/step - loss: 0.0108 - val_loss: 0.0143\n",
      "Epoch 89/90\n",
      "144/144 [==============================] - 0s 1ms/step - loss: 0.0106 - val_loss: 0.0115\n",
      "Epoch 90/90\n",
      "144/144 [==============================] - 0s 2ms/step - loss: 0.0106 - val_loss: 0.0115\n",
      "Execution time:  22.27723526954651\n",
      "DNN:\n",
      "Mean Absolute Error: 0.0050\n",
      "Root Mean Square Error: 0.0189\n",
      "Mean Square Error: 0.0004\n",
      "\n",
      "Train RMSE: 0.019\n",
      "Train MSE: 0.000\n",
      "Train MAE: 0.005\n",
      "###########################\n",
      "\n",
      "MODEL:  DNN\n",
      "sequence:  1h\n",
      "units:  12\n",
      "dropout1:  0.48476373451509647\n",
      "optimizer: adam\n",
      "activationDense: tanh\n",
      "epochs: 52\n",
      "batchsize: 57\n",
      "validation_split: 0.1\n",
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_6 (Dense)              (None, 6, 12)             24        \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 6, 16)             208       \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 6, 16)             0         \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 6, 1)              17        \n",
      "=================================================================\n",
      "Total params: 249\n",
      "Trainable params: 249\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/52\n",
      "63/63 [==============================] - 0s 4ms/step - loss: 0.3349 - val_loss: 0.1542\n",
      "Epoch 2/52\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.1239 - val_loss: 0.0164\n",
      "Epoch 3/52\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0999 - val_loss: 0.0045\n",
      "Epoch 4/52\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0906 - val_loss: 0.0093\n",
      "Epoch 5/52\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0811 - val_loss: 0.0138\n",
      "Epoch 6/52\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0719 - val_loss: 0.0108\n",
      "Epoch 7/52\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0626 - val_loss: 0.0088\n",
      "Epoch 8/52\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.0527 - val_loss: 0.0118\n",
      "Epoch 9/52\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0444 - val_loss: 0.0080\n",
      "Epoch 10/52\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0383 - val_loss: 0.0114\n",
      "Epoch 11/52\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0328 - val_loss: 0.0096\n",
      "Epoch 12/52\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0297 - val_loss: 0.0082\n",
      "Epoch 13/52\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0278 - val_loss: 0.0081\n",
      "Epoch 14/52\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0268 - val_loss: 0.0087\n",
      "Epoch 15/52\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0263 - val_loss: 0.0097\n",
      "Epoch 16/52\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0263 - val_loss: 0.0101\n",
      "Epoch 17/52\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0260 - val_loss: 0.0100\n",
      "Epoch 18/52\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0259 - val_loss: 0.0104\n",
      "Epoch 19/52\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0254 - val_loss: 0.0103\n",
      "Epoch 20/52\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0253 - val_loss: 0.0100\n",
      "Epoch 21/52\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0252 - val_loss: 0.0105\n",
      "Epoch 22/52\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0247 - val_loss: 0.0100\n",
      "Epoch 23/52\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0246 - val_loss: 0.0103\n",
      "Epoch 24/52\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0240 - val_loss: 0.0101\n",
      "Epoch 25/52\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0238 - val_loss: 0.0102\n",
      "Epoch 26/52\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0230 - val_loss: 0.0102\n",
      "Epoch 27/52\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0228 - val_loss: 0.0102\n",
      "Epoch 28/52\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0222 - val_loss: 0.0103\n",
      "Epoch 29/52\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0213 - val_loss: 0.0103\n",
      "Epoch 30/52\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0207 - val_loss: 0.0104\n",
      "Epoch 31/52\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0202 - val_loss: 0.0101\n",
      "Epoch 32/52\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0204 - val_loss: 0.0103\n",
      "Epoch 33/52\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.0191 - val_loss: 0.0100\n",
      "Epoch 34/52\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0195 - val_loss: 0.0103\n",
      "Epoch 35/52\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0179 - val_loss: 0.0101\n",
      "Epoch 36/52\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0186 - val_loss: 0.0105\n",
      "Epoch 37/52\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0166 - val_loss: 0.0168\n",
      "Epoch 38/52\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0175 - val_loss: 0.0110\n",
      "Epoch 39/52\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0168 - val_loss: 0.0096\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 40/52\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0163 - val_loss: 0.0115\n",
      "Epoch 41/52\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0168 - val_loss: 0.0098\n",
      "Epoch 42/52\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0155 - val_loss: 0.0114\n",
      "Epoch 43/52\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0160 - val_loss: 0.0096\n",
      "Epoch 44/52\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0154 - val_loss: 0.0125\n",
      "Epoch 45/52\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0155 - val_loss: 0.0098\n",
      "Epoch 46/52\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0150 - val_loss: 0.0123\n",
      "Epoch 47/52\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0152 - val_loss: 0.0100\n",
      "Epoch 48/52\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0152 - val_loss: 0.0128\n",
      "Epoch 49/52\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0158 - val_loss: 0.0096\n",
      "Epoch 50/52\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0150 - val_loss: 0.0123\n",
      "Epoch 51/52\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0154 - val_loss: 0.0100\n",
      "Epoch 52/52\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0151 - val_loss: 0.0126\n",
      "Execution time:  6.903104782104492\n",
      "DNN:\n",
      "Mean Absolute Error: 0.0114\n",
      "Root Mean Square Error: 0.0177\n",
      "Mean Square Error: 0.0003\n",
      "\n",
      "Train RMSE: 0.018\n",
      "Train MSE: 0.000\n",
      "Train MAE: 0.011\n",
      "###########################\n",
      "\n",
      "MODEL:  DNN\n",
      "sequence:  1h\n",
      "units:  87\n",
      "dropout1:  0.40519643149940265\n",
      "optimizer: adam\n",
      "activationDense: tanh\n",
      "epochs: 80\n",
      "batchsize: 31\n",
      "validation_split: 0.2\n",
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_9 (Dense)              (None, 6, 87)             174       \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 6, 16)             1408      \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 6, 16)             0         \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 6, 1)              17        \n",
      "=================================================================\n",
      "Total params: 1,599\n",
      "Trainable params: 1,599\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/80\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 0.1425 - val_loss: 0.0342\n",
      "Epoch 2/80\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.0729 - val_loss: 0.0133\n",
      "Epoch 3/80\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.0635 - val_loss: 0.0109\n",
      "Epoch 4/80\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.0563 - val_loss: 0.0203\n",
      "Epoch 5/80\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.0484 - val_loss: 0.0160\n",
      "Epoch 6/80\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.0411 - val_loss: 0.0127\n",
      "Epoch 7/80\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.0343 - val_loss: 0.0116\n",
      "Epoch 8/80\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.0299 - val_loss: 0.0118\n",
      "Epoch 9/80\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.0271 - val_loss: 0.0124\n",
      "Epoch 10/80\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.0252 - val_loss: 0.0131\n",
      "Epoch 11/80\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.0261 - val_loss: 0.0157\n",
      "Epoch 12/80\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.0285 - val_loss: 0.0153\n",
      "Epoch 13/80\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.0298 - val_loss: 0.0147\n",
      "Epoch 14/80\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.0278 - val_loss: 0.0150\n",
      "Epoch 15/80\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.0286 - val_loss: 0.0150\n",
      "Epoch 16/80\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.0275 - val_loss: 0.0149\n",
      "Epoch 17/80\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.0273 - val_loss: 0.0148\n",
      "Epoch 18/80\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.0266 - val_loss: 0.0150\n",
      "Epoch 19/80\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.0278 - val_loss: 0.0149\n",
      "Epoch 20/80\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.0236 - val_loss: 0.0151\n",
      "Epoch 21/80\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.0282 - val_loss: 0.0155\n",
      "Epoch 22/80\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.0237 - val_loss: 0.0147\n",
      "Epoch 23/80\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.0259 - val_loss: 0.0151\n",
      "Epoch 24/80\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.0209 - val_loss: 0.0144\n",
      "Epoch 25/80\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.0206 - val_loss: 0.0144\n",
      "Epoch 26/80\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.0201 - val_loss: 0.0144\n",
      "Epoch 27/80\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.0181 - val_loss: 0.0135\n",
      "Epoch 28/80\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.0175 - val_loss: 0.0127\n",
      "Epoch 29/80\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.0167 - val_loss: 0.0128\n",
      "Epoch 30/80\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.0164 - val_loss: 0.0122\n",
      "Epoch 31/80\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.0161 - val_loss: 0.0118\n",
      "Epoch 32/80\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.0161 - val_loss: 0.0118\n",
      "Epoch 33/80\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.0165 - val_loss: 0.0123\n",
      "Epoch 34/80\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.0159 - val_loss: 0.0122\n",
      "Epoch 35/80\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.0153 - val_loss: 0.0117\n",
      "Epoch 36/80\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.0156 - val_loss: 0.0117\n",
      "Epoch 37/80\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.0151 - val_loss: 0.0118\n",
      "Epoch 38/80\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.0155 - val_loss: 0.0111\n",
      "Epoch 39/80\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.0157 - val_loss: 0.0124\n",
      "Epoch 40/80\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.0160 - val_loss: 0.0115\n",
      "Epoch 41/80\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.0149 - val_loss: 0.0116\n",
      "Epoch 42/80\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.0148 - val_loss: 0.0120\n",
      "Epoch 43/80\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.0148 - val_loss: 0.0116\n",
      "Epoch 44/80\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.0148 - val_loss: 0.0115\n",
      "Epoch 45/80\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.0150 - val_loss: 0.0113\n",
      "Epoch 46/80\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.0146 - val_loss: 0.0116\n",
      "Epoch 47/80\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.0146 - val_loss: 0.0118\n",
      "Epoch 48/80\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.0146 - val_loss: 0.0117\n",
      "Epoch 49/80\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.0148 - val_loss: 0.0116\n",
      "Epoch 50/80\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.0146 - val_loss: 0.0118\n",
      "Epoch 51/80\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.0149 - val_loss: 0.0114\n",
      "Epoch 52/80\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.0148 - val_loss: 0.0111\n",
      "Epoch 53/80\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.0147 - val_loss: 0.0115\n",
      "Epoch 54/80\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.0147 - val_loss: 0.0122\n",
      "Epoch 55/80\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.0152 - val_loss: 0.0109\n",
      "Epoch 56/80\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.0142 - val_loss: 0.0119\n",
      "Epoch 57/80\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "103/103 [==============================] - 0s 2ms/step - loss: 0.0146 - val_loss: 0.0114\n",
      "Epoch 58/80\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.0145 - val_loss: 0.0118\n",
      "Epoch 59/80\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.0147 - val_loss: 0.0118\n",
      "Epoch 60/80\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.0146 - val_loss: 0.0112\n",
      "Epoch 61/80\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.0143 - val_loss: 0.0108\n",
      "Epoch 62/80\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.0139 - val_loss: 0.0110\n",
      "Epoch 63/80\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.0144 - val_loss: 0.0117\n",
      "Epoch 64/80\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.0146 - val_loss: 0.0108\n",
      "Epoch 65/80\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.0143 - val_loss: 0.0120\n",
      "Epoch 66/80\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.0147 - val_loss: 0.0120\n",
      "Epoch 67/80\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.0149 - val_loss: 0.0116\n",
      "Epoch 68/80\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.0142 - val_loss: 0.0110\n",
      "Epoch 69/80\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.0138 - val_loss: 0.0110\n",
      "Epoch 70/80\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.0143 - val_loss: 0.0118\n",
      "Epoch 71/80\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.0144 - val_loss: 0.0118\n",
      "Epoch 72/80\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.0148 - val_loss: 0.0114\n",
      "Epoch 73/80\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.0146 - val_loss: 0.0110\n",
      "Epoch 74/80\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.0139 - val_loss: 0.0111\n",
      "Epoch 75/80\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.0143 - val_loss: 0.0119\n",
      "Epoch 76/80\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.0147 - val_loss: 0.0120\n",
      "Epoch 77/80\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.0146 - val_loss: 0.0114\n",
      "Epoch 78/80\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.0142 - val_loss: 0.0116\n",
      "Epoch 79/80\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.0143 - val_loss: 0.0111\n",
      "Epoch 80/80\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.0139 - val_loss: 0.0114\n",
      "Execution time:  16.15279769897461\n",
      "DNN:\n",
      "Mean Absolute Error: 0.0136\n",
      "Root Mean Square Error: 0.0213\n",
      "Mean Square Error: 0.0005\n",
      "\n",
      "Train RMSE: 0.021\n",
      "Train MSE: 0.000\n",
      "Train MAE: 0.014\n",
      "###########################\n",
      "\n",
      "MODEL:  DNN\n",
      "sequence:  1h\n",
      "units:  80\n",
      "dropout1:  0.11814836227952394\n",
      "optimizer: adam\n",
      "activationDense: tanh\n",
      "epochs: 90\n",
      "batchsize: 25\n",
      "validation_split: 0.2\n",
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_12 (Dense)             (None, 6, 80)             160       \n",
      "_________________________________________________________________\n",
      "dense_13 (Dense)             (None, 6, 16)             1296      \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 6, 16)             0         \n",
      "_________________________________________________________________\n",
      "dense_14 (Dense)             (None, 6, 1)              17        \n",
      "=================================================================\n",
      "Total params: 1,473\n",
      "Trainable params: 1,473\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/90\n",
      "128/128 [==============================] - 0s 3ms/step - loss: 0.0864 - val_loss: 0.0337\n",
      "Epoch 2/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0452 - val_loss: 0.0340\n",
      "Epoch 3/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0418 - val_loss: 0.0242\n",
      "Epoch 4/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0400 - val_loss: 0.0307\n",
      "Epoch 5/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0374 - val_loss: 0.0268\n",
      "Epoch 6/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0357 - val_loss: 0.0113\n",
      "Epoch 7/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0329 - val_loss: 0.0168\n",
      "Epoch 8/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0322 - val_loss: 0.0147\n",
      "Epoch 9/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0306 - val_loss: 0.0107\n",
      "Epoch 10/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0287 - val_loss: 0.0115\n",
      "Epoch 11/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0282 - val_loss: 0.0104\n",
      "Epoch 12/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0267 - val_loss: 0.0105\n",
      "Epoch 13/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0256 - val_loss: 0.0106\n",
      "Epoch 14/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0247 - val_loss: 0.0117\n",
      "Epoch 15/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0235 - val_loss: 0.0112\n",
      "Epoch 16/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0252 - val_loss: 0.0114\n",
      "Epoch 17/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0228 - val_loss: 0.0112\n",
      "Epoch 18/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0218 - val_loss: 0.0114\n",
      "Epoch 19/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0228 - val_loss: 0.0101\n",
      "Epoch 20/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0213 - val_loss: 0.0106\n",
      "Epoch 21/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0200 - val_loss: 0.0096\n",
      "Epoch 22/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0197 - val_loss: 0.0104\n",
      "Epoch 23/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0182 - val_loss: 0.0111\n",
      "Epoch 24/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0174 - val_loss: 0.0107\n",
      "Epoch 25/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0167 - val_loss: 0.0105\n",
      "Epoch 26/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0163 - val_loss: 0.0116\n",
      "Epoch 27/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0165 - val_loss: 0.0115\n",
      "Epoch 28/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0160 - val_loss: 0.0127\n",
      "Epoch 29/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0163 - val_loss: 0.0126\n",
      "Epoch 30/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0170 - val_loss: 0.0126\n",
      "Epoch 31/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0168 - val_loss: 0.0125\n",
      "Epoch 32/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0162 - val_loss: 0.0114\n",
      "Epoch 33/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0147 - val_loss: 0.0120\n",
      "Epoch 34/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0150 - val_loss: 0.0119\n",
      "Epoch 35/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0150 - val_loss: 0.0121\n",
      "Epoch 36/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0153 - val_loss: 0.0122\n",
      "Epoch 37/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0149 - val_loss: 0.0122\n",
      "Epoch 38/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0143 - val_loss: 0.0121\n",
      "Epoch 39/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0133 - val_loss: 0.0112\n",
      "Epoch 40/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0136 - val_loss: 0.0118\n",
      "Epoch 41/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0138 - val_loss: 0.0119\n",
      "Epoch 42/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0131 - val_loss: 0.0115\n",
      "Epoch 43/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0142 - val_loss: 0.0121\n",
      "Epoch 44/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0147 - val_loss: 0.0122\n",
      "Epoch 45/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0133 - val_loss: 0.0112\n",
      "Epoch 46/90\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0129 - val_loss: 0.0114\n",
      "Epoch 47/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0127 - val_loss: 0.0118\n",
      "Epoch 48/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0127 - val_loss: 0.0111\n",
      "Epoch 49/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0132 - val_loss: 0.0115\n",
      "Epoch 50/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0125 - val_loss: 0.0098\n",
      "Epoch 51/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0114 - val_loss: 0.0093\n",
      "Epoch 52/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0112 - val_loss: 0.0095\n",
      "Epoch 53/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0115 - val_loss: 0.0110\n",
      "Epoch 54/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0142 - val_loss: 0.0119\n",
      "Epoch 55/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0140 - val_loss: 0.0115\n",
      "Epoch 56/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0130 - val_loss: 0.0116\n",
      "Epoch 57/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0126 - val_loss: 0.0103\n",
      "Epoch 58/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0117 - val_loss: 0.0097\n",
      "Epoch 59/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0118 - val_loss: 0.0107\n",
      "Epoch 60/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0127 - val_loss: 0.0111\n",
      "Epoch 61/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0132 - val_loss: 0.0111\n",
      "Epoch 62/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0126 - val_loss: 0.0113\n",
      "Epoch 63/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0132 - val_loss: 0.0112\n",
      "Epoch 64/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0134 - val_loss: 0.0108\n",
      "Epoch 65/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0124 - val_loss: 0.0112\n",
      "Epoch 66/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0130 - val_loss: 0.0109\n",
      "Epoch 67/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0124 - val_loss: 0.0113\n",
      "Epoch 68/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0129 - val_loss: 0.0115\n",
      "Epoch 69/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0122 - val_loss: 0.0098\n",
      "Epoch 70/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0113 - val_loss: 0.0099\n",
      "Epoch 71/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0117 - val_loss: 0.0105\n",
      "Epoch 72/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0124 - val_loss: 0.0114\n",
      "Epoch 73/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0128 - val_loss: 0.0113\n",
      "Epoch 74/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0126 - val_loss: 0.0113\n",
      "Epoch 75/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0122 - val_loss: 0.0097\n",
      "Epoch 76/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0110 - val_loss: 0.0099\n",
      "Epoch 77/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0113 - val_loss: 0.0097\n",
      "Epoch 78/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0115 - val_loss: 0.0093\n",
      "Epoch 79/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0109 - val_loss: 0.0095\n",
      "Epoch 80/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0113 - val_loss: 0.0102\n",
      "Epoch 81/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0115 - val_loss: 0.0095\n",
      "Epoch 82/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0115 - val_loss: 0.0096\n",
      "Epoch 83/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0112 - val_loss: 0.0095\n",
      "Epoch 84/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0115 - val_loss: 0.0103\n",
      "Epoch 85/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0117 - val_loss: 0.0097\n",
      "Epoch 86/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0111 - val_loss: 0.0097\n",
      "Epoch 87/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0114 - val_loss: 0.0093\n",
      "Epoch 88/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0110 - val_loss: 0.0086\n",
      "Epoch 89/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0110 - val_loss: 0.0093\n",
      "Epoch 90/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0113 - val_loss: 0.0095\n",
      "Execution time:  20.035281896591187\n",
      "DNN:\n",
      "Mean Absolute Error: 0.0086\n",
      "Root Mean Square Error: 0.0210\n",
      "Mean Square Error: 0.0004\n",
      "\n",
      "Train RMSE: 0.021\n",
      "Train MSE: 0.000\n",
      "Train MAE: 0.009\n",
      "###########################\n",
      "\n",
      "MODEL:  DNN\n",
      "sequence:  1h\n",
      "units:  12\n",
      "dropout1:  0.48476373451509647\n",
      "optimizer: adam\n",
      "activationDense: tanh\n",
      "epochs: 52\n",
      "batchsize: 57\n",
      "validation_split: 0.2\n",
      "Model: \"sequential_5\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_15 (Dense)             (None, 6, 12)             24        \n",
      "_________________________________________________________________\n",
      "dense_16 (Dense)             (None, 6, 16)             208       \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 6, 16)             0         \n",
      "_________________________________________________________________\n",
      "dense_17 (Dense)             (None, 6, 1)              17        \n",
      "=================================================================\n",
      "Total params: 249\n",
      "Trainable params: 249\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/52\n",
      "56/56 [==============================] - 0s 5ms/step - loss: 0.3539 - val_loss: 0.2205\n",
      "Epoch 2/52\n",
      "56/56 [==============================] - 0s 2ms/step - loss: 0.1550 - val_loss: 0.0349\n",
      "Epoch 3/52\n",
      "56/56 [==============================] - 0s 2ms/step - loss: 0.1042 - val_loss: 0.0175\n",
      "Epoch 4/52\n",
      "56/56 [==============================] - 0s 2ms/step - loss: 0.0939 - val_loss: 0.0134\n",
      "Epoch 5/52\n",
      "56/56 [==============================] - 0s 2ms/step - loss: 0.0852 - val_loss: 0.0138\n",
      "Epoch 6/52\n",
      "56/56 [==============================] - 0s 2ms/step - loss: 0.0775 - val_loss: 0.0144\n",
      "Epoch 7/52\n",
      "56/56 [==============================] - 0s 2ms/step - loss: 0.0697 - val_loss: 0.0142\n",
      "Epoch 8/52\n",
      "56/56 [==============================] - 0s 2ms/step - loss: 0.0617 - val_loss: 0.0135\n",
      "Epoch 9/52\n",
      "56/56 [==============================] - 0s 2ms/step - loss: 0.0535 - val_loss: 0.0138\n",
      "Epoch 10/52\n",
      "56/56 [==============================] - 0s 2ms/step - loss: 0.0474 - val_loss: 0.0142\n",
      "Epoch 11/52\n",
      "56/56 [==============================] - 0s 2ms/step - loss: 0.0422 - val_loss: 0.0141\n",
      "Epoch 12/52\n",
      "56/56 [==============================] - 0s 2ms/step - loss: 0.0375 - val_loss: 0.0153\n",
      "Epoch 13/52\n",
      "56/56 [==============================] - 0s 2ms/step - loss: 0.0341 - val_loss: 0.0161\n",
      "Epoch 14/52\n",
      "56/56 [==============================] - 0s 2ms/step - loss: 0.0313 - val_loss: 0.0171\n",
      "Epoch 15/52\n",
      "56/56 [==============================] - 0s 2ms/step - loss: 0.0293 - val_loss: 0.0163\n",
      "Epoch 16/52\n",
      "56/56 [==============================] - 0s 2ms/step - loss: 0.0285 - val_loss: 0.0145\n",
      "Epoch 17/52\n",
      "56/56 [==============================] - 0s 2ms/step - loss: 0.0284 - val_loss: 0.0162\n",
      "Epoch 18/52\n",
      "56/56 [==============================] - 0s 2ms/step - loss: 0.0279 - val_loss: 0.0160\n",
      "Epoch 19/52\n",
      "56/56 [==============================] - 0s 2ms/step - loss: 0.0278 - val_loss: 0.0162\n",
      "Epoch 20/52\n",
      "56/56 [==============================] - 0s 2ms/step - loss: 0.0275 - val_loss: 0.0161\n",
      "Epoch 21/52\n",
      "56/56 [==============================] - 0s 2ms/step - loss: 0.0276 - val_loss: 0.0163\n",
      "Epoch 22/52\n",
      "56/56 [==============================] - 0s 2ms/step - loss: 0.0271 - val_loss: 0.0158\n",
      "Epoch 23/52\n",
      "56/56 [==============================] - 0s 2ms/step - loss: 0.0271 - val_loss: 0.0155\n",
      "Epoch 24/52\n",
      "56/56 [==============================] - 0s 2ms/step - loss: 0.0269 - val_loss: 0.0154\n",
      "Epoch 25/52\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "56/56 [==============================] - 0s 2ms/step - loss: 0.0267 - val_loss: 0.0153\n",
      "Epoch 26/52\n",
      "56/56 [==============================] - 0s 2ms/step - loss: 0.0265 - val_loss: 0.0150\n",
      "Epoch 27/52\n",
      "56/56 [==============================] - 0s 2ms/step - loss: 0.0264 - val_loss: 0.0148\n",
      "Epoch 28/52\n",
      "56/56 [==============================] - 0s 2ms/step - loss: 0.0264 - val_loss: 0.0150\n",
      "Epoch 29/52\n",
      "56/56 [==============================] - 0s 2ms/step - loss: 0.0261 - val_loss: 0.0147\n",
      "Epoch 30/52\n",
      "56/56 [==============================] - 0s 2ms/step - loss: 0.0260 - val_loss: 0.0146\n",
      "Epoch 31/52\n",
      "56/56 [==============================] - 0s 2ms/step - loss: 0.0257 - val_loss: 0.0143\n",
      "Epoch 32/52\n",
      "56/56 [==============================] - 0s 2ms/step - loss: 0.0257 - val_loss: 0.0146\n",
      "Epoch 33/52\n",
      "56/56 [==============================] - 0s 2ms/step - loss: 0.0253 - val_loss: 0.0139\n",
      "Epoch 34/52\n",
      "56/56 [==============================] - 0s 2ms/step - loss: 0.0252 - val_loss: 0.0147\n",
      "Epoch 35/52\n",
      "56/56 [==============================] - 0s 2ms/step - loss: 0.0247 - val_loss: 0.0138\n",
      "Epoch 36/52\n",
      "56/56 [==============================] - 0s 2ms/step - loss: 0.0248 - val_loss: 0.0145\n",
      "Epoch 37/52\n",
      "56/56 [==============================] - 0s 2ms/step - loss: 0.0240 - val_loss: 0.0137\n",
      "Epoch 38/52\n",
      "56/56 [==============================] - 0s 2ms/step - loss: 0.0243 - val_loss: 0.0141\n",
      "Epoch 39/52\n",
      "56/56 [==============================] - 0s 2ms/step - loss: 0.0231 - val_loss: 0.0134\n",
      "Epoch 40/52\n",
      "56/56 [==============================] - 0s 2ms/step - loss: 0.0231 - val_loss: 0.0136\n",
      "Epoch 41/52\n",
      "56/56 [==============================] - 0s 2ms/step - loss: 0.0223 - val_loss: 0.0130\n",
      "Epoch 42/52\n",
      "56/56 [==============================] - 0s 2ms/step - loss: 0.0221 - val_loss: 0.0136\n",
      "Epoch 43/52\n",
      "56/56 [==============================] - 0s 2ms/step - loss: 0.0208 - val_loss: 0.0129\n",
      "Epoch 44/52\n",
      "56/56 [==============================] - 0s 2ms/step - loss: 0.0211 - val_loss: 0.0132\n",
      "Epoch 45/52\n",
      "56/56 [==============================] - 0s 2ms/step - loss: 0.0203 - val_loss: 0.0128\n",
      "Epoch 46/52\n",
      "56/56 [==============================] - 0s 2ms/step - loss: 0.0201 - val_loss: 0.0127\n",
      "Epoch 47/52\n",
      "56/56 [==============================] - 0s 2ms/step - loss: 0.0191 - val_loss: 0.0125\n",
      "Epoch 48/52\n",
      "56/56 [==============================] - 0s 2ms/step - loss: 0.0194 - val_loss: 0.0130\n",
      "Epoch 49/52\n",
      "56/56 [==============================] - 0s 2ms/step - loss: 0.0180 - val_loss: 0.0122\n",
      "Epoch 50/52\n",
      "56/56 [==============================] - 0s 2ms/step - loss: 0.0182 - val_loss: 0.0118\n",
      "Epoch 51/52\n",
      "56/56 [==============================] - 0s 2ms/step - loss: 0.0174 - val_loss: 0.0119\n",
      "Epoch 52/52\n",
      "56/56 [==============================] - 0s 2ms/step - loss: 0.0171 - val_loss: 0.0120\n",
      "Execution time:  6.411895751953125\n",
      "DNN:\n",
      "Mean Absolute Error: 0.0165\n",
      "Root Mean Square Error: 0.0250\n",
      "Mean Square Error: 0.0006\n",
      "\n",
      "Train RMSE: 0.025\n",
      "Train MSE: 0.001\n",
      "Train MAE: 0.016\n",
      "###########################\n",
      "\n",
      "MODEL:  DNN\n",
      "sequence:  1h\n",
      "units:  87\n",
      "dropout1:  0.40519643149940265\n",
      "optimizer: adam\n",
      "activationDense: sigmoid\n",
      "epochs: 80\n",
      "batchsize: 31\n",
      "validation_split: 0.1\n",
      "Model: \"sequential_6\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_18 (Dense)             (None, 6, 87)             174       \n",
      "_________________________________________________________________\n",
      "dense_19 (Dense)             (None, 6, 16)             1408      \n",
      "_________________________________________________________________\n",
      "dropout_6 (Dropout)          (None, 6, 16)             0         \n",
      "_________________________________________________________________\n",
      "dense_20 (Dense)             (None, 6, 1)              17        \n",
      "=================================================================\n",
      "Total params: 1,599\n",
      "Trainable params: 1,599\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/80\n",
      "116/116 [==============================] - 0s 3ms/step - loss: 0.0460 - val_loss: 0.0256\n",
      "Epoch 2/80\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.0422 - val_loss: 0.0265\n",
      "Epoch 3/80\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.0400 - val_loss: 0.0199\n",
      "Epoch 4/80\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.0384 - val_loss: 0.0203\n",
      "Epoch 5/80\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.0369 - val_loss: 0.0190\n",
      "Epoch 6/80\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.0356 - val_loss: 0.0188\n",
      "Epoch 7/80\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.0346 - val_loss: 0.0187\n",
      "Epoch 8/80\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.0336 - val_loss: 0.0176\n",
      "Epoch 9/80\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.0325 - val_loss: 0.0179\n",
      "Epoch 10/80\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.0316 - val_loss: 0.0170\n",
      "Epoch 11/80\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.0308 - val_loss: 0.0169\n",
      "Epoch 12/80\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.0303 - val_loss: 0.0168\n",
      "Epoch 13/80\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.0296 - val_loss: 0.0157\n",
      "Epoch 14/80\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.0290 - val_loss: 0.0169\n",
      "Epoch 15/80\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.0287 - val_loss: 0.0151\n",
      "Epoch 16/80\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.0281 - val_loss: 0.0153\n",
      "Epoch 17/80\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.0275 - val_loss: 0.0147\n",
      "Epoch 18/80\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.0269 - val_loss: 0.0147\n",
      "Epoch 19/80\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.0263 - val_loss: 0.0142\n",
      "Epoch 20/80\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.0259 - val_loss: 0.0141\n",
      "Epoch 21/80\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.0254 - val_loss: 0.0142\n",
      "Epoch 22/80\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.0250 - val_loss: 0.0139\n",
      "Epoch 23/80\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.0247 - val_loss: 0.0142\n",
      "Epoch 24/80\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.0241 - val_loss: 0.0138\n",
      "Epoch 25/80\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.0236 - val_loss: 0.0140\n",
      "Epoch 26/80\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.0229 - val_loss: 0.0136\n",
      "Epoch 27/80\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.0219 - val_loss: 0.0136\n",
      "Epoch 28/80\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.0203 - val_loss: 0.0150\n",
      "Epoch 29/80\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.0192 - val_loss: 0.0153\n",
      "Epoch 30/80\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 0.0182 - val_loss: 0.0156\n",
      "Epoch 31/80\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.0174 - val_loss: 0.0165\n",
      "Epoch 32/80\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.0166 - val_loss: 0.0154\n",
      "Epoch 33/80\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.0162 - val_loss: 0.0140\n",
      "Epoch 34/80\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.0159 - val_loss: 0.0132\n",
      "Epoch 35/80\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.0158 - val_loss: 0.0134\n",
      "Epoch 36/80\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.0158 - val_loss: 0.0135\n",
      "Epoch 37/80\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.0157 - val_loss: 0.0128\n",
      "Epoch 38/80\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.0155 - val_loss: 0.0128\n",
      "Epoch 39/80\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.0156 - val_loss: 0.0123\n",
      "Epoch 40/80\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.0156 - val_loss: 0.0124\n",
      "Epoch 41/80\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.0154 - val_loss: 0.0119\n",
      "Epoch 42/80\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "116/116 [==============================] - 0s 2ms/step - loss: 0.0157 - val_loss: 0.0114\n",
      "Epoch 43/80\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.0157 - val_loss: 0.0124\n",
      "Epoch 44/80\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.0156 - val_loss: 0.0118\n",
      "Epoch 45/80\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.0157 - val_loss: 0.0116\n",
      "Epoch 46/80\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.0155 - val_loss: 0.0108\n",
      "Epoch 47/80\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.0155 - val_loss: 0.0107\n",
      "Epoch 48/80\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.0154 - val_loss: 0.0102\n",
      "Epoch 49/80\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.0157 - val_loss: 0.0104\n",
      "Epoch 50/80\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.0153 - val_loss: 0.0106\n",
      "Epoch 51/80\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.0153 - val_loss: 0.0102\n",
      "Epoch 52/80\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.0153 - val_loss: 0.0079\n",
      "Epoch 53/80\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.0154 - val_loss: 0.0088\n",
      "Epoch 54/80\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.0155 - val_loss: 0.0089\n",
      "Epoch 55/80\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.0153 - val_loss: 0.0085\n",
      "Epoch 56/80\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.0153 - val_loss: 0.0086\n",
      "Epoch 57/80\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.0154 - val_loss: 0.0075\n",
      "Epoch 58/80\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.0152 - val_loss: 0.0074\n",
      "Epoch 59/80\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.0153 - val_loss: 0.0090\n",
      "Epoch 60/80\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.0153 - val_loss: 0.0089\n",
      "Epoch 61/80\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.0154 - val_loss: 0.0096\n",
      "Epoch 62/80\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.0152 - val_loss: 0.0079\n",
      "Epoch 63/80\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.0153 - val_loss: 0.0077\n",
      "Epoch 64/80\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.0152 - val_loss: 0.0070\n",
      "Epoch 65/80\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.0153 - val_loss: 0.0085\n",
      "Epoch 66/80\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.0153 - val_loss: 0.0074\n",
      "Epoch 67/80\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.0152 - val_loss: 0.0082\n",
      "Epoch 68/80\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.0152 - val_loss: 0.0077\n",
      "Epoch 69/80\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 0.0154 - val_loss: 0.0071\n",
      "Epoch 70/80\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.0155 - val_loss: 0.0094\n",
      "Epoch 71/80\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.0153 - val_loss: 0.0086\n",
      "Epoch 72/80\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.0156 - val_loss: 0.0097\n",
      "Epoch 73/80\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.0150 - val_loss: 0.0083\n",
      "Epoch 74/80\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.0152 - val_loss: 0.0076\n",
      "Epoch 75/80\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.0154 - val_loss: 0.0079\n",
      "Epoch 76/80\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.0153 - val_loss: 0.0085\n",
      "Epoch 77/80\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.0155 - val_loss: 0.0100\n",
      "Epoch 78/80\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.0153 - val_loss: 0.0071\n",
      "Epoch 79/80\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.0153 - val_loss: 0.0059\n",
      "Epoch 80/80\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.0154 - val_loss: 0.0085\n",
      "Execution time:  16.1406090259552\n",
      "DNN:\n",
      "Mean Absolute Error: 0.0100\n",
      "Root Mean Square Error: 0.0187\n",
      "Mean Square Error: 0.0004\n",
      "\n",
      "Train RMSE: 0.019\n",
      "Train MSE: 0.000\n",
      "Train MAE: 0.010\n",
      "###########################\n",
      "\n",
      "MODEL:  DNN\n",
      "sequence:  1h\n",
      "units:  80\n",
      "dropout1:  0.11814836227952394\n",
      "optimizer: adam\n",
      "activationDense: sigmoid\n",
      "epochs: 90\n",
      "batchsize: 25\n",
      "validation_split: 0.1\n",
      "Model: \"sequential_7\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_21 (Dense)             (None, 6, 80)             160       \n",
      "_________________________________________________________________\n",
      "dense_22 (Dense)             (None, 6, 16)             1296      \n",
      "_________________________________________________________________\n",
      "dropout_7 (Dropout)          (None, 6, 16)             0         \n",
      "_________________________________________________________________\n",
      "dense_23 (Dense)             (None, 6, 1)              17        \n",
      "=================================================================\n",
      "Total params: 1,473\n",
      "Trainable params: 1,473\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/90\n",
      "144/144 [==============================] - 0s 3ms/step - loss: 0.0383 - val_loss: 0.0358\n",
      "Epoch 2/90\n",
      "144/144 [==============================] - 0s 1ms/step - loss: 0.0380 - val_loss: 0.0289\n",
      "Epoch 3/90\n",
      "144/144 [==============================] - 0s 2ms/step - loss: 0.0366 - val_loss: 0.0238\n",
      "Epoch 4/90\n",
      "144/144 [==============================] - 0s 2ms/step - loss: 0.0354 - val_loss: 0.0203\n",
      "Epoch 5/90\n",
      "144/144 [==============================] - 0s 1ms/step - loss: 0.0344 - val_loss: 0.0204\n",
      "Epoch 6/90\n",
      "144/144 [==============================] - 0s 1ms/step - loss: 0.0336 - val_loss: 0.0186\n",
      "Epoch 7/90\n",
      "144/144 [==============================] - 0s 1ms/step - loss: 0.0326 - val_loss: 0.0191\n",
      "Epoch 8/90\n",
      "144/144 [==============================] - 0s 1ms/step - loss: 0.0320 - val_loss: 0.0189\n",
      "Epoch 9/90\n",
      "144/144 [==============================] - 0s 1ms/step - loss: 0.0311 - val_loss: 0.0177\n",
      "Epoch 10/90\n",
      "144/144 [==============================] - 0s 1ms/step - loss: 0.0303 - val_loss: 0.0164\n",
      "Epoch 11/90\n",
      "144/144 [==============================] - 0s 2ms/step - loss: 0.0297 - val_loss: 0.0169\n",
      "Epoch 12/90\n",
      "144/144 [==============================] - 0s 1ms/step - loss: 0.0292 - val_loss: 0.0167\n",
      "Epoch 13/90\n",
      "144/144 [==============================] - 0s 2ms/step - loss: 0.0280 - val_loss: 0.0162\n",
      "Epoch 14/90\n",
      "144/144 [==============================] - 0s 1ms/step - loss: 0.0267 - val_loss: 0.0170\n",
      "Epoch 15/90\n",
      "144/144 [==============================] - 0s 1ms/step - loss: 0.0255 - val_loss: 0.0161\n",
      "Epoch 16/90\n",
      "144/144 [==============================] - 0s 1ms/step - loss: 0.0240 - val_loss: 0.0159\n",
      "Epoch 17/90\n",
      "144/144 [==============================] - 0s 1ms/step - loss: 0.0227 - val_loss: 0.0148\n",
      "Epoch 18/90\n",
      "144/144 [==============================] - 0s 2ms/step - loss: 0.0201 - val_loss: 0.0177\n",
      "Epoch 19/90\n",
      "144/144 [==============================] - 0s 2ms/step - loss: 0.0186 - val_loss: 0.0174\n",
      "Epoch 20/90\n",
      "144/144 [==============================] - 0s 2ms/step - loss: 0.0167 - val_loss: 0.0183\n",
      "Epoch 21/90\n",
      "144/144 [==============================] - 0s 2ms/step - loss: 0.0155 - val_loss: 0.0169\n",
      "Epoch 22/90\n",
      "144/144 [==============================] - 0s 2ms/step - loss: 0.0145 - val_loss: 0.0155\n",
      "Epoch 23/90\n",
      "144/144 [==============================] - 0s 2ms/step - loss: 0.0137 - val_loss: 0.0118\n",
      "Epoch 24/90\n",
      "144/144 [==============================] - 0s 1ms/step - loss: 0.0133 - val_loss: 0.0088\n",
      "Epoch 25/90\n",
      "144/144 [==============================] - 0s 1ms/step - loss: 0.0127 - val_loss: 0.0076\n",
      "Epoch 26/90\n",
      "144/144 [==============================] - 0s 1ms/step - loss: 0.0127 - val_loss: 0.0086\n",
      "Epoch 27/90\n",
      "144/144 [==============================] - 0s 2ms/step - loss: 0.0122 - val_loss: 0.0071\n",
      "Epoch 28/90\n",
      "144/144 [==============================] - 0s 1ms/step - loss: 0.0122 - val_loss: 0.0084\n",
      "Epoch 29/90\n",
      "144/144 [==============================] - 0s 1ms/step - loss: 0.0120 - val_loss: 0.0074\n",
      "Epoch 30/90\n",
      "144/144 [==============================] - 0s 1ms/step - loss: 0.0120 - val_loss: 0.0071\n",
      "Epoch 31/90\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "144/144 [==============================] - 0s 1ms/step - loss: 0.0122 - val_loss: 0.0075\n",
      "Epoch 32/90\n",
      "144/144 [==============================] - 0s 1ms/step - loss: 0.0120 - val_loss: 0.0082\n",
      "Epoch 33/90\n",
      "144/144 [==============================] - 0s 1ms/step - loss: 0.0120 - val_loss: 0.0066\n",
      "Epoch 34/90\n",
      "144/144 [==============================] - 0s 1ms/step - loss: 0.0120 - val_loss: 0.0068\n",
      "Epoch 35/90\n",
      "144/144 [==============================] - 0s 1ms/step - loss: 0.0121 - val_loss: 0.0053\n",
      "Epoch 36/90\n",
      "144/144 [==============================] - 0s 1ms/step - loss: 0.0122 - val_loss: 0.0074\n",
      "Epoch 37/90\n",
      "144/144 [==============================] - 0s 1ms/step - loss: 0.0121 - val_loss: 0.0073\n",
      "Epoch 38/90\n",
      "144/144 [==============================] - 0s 1ms/step - loss: 0.0120 - val_loss: 0.0064\n",
      "Epoch 39/90\n",
      "144/144 [==============================] - 0s 1ms/step - loss: 0.0119 - val_loss: 0.0068\n",
      "Epoch 40/90\n",
      "144/144 [==============================] - 0s 1ms/step - loss: 0.0119 - val_loss: 0.0073\n",
      "Epoch 41/90\n",
      "144/144 [==============================] - 0s 1ms/step - loss: 0.0119 - val_loss: 0.0065\n",
      "Epoch 42/90\n",
      "144/144 [==============================] - 0s 1ms/step - loss: 0.0119 - val_loss: 0.0069\n",
      "Epoch 43/90\n",
      "144/144 [==============================] - 0s 1ms/step - loss: 0.0120 - val_loss: 0.0072\n",
      "Epoch 44/90\n",
      "144/144 [==============================] - 0s 1ms/step - loss: 0.0119 - val_loss: 0.0074\n",
      "Epoch 45/90\n",
      "144/144 [==============================] - 0s 1ms/step - loss: 0.0118 - val_loss: 0.0069\n",
      "Epoch 46/90\n",
      "144/144 [==============================] - 0s 1ms/step - loss: 0.0118 - val_loss: 0.0058\n",
      "Epoch 47/90\n",
      "144/144 [==============================] - 0s 1ms/step - loss: 0.0119 - val_loss: 0.0066\n",
      "Epoch 48/90\n",
      "144/144 [==============================] - 0s 1ms/step - loss: 0.0118 - val_loss: 0.0078\n",
      "Epoch 49/90\n",
      "144/144 [==============================] - 0s 1ms/step - loss: 0.0118 - val_loss: 0.0076\n",
      "Epoch 50/90\n",
      "144/144 [==============================] - 0s 1ms/step - loss: 0.0118 - val_loss: 0.0074\n",
      "Epoch 51/90\n",
      "144/144 [==============================] - 0s 1ms/step - loss: 0.0117 - val_loss: 0.0064\n",
      "Epoch 52/90\n",
      "144/144 [==============================] - 0s 1ms/step - loss: 0.0116 - val_loss: 0.0062\n",
      "Epoch 53/90\n",
      "144/144 [==============================] - 0s 1ms/step - loss: 0.0118 - val_loss: 0.0064\n",
      "Epoch 54/90\n",
      "144/144 [==============================] - 0s 1ms/step - loss: 0.0116 - val_loss: 0.0065\n",
      "Epoch 55/90\n",
      "144/144 [==============================] - 0s 1ms/step - loss: 0.0116 - val_loss: 0.0059\n",
      "Epoch 56/90\n",
      "144/144 [==============================] - 0s 1ms/step - loss: 0.0117 - val_loss: 0.0064\n",
      "Epoch 57/90\n",
      "144/144 [==============================] - 0s 1ms/step - loss: 0.0115 - val_loss: 0.0060\n",
      "Epoch 58/90\n",
      "144/144 [==============================] - 0s 1ms/step - loss: 0.0115 - val_loss: 0.0059\n",
      "Epoch 59/90\n",
      "144/144 [==============================] - 0s 1ms/step - loss: 0.0116 - val_loss: 0.0072\n",
      "Epoch 60/90\n",
      "144/144 [==============================] - 0s 1ms/step - loss: 0.0114 - val_loss: 0.0072\n",
      "Epoch 61/90\n",
      "144/144 [==============================] - 0s 1ms/step - loss: 0.0114 - val_loss: 0.0063\n",
      "Epoch 62/90\n",
      "144/144 [==============================] - 0s 1ms/step - loss: 0.0114 - val_loss: 0.0064\n",
      "Epoch 63/90\n",
      "144/144 [==============================] - 0s 1ms/step - loss: 0.0113 - val_loss: 0.0061\n",
      "Epoch 64/90\n",
      "144/144 [==============================] - 0s 1ms/step - loss: 0.0114 - val_loss: 0.0061\n",
      "Epoch 65/90\n",
      "144/144 [==============================] - 0s 1ms/step - loss: 0.0113 - val_loss: 0.0059\n",
      "Epoch 66/90\n",
      "144/144 [==============================] - 0s 1ms/step - loss: 0.0114 - val_loss: 0.0064\n",
      "Epoch 67/90\n",
      "144/144 [==============================] - 0s 1ms/step - loss: 0.0114 - val_loss: 0.0065\n",
      "Epoch 68/90\n",
      "144/144 [==============================] - 0s 1ms/step - loss: 0.0114 - val_loss: 0.0064\n",
      "Epoch 69/90\n",
      "144/144 [==============================] - 0s 1ms/step - loss: 0.0112 - val_loss: 0.0058\n",
      "Epoch 70/90\n",
      "144/144 [==============================] - 0s 1ms/step - loss: 0.0113 - val_loss: 0.0062\n",
      "Epoch 71/90\n",
      "144/144 [==============================] - 0s 1ms/step - loss: 0.0111 - val_loss: 0.0058\n",
      "Epoch 72/90\n",
      "144/144 [==============================] - 0s 1ms/step - loss: 0.0113 - val_loss: 0.0063\n",
      "Epoch 73/90\n",
      "144/144 [==============================] - 0s 1ms/step - loss: 0.0113 - val_loss: 0.0056\n",
      "Epoch 74/90\n",
      "144/144 [==============================] - 0s 1ms/step - loss: 0.0112 - val_loss: 0.0063\n",
      "Epoch 75/90\n",
      "144/144 [==============================] - 0s 1ms/step - loss: 0.0113 - val_loss: 0.0059\n",
      "Epoch 76/90\n",
      "144/144 [==============================] - 0s 1ms/step - loss: 0.0113 - val_loss: 0.0060\n",
      "Epoch 77/90\n",
      "144/144 [==============================] - 0s 1ms/step - loss: 0.0111 - val_loss: 0.0060\n",
      "Epoch 78/90\n",
      "144/144 [==============================] - 0s 1ms/step - loss: 0.0113 - val_loss: 0.0058\n",
      "Epoch 79/90\n",
      "144/144 [==============================] - 0s 1ms/step - loss: 0.0112 - val_loss: 0.0056\n",
      "Epoch 80/90\n",
      "144/144 [==============================] - 0s 1ms/step - loss: 0.0112 - val_loss: 0.0057\n",
      "Epoch 81/90\n",
      "144/144 [==============================] - 0s 1ms/step - loss: 0.0112 - val_loss: 0.0065\n",
      "Epoch 82/90\n",
      "144/144 [==============================] - 0s 1ms/step - loss: 0.0111 - val_loss: 0.0058\n",
      "Epoch 83/90\n",
      "144/144 [==============================] - 0s 1ms/step - loss: 0.0112 - val_loss: 0.0061\n",
      "Epoch 84/90\n",
      "144/144 [==============================] - 0s 1ms/step - loss: 0.0111 - val_loss: 0.0062\n",
      "Epoch 85/90\n",
      "144/144 [==============================] - 0s 1ms/step - loss: 0.0110 - val_loss: 0.0059\n",
      "Epoch 86/90\n",
      "144/144 [==============================] - 0s 1ms/step - loss: 0.0111 - val_loss: 0.0060\n",
      "Epoch 87/90\n",
      "144/144 [==============================] - 0s 1ms/step - loss: 0.0112 - val_loss: 0.0061\n",
      "Epoch 88/90\n",
      "144/144 [==============================] - 0s 1ms/step - loss: 0.0110 - val_loss: 0.0059\n",
      "Epoch 89/90\n",
      "144/144 [==============================] - 0s 1ms/step - loss: 0.0111 - val_loss: 0.0060\n",
      "Epoch 90/90\n",
      "144/144 [==============================] - 0s 1ms/step - loss: 0.0111 - val_loss: 0.0056\n",
      "Execution time:  20.425318241119385\n",
      "DNN:\n",
      "Mean Absolute Error: 0.0055\n",
      "Root Mean Square Error: 0.0201\n",
      "Mean Square Error: 0.0004\n",
      "\n",
      "Train RMSE: 0.020\n",
      "Train MSE: 0.000\n",
      "Train MAE: 0.005\n",
      "###########################\n",
      "\n",
      "MODEL:  DNN\n",
      "sequence:  1h\n",
      "units:  12\n",
      "dropout1:  0.48476373451509647\n",
      "optimizer: adam\n",
      "activationDense: sigmoid\n",
      "epochs: 52\n",
      "batchsize: 57\n",
      "validation_split: 0.1\n",
      "Model: \"sequential_8\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_24 (Dense)             (None, 6, 12)             24        \n",
      "_________________________________________________________________\n",
      "dense_25 (Dense)             (None, 6, 16)             208       \n",
      "_________________________________________________________________\n",
      "dropout_8 (Dropout)          (None, 6, 16)             0         \n",
      "_________________________________________________________________\n",
      "dense_26 (Dense)             (None, 6, 1)              17        \n",
      "=================================================================\n",
      "Total params: 249\n",
      "Trainable params: 249\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/52\n",
      "63/63 [==============================] - 0s 4ms/step - loss: 0.0734 - val_loss: 0.0439\n",
      "Epoch 2/52\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0475 - val_loss: 0.0398\n",
      "Epoch 3/52\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0425 - val_loss: 0.0352\n",
      "Epoch 4/52\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0405 - val_loss: 0.0338\n",
      "Epoch 5/52\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0388 - val_loss: 0.0339\n",
      "Epoch 6/52\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0375 - val_loss: 0.0331\n",
      "Epoch 7/52\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0365 - val_loss: 0.0319\n",
      "Epoch 8/52\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0356 - val_loss: 0.0315\n",
      "Epoch 9/52\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0344 - val_loss: 0.0297\n",
      "Epoch 10/52\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0337 - val_loss: 0.0267\n",
      "Epoch 11/52\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0328 - val_loss: 0.0242\n",
      "Epoch 12/52\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0317 - val_loss: 0.0237\n",
      "Epoch 13/52\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0309 - val_loss: 0.0227\n",
      "Epoch 14/52\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0303 - val_loss: 0.0221\n",
      "Epoch 15/52\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0294 - val_loss: 0.0213\n",
      "Epoch 16/52\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0288 - val_loss: 0.0208\n",
      "Epoch 17/52\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0281 - val_loss: 0.0202\n",
      "Epoch 18/52\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0277 - val_loss: 0.0194\n",
      "Epoch 19/52\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0270 - val_loss: 0.0187\n",
      "Epoch 20/52\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0263 - val_loss: 0.0181\n",
      "Epoch 21/52\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0256 - val_loss: 0.0177\n",
      "Epoch 22/52\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0250 - val_loss: 0.0171\n",
      "Epoch 23/52\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0245 - val_loss: 0.0167\n",
      "Epoch 24/52\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0240 - val_loss: 0.0160\n",
      "Epoch 25/52\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0234 - val_loss: 0.0156\n",
      "Epoch 26/52\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0228 - val_loss: 0.0151\n",
      "Epoch 27/52\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0223 - val_loss: 0.0147\n",
      "Epoch 28/52\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0217 - val_loss: 0.0142\n",
      "Epoch 29/52\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0211 - val_loss: 0.0138\n",
      "Epoch 30/52\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0208 - val_loss: 0.0136\n",
      "Epoch 31/52\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0202 - val_loss: 0.0125\n",
      "Epoch 32/52\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0201 - val_loss: 0.0120\n",
      "Epoch 33/52\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0196 - val_loss: 0.0114\n",
      "Epoch 34/52\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0194 - val_loss: 0.0113\n",
      "Epoch 35/52\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0189 - val_loss: 0.0107\n",
      "Epoch 36/52\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0187 - val_loss: 0.0107\n",
      "Epoch 37/52\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0182 - val_loss: 0.0100\n",
      "Epoch 38/52\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0180 - val_loss: 0.0102\n",
      "Epoch 39/52\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0177 - val_loss: 0.0099\n",
      "Epoch 40/52\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0176 - val_loss: 0.0103\n",
      "Epoch 41/52\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0172 - val_loss: 0.0099\n",
      "Epoch 42/52\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0171 - val_loss: 0.0103\n",
      "Epoch 43/52\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0168 - val_loss: 0.0097\n",
      "Epoch 44/52\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0170 - val_loss: 0.0090\n",
      "Epoch 45/52\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0167 - val_loss: 0.0100\n",
      "Epoch 46/52\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0166 - val_loss: 0.0095\n",
      "Epoch 47/52\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0165 - val_loss: 0.0095\n",
      "Epoch 48/52\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0166 - val_loss: 0.0096\n",
      "Epoch 49/52\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0167 - val_loss: 0.0093\n",
      "Epoch 50/52\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0164 - val_loss: 0.0095\n",
      "Epoch 51/52\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0164 - val_loss: 0.0097\n",
      "Epoch 52/52\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0163 - val_loss: 0.0095\n",
      "Execution time:  6.711838960647583\n",
      "DNN:\n",
      "Mean Absolute Error: 0.0109\n",
      "Root Mean Square Error: 0.0194\n",
      "Mean Square Error: 0.0004\n",
      "\n",
      "Train RMSE: 0.019\n",
      "Train MSE: 0.000\n",
      "Train MAE: 0.011\n",
      "###########################\n",
      "\n",
      "MODEL:  DNN\n",
      "sequence:  1h\n",
      "units:  87\n",
      "dropout1:  0.40519643149940265\n",
      "optimizer: adam\n",
      "activationDense: sigmoid\n",
      "epochs: 80\n",
      "batchsize: 31\n",
      "validation_split: 0.2\n",
      "Model: \"sequential_9\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_27 (Dense)             (None, 6, 87)             174       \n",
      "_________________________________________________________________\n",
      "dense_28 (Dense)             (None, 6, 16)             1408      \n",
      "_________________________________________________________________\n",
      "dropout_9 (Dropout)          (None, 6, 16)             0         \n",
      "_________________________________________________________________\n",
      "dense_29 (Dense)             (None, 6, 1)              17        \n",
      "=================================================================\n",
      "Total params: 1,599\n",
      "Trainable params: 1,599\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/80\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 0.0493 - val_loss: 0.0275\n",
      "Epoch 2/80\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.0456 - val_loss: 0.0197\n",
      "Epoch 3/80\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.0428 - val_loss: 0.0211\n",
      "Epoch 4/80\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.0410 - val_loss: 0.0217\n",
      "Epoch 5/80\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.0391 - val_loss: 0.0218\n",
      "Epoch 6/80\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.0374 - val_loss: 0.0211\n",
      "Epoch 7/80\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.0362 - val_loss: 0.0205\n",
      "Epoch 8/80\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.0351 - val_loss: 0.0195\n",
      "Epoch 9/80\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.0341 - val_loss: 0.0191\n",
      "Epoch 10/80\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.0330 - val_loss: 0.0188\n",
      "Epoch 11/80\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.0323 - val_loss: 0.0181\n",
      "Epoch 12/80\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.0313 - val_loss: 0.0176\n",
      "Epoch 13/80\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.0305 - val_loss: 0.0169\n",
      "Epoch 14/80\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.0301 - val_loss: 0.0166\n",
      "Epoch 15/80\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.0292 - val_loss: 0.0160\n",
      "Epoch 16/80\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.0287 - val_loss: 0.0154\n",
      "Epoch 17/80\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.0282 - val_loss: 0.0151\n",
      "Epoch 18/80\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.0273 - val_loss: 0.0145\n",
      "Epoch 19/80\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.0270 - val_loss: 0.0144\n",
      "Epoch 20/80\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.0264 - val_loss: 0.0142\n",
      "Epoch 21/80\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.0261 - val_loss: 0.0140\n",
      "Epoch 22/80\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.0257 - val_loss: 0.0139\n",
      "Epoch 23/80\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.0254 - val_loss: 0.0138\n",
      "Epoch 24/80\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.0252 - val_loss: 0.0138\n",
      "Epoch 25/80\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.0249 - val_loss: 0.0137\n",
      "Epoch 26/80\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.0247 - val_loss: 0.0137\n",
      "Epoch 27/80\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.0244 - val_loss: 0.0136\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 28/80\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.0241 - val_loss: 0.0137\n",
      "Epoch 29/80\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.0238 - val_loss: 0.0137\n",
      "Epoch 30/80\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.0235 - val_loss: 0.0139\n",
      "Epoch 31/80\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.0234 - val_loss: 0.0140\n",
      "Epoch 32/80\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.0233 - val_loss: 0.0140\n",
      "Epoch 33/80\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.0227 - val_loss: 0.0138\n",
      "Epoch 34/80\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.0225 - val_loss: 0.0139\n",
      "Epoch 35/80\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.0222 - val_loss: 0.0137\n",
      "Epoch 36/80\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.0221 - val_loss: 0.0135\n",
      "Epoch 37/80\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.0218 - val_loss: 0.0133\n",
      "Epoch 38/80\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.0216 - val_loss: 0.0134\n",
      "Epoch 39/80\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.0215 - val_loss: 0.0132\n",
      "Epoch 40/80\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.0212 - val_loss: 0.0132\n",
      "Epoch 41/80\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.0210 - val_loss: 0.0151\n",
      "Epoch 42/80\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.0207 - val_loss: 0.0144\n",
      "Epoch 43/80\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.0203 - val_loss: 0.0140\n",
      "Epoch 44/80\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.0200 - val_loss: 0.0140\n",
      "Epoch 45/80\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.0197 - val_loss: 0.0131\n",
      "Epoch 46/80\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.0199 - val_loss: 0.0127\n",
      "Epoch 47/80\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.0197 - val_loss: 0.0142\n",
      "Epoch 48/80\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.0196 - val_loss: 0.0140\n",
      "Epoch 49/80\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.0195 - val_loss: 0.0143\n",
      "Epoch 50/80\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.0196 - val_loss: 0.0140\n",
      "Epoch 51/80\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.0196 - val_loss: 0.0143\n",
      "Epoch 52/80\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.0195 - val_loss: 0.0136\n",
      "Epoch 53/80\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.0192 - val_loss: 0.0143\n",
      "Epoch 54/80\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.0194 - val_loss: 0.0142\n",
      "Epoch 55/80\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.0194 - val_loss: 0.0137\n",
      "Epoch 56/80\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.0196 - val_loss: 0.0133\n",
      "Epoch 57/80\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.0194 - val_loss: 0.0143\n",
      "Epoch 58/80\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.0195 - val_loss: 0.0151\n",
      "Epoch 59/80\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.0194 - val_loss: 0.0143\n",
      "Epoch 60/80\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.0197 - val_loss: 0.0136\n",
      "Epoch 61/80\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.0194 - val_loss: 0.0144\n",
      "Epoch 62/80\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.0195 - val_loss: 0.0139\n",
      "Epoch 63/80\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.0196 - val_loss: 0.0142\n",
      "Epoch 64/80\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.0195 - val_loss: 0.0141\n",
      "Epoch 65/80\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.0194 - val_loss: 0.0144\n",
      "Epoch 66/80\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.0196 - val_loss: 0.0131\n",
      "Epoch 67/80\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.0196 - val_loss: 0.0139\n",
      "Epoch 68/80\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.0198 - val_loss: 0.0136\n",
      "Epoch 69/80\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.0193 - val_loss: 0.0129\n",
      "Epoch 70/80\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.0196 - val_loss: 0.0137\n",
      "Epoch 71/80\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.0195 - val_loss: 0.0138\n",
      "Epoch 72/80\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.0195 - val_loss: 0.0153\n",
      "Epoch 73/80\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.0194 - val_loss: 0.0140\n",
      "Epoch 74/80\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.0199 - val_loss: 0.0124\n",
      "Epoch 75/80\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.0195 - val_loss: 0.0150\n",
      "Epoch 76/80\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.0195 - val_loss: 0.0134\n",
      "Epoch 77/80\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.0194 - val_loss: 0.0142\n",
      "Epoch 78/80\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.0194 - val_loss: 0.0140\n",
      "Epoch 79/80\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.0195 - val_loss: 0.0136\n",
      "Epoch 80/80\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.0195 - val_loss: 0.0145\n",
      "Execution time:  15.500949144363403\n",
      "DNN:\n",
      "Mean Absolute Error: 0.0142\n",
      "Root Mean Square Error: 0.0282\n",
      "Mean Square Error: 0.0008\n",
      "\n",
      "Train RMSE: 0.028\n",
      "Train MSE: 0.001\n",
      "Train MAE: 0.014\n",
      "###########################\n",
      "\n",
      "MODEL:  DNN\n",
      "sequence:  1h\n",
      "units:  80\n",
      "dropout1:  0.11814836227952394\n",
      "optimizer: adam\n",
      "activationDense: sigmoid\n",
      "epochs: 90\n",
      "batchsize: 25\n",
      "validation_split: 0.2\n",
      "Model: \"sequential_10\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_30 (Dense)             (None, 6, 80)             160       \n",
      "_________________________________________________________________\n",
      "dense_31 (Dense)             (None, 6, 16)             1296      \n",
      "_________________________________________________________________\n",
      "dropout_10 (Dropout)         (None, 6, 16)             0         \n",
      "_________________________________________________________________\n",
      "dense_32 (Dense)             (None, 6, 1)              17        \n",
      "=================================================================\n",
      "Total params: 1,473\n",
      "Trainable params: 1,473\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/90\n",
      "128/128 [==============================] - 0s 3ms/step - loss: 0.0387 - val_loss: 0.0180\n",
      "Epoch 2/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0392 - val_loss: 0.0185\n",
      "Epoch 3/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0380 - val_loss: 0.0185\n",
      "Epoch 4/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0369 - val_loss: 0.0183\n",
      "Epoch 5/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0364 - val_loss: 0.0187\n",
      "Epoch 6/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0358 - val_loss: 0.0178\n",
      "Epoch 7/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0354 - val_loss: 0.0178\n",
      "Epoch 8/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0350 - val_loss: 0.0181\n",
      "Epoch 9/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0334 - val_loss: 0.0167\n",
      "Epoch 10/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0342 - val_loss: 0.0176\n",
      "Epoch 11/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0332 - val_loss: 0.0174\n",
      "Epoch 12/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0327 - val_loss: 0.0174\n",
      "Epoch 13/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0323 - val_loss: 0.0171\n",
      "Epoch 14/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0319 - val_loss: 0.0169\n",
      "Epoch 15/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0315 - val_loss: 0.0168\n",
      "Epoch 16/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0311 - val_loss: 0.0166\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0306 - val_loss: 0.0166\n",
      "Epoch 18/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0301 - val_loss: 0.0158\n",
      "Epoch 19/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0300 - val_loss: 0.0163\n",
      "Epoch 20/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0295 - val_loss: 0.0161\n",
      "Epoch 21/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0290 - val_loss: 0.0158\n",
      "Epoch 22/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0285 - val_loss: 0.0156\n",
      "Epoch 23/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0280 - val_loss: 0.0150\n",
      "Epoch 24/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0277 - val_loss: 0.0144\n",
      "Epoch 25/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0267 - val_loss: 0.0143\n",
      "Epoch 26/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0259 - val_loss: 0.0140\n",
      "Epoch 27/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0249 - val_loss: 0.0141\n",
      "Epoch 28/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0240 - val_loss: 0.0137\n",
      "Epoch 29/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0231 - val_loss: 0.0135\n",
      "Epoch 30/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0225 - val_loss: 0.0126\n",
      "Epoch 31/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0219 - val_loss: 0.0128\n",
      "Epoch 32/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0211 - val_loss: 0.0123\n",
      "Epoch 33/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0201 - val_loss: 0.0119\n",
      "Epoch 34/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0190 - val_loss: 0.0115\n",
      "Epoch 35/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0184 - val_loss: 0.0109\n",
      "Epoch 36/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0173 - val_loss: 0.0109\n",
      "Epoch 37/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0163 - val_loss: 0.0108\n",
      "Epoch 38/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0156 - val_loss: 0.0109\n",
      "Epoch 39/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0151 - val_loss: 0.0107\n",
      "Epoch 40/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0146 - val_loss: 0.0091\n",
      "Epoch 41/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0143 - val_loss: 0.0117\n",
      "Epoch 42/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0138 - val_loss: 0.0098\n",
      "Epoch 43/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0138 - val_loss: 0.0111\n",
      "Epoch 44/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0135 - val_loss: 0.0089\n",
      "Epoch 45/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0138 - val_loss: 0.0098\n",
      "Epoch 46/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0135 - val_loss: 0.0095\n",
      "Epoch 47/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0136 - val_loss: 0.0094\n",
      "Epoch 48/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0136 - val_loss: 0.0110\n",
      "Epoch 49/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0135 - val_loss: 0.0109\n",
      "Epoch 50/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0136 - val_loss: 0.0114\n",
      "Epoch 51/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0137 - val_loss: 0.0083\n",
      "Epoch 52/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0135 - val_loss: 0.0113\n",
      "Epoch 53/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0134 - val_loss: 0.0109\n",
      "Epoch 54/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0135 - val_loss: 0.0105\n",
      "Epoch 55/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0134 - val_loss: 0.0106\n",
      "Epoch 56/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0135 - val_loss: 0.0107\n",
      "Epoch 57/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0134 - val_loss: 0.0098\n",
      "Epoch 58/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0136 - val_loss: 0.0116\n",
      "Epoch 59/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0135 - val_loss: 0.0123\n",
      "Epoch 60/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0135 - val_loss: 0.0117\n",
      "Epoch 61/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0137 - val_loss: 0.0114\n",
      "Epoch 62/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0135 - val_loss: 0.0097\n",
      "Epoch 63/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0136 - val_loss: 0.0117\n",
      "Epoch 64/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0136 - val_loss: 0.0094\n",
      "Epoch 65/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0138 - val_loss: 0.0100\n",
      "Epoch 66/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0136 - val_loss: 0.0103\n",
      "Epoch 67/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0137 - val_loss: 0.0108\n",
      "Epoch 68/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0134 - val_loss: 0.0110\n",
      "Epoch 69/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0134 - val_loss: 0.0088\n",
      "Epoch 70/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0135 - val_loss: 0.0082\n",
      "Epoch 71/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0134 - val_loss: 0.0087\n",
      "Epoch 72/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0134 - val_loss: 0.0078\n",
      "Epoch 73/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0134 - val_loss: 0.0081\n",
      "Epoch 74/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0134 - val_loss: 0.0081\n",
      "Epoch 75/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0134 - val_loss: 0.0084\n",
      "Epoch 76/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0133 - val_loss: 0.0082\n",
      "Epoch 77/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0133 - val_loss: 0.0087\n",
      "Epoch 78/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0134 - val_loss: 0.0085\n",
      "Epoch 79/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0134 - val_loss: 0.0087\n",
      "Epoch 80/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0133 - val_loss: 0.0083\n",
      "Epoch 81/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0134 - val_loss: 0.0085\n",
      "Epoch 82/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0134 - val_loss: 0.0091\n",
      "Epoch 83/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0133 - val_loss: 0.0085\n",
      "Epoch 84/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0133 - val_loss: 0.0083\n",
      "Epoch 85/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0132 - val_loss: 0.0084\n",
      "Epoch 86/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0134 - val_loss: 0.0086\n",
      "Epoch 87/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0133 - val_loss: 0.0084\n",
      "Epoch 88/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0134 - val_loss: 0.0085\n",
      "Epoch 89/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0134 - val_loss: 0.0087\n",
      "Epoch 90/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0133 - val_loss: 0.0083\n",
      "Execution time:  19.581538677215576\n",
      "DNN:\n",
      "Mean Absolute Error: 0.0070\n",
      "Root Mean Square Error: 0.0230\n",
      "Mean Square Error: 0.0005\n",
      "\n",
      "Train RMSE: 0.023\n",
      "Train MSE: 0.001\n",
      "Train MAE: 0.007\n",
      "###########################\n",
      "\n",
      "MODEL:  DNN\n",
      "sequence:  1h\n",
      "units:  12\n",
      "dropout1:  0.48476373451509647\n",
      "optimizer: adam\n",
      "activationDense: sigmoid\n",
      "epochs: 52\n",
      "batchsize: 57\n",
      "validation_split: 0.2\n",
      "Model: \"sequential_11\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_33 (Dense)             (None, 6, 12)             24        \n",
      "_________________________________________________________________\n",
      "dense_34 (Dense)             (None, 6, 16)             208       \n",
      "_________________________________________________________________\n",
      "dropout_11 (Dropout)         (None, 6, 16)             0         \n",
      "_________________________________________________________________\n",
      "dense_35 (Dense)             (None, 6, 1)              17        \n",
      "=================================================================\n",
      "Total params: 249\n",
      "Trainable params: 249\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/52\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "56/56 [==============================] - 0s 5ms/step - loss: 0.0495 - val_loss: 0.0381\n",
      "Epoch 2/52\n",
      "56/56 [==============================] - 0s 2ms/step - loss: 0.0453 - val_loss: 0.0382\n",
      "Epoch 3/52\n",
      "56/56 [==============================] - 0s 2ms/step - loss: 0.0431 - val_loss: 0.0353\n",
      "Epoch 4/52\n",
      "56/56 [==============================] - 0s 2ms/step - loss: 0.0417 - val_loss: 0.0351\n",
      "Epoch 5/52\n",
      "56/56 [==============================] - 0s 2ms/step - loss: 0.0405 - val_loss: 0.0338\n",
      "Epoch 6/52\n",
      "56/56 [==============================] - 0s 2ms/step - loss: 0.0393 - val_loss: 0.0327\n",
      "Epoch 7/52\n",
      "56/56 [==============================] - 0s 2ms/step - loss: 0.0389 - val_loss: 0.0329\n",
      "Epoch 8/52\n",
      "56/56 [==============================] - 0s 2ms/step - loss: 0.0376 - val_loss: 0.0324\n",
      "Epoch 9/52\n",
      "56/56 [==============================] - 0s 2ms/step - loss: 0.0370 - val_loss: 0.0272\n",
      "Epoch 10/52\n",
      "56/56 [==============================] - 0s 2ms/step - loss: 0.0358 - val_loss: 0.0263\n",
      "Epoch 11/52\n",
      "56/56 [==============================] - 0s 2ms/step - loss: 0.0352 - val_loss: 0.0258\n",
      "Epoch 12/52\n",
      "56/56 [==============================] - 0s 2ms/step - loss: 0.0346 - val_loss: 0.0256\n",
      "Epoch 13/52\n",
      "56/56 [==============================] - 0s 2ms/step - loss: 0.0335 - val_loss: 0.0244\n",
      "Epoch 14/52\n",
      "56/56 [==============================] - 0s 2ms/step - loss: 0.0332 - val_loss: 0.0244\n",
      "Epoch 15/52\n",
      "56/56 [==============================] - 0s 2ms/step - loss: 0.0328 - val_loss: 0.0243\n",
      "Epoch 16/52\n",
      "56/56 [==============================] - 0s 2ms/step - loss: 0.0322 - val_loss: 0.0238\n",
      "Epoch 17/52\n",
      "56/56 [==============================] - 0s 2ms/step - loss: 0.0318 - val_loss: 0.0237\n",
      "Epoch 18/52\n",
      "56/56 [==============================] - 0s 2ms/step - loss: 0.0312 - val_loss: 0.0229\n",
      "Epoch 19/52\n",
      "56/56 [==============================] - 0s 2ms/step - loss: 0.0308 - val_loss: 0.0225\n",
      "Epoch 20/52\n",
      "56/56 [==============================] - 0s 2ms/step - loss: 0.0306 - val_loss: 0.0222\n",
      "Epoch 21/52\n",
      "56/56 [==============================] - 0s 2ms/step - loss: 0.0300 - val_loss: 0.0217\n",
      "Epoch 22/52\n",
      "56/56 [==============================] - 0s 2ms/step - loss: 0.0293 - val_loss: 0.0206\n",
      "Epoch 23/52\n",
      "56/56 [==============================] - 0s 2ms/step - loss: 0.0292 - val_loss: 0.0201\n",
      "Epoch 24/52\n",
      "56/56 [==============================] - 0s 2ms/step - loss: 0.0290 - val_loss: 0.0200\n",
      "Epoch 25/52\n",
      "56/56 [==============================] - 0s 2ms/step - loss: 0.0282 - val_loss: 0.0194\n",
      "Epoch 26/52\n",
      "56/56 [==============================] - 0s 2ms/step - loss: 0.0281 - val_loss: 0.0191\n",
      "Epoch 27/52\n",
      "56/56 [==============================] - 0s 2ms/step - loss: 0.0275 - val_loss: 0.0183\n",
      "Epoch 28/52\n",
      "56/56 [==============================] - 0s 2ms/step - loss: 0.0272 - val_loss: 0.0179\n",
      "Epoch 29/52\n",
      "56/56 [==============================] - 0s 2ms/step - loss: 0.0269 - val_loss: 0.0177\n",
      "Epoch 30/52\n",
      "56/56 [==============================] - 0s 2ms/step - loss: 0.0264 - val_loss: 0.0172\n",
      "Epoch 31/52\n",
      "56/56 [==============================] - 0s 2ms/step - loss: 0.0260 - val_loss: 0.0171\n",
      "Epoch 32/52\n",
      "56/56 [==============================] - 0s 2ms/step - loss: 0.0256 - val_loss: 0.0167\n",
      "Epoch 33/52\n",
      "56/56 [==============================] - 0s 2ms/step - loss: 0.0253 - val_loss: 0.0165\n",
      "Epoch 34/52\n",
      "56/56 [==============================] - 0s 2ms/step - loss: 0.0249 - val_loss: 0.0162\n",
      "Epoch 35/52\n",
      "56/56 [==============================] - 0s 2ms/step - loss: 0.0245 - val_loss: 0.0160\n",
      "Epoch 36/52\n",
      "56/56 [==============================] - 0s 2ms/step - loss: 0.0240 - val_loss: 0.0156\n",
      "Epoch 37/52\n",
      "56/56 [==============================] - 0s 2ms/step - loss: 0.0237 - val_loss: 0.0152\n",
      "Epoch 38/52\n",
      "56/56 [==============================] - 0s 2ms/step - loss: 0.0233 - val_loss: 0.0149\n",
      "Epoch 39/52\n",
      "56/56 [==============================] - 0s 2ms/step - loss: 0.0233 - val_loss: 0.0148\n",
      "Epoch 40/52\n",
      "56/56 [==============================] - 0s 2ms/step - loss: 0.0228 - val_loss: 0.0145\n",
      "Epoch 41/52\n",
      "56/56 [==============================] - 0s 2ms/step - loss: 0.0222 - val_loss: 0.0140\n",
      "Epoch 42/52\n",
      "56/56 [==============================] - 0s 2ms/step - loss: 0.0222 - val_loss: 0.0140\n",
      "Epoch 43/52\n",
      "56/56 [==============================] - 0s 2ms/step - loss: 0.0215 - val_loss: 0.0135\n",
      "Epoch 44/52\n",
      "56/56 [==============================] - 0s 2ms/step - loss: 0.0214 - val_loss: 0.0132\n",
      "Epoch 45/52\n",
      "56/56 [==============================] - 0s 2ms/step - loss: 0.0212 - val_loss: 0.0131\n",
      "Epoch 46/52\n",
      "56/56 [==============================] - 0s 2ms/step - loss: 0.0205 - val_loss: 0.0127\n",
      "Epoch 47/52\n",
      "56/56 [==============================] - 0s 2ms/step - loss: 0.0202 - val_loss: 0.0123\n",
      "Epoch 48/52\n",
      "56/56 [==============================] - 0s 2ms/step - loss: 0.0202 - val_loss: 0.0123\n",
      "Epoch 49/52\n",
      "56/56 [==============================] - 0s 2ms/step - loss: 0.0197 - val_loss: 0.0120\n",
      "Epoch 50/52\n",
      "56/56 [==============================] - 0s 2ms/step - loss: 0.0194 - val_loss: 0.0118\n",
      "Epoch 51/52\n",
      "56/56 [==============================] - 0s 2ms/step - loss: 0.0191 - val_loss: 0.0116\n",
      "Epoch 52/52\n",
      "56/56 [==============================] - 0s 2ms/step - loss: 0.0189 - val_loss: 0.0115\n",
      "Execution time:  6.61554479598999\n",
      "DNN:\n",
      "Mean Absolute Error: 0.0144\n",
      "Root Mean Square Error: 0.0247\n",
      "Mean Square Error: 0.0006\n",
      "\n",
      "Train RMSE: 0.025\n",
      "Train MSE: 0.001\n",
      "Train MAE: 0.014\n",
      "###########################\n",
      "\n",
      "MODEL:  DNN\n",
      "sequence:  1h\n",
      "units:  87\n",
      "dropout1:  0.40519643149940265\n",
      "optimizer: adadelta\n",
      "activationDense: tanh\n",
      "epochs: 80\n",
      "batchsize: 31\n",
      "validation_split: 0.1\n",
      "Model: \"sequential_12\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_36 (Dense)             (None, 6, 87)             174       \n",
      "_________________________________________________________________\n",
      "dense_37 (Dense)             (None, 6, 16)             1408      \n",
      "_________________________________________________________________\n",
      "dropout_12 (Dropout)         (None, 6, 16)             0         \n",
      "_________________________________________________________________\n",
      "dense_38 (Dense)             (None, 6, 1)              17        \n",
      "=================================================================\n",
      "Total params: 1,599\n",
      "Trainable params: 1,599\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/80\n",
      "116/116 [==============================] - 0s 3ms/step - loss: 0.4534 - val_loss: 0.4112\n",
      "Epoch 2/80\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.4496 - val_loss: 0.4076\n",
      "Epoch 3/80\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.4458 - val_loss: 0.4037\n",
      "Epoch 4/80\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.4421 - val_loss: 0.3997\n",
      "Epoch 5/80\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.4376 - val_loss: 0.3955\n",
      "Epoch 6/80\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.4333 - val_loss: 0.3910\n",
      "Epoch 7/80\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.4288 - val_loss: 0.3864\n",
      "Epoch 8/80\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.4237 - val_loss: 0.3816\n",
      "Epoch 9/80\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 0.4188 - val_loss: 0.3767\n",
      "Epoch 10/80\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 0.4131 - val_loss: 0.3715\n",
      "Epoch 11/80\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.4076 - val_loss: 0.3662\n",
      "Epoch 12/80\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.4014 - val_loss: 0.3607\n",
      "Epoch 13/80\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.3961 - val_loss: 0.3550\n",
      "Epoch 14/80\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.3898 - val_loss: 0.3492\n",
      "Epoch 15/80\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.3837 - val_loss: 0.3431\n",
      "Epoch 16/80\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.3780 - val_loss: 0.3370\n",
      "Epoch 17/80\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 0.3721 - val_loss: 0.3307\n",
      "Epoch 18/80\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.3648 - val_loss: 0.3242\n",
      "Epoch 19/80\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "116/116 [==============================] - 0s 1ms/step - loss: 0.3584 - val_loss: 0.3179\n",
      "Epoch 20/80\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 0.3513 - val_loss: 0.3116\n",
      "Epoch 21/80\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 0.3450 - val_loss: 0.3052\n",
      "Epoch 22/80\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 0.3378 - val_loss: 0.2987\n",
      "Epoch 23/80\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 0.3303 - val_loss: 0.2920\n",
      "Epoch 24/80\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.3243 - val_loss: 0.2853\n",
      "Epoch 25/80\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 0.3171 - val_loss: 0.2784\n",
      "Epoch 26/80\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.3093 - val_loss: 0.2714\n",
      "Epoch 27/80\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 0.3024 - val_loss: 0.2642\n",
      "Epoch 28/80\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 0.2948 - val_loss: 0.2570\n",
      "Epoch 29/80\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.2878 - val_loss: 0.2508\n",
      "Epoch 30/80\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 0.2809 - val_loss: 0.2449\n",
      "Epoch 31/80\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.2750 - val_loss: 0.2390\n",
      "Epoch 32/80\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 0.2682 - val_loss: 0.2330\n",
      "Epoch 33/80\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 0.2619 - val_loss: 0.2269\n",
      "Epoch 34/80\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 0.2555 - val_loss: 0.2207\n",
      "Epoch 35/80\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.2493 - val_loss: 0.2143\n",
      "Epoch 36/80\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 0.2422 - val_loss: 0.2079\n",
      "Epoch 37/80\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.2355 - val_loss: 0.2023\n",
      "Epoch 38/80\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 0.2293 - val_loss: 0.1968\n",
      "Epoch 39/80\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.2236 - val_loss: 0.1912\n",
      "Epoch 40/80\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 0.2178 - val_loss: 0.1855\n",
      "Epoch 41/80\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.2125 - val_loss: 0.1797\n",
      "Epoch 42/80\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 0.2057 - val_loss: 0.1738\n",
      "Epoch 43/80\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.1987 - val_loss: 0.1677\n",
      "Epoch 44/80\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 0.1926 - val_loss: 0.1614\n",
      "Epoch 45/80\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.1863 - val_loss: 0.1551\n",
      "Epoch 46/80\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 0.1801 - val_loss: 0.1486\n",
      "Epoch 47/80\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.1736 - val_loss: 0.1419\n",
      "Epoch 48/80\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 0.1676 - val_loss: 0.1352\n",
      "Epoch 49/80\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 0.1595 - val_loss: 0.1284\n",
      "Epoch 50/80\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.1548 - val_loss: 0.1218\n",
      "Epoch 51/80\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.1464 - val_loss: 0.1152\n",
      "Epoch 52/80\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 0.1412 - val_loss: 0.1088\n",
      "Epoch 53/80\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.1359 - val_loss: 0.1029\n",
      "Epoch 54/80\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.1310 - val_loss: 0.0974\n",
      "Epoch 55/80\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.1279 - val_loss: 0.0920\n",
      "Epoch 56/80\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 0.1237 - val_loss: 0.0870\n",
      "Epoch 57/80\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.1214 - val_loss: 0.0824\n",
      "Epoch 58/80\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 0.1176 - val_loss: 0.0783\n",
      "Epoch 59/80\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.1158 - val_loss: 0.0746\n",
      "Epoch 60/80\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 0.1150 - val_loss: 0.0711\n",
      "Epoch 61/80\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 0.1131 - val_loss: 0.0679\n",
      "Epoch 62/80\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 0.1118 - val_loss: 0.0648\n",
      "Epoch 63/80\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.1089 - val_loss: 0.0621\n",
      "Epoch 64/80\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 0.1101 - val_loss: 0.0595\n",
      "Epoch 65/80\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 0.1078 - val_loss: 0.0572\n",
      "Epoch 66/80\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 0.1080 - val_loss: 0.0551\n",
      "Epoch 67/80\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 0.1062 - val_loss: 0.0531\n",
      "Epoch 68/80\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.1063 - val_loss: 0.0512\n",
      "Epoch 69/80\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 0.1050 - val_loss: 0.0495\n",
      "Epoch 70/80\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 0.1061 - val_loss: 0.0479\n",
      "Epoch 71/80\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 0.1036 - val_loss: 0.0464\n",
      "Epoch 72/80\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 0.1044 - val_loss: 0.0450\n",
      "Epoch 73/80\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 0.1031 - val_loss: 0.0437\n",
      "Epoch 74/80\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 0.1026 - val_loss: 0.0424\n",
      "Epoch 75/80\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.1024 - val_loss: 0.0411\n",
      "Epoch 76/80\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.1016 - val_loss: 0.0400\n",
      "Epoch 77/80\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.1016 - val_loss: 0.0388\n",
      "Epoch 78/80\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.1019 - val_loss: 0.0376\n",
      "Epoch 79/80\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.1016 - val_loss: 0.0366\n",
      "Epoch 80/80\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.1003 - val_loss: 0.0356\n",
      "Execution time:  15.81882357597351\n",
      "DNN:\n",
      "Mean Absolute Error: 0.0558\n",
      "Root Mean Square Error: 0.0616\n",
      "Mean Square Error: 0.0038\n",
      "\n",
      "Train RMSE: 0.062\n",
      "Train MSE: 0.004\n",
      "Train MAE: 0.056\n",
      "###########################\n",
      "\n",
      "MODEL:  DNN\n",
      "sequence:  1h\n",
      "units:  80\n",
      "dropout1:  0.11814836227952394\n",
      "optimizer: adadelta\n",
      "activationDense: tanh\n",
      "epochs: 90\n",
      "batchsize: 25\n",
      "validation_split: 0.1\n",
      "Model: \"sequential_13\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_39 (Dense)             (None, 6, 80)             160       \n",
      "_________________________________________________________________\n",
      "dense_40 (Dense)             (None, 6, 16)             1296      \n",
      "_________________________________________________________________\n",
      "dropout_13 (Dropout)         (None, 6, 16)             0         \n",
      "_________________________________________________________________\n",
      "dense_41 (Dense)             (None, 6, 1)              17        \n",
      "=================================================================\n",
      "Total params: 1,473\n",
      "Trainable params: 1,473\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/90\n",
      "144/144 [==============================] - 0s 3ms/step - loss: 0.3523 - val_loss: 0.3190\n",
      "Epoch 2/90\n",
      "144/144 [==============================] - 0s 1ms/step - loss: 0.3488 - val_loss: 0.3156\n",
      "Epoch 3/90\n",
      "144/144 [==============================] - 0s 2ms/step - loss: 0.3450 - val_loss: 0.3118\n",
      "Epoch 4/90\n",
      "144/144 [==============================] - 0s 2ms/step - loss: 0.3410 - val_loss: 0.3077\n",
      "Epoch 5/90\n",
      "144/144 [==============================] - 0s 1ms/step - loss: 0.3366 - val_loss: 0.3032\n",
      "Epoch 6/90\n",
      "144/144 [==============================] - 0s 1ms/step - loss: 0.3317 - val_loss: 0.2985\n",
      "Epoch 7/90\n",
      "144/144 [==============================] - 0s 1ms/step - loss: 0.3267 - val_loss: 0.2935\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/90\n",
      "144/144 [==============================] - 0s 1ms/step - loss: 0.3216 - val_loss: 0.2883\n",
      "Epoch 9/90\n",
      "144/144 [==============================] - 0s 1ms/step - loss: 0.3157 - val_loss: 0.2828\n",
      "Epoch 10/90\n",
      "144/144 [==============================] - 0s 1ms/step - loss: 0.3098 - val_loss: 0.2771\n",
      "Epoch 11/90\n",
      "144/144 [==============================] - 0s 1ms/step - loss: 0.3040 - val_loss: 0.2714\n",
      "Epoch 12/90\n",
      "144/144 [==============================] - 0s 1ms/step - loss: 0.2980 - val_loss: 0.2663\n",
      "Epoch 13/90\n",
      "144/144 [==============================] - 0s 1ms/step - loss: 0.2927 - val_loss: 0.2613\n",
      "Epoch 14/90\n",
      "144/144 [==============================] - 0s 1ms/step - loss: 0.2875 - val_loss: 0.2563\n",
      "Epoch 15/90\n",
      "144/144 [==============================] - 0s 1ms/step - loss: 0.2822 - val_loss: 0.2513\n",
      "Epoch 16/90\n",
      "144/144 [==============================] - 0s 1ms/step - loss: 0.2769 - val_loss: 0.2464\n",
      "Epoch 17/90\n",
      "144/144 [==============================] - 0s 1ms/step - loss: 0.2718 - val_loss: 0.2413\n",
      "Epoch 18/90\n",
      "144/144 [==============================] - 0s 1ms/step - loss: 0.2668 - val_loss: 0.2361\n",
      "Epoch 19/90\n",
      "144/144 [==============================] - 0s 1ms/step - loss: 0.2610 - val_loss: 0.2308\n",
      "Epoch 20/90\n",
      "144/144 [==============================] - 0s 1ms/step - loss: 0.2558 - val_loss: 0.2253\n",
      "Epoch 21/90\n",
      "144/144 [==============================] - 0s 1ms/step - loss: 0.2499 - val_loss: 0.2198\n",
      "Epoch 22/90\n",
      "144/144 [==============================] - 0s 1ms/step - loss: 0.2441 - val_loss: 0.2141\n",
      "Epoch 23/90\n",
      "144/144 [==============================] - 0s 1ms/step - loss: 0.2378 - val_loss: 0.2082\n",
      "Epoch 24/90\n",
      "144/144 [==============================] - 0s 1ms/step - loss: 0.2314 - val_loss: 0.2023\n",
      "Epoch 25/90\n",
      "144/144 [==============================] - 0s 1ms/step - loss: 0.2253 - val_loss: 0.1964\n",
      "Epoch 26/90\n",
      "144/144 [==============================] - 0s 1ms/step - loss: 0.2190 - val_loss: 0.1904\n",
      "Epoch 27/90\n",
      "144/144 [==============================] - 0s 1ms/step - loss: 0.2125 - val_loss: 0.1842\n",
      "Epoch 28/90\n",
      "144/144 [==============================] - 0s 1ms/step - loss: 0.2066 - val_loss: 0.1779\n",
      "Epoch 29/90\n",
      "144/144 [==============================] - 0s 1ms/step - loss: 0.1995 - val_loss: 0.1714\n",
      "Epoch 30/90\n",
      "144/144 [==============================] - 0s 1ms/step - loss: 0.1929 - val_loss: 0.1648\n",
      "Epoch 31/90\n",
      "144/144 [==============================] - 0s 1ms/step - loss: 0.1862 - val_loss: 0.1581\n",
      "Epoch 32/90\n",
      "144/144 [==============================] - 0s 1ms/step - loss: 0.1794 - val_loss: 0.1512\n",
      "Epoch 33/90\n",
      "144/144 [==============================] - 0s 1ms/step - loss: 0.1722 - val_loss: 0.1442\n",
      "Epoch 34/90\n",
      "144/144 [==============================] - 0s 1ms/step - loss: 0.1649 - val_loss: 0.1370\n",
      "Epoch 35/90\n",
      "144/144 [==============================] - 0s 1ms/step - loss: 0.1570 - val_loss: 0.1296\n",
      "Epoch 36/90\n",
      "144/144 [==============================] - 0s 1ms/step - loss: 0.1493 - val_loss: 0.1221\n",
      "Epoch 37/90\n",
      "144/144 [==============================] - 0s 1ms/step - loss: 0.1417 - val_loss: 0.1144\n",
      "Epoch 38/90\n",
      "144/144 [==============================] - 0s 1ms/step - loss: 0.1336 - val_loss: 0.1065\n",
      "Epoch 39/90\n",
      "144/144 [==============================] - 0s 1ms/step - loss: 0.1256 - val_loss: 0.0984\n",
      "Epoch 40/90\n",
      "144/144 [==============================] - 0s 1ms/step - loss: 0.1167 - val_loss: 0.0902\n",
      "Epoch 41/90\n",
      "144/144 [==============================] - 0s 1ms/step - loss: 0.1082 - val_loss: 0.0818\n",
      "Epoch 42/90\n",
      "144/144 [==============================] - 0s 1ms/step - loss: 0.1002 - val_loss: 0.0733\n",
      "Epoch 43/90\n",
      "144/144 [==============================] - 0s 1ms/step - loss: 0.0912 - val_loss: 0.0646\n",
      "Epoch 44/90\n",
      "144/144 [==============================] - 0s 1ms/step - loss: 0.0819 - val_loss: 0.0558\n",
      "Epoch 45/90\n",
      "144/144 [==============================] - 0s 1ms/step - loss: 0.0739 - val_loss: 0.0468\n",
      "Epoch 46/90\n",
      "144/144 [==============================] - 0s 1ms/step - loss: 0.0637 - val_loss: 0.0379\n",
      "Epoch 47/90\n",
      "144/144 [==============================] - 0s 1ms/step - loss: 0.0572 - val_loss: 0.0320\n",
      "Epoch 48/90\n",
      "144/144 [==============================] - 0s 1ms/step - loss: 0.0546 - val_loss: 0.0281\n",
      "Epoch 49/90\n",
      "144/144 [==============================] - 0s 1ms/step - loss: 0.0526 - val_loss: 0.0259\n",
      "Epoch 50/90\n",
      "144/144 [==============================] - 0s 1ms/step - loss: 0.0526 - val_loss: 0.0242\n",
      "Epoch 51/90\n",
      "144/144 [==============================] - 0s 1ms/step - loss: 0.0524 - val_loss: 0.0231\n",
      "Epoch 52/90\n",
      "144/144 [==============================] - 0s 1ms/step - loss: 0.0514 - val_loss: 0.0223\n",
      "Epoch 53/90\n",
      "144/144 [==============================] - 0s 1ms/step - loss: 0.0524 - val_loss: 0.0215\n",
      "Epoch 54/90\n",
      "144/144 [==============================] - 0s 1ms/step - loss: 0.0511 - val_loss: 0.0210\n",
      "Epoch 55/90\n",
      "144/144 [==============================] - 0s 1ms/step - loss: 0.0509 - val_loss: 0.0205\n",
      "Epoch 56/90\n",
      "144/144 [==============================] - 0s 1ms/step - loss: 0.0516 - val_loss: 0.0200\n",
      "Epoch 57/90\n",
      "144/144 [==============================] - 0s 1ms/step - loss: 0.0510 - val_loss: 0.0195\n",
      "Epoch 58/90\n",
      "144/144 [==============================] - 0s 1ms/step - loss: 0.0514 - val_loss: 0.0191\n",
      "Epoch 59/90\n",
      "144/144 [==============================] - 0s 1ms/step - loss: 0.0516 - val_loss: 0.0188\n",
      "Epoch 60/90\n",
      "144/144 [==============================] - 0s 1ms/step - loss: 0.0508 - val_loss: 0.0185\n",
      "Epoch 61/90\n",
      "144/144 [==============================] - 0s 1ms/step - loss: 0.0505 - val_loss: 0.0182\n",
      "Epoch 62/90\n",
      "144/144 [==============================] - 0s 1ms/step - loss: 0.0510 - val_loss: 0.0180\n",
      "Epoch 63/90\n",
      "144/144 [==============================] - 0s 1ms/step - loss: 0.0507 - val_loss: 0.0177\n",
      "Epoch 64/90\n",
      "144/144 [==============================] - 0s 1ms/step - loss: 0.0504 - val_loss: 0.0174\n",
      "Epoch 65/90\n",
      "144/144 [==============================] - 0s 1ms/step - loss: 0.0507 - val_loss: 0.0172\n",
      "Epoch 66/90\n",
      "144/144 [==============================] - 0s 1ms/step - loss: 0.0511 - val_loss: 0.0169\n",
      "Epoch 67/90\n",
      "144/144 [==============================] - 0s 1ms/step - loss: 0.0507 - val_loss: 0.0167\n",
      "Epoch 68/90\n",
      "144/144 [==============================] - 0s 2ms/step - loss: 0.0509 - val_loss: 0.0165\n",
      "Epoch 69/90\n",
      "144/144 [==============================] - 0s 2ms/step - loss: 0.0514 - val_loss: 0.0163\n",
      "Epoch 70/90\n",
      "144/144 [==============================] - 0s 2ms/step - loss: 0.0508 - val_loss: 0.0161\n",
      "Epoch 71/90\n",
      "144/144 [==============================] - 0s 2ms/step - loss: 0.0505 - val_loss: 0.0159\n",
      "Epoch 72/90\n",
      "144/144 [==============================] - 0s 2ms/step - loss: 0.0506 - val_loss: 0.0157\n",
      "Epoch 73/90\n",
      "144/144 [==============================] - 0s 1ms/step - loss: 0.0503 - val_loss: 0.0155\n",
      "Epoch 74/90\n",
      "144/144 [==============================] - 0s 1ms/step - loss: 0.0509 - val_loss: 0.0153\n",
      "Epoch 75/90\n",
      "144/144 [==============================] - 0s 1ms/step - loss: 0.0507 - val_loss: 0.0151\n",
      "Epoch 76/90\n",
      "144/144 [==============================] - 0s 1ms/step - loss: 0.0506 - val_loss: 0.0150\n",
      "Epoch 77/90\n",
      "144/144 [==============================] - 0s 1ms/step - loss: 0.0504 - val_loss: 0.0149\n",
      "Epoch 78/90\n",
      "144/144 [==============================] - 0s 1ms/step - loss: 0.0503 - val_loss: 0.0147\n",
      "Epoch 79/90\n",
      "144/144 [==============================] - 0s 1ms/step - loss: 0.0508 - val_loss: 0.0146\n",
      "Epoch 80/90\n",
      "144/144 [==============================] - 0s 1ms/step - loss: 0.0504 - val_loss: 0.0145\n",
      "Epoch 81/90\n",
      "144/144 [==============================] - 0s 1ms/step - loss: 0.0507 - val_loss: 0.0144\n",
      "Epoch 82/90\n",
      "144/144 [==============================] - 0s 1ms/step - loss: 0.0501 - val_loss: 0.0143\n",
      "Epoch 83/90\n",
      "144/144 [==============================] - 0s 1ms/step - loss: 0.0505 - val_loss: 0.0143\n",
      "Epoch 84/90\n",
      "144/144 [==============================] - 0s 1ms/step - loss: 0.0508 - val_loss: 0.0142\n",
      "Epoch 85/90\n",
      "144/144 [==============================] - 0s 1ms/step - loss: 0.0506 - val_loss: 0.0141\n",
      "Epoch 86/90\n",
      "144/144 [==============================] - 0s 1ms/step - loss: 0.0504 - val_loss: 0.0141\n",
      "Epoch 87/90\n",
      "144/144 [==============================] - 0s 1ms/step - loss: 0.0503 - val_loss: 0.0140\n",
      "Epoch 88/90\n",
      "144/144 [==============================] - 0s 1ms/step - loss: 0.0504 - val_loss: 0.0140\n",
      "Epoch 89/90\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "144/144 [==============================] - 0s 1ms/step - loss: 0.0503 - val_loss: 0.0139\n",
      "Epoch 90/90\n",
      "144/144 [==============================] - 0s 1ms/step - loss: 0.0504 - val_loss: 0.0139\n",
      "Execution time:  19.60874104499817\n",
      "DNN:\n",
      "Mean Absolute Error: 0.0310\n",
      "Root Mean Square Error: 0.0381\n",
      "Mean Square Error: 0.0015\n",
      "\n",
      "Train RMSE: 0.038\n",
      "Train MSE: 0.001\n",
      "Train MAE: 0.031\n",
      "###########################\n",
      "\n",
      "MODEL:  DNN\n",
      "sequence:  1h\n",
      "units:  12\n",
      "dropout1:  0.48476373451509647\n",
      "optimizer: adadelta\n",
      "activationDense: tanh\n",
      "epochs: 52\n",
      "batchsize: 57\n",
      "validation_split: 0.1\n",
      "Model: \"sequential_14\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_42 (Dense)             (None, 6, 12)             24        \n",
      "_________________________________________________________________\n",
      "dense_43 (Dense)             (None, 6, 16)             208       \n",
      "_________________________________________________________________\n",
      "dropout_14 (Dropout)         (None, 6, 16)             0         \n",
      "_________________________________________________________________\n",
      "dense_44 (Dense)             (None, 6, 1)              17        \n",
      "=================================================================\n",
      "Total params: 249\n",
      "Trainable params: 249\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/52\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.3766 - val_loss: 0.3423\n",
      "Epoch 2/52\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.3761 - val_loss: 0.3419\n",
      "Epoch 3/52\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.3755 - val_loss: 0.3414\n",
      "Epoch 4/52\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.3749 - val_loss: 0.3409\n",
      "Epoch 5/52\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.3747 - val_loss: 0.3403\n",
      "Epoch 6/52\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.3739 - val_loss: 0.3398\n",
      "Epoch 7/52\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.3737 - val_loss: 0.3392\n",
      "Epoch 8/52\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.3728 - val_loss: 0.3386\n",
      "Epoch 9/52\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.3729 - val_loss: 0.3380\n",
      "Epoch 10/52\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.3715 - val_loss: 0.3374\n",
      "Epoch 11/52\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.3707 - val_loss: 0.3367\n",
      "Epoch 12/52\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.3699 - val_loss: 0.3360\n",
      "Epoch 13/52\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.3694 - val_loss: 0.3353\n",
      "Epoch 14/52\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.3689 - val_loss: 0.3346\n",
      "Epoch 15/52\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.3676 - val_loss: 0.3339\n",
      "Epoch 16/52\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.3666 - val_loss: 0.3332\n",
      "Epoch 17/52\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.3664 - val_loss: 0.3324\n",
      "Epoch 18/52\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.3662 - val_loss: 0.3316\n",
      "Epoch 19/52\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.3648 - val_loss: 0.3308\n",
      "Epoch 20/52\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.3640 - val_loss: 0.3300\n",
      "Epoch 21/52\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.3631 - val_loss: 0.3292\n",
      "Epoch 22/52\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.3623 - val_loss: 0.3284\n",
      "Epoch 23/52\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.3614 - val_loss: 0.3275\n",
      "Epoch 24/52\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.3611 - val_loss: 0.3267\n",
      "Epoch 25/52\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.3589 - val_loss: 0.3258\n",
      "Epoch 26/52\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.3584 - val_loss: 0.3249\n",
      "Epoch 27/52\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.3585 - val_loss: 0.3240\n",
      "Epoch 28/52\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.3572 - val_loss: 0.3231\n",
      "Epoch 29/52\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.3561 - val_loss: 0.3221\n",
      "Epoch 30/52\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.3547 - val_loss: 0.3212\n",
      "Epoch 31/52\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.3540 - val_loss: 0.3202\n",
      "Epoch 32/52\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.3533 - val_loss: 0.3193\n",
      "Epoch 33/52\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.3526 - val_loss: 0.3183\n",
      "Epoch 34/52\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.3515 - val_loss: 0.3173\n",
      "Epoch 35/52\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.3508 - val_loss: 0.3163\n",
      "Epoch 36/52\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.3491 - val_loss: 0.3152\n",
      "Epoch 37/52\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.3478 - val_loss: 0.3142\n",
      "Epoch 38/52\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.3464 - val_loss: 0.3132\n",
      "Epoch 39/52\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.3464 - val_loss: 0.3121\n",
      "Epoch 40/52\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.3448 - val_loss: 0.3111\n",
      "Epoch 41/52\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.3440 - val_loss: 0.3100\n",
      "Epoch 42/52\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.3428 - val_loss: 0.3089\n",
      "Epoch 43/52\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.3425 - val_loss: 0.3078\n",
      "Epoch 44/52\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.3405 - val_loss: 0.3067\n",
      "Epoch 45/52\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.3392 - val_loss: 0.3056\n",
      "Epoch 46/52\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.3374 - val_loss: 0.3044\n",
      "Epoch 47/52\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.3365 - val_loss: 0.3033\n",
      "Epoch 48/52\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.3357 - val_loss: 0.3021\n",
      "Epoch 49/52\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.3349 - val_loss: 0.3009\n",
      "Epoch 50/52\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.3336 - val_loss: 0.2998\n",
      "Epoch 51/52\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.3310 - val_loss: 0.2986\n",
      "Epoch 52/52\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.3312 - val_loss: 0.2974\n",
      "Execution time:  6.342407703399658\n",
      "DNN:\n",
      "Mean Absolute Error: 0.3266\n",
      "Root Mean Square Error: 0.3286\n",
      "Mean Square Error: 0.1080\n",
      "\n",
      "Train RMSE: 0.329\n",
      "Train MSE: 0.108\n",
      "Train MAE: 0.327\n",
      "###########################\n",
      "\n",
      "MODEL:  DNN\n",
      "sequence:  1h\n",
      "units:  87\n",
      "dropout1:  0.40519643149940265\n",
      "optimizer: adadelta\n",
      "activationDense: tanh\n",
      "epochs: 80\n",
      "batchsize: 31\n",
      "validation_split: 0.2\n",
      "Model: \"sequential_15\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_45 (Dense)             (None, 6, 87)             174       \n",
      "_________________________________________________________________\n",
      "dense_46 (Dense)             (None, 6, 16)             1408      \n",
      "_________________________________________________________________\n",
      "dropout_15 (Dropout)         (None, 6, 16)             0         \n",
      "_________________________________________________________________\n",
      "dense_47 (Dense)             (None, 6, 1)              17        \n",
      "=================================================================\n",
      "Total params: 1,599\n",
      "Trainable params: 1,599\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/80\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 0.3971 - val_loss: 0.3740\n",
      "Epoch 2/80\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.3943 - val_loss: 0.3714\n",
      "Epoch 3/80\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.3920 - val_loss: 0.3685\n",
      "Epoch 4/80\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "103/103 [==============================] - 0s 2ms/step - loss: 0.3893 - val_loss: 0.3654\n",
      "Epoch 5/80\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.3853 - val_loss: 0.3622\n",
      "Epoch 6/80\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.3823 - val_loss: 0.3588\n",
      "Epoch 7/80\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.3790 - val_loss: 0.3552\n",
      "Epoch 8/80\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.3744 - val_loss: 0.3514\n",
      "Epoch 9/80\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.3708 - val_loss: 0.3475\n",
      "Epoch 10/80\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.3669 - val_loss: 0.3435\n",
      "Epoch 11/80\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.3629 - val_loss: 0.3393\n",
      "Epoch 12/80\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.3580 - val_loss: 0.3350\n",
      "Epoch 13/80\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.3536 - val_loss: 0.3305\n",
      "Epoch 14/80\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.3492 - val_loss: 0.3260\n",
      "Epoch 15/80\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.3440 - val_loss: 0.3215\n",
      "Epoch 16/80\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.3392 - val_loss: 0.3169\n",
      "Epoch 17/80\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.3350 - val_loss: 0.3122\n",
      "Epoch 18/80\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.3304 - val_loss: 0.3076\n",
      "Epoch 19/80\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.3258 - val_loss: 0.3030\n",
      "Epoch 20/80\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.3207 - val_loss: 0.2983\n",
      "Epoch 21/80\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.3160 - val_loss: 0.2935\n",
      "Epoch 22/80\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.3104 - val_loss: 0.2887\n",
      "Epoch 23/80\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.3066 - val_loss: 0.2839\n",
      "Epoch 24/80\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.3005 - val_loss: 0.2790\n",
      "Epoch 25/80\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.2957 - val_loss: 0.2740\n",
      "Epoch 26/80\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.2913 - val_loss: 0.2690\n",
      "Epoch 27/80\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.2859 - val_loss: 0.2640\n",
      "Epoch 28/80\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.2809 - val_loss: 0.2588\n",
      "Epoch 29/80\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.2758 - val_loss: 0.2537\n",
      "Epoch 30/80\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.2691 - val_loss: 0.2485\n",
      "Epoch 31/80\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.2646 - val_loss: 0.2432\n",
      "Epoch 32/80\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.2592 - val_loss: 0.2379\n",
      "Epoch 33/80\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.2548 - val_loss: 0.2325\n",
      "Epoch 34/80\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.2473 - val_loss: 0.2271\n",
      "Epoch 35/80\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.2425 - val_loss: 0.2217\n",
      "Epoch 36/80\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.2368 - val_loss: 0.2169\n",
      "Epoch 37/80\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.2320 - val_loss: 0.2123\n",
      "Epoch 38/80\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.2273 - val_loss: 0.2078\n",
      "Epoch 39/80\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.2241 - val_loss: 0.2032\n",
      "Epoch 40/80\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.2196 - val_loss: 0.1986\n",
      "Epoch 41/80\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.2136 - val_loss: 0.1940\n",
      "Epoch 42/80\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.2091 - val_loss: 0.1893\n",
      "Epoch 43/80\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.2041 - val_loss: 0.1845\n",
      "Epoch 44/80\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.1995 - val_loss: 0.1797\n",
      "Epoch 45/80\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.1942 - val_loss: 0.1748\n",
      "Epoch 46/80\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.1904 - val_loss: 0.1699\n",
      "Epoch 47/80\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.1849 - val_loss: 0.1650\n",
      "Epoch 48/80\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.1799 - val_loss: 0.1599\n",
      "Epoch 49/80\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.1742 - val_loss: 0.1548\n",
      "Epoch 50/80\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.1689 - val_loss: 0.1497\n",
      "Epoch 51/80\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.1642 - val_loss: 0.1445\n",
      "Epoch 52/80\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.1600 - val_loss: 0.1396\n",
      "Epoch 53/80\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.1573 - val_loss: 0.1349\n",
      "Epoch 54/80\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.1504 - val_loss: 0.1305\n",
      "Epoch 55/80\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.1481 - val_loss: 0.1264\n",
      "Epoch 56/80\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.1452 - val_loss: 0.1224\n",
      "Epoch 57/80\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.1417 - val_loss: 0.1185\n",
      "Epoch 58/80\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.1389 - val_loss: 0.1147\n",
      "Epoch 59/80\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.1361 - val_loss: 0.1110\n",
      "Epoch 60/80\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.1340 - val_loss: 0.1074\n",
      "Epoch 61/80\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.1322 - val_loss: 0.1039\n",
      "Epoch 62/80\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.1294 - val_loss: 0.1005\n",
      "Epoch 63/80\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.1273 - val_loss: 0.0972\n",
      "Epoch 64/80\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.1253 - val_loss: 0.0940\n",
      "Epoch 65/80\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.1235 - val_loss: 0.0910\n",
      "Epoch 66/80\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.1211 - val_loss: 0.0881\n",
      "Epoch 67/80\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.1206 - val_loss: 0.0854\n",
      "Epoch 68/80\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.1195 - val_loss: 0.0829\n",
      "Epoch 69/80\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.1182 - val_loss: 0.0805\n",
      "Epoch 70/80\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.1170 - val_loss: 0.0782\n",
      "Epoch 71/80\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.1162 - val_loss: 0.0760\n",
      "Epoch 72/80\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.1159 - val_loss: 0.0738\n",
      "Epoch 73/80\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.1157 - val_loss: 0.0717\n",
      "Epoch 74/80\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.1127 - val_loss: 0.0697\n",
      "Epoch 75/80\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.1133 - val_loss: 0.0679\n",
      "Epoch 76/80\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.1122 - val_loss: 0.0661\n",
      "Epoch 77/80\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.1114 - val_loss: 0.0643\n",
      "Epoch 78/80\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.1108 - val_loss: 0.0625\n",
      "Epoch 79/80\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.1100 - val_loss: 0.0607\n",
      "Epoch 80/80\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.1092 - val_loss: 0.0590\n",
      "Execution time:  15.335560083389282\n",
      "DNN:\n",
      "Mean Absolute Error: 0.0694\n",
      "Root Mean Square Error: 0.0736\n",
      "Mean Square Error: 0.0054\n",
      "\n",
      "Train RMSE: 0.074\n",
      "Train MSE: 0.005\n",
      "Train MAE: 0.069\n",
      "###########################\n",
      "\n",
      "MODEL:  DNN\n",
      "sequence:  1h\n",
      "units:  80\n",
      "dropout1:  0.11814836227952394\n",
      "optimizer: adadelta\n",
      "activationDense: tanh\n",
      "epochs: 90\n",
      "batchsize: 25\n",
      "validation_split: 0.2\n",
      "Model: \"sequential_16\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_48 (Dense)             (None, 6, 80)             160       \n",
      "_________________________________________________________________\n",
      "dense_49 (Dense)             (None, 6, 16)             1296      \n",
      "_________________________________________________________________\n",
      "dropout_16 (Dropout)         (None, 6, 16)             0         \n",
      "_________________________________________________________________\n",
      "dense_50 (Dense)             (None, 6, 1)              17        \n",
      "=================================================================\n",
      "Total params: 1,473\n",
      "Trainable params: 1,473\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/90\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "128/128 [==============================] - 0s 3ms/step - loss: 0.4001 - val_loss: 0.3766\n",
      "Epoch 2/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.3970 - val_loss: 0.3737\n",
      "Epoch 3/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.3939 - val_loss: 0.3705\n",
      "Epoch 4/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.3906 - val_loss: 0.3670\n",
      "Epoch 5/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.3869 - val_loss: 0.3633\n",
      "Epoch 6/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.3830 - val_loss: 0.3594\n",
      "Epoch 7/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.3791 - val_loss: 0.3553\n",
      "Epoch 8/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.3745 - val_loss: 0.3509\n",
      "Epoch 9/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.3702 - val_loss: 0.3464\n",
      "Epoch 10/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.3653 - val_loss: 0.3417\n",
      "Epoch 11/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.3604 - val_loss: 0.3367\n",
      "Epoch 12/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.3556 - val_loss: 0.3317\n",
      "Epoch 13/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.3502 - val_loss: 0.3265\n",
      "Epoch 14/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.3445 - val_loss: 0.3211\n",
      "Epoch 15/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.3387 - val_loss: 0.3155\n",
      "Epoch 16/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.3330 - val_loss: 0.3098\n",
      "Epoch 17/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.3272 - val_loss: 0.3040\n",
      "Epoch 18/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.3212 - val_loss: 0.2979\n",
      "Epoch 19/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.3149 - val_loss: 0.2917\n",
      "Epoch 20/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.3082 - val_loss: 0.2854\n",
      "Epoch 21/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.3016 - val_loss: 0.2789\n",
      "Epoch 22/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.2954 - val_loss: 0.2732\n",
      "Epoch 23/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.2898 - val_loss: 0.2680\n",
      "Epoch 24/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.2839 - val_loss: 0.2629\n",
      "Epoch 25/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.2794 - val_loss: 0.2577\n",
      "Epoch 26/90\n",
      "128/128 [==============================] - 0s 1ms/step - loss: 0.2738 - val_loss: 0.2524\n",
      "Epoch 27/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.2686 - val_loss: 0.2471\n",
      "Epoch 28/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.2626 - val_loss: 0.2417\n",
      "Epoch 29/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.2570 - val_loss: 0.2362\n",
      "Epoch 30/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.2518 - val_loss: 0.2306\n",
      "Epoch 31/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.2458 - val_loss: 0.2249\n",
      "Epoch 32/90\n",
      "128/128 [==============================] - 0s 1ms/step - loss: 0.2400 - val_loss: 0.2192\n",
      "Epoch 33/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.2342 - val_loss: 0.2135\n",
      "Epoch 34/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.2280 - val_loss: 0.2077\n",
      "Epoch 35/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.2218 - val_loss: 0.2017\n",
      "Epoch 36/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.2161 - val_loss: 0.1957\n",
      "Epoch 37/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.2104 - val_loss: 0.1896\n",
      "Epoch 38/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.2044 - val_loss: 0.1834\n",
      "Epoch 39/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.1974 - val_loss: 0.1772\n",
      "Epoch 40/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.1910 - val_loss: 0.1708\n",
      "Epoch 41/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.1846 - val_loss: 0.1643\n",
      "Epoch 42/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.1779 - val_loss: 0.1577\n",
      "Epoch 43/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.1716 - val_loss: 0.1510\n",
      "Epoch 44/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.1640 - val_loss: 0.1443\n",
      "Epoch 45/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.1587 - val_loss: 0.1374\n",
      "Epoch 46/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.1511 - val_loss: 0.1304\n",
      "Epoch 47/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.1431 - val_loss: 0.1234\n",
      "Epoch 48/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.1362 - val_loss: 0.1162\n",
      "Epoch 49/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.1295 - val_loss: 0.1090\n",
      "Epoch 50/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.1221 - val_loss: 0.1017\n",
      "Epoch 51/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.1135 - val_loss: 0.0943\n",
      "Epoch 52/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.1073 - val_loss: 0.0869\n",
      "Epoch 53/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0998 - val_loss: 0.0794\n",
      "Epoch 54/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0928 - val_loss: 0.0718\n",
      "Epoch 55/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0845 - val_loss: 0.0641\n",
      "Epoch 56/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0776 - val_loss: 0.0564\n",
      "Epoch 57/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0704 - val_loss: 0.0487\n",
      "Epoch 58/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0619 - val_loss: 0.0420\n",
      "Epoch 59/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0590 - val_loss: 0.0393\n",
      "Epoch 60/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0580 - val_loss: 0.0373\n",
      "Epoch 61/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0357\n",
      "Epoch 62/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0569 - val_loss: 0.0348\n",
      "Epoch 63/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0567 - val_loss: 0.0341\n",
      "Epoch 64/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0572 - val_loss: 0.0335\n",
      "Epoch 65/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0565 - val_loss: 0.0331\n",
      "Epoch 66/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0573 - val_loss: 0.0327\n",
      "Epoch 67/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0574 - val_loss: 0.0324\n",
      "Epoch 68/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0573 - val_loss: 0.0321\n",
      "Epoch 69/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0564 - val_loss: 0.0318\n",
      "Epoch 70/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0574 - val_loss: 0.0315\n",
      "Epoch 71/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0571 - val_loss: 0.0313\n",
      "Epoch 72/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0566 - val_loss: 0.0313\n",
      "Epoch 73/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0560 - val_loss: 0.0312\n",
      "Epoch 74/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0570 - val_loss: 0.0312\n",
      "Epoch 75/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0567 - val_loss: 0.0311\n",
      "Epoch 76/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0560 - val_loss: 0.0311\n",
      "Epoch 77/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0558 - val_loss: 0.0311\n",
      "Epoch 78/90\n",
      "128/128 [==============================] - 0s 1ms/step - loss: 0.0567 - val_loss: 0.0310\n",
      "Epoch 79/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0556 - val_loss: 0.0310\n",
      "Epoch 80/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0568 - val_loss: 0.0310\n",
      "Epoch 81/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0568 - val_loss: 0.0309\n",
      "Epoch 82/90\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0554 - val_loss: 0.0309\n",
      "Epoch 83/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0561 - val_loss: 0.0309\n",
      "Epoch 84/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0562 - val_loss: 0.0309\n",
      "Epoch 85/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0570 - val_loss: 0.0308\n",
      "Epoch 86/90\n",
      "128/128 [==============================] - 0s 1ms/step - loss: 0.0564 - val_loss: 0.0308\n",
      "Epoch 87/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0548 - val_loss: 0.0309\n",
      "Epoch 88/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0566 - val_loss: 0.0308\n",
      "Epoch 89/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0569 - val_loss: 0.0308\n",
      "Epoch 90/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0564 - val_loss: 0.0308\n",
      "Execution time:  19.509649991989136\n",
      "DNN:\n",
      "Mean Absolute Error: 0.0414\n",
      "Root Mean Square Error: 0.0483\n",
      "Mean Square Error: 0.0023\n",
      "\n",
      "Train RMSE: 0.048\n",
      "Train MSE: 0.002\n",
      "Train MAE: 0.041\n",
      "###########################\n",
      "\n",
      "MODEL:  DNN\n",
      "sequence:  1h\n",
      "units:  12\n",
      "dropout1:  0.48476373451509647\n",
      "optimizer: adadelta\n",
      "activationDense: tanh\n",
      "epochs: 52\n",
      "batchsize: 57\n",
      "validation_split: 0.2\n",
      "Model: \"sequential_17\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_51 (Dense)             (None, 6, 12)             24        \n",
      "_________________________________________________________________\n",
      "dense_52 (Dense)             (None, 6, 16)             208       \n",
      "_________________________________________________________________\n",
      "dropout_17 (Dropout)         (None, 6, 16)             0         \n",
      "_________________________________________________________________\n",
      "dense_53 (Dense)             (None, 6, 1)              17        \n",
      "=================================================================\n",
      "Total params: 249\n",
      "Trainable params: 249\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/52\n",
      "56/56 [==============================] - 0s 5ms/step - loss: 0.3856 - val_loss: 0.3645\n",
      "Epoch 2/52\n",
      "56/56 [==============================] - 0s 2ms/step - loss: 0.3857 - val_loss: 0.3638\n",
      "Epoch 3/52\n",
      "56/56 [==============================] - 0s 2ms/step - loss: 0.3852 - val_loss: 0.3632\n",
      "Epoch 4/52\n",
      "56/56 [==============================] - 0s 2ms/step - loss: 0.3841 - val_loss: 0.3625\n",
      "Epoch 5/52\n",
      "56/56 [==============================] - 0s 2ms/step - loss: 0.3834 - val_loss: 0.3618\n",
      "Epoch 6/52\n",
      "56/56 [==============================] - 0s 2ms/step - loss: 0.3823 - val_loss: 0.3610\n",
      "Epoch 7/52\n",
      "56/56 [==============================] - 0s 2ms/step - loss: 0.3819 - val_loss: 0.3603\n",
      "Epoch 8/52\n",
      "56/56 [==============================] - 0s 2ms/step - loss: 0.3815 - val_loss: 0.3595\n",
      "Epoch 9/52\n",
      "56/56 [==============================] - 0s 2ms/step - loss: 0.3798 - val_loss: 0.3586\n",
      "Epoch 10/52\n",
      "56/56 [==============================] - 0s 2ms/step - loss: 0.3788 - val_loss: 0.3578\n",
      "Epoch 11/52\n",
      "56/56 [==============================] - 0s 2ms/step - loss: 0.3778 - val_loss: 0.3569\n",
      "Epoch 12/52\n",
      "56/56 [==============================] - 0s 2ms/step - loss: 0.3777 - val_loss: 0.3560\n",
      "Epoch 13/52\n",
      "56/56 [==============================] - 0s 2ms/step - loss: 0.3764 - val_loss: 0.3551\n",
      "Epoch 14/52\n",
      "56/56 [==============================] - 0s 2ms/step - loss: 0.3753 - val_loss: 0.3542\n",
      "Epoch 15/52\n",
      "56/56 [==============================] - 0s 2ms/step - loss: 0.3743 - val_loss: 0.3532\n",
      "Epoch 16/52\n",
      "56/56 [==============================] - 0s 2ms/step - loss: 0.3742 - val_loss: 0.3523\n",
      "Epoch 17/52\n",
      "56/56 [==============================] - 0s 2ms/step - loss: 0.3721 - val_loss: 0.3513\n",
      "Epoch 18/52\n",
      "56/56 [==============================] - 0s 2ms/step - loss: 0.3718 - val_loss: 0.3503\n",
      "Epoch 19/52\n",
      "56/56 [==============================] - 0s 2ms/step - loss: 0.3707 - val_loss: 0.3493\n",
      "Epoch 20/52\n",
      "56/56 [==============================] - 0s 2ms/step - loss: 0.3699 - val_loss: 0.3482\n",
      "Epoch 21/52\n",
      "56/56 [==============================] - 0s 2ms/step - loss: 0.3693 - val_loss: 0.3472\n",
      "Epoch 22/52\n",
      "56/56 [==============================] - 0s 2ms/step - loss: 0.3678 - val_loss: 0.3461\n",
      "Epoch 23/52\n",
      "56/56 [==============================] - 0s 2ms/step - loss: 0.3667 - val_loss: 0.3450\n",
      "Epoch 24/52\n",
      "56/56 [==============================] - 0s 2ms/step - loss: 0.3658 - val_loss: 0.3439\n",
      "Epoch 25/52\n",
      "56/56 [==============================] - 0s 2ms/step - loss: 0.3641 - val_loss: 0.3428\n",
      "Epoch 26/52\n",
      "56/56 [==============================] - 0s 2ms/step - loss: 0.3632 - val_loss: 0.3416\n",
      "Epoch 27/52\n",
      "56/56 [==============================] - 0s 2ms/step - loss: 0.3623 - val_loss: 0.3404\n",
      "Epoch 28/52\n",
      "56/56 [==============================] - 0s 2ms/step - loss: 0.3605 - val_loss: 0.3393\n",
      "Epoch 29/52\n",
      "56/56 [==============================] - 0s 2ms/step - loss: 0.3597 - val_loss: 0.3382\n",
      "Epoch 30/52\n",
      "56/56 [==============================] - 0s 2ms/step - loss: 0.3581 - val_loss: 0.3371\n",
      "Epoch 31/52\n",
      "56/56 [==============================] - 0s 2ms/step - loss: 0.3571 - val_loss: 0.3359\n",
      "Epoch 32/52\n",
      "56/56 [==============================] - 0s 2ms/step - loss: 0.3559 - val_loss: 0.3347\n",
      "Epoch 33/52\n",
      "56/56 [==============================] - 0s 2ms/step - loss: 0.3552 - val_loss: 0.3336\n",
      "Epoch 34/52\n",
      "56/56 [==============================] - 0s 2ms/step - loss: 0.3539 - val_loss: 0.3324\n",
      "Epoch 35/52\n",
      "56/56 [==============================] - 0s 2ms/step - loss: 0.3526 - val_loss: 0.3312\n",
      "Epoch 36/52\n",
      "56/56 [==============================] - 0s 2ms/step - loss: 0.3512 - val_loss: 0.3300\n",
      "Epoch 37/52\n",
      "56/56 [==============================] - 0s 2ms/step - loss: 0.3503 - val_loss: 0.3288\n",
      "Epoch 38/52\n",
      "56/56 [==============================] - 0s 2ms/step - loss: 0.3486 - val_loss: 0.3275\n",
      "Epoch 39/52\n",
      "56/56 [==============================] - 0s 2ms/step - loss: 0.3480 - val_loss: 0.3263\n",
      "Epoch 40/52\n",
      "56/56 [==============================] - 0s 2ms/step - loss: 0.3456 - val_loss: 0.3250\n",
      "Epoch 41/52\n",
      "56/56 [==============================] - 0s 2ms/step - loss: 0.3452 - val_loss: 0.3237\n",
      "Epoch 42/52\n",
      "56/56 [==============================] - 0s 2ms/step - loss: 0.3437 - val_loss: 0.3224\n",
      "Epoch 43/52\n",
      "56/56 [==============================] - 0s 2ms/step - loss: 0.3426 - val_loss: 0.3211\n",
      "Epoch 44/52\n",
      "56/56 [==============================] - 0s 2ms/step - loss: 0.3413 - val_loss: 0.3198\n",
      "Epoch 45/52\n",
      "56/56 [==============================] - 0s 2ms/step - loss: 0.3395 - val_loss: 0.3185\n",
      "Epoch 46/52\n",
      "56/56 [==============================] - 0s 2ms/step - loss: 0.3381 - val_loss: 0.3171\n",
      "Epoch 47/52\n",
      "56/56 [==============================] - 0s 2ms/step - loss: 0.3376 - val_loss: 0.3158\n",
      "Epoch 48/52\n",
      "56/56 [==============================] - 0s 2ms/step - loss: 0.3362 - val_loss: 0.3144\n",
      "Epoch 49/52\n",
      "56/56 [==============================] - 0s 2ms/step - loss: 0.3343 - val_loss: 0.3130\n",
      "Epoch 50/52\n",
      "56/56 [==============================] - 0s 2ms/step - loss: 0.3325 - val_loss: 0.3116\n",
      "Epoch 51/52\n",
      "56/56 [==============================] - 0s 2ms/step - loss: 0.3309 - val_loss: 0.3102\n",
      "Epoch 52/52\n",
      "56/56 [==============================] - 0s 2ms/step - loss: 0.3304 - val_loss: 0.3088\n",
      "Execution time:  6.494782447814941\n",
      "DNN:\n",
      "Mean Absolute Error: 0.3250\n",
      "Root Mean Square Error: 0.3271\n",
      "Mean Square Error: 0.1070\n",
      "\n",
      "Train RMSE: 0.327\n",
      "Train MSE: 0.107\n",
      "Train MAE: 0.325\n",
      "###########################\n",
      "\n",
      "MODEL:  DNN\n",
      "sequence:  1h\n",
      "units:  87\n",
      "dropout1:  0.40519643149940265\n",
      "optimizer: adadelta\n",
      "activationDense: sigmoid\n",
      "epochs: 80\n",
      "batchsize: 31\n",
      "validation_split: 0.1\n",
      "Model: \"sequential_18\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_54 (Dense)             (None, 6, 87)             174       \n",
      "_________________________________________________________________\n",
      "dense_55 (Dense)             (None, 6, 16)             1408      \n",
      "_________________________________________________________________\n",
      "dropout_18 (Dropout)         (None, 6, 16)             0         \n",
      "_________________________________________________________________\n",
      "dense_56 (Dense)             (None, 6, 1)              17        \n",
      "=================================================================\n",
      "Total params: 1,599\n",
      "Trainable params: 1,599\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/80\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "116/116 [==============================] - 0s 3ms/step - loss: 0.1214 - val_loss: 0.1534\n",
      "Epoch 2/80\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.1204 - val_loss: 0.1524\n",
      "Epoch 3/80\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.1193 - val_loss: 0.1513\n",
      "Epoch 4/80\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.1181 - val_loss: 0.1501\n",
      "Epoch 5/80\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.1168 - val_loss: 0.1488\n",
      "Epoch 6/80\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.1154 - val_loss: 0.1475\n",
      "Epoch 7/80\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.1143 - val_loss: 0.1462\n",
      "Epoch 8/80\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 0.1128 - val_loss: 0.1449\n",
      "Epoch 9/80\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.1116 - val_loss: 0.1435\n",
      "Epoch 10/80\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 0.1100 - val_loss: 0.1421\n",
      "Epoch 11/80\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.1085 - val_loss: 0.1406\n",
      "Epoch 12/80\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.1072 - val_loss: 0.1391\n",
      "Epoch 13/80\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.1055 - val_loss: 0.1376\n",
      "Epoch 14/80\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.1041 - val_loss: 0.1361\n",
      "Epoch 15/80\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.1026 - val_loss: 0.1348\n",
      "Epoch 16/80\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.1011 - val_loss: 0.1335\n",
      "Epoch 17/80\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.1001 - val_loss: 0.1323\n",
      "Epoch 18/80\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.0987 - val_loss: 0.1310\n",
      "Epoch 19/80\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.0974 - val_loss: 0.1297\n",
      "Epoch 20/80\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.0963 - val_loss: 0.1285\n",
      "Epoch 21/80\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.0949 - val_loss: 0.1272\n",
      "Epoch 22/80\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.0937 - val_loss: 0.1259\n",
      "Epoch 23/80\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 0.0924 - val_loss: 0.1245\n",
      "Epoch 24/80\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.0910 - val_loss: 0.1232\n",
      "Epoch 25/80\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.0896 - val_loss: 0.1219\n",
      "Epoch 26/80\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.0884 - val_loss: 0.1206\n",
      "Epoch 27/80\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.0871 - val_loss: 0.1193\n",
      "Epoch 28/80\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 0.0859 - val_loss: 0.1180\n",
      "Epoch 29/80\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.0846 - val_loss: 0.1166\n",
      "Epoch 30/80\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.0834 - val_loss: 0.1153\n",
      "Epoch 31/80\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.0821 - val_loss: 0.1140\n",
      "Epoch 32/80\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.0809 - val_loss: 0.1127\n",
      "Epoch 33/80\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.0796 - val_loss: 0.1114\n",
      "Epoch 34/80\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.0782 - val_loss: 0.1100\n",
      "Epoch 35/80\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.0773 - val_loss: 0.1087\n",
      "Epoch 36/80\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.0759 - val_loss: 0.1074\n",
      "Epoch 37/80\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.0747 - val_loss: 0.1061\n",
      "Epoch 38/80\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.0736 - val_loss: 0.1048\n",
      "Epoch 39/80\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.0724 - val_loss: 0.1036\n",
      "Epoch 40/80\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.0714 - val_loss: 0.1023\n",
      "Epoch 41/80\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.0705 - val_loss: 0.1011\n",
      "Epoch 42/80\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.0691 - val_loss: 0.0999\n",
      "Epoch 43/80\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.0681 - val_loss: 0.0988\n",
      "Epoch 44/80\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.0673 - val_loss: 0.0977\n",
      "Epoch 45/80\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.0664 - val_loss: 0.0966\n",
      "Epoch 46/80\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.0655 - val_loss: 0.0955\n",
      "Epoch 47/80\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.0647 - val_loss: 0.0945\n",
      "Epoch 48/80\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.0639 - val_loss: 0.0936\n",
      "Epoch 49/80\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.0632 - val_loss: 0.0929\n",
      "Epoch 50/80\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.0626 - val_loss: 0.0922\n",
      "Epoch 51/80\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.0621 - val_loss: 0.0915\n",
      "Epoch 52/80\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.0615 - val_loss: 0.0908\n",
      "Epoch 53/80\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.0612 - val_loss: 0.0901\n",
      "Epoch 54/80\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.0606 - val_loss: 0.0894\n",
      "Epoch 55/80\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.0600 - val_loss: 0.0888\n",
      "Epoch 56/80\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.0596 - val_loss: 0.0881\n",
      "Epoch 57/80\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.0591 - val_loss: 0.0875\n",
      "Epoch 58/80\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.0586 - val_loss: 0.0869\n",
      "Epoch 59/80\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.0584 - val_loss: 0.0863\n",
      "Epoch 60/80\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.0580 - val_loss: 0.0856\n",
      "Epoch 61/80\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.0575 - val_loss: 0.0851\n",
      "Epoch 62/80\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 0.0572 - val_loss: 0.0845\n",
      "Epoch 63/80\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.0566 - val_loss: 0.0839\n",
      "Epoch 64/80\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 0.0561 - val_loss: 0.0833\n",
      "Epoch 65/80\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.0558 - val_loss: 0.0827\n",
      "Epoch 66/80\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.0556 - val_loss: 0.0821\n",
      "Epoch 67/80\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 0.0549 - val_loss: 0.0816\n",
      "Epoch 68/80\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 0.0547 - val_loss: 0.0810\n",
      "Epoch 69/80\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.0544 - val_loss: 0.0805\n",
      "Epoch 70/80\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 0.0543 - val_loss: 0.0799\n",
      "Epoch 71/80\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.0535 - val_loss: 0.0794\n",
      "Epoch 72/80\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 0.0536 - val_loss: 0.0789\n",
      "Epoch 73/80\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.0530 - val_loss: 0.0784\n",
      "Epoch 74/80\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.0525 - val_loss: 0.0778\n",
      "Epoch 75/80\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.0522 - val_loss: 0.0773\n",
      "Epoch 76/80\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.0521 - val_loss: 0.0768\n",
      "Epoch 77/80\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.0519 - val_loss: 0.0764\n",
      "Epoch 78/80\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.0517 - val_loss: 0.0759\n",
      "Epoch 79/80\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.0513 - val_loss: 0.0754\n",
      "Epoch 80/80\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 0.0511 - val_loss: 0.0749\n",
      "Execution time:  16.37921118736267\n",
      "DNN:\n",
      "Mean Absolute Error: 0.0510\n",
      "Root Mean Square Error: 0.0591\n",
      "Mean Square Error: 0.0035\n",
      "\n",
      "Train RMSE: 0.059\n",
      "Train MSE: 0.003\n",
      "Train MAE: 0.051\n",
      "###########################\n",
      "\n",
      "MODEL:  DNN\n",
      "sequence:  1h\n",
      "units:  80\n",
      "dropout1:  0.11814836227952394\n",
      "optimizer: adadelta\n",
      "activationDense: sigmoid\n",
      "epochs: 90\n",
      "batchsize: 25\n",
      "validation_split: 0.1\n",
      "Model: \"sequential_19\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_57 (Dense)             (None, 6, 80)             160       \n",
      "_________________________________________________________________\n",
      "dense_58 (Dense)             (None, 6, 16)             1296      \n",
      "_________________________________________________________________\n",
      "dropout_19 (Dropout)         (None, 6, 16)             0         \n",
      "_________________________________________________________________\n",
      "dense_59 (Dense)             (None, 6, 1)              17        \n",
      "=================================================================\n",
      "Total params: 1,473\n",
      "Trainable params: 1,473\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/90\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "144/144 [==============================] - 0s 3ms/step - loss: 0.0916 - val_loss: 0.1254\n",
      "Epoch 2/90\n",
      "144/144 [==============================] - 0s 1ms/step - loss: 0.0908 - val_loss: 0.1246\n",
      "Epoch 3/90\n",
      "144/144 [==============================] - 0s 1ms/step - loss: 0.0901 - val_loss: 0.1237\n",
      "Epoch 4/90\n",
      "144/144 [==============================] - 0s 1ms/step - loss: 0.0891 - val_loss: 0.1227\n",
      "Epoch 5/90\n",
      "144/144 [==============================] - 0s 1ms/step - loss: 0.0882 - val_loss: 0.1217\n",
      "Epoch 6/90\n",
      "144/144 [==============================] - 0s 1ms/step - loss: 0.0872 - val_loss: 0.1206\n",
      "Epoch 7/90\n",
      "144/144 [==============================] - 0s 1ms/step - loss: 0.0861 - val_loss: 0.1195\n",
      "Epoch 8/90\n",
      "144/144 [==============================] - 0s 1ms/step - loss: 0.0850 - val_loss: 0.1183\n",
      "Epoch 9/90\n",
      "144/144 [==============================] - 0s 1ms/step - loss: 0.0838 - val_loss: 0.1171\n",
      "Epoch 10/90\n",
      "144/144 [==============================] - 0s 1ms/step - loss: 0.0827 - val_loss: 0.1159\n",
      "Epoch 11/90\n",
      "144/144 [==============================] - 0s 1ms/step - loss: 0.0815 - val_loss: 0.1147\n",
      "Epoch 12/90\n",
      "144/144 [==============================] - 0s 1ms/step - loss: 0.0804 - val_loss: 0.1136\n",
      "Epoch 13/90\n",
      "144/144 [==============================] - 0s 1ms/step - loss: 0.0794 - val_loss: 0.1125\n",
      "Epoch 14/90\n",
      "144/144 [==============================] - 0s 1ms/step - loss: 0.0784 - val_loss: 0.1114\n",
      "Epoch 15/90\n",
      "144/144 [==============================] - 0s 1ms/step - loss: 0.0773 - val_loss: 0.1103\n",
      "Epoch 16/90\n",
      "144/144 [==============================] - 0s 1ms/step - loss: 0.0763 - val_loss: 0.1091\n",
      "Epoch 17/90\n",
      "144/144 [==============================] - 0s 1ms/step - loss: 0.0753 - val_loss: 0.1080\n",
      "Epoch 18/90\n",
      "144/144 [==============================] - 0s 1ms/step - loss: 0.0743 - val_loss: 0.1068\n",
      "Epoch 19/90\n",
      "144/144 [==============================] - 0s 1ms/step - loss: 0.0733 - val_loss: 0.1057\n",
      "Epoch 20/90\n",
      "144/144 [==============================] - 0s 1ms/step - loss: 0.0722 - val_loss: 0.1045\n",
      "Epoch 21/90\n",
      "144/144 [==============================] - 0s 1ms/step - loss: 0.0711 - val_loss: 0.1033\n",
      "Epoch 22/90\n",
      "144/144 [==============================] - 0s 1ms/step - loss: 0.0701 - val_loss: 0.1021\n",
      "Epoch 23/90\n",
      "144/144 [==============================] - 0s 1ms/step - loss: 0.0690 - val_loss: 0.1009\n",
      "Epoch 24/90\n",
      "144/144 [==============================] - 0s 1ms/step - loss: 0.0681 - val_loss: 0.0998\n",
      "Epoch 25/90\n",
      "144/144 [==============================] - 0s 1ms/step - loss: 0.0670 - val_loss: 0.0986\n",
      "Epoch 26/90\n",
      "144/144 [==============================] - 0s 1ms/step - loss: 0.0661 - val_loss: 0.0974\n",
      "Epoch 27/90\n",
      "144/144 [==============================] - 0s 1ms/step - loss: 0.0651 - val_loss: 0.0963\n",
      "Epoch 28/90\n",
      "144/144 [==============================] - 0s 1ms/step - loss: 0.0640 - val_loss: 0.0951\n",
      "Epoch 29/90\n",
      "144/144 [==============================] - 0s 1ms/step - loss: 0.0632 - val_loss: 0.0939\n",
      "Epoch 30/90\n",
      "144/144 [==============================] - 0s 1ms/step - loss: 0.0623 - val_loss: 0.0928\n",
      "Epoch 31/90\n",
      "144/144 [==============================] - 0s 1ms/step - loss: 0.0614 - val_loss: 0.0916\n",
      "Epoch 32/90\n",
      "144/144 [==============================] - 0s 1ms/step - loss: 0.0604 - val_loss: 0.0905\n",
      "Epoch 33/90\n",
      "144/144 [==============================] - 0s 1ms/step - loss: 0.0595 - val_loss: 0.0893\n",
      "Epoch 34/90\n",
      "144/144 [==============================] - 0s 1ms/step - loss: 0.0586 - val_loss: 0.0882\n",
      "Epoch 35/90\n",
      "144/144 [==============================] - 0s 1ms/step - loss: 0.0577 - val_loss: 0.0870\n",
      "Epoch 36/90\n",
      "144/144 [==============================] - 0s 1ms/step - loss: 0.0568 - val_loss: 0.0859\n",
      "Epoch 37/90\n",
      "144/144 [==============================] - 0s 1ms/step - loss: 0.0561 - val_loss: 0.0849\n",
      "Epoch 38/90\n",
      "144/144 [==============================] - 0s 1ms/step - loss: 0.0553 - val_loss: 0.0839\n",
      "Epoch 39/90\n",
      "144/144 [==============================] - 0s 1ms/step - loss: 0.0546 - val_loss: 0.0829\n",
      "Epoch 40/90\n",
      "144/144 [==============================] - 0s 2ms/step - loss: 0.0539 - val_loss: 0.0819\n",
      "Epoch 41/90\n",
      "144/144 [==============================] - 0s 1ms/step - loss: 0.0533 - val_loss: 0.0810\n",
      "Epoch 42/90\n",
      "144/144 [==============================] - 0s 2ms/step - loss: 0.0527 - val_loss: 0.0801\n",
      "Epoch 43/90\n",
      "144/144 [==============================] - 0s 2ms/step - loss: 0.0520 - val_loss: 0.0792\n",
      "Epoch 44/90\n",
      "144/144 [==============================] - 0s 2ms/step - loss: 0.0514 - val_loss: 0.0783\n",
      "Epoch 45/90\n",
      "144/144 [==============================] - 0s 2ms/step - loss: 0.0510 - val_loss: 0.0774\n",
      "Epoch 46/90\n",
      "144/144 [==============================] - 0s 2ms/step - loss: 0.0503 - val_loss: 0.0765\n",
      "Epoch 47/90\n",
      "144/144 [==============================] - 0s 2ms/step - loss: 0.0498 - val_loss: 0.0756\n",
      "Epoch 48/90\n",
      "144/144 [==============================] - 0s 1ms/step - loss: 0.0493 - val_loss: 0.0748\n",
      "Epoch 49/90\n",
      "144/144 [==============================] - 0s 1ms/step - loss: 0.0487 - val_loss: 0.0740\n",
      "Epoch 50/90\n",
      "144/144 [==============================] - 0s 1ms/step - loss: 0.0482 - val_loss: 0.0732\n",
      "Epoch 51/90\n",
      "144/144 [==============================] - 0s 1ms/step - loss: 0.0478 - val_loss: 0.0724\n",
      "Epoch 52/90\n",
      "144/144 [==============================] - 0s 1ms/step - loss: 0.0473 - val_loss: 0.0716\n",
      "Epoch 53/90\n",
      "144/144 [==============================] - 0s 1ms/step - loss: 0.0469 - val_loss: 0.0708\n",
      "Epoch 54/90\n",
      "144/144 [==============================] - 0s 1ms/step - loss: 0.0464 - val_loss: 0.0700\n",
      "Epoch 55/90\n",
      "144/144 [==============================] - 0s 1ms/step - loss: 0.0460 - val_loss: 0.0693\n",
      "Epoch 56/90\n",
      "144/144 [==============================] - 0s 1ms/step - loss: 0.0455 - val_loss: 0.0685\n",
      "Epoch 57/90\n",
      "144/144 [==============================] - 0s 1ms/step - loss: 0.0452 - val_loss: 0.0678\n",
      "Epoch 58/90\n",
      "144/144 [==============================] - 0s 1ms/step - loss: 0.0448 - val_loss: 0.0671\n",
      "Epoch 59/90\n",
      "144/144 [==============================] - 0s 1ms/step - loss: 0.0445 - val_loss: 0.0664\n",
      "Epoch 60/90\n",
      "144/144 [==============================] - 0s 1ms/step - loss: 0.0441 - val_loss: 0.0657\n",
      "Epoch 61/90\n",
      "144/144 [==============================] - 0s 1ms/step - loss: 0.0437 - val_loss: 0.0650\n",
      "Epoch 62/90\n",
      "144/144 [==============================] - 0s 1ms/step - loss: 0.0433 - val_loss: 0.0643\n",
      "Epoch 63/90\n",
      "144/144 [==============================] - 0s 1ms/step - loss: 0.0430 - val_loss: 0.0636\n",
      "Epoch 64/90\n",
      "144/144 [==============================] - 0s 1ms/step - loss: 0.0425 - val_loss: 0.0629\n",
      "Epoch 65/90\n",
      "144/144 [==============================] - 0s 1ms/step - loss: 0.0423 - val_loss: 0.0622\n",
      "Epoch 66/90\n",
      "144/144 [==============================] - 0s 1ms/step - loss: 0.0421 - val_loss: 0.0615\n",
      "Epoch 67/90\n",
      "144/144 [==============================] - 0s 1ms/step - loss: 0.0416 - val_loss: 0.0608\n",
      "Epoch 68/90\n",
      "144/144 [==============================] - 0s 1ms/step - loss: 0.0413 - val_loss: 0.0601\n",
      "Epoch 69/90\n",
      "144/144 [==============================] - 0s 1ms/step - loss: 0.0411 - val_loss: 0.0595\n",
      "Epoch 70/90\n",
      "144/144 [==============================] - 0s 1ms/step - loss: 0.0405 - val_loss: 0.0588\n",
      "Epoch 71/90\n",
      "144/144 [==============================] - 0s 1ms/step - loss: 0.0404 - val_loss: 0.0582\n",
      "Epoch 72/90\n",
      "144/144 [==============================] - 0s 1ms/step - loss: 0.0399 - val_loss: 0.0575\n",
      "Epoch 73/90\n",
      "144/144 [==============================] - 0s 1ms/step - loss: 0.0397 - val_loss: 0.0569\n",
      "Epoch 74/90\n",
      "144/144 [==============================] - 0s 1ms/step - loss: 0.0395 - val_loss: 0.0562\n",
      "Epoch 75/90\n",
      "144/144 [==============================] - 0s 1ms/step - loss: 0.0394 - val_loss: 0.0556\n",
      "Epoch 76/90\n",
      "144/144 [==============================] - 0s 1ms/step - loss: 0.0390 - val_loss: 0.0550\n",
      "Epoch 77/90\n",
      "144/144 [==============================] - 0s 1ms/step - loss: 0.0387 - val_loss: 0.0544\n",
      "Epoch 78/90\n",
      "144/144 [==============================] - 0s 1ms/step - loss: 0.0386 - val_loss: 0.0539\n",
      "Epoch 79/90\n",
      "144/144 [==============================] - 0s 1ms/step - loss: 0.0384 - val_loss: 0.0533\n",
      "Epoch 80/90\n",
      "144/144 [==============================] - 0s 1ms/step - loss: 0.0381 - val_loss: 0.0528\n",
      "Epoch 81/90\n",
      "144/144 [==============================] - 0s 1ms/step - loss: 0.0379 - val_loss: 0.0522\n",
      "Epoch 82/90\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "144/144 [==============================] - 0s 1ms/step - loss: 0.0376 - val_loss: 0.0517\n",
      "Epoch 83/90\n",
      "144/144 [==============================] - 0s 1ms/step - loss: 0.0376 - val_loss: 0.0511\n",
      "Epoch 84/90\n",
      "144/144 [==============================] - 0s 1ms/step - loss: 0.0372 - val_loss: 0.0506\n",
      "Epoch 85/90\n",
      "144/144 [==============================] - 0s 1ms/step - loss: 0.0371 - val_loss: 0.0501\n",
      "Epoch 86/90\n",
      "144/144 [==============================] - 0s 1ms/step - loss: 0.0371 - val_loss: 0.0496\n",
      "Epoch 87/90\n",
      "144/144 [==============================] - 0s 1ms/step - loss: 0.0367 - val_loss: 0.0491\n",
      "Epoch 88/90\n",
      "144/144 [==============================] - 0s 1ms/step - loss: 0.0367 - val_loss: 0.0486\n",
      "Epoch 89/90\n",
      "144/144 [==============================] - 0s 1ms/step - loss: 0.0363 - val_loss: 0.0481\n",
      "Epoch 90/90\n",
      "144/144 [==============================] - 0s 1ms/step - loss: 0.0362 - val_loss: 0.0476\n",
      "Execution time:  19.777557611465454\n",
      "DNN:\n",
      "Mean Absolute Error: 0.0366\n",
      "Root Mean Square Error: 0.0470\n",
      "Mean Square Error: 0.0022\n",
      "\n",
      "Train RMSE: 0.047\n",
      "Train MSE: 0.002\n",
      "Train MAE: 0.037\n",
      "###########################\n",
      "\n",
      "MODEL:  DNN\n",
      "sequence:  1h\n",
      "units:  12\n",
      "dropout1:  0.48476373451509647\n",
      "optimizer: adadelta\n",
      "activationDense: sigmoid\n",
      "epochs: 52\n",
      "batchsize: 57\n",
      "validation_split: 0.1\n",
      "Model: \"sequential_20\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_60 (Dense)             (None, 6, 12)             24        \n",
      "_________________________________________________________________\n",
      "dense_61 (Dense)             (None, 6, 16)             208       \n",
      "_________________________________________________________________\n",
      "dropout_20 (Dropout)         (None, 6, 16)             0         \n",
      "_________________________________________________________________\n",
      "dense_62 (Dense)             (None, 6, 1)              17        \n",
      "=================================================================\n",
      "Total params: 249\n",
      "Trainable params: 249\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/52\n",
      "63/63 [==============================] - 0s 4ms/step - loss: 0.0778 - val_loss: 0.1108\n",
      "Epoch 2/52\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0776 - val_loss: 0.1106\n",
      "Epoch 3/52\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0777 - val_loss: 0.1104\n",
      "Epoch 4/52\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0772 - val_loss: 0.1102\n",
      "Epoch 5/52\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0771 - val_loss: 0.1100\n",
      "Epoch 6/52\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0768 - val_loss: 0.1098\n",
      "Epoch 7/52\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0767 - val_loss: 0.1095\n",
      "Epoch 8/52\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0763 - val_loss: 0.1093\n",
      "Epoch 9/52\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0763 - val_loss: 0.1091\n",
      "Epoch 10/52\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0762 - val_loss: 0.1089\n",
      "Epoch 11/52\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0760 - val_loss: 0.1086\n",
      "Epoch 12/52\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0756 - val_loss: 0.1084\n",
      "Epoch 13/52\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0758 - val_loss: 0.1081\n",
      "Epoch 14/52\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0755 - val_loss: 0.1079\n",
      "Epoch 15/52\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0750 - val_loss: 0.1076\n",
      "Epoch 16/52\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0750 - val_loss: 0.1074\n",
      "Epoch 17/52\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0748 - val_loss: 0.1071\n",
      "Epoch 18/52\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0745 - val_loss: 0.1069\n",
      "Epoch 19/52\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0742 - val_loss: 0.1066\n",
      "Epoch 20/52\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0741 - val_loss: 0.1063\n",
      "Epoch 21/52\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0741 - val_loss: 0.1061\n",
      "Epoch 22/52\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0736 - val_loss: 0.1058\n",
      "Epoch 23/52\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0734 - val_loss: 0.1055\n",
      "Epoch 24/52\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0730 - val_loss: 0.1053\n",
      "Epoch 25/52\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0729 - val_loss: 0.1050\n",
      "Epoch 26/52\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0728 - val_loss: 0.1047\n",
      "Epoch 27/52\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0722 - val_loss: 0.1044\n",
      "Epoch 28/52\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0722 - val_loss: 0.1041\n",
      "Epoch 29/52\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0719 - val_loss: 0.1039\n",
      "Epoch 30/52\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0718 - val_loss: 0.1036\n",
      "Epoch 31/52\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0716 - val_loss: 0.1033\n",
      "Epoch 32/52\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0714 - val_loss: 0.1030\n",
      "Epoch 33/52\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0710 - val_loss: 0.1027\n",
      "Epoch 34/52\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0708 - val_loss: 0.1024\n",
      "Epoch 35/52\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0709 - val_loss: 0.1022\n",
      "Epoch 36/52\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0704 - val_loss: 0.1019\n",
      "Epoch 37/52\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0702 - val_loss: 0.1016\n",
      "Epoch 38/52\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0700 - val_loss: 0.1013\n",
      "Epoch 39/52\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0698 - val_loss: 0.1010\n",
      "Epoch 40/52\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0694 - val_loss: 0.1007\n",
      "Epoch 41/52\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0693 - val_loss: 0.1005\n",
      "Epoch 42/52\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0688 - val_loss: 0.1002\n",
      "Epoch 43/52\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0689 - val_loss: 0.1000\n",
      "Epoch 44/52\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0686 - val_loss: 0.0998\n",
      "Epoch 45/52\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0685 - val_loss: 0.0996\n",
      "Epoch 46/52\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0684 - val_loss: 0.0994\n",
      "Epoch 47/52\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0681 - val_loss: 0.0992\n",
      "Epoch 48/52\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0683 - val_loss: 0.0990\n",
      "Epoch 49/52\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0676 - val_loss: 0.0988\n",
      "Epoch 50/52\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0675 - val_loss: 0.0986\n",
      "Epoch 51/52\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0678 - val_loss: 0.0984\n",
      "Epoch 52/52\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0674 - val_loss: 0.0982\n",
      "Execution time:  6.700023889541626\n",
      "DNN:\n",
      "Mean Absolute Error: 0.0691\n",
      "Root Mean Square Error: 0.0770\n",
      "Mean Square Error: 0.0059\n",
      "\n",
      "Train RMSE: 0.077\n",
      "Train MSE: 0.006\n",
      "Train MAE: 0.069\n",
      "###########################\n",
      "\n",
      "MODEL:  DNN\n",
      "sequence:  1h\n",
      "units:  87\n",
      "dropout1:  0.40519643149940265\n",
      "optimizer: adadelta\n",
      "activationDense: sigmoid\n",
      "epochs: 80\n",
      "batchsize: 31\n",
      "validation_split: 0.2\n",
      "Model: \"sequential_21\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_63 (Dense)             (None, 6, 87)             174       \n",
      "_________________________________________________________________\n",
      "dense_64 (Dense)             (None, 6, 16)             1408      \n",
      "_________________________________________________________________\n",
      "dropout_21 (Dropout)         (None, 6, 16)             0         \n",
      "_________________________________________________________________\n",
      "dense_65 (Dense)             (None, 6, 1)              17        \n",
      "=================================================================\n",
      "Total params: 1,599\n",
      "Trainable params: 1,599\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/80\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "103/103 [==============================] - 0s 3ms/step - loss: 0.1092 - val_loss: 0.1292\n",
      "Epoch 2/80\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.1088 - val_loss: 0.1289\n",
      "Epoch 3/80\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.1084 - val_loss: 0.1284\n",
      "Epoch 4/80\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.1079 - val_loss: 0.1280\n",
      "Epoch 5/80\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.1076 - val_loss: 0.1276\n",
      "Epoch 6/80\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.1070 - val_loss: 0.1271\n",
      "Epoch 7/80\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.1066 - val_loss: 0.1266\n",
      "Epoch 8/80\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.1060 - val_loss: 0.1261\n",
      "Epoch 9/80\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.1055 - val_loss: 0.1256\n",
      "Epoch 10/80\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.1050 - val_loss: 0.1250\n",
      "Epoch 11/80\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.1044 - val_loss: 0.1245\n",
      "Epoch 12/80\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.1039 - val_loss: 0.1240\n",
      "Epoch 13/80\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.1033 - val_loss: 0.1234\n",
      "Epoch 14/80\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.1027 - val_loss: 0.1228\n",
      "Epoch 15/80\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.1019 - val_loss: 0.1222\n",
      "Epoch 16/80\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.1014 - val_loss: 0.1216\n",
      "Epoch 17/80\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.1008 - val_loss: 0.1210\n",
      "Epoch 18/80\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.1001 - val_loss: 0.1204\n",
      "Epoch 19/80\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.0995 - val_loss: 0.1198\n",
      "Epoch 20/80\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.0989 - val_loss: 0.1192\n",
      "Epoch 21/80\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.0983 - val_loss: 0.1186\n",
      "Epoch 22/80\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.0975 - val_loss: 0.1181\n",
      "Epoch 23/80\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.0970 - val_loss: 0.1175\n",
      "Epoch 24/80\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.0965 - val_loss: 0.1170\n",
      "Epoch 25/80\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.0959 - val_loss: 0.1164\n",
      "Epoch 26/80\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.0953 - val_loss: 0.1159\n",
      "Epoch 27/80\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.0948 - val_loss: 0.1153\n",
      "Epoch 28/80\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.0942 - val_loss: 0.1147\n",
      "Epoch 29/80\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.0935 - val_loss: 0.1142\n",
      "Epoch 30/80\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.0929 - val_loss: 0.1136\n",
      "Epoch 31/80\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.0924 - val_loss: 0.1130\n",
      "Epoch 32/80\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.0918 - val_loss: 0.1124\n",
      "Epoch 33/80\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.0912 - val_loss: 0.1118\n",
      "Epoch 34/80\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.0906 - val_loss: 0.1113\n",
      "Epoch 35/80\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.0899 - val_loss: 0.1107\n",
      "Epoch 36/80\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.0893 - val_loss: 0.1101\n",
      "Epoch 37/80\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.0887 - val_loss: 0.1094\n",
      "Epoch 38/80\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.0880 - val_loss: 0.1085\n",
      "Epoch 39/80\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.0870 - val_loss: 0.1075\n",
      "Epoch 40/80\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.0861 - val_loss: 0.1065\n",
      "Epoch 41/80\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.0849 - val_loss: 0.1055\n",
      "Epoch 42/80\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.0840 - val_loss: 0.1045\n",
      "Epoch 43/80\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.0829 - val_loss: 0.1035\n",
      "Epoch 44/80\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.0821 - val_loss: 0.1025\n",
      "Epoch 45/80\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.0809 - val_loss: 0.1016\n",
      "Epoch 46/80\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.0801 - val_loss: 0.1006\n",
      "Epoch 47/80\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.0790 - val_loss: 0.0996\n",
      "Epoch 48/80\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.0781 - val_loss: 0.0986\n",
      "Epoch 49/80\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.0770 - val_loss: 0.0976\n",
      "Epoch 50/80\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.0761 - val_loss: 0.0966\n",
      "Epoch 51/80\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.0750 - val_loss: 0.0956\n",
      "Epoch 52/80\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.0742 - val_loss: 0.0947\n",
      "Epoch 53/80\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.0733 - val_loss: 0.0937\n",
      "Epoch 54/80\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.0722 - val_loss: 0.0927\n",
      "Epoch 55/80\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.0714 - val_loss: 0.0918\n",
      "Epoch 56/80\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.0704 - val_loss: 0.0908\n",
      "Epoch 57/80\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.0697 - val_loss: 0.0899\n",
      "Epoch 58/80\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.0686 - val_loss: 0.0890\n",
      "Epoch 59/80\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.0679 - val_loss: 0.0882\n",
      "Epoch 60/80\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.0670 - val_loss: 0.0875\n",
      "Epoch 61/80\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.0665 - val_loss: 0.0867\n",
      "Epoch 62/80\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.0658 - val_loss: 0.0860\n",
      "Epoch 63/80\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.0651 - val_loss: 0.0853\n",
      "Epoch 64/80\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.0644 - val_loss: 0.0846\n",
      "Epoch 65/80\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.0638 - val_loss: 0.0839\n",
      "Epoch 66/80\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.0633 - val_loss: 0.0833\n",
      "Epoch 67/80\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.0628 - val_loss: 0.0826\n",
      "Epoch 68/80\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.0620 - val_loss: 0.0820\n",
      "Epoch 69/80\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.0617 - val_loss: 0.0813\n",
      "Epoch 70/80\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.0610 - val_loss: 0.0807\n",
      "Epoch 71/80\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.0605 - val_loss: 0.0800\n",
      "Epoch 72/80\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.0602 - val_loss: 0.0794\n",
      "Epoch 73/80\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.0597 - val_loss: 0.0788\n",
      "Epoch 74/80\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.0593 - val_loss: 0.0782\n",
      "Epoch 75/80\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.0587 - val_loss: 0.0777\n",
      "Epoch 76/80\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.0584 - val_loss: 0.0771\n",
      "Epoch 77/80\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.0576 - val_loss: 0.0765\n",
      "Epoch 78/80\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.0571 - val_loss: 0.0760\n",
      "Epoch 79/80\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.0571 - val_loss: 0.0754\n",
      "Epoch 80/80\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.0568 - val_loss: 0.0749\n",
      "Execution time:  15.50702428817749\n",
      "DNN:\n",
      "Mean Absolute Error: 0.0588\n",
      "Root Mean Square Error: 0.0666\n",
      "Mean Square Error: 0.0044\n",
      "\n",
      "Train RMSE: 0.067\n",
      "Train MSE: 0.004\n",
      "Train MAE: 0.059\n",
      "###########################\n",
      "\n",
      "MODEL:  DNN\n",
      "sequence:  1h\n",
      "units:  80\n",
      "dropout1:  0.11814836227952394\n",
      "optimizer: adadelta\n",
      "activationDense: sigmoid\n",
      "epochs: 90\n",
      "batchsize: 25\n",
      "validation_split: 0.2\n",
      "Model: \"sequential_22\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_66 (Dense)             (None, 6, 80)             160       \n",
      "_________________________________________________________________\n",
      "dense_67 (Dense)             (None, 6, 16)             1296      \n",
      "_________________________________________________________________\n",
      "dropout_22 (Dropout)         (None, 6, 16)             0         \n",
      "_________________________________________________________________\n",
      "dense_68 (Dense)             (None, 6, 1)              17        \n",
      "=================================================================\n",
      "Total params: 1,473\n",
      "Trainable params: 1,473\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/90\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "128/128 [==============================] - 0s 3ms/step - loss: 0.0888 - val_loss: 0.1101\n",
      "Epoch 2/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0881 - val_loss: 0.1094\n",
      "Epoch 3/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0873 - val_loss: 0.1087\n",
      "Epoch 4/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0865 - val_loss: 0.1079\n",
      "Epoch 5/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0857 - val_loss: 0.1070\n",
      "Epoch 6/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0847 - val_loss: 0.1061\n",
      "Epoch 7/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0838 - val_loss: 0.1052\n",
      "Epoch 8/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0828 - val_loss: 0.1042\n",
      "Epoch 9/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0818 - val_loss: 0.1031\n",
      "Epoch 10/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0807 - val_loss: 0.1021\n",
      "Epoch 11/90\n",
      "128/128 [==============================] - 0s 1ms/step - loss: 0.0796 - val_loss: 0.1010\n",
      "Epoch 12/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0786 - val_loss: 0.1000\n",
      "Epoch 13/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0776 - val_loss: 0.0990\n",
      "Epoch 14/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0764 - val_loss: 0.0979\n",
      "Epoch 15/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0755 - val_loss: 0.0968\n",
      "Epoch 16/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0744 - val_loss: 0.0958\n",
      "Epoch 17/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0732 - val_loss: 0.0947\n",
      "Epoch 18/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0722 - val_loss: 0.0936\n",
      "Epoch 19/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0711 - val_loss: 0.0925\n",
      "Epoch 20/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0702 - val_loss: 0.0914\n",
      "Epoch 21/90\n",
      "128/128 [==============================] - 0s 1ms/step - loss: 0.0690 - val_loss: 0.0903\n",
      "Epoch 22/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0680 - val_loss: 0.0891\n",
      "Epoch 23/90\n",
      "128/128 [==============================] - 0s 1ms/step - loss: 0.0670 - val_loss: 0.0880\n",
      "Epoch 24/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0660 - val_loss: 0.0869\n",
      "Epoch 25/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0649 - val_loss: 0.0858\n",
      "Epoch 26/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0639 - val_loss: 0.0848\n",
      "Epoch 27/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0629 - val_loss: 0.0837\n",
      "Epoch 28/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0620 - val_loss: 0.0827\n",
      "Epoch 29/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0610 - val_loss: 0.0816\n",
      "Epoch 30/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0602 - val_loss: 0.0806\n",
      "Epoch 31/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0593 - val_loss: 0.0795\n",
      "Epoch 32/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0583 - val_loss: 0.0785\n",
      "Epoch 33/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0575 - val_loss: 0.0775\n",
      "Epoch 34/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0569 - val_loss: 0.0765\n",
      "Epoch 35/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0560 - val_loss: 0.0757\n",
      "Epoch 36/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0554 - val_loss: 0.0748\n",
      "Epoch 37/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0547 - val_loss: 0.0740\n",
      "Epoch 38/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0540 - val_loss: 0.0732\n",
      "Epoch 39/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0535 - val_loss: 0.0724\n",
      "Epoch 40/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0529 - val_loss: 0.0717\n",
      "Epoch 41/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0523 - val_loss: 0.0709\n",
      "Epoch 42/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0520 - val_loss: 0.0702\n",
      "Epoch 43/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0516 - val_loss: 0.0695\n",
      "Epoch 44/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0508 - val_loss: 0.0688\n",
      "Epoch 45/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0505 - val_loss: 0.0680\n",
      "Epoch 46/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0498 - val_loss: 0.0673\n",
      "Epoch 47/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0494 - val_loss: 0.0666\n",
      "Epoch 48/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0489 - val_loss: 0.0659\n",
      "Epoch 49/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0485 - val_loss: 0.0653\n",
      "Epoch 50/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0481 - val_loss: 0.0646\n",
      "Epoch 51/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0475 - val_loss: 0.0640\n",
      "Epoch 52/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0474 - val_loss: 0.0634\n",
      "Epoch 53/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0469 - val_loss: 0.0628\n",
      "Epoch 54/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0467 - val_loss: 0.0621\n",
      "Epoch 55/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0462 - val_loss: 0.0615\n",
      "Epoch 56/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0459 - val_loss: 0.0609\n",
      "Epoch 57/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0456 - val_loss: 0.0603\n",
      "Epoch 58/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0453 - val_loss: 0.0598\n",
      "Epoch 59/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0448 - val_loss: 0.0592\n",
      "Epoch 60/90\n",
      "128/128 [==============================] - 0s 1ms/step - loss: 0.0445 - val_loss: 0.0586\n",
      "Epoch 61/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0442 - val_loss: 0.0580\n",
      "Epoch 62/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0439 - val_loss: 0.0575\n",
      "Epoch 63/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0438 - val_loss: 0.0569\n",
      "Epoch 64/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0434 - val_loss: 0.0564\n",
      "Epoch 65/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0430 - val_loss: 0.0558\n",
      "Epoch 66/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0429 - val_loss: 0.0553\n",
      "Epoch 67/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0428 - val_loss: 0.0547\n",
      "Epoch 68/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0425 - val_loss: 0.0542\n",
      "Epoch 69/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0422 - val_loss: 0.0537\n",
      "Epoch 70/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0418 - val_loss: 0.0532\n",
      "Epoch 71/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0415 - val_loss: 0.0526\n",
      "Epoch 72/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0413 - val_loss: 0.0521\n",
      "Epoch 73/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0410 - val_loss: 0.0516\n",
      "Epoch 74/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0410 - val_loss: 0.0511\n",
      "Epoch 75/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0406 - val_loss: 0.0506\n",
      "Epoch 76/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0404 - val_loss: 0.0501\n",
      "Epoch 77/90\n",
      "128/128 [==============================] - 0s 1ms/step - loss: 0.0401 - val_loss: 0.0496\n",
      "Epoch 78/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0397 - val_loss: 0.0491\n",
      "Epoch 79/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0398 - val_loss: 0.0487\n",
      "Epoch 80/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0396 - val_loss: 0.0482\n",
      "Epoch 81/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0394 - val_loss: 0.0478\n",
      "Epoch 82/90\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0390 - val_loss: 0.0474\n",
      "Epoch 83/90\n",
      "128/128 [==============================] - 0s 1ms/step - loss: 0.0391 - val_loss: 0.0469\n",
      "Epoch 84/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0388 - val_loss: 0.0465\n",
      "Epoch 85/90\n",
      "128/128 [==============================] - 0s 1ms/step - loss: 0.0387 - val_loss: 0.0462\n",
      "Epoch 86/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0385 - val_loss: 0.0458\n",
      "Epoch 87/90\n",
      "128/128 [==============================] - 0s 1ms/step - loss: 0.0381 - val_loss: 0.0454\n",
      "Epoch 88/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0384 - val_loss: 0.0450\n",
      "Epoch 89/90\n",
      "128/128 [==============================] - 0s 1ms/step - loss: 0.0383 - val_loss: 0.0446\n",
      "Epoch 90/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0379 - val_loss: 0.0442\n",
      "Execution time:  19.163029432296753\n",
      "DNN:\n",
      "Mean Absolute Error: 0.0381\n",
      "Root Mean Square Error: 0.0480\n",
      "Mean Square Error: 0.0023\n",
      "\n",
      "Train RMSE: 0.048\n",
      "Train MSE: 0.002\n",
      "Train MAE: 0.038\n",
      "###########################\n",
      "\n",
      "MODEL:  DNN\n",
      "sequence:  1h\n",
      "units:  12\n",
      "dropout1:  0.48476373451509647\n",
      "optimizer: adadelta\n",
      "activationDense: sigmoid\n",
      "epochs: 52\n",
      "batchsize: 57\n",
      "validation_split: 0.2\n",
      "Model: \"sequential_23\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_69 (Dense)             (None, 6, 12)             24        \n",
      "_________________________________________________________________\n",
      "dense_70 (Dense)             (None, 6, 16)             208       \n",
      "_________________________________________________________________\n",
      "dropout_23 (Dropout)         (None, 6, 16)             0         \n",
      "_________________________________________________________________\n",
      "dense_71 (Dense)             (None, 6, 1)              17        \n",
      "=================================================================\n",
      "Total params: 249\n",
      "Trainable params: 249\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/52\n",
      "56/56 [==============================] - 0s 5ms/step - loss: 0.0992 - val_loss: 0.1196\n",
      "Epoch 2/52\n",
      "56/56 [==============================] - 0s 2ms/step - loss: 0.0990 - val_loss: 0.1194\n",
      "Epoch 3/52\n",
      "56/56 [==============================] - 0s 2ms/step - loss: 0.0988 - val_loss: 0.1192\n",
      "Epoch 4/52\n",
      "56/56 [==============================] - 0s 2ms/step - loss: 0.0984 - val_loss: 0.1190\n",
      "Epoch 5/52\n",
      "56/56 [==============================] - 0s 2ms/step - loss: 0.0982 - val_loss: 0.1187\n",
      "Epoch 6/52\n",
      "56/56 [==============================] - 0s 2ms/step - loss: 0.0977 - val_loss: 0.1184\n",
      "Epoch 7/52\n",
      "56/56 [==============================] - 0s 2ms/step - loss: 0.0977 - val_loss: 0.1181\n",
      "Epoch 8/52\n",
      "56/56 [==============================] - 0s 2ms/step - loss: 0.0973 - val_loss: 0.1178\n",
      "Epoch 9/52\n",
      "56/56 [==============================] - 0s 2ms/step - loss: 0.0972 - val_loss: 0.1175\n",
      "Epoch 10/52\n",
      "56/56 [==============================] - 0s 2ms/step - loss: 0.0966 - val_loss: 0.1171\n",
      "Epoch 11/52\n",
      "56/56 [==============================] - 0s 2ms/step - loss: 0.0965 - val_loss: 0.1168\n",
      "Epoch 12/52\n",
      "56/56 [==============================] - 0s 2ms/step - loss: 0.0958 - val_loss: 0.1165\n",
      "Epoch 13/52\n",
      "56/56 [==============================] - 0s 2ms/step - loss: 0.0954 - val_loss: 0.1161\n",
      "Epoch 14/52\n",
      "56/56 [==============================] - 0s 2ms/step - loss: 0.0955 - val_loss: 0.1158\n",
      "Epoch 15/52\n",
      "56/56 [==============================] - 0s 2ms/step - loss: 0.0953 - val_loss: 0.1154\n",
      "Epoch 16/52\n",
      "56/56 [==============================] - 0s 2ms/step - loss: 0.0946 - val_loss: 0.1151\n",
      "Epoch 17/52\n",
      "56/56 [==============================] - 0s 2ms/step - loss: 0.0939 - val_loss: 0.1147\n",
      "Epoch 18/52\n",
      "56/56 [==============================] - 0s 2ms/step - loss: 0.0940 - val_loss: 0.1143\n",
      "Epoch 19/52\n",
      "56/56 [==============================] - 0s 2ms/step - loss: 0.0935 - val_loss: 0.1140\n",
      "Epoch 20/52\n",
      "56/56 [==============================] - 0s 2ms/step - loss: 0.0931 - val_loss: 0.1136\n",
      "Epoch 21/52\n",
      "56/56 [==============================] - 0s 2ms/step - loss: 0.0924 - val_loss: 0.1132\n",
      "Epoch 22/52\n",
      "56/56 [==============================] - 0s 2ms/step - loss: 0.0922 - val_loss: 0.1128\n",
      "Epoch 23/52\n",
      "56/56 [==============================] - 0s 2ms/step - loss: 0.0918 - val_loss: 0.1124\n",
      "Epoch 24/52\n",
      "56/56 [==============================] - 0s 2ms/step - loss: 0.0916 - val_loss: 0.1120\n",
      "Epoch 25/52\n",
      "56/56 [==============================] - 0s 2ms/step - loss: 0.0913 - val_loss: 0.1117\n",
      "Epoch 26/52\n",
      "56/56 [==============================] - 0s 2ms/step - loss: 0.0906 - val_loss: 0.1113\n",
      "Epoch 27/52\n",
      "56/56 [==============================] - 0s 2ms/step - loss: 0.0904 - val_loss: 0.1109\n",
      "Epoch 28/52\n",
      "56/56 [==============================] - 0s 2ms/step - loss: 0.0901 - val_loss: 0.1105\n",
      "Epoch 29/52\n",
      "56/56 [==============================] - 0s 2ms/step - loss: 0.0893 - val_loss: 0.1101\n",
      "Epoch 30/52\n",
      "56/56 [==============================] - 0s 2ms/step - loss: 0.0892 - val_loss: 0.1097\n",
      "Epoch 31/52\n",
      "56/56 [==============================] - 0s 2ms/step - loss: 0.0889 - val_loss: 0.1093\n",
      "Epoch 32/52\n",
      "56/56 [==============================] - 0s 2ms/step - loss: 0.0883 - val_loss: 0.1088\n",
      "Epoch 33/52\n",
      "56/56 [==============================] - 0s 2ms/step - loss: 0.0879 - val_loss: 0.1084\n",
      "Epoch 34/52\n",
      "56/56 [==============================] - 0s 2ms/step - loss: 0.0875 - val_loss: 0.1080\n",
      "Epoch 35/52\n",
      "56/56 [==============================] - 0s 2ms/step - loss: 0.0870 - val_loss: 0.1076\n",
      "Epoch 36/52\n",
      "56/56 [==============================] - 0s 2ms/step - loss: 0.0868 - val_loss: 0.1072\n",
      "Epoch 37/52\n",
      "56/56 [==============================] - 0s 2ms/step - loss: 0.0861 - val_loss: 0.1068\n",
      "Epoch 38/52\n",
      "56/56 [==============================] - 0s 2ms/step - loss: 0.0859 - val_loss: 0.1064\n",
      "Epoch 39/52\n",
      "56/56 [==============================] - 0s 2ms/step - loss: 0.0855 - val_loss: 0.1060\n",
      "Epoch 40/52\n",
      "56/56 [==============================] - 0s 2ms/step - loss: 0.0851 - val_loss: 0.1055\n",
      "Epoch 41/52\n",
      "56/56 [==============================] - 0s 2ms/step - loss: 0.0848 - val_loss: 0.1051\n",
      "Epoch 42/52\n",
      "56/56 [==============================] - 0s 2ms/step - loss: 0.0841 - val_loss: 0.1047\n",
      "Epoch 43/52\n",
      "56/56 [==============================] - 0s 2ms/step - loss: 0.0839 - val_loss: 0.1043\n",
      "Epoch 44/52\n",
      "56/56 [==============================] - 0s 2ms/step - loss: 0.0835 - val_loss: 0.1039\n",
      "Epoch 45/52\n",
      "56/56 [==============================] - 0s 2ms/step - loss: 0.0832 - val_loss: 0.1034\n",
      "Epoch 46/52\n",
      "56/56 [==============================] - 0s 2ms/step - loss: 0.0827 - val_loss: 0.1030\n",
      "Epoch 47/52\n",
      "56/56 [==============================] - 0s 2ms/step - loss: 0.0820 - val_loss: 0.1026\n",
      "Epoch 48/52\n",
      "56/56 [==============================] - 0s 2ms/step - loss: 0.0816 - val_loss: 0.1022\n",
      "Epoch 49/52\n",
      "56/56 [==============================] - 0s 2ms/step - loss: 0.0816 - val_loss: 0.1017\n",
      "Epoch 50/52\n",
      "56/56 [==============================] - 0s 2ms/step - loss: 0.0811 - val_loss: 0.1013\n",
      "Epoch 51/52\n",
      "56/56 [==============================] - 0s 2ms/step - loss: 0.0806 - val_loss: 0.1009\n",
      "Epoch 52/52\n",
      "56/56 [==============================] - 0s 2ms/step - loss: 0.0801 - val_loss: 0.1004\n",
      "Execution time:  6.310053586959839\n",
      "DNN:\n",
      "Mean Absolute Error: 0.0832\n",
      "Root Mean Square Error: 0.0902\n",
      "Mean Square Error: 0.0081\n",
      "\n",
      "Train RMSE: 0.090\n",
      "Train MSE: 0.008\n",
      "Train MAE: 0.083\n",
      "###########################\n",
      "\n",
      "MODEL:  DNN\n",
      "sequence:  1h\n",
      "units:  87\n",
      "dropout1:  0.40519643149940265\n",
      "optimizer: adamax\n",
      "activationDense: tanh\n",
      "epochs: 80\n",
      "batchsize: 31\n",
      "validation_split: 0.1\n",
      "Model: \"sequential_24\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_72 (Dense)             (None, 6, 87)             174       \n",
      "_________________________________________________________________\n",
      "dense_73 (Dense)             (None, 6, 16)             1408      \n",
      "_________________________________________________________________\n",
      "dropout_24 (Dropout)         (None, 6, 16)             0         \n",
      "_________________________________________________________________\n",
      "dense_74 (Dense)             (None, 6, 1)              17        \n",
      "=================================================================\n",
      "Total params: 1,599\n",
      "Trainable params: 1,599\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/80\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "116/116 [==============================] - 0s 3ms/step - loss: 0.1313 - val_loss: 0.0079\n",
      "Epoch 2/80\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.0826 - val_loss: 0.0171\n",
      "Epoch 3/80\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.0766 - val_loss: 0.0164\n",
      "Epoch 4/80\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.0697 - val_loss: 0.0093\n",
      "Epoch 5/80\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.0626 - val_loss: 0.0073\n",
      "Epoch 6/80\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.0560 - val_loss: 0.0046\n",
      "Epoch 7/80\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 0.0496 - val_loss: 0.0045\n",
      "Epoch 8/80\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.0433 - val_loss: 0.0055\n",
      "Epoch 9/80\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.0388 - val_loss: 0.0071\n",
      "Epoch 10/80\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.0350 - val_loss: 0.0084\n",
      "Epoch 11/80\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 0.0314 - val_loss: 0.0128\n",
      "Epoch 12/80\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 0.0284 - val_loss: 0.0151\n",
      "Epoch 13/80\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.0264 - val_loss: 0.0159\n",
      "Epoch 14/80\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 0.0258 - val_loss: 0.0149\n",
      "Epoch 15/80\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 0.0261 - val_loss: 0.0102\n",
      "Epoch 16/80\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.0248 - val_loss: 0.0106\n",
      "Epoch 17/80\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.0242 - val_loss: 0.0104\n",
      "Epoch 18/80\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 0.0234 - val_loss: 0.0113\n",
      "Epoch 19/80\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.0231 - val_loss: 0.0101\n",
      "Epoch 20/80\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.0224 - val_loss: 0.0102\n",
      "Epoch 21/80\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.0222 - val_loss: 0.0105\n",
      "Epoch 22/80\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.0203 - val_loss: 0.0115\n",
      "Epoch 23/80\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.0185 - val_loss: 0.0121\n",
      "Epoch 24/80\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.0177 - val_loss: 0.0127\n",
      "Epoch 25/80\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.0164 - val_loss: 0.0140\n",
      "Epoch 26/80\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.0159 - val_loss: 0.0136\n",
      "Epoch 27/80\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.0149 - val_loss: 0.0145\n",
      "Epoch 28/80\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 0.0148 - val_loss: 0.0142\n",
      "Epoch 29/80\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.0145 - val_loss: 0.0140\n",
      "Epoch 30/80\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.0143 - val_loss: 0.0135\n",
      "Epoch 31/80\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.0140 - val_loss: 0.0134\n",
      "Epoch 32/80\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.0137 - val_loss: 0.0119\n",
      "Epoch 33/80\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.0138 - val_loss: 0.0135\n",
      "Epoch 34/80\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.0137 - val_loss: 0.0124\n",
      "Epoch 35/80\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.0138 - val_loss: 0.0117\n",
      "Epoch 36/80\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.0138 - val_loss: 0.0135\n",
      "Epoch 37/80\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 0.0136 - val_loss: 0.0133\n",
      "Epoch 38/80\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.0136 - val_loss: 0.0126\n",
      "Epoch 39/80\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 0.0138 - val_loss: 0.0125\n",
      "Epoch 40/80\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.0135 - val_loss: 0.0124\n",
      "Epoch 41/80\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.0139 - val_loss: 0.0137\n",
      "Epoch 42/80\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 0.0139 - val_loss: 0.0128\n",
      "Epoch 43/80\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.0135 - val_loss: 0.0134\n",
      "Epoch 44/80\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.0135 - val_loss: 0.0130\n",
      "Epoch 45/80\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 0.0137 - val_loss: 0.0131\n",
      "Epoch 46/80\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 0.0138 - val_loss: 0.0123\n",
      "Epoch 47/80\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 0.0137 - val_loss: 0.0123\n",
      "Epoch 48/80\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 0.0137 - val_loss: 0.0123\n",
      "Epoch 49/80\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.0132 - val_loss: 0.0119\n",
      "Epoch 50/80\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 0.0134 - val_loss: 0.0122\n",
      "Epoch 51/80\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.0135 - val_loss: 0.0120\n",
      "Epoch 52/80\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 0.0135 - val_loss: 0.0124\n",
      "Epoch 53/80\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.0135 - val_loss: 0.0133\n",
      "Epoch 54/80\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 0.0135 - val_loss: 0.0136\n",
      "Epoch 55/80\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.0135 - val_loss: 0.0135\n",
      "Epoch 56/80\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.0136 - val_loss: 0.0120\n",
      "Epoch 57/80\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 0.0137 - val_loss: 0.0130\n",
      "Epoch 58/80\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.0135 - val_loss: 0.0128\n",
      "Epoch 59/80\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 0.0134 - val_loss: 0.0136\n",
      "Epoch 60/80\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.0134 - val_loss: 0.0124\n",
      "Epoch 61/80\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 0.0136 - val_loss: 0.0134\n",
      "Epoch 62/80\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.0138 - val_loss: 0.0127\n",
      "Epoch 63/80\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 0.0133 - val_loss: 0.0124\n",
      "Epoch 64/80\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 0.0133 - val_loss: 0.0131\n",
      "Epoch 65/80\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 0.0135 - val_loss: 0.0121\n",
      "Epoch 66/80\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.0137 - val_loss: 0.0128\n",
      "Epoch 67/80\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.0137 - val_loss: 0.0128\n",
      "Epoch 68/80\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 0.0133 - val_loss: 0.0123\n",
      "Epoch 69/80\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 0.0134 - val_loss: 0.0129\n",
      "Epoch 70/80\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.0137 - val_loss: 0.0127\n",
      "Epoch 71/80\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 0.0135 - val_loss: 0.0134\n",
      "Epoch 72/80\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.0135 - val_loss: 0.0128\n",
      "Epoch 73/80\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.0133 - val_loss: 0.0132\n",
      "Epoch 74/80\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.0132 - val_loss: 0.0137\n",
      "Epoch 75/80\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 0.0137 - val_loss: 0.0124\n",
      "Epoch 76/80\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.0135 - val_loss: 0.0132\n",
      "Epoch 77/80\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.0134 - val_loss: 0.0123\n",
      "Epoch 78/80\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.0135 - val_loss: 0.0123\n",
      "Epoch 79/80\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 0.0131 - val_loss: 0.0124\n",
      "Epoch 80/80\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.0132 - val_loss: 0.0135\n",
      "Execution time:  15.828001737594604\n",
      "DNN:\n",
      "Mean Absolute Error: 0.0071\n",
      "Root Mean Square Error: 0.0136\n",
      "Mean Square Error: 0.0002\n",
      "\n",
      "Train RMSE: 0.014\n",
      "Train MSE: 0.000\n",
      "Train MAE: 0.007\n",
      "###########################\n",
      "\n",
      "MODEL:  DNN\n",
      "sequence:  1h\n",
      "units:  80\n",
      "dropout1:  0.11814836227952394\n",
      "optimizer: adamax\n",
      "activationDense: tanh\n",
      "epochs: 90\n",
      "batchsize: 25\n",
      "validation_split: 0.1\n",
      "Model: \"sequential_25\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_75 (Dense)             (None, 6, 80)             160       \n",
      "_________________________________________________________________\n",
      "dense_76 (Dense)             (None, 6, 16)             1296      \n",
      "_________________________________________________________________\n",
      "dropout_25 (Dropout)         (None, 6, 16)             0         \n",
      "_________________________________________________________________\n",
      "dense_77 (Dense)             (None, 6, 1)              17        \n",
      "=================================================================\n",
      "Total params: 1,473\n",
      "Trainable params: 1,473\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/90\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "144/144 [==============================] - 0s 3ms/step - loss: 0.1100 - val_loss: 0.0149\n",
      "Epoch 2/90\n",
      "144/144 [==============================] - 0s 1ms/step - loss: 0.0507 - val_loss: 0.0158\n",
      "Epoch 3/90\n",
      "144/144 [==============================] - 0s 1ms/step - loss: 0.0496 - val_loss: 0.0158\n",
      "Epoch 4/90\n",
      "144/144 [==============================] - 0s 1ms/step - loss: 0.0473 - val_loss: 0.0139\n",
      "Epoch 5/90\n",
      "144/144 [==============================] - 0s 1ms/step - loss: 0.0462 - val_loss: 0.0098\n",
      "Epoch 6/90\n",
      "144/144 [==============================] - 0s 1ms/step - loss: 0.0444 - val_loss: 0.0071\n",
      "Epoch 7/90\n",
      "144/144 [==============================] - 0s 1ms/step - loss: 0.0419 - val_loss: 0.0075\n",
      "Epoch 8/90\n",
      "144/144 [==============================] - 0s 1ms/step - loss: 0.0410 - val_loss: 0.0059\n",
      "Epoch 9/90\n",
      "144/144 [==============================] - 0s 1ms/step - loss: 0.0387 - val_loss: 0.0047\n",
      "Epoch 10/90\n",
      "144/144 [==============================] - 0s 1ms/step - loss: 0.0364 - val_loss: 0.0040\n",
      "Epoch 11/90\n",
      "144/144 [==============================] - 0s 1ms/step - loss: 0.0352 - val_loss: 0.0040\n",
      "Epoch 12/90\n",
      "144/144 [==============================] - 0s 1ms/step - loss: 0.0336 - val_loss: 0.0050\n",
      "Epoch 13/90\n",
      "144/144 [==============================] - 0s 1ms/step - loss: 0.0320 - val_loss: 0.0053\n",
      "Epoch 14/90\n",
      "144/144 [==============================] - 0s 1ms/step - loss: 0.0302 - val_loss: 0.0061\n",
      "Epoch 15/90\n",
      "144/144 [==============================] - 0s 1ms/step - loss: 0.0291 - val_loss: 0.0069\n",
      "Epoch 16/90\n",
      "144/144 [==============================] - 0s 1ms/step - loss: 0.0275 - val_loss: 0.0069\n",
      "Epoch 17/90\n",
      "144/144 [==============================] - 0s 1ms/step - loss: 0.0257 - val_loss: 0.0086\n",
      "Epoch 18/90\n",
      "144/144 [==============================] - 0s 1ms/step - loss: 0.0235 - val_loss: 0.0079\n",
      "Epoch 19/90\n",
      "144/144 [==============================] - 0s 1ms/step - loss: 0.0224 - val_loss: 0.0082\n",
      "Epoch 20/90\n",
      "144/144 [==============================] - 0s 2ms/step - loss: 0.0211 - val_loss: 0.0115\n",
      "Epoch 21/90\n",
      "144/144 [==============================] - 0s 2ms/step - loss: 0.0196 - val_loss: 0.0108\n",
      "Epoch 22/90\n",
      "144/144 [==============================] - 0s 2ms/step - loss: 0.0185 - val_loss: 0.0108\n",
      "Epoch 23/90\n",
      "144/144 [==============================] - 0s 2ms/step - loss: 0.0173 - val_loss: 0.0133\n",
      "Epoch 24/90\n",
      "144/144 [==============================] - 0s 2ms/step - loss: 0.0164 - val_loss: 0.0128\n",
      "Epoch 25/90\n",
      "144/144 [==============================] - 0s 1ms/step - loss: 0.0151 - val_loss: 0.0116\n",
      "Epoch 26/90\n",
      "144/144 [==============================] - 0s 1ms/step - loss: 0.0144 - val_loss: 0.0160\n",
      "Epoch 27/90\n",
      "144/144 [==============================] - 0s 1ms/step - loss: 0.0139 - val_loss: 0.0144\n",
      "Epoch 28/90\n",
      "144/144 [==============================] - 0s 1ms/step - loss: 0.0134 - val_loss: 0.0140\n",
      "Epoch 29/90\n",
      "144/144 [==============================] - 0s 1ms/step - loss: 0.0134 - val_loss: 0.0137\n",
      "Epoch 30/90\n",
      "144/144 [==============================] - 0s 1ms/step - loss: 0.0125 - val_loss: 0.0138\n",
      "Epoch 31/90\n",
      "144/144 [==============================] - 0s 1ms/step - loss: 0.0122 - val_loss: 0.0148\n",
      "Epoch 32/90\n",
      "144/144 [==============================] - 0s 2ms/step - loss: 0.0121 - val_loss: 0.0149\n",
      "Epoch 33/90\n",
      "144/144 [==============================] - 0s 1ms/step - loss: 0.0120 - val_loss: 0.0134\n",
      "Epoch 34/90\n",
      "144/144 [==============================] - 0s 1ms/step - loss: 0.0116 - val_loss: 0.0132\n",
      "Epoch 35/90\n",
      "144/144 [==============================] - 0s 1ms/step - loss: 0.0116 - val_loss: 0.0133\n",
      "Epoch 36/90\n",
      "144/144 [==============================] - 0s 1ms/step - loss: 0.0116 - val_loss: 0.0134\n",
      "Epoch 37/90\n",
      "144/144 [==============================] - 0s 1ms/step - loss: 0.0116 - val_loss: 0.0136\n",
      "Epoch 38/90\n",
      "144/144 [==============================] - 0s 1ms/step - loss: 0.0115 - val_loss: 0.0135\n",
      "Epoch 39/90\n",
      "144/144 [==============================] - 0s 1ms/step - loss: 0.0114 - val_loss: 0.0126\n",
      "Epoch 40/90\n",
      "144/144 [==============================] - 0s 1ms/step - loss: 0.0115 - val_loss: 0.0130\n",
      "Epoch 41/90\n",
      "144/144 [==============================] - 0s 1ms/step - loss: 0.0114 - val_loss: 0.0137\n",
      "Epoch 42/90\n",
      "144/144 [==============================] - 0s 1ms/step - loss: 0.0118 - val_loss: 0.0136\n",
      "Epoch 43/90\n",
      "144/144 [==============================] - 0s 1ms/step - loss: 0.0116 - val_loss: 0.0124\n",
      "Epoch 44/90\n",
      "144/144 [==============================] - 0s 1ms/step - loss: 0.0115 - val_loss: 0.0129\n",
      "Epoch 45/90\n",
      "144/144 [==============================] - 0s 1ms/step - loss: 0.0113 - val_loss: 0.0138\n",
      "Epoch 46/90\n",
      "144/144 [==============================] - 0s 1ms/step - loss: 0.0114 - val_loss: 0.0133\n",
      "Epoch 47/90\n",
      "144/144 [==============================] - 0s 1ms/step - loss: 0.0113 - val_loss: 0.0113\n",
      "Epoch 48/90\n",
      "144/144 [==============================] - 0s 1ms/step - loss: 0.0115 - val_loss: 0.0126\n",
      "Epoch 49/90\n",
      "144/144 [==============================] - 0s 1ms/step - loss: 0.0115 - val_loss: 0.0143\n",
      "Epoch 50/90\n",
      "144/144 [==============================] - 0s 1ms/step - loss: 0.0115 - val_loss: 0.0130\n",
      "Epoch 51/90\n",
      "144/144 [==============================] - 0s 1ms/step - loss: 0.0113 - val_loss: 0.0133\n",
      "Epoch 52/90\n",
      "144/144 [==============================] - 0s 1ms/step - loss: 0.0114 - val_loss: 0.0128\n",
      "Epoch 53/90\n",
      "144/144 [==============================] - 0s 1ms/step - loss: 0.0115 - val_loss: 0.0138\n",
      "Epoch 54/90\n",
      "144/144 [==============================] - 0s 1ms/step - loss: 0.0118 - val_loss: 0.0133\n",
      "Epoch 55/90\n",
      "144/144 [==============================] - 0s 1ms/step - loss: 0.0115 - val_loss: 0.0136\n",
      "Epoch 56/90\n",
      "144/144 [==============================] - 0s 1ms/step - loss: 0.0114 - val_loss: 0.0130\n",
      "Epoch 57/90\n",
      "144/144 [==============================] - 0s 1ms/step - loss: 0.0115 - val_loss: 0.0130\n",
      "Epoch 58/90\n",
      "144/144 [==============================] - 0s 1ms/step - loss: 0.0114 - val_loss: 0.0140\n",
      "Epoch 59/90\n",
      "144/144 [==============================] - 0s 1ms/step - loss: 0.0116 - val_loss: 0.0141\n",
      "Epoch 60/90\n",
      "144/144 [==============================] - 0s 1ms/step - loss: 0.0114 - val_loss: 0.0139\n",
      "Epoch 61/90\n",
      "144/144 [==============================] - 0s 1ms/step - loss: 0.0115 - val_loss: 0.0139\n",
      "Epoch 62/90\n",
      "144/144 [==============================] - 0s 1ms/step - loss: 0.0114 - val_loss: 0.0141\n",
      "Epoch 63/90\n",
      "144/144 [==============================] - 0s 1ms/step - loss: 0.0115 - val_loss: 0.0144\n",
      "Epoch 64/90\n",
      "144/144 [==============================] - 0s 1ms/step - loss: 0.0115 - val_loss: 0.0137\n",
      "Epoch 65/90\n",
      "144/144 [==============================] - 0s 1ms/step - loss: 0.0114 - val_loss: 0.0140\n",
      "Epoch 66/90\n",
      "144/144 [==============================] - 0s 1ms/step - loss: 0.0115 - val_loss: 0.0136\n",
      "Epoch 67/90\n",
      "144/144 [==============================] - 0s 1ms/step - loss: 0.0116 - val_loss: 0.0141\n",
      "Epoch 68/90\n",
      "144/144 [==============================] - 0s 1ms/step - loss: 0.0114 - val_loss: 0.0138\n",
      "Epoch 69/90\n",
      "144/144 [==============================] - 0s 1ms/step - loss: 0.0114 - val_loss: 0.0138\n",
      "Epoch 70/90\n",
      "144/144 [==============================] - 0s 1ms/step - loss: 0.0116 - val_loss: 0.0139\n",
      "Epoch 71/90\n",
      "144/144 [==============================] - 0s 1ms/step - loss: 0.0113 - val_loss: 0.0134\n",
      "Epoch 72/90\n",
      "144/144 [==============================] - 0s 1ms/step - loss: 0.0115 - val_loss: 0.0134\n",
      "Epoch 73/90\n",
      "144/144 [==============================] - 0s 1ms/step - loss: 0.0112 - val_loss: 0.0129\n",
      "Epoch 74/90\n",
      "144/144 [==============================] - 0s 1ms/step - loss: 0.0114 - val_loss: 0.0139\n",
      "Epoch 75/90\n",
      "144/144 [==============================] - 0s 1ms/step - loss: 0.0116 - val_loss: 0.0135\n",
      "Epoch 76/90\n",
      "144/144 [==============================] - 0s 1ms/step - loss: 0.0114 - val_loss: 0.0143\n",
      "Epoch 77/90\n",
      "144/144 [==============================] - 0s 1ms/step - loss: 0.0116 - val_loss: 0.0138\n",
      "Epoch 78/90\n",
      "144/144 [==============================] - 0s 1ms/step - loss: 0.0116 - val_loss: 0.0144\n",
      "Epoch 79/90\n",
      "144/144 [==============================] - 0s 1ms/step - loss: 0.0115 - val_loss: 0.0142\n",
      "Epoch 80/90\n",
      "144/144 [==============================] - 0s 1ms/step - loss: 0.0116 - val_loss: 0.0139\n",
      "Epoch 81/90\n",
      "144/144 [==============================] - 0s 1ms/step - loss: 0.0116 - val_loss: 0.0131\n",
      "Epoch 82/90\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "144/144 [==============================] - 0s 1ms/step - loss: 0.0117 - val_loss: 0.0138\n",
      "Epoch 83/90\n",
      "144/144 [==============================] - 0s 1ms/step - loss: 0.0114 - val_loss: 0.0134\n",
      "Epoch 84/90\n",
      "144/144 [==============================] - 0s 1ms/step - loss: 0.0115 - val_loss: 0.0137\n",
      "Epoch 85/90\n",
      "144/144 [==============================] - 0s 1ms/step - loss: 0.0115 - val_loss: 0.0138\n",
      "Epoch 86/90\n",
      "144/144 [==============================] - 0s 1ms/step - loss: 0.0116 - val_loss: 0.0141\n",
      "Epoch 87/90\n",
      "144/144 [==============================] - 0s 1ms/step - loss: 0.0115 - val_loss: 0.0140\n",
      "Epoch 88/90\n",
      "144/144 [==============================] - 0s 1ms/step - loss: 0.0115 - val_loss: 0.0144\n",
      "Epoch 89/90\n",
      "144/144 [==============================] - 0s 1ms/step - loss: 0.0116 - val_loss: 0.0132\n",
      "Epoch 90/90\n",
      "144/144 [==============================] - 0s 1ms/step - loss: 0.0116 - val_loss: 0.0146\n",
      "Execution time:  19.506383895874023\n",
      "DNN:\n",
      "Mean Absolute Error: 0.0072\n",
      "Root Mean Square Error: 0.0150\n",
      "Mean Square Error: 0.0002\n",
      "\n",
      "Train RMSE: 0.015\n",
      "Train MSE: 0.000\n",
      "Train MAE: 0.007\n",
      "###########################\n",
      "\n",
      "MODEL:  DNN\n",
      "sequence:  1h\n",
      "units:  12\n",
      "dropout1:  0.48476373451509647\n",
      "optimizer: adamax\n",
      "activationDense: tanh\n",
      "epochs: 52\n",
      "batchsize: 57\n",
      "validation_split: 0.1\n",
      "Model: \"sequential_26\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_78 (Dense)             (None, 6, 12)             24        \n",
      "_________________________________________________________________\n",
      "dense_79 (Dense)             (None, 6, 16)             208       \n",
      "_________________________________________________________________\n",
      "dropout_26 (Dropout)         (None, 6, 16)             0         \n",
      "_________________________________________________________________\n",
      "dense_80 (Dense)             (None, 6, 1)              17        \n",
      "=================================================================\n",
      "Total params: 249\n",
      "Trainable params: 249\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/52\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.1391 - val_loss: 0.0224\n",
      "Epoch 2/52\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.1111 - val_loss: 0.0217\n",
      "Epoch 3/52\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0985 - val_loss: 0.0211\n",
      "Epoch 4/52\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0887 - val_loss: 0.0191\n",
      "Epoch 5/52\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0821 - val_loss: 0.0150\n",
      "Epoch 6/52\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0758 - val_loss: 0.0179\n",
      "Epoch 7/52\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0706 - val_loss: 0.0179\n",
      "Epoch 8/52\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0654 - val_loss: 0.0150\n",
      "Epoch 9/52\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0609 - val_loss: 0.0135\n",
      "Epoch 10/52\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0559 - val_loss: 0.0117\n",
      "Epoch 11/52\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0503 - val_loss: 0.0084\n",
      "Epoch 12/52\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0456 - val_loss: 0.0057\n",
      "Epoch 13/52\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0402 - val_loss: 0.0039\n",
      "Epoch 14/52\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0359 - val_loss: 0.0048\n",
      "Epoch 15/52\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0321 - val_loss: 0.0049\n",
      "Epoch 16/52\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0289 - val_loss: 0.0059\n",
      "Epoch 17/52\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0264 - val_loss: 0.0061\n",
      "Epoch 18/52\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0238 - val_loss: 0.0058\n",
      "Epoch 19/52\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0222 - val_loss: 0.0064\n",
      "Epoch 20/52\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0207 - val_loss: 0.0072\n",
      "Epoch 21/52\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0198 - val_loss: 0.0081\n",
      "Epoch 22/52\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0190 - val_loss: 0.0092\n",
      "Epoch 23/52\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0183 - val_loss: 0.0098\n",
      "Epoch 24/52\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0182 - val_loss: 0.0101\n",
      "Epoch 25/52\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0177 - val_loss: 0.0101\n",
      "Epoch 26/52\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0173 - val_loss: 0.0099\n",
      "Epoch 27/52\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0171 - val_loss: 0.0099\n",
      "Epoch 28/52\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0170 - val_loss: 0.0100\n",
      "Epoch 29/52\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0164 - val_loss: 0.0101\n",
      "Epoch 30/52\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0161 - val_loss: 0.0102\n",
      "Epoch 31/52\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0161 - val_loss: 0.0099\n",
      "Epoch 32/52\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0155 - val_loss: 0.0102\n",
      "Epoch 33/52\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0155 - val_loss: 0.0102\n",
      "Epoch 34/52\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0155 - val_loss: 0.0101\n",
      "Epoch 35/52\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0150 - val_loss: 0.0104\n",
      "Epoch 36/52\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0150 - val_loss: 0.0100\n",
      "Epoch 37/52\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0147 - val_loss: 0.0110\n",
      "Epoch 38/52\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0145 - val_loss: 0.0104\n",
      "Epoch 39/52\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0144 - val_loss: 0.0110\n",
      "Epoch 40/52\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0144 - val_loss: 0.0103\n",
      "Epoch 41/52\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0142 - val_loss: 0.0116\n",
      "Epoch 42/52\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0143 - val_loss: 0.0103\n",
      "Epoch 43/52\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0141 - val_loss: 0.0118\n",
      "Epoch 44/52\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0141 - val_loss: 0.0108\n",
      "Epoch 45/52\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0141 - val_loss: 0.0109\n",
      "Epoch 46/52\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0140 - val_loss: 0.0114\n",
      "Epoch 47/52\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0140 - val_loss: 0.0107\n",
      "Epoch 48/52\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0138 - val_loss: 0.0115\n",
      "Epoch 49/52\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0141 - val_loss: 0.0108\n",
      "Epoch 50/52\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0138 - val_loss: 0.0115\n",
      "Epoch 51/52\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0141 - val_loss: 0.0109\n",
      "Epoch 52/52\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0138 - val_loss: 0.0114\n",
      "Execution time:  6.807473659515381\n",
      "DNN:\n",
      "Mean Absolute Error: 0.0080\n",
      "Root Mean Square Error: 0.0137\n",
      "Mean Square Error: 0.0002\n",
      "\n",
      "Train RMSE: 0.014\n",
      "Train MSE: 0.000\n",
      "Train MAE: 0.008\n",
      "###########################\n",
      "\n",
      "MODEL:  DNN\n",
      "sequence:  1h\n",
      "units:  87\n",
      "dropout1:  0.40519643149940265\n",
      "optimizer: adamax\n",
      "activationDense: tanh\n",
      "epochs: 80\n",
      "batchsize: 31\n",
      "validation_split: 0.2\n",
      "Model: \"sequential_27\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_81 (Dense)             (None, 6, 87)             174       \n",
      "_________________________________________________________________\n",
      "dense_82 (Dense)             (None, 6, 16)             1408      \n",
      "_________________________________________________________________\n",
      "dropout_27 (Dropout)         (None, 6, 16)             0         \n",
      "_________________________________________________________________\n",
      "dense_83 (Dense)             (None, 6, 1)              17        \n",
      "=================================================================\n",
      "Total params: 1,599\n",
      "Trainable params: 1,599\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/80\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "103/103 [==============================] - 0s 4ms/step - loss: 0.2657 - val_loss: 0.0575\n",
      "Epoch 2/80\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.1043 - val_loss: 0.0383\n",
      "Epoch 3/80\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.0863 - val_loss: 0.0345\n",
      "Epoch 4/80\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.0776 - val_loss: 0.0312\n",
      "Epoch 5/80\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.0668 - val_loss: 0.0251\n",
      "Epoch 6/80\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.0582 - val_loss: 0.0244\n",
      "Epoch 7/80\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.0515 - val_loss: 0.0180\n",
      "Epoch 8/80\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.0449 - val_loss: 0.0155\n",
      "Epoch 9/80\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.0399 - val_loss: 0.0143\n",
      "Epoch 10/80\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.0351 - val_loss: 0.0139\n",
      "Epoch 11/80\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.0317 - val_loss: 0.0149\n",
      "Epoch 12/80\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.0303 - val_loss: 0.0146\n",
      "Epoch 13/80\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.0296 - val_loss: 0.0155\n",
      "Epoch 14/80\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.0293 - val_loss: 0.0161\n",
      "Epoch 15/80\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.0287 - val_loss: 0.0162\n",
      "Epoch 16/80\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.0287 - val_loss: 0.0159\n",
      "Epoch 17/80\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.0286 - val_loss: 0.0158\n",
      "Epoch 18/80\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.0286 - val_loss: 0.0158\n",
      "Epoch 19/80\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.0290 - val_loss: 0.0162\n",
      "Epoch 20/80\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.0279 - val_loss: 0.0154\n",
      "Epoch 21/80\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.0270 - val_loss: 0.0148\n",
      "Epoch 22/80\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.0278 - val_loss: 0.0152\n",
      "Epoch 23/80\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.0259 - val_loss: 0.0148\n",
      "Epoch 24/80\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.0270 - val_loss: 0.0143\n",
      "Epoch 25/80\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.0243 - val_loss: 0.0146\n",
      "Epoch 26/80\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.0255 - val_loss: 0.0144\n",
      "Epoch 27/80\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.0232 - val_loss: 0.0145\n",
      "Epoch 28/80\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.0240 - val_loss: 0.0141\n",
      "Epoch 29/80\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.0221 - val_loss: 0.0142\n",
      "Epoch 30/80\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.0224 - val_loss: 0.0140\n",
      "Epoch 31/80\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.0221 - val_loss: 0.0139\n",
      "Epoch 32/80\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.0211 - val_loss: 0.0139\n",
      "Epoch 33/80\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.0200 - val_loss: 0.0139\n",
      "Epoch 34/80\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.0192 - val_loss: 0.0136\n",
      "Epoch 35/80\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.0182 - val_loss: 0.0134\n",
      "Epoch 36/80\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.0180 - val_loss: 0.0131\n",
      "Epoch 37/80\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.0173 - val_loss: 0.0128\n",
      "Epoch 38/80\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.0169 - val_loss: 0.0124\n",
      "Epoch 39/80\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.0162 - val_loss: 0.0120\n",
      "Epoch 40/80\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.0161 - val_loss: 0.0112\n",
      "Epoch 41/80\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.0156 - val_loss: 0.0118\n",
      "Epoch 42/80\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.0157 - val_loss: 0.0101\n",
      "Epoch 43/80\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.0153 - val_loss: 0.0110\n",
      "Epoch 44/80\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.0154 - val_loss: 0.0103\n",
      "Epoch 45/80\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.0154 - val_loss: 0.0104\n",
      "Epoch 46/80\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.0154 - val_loss: 0.0105\n",
      "Epoch 47/80\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.0154 - val_loss: 0.0108\n",
      "Epoch 48/80\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.0153 - val_loss: 0.0104\n",
      "Epoch 49/80\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.0154 - val_loss: 0.0096\n",
      "Epoch 50/80\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.0151 - val_loss: 0.0109\n",
      "Epoch 51/80\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.0154 - val_loss: 0.0098\n",
      "Epoch 52/80\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.0153 - val_loss: 0.0104\n",
      "Epoch 53/80\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.0152 - val_loss: 0.0097\n",
      "Epoch 54/80\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.0150 - val_loss: 0.0110\n",
      "Epoch 55/80\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.0150 - val_loss: 0.0094\n",
      "Epoch 56/80\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.0151 - val_loss: 0.0113\n",
      "Epoch 57/80\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.0153 - val_loss: 0.0104\n",
      "Epoch 58/80\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.0153 - val_loss: 0.0098\n",
      "Epoch 59/80\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.0153 - val_loss: 0.0111\n",
      "Epoch 60/80\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.0154 - val_loss: 0.0097\n",
      "Epoch 61/80\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.0151 - val_loss: 0.0100\n",
      "Epoch 62/80\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.0151 - val_loss: 0.0104\n",
      "Epoch 63/80\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.0151 - val_loss: 0.0114\n",
      "Epoch 64/80\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.0152 - val_loss: 0.0095\n",
      "Epoch 65/80\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.0151 - val_loss: 0.0105\n",
      "Epoch 66/80\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.0152 - val_loss: 0.0108\n",
      "Epoch 67/80\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.0156 - val_loss: 0.0100\n",
      "Epoch 68/80\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.0151 - val_loss: 0.0111\n",
      "Epoch 69/80\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.0152 - val_loss: 0.0103\n",
      "Epoch 70/80\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.0153 - val_loss: 0.0104\n",
      "Epoch 71/80\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.0152 - val_loss: 0.0107\n",
      "Epoch 72/80\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.0154 - val_loss: 0.0100\n",
      "Epoch 73/80\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.0153 - val_loss: 0.0107\n",
      "Epoch 74/80\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.0155 - val_loss: 0.0102\n",
      "Epoch 75/80\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.0154 - val_loss: 0.0103\n",
      "Epoch 76/80\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.0151 - val_loss: 0.0101\n",
      "Epoch 77/80\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.0151 - val_loss: 0.0114\n",
      "Epoch 78/80\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.0152 - val_loss: 0.0103\n",
      "Epoch 79/80\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.0151 - val_loss: 0.0108\n",
      "Epoch 80/80\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.0154 - val_loss: 0.0099\n",
      "Execution time:  15.186566591262817\n",
      "DNN:\n",
      "Mean Absolute Error: 0.0098\n",
      "Root Mean Square Error: 0.0176\n",
      "Mean Square Error: 0.0003\n",
      "\n",
      "Train RMSE: 0.018\n",
      "Train MSE: 0.000\n",
      "Train MAE: 0.010\n",
      "###########################\n",
      "\n",
      "MODEL:  DNN\n",
      "sequence:  1h\n",
      "units:  80\n",
      "dropout1:  0.11814836227952394\n",
      "optimizer: adamax\n",
      "activationDense: tanh\n",
      "epochs: 90\n",
      "batchsize: 25\n",
      "validation_split: 0.2\n",
      "Model: \"sequential_28\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_84 (Dense)             (None, 6, 80)             160       \n",
      "_________________________________________________________________\n",
      "dense_85 (Dense)             (None, 6, 16)             1296      \n",
      "_________________________________________________________________\n",
      "dropout_28 (Dropout)         (None, 6, 16)             0         \n",
      "_________________________________________________________________\n",
      "dense_86 (Dense)             (None, 6, 1)              17        \n",
      "=================================================================\n",
      "Total params: 1,473\n",
      "Trainable params: 1,473\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/90\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "128/128 [==============================] - 0s 3ms/step - loss: 0.0727 - val_loss: 0.0244\n",
      "Epoch 2/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0415 - val_loss: 0.0218\n",
      "Epoch 3/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0400 - val_loss: 0.0139\n",
      "Epoch 4/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0381 - val_loss: 0.0146\n",
      "Epoch 5/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0369 - val_loss: 0.0107\n",
      "Epoch 6/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0355 - val_loss: 0.0093\n",
      "Epoch 7/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0345 - val_loss: 0.0098\n",
      "Epoch 8/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0336 - val_loss: 0.0095\n",
      "Epoch 9/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0326 - val_loss: 0.0092\n",
      "Epoch 10/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0320 - val_loss: 0.0096\n",
      "Epoch 11/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0310 - val_loss: 0.0097\n",
      "Epoch 12/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0305 - val_loss: 0.0121\n",
      "Epoch 13/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0293 - val_loss: 0.0133\n",
      "Epoch 14/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0287 - val_loss: 0.0113\n",
      "Epoch 15/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0279 - val_loss: 0.0124\n",
      "Epoch 16/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0270 - val_loss: 0.0096\n",
      "Epoch 17/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0263 - val_loss: 0.0133\n",
      "Epoch 18/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0259 - val_loss: 0.0091\n",
      "Epoch 19/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0250 - val_loss: 0.0084\n",
      "Epoch 20/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0243 - val_loss: 0.0127\n",
      "Epoch 21/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0239 - val_loss: 0.0080\n",
      "Epoch 22/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0230 - val_loss: 0.0089\n",
      "Epoch 23/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0224 - val_loss: 0.0093\n",
      "Epoch 24/90\n",
      "128/128 [==============================] - 0s 1ms/step - loss: 0.0215 - val_loss: 0.0078\n",
      "Epoch 25/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0203 - val_loss: 0.0077\n",
      "Epoch 26/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0197 - val_loss: 0.0086\n",
      "Epoch 27/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0195 - val_loss: 0.0078\n",
      "Epoch 28/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0181 - val_loss: 0.0081\n",
      "Epoch 29/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0177 - val_loss: 0.0076\n",
      "Epoch 30/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0171 - val_loss: 0.0076\n",
      "Epoch 31/90\n",
      "128/128 [==============================] - 0s 1ms/step - loss: 0.0166 - val_loss: 0.0071\n",
      "Epoch 32/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0160 - val_loss: 0.0071\n",
      "Epoch 33/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0155 - val_loss: 0.0068\n",
      "Epoch 34/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0150 - val_loss: 0.0069\n",
      "Epoch 35/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0143 - val_loss: 0.0065\n",
      "Epoch 36/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0137 - val_loss: 0.0066\n",
      "Epoch 37/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0136 - val_loss: 0.0063\n",
      "Epoch 38/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0129 - val_loss: 0.0062\n",
      "Epoch 39/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0126 - val_loss: 0.0063\n",
      "Epoch 40/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0124 - val_loss: 0.0068\n",
      "Epoch 41/90\n",
      "128/128 [==============================] - 0s 1ms/step - loss: 0.0124 - val_loss: 0.0070\n",
      "Epoch 42/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0123 - val_loss: 0.0074\n",
      "Epoch 43/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0121 - val_loss: 0.0075\n",
      "Epoch 44/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0120 - val_loss: 0.0079\n",
      "Epoch 45/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0120 - val_loss: 0.0081\n",
      "Epoch 46/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0122 - val_loss: 0.0084\n",
      "Epoch 47/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0120 - val_loss: 0.0078\n",
      "Epoch 48/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0117 - val_loss: 0.0080\n",
      "Epoch 49/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0120 - val_loss: 0.0090\n",
      "Epoch 50/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0124 - val_loss: 0.0101\n",
      "Epoch 51/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0121 - val_loss: 0.0094\n",
      "Epoch 52/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0119 - val_loss: 0.0094\n",
      "Epoch 53/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0122 - val_loss: 0.0106\n",
      "Epoch 54/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0121 - val_loss: 0.0098\n",
      "Epoch 55/90\n",
      "128/128 [==============================] - 0s 1ms/step - loss: 0.0121 - val_loss: 0.0103\n",
      "Epoch 56/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0120 - val_loss: 0.0100\n",
      "Epoch 57/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0119 - val_loss: 0.0097\n",
      "Epoch 58/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0118 - val_loss: 0.0098\n",
      "Epoch 59/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0117 - val_loss: 0.0093\n",
      "Epoch 60/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0115 - val_loss: 0.0097\n",
      "Epoch 61/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0119 - val_loss: 0.0100\n",
      "Epoch 62/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0119 - val_loss: 0.0096\n",
      "Epoch 63/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0117 - val_loss: 0.0100\n",
      "Epoch 64/90\n",
      "128/128 [==============================] - 0s 1ms/step - loss: 0.0118 - val_loss: 0.0092\n",
      "Epoch 65/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0113 - val_loss: 0.0095\n",
      "Epoch 66/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0117 - val_loss: 0.0097\n",
      "Epoch 67/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0120 - val_loss: 0.0107\n",
      "Epoch 68/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0120 - val_loss: 0.0098\n",
      "Epoch 69/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0114 - val_loss: 0.0097\n",
      "Epoch 70/90\n",
      "128/128 [==============================] - 0s 1ms/step - loss: 0.0117 - val_loss: 0.0094\n",
      "Epoch 71/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0115 - val_loss: 0.0095\n",
      "Epoch 72/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0121 - val_loss: 0.0104\n",
      "Epoch 73/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0118 - val_loss: 0.0095\n",
      "Epoch 74/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0117 - val_loss: 0.0103\n",
      "Epoch 75/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0118 - val_loss: 0.0095\n",
      "Epoch 76/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0118 - val_loss: 0.0099\n",
      "Epoch 77/90\n",
      "128/128 [==============================] - 0s 1ms/step - loss: 0.0120 - val_loss: 0.0102\n",
      "Epoch 78/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0119 - val_loss: 0.0094\n",
      "Epoch 79/90\n",
      "128/128 [==============================] - 0s 1ms/step - loss: 0.0115 - val_loss: 0.0095\n",
      "Epoch 80/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0120 - val_loss: 0.0097\n",
      "Epoch 81/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0117 - val_loss: 0.0098\n",
      "Epoch 82/90\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0117 - val_loss: 0.0090\n",
      "Epoch 83/90\n",
      "128/128 [==============================] - 0s 1ms/step - loss: 0.0115 - val_loss: 0.0097\n",
      "Epoch 84/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0119 - val_loss: 0.0096\n",
      "Epoch 85/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0116 - val_loss: 0.0098\n",
      "Epoch 86/90\n",
      "128/128 [==============================] - 0s 1ms/step - loss: 0.0115 - val_loss: 0.0095\n",
      "Epoch 87/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0115 - val_loss: 0.0097\n",
      "Epoch 88/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0116 - val_loss: 0.0098\n",
      "Epoch 89/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0114 - val_loss: 0.0092\n",
      "Epoch 90/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0116 - val_loss: 0.0096\n",
      "Execution time:  19.297134399414062\n",
      "DNN:\n",
      "Mean Absolute Error: 0.0092\n",
      "Root Mean Square Error: 0.0147\n",
      "Mean Square Error: 0.0002\n",
      "\n",
      "Train RMSE: 0.015\n",
      "Train MSE: 0.000\n",
      "Train MAE: 0.009\n",
      "###########################\n",
      "\n",
      "MODEL:  DNN\n",
      "sequence:  1h\n",
      "units:  12\n",
      "dropout1:  0.48476373451509647\n",
      "optimizer: adamax\n",
      "activationDense: tanh\n",
      "epochs: 52\n",
      "batchsize: 57\n",
      "validation_split: 0.2\n",
      "Model: \"sequential_29\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_87 (Dense)             (None, 6, 12)             24        \n",
      "_________________________________________________________________\n",
      "dense_88 (Dense)             (None, 6, 16)             208       \n",
      "_________________________________________________________________\n",
      "dropout_29 (Dropout)         (None, 6, 16)             0         \n",
      "_________________________________________________________________\n",
      "dense_89 (Dense)             (None, 6, 1)              17        \n",
      "=================================================================\n",
      "Total params: 249\n",
      "Trainable params: 249\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/52\n",
      "56/56 [==============================] - 0s 8ms/step - loss: 0.3054 - val_loss: 0.1414\n",
      "Epoch 2/52\n",
      "56/56 [==============================] - 0s 2ms/step - loss: 0.1549 - val_loss: 0.0785\n",
      "Epoch 3/52\n",
      "56/56 [==============================] - 0s 2ms/step - loss: 0.1389 - val_loss: 0.0396\n",
      "Epoch 4/52\n",
      "56/56 [==============================] - 0s 2ms/step - loss: 0.1230 - val_loss: 0.0123\n",
      "Epoch 5/52\n",
      "56/56 [==============================] - 0s 2ms/step - loss: 0.1131 - val_loss: 0.0140\n",
      "Epoch 6/52\n",
      "56/56 [==============================] - 0s 2ms/step - loss: 0.1034 - val_loss: 0.0142\n",
      "Epoch 7/52\n",
      "56/56 [==============================] - 0s 2ms/step - loss: 0.0939 - val_loss: 0.0144\n",
      "Epoch 8/52\n",
      "56/56 [==============================] - 0s 2ms/step - loss: 0.0844 - val_loss: 0.0144\n",
      "Epoch 9/52\n",
      "56/56 [==============================] - 0s 2ms/step - loss: 0.0733 - val_loss: 0.0146\n",
      "Epoch 10/52\n",
      "56/56 [==============================] - 0s 2ms/step - loss: 0.0631 - val_loss: 0.0144\n",
      "Epoch 11/52\n",
      "56/56 [==============================] - 0s 2ms/step - loss: 0.0531 - val_loss: 0.0140\n",
      "Epoch 12/52\n",
      "56/56 [==============================] - 0s 2ms/step - loss: 0.0446 - val_loss: 0.0143\n",
      "Epoch 13/52\n",
      "56/56 [==============================] - 0s 2ms/step - loss: 0.0392 - val_loss: 0.0145\n",
      "Epoch 14/52\n",
      "56/56 [==============================] - 0s 2ms/step - loss: 0.0351 - val_loss: 0.0146\n",
      "Epoch 15/52\n",
      "56/56 [==============================] - 0s 2ms/step - loss: 0.0317 - val_loss: 0.0158\n",
      "Epoch 16/52\n",
      "56/56 [==============================] - 0s 2ms/step - loss: 0.0292 - val_loss: 0.0159\n",
      "Epoch 17/52\n",
      "56/56 [==============================] - 0s 2ms/step - loss: 0.0277 - val_loss: 0.0155\n",
      "Epoch 18/52\n",
      "56/56 [==============================] - 0s 2ms/step - loss: 0.0278 - val_loss: 0.0161\n",
      "Epoch 19/52\n",
      "56/56 [==============================] - 0s 2ms/step - loss: 0.0275 - val_loss: 0.0161\n",
      "Epoch 20/52\n",
      "56/56 [==============================] - 0s 2ms/step - loss: 0.0276 - val_loss: 0.0163\n",
      "Epoch 21/52\n",
      "56/56 [==============================] - 0s 2ms/step - loss: 0.0274 - val_loss: 0.0164\n",
      "Epoch 22/52\n",
      "56/56 [==============================] - 0s 2ms/step - loss: 0.0273 - val_loss: 0.0167\n",
      "Epoch 23/52\n",
      "56/56 [==============================] - 0s 2ms/step - loss: 0.0270 - val_loss: 0.0168\n",
      "Epoch 24/52\n",
      "56/56 [==============================] - 0s 2ms/step - loss: 0.0270 - val_loss: 0.0170\n",
      "Epoch 25/52\n",
      "56/56 [==============================] - 0s 2ms/step - loss: 0.0268 - val_loss: 0.0170\n",
      "Epoch 26/52\n",
      "56/56 [==============================] - 0s 2ms/step - loss: 0.0267 - val_loss: 0.0169\n",
      "Epoch 27/52\n",
      "56/56 [==============================] - 0s 2ms/step - loss: 0.0266 - val_loss: 0.0165\n",
      "Epoch 28/52\n",
      "56/56 [==============================] - 0s 2ms/step - loss: 0.0265 - val_loss: 0.0161\n",
      "Epoch 29/52\n",
      "56/56 [==============================] - 0s 2ms/step - loss: 0.0265 - val_loss: 0.0160\n",
      "Epoch 30/52\n",
      "56/56 [==============================] - 0s 2ms/step - loss: 0.0263 - val_loss: 0.0159\n",
      "Epoch 31/52\n",
      "56/56 [==============================] - 0s 2ms/step - loss: 0.0262 - val_loss: 0.0159\n",
      "Epoch 32/52\n",
      "56/56 [==============================] - 0s 2ms/step - loss: 0.0260 - val_loss: 0.0158\n",
      "Epoch 33/52\n",
      "56/56 [==============================] - 0s 2ms/step - loss: 0.0260 - val_loss: 0.0157\n",
      "Epoch 34/52\n",
      "56/56 [==============================] - 0s 2ms/step - loss: 0.0257 - val_loss: 0.0158\n",
      "Epoch 35/52\n",
      "56/56 [==============================] - 0s 2ms/step - loss: 0.0256 - val_loss: 0.0156\n",
      "Epoch 36/52\n",
      "56/56 [==============================] - 0s 2ms/step - loss: 0.0256 - val_loss: 0.0155\n",
      "Epoch 37/52\n",
      "56/56 [==============================] - 0s 2ms/step - loss: 0.0253 - val_loss: 0.0153\n",
      "Epoch 38/52\n",
      "56/56 [==============================] - 0s 2ms/step - loss: 0.0255 - val_loss: 0.0152\n",
      "Epoch 39/52\n",
      "56/56 [==============================] - 0s 2ms/step - loss: 0.0251 - val_loss: 0.0153\n",
      "Epoch 40/52\n",
      "56/56 [==============================] - 0s 2ms/step - loss: 0.0251 - val_loss: 0.0152\n",
      "Epoch 41/52\n",
      "56/56 [==============================] - 0s 2ms/step - loss: 0.0248 - val_loss: 0.0151\n",
      "Epoch 42/52\n",
      "56/56 [==============================] - 0s 2ms/step - loss: 0.0248 - val_loss: 0.0148\n",
      "Epoch 43/52\n",
      "56/56 [==============================] - 0s 2ms/step - loss: 0.0245 - val_loss: 0.0146\n",
      "Epoch 44/52\n",
      "56/56 [==============================] - 0s 2ms/step - loss: 0.0243 - val_loss: 0.0144\n",
      "Epoch 45/52\n",
      "56/56 [==============================] - 0s 2ms/step - loss: 0.0243 - val_loss: 0.0143\n",
      "Epoch 46/52\n",
      "56/56 [==============================] - 0s 2ms/step - loss: 0.0241 - val_loss: 0.0142\n",
      "Epoch 47/52\n",
      "56/56 [==============================] - 0s 2ms/step - loss: 0.0237 - val_loss: 0.0141\n",
      "Epoch 48/52\n",
      "56/56 [==============================] - 0s 2ms/step - loss: 0.0238 - val_loss: 0.0142\n",
      "Epoch 49/52\n",
      "56/56 [==============================] - 0s 2ms/step - loss: 0.0233 - val_loss: 0.0135\n",
      "Epoch 50/52\n",
      "56/56 [==============================] - 0s 2ms/step - loss: 0.0232 - val_loss: 0.0141\n",
      "Epoch 51/52\n",
      "56/56 [==============================] - 0s 2ms/step - loss: 0.0225 - val_loss: 0.0136\n",
      "Epoch 52/52\n",
      "56/56 [==============================] - 0s 2ms/step - loss: 0.0226 - val_loss: 0.0138\n",
      "Execution time:  6.577101230621338\n",
      "DNN:\n",
      "Mean Absolute Error: 0.0197\n",
      "Root Mean Square Error: 0.0324\n",
      "Mean Square Error: 0.0011\n",
      "\n",
      "Train RMSE: 0.032\n",
      "Train MSE: 0.001\n",
      "Train MAE: 0.020\n",
      "###########################\n",
      "\n",
      "MODEL:  DNN\n",
      "sequence:  1h\n",
      "units:  87\n",
      "dropout1:  0.40519643149940265\n",
      "optimizer: adamax\n",
      "activationDense: sigmoid\n",
      "epochs: 80\n",
      "batchsize: 31\n",
      "validation_split: 0.1\n",
      "Model: \"sequential_30\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_90 (Dense)             (None, 6, 87)             174       \n",
      "_________________________________________________________________\n",
      "dense_91 (Dense)             (None, 6, 16)             1408      \n",
      "_________________________________________________________________\n",
      "dropout_30 (Dropout)         (None, 6, 16)             0         \n",
      "_________________________________________________________________\n",
      "dense_92 (Dense)             (None, 6, 1)              17        \n",
      "=================================================================\n",
      "Total params: 1,599\n",
      "Trainable params: 1,599\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/80\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "116/116 [==============================] - 0s 3ms/step - loss: 0.0486 - val_loss: 0.0366\n",
      "Epoch 2/80\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.0428 - val_loss: 0.0333\n",
      "Epoch 3/80\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.0416 - val_loss: 0.0319\n",
      "Epoch 4/80\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.0399 - val_loss: 0.0297\n",
      "Epoch 5/80\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.0389 - val_loss: 0.0293\n",
      "Epoch 6/80\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.0375 - val_loss: 0.0276\n",
      "Epoch 7/80\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.0364 - val_loss: 0.0246\n",
      "Epoch 8/80\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 0.0357 - val_loss: 0.0234\n",
      "Epoch 9/80\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 0.0347 - val_loss: 0.0231\n",
      "Epoch 10/80\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.0339 - val_loss: 0.0216\n",
      "Epoch 11/80\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.0330 - val_loss: 0.0212\n",
      "Epoch 12/80\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.0325 - val_loss: 0.0209\n",
      "Epoch 13/80\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.0317 - val_loss: 0.0199\n",
      "Epoch 14/80\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.0312 - val_loss: 0.0192\n",
      "Epoch 15/80\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 0.0305 - val_loss: 0.0184\n",
      "Epoch 16/80\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.0303 - val_loss: 0.0175\n",
      "Epoch 17/80\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 0.0297 - val_loss: 0.0172\n",
      "Epoch 18/80\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 0.0293 - val_loss: 0.0177\n",
      "Epoch 19/80\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 0.0292 - val_loss: 0.0169\n",
      "Epoch 20/80\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.0283 - val_loss: 0.0163\n",
      "Epoch 21/80\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 0.0280 - val_loss: 0.0158\n",
      "Epoch 22/80\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.0277 - val_loss: 0.0155\n",
      "Epoch 23/80\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 0.0275 - val_loss: 0.0149\n",
      "Epoch 24/80\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.0273 - val_loss: 0.0145\n",
      "Epoch 25/80\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 0.0271 - val_loss: 0.0142\n",
      "Epoch 26/80\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.0269 - val_loss: 0.0144\n",
      "Epoch 27/80\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.0266 - val_loss: 0.0138\n",
      "Epoch 28/80\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.0264 - val_loss: 0.0136\n",
      "Epoch 29/80\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.0262 - val_loss: 0.0130\n",
      "Epoch 30/80\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.0260 - val_loss: 0.0131\n",
      "Epoch 31/80\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.0260 - val_loss: 0.0128\n",
      "Epoch 32/80\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.0258 - val_loss: 0.0127\n",
      "Epoch 33/80\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.0260 - val_loss: 0.0114\n",
      "Epoch 34/80\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.0256 - val_loss: 0.0118\n",
      "Epoch 35/80\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 0.0254 - val_loss: 0.0121\n",
      "Epoch 36/80\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 0.0251 - val_loss: 0.0119\n",
      "Epoch 37/80\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.0247 - val_loss: 0.0121\n",
      "Epoch 38/80\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.0244 - val_loss: 0.0121\n",
      "Epoch 39/80\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.0240 - val_loss: 0.0120\n",
      "Epoch 40/80\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 0.0237 - val_loss: 0.0122\n",
      "Epoch 41/80\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 0.0230 - val_loss: 0.0123\n",
      "Epoch 42/80\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.0226 - val_loss: 0.0121\n",
      "Epoch 43/80\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 0.0223 - val_loss: 0.0122\n",
      "Epoch 44/80\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 0.0219 - val_loss: 0.0125\n",
      "Epoch 45/80\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.0214 - val_loss: 0.0124\n",
      "Epoch 46/80\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 0.0209 - val_loss: 0.0130\n",
      "Epoch 47/80\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 0.0202 - val_loss: 0.0133\n",
      "Epoch 48/80\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.0199 - val_loss: 0.0129\n",
      "Epoch 49/80\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.0193 - val_loss: 0.0133\n",
      "Epoch 50/80\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 0.0190 - val_loss: 0.0138\n",
      "Epoch 51/80\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.0184 - val_loss: 0.0151\n",
      "Epoch 52/80\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.0181 - val_loss: 0.0150\n",
      "Epoch 53/80\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.0177 - val_loss: 0.0145\n",
      "Epoch 54/80\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.0172 - val_loss: 0.0141\n",
      "Epoch 55/80\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.0168 - val_loss: 0.0124\n",
      "Epoch 56/80\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 0.0165 - val_loss: 0.0117\n",
      "Epoch 57/80\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 0.0163 - val_loss: 0.0105\n",
      "Epoch 58/80\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 0.0161 - val_loss: 0.0099\n",
      "Epoch 59/80\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.0162 - val_loss: 0.0090\n",
      "Epoch 60/80\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.0163 - val_loss: 0.0091\n",
      "Epoch 61/80\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 0.0159 - val_loss: 0.0081\n",
      "Epoch 62/80\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 0.0160 - val_loss: 0.0105\n",
      "Epoch 63/80\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 0.0160 - val_loss: 0.0097\n",
      "Epoch 64/80\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 0.0159 - val_loss: 0.0104\n",
      "Epoch 65/80\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.0158 - val_loss: 0.0096\n",
      "Epoch 66/80\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.0158 - val_loss: 0.0091\n",
      "Epoch 67/80\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 0.0156 - val_loss: 0.0095\n",
      "Epoch 68/80\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 0.0156 - val_loss: 0.0095\n",
      "Epoch 69/80\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.0157 - val_loss: 0.0097\n",
      "Epoch 70/80\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 0.0156 - val_loss: 0.0089\n",
      "Epoch 71/80\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.0156 - val_loss: 0.0089\n",
      "Epoch 72/80\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 0.0156 - val_loss: 0.0092\n",
      "Epoch 73/80\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.0156 - val_loss: 0.0098\n",
      "Epoch 74/80\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 0.0155 - val_loss: 0.0092\n",
      "Epoch 75/80\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.0154 - val_loss: 0.0092\n",
      "Epoch 76/80\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.0155 - val_loss: 0.0100\n",
      "Epoch 77/80\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.0155 - val_loss: 0.0093\n",
      "Epoch 78/80\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.0156 - val_loss: 0.0092\n",
      "Epoch 79/80\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 0.0155 - val_loss: 0.0085\n",
      "Epoch 80/80\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.0156 - val_loss: 0.0096\n",
      "Execution time:  15.967062711715698\n",
      "DNN:\n",
      "Mean Absolute Error: 0.0095\n",
      "Root Mean Square Error: 0.0194\n",
      "Mean Square Error: 0.0004\n",
      "\n",
      "Train RMSE: 0.019\n",
      "Train MSE: 0.000\n",
      "Train MAE: 0.010\n",
      "###########################\n",
      "\n",
      "MODEL:  DNN\n",
      "sequence:  1h\n",
      "units:  80\n",
      "dropout1:  0.11814836227952394\n",
      "optimizer: adamax\n",
      "activationDense: sigmoid\n",
      "epochs: 90\n",
      "batchsize: 25\n",
      "validation_split: 0.1\n",
      "Model: \"sequential_31\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_93 (Dense)             (None, 6, 80)             160       \n",
      "_________________________________________________________________\n",
      "dense_94 (Dense)             (None, 6, 16)             1296      \n",
      "_________________________________________________________________\n",
      "dropout_31 (Dropout)         (None, 6, 16)             0         \n",
      "_________________________________________________________________\n",
      "dense_95 (Dense)             (None, 6, 1)              17        \n",
      "=================================================================\n",
      "Total params: 1,473\n",
      "Trainable params: 1,473\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/90\n",
      "144/144 [==============================] - 0s 3ms/step - loss: 0.0409 - val_loss: 0.0259\n",
      "Epoch 2/90\n",
      "144/144 [==============================] - 0s 1ms/step - loss: 0.0363 - val_loss: 0.0242\n",
      "Epoch 3/90\n",
      "144/144 [==============================] - 0s 2ms/step - loss: 0.0356 - val_loss: 0.0247\n",
      "Epoch 4/90\n",
      "144/144 [==============================] - 0s 1ms/step - loss: 0.0353 - val_loss: 0.0245\n",
      "Epoch 5/90\n",
      "144/144 [==============================] - 0s 1ms/step - loss: 0.0349 - val_loss: 0.0221\n",
      "Epoch 6/90\n",
      "144/144 [==============================] - 0s 1ms/step - loss: 0.0342 - val_loss: 0.0225\n",
      "Epoch 7/90\n",
      "144/144 [==============================] - 0s 1ms/step - loss: 0.0337 - val_loss: 0.0223\n",
      "Epoch 8/90\n",
      "144/144 [==============================] - 0s 1ms/step - loss: 0.0334 - val_loss: 0.0220\n",
      "Epoch 9/90\n",
      "144/144 [==============================] - 0s 1ms/step - loss: 0.0330 - val_loss: 0.0218\n",
      "Epoch 10/90\n",
      "144/144 [==============================] - 0s 1ms/step - loss: 0.0326 - val_loss: 0.0197\n",
      "Epoch 11/90\n",
      "144/144 [==============================] - 0s 1ms/step - loss: 0.0324 - val_loss: 0.0192\n",
      "Epoch 12/90\n",
      "144/144 [==============================] - 0s 1ms/step - loss: 0.0318 - val_loss: 0.0205\n",
      "Epoch 13/90\n",
      "144/144 [==============================] - 0s 1ms/step - loss: 0.0314 - val_loss: 0.0189\n",
      "Epoch 14/90\n",
      "144/144 [==============================] - 0s 1ms/step - loss: 0.0306 - val_loss: 0.0191\n",
      "Epoch 15/90\n",
      "144/144 [==============================] - 0s 1ms/step - loss: 0.0306 - val_loss: 0.0191\n",
      "Epoch 16/90\n",
      "144/144 [==============================] - 0s 1ms/step - loss: 0.0300 - val_loss: 0.0185\n",
      "Epoch 17/90\n",
      "144/144 [==============================] - 0s 1ms/step - loss: 0.0299 - val_loss: 0.0172\n",
      "Epoch 18/90\n",
      "144/144 [==============================] - 0s 1ms/step - loss: 0.0296 - val_loss: 0.0169\n",
      "Epoch 19/90\n",
      "144/144 [==============================] - 0s 1ms/step - loss: 0.0290 - val_loss: 0.0174\n",
      "Epoch 20/90\n",
      "144/144 [==============================] - 0s 1ms/step - loss: 0.0288 - val_loss: 0.0160\n",
      "Epoch 21/90\n",
      "144/144 [==============================] - 0s 1ms/step - loss: 0.0285 - val_loss: 0.0162\n",
      "Epoch 22/90\n",
      "144/144 [==============================] - 0s 1ms/step - loss: 0.0279 - val_loss: 0.0169\n",
      "Epoch 23/90\n",
      "144/144 [==============================] - 0s 1ms/step - loss: 0.0275 - val_loss: 0.0166\n",
      "Epoch 24/90\n",
      "144/144 [==============================] - 0s 1ms/step - loss: 0.0273 - val_loss: 0.0157\n",
      "Epoch 25/90\n",
      "144/144 [==============================] - 0s 1ms/step - loss: 0.0269 - val_loss: 0.0166\n",
      "Epoch 26/90\n",
      "144/144 [==============================] - 0s 1ms/step - loss: 0.0265 - val_loss: 0.0159\n",
      "Epoch 27/90\n",
      "144/144 [==============================] - 0s 1ms/step - loss: 0.0259 - val_loss: 0.0162\n",
      "Epoch 28/90\n",
      "144/144 [==============================] - 0s 1ms/step - loss: 0.0255 - val_loss: 0.0160\n",
      "Epoch 29/90\n",
      "144/144 [==============================] - 0s 1ms/step - loss: 0.0248 - val_loss: 0.0160\n",
      "Epoch 30/90\n",
      "144/144 [==============================] - 0s 1ms/step - loss: 0.0244 - val_loss: 0.0155\n",
      "Epoch 31/90\n",
      "144/144 [==============================] - 0s 1ms/step - loss: 0.0239 - val_loss: 0.0163\n",
      "Epoch 32/90\n",
      "144/144 [==============================] - 0s 1ms/step - loss: 0.0233 - val_loss: 0.0154\n",
      "Epoch 33/90\n",
      "144/144 [==============================] - 0s 1ms/step - loss: 0.0226 - val_loss: 0.0164\n",
      "Epoch 34/90\n",
      "144/144 [==============================] - 0s 1ms/step - loss: 0.0220 - val_loss: 0.0163\n",
      "Epoch 35/90\n",
      "144/144 [==============================] - 0s 1ms/step - loss: 0.0215 - val_loss: 0.0163\n",
      "Epoch 36/90\n",
      "144/144 [==============================] - 0s 1ms/step - loss: 0.0208 - val_loss: 0.0163\n",
      "Epoch 37/90\n",
      "144/144 [==============================] - 0s 1ms/step - loss: 0.0204 - val_loss: 0.0167\n",
      "Epoch 38/90\n",
      "144/144 [==============================] - 0s 1ms/step - loss: 0.0199 - val_loss: 0.0163\n",
      "Epoch 39/90\n",
      "144/144 [==============================] - 0s 1ms/step - loss: 0.0194 - val_loss: 0.0162\n",
      "Epoch 40/90\n",
      "144/144 [==============================] - 0s 1ms/step - loss: 0.0187 - val_loss: 0.0174\n",
      "Epoch 41/90\n",
      "144/144 [==============================] - 0s 1ms/step - loss: 0.0181 - val_loss: 0.0182\n",
      "Epoch 42/90\n",
      "144/144 [==============================] - 0s 1ms/step - loss: 0.0174 - val_loss: 0.0173\n",
      "Epoch 43/90\n",
      "144/144 [==============================] - 0s 1ms/step - loss: 0.0167 - val_loss: 0.0129\n",
      "Epoch 44/90\n",
      "144/144 [==============================] - 0s 1ms/step - loss: 0.0163 - val_loss: 0.0126\n",
      "Epoch 45/90\n",
      "144/144 [==============================] - 0s 1ms/step - loss: 0.0159 - val_loss: 0.0103\n",
      "Epoch 46/90\n",
      "144/144 [==============================] - 0s 1ms/step - loss: 0.0155 - val_loss: 0.0094\n",
      "Epoch 47/90\n",
      "144/144 [==============================] - 0s 1ms/step - loss: 0.0152 - val_loss: 0.0090\n",
      "Epoch 48/90\n",
      "144/144 [==============================] - 0s 1ms/step - loss: 0.0151 - val_loss: 0.0087\n",
      "Epoch 49/90\n",
      "144/144 [==============================] - 0s 1ms/step - loss: 0.0148 - val_loss: 0.0093\n",
      "Epoch 50/90\n",
      "144/144 [==============================] - 0s 1ms/step - loss: 0.0145 - val_loss: 0.0072\n",
      "Epoch 51/90\n",
      "144/144 [==============================] - 0s 1ms/step - loss: 0.0144 - val_loss: 0.0074\n",
      "Epoch 52/90\n",
      "144/144 [==============================] - 0s 1ms/step - loss: 0.0141 - val_loss: 0.0067\n",
      "Epoch 53/90\n",
      "144/144 [==============================] - 0s 1ms/step - loss: 0.0142 - val_loss: 0.0079\n",
      "Epoch 54/90\n",
      "144/144 [==============================] - 0s 1ms/step - loss: 0.0141 - val_loss: 0.0068\n",
      "Epoch 55/90\n",
      "144/144 [==============================] - 0s 1ms/step - loss: 0.0141 - val_loss: 0.0079\n",
      "Epoch 56/90\n",
      "144/144 [==============================] - 0s 1ms/step - loss: 0.0141 - val_loss: 0.0063\n",
      "Epoch 57/90\n",
      "144/144 [==============================] - 0s 1ms/step - loss: 0.0141 - val_loss: 0.0069\n",
      "Epoch 58/90\n",
      "144/144 [==============================] - 0s 1ms/step - loss: 0.0139 - val_loss: 0.0081\n",
      "Epoch 59/90\n",
      "144/144 [==============================] - 0s 1ms/step - loss: 0.0140 - val_loss: 0.0076\n",
      "Epoch 60/90\n",
      "144/144 [==============================] - 0s 1ms/step - loss: 0.0140 - val_loss: 0.0073\n",
      "Epoch 61/90\n",
      "144/144 [==============================] - 0s 1ms/step - loss: 0.0141 - val_loss: 0.0063\n",
      "Epoch 62/90\n",
      "144/144 [==============================] - 0s 1ms/step - loss: 0.0141 - val_loss: 0.0078\n",
      "Epoch 63/90\n",
      "144/144 [==============================] - 0s 1ms/step - loss: 0.0139 - val_loss: 0.0076\n",
      "Epoch 64/90\n",
      "144/144 [==============================] - 0s 1ms/step - loss: 0.0139 - val_loss: 0.0090\n",
      "Epoch 65/90\n",
      "144/144 [==============================] - 0s 1ms/step - loss: 0.0140 - val_loss: 0.0071\n",
      "Epoch 66/90\n",
      "144/144 [==============================] - 0s 1ms/step - loss: 0.0141 - val_loss: 0.0080\n",
      "Epoch 67/90\n",
      "144/144 [==============================] - 0s 1ms/step - loss: 0.0139 - val_loss: 0.0076\n",
      "Epoch 68/90\n",
      "144/144 [==============================] - 0s 1ms/step - loss: 0.0139 - val_loss: 0.0075\n",
      "Epoch 69/90\n",
      "144/144 [==============================] - 0s 1ms/step - loss: 0.0140 - val_loss: 0.0077\n",
      "Epoch 70/90\n",
      "144/144 [==============================] - 0s 1ms/step - loss: 0.0139 - val_loss: 0.0081\n",
      "Epoch 71/90\n",
      "144/144 [==============================] - 0s 1ms/step - loss: 0.0140 - val_loss: 0.0074\n",
      "Epoch 72/90\n",
      "144/144 [==============================] - 0s 1ms/step - loss: 0.0140 - val_loss: 0.0076\n",
      "Epoch 73/90\n",
      "144/144 [==============================] - 0s 2ms/step - loss: 0.0139 - val_loss: 0.0073\n",
      "Epoch 74/90\n",
      "144/144 [==============================] - 0s 2ms/step - loss: 0.0139 - val_loss: 0.0085\n",
      "Epoch 75/90\n",
      "144/144 [==============================] - 0s 2ms/step - loss: 0.0140 - val_loss: 0.0073\n",
      "Epoch 76/90\n",
      "144/144 [==============================] - 0s 2ms/step - loss: 0.0139 - val_loss: 0.0081\n",
      "Epoch 77/90\n",
      "144/144 [==============================] - 0s 2ms/step - loss: 0.0139 - val_loss: 0.0075\n",
      "Epoch 78/90\n",
      "144/144 [==============================] - 0s 1ms/step - loss: 0.0140 - val_loss: 0.0074\n",
      "Epoch 79/90\n",
      "144/144 [==============================] - 0s 1ms/step - loss: 0.0140 - val_loss: 0.0079\n",
      "Epoch 80/90\n",
      "144/144 [==============================] - 0s 1ms/step - loss: 0.0141 - val_loss: 0.0065\n",
      "Epoch 81/90\n",
      "144/144 [==============================] - 0s 1ms/step - loss: 0.0140 - val_loss: 0.0076\n",
      "Epoch 82/90\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "144/144 [==============================] - 0s 1ms/step - loss: 0.0140 - val_loss: 0.0074\n",
      "Epoch 83/90\n",
      "144/144 [==============================] - 0s 1ms/step - loss: 0.0139 - val_loss: 0.0073\n",
      "Epoch 84/90\n",
      "144/144 [==============================] - 0s 1ms/step - loss: 0.0140 - val_loss: 0.0079\n",
      "Epoch 85/90\n",
      "144/144 [==============================] - 0s 1ms/step - loss: 0.0139 - val_loss: 0.0075\n",
      "Epoch 86/90\n",
      "144/144 [==============================] - 0s 1ms/step - loss: 0.0140 - val_loss: 0.0086\n",
      "Epoch 87/90\n",
      "144/144 [==============================] - 0s 1ms/step - loss: 0.0140 - val_loss: 0.0078\n",
      "Epoch 88/90\n",
      "144/144 [==============================] - 0s 1ms/step - loss: 0.0139 - val_loss: 0.0081\n",
      "Epoch 89/90\n",
      "144/144 [==============================] - 0s 1ms/step - loss: 0.0140 - val_loss: 0.0081\n",
      "Epoch 90/90\n",
      "144/144 [==============================] - 0s 1ms/step - loss: 0.0140 - val_loss: 0.0074\n",
      "Execution time:  19.883842706680298\n",
      "DNN:\n",
      "Mean Absolute Error: 0.0076\n",
      "Root Mean Square Error: 0.0236\n",
      "Mean Square Error: 0.0006\n",
      "\n",
      "Train RMSE: 0.024\n",
      "Train MSE: 0.001\n",
      "Train MAE: 0.008\n",
      "###########################\n",
      "\n",
      "MODEL:  DNN\n",
      "sequence:  1h\n",
      "units:  12\n",
      "dropout1:  0.48476373451509647\n",
      "optimizer: adamax\n",
      "activationDense: sigmoid\n",
      "epochs: 52\n",
      "batchsize: 57\n",
      "validation_split: 0.1\n",
      "Model: \"sequential_32\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_96 (Dense)             (None, 6, 12)             24        \n",
      "_________________________________________________________________\n",
      "dense_97 (Dense)             (None, 6, 16)             208       \n",
      "_________________________________________________________________\n",
      "dropout_32 (Dropout)         (None, 6, 16)             0         \n",
      "_________________________________________________________________\n",
      "dense_98 (Dense)             (None, 6, 1)              17        \n",
      "=================================================================\n",
      "Total params: 249\n",
      "Trainable params: 249\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/52\n",
      "63/63 [==============================] - 0s 7ms/step - loss: 0.0508 - val_loss: 0.0422\n",
      "Epoch 2/52\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0422 - val_loss: 0.0377\n",
      "Epoch 3/52\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0410 - val_loss: 0.0363\n",
      "Epoch 4/52\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0403 - val_loss: 0.0367\n",
      "Epoch 5/52\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0392 - val_loss: 0.0364\n",
      "Epoch 6/52\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0386 - val_loss: 0.0352\n",
      "Epoch 7/52\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0378 - val_loss: 0.0337\n",
      "Epoch 8/52\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0373 - val_loss: 0.0332\n",
      "Epoch 9/52\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0368 - val_loss: 0.0327\n",
      "Epoch 10/52\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0362 - val_loss: 0.0318\n",
      "Epoch 11/52\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0361 - val_loss: 0.0313\n",
      "Epoch 12/52\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0352 - val_loss: 0.0312\n",
      "Epoch 13/52\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0348 - val_loss: 0.0303\n",
      "Epoch 14/52\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0344 - val_loss: 0.0299\n",
      "Epoch 15/52\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0337 - val_loss: 0.0287\n",
      "Epoch 16/52\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0338 - val_loss: 0.0282\n",
      "Epoch 17/52\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0332 - val_loss: 0.0276\n",
      "Epoch 18/52\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0332 - val_loss: 0.0269\n",
      "Epoch 19/52\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0327 - val_loss: 0.0267\n",
      "Epoch 20/52\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0322 - val_loss: 0.0261\n",
      "Epoch 21/52\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0319 - val_loss: 0.0253\n",
      "Epoch 22/52\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0316 - val_loss: 0.0250\n",
      "Epoch 23/52\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0314 - val_loss: 0.0250\n",
      "Epoch 24/52\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0310 - val_loss: 0.0242\n",
      "Epoch 25/52\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0309 - val_loss: 0.0237\n",
      "Epoch 26/52\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0305 - val_loss: 0.0234\n",
      "Epoch 27/52\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0303 - val_loss: 0.0230\n",
      "Epoch 28/52\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0300 - val_loss: 0.0226\n",
      "Epoch 29/52\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0298 - val_loss: 0.0224\n",
      "Epoch 30/52\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0295 - val_loss: 0.0222\n",
      "Epoch 31/52\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0294 - val_loss: 0.0220\n",
      "Epoch 32/52\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0291 - val_loss: 0.0212\n",
      "Epoch 33/52\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0287 - val_loss: 0.0209\n",
      "Epoch 34/52\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0285 - val_loss: 0.0205\n",
      "Epoch 35/52\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0283 - val_loss: 0.0199\n",
      "Epoch 36/52\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0281 - val_loss: 0.0195\n",
      "Epoch 37/52\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0278 - val_loss: 0.0193\n",
      "Epoch 38/52\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0277 - val_loss: 0.0188\n",
      "Epoch 39/52\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0275 - val_loss: 0.0183\n",
      "Epoch 40/52\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0273 - val_loss: 0.0178\n",
      "Epoch 41/52\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0271 - val_loss: 0.0178\n",
      "Epoch 42/52\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0268 - val_loss: 0.0175\n",
      "Epoch 43/52\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0267 - val_loss: 0.0168\n",
      "Epoch 44/52\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0265 - val_loss: 0.0166\n",
      "Epoch 45/52\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0263 - val_loss: 0.0162\n",
      "Epoch 46/52\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0262 - val_loss: 0.0161\n",
      "Epoch 47/52\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0259 - val_loss: 0.0155\n",
      "Epoch 48/52\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0258 - val_loss: 0.0152\n",
      "Epoch 49/52\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0256 - val_loss: 0.0148\n",
      "Epoch 50/52\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0254 - val_loss: 0.0144\n",
      "Epoch 51/52\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0253 - val_loss: 0.0141\n",
      "Epoch 52/52\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0251 - val_loss: 0.0139\n",
      "Execution time:  6.661231994628906\n",
      "DNN:\n",
      "Mean Absolute Error: 0.0229\n",
      "Root Mean Square Error: 0.0385\n",
      "Mean Square Error: 0.0015\n",
      "\n",
      "Train RMSE: 0.039\n",
      "Train MSE: 0.001\n",
      "Train MAE: 0.023\n",
      "###########################\n",
      "\n",
      "MODEL:  DNN\n",
      "sequence:  1h\n",
      "units:  87\n",
      "dropout1:  0.40519643149940265\n",
      "optimizer: adamax\n",
      "activationDense: sigmoid\n",
      "epochs: 80\n",
      "batchsize: 31\n",
      "validation_split: 0.2\n",
      "Model: \"sequential_33\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_99 (Dense)             (None, 6, 87)             174       \n",
      "_________________________________________________________________\n",
      "dense_100 (Dense)            (None, 6, 16)             1408      \n",
      "_________________________________________________________________\n",
      "dropout_33 (Dropout)         (None, 6, 16)             0         \n",
      "_________________________________________________________________\n",
      "dense_101 (Dense)            (None, 6, 1)              17        \n",
      "=================================================================\n",
      "Total params: 1,599\n",
      "Trainable params: 1,599\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/80\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "103/103 [==============================] - 0s 3ms/step - loss: 0.0456 - val_loss: 0.0286\n",
      "Epoch 2/80\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.0422 - val_loss: 0.0276\n",
      "Epoch 3/80\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.0413 - val_loss: 0.0273\n",
      "Epoch 4/80\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.0402 - val_loss: 0.0262\n",
      "Epoch 5/80\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.0394 - val_loss: 0.0255\n",
      "Epoch 6/80\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.0387 - val_loss: 0.0249\n",
      "Epoch 7/80\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.0377 - val_loss: 0.0241\n",
      "Epoch 8/80\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.0371 - val_loss: 0.0235\n",
      "Epoch 9/80\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.0363 - val_loss: 0.0230\n",
      "Epoch 10/80\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.0355 - val_loss: 0.0218\n",
      "Epoch 11/80\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.0352 - val_loss: 0.0218\n",
      "Epoch 12/80\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.0344 - val_loss: 0.0214\n",
      "Epoch 13/80\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.0337 - val_loss: 0.0213\n",
      "Epoch 14/80\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.0334 - val_loss: 0.0207\n",
      "Epoch 15/80\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.0323 - val_loss: 0.0200\n",
      "Epoch 16/80\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.0319 - val_loss: 0.0191\n",
      "Epoch 17/80\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.0316 - val_loss: 0.0187\n",
      "Epoch 18/80\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.0312 - val_loss: 0.0186\n",
      "Epoch 19/80\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.0306 - val_loss: 0.0182\n",
      "Epoch 20/80\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.0302 - val_loss: 0.0177\n",
      "Epoch 21/80\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.0298 - val_loss: 0.0172\n",
      "Epoch 22/80\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.0293 - val_loss: 0.0169\n",
      "Epoch 23/80\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.0288 - val_loss: 0.0164\n",
      "Epoch 24/80\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.0283 - val_loss: 0.0161\n",
      "Epoch 25/80\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.0279 - val_loss: 0.0156\n",
      "Epoch 26/80\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.0275 - val_loss: 0.0152\n",
      "Epoch 27/80\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.0270 - val_loss: 0.0145\n",
      "Epoch 28/80\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.0267 - val_loss: 0.0140\n",
      "Epoch 29/80\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.0263 - val_loss: 0.0138\n",
      "Epoch 30/80\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.0255 - val_loss: 0.0131\n",
      "Epoch 31/80\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.0252 - val_loss: 0.0129\n",
      "Epoch 32/80\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.0247 - val_loss: 0.0128\n",
      "Epoch 33/80\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.0240 - val_loss: 0.0126\n",
      "Epoch 34/80\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.0235 - val_loss: 0.0124\n",
      "Epoch 35/80\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.0229 - val_loss: 0.0123\n",
      "Epoch 36/80\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.0225 - val_loss: 0.0121\n",
      "Epoch 37/80\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.0217 - val_loss: 0.0119\n",
      "Epoch 38/80\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.0211 - val_loss: 0.0116\n",
      "Epoch 39/80\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.0206 - val_loss: 0.0115\n",
      "Epoch 40/80\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.0197 - val_loss: 0.0113\n",
      "Epoch 41/80\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.0191 - val_loss: 0.0110\n",
      "Epoch 42/80\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.0183 - val_loss: 0.0106\n",
      "Epoch 43/80\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.0176 - val_loss: 0.0104\n",
      "Epoch 44/80\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.0172 - val_loss: 0.0100\n",
      "Epoch 45/80\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.0166 - val_loss: 0.0099\n",
      "Epoch 46/80\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.0164 - val_loss: 0.0095\n",
      "Epoch 47/80\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.0160 - val_loss: 0.0095\n",
      "Epoch 48/80\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.0155 - val_loss: 0.0094\n",
      "Epoch 49/80\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.0152 - val_loss: 0.0096\n",
      "Epoch 50/80\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.0149 - val_loss: 0.0096\n",
      "Epoch 51/80\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.0148 - val_loss: 0.0095\n",
      "Epoch 52/80\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.0147 - val_loss: 0.0096\n",
      "Epoch 53/80\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.0146 - val_loss: 0.0096\n",
      "Epoch 54/80\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.0145 - val_loss: 0.0094\n",
      "Epoch 55/80\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.0145 - val_loss: 0.0095\n",
      "Epoch 56/80\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.0144 - val_loss: 0.0095\n",
      "Epoch 57/80\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.0142 - val_loss: 0.0094\n",
      "Epoch 58/80\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.0142 - val_loss: 0.0094\n",
      "Epoch 59/80\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.0142 - val_loss: 0.0092\n",
      "Epoch 60/80\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.0139 - val_loss: 0.0092\n",
      "Epoch 61/80\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.0140 - val_loss: 0.0093\n",
      "Epoch 62/80\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.0140 - val_loss: 0.0089\n",
      "Epoch 63/80\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.0140 - val_loss: 0.0089\n",
      "Epoch 64/80\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.0140 - val_loss: 0.0088\n",
      "Epoch 65/80\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.0138 - val_loss: 0.0089\n",
      "Epoch 66/80\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.0139 - val_loss: 0.0085\n",
      "Epoch 67/80\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.0139 - val_loss: 0.0084\n",
      "Epoch 68/80\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.0139 - val_loss: 0.0087\n",
      "Epoch 69/80\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.0138 - val_loss: 0.0087\n",
      "Epoch 70/80\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.0137 - val_loss: 0.0085\n",
      "Epoch 71/80\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.0138 - val_loss: 0.0085\n",
      "Epoch 72/80\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.0139 - val_loss: 0.0086\n",
      "Epoch 73/80\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.0139 - val_loss: 0.0084\n",
      "Epoch 74/80\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.0139 - val_loss: 0.0083\n",
      "Epoch 75/80\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.0138 - val_loss: 0.0083\n",
      "Epoch 76/80\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.0137 - val_loss: 0.0085\n",
      "Epoch 77/80\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.0136 - val_loss: 0.0084\n",
      "Epoch 78/80\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.0138 - val_loss: 0.0083\n",
      "Epoch 79/80\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.0138 - val_loss: 0.0084\n",
      "Epoch 80/80\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.0137 - val_loss: 0.0083\n",
      "Execution time:  15.485010385513306\n",
      "DNN:\n",
      "Mean Absolute Error: 0.0070\n",
      "Root Mean Square Error: 0.0135\n",
      "Mean Square Error: 0.0002\n",
      "\n",
      "Train RMSE: 0.013\n",
      "Train MSE: 0.000\n",
      "Train MAE: 0.007\n",
      "###########################\n",
      "\n",
      "MODEL:  DNN\n",
      "sequence:  1h\n",
      "units:  80\n",
      "dropout1:  0.11814836227952394\n",
      "optimizer: adamax\n",
      "activationDense: sigmoid\n",
      "epochs: 90\n",
      "batchsize: 25\n",
      "validation_split: 0.2\n",
      "Model: \"sequential_34\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_102 (Dense)            (None, 6, 80)             160       \n",
      "_________________________________________________________________\n",
      "dense_103 (Dense)            (None, 6, 16)             1296      \n",
      "_________________________________________________________________\n",
      "dropout_34 (Dropout)         (None, 6, 16)             0         \n",
      "_________________________________________________________________\n",
      "dense_104 (Dense)            (None, 6, 1)              17        \n",
      "=================================================================\n",
      "Total params: 1,473\n",
      "Trainable params: 1,473\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/90\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "128/128 [==============================] - 0s 3ms/step - loss: 0.0426 - val_loss: 0.0204\n",
      "Epoch 2/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0370 - val_loss: 0.0202\n",
      "Epoch 3/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0369 - val_loss: 0.0200\n",
      "Epoch 4/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0366 - val_loss: 0.0195\n",
      "Epoch 5/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0362 - val_loss: 0.0195\n",
      "Epoch 6/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0357 - val_loss: 0.0194\n",
      "Epoch 7/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0353 - val_loss: 0.0190\n",
      "Epoch 8/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0351 - val_loss: 0.0190\n",
      "Epoch 9/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0349 - val_loss: 0.0189\n",
      "Epoch 10/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0342 - val_loss: 0.0187\n",
      "Epoch 11/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0338 - val_loss: 0.0185\n",
      "Epoch 12/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0334 - val_loss: 0.0185\n",
      "Epoch 13/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0333 - val_loss: 0.0185\n",
      "Epoch 14/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0332 - val_loss: 0.0183\n",
      "Epoch 15/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0328 - val_loss: 0.0181\n",
      "Epoch 16/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0325 - val_loss: 0.0179\n",
      "Epoch 17/90\n",
      "128/128 [==============================] - 0s 1ms/step - loss: 0.0324 - val_loss: 0.0181\n",
      "Epoch 18/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0318 - val_loss: 0.0178\n",
      "Epoch 19/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0317 - val_loss: 0.0178\n",
      "Epoch 20/90\n",
      "128/128 [==============================] - 0s 1ms/step - loss: 0.0314 - val_loss: 0.0177\n",
      "Epoch 21/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0313 - val_loss: 0.0175\n",
      "Epoch 22/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0311 - val_loss: 0.0175\n",
      "Epoch 23/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0305 - val_loss: 0.0171\n",
      "Epoch 24/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0301 - val_loss: 0.0166\n",
      "Epoch 25/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0301 - val_loss: 0.0161\n",
      "Epoch 26/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0297 - val_loss: 0.0161\n",
      "Epoch 27/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0295 - val_loss: 0.0157\n",
      "Epoch 28/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0291 - val_loss: 0.0157\n",
      "Epoch 29/90\n",
      "128/128 [==============================] - 0s 1ms/step - loss: 0.0288 - val_loss: 0.0155\n",
      "Epoch 30/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0287 - val_loss: 0.0153\n",
      "Epoch 31/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0282 - val_loss: 0.0149\n",
      "Epoch 32/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0279 - val_loss: 0.0147\n",
      "Epoch 33/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0273 - val_loss: 0.0142\n",
      "Epoch 34/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0270 - val_loss: 0.0139\n",
      "Epoch 35/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0267 - val_loss: 0.0138\n",
      "Epoch 36/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0264 - val_loss: 0.0134\n",
      "Epoch 37/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0258 - val_loss: 0.0133\n",
      "Epoch 38/90\n",
      "128/128 [==============================] - 0s 1ms/step - loss: 0.0252 - val_loss: 0.0131\n",
      "Epoch 39/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0247 - val_loss: 0.0129\n",
      "Epoch 40/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0240 - val_loss: 0.0127\n",
      "Epoch 41/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0234 - val_loss: 0.0126\n",
      "Epoch 42/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0224 - val_loss: 0.0124\n",
      "Epoch 43/90\n",
      "128/128 [==============================] - 0s 1ms/step - loss: 0.0217 - val_loss: 0.0122\n",
      "Epoch 44/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0210 - val_loss: 0.0119\n",
      "Epoch 45/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0206 - val_loss: 0.0115\n",
      "Epoch 46/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0195 - val_loss: 0.0112\n",
      "Epoch 47/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0187 - val_loss: 0.0108\n",
      "Epoch 48/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0177 - val_loss: 0.0105\n",
      "Epoch 49/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0166 - val_loss: 0.0101\n",
      "Epoch 50/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0160 - val_loss: 0.0097\n",
      "Epoch 51/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0153 - val_loss: 0.0093\n",
      "Epoch 52/90\n",
      "128/128 [==============================] - 0s 1ms/step - loss: 0.0145 - val_loss: 0.0083\n",
      "Epoch 53/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0140 - val_loss: 0.0083\n",
      "Epoch 54/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0134 - val_loss: 0.0081\n",
      "Epoch 55/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0130 - val_loss: 0.0081\n",
      "Epoch 56/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0129 - val_loss: 0.0079\n",
      "Epoch 57/90\n",
      "128/128 [==============================] - 0s 1ms/step - loss: 0.0127 - val_loss: 0.0095\n",
      "Epoch 58/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0123 - val_loss: 0.0099\n",
      "Epoch 59/90\n",
      "128/128 [==============================] - 0s 1ms/step - loss: 0.0122 - val_loss: 0.0098\n",
      "Epoch 60/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0120 - val_loss: 0.0087\n",
      "Epoch 61/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0120 - val_loss: 0.0095\n",
      "Epoch 62/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0119 - val_loss: 0.0094\n",
      "Epoch 63/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0119 - val_loss: 0.0083\n",
      "Epoch 64/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0118 - val_loss: 0.0097\n",
      "Epoch 65/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0118 - val_loss: 0.0097\n",
      "Epoch 66/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0118 - val_loss: 0.0093\n",
      "Epoch 67/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0118 - val_loss: 0.0084\n",
      "Epoch 68/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0117 - val_loss: 0.0096\n",
      "Epoch 69/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0118 - val_loss: 0.0088\n",
      "Epoch 70/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0117 - val_loss: 0.0090\n",
      "Epoch 71/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0117 - val_loss: 0.0096\n",
      "Epoch 72/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0116 - val_loss: 0.0094\n",
      "Epoch 73/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0116 - val_loss: 0.0093\n",
      "Epoch 74/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0117 - val_loss: 0.0084\n",
      "Epoch 75/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0116 - val_loss: 0.0091\n",
      "Epoch 76/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0116 - val_loss: 0.0092\n",
      "Epoch 77/90\n",
      "128/128 [==============================] - 0s 1ms/step - loss: 0.0115 - val_loss: 0.0090\n",
      "Epoch 78/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0116 - val_loss: 0.0090\n",
      "Epoch 79/90\n",
      "128/128 [==============================] - 0s 1ms/step - loss: 0.0115 - val_loss: 0.0094\n",
      "Epoch 80/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0116 - val_loss: 0.0089\n",
      "Epoch 81/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0115 - val_loss: 0.0086\n",
      "Epoch 82/90\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0115 - val_loss: 0.0087\n",
      "Epoch 83/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0115 - val_loss: 0.0084\n",
      "Epoch 84/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0115 - val_loss: 0.0091\n",
      "Epoch 85/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0114 - val_loss: 0.0089\n",
      "Epoch 86/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0115 - val_loss: 0.0084\n",
      "Epoch 87/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0114 - val_loss: 0.0089\n",
      "Epoch 88/90\n",
      "128/128 [==============================] - 0s 1ms/step - loss: 0.0114 - val_loss: 0.0088\n",
      "Epoch 89/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0114 - val_loss: 0.0082\n",
      "Epoch 90/90\n",
      "128/128 [==============================] - 0s 1ms/step - loss: 0.0114 - val_loss: 0.0087\n",
      "Execution time:  19.100332498550415\n",
      "DNN:\n",
      "Mean Absolute Error: 0.0055\n",
      "Root Mean Square Error: 0.0134\n",
      "Mean Square Error: 0.0002\n",
      "\n",
      "Train RMSE: 0.013\n",
      "Train MSE: 0.000\n",
      "Train MAE: 0.006\n",
      "###########################\n",
      "\n",
      "MODEL:  DNN\n",
      "sequence:  1h\n",
      "units:  12\n",
      "dropout1:  0.48476373451509647\n",
      "optimizer: adamax\n",
      "activationDense: sigmoid\n",
      "epochs: 52\n",
      "batchsize: 57\n",
      "validation_split: 0.2\n",
      "Model: \"sequential_35\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_105 (Dense)            (None, 6, 12)             24        \n",
      "_________________________________________________________________\n",
      "dense_106 (Dense)            (None, 6, 16)             208       \n",
      "_________________________________________________________________\n",
      "dropout_35 (Dropout)         (None, 6, 16)             0         \n",
      "_________________________________________________________________\n",
      "dense_107 (Dense)            (None, 6, 1)              17        \n",
      "=================================================================\n",
      "Total params: 249\n",
      "Trainable params: 249\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/52\n",
      "56/56 [==============================] - 0s 8ms/step - loss: 0.0942 - val_loss: 0.0898\n",
      "Epoch 2/52\n",
      "56/56 [==============================] - 0s 2ms/step - loss: 0.0580 - val_loss: 0.0632\n",
      "Epoch 3/52\n",
      "56/56 [==============================] - 0s 2ms/step - loss: 0.0476 - val_loss: 0.0494\n",
      "Epoch 4/52\n",
      "56/56 [==============================] - 0s 2ms/step - loss: 0.0444 - val_loss: 0.0451\n",
      "Epoch 5/52\n",
      "56/56 [==============================] - 0s 2ms/step - loss: 0.0426 - val_loss: 0.0430\n",
      "Epoch 6/52\n",
      "56/56 [==============================] - 0s 2ms/step - loss: 0.0407 - val_loss: 0.0411\n",
      "Epoch 7/52\n",
      "56/56 [==============================] - 0s 2ms/step - loss: 0.0390 - val_loss: 0.0395\n",
      "Epoch 8/52\n",
      "56/56 [==============================] - 0s 2ms/step - loss: 0.0375 - val_loss: 0.0380\n",
      "Epoch 9/52\n",
      "56/56 [==============================] - 0s 2ms/step - loss: 0.0374 - val_loss: 0.0366\n",
      "Epoch 10/52\n",
      "56/56 [==============================] - 0s 2ms/step - loss: 0.0358 - val_loss: 0.0350\n",
      "Epoch 11/52\n",
      "56/56 [==============================] - 0s 2ms/step - loss: 0.0351 - val_loss: 0.0337\n",
      "Epoch 12/52\n",
      "56/56 [==============================] - 0s 2ms/step - loss: 0.0340 - val_loss: 0.0325\n",
      "Epoch 13/52\n",
      "56/56 [==============================] - 0s 2ms/step - loss: 0.0334 - val_loss: 0.0314\n",
      "Epoch 14/52\n",
      "56/56 [==============================] - 0s 2ms/step - loss: 0.0328 - val_loss: 0.0303\n",
      "Epoch 15/52\n",
      "56/56 [==============================] - 0s 2ms/step - loss: 0.0323 - val_loss: 0.0294\n",
      "Epoch 16/52\n",
      "56/56 [==============================] - 0s 2ms/step - loss: 0.0317 - val_loss: 0.0285\n",
      "Epoch 17/52\n",
      "56/56 [==============================] - 0s 2ms/step - loss: 0.0312 - val_loss: 0.0275\n",
      "Epoch 18/52\n",
      "56/56 [==============================] - 0s 2ms/step - loss: 0.0308 - val_loss: 0.0268\n",
      "Epoch 19/52\n",
      "56/56 [==============================] - 0s 2ms/step - loss: 0.0302 - val_loss: 0.0257\n",
      "Epoch 20/52\n",
      "56/56 [==============================] - 0s 2ms/step - loss: 0.0301 - val_loss: 0.0254\n",
      "Epoch 21/52\n",
      "56/56 [==============================] - 0s 2ms/step - loss: 0.0297 - val_loss: 0.0249\n",
      "Epoch 22/52\n",
      "56/56 [==============================] - 0s 2ms/step - loss: 0.0293 - val_loss: 0.0241\n",
      "Epoch 23/52\n",
      "56/56 [==============================] - 0s 2ms/step - loss: 0.0290 - val_loss: 0.0238\n",
      "Epoch 24/52\n",
      "56/56 [==============================] - 0s 2ms/step - loss: 0.0286 - val_loss: 0.0228\n",
      "Epoch 25/52\n",
      "56/56 [==============================] - 0s 2ms/step - loss: 0.0286 - val_loss: 0.0228\n",
      "Epoch 26/52\n",
      "56/56 [==============================] - 0s 2ms/step - loss: 0.0283 - val_loss: 0.0222\n",
      "Epoch 27/52\n",
      "56/56 [==============================] - 0s 2ms/step - loss: 0.0280 - val_loss: 0.0218\n",
      "Epoch 28/52\n",
      "56/56 [==============================] - 0s 2ms/step - loss: 0.0277 - val_loss: 0.0213\n",
      "Epoch 29/52\n",
      "56/56 [==============================] - 0s 2ms/step - loss: 0.0276 - val_loss: 0.0211\n",
      "Epoch 30/52\n",
      "56/56 [==============================] - 0s 2ms/step - loss: 0.0272 - val_loss: 0.0207\n",
      "Epoch 31/52\n",
      "56/56 [==============================] - 0s 2ms/step - loss: 0.0271 - val_loss: 0.0205\n",
      "Epoch 32/52\n",
      "56/56 [==============================] - 0s 2ms/step - loss: 0.0268 - val_loss: 0.0201\n",
      "Epoch 33/52\n",
      "56/56 [==============================] - 0s 2ms/step - loss: 0.0267 - val_loss: 0.0198\n",
      "Epoch 34/52\n",
      "56/56 [==============================] - 0s 2ms/step - loss: 0.0265 - val_loss: 0.0197\n",
      "Epoch 35/52\n",
      "56/56 [==============================] - 0s 2ms/step - loss: 0.0263 - val_loss: 0.0192\n",
      "Epoch 36/52\n",
      "56/56 [==============================] - 0s 2ms/step - loss: 0.0261 - val_loss: 0.0188\n",
      "Epoch 37/52\n",
      "56/56 [==============================] - 0s 2ms/step - loss: 0.0261 - val_loss: 0.0186\n",
      "Epoch 38/52\n",
      "56/56 [==============================] - 0s 2ms/step - loss: 0.0257 - val_loss: 0.0184\n",
      "Epoch 39/52\n",
      "56/56 [==============================] - 0s 2ms/step - loss: 0.0256 - val_loss: 0.0182\n",
      "Epoch 40/52\n",
      "56/56 [==============================] - 0s 2ms/step - loss: 0.0255 - val_loss: 0.0180\n",
      "Epoch 41/52\n",
      "56/56 [==============================] - 0s 2ms/step - loss: 0.0253 - val_loss: 0.0178\n",
      "Epoch 42/52\n",
      "56/56 [==============================] - 0s 2ms/step - loss: 0.0251 - val_loss: 0.0176\n",
      "Epoch 43/52\n",
      "56/56 [==============================] - 0s 2ms/step - loss: 0.0251 - val_loss: 0.0175\n",
      "Epoch 44/52\n",
      "56/56 [==============================] - 0s 2ms/step - loss: 0.0250 - val_loss: 0.0172\n",
      "Epoch 45/52\n",
      "56/56 [==============================] - 0s 2ms/step - loss: 0.0248 - val_loss: 0.0169\n",
      "Epoch 46/52\n",
      "56/56 [==============================] - 0s 2ms/step - loss: 0.0247 - val_loss: 0.0168\n",
      "Epoch 47/52\n",
      "56/56 [==============================] - 0s 2ms/step - loss: 0.0245 - val_loss: 0.0166\n",
      "Epoch 48/52\n",
      "56/56 [==============================] - 0s 2ms/step - loss: 0.0244 - val_loss: 0.0164\n",
      "Epoch 49/52\n",
      "56/56 [==============================] - 0s 2ms/step - loss: 0.0243 - val_loss: 0.0163\n",
      "Epoch 50/52\n",
      "56/56 [==============================] - 0s 2ms/step - loss: 0.0240 - val_loss: 0.0161\n",
      "Epoch 51/52\n",
      "56/56 [==============================] - 0s 2ms/step - loss: 0.0240 - val_loss: 0.0160\n",
      "Epoch 52/52\n",
      "56/56 [==============================] - 0s 2ms/step - loss: 0.0238 - val_loss: 0.0159\n",
      "Execution time:  6.896315574645996\n",
      "DNN:\n",
      "Mean Absolute Error: 0.0209\n",
      "Root Mean Square Error: 0.0341\n",
      "Mean Square Error: 0.0012\n",
      "\n",
      "Train RMSE: 0.034\n",
      "Train MSE: 0.001\n",
      "Train MAE: 0.021\n",
      "###########################\n",
      "\n",
      "MODEL:  DNN\n",
      "sequence:  3h\n",
      "units:  87\n",
      "dropout1:  0.40519643149940265\n",
      "optimizer: adam\n",
      "activationDense: tanh\n",
      "epochs: 80\n",
      "batchsize: 31\n",
      "validation_split: 0.1\n",
      "Model: \"sequential_36\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_108 (Dense)            (None, 18, 87)            174       \n",
      "_________________________________________________________________\n",
      "dense_109 (Dense)            (None, 18, 16)            1408      \n",
      "_________________________________________________________________\n",
      "dropout_36 (Dropout)         (None, 18, 16)            0         \n",
      "_________________________________________________________________\n",
      "dense_110 (Dense)            (None, 18, 1)             17        \n",
      "=================================================================\n",
      "Total params: 1,599\n",
      "Trainable params: 1,599\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/80\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "116/116 [==============================] - 0s 4ms/step - loss: 0.1344 - val_loss: 0.0059\n",
      "Epoch 2/80\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.0786 - val_loss: 0.0118\n",
      "Epoch 3/80\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.0665 - val_loss: 0.0056\n",
      "Epoch 4/80\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.0544 - val_loss: 0.0069\n",
      "Epoch 5/80\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.0435 - val_loss: 0.0130\n",
      "Epoch 6/80\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.0348 - val_loss: 0.0135\n",
      "Epoch 7/80\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.0294 - val_loss: 0.0129\n",
      "Epoch 8/80\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.0280 - val_loss: 0.0229\n",
      "Epoch 9/80\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.0279 - val_loss: 0.0121\n",
      "Epoch 10/80\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.0289 - val_loss: 0.0110\n",
      "Epoch 11/80\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.0286 - val_loss: 0.0100\n",
      "Epoch 12/80\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.0286 - val_loss: 0.0107\n",
      "Epoch 13/80\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.0283 - val_loss: 0.0109\n",
      "Epoch 14/80\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.0286 - val_loss: 0.0108\n",
      "Epoch 15/80\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.0283 - val_loss: 0.0109\n",
      "Epoch 16/80\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.0284 - val_loss: 0.0112\n",
      "Epoch 17/80\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.0278 - val_loss: 0.0106\n",
      "Epoch 18/80\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.0282 - val_loss: 0.0111\n",
      "Epoch 19/80\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.0276 - val_loss: 0.0105\n",
      "Epoch 20/80\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.0279 - val_loss: 0.0108\n",
      "Epoch 21/80\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.0276 - val_loss: 0.0110\n",
      "Epoch 22/80\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.0272 - val_loss: 0.0107\n",
      "Epoch 23/80\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.0271 - val_loss: 0.0107\n",
      "Epoch 24/80\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.0265 - val_loss: 0.0105\n",
      "Epoch 25/80\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.0263 - val_loss: 0.0112\n",
      "Epoch 26/80\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.0257 - val_loss: 0.0106\n",
      "Epoch 27/80\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.0253 - val_loss: 0.0109\n",
      "Epoch 28/80\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.0249 - val_loss: 0.0109\n",
      "Epoch 29/80\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.0248 - val_loss: 0.0135\n",
      "Epoch 30/80\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.0235 - val_loss: 0.0105\n",
      "Epoch 31/80\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.0232 - val_loss: 0.0122\n",
      "Epoch 32/80\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.0225 - val_loss: 0.0107\n",
      "Epoch 33/80\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.0225 - val_loss: 0.0104\n",
      "Epoch 34/80\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.0206 - val_loss: 0.0122\n",
      "Epoch 35/80\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.0205 - val_loss: 0.0108\n",
      "Epoch 36/80\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.0202 - val_loss: 0.0123\n",
      "Epoch 37/80\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.0202 - val_loss: 0.0118\n",
      "Epoch 38/80\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.0209 - val_loss: 0.0105\n",
      "Epoch 39/80\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.0199 - val_loss: 0.0122\n",
      "Epoch 40/80\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.0199 - val_loss: 0.0114\n",
      "Epoch 41/80\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.0201 - val_loss: 0.0117\n",
      "Epoch 42/80\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.0201 - val_loss: 0.0114\n",
      "Epoch 43/80\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.0202 - val_loss: 0.0112\n",
      "Epoch 44/80\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.0202 - val_loss: 0.0118\n",
      "Epoch 45/80\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.0202 - val_loss: 0.0115\n",
      "Epoch 46/80\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.0200 - val_loss: 0.0122\n",
      "Epoch 47/80\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.0199 - val_loss: 0.0120\n",
      "Epoch 48/80\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.0201 - val_loss: 0.0116\n",
      "Epoch 49/80\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.0196 - val_loss: 0.0121\n",
      "Epoch 50/80\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.0200 - val_loss: 0.0115\n",
      "Epoch 51/80\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.0199 - val_loss: 0.0123\n",
      "Epoch 52/80\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.0198 - val_loss: 0.0120\n",
      "Epoch 53/80\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.0201 - val_loss: 0.0116\n",
      "Epoch 54/80\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.0205 - val_loss: 0.0110\n",
      "Epoch 55/80\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.0202 - val_loss: 0.0123\n",
      "Epoch 56/80\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.0200 - val_loss: 0.0124\n",
      "Epoch 57/80\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.0201 - val_loss: 0.0119\n",
      "Epoch 58/80\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.0196 - val_loss: 0.0133\n",
      "Epoch 59/80\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.0200 - val_loss: 0.0116\n",
      "Epoch 60/80\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.0200 - val_loss: 0.0116\n",
      "Epoch 61/80\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.0201 - val_loss: 0.0115\n",
      "Epoch 62/80\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.0197 - val_loss: 0.0122\n",
      "Epoch 63/80\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.0199 - val_loss: 0.0115\n",
      "Epoch 64/80\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.0197 - val_loss: 0.0121\n",
      "Epoch 65/80\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.0201 - val_loss: 0.0113\n",
      "Epoch 66/80\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.0198 - val_loss: 0.0121\n",
      "Epoch 67/80\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.0200 - val_loss: 0.0115\n",
      "Epoch 68/80\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.0199 - val_loss: 0.0125\n",
      "Epoch 69/80\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.0200 - val_loss: 0.0116\n",
      "Epoch 70/80\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.0196 - val_loss: 0.0120\n",
      "Epoch 71/80\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.0199 - val_loss: 0.0115\n",
      "Epoch 72/80\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.0197 - val_loss: 0.0122\n",
      "Epoch 73/80\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.0196 - val_loss: 0.0133\n",
      "Epoch 74/80\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.0200 - val_loss: 0.0116\n",
      "Epoch 75/80\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.0200 - val_loss: 0.0117\n",
      "Epoch 76/80\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.0198 - val_loss: 0.0118\n",
      "Epoch 77/80\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.0198 - val_loss: 0.0125\n",
      "Epoch 78/80\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.0196 - val_loss: 0.0122\n",
      "Epoch 79/80\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.0196 - val_loss: 0.0125\n",
      "Epoch 80/80\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.0197 - val_loss: 0.0120\n",
      "Execution time:  21.342922687530518\n",
      "DNN:\n",
      "Mean Absolute Error: 0.0145\n",
      "Root Mean Square Error: 0.0233\n",
      "Mean Square Error: 0.0005\n",
      "\n",
      "Train RMSE: 0.023\n",
      "Train MSE: 0.001\n",
      "Train MAE: 0.014\n",
      "###########################\n",
      "\n",
      "MODEL:  DNN\n",
      "sequence:  3h\n",
      "units:  80\n",
      "dropout1:  0.11814836227952394\n",
      "optimizer: adam\n",
      "activationDense: tanh\n",
      "epochs: 90\n",
      "batchsize: 25\n",
      "validation_split: 0.1\n",
      "Model: \"sequential_37\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_111 (Dense)            (None, 18, 80)            160       \n",
      "_________________________________________________________________\n",
      "dense_112 (Dense)            (None, 18, 16)            1296      \n",
      "_________________________________________________________________\n",
      "dropout_37 (Dropout)         (None, 18, 16)            0         \n",
      "_________________________________________________________________\n",
      "dense_113 (Dense)            (None, 18, 1)             17        \n",
      "=================================================================\n",
      "Total params: 1,473\n",
      "Trainable params: 1,473\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/90\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "143/143 [==============================] - 0s 3ms/step - loss: 0.1376 - val_loss: 0.0187\n",
      "Epoch 2/90\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.0516 - val_loss: 0.0201\n",
      "Epoch 3/90\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.0490 - val_loss: 0.0175\n",
      "Epoch 4/90\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.0464 - val_loss: 0.0124\n",
      "Epoch 5/90\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.0436 - val_loss: 0.0087\n",
      "Epoch 6/90\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.0406 - val_loss: 0.0054\n",
      "Epoch 7/90\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.0379 - val_loss: 0.0056\n",
      "Epoch 8/90\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.0353 - val_loss: 0.0068\n",
      "Epoch 9/90\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.0330 - val_loss: 0.0106\n",
      "Epoch 10/90\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.0305 - val_loss: 0.0114\n",
      "Epoch 11/90\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.0287 - val_loss: 0.0130\n",
      "Epoch 12/90\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.0275 - val_loss: 0.0166\n",
      "Epoch 13/90\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.0262 - val_loss: 0.0123\n",
      "Epoch 14/90\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.0266 - val_loss: 0.0190\n",
      "Epoch 15/90\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.0258 - val_loss: 0.0210\n",
      "Epoch 16/90\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.0253 - val_loss: 0.0210\n",
      "Epoch 17/90\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.0244 - val_loss: 0.0205\n",
      "Epoch 18/90\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.0241 - val_loss: 0.0205\n",
      "Epoch 19/90\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.0237 - val_loss: 0.0202\n",
      "Epoch 20/90\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.0233 - val_loss: 0.0200\n",
      "Epoch 21/90\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.0238 - val_loss: 0.0185\n",
      "Epoch 22/90\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.0232 - val_loss: 0.0194\n",
      "Epoch 23/90\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.0229 - val_loss: 0.0188\n",
      "Epoch 24/90\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.0225 - val_loss: 0.0156\n",
      "Epoch 25/90\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.0224 - val_loss: 0.0124\n",
      "Epoch 26/90\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.0215 - val_loss: 0.0163\n",
      "Epoch 27/90\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.0200 - val_loss: 0.0173\n",
      "Epoch 28/90\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.0192 - val_loss: 0.0188\n",
      "Epoch 29/90\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.0182 - val_loss: 0.0167\n",
      "Epoch 30/90\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.0178 - val_loss: 0.0165\n",
      "Epoch 31/90\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.0175 - val_loss: 0.0129\n",
      "Epoch 32/90\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.0173 - val_loss: 0.0133\n",
      "Epoch 33/90\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.0170 - val_loss: 0.0142\n",
      "Epoch 34/90\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.0168 - val_loss: 0.0137\n",
      "Epoch 35/90\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.0163 - val_loss: 0.0133\n",
      "Epoch 36/90\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.0166 - val_loss: 0.0148\n",
      "Epoch 37/90\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.0166 - val_loss: 0.0128\n",
      "Epoch 38/90\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.0164 - val_loss: 0.0146\n",
      "Epoch 39/90\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.0164 - val_loss: 0.0155\n",
      "Epoch 40/90\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.0163 - val_loss: 0.0138\n",
      "Epoch 41/90\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.0162 - val_loss: 0.0150\n",
      "Epoch 42/90\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.0162 - val_loss: 0.0132\n",
      "Epoch 43/90\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.0161 - val_loss: 0.0162\n",
      "Epoch 44/90\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.0164 - val_loss: 0.0141\n",
      "Epoch 45/90\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.0162 - val_loss: 0.0141\n",
      "Epoch 46/90\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.0160 - val_loss: 0.0146\n",
      "Epoch 47/90\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.0165 - val_loss: 0.0130\n",
      "Epoch 48/90\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.0161 - val_loss: 0.0158\n",
      "Epoch 49/90\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.0161 - val_loss: 0.0132\n",
      "Epoch 50/90\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.0160 - val_loss: 0.0132\n",
      "Epoch 51/90\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.0162 - val_loss: 0.0130\n",
      "Epoch 52/90\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.0162 - val_loss: 0.0158\n",
      "Epoch 53/90\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.0160 - val_loss: 0.0150\n",
      "Epoch 54/90\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.0161 - val_loss: 0.0142\n",
      "Epoch 55/90\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.0160 - val_loss: 0.0150\n",
      "Epoch 56/90\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.0159 - val_loss: 0.0143\n",
      "Epoch 57/90\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.0159 - val_loss: 0.0149\n",
      "Epoch 58/90\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.0159 - val_loss: 0.0132\n",
      "Epoch 59/90\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.0157 - val_loss: 0.0146\n",
      "Epoch 60/90\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.0160 - val_loss: 0.0151\n",
      "Epoch 61/90\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.0160 - val_loss: 0.0151\n",
      "Epoch 62/90\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.0159 - val_loss: 0.0146\n",
      "Epoch 63/90\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.0159 - val_loss: 0.0132\n",
      "Epoch 64/90\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.0158 - val_loss: 0.0142\n",
      "Epoch 65/90\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.0158 - val_loss: 0.0145\n",
      "Epoch 66/90\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.0157 - val_loss: 0.0156\n",
      "Epoch 67/90\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.0158 - val_loss: 0.0145\n",
      "Epoch 68/90\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.0157 - val_loss: 0.0161\n",
      "Epoch 69/90\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.0157 - val_loss: 0.0163\n",
      "Epoch 70/90\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.0158 - val_loss: 0.0146\n",
      "Epoch 71/90\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.0158 - val_loss: 0.0154\n",
      "Epoch 72/90\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.0154 - val_loss: 0.0156\n",
      "Epoch 73/90\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.0158 - val_loss: 0.0164\n",
      "Epoch 74/90\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.0158 - val_loss: 0.0164\n",
      "Epoch 75/90\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.0157 - val_loss: 0.0165\n",
      "Epoch 76/90\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.0158 - val_loss: 0.0148\n",
      "Epoch 77/90\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.0157 - val_loss: 0.0139\n",
      "Epoch 78/90\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.0159 - val_loss: 0.0151\n",
      "Epoch 79/90\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.0157 - val_loss: 0.0157\n",
      "Epoch 80/90\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.0156 - val_loss: 0.0138\n",
      "Epoch 81/90\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.0155 - val_loss: 0.0146\n",
      "Epoch 82/90\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "143/143 [==============================] - 0s 2ms/step - loss: 0.0157 - val_loss: 0.0169\n",
      "Epoch 83/90\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.0155 - val_loss: 0.0147\n",
      "Epoch 84/90\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.0155 - val_loss: 0.0157\n",
      "Epoch 85/90\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.0155 - val_loss: 0.0159\n",
      "Epoch 86/90\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.0157 - val_loss: 0.0147\n",
      "Epoch 87/90\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.0157 - val_loss: 0.0140\n",
      "Epoch 88/90\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.0155 - val_loss: 0.0140\n",
      "Epoch 89/90\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.0153 - val_loss: 0.0159\n",
      "Epoch 90/90\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.0157 - val_loss: 0.0156\n",
      "Execution time:  21.208261013031006\n",
      "DNN:\n",
      "Mean Absolute Error: 0.0132\n",
      "Root Mean Square Error: 0.0230\n",
      "Mean Square Error: 0.0005\n",
      "\n",
      "Train RMSE: 0.023\n",
      "Train MSE: 0.001\n",
      "Train MAE: 0.013\n",
      "###########################\n",
      "\n",
      "MODEL:  DNN\n",
      "sequence:  3h\n",
      "units:  12\n",
      "dropout1:  0.48476373451509647\n",
      "optimizer: adam\n",
      "activationDense: tanh\n",
      "epochs: 52\n",
      "batchsize: 57\n",
      "validation_split: 0.1\n",
      "Model: \"sequential_38\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_114 (Dense)            (None, 18, 12)            24        \n",
      "_________________________________________________________________\n",
      "dense_115 (Dense)            (None, 18, 16)            208       \n",
      "_________________________________________________________________\n",
      "dropout_38 (Dropout)         (None, 18, 16)            0         \n",
      "_________________________________________________________________\n",
      "dense_116 (Dense)            (None, 18, 1)             17        \n",
      "=================================================================\n",
      "Total params: 249\n",
      "Trainable params: 249\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/52\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.3404 - val_loss: 0.1351\n",
      "Epoch 2/52\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.1244 - val_loss: 0.0072\n",
      "Epoch 3/52\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0927 - val_loss: 0.0068\n",
      "Epoch 4/52\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0812 - val_loss: 0.0071\n",
      "Epoch 5/52\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0744 - val_loss: 0.0093\n",
      "Epoch 6/52\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0680 - val_loss: 0.0071\n",
      "Epoch 7/52\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0612 - val_loss: 0.0068\n",
      "Epoch 8/52\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0551 - val_loss: 0.0064\n",
      "Epoch 9/52\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0494 - val_loss: 0.0063\n",
      "Epoch 10/52\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0442 - val_loss: 0.0069\n",
      "Epoch 11/52\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0396 - val_loss: 0.0073\n",
      "Epoch 12/52\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0358 - val_loss: 0.0085\n",
      "Epoch 13/52\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0328 - val_loss: 0.0093\n",
      "Epoch 14/52\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0307 - val_loss: 0.0093\n",
      "Epoch 15/52\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0294 - val_loss: 0.0098\n",
      "Epoch 16/52\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0287 - val_loss: 0.0099\n",
      "Epoch 17/52\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0281 - val_loss: 0.0105\n",
      "Epoch 18/52\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0277 - val_loss: 0.0099\n",
      "Epoch 19/52\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0276 - val_loss: 0.0106\n",
      "Epoch 20/52\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0277 - val_loss: 0.0094\n",
      "Epoch 21/52\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0272 - val_loss: 0.0107\n",
      "Epoch 22/52\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0270 - val_loss: 0.0098\n",
      "Epoch 23/52\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0270 - val_loss: 0.0111\n",
      "Epoch 24/52\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0265 - val_loss: 0.0099\n",
      "Epoch 25/52\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0267 - val_loss: 0.0110\n",
      "Epoch 26/52\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0264 - val_loss: 0.0121\n",
      "Epoch 27/52\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0252 - val_loss: 0.0100\n",
      "Epoch 28/52\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0253 - val_loss: 0.0101\n",
      "Epoch 29/52\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0255 - val_loss: 0.0100\n",
      "Epoch 30/52\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0248 - val_loss: 0.0100\n",
      "Epoch 31/52\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0250 - val_loss: 0.0099\n",
      "Epoch 32/52\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0241 - val_loss: 0.0102\n",
      "Epoch 33/52\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0248 - val_loss: 0.0102\n",
      "Epoch 34/52\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0235 - val_loss: 0.0101\n",
      "Epoch 35/52\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0237 - val_loss: 0.0101\n",
      "Epoch 36/52\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0227 - val_loss: 0.0100\n",
      "Epoch 37/52\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0233 - val_loss: 0.0101\n",
      "Epoch 38/52\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0220 - val_loss: 0.0099\n",
      "Epoch 39/52\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0223 - val_loss: 0.0102\n",
      "Epoch 40/52\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0210 - val_loss: 0.0098\n",
      "Epoch 41/52\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0218 - val_loss: 0.0100\n",
      "Epoch 42/52\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0210 - val_loss: 0.0097\n",
      "Epoch 43/52\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0217 - val_loss: 0.0104\n",
      "Epoch 44/52\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0202 - val_loss: 0.0097\n",
      "Epoch 45/52\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0209 - val_loss: 0.0101\n",
      "Epoch 46/52\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0194 - val_loss: 0.0100\n",
      "Epoch 47/52\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0204 - val_loss: 0.0104\n",
      "Epoch 48/52\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0184 - val_loss: 0.0099\n",
      "Epoch 49/52\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0201 - val_loss: 0.0099\n",
      "Epoch 50/52\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0188 - val_loss: 0.0110\n",
      "Epoch 51/52\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0191 - val_loss: 0.0100\n",
      "Epoch 52/52\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0193 - val_loss: 0.0105\n",
      "Execution time:  7.914307594299316\n",
      "DNN:\n",
      "Mean Absolute Error: 0.0172\n",
      "Root Mean Square Error: 0.0261\n",
      "Mean Square Error: 0.0007\n",
      "\n",
      "Train RMSE: 0.026\n",
      "Train MSE: 0.001\n",
      "Train MAE: 0.017\n",
      "###########################\n",
      "\n",
      "MODEL:  DNN\n",
      "sequence:  3h\n",
      "units:  87\n",
      "dropout1:  0.40519643149940265\n",
      "optimizer: adam\n",
      "activationDense: tanh\n",
      "epochs: 80\n",
      "batchsize: 31\n",
      "validation_split: 0.2\n",
      "Model: \"sequential_39\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_117 (Dense)            (None, 18, 87)            174       \n",
      "_________________________________________________________________\n",
      "dense_118 (Dense)            (None, 18, 16)            1408      \n",
      "_________________________________________________________________\n",
      "dropout_39 (Dropout)         (None, 18, 16)            0         \n",
      "_________________________________________________________________\n",
      "dense_119 (Dense)            (None, 18, 1)             17        \n",
      "=================================================================\n",
      "Total params: 1,599\n",
      "Trainable params: 1,599\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/80\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "103/103 [==============================] - 0s 4ms/step - loss: 0.1393 - val_loss: 0.0494\n",
      "Epoch 2/80\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.0861 - val_loss: 0.0249\n",
      "Epoch 3/80\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.0684 - val_loss: 0.0136\n",
      "Epoch 4/80\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 0.0562 - val_loss: 0.0130\n",
      "Epoch 5/80\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.0466 - val_loss: 0.0122\n",
      "Epoch 6/80\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.0378 - val_loss: 0.0129\n",
      "Epoch 7/80\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 0.0322 - val_loss: 0.0144\n",
      "Epoch 8/80\n",
      "103/103 [==============================] - ETA: 0s - loss: 0.031 - 0s 2ms/step - loss: 0.0289 - val_loss: 0.0148\n",
      "Epoch 9/80\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.0304 - val_loss: 0.0156\n",
      "Epoch 10/80\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.0309 - val_loss: 0.0160\n",
      "Epoch 11/80\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.0305 - val_loss: 0.0157\n",
      "Epoch 12/80\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.0302 - val_loss: 0.0170\n",
      "Epoch 13/80\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.0297 - val_loss: 0.0156\n",
      "Epoch 14/80\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.0300 - val_loss: 0.0171\n",
      "Epoch 15/80\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.0297 - val_loss: 0.0166\n",
      "Epoch 16/80\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.0297 - val_loss: 0.0165\n",
      "Epoch 17/80\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.0297 - val_loss: 0.0164\n",
      "Epoch 18/80\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.0295 - val_loss: 0.0163\n",
      "Epoch 19/80\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.0295 - val_loss: 0.0162\n",
      "Epoch 20/80\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.0296 - val_loss: 0.0160\n",
      "Epoch 21/80\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.0295 - val_loss: 0.0160\n",
      "Epoch 22/80\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.0294 - val_loss: 0.0159\n",
      "Epoch 23/80\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.0294 - val_loss: 0.0159\n",
      "Epoch 24/80\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.0293 - val_loss: 0.0157\n",
      "Epoch 25/80\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.0293 - val_loss: 0.0157\n",
      "Epoch 26/80\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 0.0293 - val_loss: 0.0162\n",
      "Epoch 27/80\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 0.0291 - val_loss: 0.0158\n",
      "Epoch 28/80\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 0.0289 - val_loss: 0.0155\n",
      "Epoch 29/80\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 0.0289 - val_loss: 0.0158\n",
      "Epoch 30/80\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 0.0286 - val_loss: 0.0153\n",
      "Epoch 31/80\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.0287 - val_loss: 0.0155\n",
      "Epoch 32/80\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.0286 - val_loss: 0.0154\n",
      "Epoch 33/80\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.0284 - val_loss: 0.0154\n",
      "Epoch 34/80\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.0282 - val_loss: 0.0152\n",
      "Epoch 35/80\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.0280 - val_loss: 0.0155\n",
      "Epoch 36/80\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.0275 - val_loss: 0.0150\n",
      "Epoch 37/80\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.0275 - val_loss: 0.0156\n",
      "Epoch 38/80\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.0268 - val_loss: 0.0149\n",
      "Epoch 39/80\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.0267 - val_loss: 0.0151\n",
      "Epoch 40/80\n",
      "103/103 [==============================] - ETA: 0s - loss: 0.028 - 0s 2ms/step - loss: 0.0262 - val_loss: 0.0149\n",
      "Epoch 41/80\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.0264 - val_loss: 0.0151\n",
      "Epoch 42/80\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.0255 - val_loss: 0.0148\n",
      "Epoch 43/80\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.0258 - val_loss: 0.0155\n",
      "Epoch 44/80\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.0243 - val_loss: 0.0148\n",
      "Epoch 45/80\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 0.0238 - val_loss: 0.0144\n",
      "Epoch 46/80\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.0233 - val_loss: 0.0146\n",
      "Epoch 47/80\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.0235 - val_loss: 0.0144\n",
      "Epoch 48/80\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.0218 - val_loss: 0.0144\n",
      "Epoch 49/80\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.0213 - val_loss: 0.0144\n",
      "Epoch 50/80\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.0210 - val_loss: 0.0141\n",
      "Epoch 51/80\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.0209 - val_loss: 0.0139\n",
      "Epoch 52/80\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.0206 - val_loss: 0.0138\n",
      "Epoch 53/80\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.0203 - val_loss: 0.0135\n",
      "Epoch 54/80\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.0201 - val_loss: 0.0137\n",
      "Epoch 55/80\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.0200 - val_loss: 0.0134\n",
      "Epoch 56/80\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.0202 - val_loss: 0.0129\n",
      "Epoch 57/80\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.0198 - val_loss: 0.0135\n",
      "Epoch 58/80\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.0203 - val_loss: 0.0127\n",
      "Epoch 59/80\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.0197 - val_loss: 0.0135\n",
      "Epoch 60/80\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.0202 - val_loss: 0.0130\n",
      "Epoch 61/80\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.0199 - val_loss: 0.0132\n",
      "Epoch 62/80\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.0200 - val_loss: 0.0132\n",
      "Epoch 63/80\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.0199 - val_loss: 0.0132\n",
      "Epoch 64/80\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.0198 - val_loss: 0.0131\n",
      "Epoch 65/80\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.0200 - val_loss: 0.0130\n",
      "Epoch 66/80\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.0197 - val_loss: 0.0132\n",
      "Epoch 67/80\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.0199 - val_loss: 0.0127\n",
      "Epoch 68/80\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.0196 - val_loss: 0.0134\n",
      "Epoch 69/80\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.0201 - val_loss: 0.0128\n",
      "Epoch 70/80\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 0.0199 - val_loss: 0.0131\n",
      "Epoch 71/80\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.0199 - val_loss: 0.0132\n",
      "Epoch 72/80\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.0198 - val_loss: 0.0133\n",
      "Epoch 73/80\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.0199 - val_loss: 0.0128\n",
      "Epoch 74/80\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.0197 - val_loss: 0.0133\n",
      "Epoch 75/80\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.0197 - val_loss: 0.0130\n",
      "Epoch 76/80\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.0199 - val_loss: 0.0130\n",
      "Epoch 77/80\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.0198 - val_loss: 0.0133\n",
      "Epoch 78/80\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.0201 - val_loss: 0.0129\n",
      "Epoch 79/80\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.0197 - val_loss: 0.0132\n",
      "Epoch 80/80\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.0201 - val_loss: 0.0125\n",
      "Execution time:  20.461792469024658\n",
      "DNN:\n",
      "Mean Absolute Error: 0.0169\n",
      "Root Mean Square Error: 0.0274\n",
      "Mean Square Error: 0.0008\n",
      "\n",
      "Train RMSE: 0.027\n",
      "Train MSE: 0.001\n",
      "Train MAE: 0.017\n",
      "###########################\n",
      "\n",
      "MODEL:  DNN\n",
      "sequence:  3h\n",
      "units:  80\n",
      "dropout1:  0.11814836227952394\n",
      "optimizer: adam\n",
      "activationDense: tanh\n",
      "epochs: 90\n",
      "batchsize: 25\n",
      "validation_split: 0.2\n",
      "Model: \"sequential_40\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_120 (Dense)            (None, 18, 80)            160       \n",
      "_________________________________________________________________\n",
      "dense_121 (Dense)            (None, 18, 16)            1296      \n",
      "_________________________________________________________________\n",
      "dropout_40 (Dropout)         (None, 18, 16)            0         \n",
      "_________________________________________________________________\n",
      "dense_122 (Dense)            (None, 18, 1)             17        \n",
      "=================================================================\n",
      "Total params: 1,473\n",
      "Trainable params: 1,473\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/90\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "128/128 [==============================] - 0s 4ms/step - loss: 0.1082 - val_loss: 0.0327\n",
      "Epoch 2/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0511 - val_loss: 0.0342\n",
      "Epoch 3/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0487 - val_loss: 0.0342\n",
      "Epoch 4/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0464 - val_loss: 0.0225\n",
      "Epoch 5/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0425 - val_loss: 0.0186\n",
      "Epoch 6/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0395 - val_loss: 0.0173\n",
      "Epoch 7/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0374 - val_loss: 0.0160\n",
      "Epoch 8/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0354 - val_loss: 0.0121\n",
      "Epoch 9/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0330 - val_loss: 0.0140\n",
      "Epoch 10/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0317 - val_loss: 0.0128\n",
      "Epoch 11/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0300 - val_loss: 0.0116\n",
      "Epoch 12/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0284 - val_loss: 0.0116\n",
      "Epoch 13/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0273 - val_loss: 0.0117\n",
      "Epoch 14/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0264 - val_loss: 0.0119\n",
      "Epoch 15/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0258 - val_loss: 0.0121\n",
      "Epoch 16/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0252 - val_loss: 0.0121\n",
      "Epoch 17/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0244 - val_loss: 0.0129\n",
      "Epoch 18/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0240 - val_loss: 0.0134\n",
      "Epoch 19/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0236 - val_loss: 0.0131\n",
      "Epoch 20/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0234 - val_loss: 0.0133\n",
      "Epoch 21/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0231 - val_loss: 0.0134\n",
      "Epoch 22/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0227 - val_loss: 0.0129\n",
      "Epoch 23/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0225 - val_loss: 0.0137\n",
      "Epoch 24/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0248 - val_loss: 0.0135\n",
      "Epoch 25/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0218 - val_loss: 0.0128\n",
      "Epoch 26/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0222 - val_loss: 0.0144\n",
      "Epoch 27/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0224 - val_loss: 0.0141\n",
      "Epoch 28/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0243 - val_loss: 0.0141\n",
      "Epoch 29/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0201 - val_loss: 0.0144\n",
      "Epoch 30/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0208 - val_loss: 0.0143\n",
      "Epoch 31/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0191 - val_loss: 0.0138\n",
      "Epoch 32/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0204 - val_loss: 0.0144\n",
      "Epoch 33/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0188 - val_loss: 0.0134\n",
      "Epoch 34/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0198 - val_loss: 0.0136\n",
      "Epoch 35/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0194 - val_loss: 0.0136\n",
      "Epoch 36/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0192 - val_loss: 0.0133\n",
      "Epoch 37/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0196 - val_loss: 0.0133\n",
      "Epoch 38/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0186 - val_loss: 0.0133\n",
      "Epoch 39/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0185 - val_loss: 0.0130\n",
      "Epoch 40/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0202 - val_loss: 0.0146\n",
      "Epoch 41/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0184 - val_loss: 0.0135\n",
      "Epoch 42/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0183 - val_loss: 0.0134\n",
      "Epoch 43/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0174 - val_loss: 0.0131\n",
      "Epoch 44/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0171 - val_loss: 0.0130\n",
      "Epoch 45/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0170 - val_loss: 0.0131\n",
      "Epoch 46/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0190 - val_loss: 0.0142\n",
      "Epoch 47/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0178 - val_loss: 0.0132\n",
      "Epoch 48/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0175 - val_loss: 0.0135\n",
      "Epoch 49/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0171 - val_loss: 0.0124\n",
      "Epoch 50/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0164 - val_loss: 0.0131\n",
      "Epoch 51/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0168 - val_loss: 0.0128\n",
      "Epoch 52/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0167 - val_loss: 0.0129\n",
      "Epoch 53/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0164 - val_loss: 0.0131\n",
      "Epoch 54/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0168 - val_loss: 0.0129\n",
      "Epoch 55/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0168 - val_loss: 0.0130\n",
      "Epoch 56/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0165 - val_loss: 0.0128\n",
      "Epoch 57/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0168 - val_loss: 0.0128\n",
      "Epoch 58/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0181 - val_loss: 0.0141\n",
      "Epoch 59/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0179 - val_loss: 0.0132\n",
      "Epoch 60/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0170 - val_loss: 0.0126\n",
      "Epoch 61/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0162 - val_loss: 0.0131\n",
      "Epoch 62/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0163 - val_loss: 0.0126\n",
      "Epoch 63/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0160 - val_loss: 0.0130\n",
      "Epoch 64/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0168 - val_loss: 0.0125\n",
      "Epoch 65/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0162 - val_loss: 0.0126\n",
      "Epoch 66/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0158 - val_loss: 0.0127\n",
      "Epoch 67/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0159 - val_loss: 0.0128\n",
      "Epoch 68/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0160 - val_loss: 0.0130\n",
      "Epoch 69/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0158 - val_loss: 0.0126\n",
      "Epoch 70/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0162 - val_loss: 0.0129\n",
      "Epoch 71/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0158 - val_loss: 0.0129\n",
      "Epoch 72/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0161 - val_loss: 0.0133\n",
      "Epoch 73/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0161 - val_loss: 0.0129\n",
      "Epoch 74/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0162 - val_loss: 0.0129\n",
      "Epoch 75/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0159 - val_loss: 0.0129\n",
      "Epoch 76/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0158 - val_loss: 0.0129\n",
      "Epoch 77/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0161 - val_loss: 0.0129\n",
      "Epoch 78/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0161 - val_loss: 0.0120\n",
      "Epoch 79/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0154 - val_loss: 0.0129\n",
      "Epoch 80/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0160 - val_loss: 0.0127\n",
      "Epoch 81/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0156 - val_loss: 0.0127\n",
      "Epoch 82/90\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0156 - val_loss: 0.0129\n",
      "Epoch 83/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0160 - val_loss: 0.0128\n",
      "Epoch 84/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0157 - val_loss: 0.0128\n",
      "Epoch 85/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0159 - val_loss: 0.0125\n",
      "Epoch 86/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0156 - val_loss: 0.0128\n",
      "Epoch 87/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0156 - val_loss: 0.0130\n",
      "Epoch 88/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0157 - val_loss: 0.0128\n",
      "Epoch 89/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0157 - val_loss: 0.0128\n",
      "Epoch 90/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0157 - val_loss: 0.0127\n",
      "Execution time:  25.262813091278076\n",
      "DNN:\n",
      "Mean Absolute Error: 0.0149\n",
      "Root Mean Square Error: 0.0276\n",
      "Mean Square Error: 0.0008\n",
      "\n",
      "Train RMSE: 0.028\n",
      "Train MSE: 0.001\n",
      "Train MAE: 0.015\n",
      "###########################\n",
      "\n",
      "MODEL:  DNN\n",
      "sequence:  3h\n",
      "units:  12\n",
      "dropout1:  0.48476373451509647\n",
      "optimizer: adam\n",
      "activationDense: tanh\n",
      "epochs: 52\n",
      "batchsize: 57\n",
      "validation_split: 0.2\n",
      "Model: \"sequential_41\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_123 (Dense)            (None, 18, 12)            24        \n",
      "_________________________________________________________________\n",
      "dense_124 (Dense)            (None, 18, 16)            208       \n",
      "_________________________________________________________________\n",
      "dropout_41 (Dropout)         (None, 18, 16)            0         \n",
      "_________________________________________________________________\n",
      "dense_125 (Dense)            (None, 18, 1)             17        \n",
      "=================================================================\n",
      "Total params: 249\n",
      "Trainable params: 249\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/52\n",
      "56/56 [==============================] - 0s 9ms/step - loss: 0.3221 - val_loss: 0.0279\n",
      "Epoch 2/52\n",
      "56/56 [==============================] - 0s 2ms/step - loss: 0.1179 - val_loss: 0.0173\n",
      "Epoch 3/52\n",
      "56/56 [==============================] - 0s 2ms/step - loss: 0.1018 - val_loss: 0.0273\n",
      "Epoch 4/52\n",
      "56/56 [==============================] - 0s 2ms/step - loss: 0.0910 - val_loss: 0.0356\n",
      "Epoch 5/52\n",
      "56/56 [==============================] - 0s 2ms/step - loss: 0.0835 - val_loss: 0.0313\n",
      "Epoch 6/52\n",
      "56/56 [==============================] - 0s 2ms/step - loss: 0.0755 - val_loss: 0.0220\n",
      "Epoch 7/52\n",
      "56/56 [==============================] - 0s 2ms/step - loss: 0.0641 - val_loss: 0.0139\n",
      "Epoch 8/52\n",
      "56/56 [==============================] - 0s 2ms/step - loss: 0.0566 - val_loss: 0.0138\n",
      "Epoch 9/52\n",
      "56/56 [==============================] - 0s 2ms/step - loss: 0.0500 - val_loss: 0.0137\n",
      "Epoch 10/52\n",
      "56/56 [==============================] - 0s 2ms/step - loss: 0.0448 - val_loss: 0.0132\n",
      "Epoch 11/52\n",
      "56/56 [==============================] - 0s 2ms/step - loss: 0.0396 - val_loss: 0.0143\n",
      "Epoch 12/52\n",
      "56/56 [==============================] - 0s 2ms/step - loss: 0.0365 - val_loss: 0.0133\n",
      "Epoch 13/52\n",
      "56/56 [==============================] - 0s 2ms/step - loss: 0.0326 - val_loss: 0.0131\n",
      "Epoch 14/52\n",
      "56/56 [==============================] - 0s 2ms/step - loss: 0.0307 - val_loss: 0.0131\n",
      "Epoch 15/52\n",
      "56/56 [==============================] - 0s 2ms/step - loss: 0.0291 - val_loss: 0.0131\n",
      "Epoch 16/52\n",
      "56/56 [==============================] - 0s 2ms/step - loss: 0.0278 - val_loss: 0.0135\n",
      "Epoch 17/52\n",
      "56/56 [==============================] - 0s 2ms/step - loss: 0.0268 - val_loss: 0.0143\n",
      "Epoch 18/52\n",
      "56/56 [==============================] - 0s 2ms/step - loss: 0.0268 - val_loss: 0.0146\n",
      "Epoch 19/52\n",
      "56/56 [==============================] - 0s 2ms/step - loss: 0.0264 - val_loss: 0.0141\n",
      "Epoch 20/52\n",
      "56/56 [==============================] - 0s 2ms/step - loss: 0.0256 - val_loss: 0.0140\n",
      "Epoch 21/52\n",
      "56/56 [==============================] - 0s 2ms/step - loss: 0.0249 - val_loss: 0.0135\n",
      "Epoch 22/52\n",
      "56/56 [==============================] - 0s 2ms/step - loss: 0.0240 - val_loss: 0.0138\n",
      "Epoch 23/52\n",
      "56/56 [==============================] - 0s 2ms/step - loss: 0.0246 - val_loss: 0.0135\n",
      "Epoch 24/52\n",
      "56/56 [==============================] - 0s 2ms/step - loss: 0.0237 - val_loss: 0.0138\n",
      "Epoch 25/52\n",
      "56/56 [==============================] - 0s 2ms/step - loss: 0.0232 - val_loss: 0.0137\n",
      "Epoch 26/52\n",
      "56/56 [==============================] - 0s 2ms/step - loss: 0.0223 - val_loss: 0.0136\n",
      "Epoch 27/52\n",
      "56/56 [==============================] - 0s 2ms/step - loss: 0.0231 - val_loss: 0.0139\n",
      "Epoch 28/52\n",
      "56/56 [==============================] - 0s 2ms/step - loss: 0.0210 - val_loss: 0.0136\n",
      "Epoch 29/52\n",
      "56/56 [==============================] - 0s 2ms/step - loss: 0.0224 - val_loss: 0.0135\n",
      "Epoch 30/52\n",
      "56/56 [==============================] - 0s 2ms/step - loss: 0.0209 - val_loss: 0.0128\n",
      "Epoch 31/52\n",
      "56/56 [==============================] - 0s 2ms/step - loss: 0.0214 - val_loss: 0.0125\n",
      "Epoch 32/52\n",
      "56/56 [==============================] - 0s 2ms/step - loss: 0.0205 - val_loss: 0.0129\n",
      "Epoch 33/52\n",
      "56/56 [==============================] - 0s 2ms/step - loss: 0.0210 - val_loss: 0.0129\n",
      "Epoch 34/52\n",
      "56/56 [==============================] - 0s 2ms/step - loss: 0.0209 - val_loss: 0.0124\n",
      "Epoch 35/52\n",
      "56/56 [==============================] - 0s 2ms/step - loss: 0.0195 - val_loss: 0.0128\n",
      "Epoch 36/52\n",
      "56/56 [==============================] - 0s 2ms/step - loss: 0.0207 - val_loss: 0.0128\n",
      "Epoch 37/52\n",
      "56/56 [==============================] - 0s 2ms/step - loss: 0.0192 - val_loss: 0.0128\n",
      "Epoch 38/52\n",
      "56/56 [==============================] - 0s 2ms/step - loss: 0.0201 - val_loss: 0.0122\n",
      "Epoch 39/52\n",
      "56/56 [==============================] - 0s 2ms/step - loss: 0.0190 - val_loss: 0.0127\n",
      "Epoch 40/52\n",
      "56/56 [==============================] - 0s 2ms/step - loss: 0.0196 - val_loss: 0.0124\n",
      "Epoch 41/52\n",
      "56/56 [==============================] - 0s 2ms/step - loss: 0.0191 - val_loss: 0.0126\n",
      "Epoch 42/52\n",
      "56/56 [==============================] - 0s 2ms/step - loss: 0.0195 - val_loss: 0.0126\n",
      "Epoch 43/52\n",
      "56/56 [==============================] - 0s 2ms/step - loss: 0.0193 - val_loss: 0.0126\n",
      "Epoch 44/52\n",
      "56/56 [==============================] - 0s 2ms/step - loss: 0.0192 - val_loss: 0.0125\n",
      "Epoch 45/52\n",
      "56/56 [==============================] - 0s 2ms/step - loss: 0.0189 - val_loss: 0.0126\n",
      "Epoch 46/52\n",
      "56/56 [==============================] - 0s 2ms/step - loss: 0.0188 - val_loss: 0.0126\n",
      "Epoch 47/52\n",
      "56/56 [==============================] - 0s 2ms/step - loss: 0.0187 - val_loss: 0.0124\n",
      "Epoch 48/52\n",
      "56/56 [==============================] - 0s 2ms/step - loss: 0.0186 - val_loss: 0.0127\n",
      "Epoch 49/52\n",
      "56/56 [==============================] - 0s 2ms/step - loss: 0.0188 - val_loss: 0.0120\n",
      "Epoch 50/52\n",
      "56/56 [==============================] - 0s 2ms/step - loss: 0.0183 - val_loss: 0.0127\n",
      "Epoch 51/52\n",
      "56/56 [==============================] - 0s 2ms/step - loss: 0.0186 - val_loss: 0.0125\n",
      "Epoch 52/52\n",
      "56/56 [==============================] - 0s 2ms/step - loss: 0.0183 - val_loss: 0.0125\n",
      "Execution time:  7.537402868270874\n",
      "DNN:\n",
      "Mean Absolute Error: 0.0161\n",
      "Root Mean Square Error: 0.0249\n",
      "Mean Square Error: 0.0006\n",
      "\n",
      "Train RMSE: 0.025\n",
      "Train MSE: 0.001\n",
      "Train MAE: 0.016\n",
      "###########################\n",
      "\n",
      "MODEL:  DNN\n",
      "sequence:  3h\n",
      "units:  87\n",
      "dropout1:  0.40519643149940265\n",
      "optimizer: adam\n",
      "activationDense: sigmoid\n",
      "epochs: 80\n",
      "batchsize: 31\n",
      "validation_split: 0.1\n",
      "Model: \"sequential_42\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_126 (Dense)            (None, 18, 87)            174       \n",
      "_________________________________________________________________\n",
      "dense_127 (Dense)            (None, 18, 16)            1408      \n",
      "_________________________________________________________________\n",
      "dropout_42 (Dropout)         (None, 18, 16)            0         \n",
      "_________________________________________________________________\n",
      "dense_128 (Dense)            (None, 18, 1)             17        \n",
      "=================================================================\n",
      "Total params: 1,599\n",
      "Trainable params: 1,599\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/80\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "116/116 [==============================] - 0s 4ms/step - loss: 0.0448 - val_loss: 0.0260\n",
      "Epoch 2/80\n",
      "116/116 [==============================] - 0s 3ms/step - loss: 0.0423 - val_loss: 0.0261\n",
      "Epoch 3/80\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.0405 - val_loss: 0.0247\n",
      "Epoch 4/80\n",
      "116/116 [==============================] - 0s 3ms/step - loss: 0.0390 - val_loss: 0.0239\n",
      "Epoch 5/80\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.0374 - val_loss: 0.0234\n",
      "Epoch 6/80\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.0361 - val_loss: 0.0225\n",
      "Epoch 7/80\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.0347 - val_loss: 0.0224\n",
      "Epoch 8/80\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.0337 - val_loss: 0.0213\n",
      "Epoch 9/80\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.0330 - val_loss: 0.0204\n",
      "Epoch 10/80\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.0320 - val_loss: 0.0199\n",
      "Epoch 11/80\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.0312 - val_loss: 0.0195\n",
      "Epoch 12/80\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.0305 - val_loss: 0.0185\n",
      "Epoch 13/80\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.0301 - val_loss: 0.0180\n",
      "Epoch 14/80\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.0296 - val_loss: 0.0171\n",
      "Epoch 15/80\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.0292 - val_loss: 0.0164\n",
      "Epoch 16/80\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.0288 - val_loss: 0.0160\n",
      "Epoch 17/80\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.0285 - val_loss: 0.0156\n",
      "Epoch 18/80\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.0281 - val_loss: 0.0147\n",
      "Epoch 19/80\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.0278 - val_loss: 0.0149\n",
      "Epoch 20/80\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.0274 - val_loss: 0.0146\n",
      "Epoch 21/80\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.0272 - val_loss: 0.0144\n",
      "Epoch 22/80\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.0269 - val_loss: 0.0141\n",
      "Epoch 23/80\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.0266 - val_loss: 0.0137\n",
      "Epoch 24/80\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.0264 - val_loss: 0.0138\n",
      "Epoch 25/80\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.0262 - val_loss: 0.0139\n",
      "Epoch 26/80\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.0261 - val_loss: 0.0136\n",
      "Epoch 27/80\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.0259 - val_loss: 0.0137\n",
      "Epoch 28/80\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.0259 - val_loss: 0.0135\n",
      "Epoch 29/80\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.0257 - val_loss: 0.0134\n",
      "Epoch 30/80\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.0257 - val_loss: 0.0136\n",
      "Epoch 31/80\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.0254 - val_loss: 0.0136\n",
      "Epoch 32/80\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.0252 - val_loss: 0.0138\n",
      "Epoch 33/80\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.0250 - val_loss: 0.0138\n",
      "Epoch 34/80\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.0248 - val_loss: 0.0139\n",
      "Epoch 35/80\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.0246 - val_loss: 0.0139\n",
      "Epoch 36/80\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.0244 - val_loss: 0.0140\n",
      "Epoch 37/80\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.0242 - val_loss: 0.0138\n",
      "Epoch 38/80\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.0239 - val_loss: 0.0137\n",
      "Epoch 39/80\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.0236 - val_loss: 0.0130\n",
      "Epoch 40/80\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.0234 - val_loss: 0.0130\n",
      "Epoch 41/80\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.0233 - val_loss: 0.0131\n",
      "Epoch 42/80\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.0229 - val_loss: 0.0126\n",
      "Epoch 43/80\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.0227 - val_loss: 0.0129\n",
      "Epoch 44/80\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.0225 - val_loss: 0.0129\n",
      "Epoch 45/80\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.0227 - val_loss: 0.0129\n",
      "Epoch 46/80\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.0222 - val_loss: 0.0130\n",
      "Epoch 47/80\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.0221 - val_loss: 0.0131\n",
      "Epoch 48/80\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.0219 - val_loss: 0.0133\n",
      "Epoch 49/80\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.0217 - val_loss: 0.0137\n",
      "Epoch 50/80\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.0215 - val_loss: 0.0142\n",
      "Epoch 51/80\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.0215 - val_loss: 0.0135\n",
      "Epoch 52/80\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.0214 - val_loss: 0.0136\n",
      "Epoch 53/80\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.0212 - val_loss: 0.0141\n",
      "Epoch 54/80\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.0212 - val_loss: 0.0143\n",
      "Epoch 55/80\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.0211 - val_loss: 0.0141\n",
      "Epoch 56/80\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.0211 - val_loss: 0.0148\n",
      "Epoch 57/80\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.0211 - val_loss: 0.0141\n",
      "Epoch 58/80\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.0210 - val_loss: 0.0153\n",
      "Epoch 59/80\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.0210 - val_loss: 0.0141\n",
      "Epoch 60/80\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.0209 - val_loss: 0.0153\n",
      "Epoch 61/80\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.0209 - val_loss: 0.0157\n",
      "Epoch 62/80\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.0208 - val_loss: 0.0136\n",
      "Epoch 63/80\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.0206 - val_loss: 0.0180\n",
      "Epoch 64/80\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.0205 - val_loss: 0.0146\n",
      "Epoch 65/80\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.0205 - val_loss: 0.0166\n",
      "Epoch 66/80\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.0205 - val_loss: 0.0154\n",
      "Epoch 67/80\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.0198 - val_loss: 0.0165\n",
      "Epoch 68/80\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.0195 - val_loss: 0.0156\n",
      "Epoch 69/80\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.0192 - val_loss: 0.0159\n",
      "Epoch 70/80\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.0190 - val_loss: 0.0147\n",
      "Epoch 71/80\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.0188 - val_loss: 0.0153\n",
      "Epoch 72/80\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.0188 - val_loss: 0.0154\n",
      "Epoch 73/80\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.0186 - val_loss: 0.0138\n",
      "Epoch 74/80\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.0185 - val_loss: 0.0148\n",
      "Epoch 75/80\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.0185 - val_loss: 0.0152\n",
      "Epoch 76/80\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.0185 - val_loss: 0.0150\n",
      "Epoch 77/80\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.0185 - val_loss: 0.0144\n",
      "Epoch 78/80\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.0185 - val_loss: 0.0157\n",
      "Epoch 79/80\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.0185 - val_loss: 0.0159\n",
      "Epoch 80/80\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.0184 - val_loss: 0.0143\n",
      "Execution time:  21.58287000656128\n",
      "DNN:\n",
      "Mean Absolute Error: 0.0136\n",
      "Root Mean Square Error: 0.0236\n",
      "Mean Square Error: 0.0006\n",
      "\n",
      "Train RMSE: 0.024\n",
      "Train MSE: 0.001\n",
      "Train MAE: 0.014\n",
      "###########################\n",
      "\n",
      "MODEL:  DNN\n",
      "sequence:  3h\n",
      "units:  80\n",
      "dropout1:  0.11814836227952394\n",
      "optimizer: adam\n",
      "activationDense: sigmoid\n",
      "epochs: 90\n",
      "batchsize: 25\n",
      "validation_split: 0.1\n",
      "Model: \"sequential_43\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_129 (Dense)            (None, 18, 80)            160       \n",
      "_________________________________________________________________\n",
      "dense_130 (Dense)            (None, 18, 16)            1296      \n",
      "_________________________________________________________________\n",
      "dropout_43 (Dropout)         (None, 18, 16)            0         \n",
      "_________________________________________________________________\n",
      "dense_131 (Dense)            (None, 18, 1)             17        \n",
      "=================================================================\n",
      "Total params: 1,473\n",
      "Trainable params: 1,473\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/90\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "143/143 [==============================] - 0s 3ms/step - loss: 0.0449 - val_loss: 0.0277\n",
      "Epoch 2/90\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.0372 - val_loss: 0.0250\n",
      "Epoch 3/90\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.0369 - val_loss: 0.0242\n",
      "Epoch 4/90\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.0353 - val_loss: 0.0218\n",
      "Epoch 5/90\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.0343 - val_loss: 0.0226\n",
      "Epoch 6/90\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.0336 - val_loss: 0.0202\n",
      "Epoch 7/90\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.0333 - val_loss: 0.0191\n",
      "Epoch 8/90\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.0327 - val_loss: 0.0191\n",
      "Epoch 9/90\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.0321 - val_loss: 0.0183\n",
      "Epoch 10/90\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.0317 - val_loss: 0.0276\n",
      "Epoch 11/90\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.0322 - val_loss: 0.0174\n",
      "Epoch 12/90\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.0315 - val_loss: 0.0170\n",
      "Epoch 13/90\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.0306 - val_loss: 0.0168\n",
      "Epoch 14/90\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.0301 - val_loss: 0.0155\n",
      "Epoch 15/90\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.0298 - val_loss: 0.0159\n",
      "Epoch 16/90\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.0295 - val_loss: 0.0155\n",
      "Epoch 17/90\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.0290 - val_loss: 0.0161\n",
      "Epoch 18/90\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.0288 - val_loss: 0.0150\n",
      "Epoch 19/90\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.0285 - val_loss: 0.0149\n",
      "Epoch 20/90\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.0281 - val_loss: 0.0147\n",
      "Epoch 21/90\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.0271 - val_loss: 0.0232\n",
      "Epoch 22/90\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.0270 - val_loss: 0.0138\n",
      "Epoch 23/90\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.0267 - val_loss: 0.0145\n",
      "Epoch 24/90\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.0263 - val_loss: 0.0145\n",
      "Epoch 25/90\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.0258 - val_loss: 0.0147\n",
      "Epoch 26/90\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.0253 - val_loss: 0.0147\n",
      "Epoch 27/90\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.0247 - val_loss: 0.0136\n",
      "Epoch 28/90\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.0241 - val_loss: 0.0141\n",
      "Epoch 29/90\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.0233 - val_loss: 0.0141\n",
      "Epoch 30/90\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.0227 - val_loss: 0.0136\n",
      "Epoch 31/90\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.0213 - val_loss: 0.0135\n",
      "Epoch 32/90\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.0198 - val_loss: 0.0139\n",
      "Epoch 33/90\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.0187 - val_loss: 0.0146\n",
      "Epoch 34/90\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.0179 - val_loss: 0.0148\n",
      "Epoch 35/90\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.0173 - val_loss: 0.0155\n",
      "Epoch 36/90\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.0167 - val_loss: 0.0144\n",
      "Epoch 37/90\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.0159 - val_loss: 0.0138\n",
      "Epoch 38/90\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.0156 - val_loss: 0.0139\n",
      "Epoch 39/90\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.0155 - val_loss: 0.0126\n",
      "Epoch 40/90\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.0153 - val_loss: 0.0109\n",
      "Epoch 41/90\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.0153 - val_loss: 0.0101\n",
      "Epoch 42/90\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.0153 - val_loss: 0.0102\n",
      "Epoch 43/90\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.0151 - val_loss: 0.0101\n",
      "Epoch 44/90\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.0152 - val_loss: 0.0098\n",
      "Epoch 45/90\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.0151 - val_loss: 0.0100\n",
      "Epoch 46/90\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.0150 - val_loss: 0.0095\n",
      "Epoch 47/90\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.0151 - val_loss: 0.0092\n",
      "Epoch 48/90\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.0150 - val_loss: 0.0101\n",
      "Epoch 49/90\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.0151 - val_loss: 0.0098\n",
      "Epoch 50/90\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.0150 - val_loss: 0.0107\n",
      "Epoch 51/90\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.0150 - val_loss: 0.0103\n",
      "Epoch 52/90\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.0151 - val_loss: 0.0109\n",
      "Epoch 53/90\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.0151 - val_loss: 0.0104\n",
      "Epoch 54/90\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.0151 - val_loss: 0.0108\n",
      "Epoch 55/90\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.0150 - val_loss: 0.0113\n",
      "Epoch 56/90\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.0149 - val_loss: 0.0108\n",
      "Epoch 57/90\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.0151 - val_loss: 0.0109\n",
      "Epoch 58/90\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.0151 - val_loss: 0.0107\n",
      "Epoch 59/90\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.0151 - val_loss: 0.0118\n",
      "Epoch 60/90\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.0150 - val_loss: 0.0118\n",
      "Epoch 61/90\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.0152 - val_loss: 0.0107\n",
      "Epoch 62/90\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.0151 - val_loss: 0.0122\n",
      "Epoch 63/90\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.0150 - val_loss: 0.0124\n",
      "Epoch 64/90\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.0151 - val_loss: 0.0132\n",
      "Epoch 65/90\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.0151 - val_loss: 0.0109\n",
      "Epoch 66/90\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.0150 - val_loss: 0.0106\n",
      "Epoch 67/90\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.0149 - val_loss: 0.0105\n",
      "Epoch 68/90\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.0150 - val_loss: 0.0115\n",
      "Epoch 69/90\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.0149 - val_loss: 0.0112\n",
      "Epoch 70/90\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.0151 - val_loss: 0.0116\n",
      "Epoch 71/90\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.0149 - val_loss: 0.0108\n",
      "Epoch 72/90\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.0150 - val_loss: 0.0111\n",
      "Epoch 73/90\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.0149 - val_loss: 0.0109\n",
      "Epoch 74/90\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.0150 - val_loss: 0.0104\n",
      "Epoch 75/90\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.0149 - val_loss: 0.0106\n",
      "Epoch 76/90\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.0149 - val_loss: 0.0121\n",
      "Epoch 77/90\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.0149 - val_loss: 0.0111\n",
      "Epoch 78/90\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.0150 - val_loss: 0.0111\n",
      "Epoch 79/90\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.0148 - val_loss: 0.0105\n",
      "Epoch 80/90\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.0149 - val_loss: 0.0111\n",
      "Epoch 81/90\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.0148 - val_loss: 0.0109\n",
      "Epoch 82/90\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "143/143 [==============================] - 0s 2ms/step - loss: 0.0148 - val_loss: 0.0110\n",
      "Epoch 83/90\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.0149 - val_loss: 0.0105\n",
      "Epoch 84/90\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.0148 - val_loss: 0.0109\n",
      "Epoch 85/90\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.0149 - val_loss: 0.0110\n",
      "Epoch 86/90\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.0149 - val_loss: 0.0108\n",
      "Epoch 87/90\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.0148 - val_loss: 0.0109\n",
      "Epoch 88/90\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.0148 - val_loss: 0.0109\n",
      "Epoch 89/90\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.0148 - val_loss: 0.0110\n",
      "Epoch 90/90\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.0149 - val_loss: 0.0111\n",
      "Execution time:  21.16887092590332\n",
      "DNN:\n",
      "Mean Absolute Error: 0.0079\n",
      "Root Mean Square Error: 0.0168\n",
      "Mean Square Error: 0.0003\n",
      "\n",
      "Train RMSE: 0.017\n",
      "Train MSE: 0.000\n",
      "Train MAE: 0.008\n",
      "###########################\n",
      "\n",
      "MODEL:  DNN\n",
      "sequence:  3h\n",
      "units:  12\n",
      "dropout1:  0.48476373451509647\n",
      "optimizer: adam\n",
      "activationDense: sigmoid\n",
      "epochs: 52\n",
      "batchsize: 57\n",
      "validation_split: 0.1\n",
      "Model: \"sequential_44\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_132 (Dense)            (None, 18, 12)            24        \n",
      "_________________________________________________________________\n",
      "dense_133 (Dense)            (None, 18, 16)            208       \n",
      "_________________________________________________________________\n",
      "dropout_44 (Dropout)         (None, 18, 16)            0         \n",
      "_________________________________________________________________\n",
      "dense_134 (Dense)            (None, 18, 1)             17        \n",
      "=================================================================\n",
      "Total params: 249\n",
      "Trainable params: 249\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/52\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.0548 - val_loss: 0.0476\n",
      "Epoch 2/52\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0468 - val_loss: 0.0439\n",
      "Epoch 3/52\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0441 - val_loss: 0.0421\n",
      "Epoch 4/52\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0419 - val_loss: 0.0370\n",
      "Epoch 5/52\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0401 - val_loss: 0.0327\n",
      "Epoch 6/52\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0385 - val_loss: 0.0321\n",
      "Epoch 7/52\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0374 - val_loss: 0.0315\n",
      "Epoch 8/52\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0361 - val_loss: 0.0307\n",
      "Epoch 9/52\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0350 - val_loss: 0.0266\n",
      "Epoch 10/52\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0343 - val_loss: 0.0260\n",
      "Epoch 11/52\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0336 - val_loss: 0.0263\n",
      "Epoch 12/52\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0327 - val_loss: 0.0253\n",
      "Epoch 13/52\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0321 - val_loss: 0.0244\n",
      "Epoch 14/52\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0315 - val_loss: 0.0238\n",
      "Epoch 15/52\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0310 - val_loss: 0.0228\n",
      "Epoch 16/52\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0306 - val_loss: 0.0221\n",
      "Epoch 17/52\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0302 - val_loss: 0.0218\n",
      "Epoch 18/52\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0298 - val_loss: 0.0207\n",
      "Epoch 19/52\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0295 - val_loss: 0.0202\n",
      "Epoch 20/52\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0292 - val_loss: 0.0196\n",
      "Epoch 21/52\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0289 - val_loss: 0.0191\n",
      "Epoch 22/52\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0285 - val_loss: 0.0185\n",
      "Epoch 23/52\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0282 - val_loss: 0.0180\n",
      "Epoch 24/52\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0279 - val_loss: 0.0173\n",
      "Epoch 25/52\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0278 - val_loss: 0.0169\n",
      "Epoch 26/52\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0274 - val_loss: 0.0162\n",
      "Epoch 27/52\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0272 - val_loss: 0.0157\n",
      "Epoch 28/52\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0270 - val_loss: 0.0153\n",
      "Epoch 29/52\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0267 - val_loss: 0.0147\n",
      "Epoch 30/52\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0265 - val_loss: 0.0144\n",
      "Epoch 31/52\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0263 - val_loss: 0.0138\n",
      "Epoch 32/52\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0262 - val_loss: 0.0136\n",
      "Epoch 33/52\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0260 - val_loss: 0.0132\n",
      "Epoch 34/52\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0258 - val_loss: 0.0129\n",
      "Epoch 35/52\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0256 - val_loss: 0.0127\n",
      "Epoch 36/52\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0254 - val_loss: 0.0127\n",
      "Epoch 37/52\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0253 - val_loss: 0.0124\n",
      "Epoch 38/52\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0252 - val_loss: 0.0127\n",
      "Epoch 39/52\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0250 - val_loss: 0.0123\n",
      "Epoch 40/52\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0249 - val_loss: 0.0124\n",
      "Epoch 41/52\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0246 - val_loss: 0.0121\n",
      "Epoch 42/52\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0244 - val_loss: 0.0121\n",
      "Epoch 43/52\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0242 - val_loss: 0.0124\n",
      "Epoch 44/52\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0239 - val_loss: 0.0121\n",
      "Epoch 45/52\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0238 - val_loss: 0.0125\n",
      "Epoch 46/52\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0235 - val_loss: 0.0125\n",
      "Epoch 47/52\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0232 - val_loss: 0.0123\n",
      "Epoch 48/52\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0232 - val_loss: 0.0124\n",
      "Epoch 49/52\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0230 - val_loss: 0.0123\n",
      "Epoch 50/52\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0229 - val_loss: 0.0120\n",
      "Epoch 51/52\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0227 - val_loss: 0.0123\n",
      "Epoch 52/52\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0224 - val_loss: 0.0121\n",
      "Execution time:  7.899348974227905\n",
      "DNN:\n",
      "Mean Absolute Error: 0.0188\n",
      "Root Mean Square Error: 0.0325\n",
      "Mean Square Error: 0.0011\n",
      "\n",
      "Train RMSE: 0.032\n",
      "Train MSE: 0.001\n",
      "Train MAE: 0.019\n",
      "###########################\n",
      "\n",
      "MODEL:  DNN\n",
      "sequence:  3h\n",
      "units:  87\n",
      "dropout1:  0.40519643149940265\n",
      "optimizer: adam\n",
      "activationDense: sigmoid\n",
      "epochs: 80\n",
      "batchsize: 31\n",
      "validation_split: 0.2\n",
      "Model: \"sequential_45\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_135 (Dense)            (None, 18, 87)            174       \n",
      "_________________________________________________________________\n",
      "dense_136 (Dense)            (None, 18, 16)            1408      \n",
      "_________________________________________________________________\n",
      "dropout_45 (Dropout)         (None, 18, 16)            0         \n",
      "_________________________________________________________________\n",
      "dense_137 (Dense)            (None, 18, 1)             17        \n",
      "=================================================================\n",
      "Total params: 1,599\n",
      "Trainable params: 1,599\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/80\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "103/103 [==============================] - 0s 4ms/step - loss: 0.0475 - val_loss: 0.0247\n",
      "Epoch 2/80\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.0437 - val_loss: 0.0241\n",
      "Epoch 3/80\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.0417 - val_loss: 0.0239\n",
      "Epoch 4/80\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.0399 - val_loss: 0.0239\n",
      "Epoch 5/80\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.0385 - val_loss: 0.0228\n",
      "Epoch 6/80\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.0374 - val_loss: 0.0225\n",
      "Epoch 7/80\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.0362 - val_loss: 0.0220\n",
      "Epoch 8/80\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.0352 - val_loss: 0.0211\n",
      "Epoch 9/80\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.0343 - val_loss: 0.0171\n",
      "Epoch 10/80\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.0345 - val_loss: 0.0177\n",
      "Epoch 11/80\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.0336 - val_loss: 0.0197\n",
      "Epoch 12/80\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.0323 - val_loss: 0.0195\n",
      "Epoch 13/80\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.0318 - val_loss: 0.0186\n",
      "Epoch 14/80\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.0315 - val_loss: 0.0185\n",
      "Epoch 15/80\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.0309 - val_loss: 0.0181\n",
      "Epoch 16/80\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.0304 - val_loss: 0.0175\n",
      "Epoch 17/80\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.0301 - val_loss: 0.0173\n",
      "Epoch 18/80\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.0297 - val_loss: 0.0168\n",
      "Epoch 19/80\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 0.0294 - val_loss: 0.0161\n",
      "Epoch 20/80\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.0290 - val_loss: 0.0159\n",
      "Epoch 21/80\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.0286 - val_loss: 0.0155\n",
      "Epoch 22/80\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.0284 - val_loss: 0.0152\n",
      "Epoch 23/80\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.0282 - val_loss: 0.0149\n",
      "Epoch 24/80\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.0278 - val_loss: 0.0145\n",
      "Epoch 25/80\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.0277 - val_loss: 0.0144\n",
      "Epoch 26/80\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.0275 - val_loss: 0.0142\n",
      "Epoch 27/80\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.0272 - val_loss: 0.0141\n",
      "Epoch 28/80\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.0268 - val_loss: 0.0141\n",
      "Epoch 29/80\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.0265 - val_loss: 0.0141\n",
      "Epoch 30/80\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.0263 - val_loss: 0.0140\n",
      "Epoch 31/80\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.0260 - val_loss: 0.0142\n",
      "Epoch 32/80\n",
      "103/103 [==============================] - ETA: 0s - loss: 0.027 - 0s 2ms/step - loss: 0.0258 - val_loss: 0.0142\n",
      "Epoch 33/80\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.0257 - val_loss: 0.0142\n",
      "Epoch 34/80\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.0255 - val_loss: 0.0142\n",
      "Epoch 35/80\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.0252 - val_loss: 0.0142\n",
      "Epoch 36/80\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.0250 - val_loss: 0.0142\n",
      "Epoch 37/80\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.0248 - val_loss: 0.0144\n",
      "Epoch 38/80\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.0245 - val_loss: 0.0144\n",
      "Epoch 39/80\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.0242 - val_loss: 0.0143\n",
      "Epoch 40/80\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.0240 - val_loss: 0.0143\n",
      "Epoch 41/80\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.0237 - val_loss: 0.0143\n",
      "Epoch 42/80\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.0234 - val_loss: 0.0143\n",
      "Epoch 43/80\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.0231 - val_loss: 0.0143\n",
      "Epoch 44/80\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.0229 - val_loss: 0.0142\n",
      "Epoch 45/80\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.0223 - val_loss: 0.0138\n",
      "Epoch 46/80\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.0221 - val_loss: 0.0136\n",
      "Epoch 47/80\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.0217 - val_loss: 0.0137\n",
      "Epoch 48/80\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.0215 - val_loss: 0.0137\n",
      "Epoch 49/80\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.0214 - val_loss: 0.0137\n",
      "Epoch 50/80\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 0.0212 - val_loss: 0.0134\n",
      "Epoch 51/80\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.0208 - val_loss: 0.0136\n",
      "Epoch 52/80\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.0207 - val_loss: 0.0137\n",
      "Epoch 53/80\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 0.0206 - val_loss: 0.0136\n",
      "Epoch 54/80\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 0.0206 - val_loss: 0.0132\n",
      "Epoch 55/80\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 0.0205 - val_loss: 0.0137\n",
      "Epoch 56/80\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 0.0204 - val_loss: 0.0141\n",
      "Epoch 57/80\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 0.0202 - val_loss: 0.0141\n",
      "Epoch 58/80\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.0200 - val_loss: 0.0140\n",
      "Epoch 59/80\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.0201 - val_loss: 0.0140\n",
      "Epoch 60/80\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.0199 - val_loss: 0.0142\n",
      "Epoch 61/80\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.0199 - val_loss: 0.0141\n",
      "Epoch 62/80\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.0198 - val_loss: 0.0139\n",
      "Epoch 63/80\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.0198 - val_loss: 0.0140\n",
      "Epoch 64/80\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.0198 - val_loss: 0.0141\n",
      "Epoch 65/80\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.0199 - val_loss: 0.0137\n",
      "Epoch 66/80\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.0198 - val_loss: 0.0140\n",
      "Epoch 67/80\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.0199 - val_loss: 0.0142\n",
      "Epoch 68/80\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.0199 - val_loss: 0.0140\n",
      "Epoch 69/80\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.0199 - val_loss: 0.0140\n",
      "Epoch 70/80\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.0198 - val_loss: 0.0137\n",
      "Epoch 71/80\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.0198 - val_loss: 0.0140\n",
      "Epoch 72/80\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.0199 - val_loss: 0.0139\n",
      "Epoch 73/80\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.0199 - val_loss: 0.0140\n",
      "Epoch 74/80\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 0.0199 - val_loss: 0.0134\n",
      "Epoch 75/80\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.0197 - val_loss: 0.0136\n",
      "Epoch 76/80\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.0198 - val_loss: 0.0135\n",
      "Epoch 77/80\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.0198 - val_loss: 0.0134\n",
      "Epoch 78/80\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.0198 - val_loss: 0.0136\n",
      "Epoch 79/80\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 0.0198 - val_loss: 0.0128\n",
      "Epoch 80/80\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.0198 - val_loss: 0.0143\n",
      "Execution time:  20.633455991744995\n",
      "DNN:\n",
      "Mean Absolute Error: 0.0129\n",
      "Root Mean Square Error: 0.0278\n",
      "Mean Square Error: 0.0008\n",
      "\n",
      "Train RMSE: 0.028\n",
      "Train MSE: 0.001\n",
      "Train MAE: 0.013\n",
      "###########################\n",
      "\n",
      "MODEL:  DNN\n",
      "sequence:  3h\n",
      "units:  80\n",
      "dropout1:  0.11814836227952394\n",
      "optimizer: adam\n",
      "activationDense: sigmoid\n",
      "epochs: 90\n",
      "batchsize: 25\n",
      "validation_split: 0.2\n",
      "Model: \"sequential_46\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_138 (Dense)            (None, 18, 80)            160       \n",
      "_________________________________________________________________\n",
      "dense_139 (Dense)            (None, 18, 16)            1296      \n",
      "_________________________________________________________________\n",
      "dropout_46 (Dropout)         (None, 18, 16)            0         \n",
      "_________________________________________________________________\n",
      "dense_140 (Dense)            (None, 18, 1)             17        \n",
      "=================================================================\n",
      "Total params: 1,473\n",
      "Trainable params: 1,473\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/90\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "128/128 [==============================] - 0s 4ms/step - loss: 0.0384 - val_loss: 0.0183\n",
      "Epoch 2/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0388 - val_loss: 0.0192\n",
      "Epoch 3/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0387 - val_loss: 0.0180\n",
      "Epoch 4/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0377 - val_loss: 0.0185\n",
      "Epoch 5/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0374 - val_loss: 0.0175\n",
      "Epoch 6/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0363 - val_loss: 0.0173\n",
      "Epoch 7/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0357 - val_loss: 0.0170\n",
      "Epoch 8/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0348 - val_loss: 0.0168\n",
      "Epoch 9/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0342 - val_loss: 0.0166\n",
      "Epoch 10/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0337 - val_loss: 0.0168\n",
      "Epoch 11/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0330 - val_loss: 0.0169\n",
      "Epoch 12/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0325 - val_loss: 0.0167\n",
      "Epoch 13/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0323 - val_loss: 0.0166\n",
      "Epoch 14/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0318 - val_loss: 0.0165\n",
      "Epoch 15/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0315 - val_loss: 0.0164\n",
      "Epoch 16/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0312 - val_loss: 0.0166\n",
      "Epoch 17/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0308 - val_loss: 0.0164\n",
      "Epoch 18/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0306 - val_loss: 0.0164\n",
      "Epoch 19/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0303 - val_loss: 0.0162\n",
      "Epoch 20/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0301 - val_loss: 0.0161\n",
      "Epoch 21/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0298 - val_loss: 0.0159\n",
      "Epoch 22/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0296 - val_loss: 0.0156\n",
      "Epoch 23/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0294 - val_loss: 0.0153\n",
      "Epoch 24/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0291 - val_loss: 0.0149\n",
      "Epoch 25/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0289 - val_loss: 0.0148\n",
      "Epoch 26/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0290 - val_loss: 0.0148\n",
      "Epoch 27/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0283 - val_loss: 0.0145\n",
      "Epoch 28/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0277 - val_loss: 0.0143\n",
      "Epoch 29/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0271 - val_loss: 0.0142\n",
      "Epoch 30/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0268 - val_loss: 0.0139\n",
      "Epoch 31/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0261 - val_loss: 0.0138\n",
      "Epoch 32/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0253 - val_loss: 0.0137\n",
      "Epoch 33/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0247 - val_loss: 0.0134\n",
      "Epoch 34/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0240 - val_loss: 0.0131\n",
      "Epoch 35/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0234 - val_loss: 0.0129\n",
      "Epoch 36/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0228 - val_loss: 0.0126\n",
      "Epoch 37/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0218 - val_loss: 0.0122\n",
      "Epoch 38/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0216 - val_loss: 0.0121\n",
      "Epoch 39/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0204 - val_loss: 0.0118\n",
      "Epoch 40/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0196 - val_loss: 0.0119\n",
      "Epoch 41/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0190 - val_loss: 0.0122\n",
      "Epoch 42/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0185 - val_loss: 0.0119\n",
      "Epoch 43/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0177 - val_loss: 0.0121\n",
      "Epoch 44/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0174 - val_loss: 0.0121\n",
      "Epoch 45/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0171 - val_loss: 0.0119\n",
      "Epoch 46/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0166 - val_loss: 0.0108\n",
      "Epoch 47/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0164 - val_loss: 0.0106\n",
      "Epoch 48/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0162 - val_loss: 0.0112\n",
      "Epoch 49/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0160 - val_loss: 0.0115\n",
      "Epoch 50/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0160 - val_loss: 0.0104\n",
      "Epoch 51/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0160 - val_loss: 0.0106\n",
      "Epoch 52/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0159 - val_loss: 0.0108\n",
      "Epoch 53/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0159 - val_loss: 0.0104\n",
      "Epoch 54/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0159 - val_loss: 0.0103\n",
      "Epoch 55/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0159 - val_loss: 0.0110\n",
      "Epoch 56/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0159 - val_loss: 0.0109\n",
      "Epoch 57/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0158 - val_loss: 0.0104\n",
      "Epoch 58/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0160 - val_loss: 0.0117\n",
      "Epoch 59/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0158 - val_loss: 0.0106\n",
      "Epoch 60/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0159 - val_loss: 0.0109\n",
      "Epoch 61/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0158 - val_loss: 0.0109\n",
      "Epoch 62/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0158 - val_loss: 0.0106\n",
      "Epoch 63/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0158 - val_loss: 0.0108\n",
      "Epoch 64/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0158 - val_loss: 0.0106\n",
      "Epoch 65/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0158 - val_loss: 0.0110\n",
      "Epoch 66/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0158 - val_loss: 0.0109\n",
      "Epoch 67/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0158 - val_loss: 0.0106\n",
      "Epoch 68/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0158 - val_loss: 0.0104\n",
      "Epoch 69/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0159 - val_loss: 0.0111\n",
      "Epoch 70/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0158 - val_loss: 0.0106\n",
      "Epoch 71/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0158 - val_loss: 0.0104\n",
      "Epoch 72/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0158 - val_loss: 0.0111\n",
      "Epoch 73/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0158 - val_loss: 0.0108\n",
      "Epoch 74/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0157 - val_loss: 0.0105\n",
      "Epoch 75/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0158 - val_loss: 0.0109\n",
      "Epoch 76/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0157 - val_loss: 0.0106\n",
      "Epoch 77/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0157 - val_loss: 0.0103\n",
      "Epoch 78/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0158 - val_loss: 0.0107\n",
      "Epoch 79/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0158 - val_loss: 0.0106\n",
      "Epoch 80/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0156 - val_loss: 0.0104\n",
      "Epoch 81/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0158 - val_loss: 0.0111\n",
      "Epoch 82/90\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0157 - val_loss: 0.0104\n",
      "Epoch 83/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0158 - val_loss: 0.0108\n",
      "Epoch 84/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0158 - val_loss: 0.0102\n",
      "Epoch 85/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0157 - val_loss: 0.0104\n",
      "Epoch 86/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0157 - val_loss: 0.0106\n",
      "Epoch 87/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0157 - val_loss: 0.0105\n",
      "Epoch 88/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0157 - val_loss: 0.0108\n",
      "Epoch 89/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0158 - val_loss: 0.0105\n",
      "Epoch 90/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0158 - val_loss: 0.0110\n",
      "Execution time:  25.066622257232666\n",
      "DNN:\n",
      "Mean Absolute Error: 0.0082\n",
      "Root Mean Square Error: 0.0238\n",
      "Mean Square Error: 0.0006\n",
      "\n",
      "Train RMSE: 0.024\n",
      "Train MSE: 0.001\n",
      "Train MAE: 0.008\n",
      "###########################\n",
      "\n",
      "MODEL:  DNN\n",
      "sequence:  3h\n",
      "units:  12\n",
      "dropout1:  0.48476373451509647\n",
      "optimizer: adam\n",
      "activationDense: sigmoid\n",
      "epochs: 52\n",
      "batchsize: 57\n",
      "validation_split: 0.2\n",
      "Model: \"sequential_47\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_141 (Dense)            (None, 18, 12)            24        \n",
      "_________________________________________________________________\n",
      "dense_142 (Dense)            (None, 18, 16)            208       \n",
      "_________________________________________________________________\n",
      "dropout_47 (Dropout)         (None, 18, 16)            0         \n",
      "_________________________________________________________________\n",
      "dense_143 (Dense)            (None, 18, 1)             17        \n",
      "=================================================================\n",
      "Total params: 249\n",
      "Trainable params: 249\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/52\n",
      "56/56 [==============================] - 0s 5ms/step - loss: 0.0582 - val_loss: 0.0473\n",
      "Epoch 2/52\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 0.0453 - val_loss: 0.0404\n",
      "Epoch 3/52\n",
      "56/56 [==============================] - 0s 2ms/step - loss: 0.0435 - val_loss: 0.0380\n",
      "Epoch 4/52\n",
      "56/56 [==============================] - 0s 2ms/step - loss: 0.0416 - val_loss: 0.0363\n",
      "Epoch 5/52\n",
      "56/56 [==============================] - 0s 2ms/step - loss: 0.0402 - val_loss: 0.0348\n",
      "Epoch 6/52\n",
      "56/56 [==============================] - 0s 2ms/step - loss: 0.0391 - val_loss: 0.0343\n",
      "Epoch 7/52\n",
      "56/56 [==============================] - 0s 2ms/step - loss: 0.0381 - val_loss: 0.0326\n",
      "Epoch 8/52\n",
      "56/56 [==============================] - 0s 2ms/step - loss: 0.0373 - val_loss: 0.0317\n",
      "Epoch 9/52\n",
      "56/56 [==============================] - 0s 2ms/step - loss: 0.0368 - val_loss: 0.0306\n",
      "Epoch 10/52\n",
      "56/56 [==============================] - 0s 2ms/step - loss: 0.0360 - val_loss: 0.0298\n",
      "Epoch 11/52\n",
      "56/56 [==============================] - 0s 2ms/step - loss: 0.0353 - val_loss: 0.0290\n",
      "Epoch 12/52\n",
      "56/56 [==============================] - 0s 2ms/step - loss: 0.0346 - val_loss: 0.0283\n",
      "Epoch 13/52\n",
      "56/56 [==============================] - 0s 2ms/step - loss: 0.0343 - val_loss: 0.0277\n",
      "Epoch 14/52\n",
      "56/56 [==============================] - 0s 2ms/step - loss: 0.0339 - val_loss: 0.0272\n",
      "Epoch 15/52\n",
      "56/56 [==============================] - 0s 2ms/step - loss: 0.0334 - val_loss: 0.0269\n",
      "Epoch 16/52\n",
      "56/56 [==============================] - 0s 2ms/step - loss: 0.0329 - val_loss: 0.0264\n",
      "Epoch 17/52\n",
      "56/56 [==============================] - 0s 2ms/step - loss: 0.0325 - val_loss: 0.0260\n",
      "Epoch 18/52\n",
      "56/56 [==============================] - 0s 2ms/step - loss: 0.0322 - val_loss: 0.0258\n",
      "Epoch 19/52\n",
      "56/56 [==============================] - 0s 2ms/step - loss: 0.0316 - val_loss: 0.0252\n",
      "Epoch 20/52\n",
      "56/56 [==============================] - 0s 2ms/step - loss: 0.0316 - val_loss: 0.0252\n",
      "Epoch 21/52\n",
      "56/56 [==============================] - 0s 2ms/step - loss: 0.0310 - val_loss: 0.0245\n",
      "Epoch 22/52\n",
      "56/56 [==============================] - 0s 2ms/step - loss: 0.0307 - val_loss: 0.0240\n",
      "Epoch 23/52\n",
      "56/56 [==============================] - 0s 2ms/step - loss: 0.0305 - val_loss: 0.0238\n",
      "Epoch 24/52\n",
      "56/56 [==============================] - 0s 2ms/step - loss: 0.0301 - val_loss: 0.0233\n",
      "Epoch 25/52\n",
      "56/56 [==============================] - 0s 2ms/step - loss: 0.0299 - val_loss: 0.0229\n",
      "Epoch 26/52\n",
      "56/56 [==============================] - 0s 2ms/step - loss: 0.0296 - val_loss: 0.0224\n",
      "Epoch 27/52\n",
      "56/56 [==============================] - 0s 2ms/step - loss: 0.0295 - val_loss: 0.0222\n",
      "Epoch 28/52\n",
      "56/56 [==============================] - 0s 2ms/step - loss: 0.0292 - val_loss: 0.0218\n",
      "Epoch 29/52\n",
      "56/56 [==============================] - 0s 2ms/step - loss: 0.0290 - val_loss: 0.0215\n",
      "Epoch 30/52\n",
      "56/56 [==============================] - 0s 2ms/step - loss: 0.0290 - val_loss: 0.0213\n",
      "Epoch 31/52\n",
      "56/56 [==============================] - 0s 2ms/step - loss: 0.0288 - val_loss: 0.0211\n",
      "Epoch 32/52\n",
      "56/56 [==============================] - 0s 2ms/step - loss: 0.0285 - val_loss: 0.0207\n",
      "Epoch 33/52\n",
      "56/56 [==============================] - 0s 2ms/step - loss: 0.0284 - val_loss: 0.0205\n",
      "Epoch 34/52\n",
      "56/56 [==============================] - 0s 2ms/step - loss: 0.0283 - val_loss: 0.0203\n",
      "Epoch 35/52\n",
      "56/56 [==============================] - 0s 2ms/step - loss: 0.0281 - val_loss: 0.0200\n",
      "Epoch 36/52\n",
      "56/56 [==============================] - 0s 2ms/step - loss: 0.0280 - val_loss: 0.0197\n",
      "Epoch 37/52\n",
      "56/56 [==============================] - 0s 2ms/step - loss: 0.0278 - val_loss: 0.0194\n",
      "Epoch 38/52\n",
      "56/56 [==============================] - 0s 2ms/step - loss: 0.0277 - val_loss: 0.0191\n",
      "Epoch 39/52\n",
      "56/56 [==============================] - 0s 2ms/step - loss: 0.0276 - val_loss: 0.0189\n",
      "Epoch 40/52\n",
      "56/56 [==============================] - 0s 2ms/step - loss: 0.0275 - val_loss: 0.0186\n",
      "Epoch 41/52\n",
      "56/56 [==============================] - 0s 2ms/step - loss: 0.0273 - val_loss: 0.0184\n",
      "Epoch 42/52\n",
      "56/56 [==============================] - 0s 2ms/step - loss: 0.0273 - val_loss: 0.0182\n",
      "Epoch 43/52\n",
      "56/56 [==============================] - 0s 2ms/step - loss: 0.0272 - val_loss: 0.0180\n",
      "Epoch 44/52\n",
      "56/56 [==============================] - 0s 2ms/step - loss: 0.0271 - val_loss: 0.0178\n",
      "Epoch 45/52\n",
      "56/56 [==============================] - 0s 2ms/step - loss: 0.0270 - val_loss: 0.0176\n",
      "Epoch 46/52\n",
      "56/56 [==============================] - 0s 2ms/step - loss: 0.0269 - val_loss: 0.0174\n",
      "Epoch 47/52\n",
      "56/56 [==============================] - 0s 2ms/step - loss: 0.0269 - val_loss: 0.0172\n",
      "Epoch 48/52\n",
      "56/56 [==============================] - 0s 2ms/step - loss: 0.0268 - val_loss: 0.0170\n",
      "Epoch 49/52\n",
      "56/56 [==============================] - 0s 2ms/step - loss: 0.0268 - val_loss: 0.0170\n",
      "Epoch 50/52\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 0.0267 - val_loss: 0.0168\n",
      "Epoch 51/52\n",
      "56/56 [==============================] - 0s 2ms/step - loss: 0.0266 - val_loss: 0.0166\n",
      "Epoch 52/52\n",
      "56/56 [==============================] - 0s 2ms/step - loss: 0.0265 - val_loss: 0.0165\n",
      "Execution time:  7.578886032104492\n",
      "DNN:\n",
      "Mean Absolute Error: 0.0232\n",
      "Root Mean Square Error: 0.0398\n",
      "Mean Square Error: 0.0016\n",
      "\n",
      "Train RMSE: 0.040\n",
      "Train MSE: 0.002\n",
      "Train MAE: 0.023\n",
      "###########################\n",
      "\n",
      "MODEL:  DNN\n",
      "sequence:  3h\n",
      "units:  87\n",
      "dropout1:  0.40519643149940265\n",
      "optimizer: adadelta\n",
      "activationDense: tanh\n",
      "epochs: 80\n",
      "batchsize: 31\n",
      "validation_split: 0.1\n",
      "Model: \"sequential_48\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_144 (Dense)            (None, 18, 87)            174       \n",
      "_________________________________________________________________\n",
      "dense_145 (Dense)            (None, 18, 16)            1408      \n",
      "_________________________________________________________________\n",
      "dropout_48 (Dropout)         (None, 18, 16)            0         \n",
      "_________________________________________________________________\n",
      "dense_146 (Dense)            (None, 18, 1)             17        \n",
      "=================================================================\n",
      "Total params: 1,599\n",
      "Trainable params: 1,599\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/80\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "116/116 [==============================] - 0s 4ms/step - loss: 0.4326 - val_loss: 0.3923\n",
      "Epoch 2/80\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.4296 - val_loss: 0.3894\n",
      "Epoch 3/80\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.4264 - val_loss: 0.3862\n",
      "Epoch 4/80\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.4229 - val_loss: 0.3828\n",
      "Epoch 5/80\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.4192 - val_loss: 0.3791\n",
      "Epoch 6/80\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.4153 - val_loss: 0.3753\n",
      "Epoch 7/80\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.4112 - val_loss: 0.3712\n",
      "Epoch 8/80\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.4069 - val_loss: 0.3670\n",
      "Epoch 9/80\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.4027 - val_loss: 0.3627\n",
      "Epoch 10/80\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.3978 - val_loss: 0.3582\n",
      "Epoch 11/80\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.3931 - val_loss: 0.3535\n",
      "Epoch 12/80\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.3883 - val_loss: 0.3488\n",
      "Epoch 13/80\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.3830 - val_loss: 0.3441\n",
      "Epoch 14/80\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.3783 - val_loss: 0.3395\n",
      "Epoch 15/80\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.3736 - val_loss: 0.3349\n",
      "Epoch 16/80\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.3686 - val_loss: 0.3302\n",
      "Epoch 17/80\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.3636 - val_loss: 0.3254\n",
      "Epoch 18/80\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.3584 - val_loss: 0.3205\n",
      "Epoch 19/80\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.3537 - val_loss: 0.3160\n",
      "Epoch 20/80\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.3489 - val_loss: 0.3114\n",
      "Epoch 21/80\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.3441 - val_loss: 0.3077\n",
      "Epoch 22/80\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.3402 - val_loss: 0.3046\n",
      "Epoch 23/80\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.3365 - val_loss: 0.3014\n",
      "Epoch 24/80\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.3333 - val_loss: 0.2982\n",
      "Epoch 25/80\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.3296 - val_loss: 0.2949\n",
      "Epoch 26/80\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.3263 - val_loss: 0.2916\n",
      "Epoch 27/80\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.3224 - val_loss: 0.2881\n",
      "Epoch 28/80\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.3190 - val_loss: 0.2846\n",
      "Epoch 29/80\n",
      "116/116 [==============================] - 0s 3ms/step - loss: 0.3154 - val_loss: 0.2809\n",
      "Epoch 30/80\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.3115 - val_loss: 0.2772\n",
      "Epoch 31/80\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.3078 - val_loss: 0.2735\n",
      "Epoch 32/80\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.3038 - val_loss: 0.2696\n",
      "Epoch 33/80\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.2995 - val_loss: 0.2656\n",
      "Epoch 34/80\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.2952 - val_loss: 0.2615\n",
      "Epoch 35/80\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.2910 - val_loss: 0.2573\n",
      "Epoch 36/80\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.2867 - val_loss: 0.2530\n",
      "Epoch 37/80\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.2819 - val_loss: 0.2486\n",
      "Epoch 38/80\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.2772 - val_loss: 0.2441\n",
      "Epoch 39/80\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.2732 - val_loss: 0.2394\n",
      "Epoch 40/80\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.2678 - val_loss: 0.2347\n",
      "Epoch 41/80\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.2630 - val_loss: 0.2298\n",
      "Epoch 42/80\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.2582 - val_loss: 0.2248\n",
      "Epoch 43/80\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.2531 - val_loss: 0.2197\n",
      "Epoch 44/80\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.2484 - val_loss: 0.2145\n",
      "Epoch 45/80\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.2425 - val_loss: 0.2091\n",
      "Epoch 46/80\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.2366 - val_loss: 0.2036\n",
      "Epoch 47/80\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.2306 - val_loss: 0.1980\n",
      "Epoch 48/80\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.2250 - val_loss: 0.1922\n",
      "Epoch 49/80\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.2199 - val_loss: 0.1863\n",
      "Epoch 50/80\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.2135 - val_loss: 0.1802\n",
      "Epoch 51/80\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.2069 - val_loss: 0.1740\n",
      "Epoch 52/80\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.2007 - val_loss: 0.1677\n",
      "Epoch 53/80\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.1942 - val_loss: 0.1612\n",
      "Epoch 54/80\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.1876 - val_loss: 0.1546\n",
      "Epoch 55/80\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.1822 - val_loss: 0.1478\n",
      "Epoch 56/80\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.1748 - val_loss: 0.1409\n",
      "Epoch 57/80\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.1676 - val_loss: 0.1340\n",
      "Epoch 58/80\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.1610 - val_loss: 0.1273\n",
      "Epoch 59/80\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.1565 - val_loss: 0.1222\n",
      "Epoch 60/80\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.1536 - val_loss: 0.1179\n",
      "Epoch 61/80\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.1515 - val_loss: 0.1143\n",
      "Epoch 62/80\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.1495 - val_loss: 0.1110\n",
      "Epoch 63/80\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.1474 - val_loss: 0.1082\n",
      "Epoch 64/80\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.1451 - val_loss: 0.1056\n",
      "Epoch 65/80\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.1451 - val_loss: 0.1032\n",
      "Epoch 66/80\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.1431 - val_loss: 0.1010\n",
      "Epoch 67/80\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.1426 - val_loss: 0.0989\n",
      "Epoch 68/80\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.1421 - val_loss: 0.0970\n",
      "Epoch 69/80\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.1422 - val_loss: 0.0951\n",
      "Epoch 70/80\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.1400 - val_loss: 0.0933\n",
      "Epoch 71/80\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.1397 - val_loss: 0.0916\n",
      "Epoch 72/80\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.1397 - val_loss: 0.0902\n",
      "Epoch 73/80\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.1380 - val_loss: 0.0890\n",
      "Epoch 74/80\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.1374 - val_loss: 0.0879\n",
      "Epoch 75/80\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.1385 - val_loss: 0.0868\n",
      "Epoch 76/80\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.1374 - val_loss: 0.0857\n",
      "Epoch 77/80\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.1365 - val_loss: 0.0847\n",
      "Epoch 78/80\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.1365 - val_loss: 0.0837\n",
      "Epoch 79/80\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.1368 - val_loss: 0.0828\n",
      "Epoch 80/80\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.1356 - val_loss: 0.0819\n",
      "Execution time:  21.224387168884277\n",
      "DNN:\n",
      "Mean Absolute Error: 0.1045\n",
      "Root Mean Square Error: 0.1084\n",
      "Mean Square Error: 0.0117\n",
      "\n",
      "Train RMSE: 0.108\n",
      "Train MSE: 0.012\n",
      "Train MAE: 0.105\n",
      "###########################\n",
      "\n",
      "MODEL:  DNN\n",
      "sequence:  3h\n",
      "units:  80\n",
      "dropout1:  0.11814836227952394\n",
      "optimizer: adadelta\n",
      "activationDense: tanh\n",
      "epochs: 90\n",
      "batchsize: 25\n",
      "validation_split: 0.1\n",
      "Model: \"sequential_49\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_147 (Dense)            (None, 18, 80)            160       \n",
      "_________________________________________________________________\n",
      "dense_148 (Dense)            (None, 18, 16)            1296      \n",
      "_________________________________________________________________\n",
      "dropout_49 (Dropout)         (None, 18, 16)            0         \n",
      "_________________________________________________________________\n",
      "dense_149 (Dense)            (None, 18, 1)             17        \n",
      "=================================================================\n",
      "Total params: 1,473\n",
      "Trainable params: 1,473\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/90\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "143/143 [==============================] - 0s 3ms/step - loss: 0.3116 - val_loss: 0.2811\n",
      "Epoch 2/90\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.3065 - val_loss: 0.2756\n",
      "Epoch 3/90\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.3005 - val_loss: 0.2696\n",
      "Epoch 4/90\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.2939 - val_loss: 0.2631\n",
      "Epoch 5/90\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.2868 - val_loss: 0.2560\n",
      "Epoch 6/90\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.2791 - val_loss: 0.2484\n",
      "Epoch 7/90\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.2709 - val_loss: 0.2401\n",
      "Epoch 8/90\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.2621 - val_loss: 0.2317\n",
      "Epoch 9/90\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.2533 - val_loss: 0.2233\n",
      "Epoch 10/90\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.2444 - val_loss: 0.2146\n",
      "Epoch 11/90\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.2353 - val_loss: 0.2056\n",
      "Epoch 12/90\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.2256 - val_loss: 0.1963\n",
      "Epoch 13/90\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.2158 - val_loss: 0.1868\n",
      "Epoch 14/90\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.2055 - val_loss: 0.1770\n",
      "Epoch 15/90\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.1957 - val_loss: 0.1670\n",
      "Epoch 16/90\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.1851 - val_loss: 0.1567\n",
      "Epoch 17/90\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.1740 - val_loss: 0.1461\n",
      "Epoch 18/90\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.1634 - val_loss: 0.1359\n",
      "Epoch 19/90\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.1529 - val_loss: 0.1261\n",
      "Epoch 20/90\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.1428 - val_loss: 0.1167\n",
      "Epoch 21/90\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.1326 - val_loss: 0.1071\n",
      "Epoch 22/90\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.1226 - val_loss: 0.0973\n",
      "Epoch 23/90\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.1126 - val_loss: 0.0873\n",
      "Epoch 24/90\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.1026 - val_loss: 0.0772\n",
      "Epoch 25/90\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.0921 - val_loss: 0.0670\n",
      "Epoch 26/90\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.0818 - val_loss: 0.0568\n",
      "Epoch 27/90\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.0713 - val_loss: 0.0466\n",
      "Epoch 28/90\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.0618 - val_loss: 0.0369\n",
      "Epoch 29/90\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.0552 - val_loss: 0.0310\n",
      "Epoch 30/90\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.0525 - val_loss: 0.0272\n",
      "Epoch 31/90\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.0517 - val_loss: 0.0246\n",
      "Epoch 32/90\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.0503 - val_loss: 0.0228\n",
      "Epoch 33/90\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.0503 - val_loss: 0.0214\n",
      "Epoch 34/90\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.0499 - val_loss: 0.0203\n",
      "Epoch 35/90\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.0497 - val_loss: 0.0193\n",
      "Epoch 36/90\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.0494 - val_loss: 0.0183\n",
      "Epoch 37/90\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.0492 - val_loss: 0.0174\n",
      "Epoch 38/90\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.0489 - val_loss: 0.0167\n",
      "Epoch 39/90\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.0486 - val_loss: 0.0160\n",
      "Epoch 40/90\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.0484 - val_loss: 0.0154\n",
      "Epoch 41/90\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.0486 - val_loss: 0.0148\n",
      "Epoch 42/90\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.0483 - val_loss: 0.0143\n",
      "Epoch 43/90\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.0483 - val_loss: 0.0138\n",
      "Epoch 44/90\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.0486 - val_loss: 0.0133\n",
      "Epoch 45/90\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.0485 - val_loss: 0.0128\n",
      "Epoch 46/90\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.0484 - val_loss: 0.0124\n",
      "Epoch 47/90\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.0482 - val_loss: 0.0120\n",
      "Epoch 48/90\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.0481 - val_loss: 0.0117\n",
      "Epoch 49/90\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.0484 - val_loss: 0.0113\n",
      "Epoch 50/90\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.0478 - val_loss: 0.0110\n",
      "Epoch 51/90\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.0480 - val_loss: 0.0107\n",
      "Epoch 52/90\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.0479 - val_loss: 0.0104\n",
      "Epoch 53/90\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.0481 - val_loss: 0.0102\n",
      "Epoch 54/90\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.0481 - val_loss: 0.0099\n",
      "Epoch 55/90\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.0479 - val_loss: 0.0097\n",
      "Epoch 56/90\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.0483 - val_loss: 0.0094\n",
      "Epoch 57/90\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.0479 - val_loss: 0.0092\n",
      "Epoch 58/90\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.0482 - val_loss: 0.0090\n",
      "Epoch 59/90\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.0478 - val_loss: 0.0088\n",
      "Epoch 60/90\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.0478 - val_loss: 0.0086\n",
      "Epoch 61/90\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.0478 - val_loss: 0.0085\n",
      "Epoch 62/90\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.0476 - val_loss: 0.0083\n",
      "Epoch 63/90\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.0477 - val_loss: 0.0082\n",
      "Epoch 64/90\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.0477 - val_loss: 0.0081\n",
      "Epoch 65/90\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.0476 - val_loss: 0.0079\n",
      "Epoch 66/90\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.0477 - val_loss: 0.0078\n",
      "Epoch 67/90\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.0477 - val_loss: 0.0078\n",
      "Epoch 68/90\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.0484 - val_loss: 0.0077\n",
      "Epoch 69/90\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.0478 - val_loss: 0.0076\n",
      "Epoch 70/90\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.0477 - val_loss: 0.0075\n",
      "Epoch 71/90\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.0477 - val_loss: 0.0074\n",
      "Epoch 72/90\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.0475 - val_loss: 0.0074\n",
      "Epoch 73/90\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.0477 - val_loss: 0.0073\n",
      "Epoch 74/90\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.0477 - val_loss: 0.0072\n",
      "Epoch 75/90\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.0476 - val_loss: 0.0072\n",
      "Epoch 76/90\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.0478 - val_loss: 0.0071\n",
      "Epoch 77/90\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.0474 - val_loss: 0.0071\n",
      "Epoch 78/90\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.0476 - val_loss: 0.0071\n",
      "Epoch 79/90\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.0475 - val_loss: 0.0070\n",
      "Epoch 80/90\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.0477 - val_loss: 0.0070\n",
      "Epoch 81/90\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.0476 - val_loss: 0.0069\n",
      "Epoch 82/90\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "143/143 [==============================] - 0s 2ms/step - loss: 0.0475 - val_loss: 0.0069\n",
      "Epoch 83/90\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.0476 - val_loss: 0.0069\n",
      "Epoch 84/90\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.0476 - val_loss: 0.0069\n",
      "Epoch 85/90\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.0472 - val_loss: 0.0069\n",
      "Epoch 86/90\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.0474 - val_loss: 0.0068\n",
      "Epoch 87/90\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.0477 - val_loss: 0.0068\n",
      "Epoch 88/90\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.0474 - val_loss: 0.0068\n",
      "Epoch 89/90\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.0474 - val_loss: 0.0067\n",
      "Epoch 90/90\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.0472 - val_loss: 0.0067\n",
      "Execution time:  21.23253107070923\n",
      "DNN:\n",
      "Mean Absolute Error: 0.0203\n",
      "Root Mean Square Error: 0.0279\n",
      "Mean Square Error: 0.0008\n",
      "\n",
      "Train RMSE: 0.028\n",
      "Train MSE: 0.001\n",
      "Train MAE: 0.020\n",
      "###########################\n",
      "\n",
      "MODEL:  DNN\n",
      "sequence:  3h\n",
      "units:  12\n",
      "dropout1:  0.48476373451509647\n",
      "optimizer: adadelta\n",
      "activationDense: tanh\n",
      "epochs: 52\n",
      "batchsize: 57\n",
      "validation_split: 0.1\n",
      "Model: \"sequential_50\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_150 (Dense)            (None, 18, 12)            24        \n",
      "_________________________________________________________________\n",
      "dense_151 (Dense)            (None, 18, 16)            208       \n",
      "_________________________________________________________________\n",
      "dropout_50 (Dropout)         (None, 18, 16)            0         \n",
      "_________________________________________________________________\n",
      "dense_152 (Dense)            (None, 18, 1)             17        \n",
      "=================================================================\n",
      "Total params: 249\n",
      "Trainable params: 249\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/52\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.4140 - val_loss: 0.3765\n",
      "Epoch 2/52\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.4134 - val_loss: 0.3760\n",
      "Epoch 3/52\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.4127 - val_loss: 0.3754\n",
      "Epoch 4/52\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.4122 - val_loss: 0.3748\n",
      "Epoch 5/52\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.4114 - val_loss: 0.3742\n",
      "Epoch 6/52\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.4108 - val_loss: 0.3736\n",
      "Epoch 7/52\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.4102 - val_loss: 0.3729\n",
      "Epoch 8/52\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.4095 - val_loss: 0.3722\n",
      "Epoch 9/52\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.4087 - val_loss: 0.3715\n",
      "Epoch 10/52\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.4082 - val_loss: 0.3708\n",
      "Epoch 11/52\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.4072 - val_loss: 0.3700\n",
      "Epoch 12/52\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.4066 - val_loss: 0.3693\n",
      "Epoch 13/52\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.4058 - val_loss: 0.3685\n",
      "Epoch 14/52\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.4050 - val_loss: 0.3676\n",
      "Epoch 15/52\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.4042 - val_loss: 0.3668\n",
      "Epoch 16/52\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.4032 - val_loss: 0.3660\n",
      "Epoch 17/52\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.4022 - val_loss: 0.3651\n",
      "Epoch 18/52\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.4017 - val_loss: 0.3642\n",
      "Epoch 19/52\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.4007 - val_loss: 0.3633\n",
      "Epoch 20/52\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.3994 - val_loss: 0.3623\n",
      "Epoch 21/52\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.3983 - val_loss: 0.3614\n",
      "Epoch 22/52\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.3974 - val_loss: 0.3604\n",
      "Epoch 23/52\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.3964 - val_loss: 0.3595\n",
      "Epoch 24/52\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.3955 - val_loss: 0.3585\n",
      "Epoch 25/52\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.3946 - val_loss: 0.3574\n",
      "Epoch 26/52\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.3933 - val_loss: 0.3564\n",
      "Epoch 27/52\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.3923 - val_loss: 0.3554\n",
      "Epoch 28/52\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.3913 - val_loss: 0.3543\n",
      "Epoch 29/52\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.3899 - val_loss: 0.3532\n",
      "Epoch 30/52\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.3895 - val_loss: 0.3521\n",
      "Epoch 31/52\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.3880 - val_loss: 0.3510\n",
      "Epoch 32/52\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.3868 - val_loss: 0.3499\n",
      "Epoch 33/52\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.3856 - val_loss: 0.3488\n",
      "Epoch 34/52\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.3847 - val_loss: 0.3476\n",
      "Epoch 35/52\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.3834 - val_loss: 0.3465\n",
      "Epoch 36/52\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.3817 - val_loss: 0.3453\n",
      "Epoch 37/52\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.3810 - val_loss: 0.3441\n",
      "Epoch 38/52\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.3798 - val_loss: 0.3429\n",
      "Epoch 39/52\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.3786 - val_loss: 0.3417\n",
      "Epoch 40/52\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.3773 - val_loss: 0.3404\n",
      "Epoch 41/52\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.3760 - val_loss: 0.3392\n",
      "Epoch 42/52\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.3743 - val_loss: 0.3379\n",
      "Epoch 43/52\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.3735 - val_loss: 0.3366\n",
      "Epoch 44/52\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.3719 - val_loss: 0.3353\n",
      "Epoch 45/52\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.3707 - val_loss: 0.3340\n",
      "Epoch 46/52\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.3692 - val_loss: 0.3327\n",
      "Epoch 47/52\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.3679 - val_loss: 0.3314\n",
      "Epoch 48/52\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.3667 - val_loss: 0.3300\n",
      "Epoch 49/52\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.3654 - val_loss: 0.3287\n",
      "Epoch 50/52\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.3638 - val_loss: 0.3273\n",
      "Epoch 51/52\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.3625 - val_loss: 0.3260\n",
      "Epoch 52/52\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.3613 - val_loss: 0.3246\n",
      "Execution time:  7.709161043167114\n",
      "DNN:\n",
      "Mean Absolute Error: 0.3567\n",
      "Root Mean Square Error: 0.3590\n",
      "Mean Square Error: 0.1289\n",
      "\n",
      "Train RMSE: 0.359\n",
      "Train MSE: 0.129\n",
      "Train MAE: 0.357\n",
      "###########################\n",
      "\n",
      "MODEL:  DNN\n",
      "sequence:  3h\n",
      "units:  87\n",
      "dropout1:  0.40519643149940265\n",
      "optimizer: adadelta\n",
      "activationDense: tanh\n",
      "epochs: 80\n",
      "batchsize: 31\n",
      "validation_split: 0.2\n",
      "Model: \"sequential_51\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_153 (Dense)            (None, 18, 87)            174       \n",
      "_________________________________________________________________\n",
      "dense_154 (Dense)            (None, 18, 16)            1408      \n",
      "_________________________________________________________________\n",
      "dropout_51 (Dropout)         (None, 18, 16)            0         \n",
      "_________________________________________________________________\n",
      "dense_155 (Dense)            (None, 18, 1)             17        \n",
      "=================================================================\n",
      "Total params: 1,599\n",
      "Trainable params: 1,599\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/80\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "103/103 [==============================] - 0s 4ms/step - loss: 0.4200 - val_loss: 0.3957\n",
      "Epoch 2/80\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.4175 - val_loss: 0.3930\n",
      "Epoch 3/80\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.4143 - val_loss: 0.3900\n",
      "Epoch 4/80\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.4113 - val_loss: 0.3868\n",
      "Epoch 5/80\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.4080 - val_loss: 0.3834\n",
      "Epoch 6/80\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.4045 - val_loss: 0.3799\n",
      "Epoch 7/80\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.4006 - val_loss: 0.3761\n",
      "Epoch 8/80\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.3964 - val_loss: 0.3723\n",
      "Epoch 9/80\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.3929 - val_loss: 0.3688\n",
      "Epoch 10/80\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.3894 - val_loss: 0.3651\n",
      "Epoch 11/80\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.3854 - val_loss: 0.3613\n",
      "Epoch 12/80\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.3814 - val_loss: 0.3574\n",
      "Epoch 13/80\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.3773 - val_loss: 0.3533\n",
      "Epoch 14/80\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.3730 - val_loss: 0.3491\n",
      "Epoch 15/80\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.3687 - val_loss: 0.3448\n",
      "Epoch 16/80\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 0.3643 - val_loss: 0.3403\n",
      "Epoch 17/80\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 0.3598 - val_loss: 0.3358\n",
      "Epoch 18/80\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 0.3550 - val_loss: 0.3311\n",
      "Epoch 19/80\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 0.3498 - val_loss: 0.3262\n",
      "Epoch 20/80\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 0.3451 - val_loss: 0.3213\n",
      "Epoch 21/80\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.3399 - val_loss: 0.3162\n",
      "Epoch 22/80\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.3347 - val_loss: 0.3114\n",
      "Epoch 23/80\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.3303 - val_loss: 0.3071\n",
      "Epoch 24/80\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.3255 - val_loss: 0.3029\n",
      "Epoch 25/80\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.3213 - val_loss: 0.2986\n",
      "Epoch 26/80\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.3169 - val_loss: 0.2943\n",
      "Epoch 27/80\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.3122 - val_loss: 0.2899\n",
      "Epoch 28/80\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.3077 - val_loss: 0.2855\n",
      "Epoch 29/80\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.3031 - val_loss: 0.2810\n",
      "Epoch 30/80\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.2988 - val_loss: 0.2765\n",
      "Epoch 31/80\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.2935 - val_loss: 0.2719\n",
      "Epoch 32/80\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.2891 - val_loss: 0.2672\n",
      "Epoch 33/80\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.2846 - val_loss: 0.2625\n",
      "Epoch 34/80\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.2794 - val_loss: 0.2577\n",
      "Epoch 35/80\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.2744 - val_loss: 0.2528\n",
      "Epoch 36/80\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.2693 - val_loss: 0.2479\n",
      "Epoch 37/80\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.2651 - val_loss: 0.2429\n",
      "Epoch 38/80\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.2591 - val_loss: 0.2378\n",
      "Epoch 39/80\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.2541 - val_loss: 0.2327\n",
      "Epoch 40/80\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.2488 - val_loss: 0.2276\n",
      "Epoch 41/80\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.2439 - val_loss: 0.2223\n",
      "Epoch 42/80\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.2380 - val_loss: 0.2171\n",
      "Epoch 43/80\n",
      "103/103 [==============================] - ETA: 0s - loss: 0.238 - 0s 2ms/step - loss: 0.2336 - val_loss: 0.2123\n",
      "Epoch 44/80\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.2280 - val_loss: 0.2077\n",
      "Epoch 45/80\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.2236 - val_loss: 0.2031\n",
      "Epoch 46/80\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.2184 - val_loss: 0.1983\n",
      "Epoch 47/80\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.2135 - val_loss: 0.1935\n",
      "Epoch 48/80\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.2086 - val_loss: 0.1887\n",
      "Epoch 49/80\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.2033 - val_loss: 0.1837\n",
      "Epoch 50/80\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.1990 - val_loss: 0.1787\n",
      "Epoch 51/80\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.1929 - val_loss: 0.1735\n",
      "Epoch 52/80\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.1885 - val_loss: 0.1683\n",
      "Epoch 53/80\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.1832 - val_loss: 0.1630\n",
      "Epoch 54/80\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.1777 - val_loss: 0.1576\n",
      "Epoch 55/80\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.1725 - val_loss: 0.1521\n",
      "Epoch 56/80\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.1672 - val_loss: 0.1465\n",
      "Epoch 57/80\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.1619 - val_loss: 0.1410\n",
      "Epoch 58/80\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.1568 - val_loss: 0.1361\n",
      "Epoch 59/80\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 0.1528 - val_loss: 0.1314\n",
      "Epoch 60/80\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.1494 - val_loss: 0.1269\n",
      "Epoch 61/80\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.1465 - val_loss: 0.1226\n",
      "Epoch 62/80\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.1433 - val_loss: 0.1184\n",
      "Epoch 63/80\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.1399 - val_loss: 0.1143\n",
      "Epoch 64/80\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.1371 - val_loss: 0.1102\n",
      "Epoch 65/80\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.1349 - val_loss: 0.1062\n",
      "Epoch 66/80\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.1326 - val_loss: 0.1022\n",
      "Epoch 67/80\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.1292 - val_loss: 0.0982\n",
      "Epoch 68/80\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.1272 - val_loss: 0.0942\n",
      "Epoch 69/80\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.1248 - val_loss: 0.0902\n",
      "Epoch 70/80\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.1220 - val_loss: 0.0863\n",
      "Epoch 71/80\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.1198 - val_loss: 0.0827\n",
      "Epoch 72/80\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.1183 - val_loss: 0.0792\n",
      "Epoch 73/80\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.1159 - val_loss: 0.0759\n",
      "Epoch 74/80\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.1147 - val_loss: 0.0728\n",
      "Epoch 75/80\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 0.1130 - val_loss: 0.0701\n",
      "Epoch 76/80\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.1125 - val_loss: 0.0678\n",
      "Epoch 77/80\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.1117 - val_loss: 0.0657\n",
      "Epoch 78/80\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.1106 - val_loss: 0.0637\n",
      "Epoch 79/80\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.1108 - val_loss: 0.0623\n",
      "Epoch 80/80\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.1102 - val_loss: 0.0610\n",
      "Execution time:  20.530303955078125\n",
      "DNN:\n",
      "Mean Absolute Error: 0.0722\n",
      "Root Mean Square Error: 0.0768\n",
      "Mean Square Error: 0.0059\n",
      "\n",
      "Train RMSE: 0.077\n",
      "Train MSE: 0.006\n",
      "Train MAE: 0.072\n",
      "###########################\n",
      "\n",
      "MODEL:  DNN\n",
      "sequence:  3h\n",
      "units:  80\n",
      "dropout1:  0.11814836227952394\n",
      "optimizer: adadelta\n",
      "activationDense: tanh\n",
      "epochs: 90\n",
      "batchsize: 25\n",
      "validation_split: 0.2\n",
      "Model: \"sequential_52\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_156 (Dense)            (None, 18, 80)            160       \n",
      "_________________________________________________________________\n",
      "dense_157 (Dense)            (None, 18, 16)            1296      \n",
      "_________________________________________________________________\n",
      "dropout_52 (Dropout)         (None, 18, 16)            0         \n",
      "_________________________________________________________________\n",
      "dense_158 (Dense)            (None, 18, 1)             17        \n",
      "=================================================================\n",
      "Total params: 1,473\n",
      "Trainable params: 1,473\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/90\n",
      "128/128 [==============================] - 0s 3ms/step - loss: 0.3752 - val_loss: 0.3535\n",
      "Epoch 2/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.3728 - val_loss: 0.3509\n",
      "Epoch 3/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.3701 - val_loss: 0.3483\n",
      "Epoch 4/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.3673 - val_loss: 0.3455\n",
      "Epoch 5/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.3644 - val_loss: 0.3426\n",
      "Epoch 6/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.3613 - val_loss: 0.3394\n",
      "Epoch 7/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.3579 - val_loss: 0.3361\n",
      "Epoch 8/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.3545 - val_loss: 0.3326\n",
      "Epoch 9/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.3507 - val_loss: 0.3290\n",
      "Epoch 10/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.3471 - val_loss: 0.3253\n",
      "Epoch 11/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.3432 - val_loss: 0.3214\n",
      "Epoch 12/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.3390 - val_loss: 0.3173\n",
      "Epoch 13/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.3351 - val_loss: 0.3138\n",
      "Epoch 14/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.3314 - val_loss: 0.3103\n",
      "Epoch 15/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.3277 - val_loss: 0.3067\n",
      "Epoch 16/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.3240 - val_loss: 0.3030\n",
      "Epoch 17/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.3203 - val_loss: 0.2993\n",
      "Epoch 18/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.3164 - val_loss: 0.2956\n",
      "Epoch 19/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.3126 - val_loss: 0.2918\n",
      "Epoch 20/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.3087 - val_loss: 0.2879\n",
      "Epoch 21/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.3044 - val_loss: 0.2839\n",
      "Epoch 22/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.3004 - val_loss: 0.2799\n",
      "Epoch 23/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.2964 - val_loss: 0.2757\n",
      "Epoch 24/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.2923 - val_loss: 0.2715\n",
      "Epoch 25/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.2876 - val_loss: 0.2672\n",
      "Epoch 26/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.2831 - val_loss: 0.2628\n",
      "Epoch 27/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.2785 - val_loss: 0.2583\n",
      "Epoch 28/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.2741 - val_loss: 0.2537\n",
      "Epoch 29/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.2693 - val_loss: 0.2490\n",
      "Epoch 30/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.2646 - val_loss: 0.2442\n",
      "Epoch 31/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.2596 - val_loss: 0.2394\n",
      "Epoch 32/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.2545 - val_loss: 0.2344\n",
      "Epoch 33/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.2493 - val_loss: 0.2293\n",
      "Epoch 34/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.2442 - val_loss: 0.2241\n",
      "Epoch 35/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.2387 - val_loss: 0.2188\n",
      "Epoch 36/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.2333 - val_loss: 0.2134\n",
      "Epoch 37/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.2279 - val_loss: 0.2080\n",
      "Epoch 38/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.2222 - val_loss: 0.2024\n",
      "Epoch 39/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.2164 - val_loss: 0.1968\n",
      "Epoch 40/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.2108 - val_loss: 0.1911\n",
      "Epoch 41/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.2046 - val_loss: 0.1853\n",
      "Epoch 42/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.1986 - val_loss: 0.1794\n",
      "Epoch 43/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.1926 - val_loss: 0.1734\n",
      "Epoch 44/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.1871 - val_loss: 0.1673\n",
      "Epoch 45/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.1805 - val_loss: 0.1611\n",
      "Epoch 46/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.1744 - val_loss: 0.1548\n",
      "Epoch 47/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.1671 - val_loss: 0.1483\n",
      "Epoch 48/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.1606 - val_loss: 0.1417\n",
      "Epoch 49/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.1544 - val_loss: 0.1350\n",
      "Epoch 50/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.1476 - val_loss: 0.1282\n",
      "Epoch 51/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.1405 - val_loss: 0.1213\n",
      "Epoch 52/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.1336 - val_loss: 0.1143\n",
      "Epoch 53/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.1266 - val_loss: 0.1072\n",
      "Epoch 54/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.1191 - val_loss: 0.0999\n",
      "Epoch 55/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.1114 - val_loss: 0.0925\n",
      "Epoch 56/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.1046 - val_loss: 0.0850\n",
      "Epoch 57/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0969 - val_loss: 0.0775\n",
      "Epoch 58/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0891 - val_loss: 0.0699\n",
      "Epoch 59/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0818 - val_loss: 0.0622\n",
      "Epoch 60/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0742 - val_loss: 0.0545\n",
      "Epoch 61/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0671 - val_loss: 0.0470\n",
      "Epoch 62/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0603 - val_loss: 0.0406\n",
      "Epoch 63/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0573 - val_loss: 0.0378\n",
      "Epoch 64/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0565 - val_loss: 0.0355\n",
      "Epoch 65/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0564 - val_loss: 0.0340\n",
      "Epoch 66/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0563 - val_loss: 0.0328\n",
      "Epoch 67/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0556 - val_loss: 0.0319\n",
      "Epoch 68/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0554 - val_loss: 0.0311\n",
      "Epoch 69/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0552 - val_loss: 0.0305\n",
      "Epoch 70/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0553 - val_loss: 0.0301\n",
      "Epoch 71/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0551 - val_loss: 0.0298\n",
      "Epoch 72/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0549 - val_loss: 0.0296\n",
      "Epoch 73/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0545 - val_loss: 0.0293\n",
      "Epoch 74/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0550 - val_loss: 0.0291\n",
      "Epoch 75/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0553 - val_loss: 0.0288\n",
      "Epoch 76/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0546 - val_loss: 0.0286\n",
      "Epoch 77/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0548 - val_loss: 0.0284\n",
      "Epoch 78/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0550 - val_loss: 0.0282\n",
      "Epoch 79/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0544 - val_loss: 0.0280\n",
      "Epoch 80/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0547 - val_loss: 0.0279\n",
      "Epoch 81/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0549 - val_loss: 0.0278\n",
      "Epoch 82/90\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0544 - val_loss: 0.0276\n",
      "Epoch 83/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0549 - val_loss: 0.0275\n",
      "Epoch 84/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0551 - val_loss: 0.0274\n",
      "Epoch 85/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0547 - val_loss: 0.0273\n",
      "Epoch 86/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0547 - val_loss: 0.0272\n",
      "Epoch 87/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0547 - val_loss: 0.0271\n",
      "Epoch 88/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0547 - val_loss: 0.0270\n",
      "Epoch 89/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0548 - val_loss: 0.0269\n",
      "Epoch 90/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0546 - val_loss: 0.0268\n",
      "Execution time:  25.251575708389282\n",
      "DNN:\n",
      "Mean Absolute Error: 0.0371\n",
      "Root Mean Square Error: 0.0441\n",
      "Mean Square Error: 0.0019\n",
      "\n",
      "Train RMSE: 0.044\n",
      "Train MSE: 0.002\n",
      "Train MAE: 0.037\n",
      "###########################\n",
      "\n",
      "MODEL:  DNN\n",
      "sequence:  3h\n",
      "units:  12\n",
      "dropout1:  0.48476373451509647\n",
      "optimizer: adadelta\n",
      "activationDense: tanh\n",
      "epochs: 52\n",
      "batchsize: 57\n",
      "validation_split: 0.2\n",
      "Model: \"sequential_53\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_159 (Dense)            (None, 18, 12)            24        \n",
      "_________________________________________________________________\n",
      "dense_160 (Dense)            (None, 18, 16)            208       \n",
      "_________________________________________________________________\n",
      "dropout_53 (Dropout)         (None, 18, 16)            0         \n",
      "_________________________________________________________________\n",
      "dense_161 (Dense)            (None, 18, 1)             17        \n",
      "=================================================================\n",
      "Total params: 249\n",
      "Trainable params: 249\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/52\n",
      "56/56 [==============================] - 0s 5ms/step - loss: 0.4560 - val_loss: 0.4313\n",
      "Epoch 2/52\n",
      "56/56 [==============================] - 0s 2ms/step - loss: 0.4559 - val_loss: 0.4304\n",
      "Epoch 3/52\n",
      "56/56 [==============================] - 0s 2ms/step - loss: 0.4540 - val_loss: 0.4295\n",
      "Epoch 4/52\n",
      "56/56 [==============================] - 0s 2ms/step - loss: 0.4523 - val_loss: 0.4285\n",
      "Epoch 5/52\n",
      "56/56 [==============================] - 0s 2ms/step - loss: 0.4528 - val_loss: 0.4275\n",
      "Epoch 6/52\n",
      "56/56 [==============================] - 0s 2ms/step - loss: 0.4520 - val_loss: 0.4265\n",
      "Epoch 7/52\n",
      "56/56 [==============================] - 0s 2ms/step - loss: 0.4488 - val_loss: 0.4254\n",
      "Epoch 8/52\n",
      "56/56 [==============================] - 0s 2ms/step - loss: 0.4475 - val_loss: 0.4243\n",
      "Epoch 9/52\n",
      "56/56 [==============================] - 0s 2ms/step - loss: 0.4484 - val_loss: 0.4231\n",
      "Epoch 10/52\n",
      "56/56 [==============================] - 0s 2ms/step - loss: 0.4464 - val_loss: 0.4219\n",
      "Epoch 11/52\n",
      "56/56 [==============================] - 0s 2ms/step - loss: 0.4454 - val_loss: 0.4207\n",
      "Epoch 12/52\n",
      "56/56 [==============================] - 0s 2ms/step - loss: 0.4436 - val_loss: 0.4194\n",
      "Epoch 13/52\n",
      "56/56 [==============================] - 0s 2ms/step - loss: 0.4429 - val_loss: 0.4181\n",
      "Epoch 14/52\n",
      "56/56 [==============================] - 0s 2ms/step - loss: 0.4409 - val_loss: 0.4168\n",
      "Epoch 15/52\n",
      "56/56 [==============================] - 0s 2ms/step - loss: 0.4400 - val_loss: 0.4155\n",
      "Epoch 16/52\n",
      "56/56 [==============================] - 0s 2ms/step - loss: 0.4386 - val_loss: 0.4141\n",
      "Epoch 17/52\n",
      "56/56 [==============================] - 0s 2ms/step - loss: 0.4366 - val_loss: 0.4127\n",
      "Epoch 18/52\n",
      "56/56 [==============================] - 0s 2ms/step - loss: 0.4372 - val_loss: 0.4112\n",
      "Epoch 19/52\n",
      "56/56 [==============================] - 0s 2ms/step - loss: 0.4337 - val_loss: 0.4098\n",
      "Epoch 20/52\n",
      "56/56 [==============================] - 0s 2ms/step - loss: 0.4329 - val_loss: 0.4083\n",
      "Epoch 21/52\n",
      "56/56 [==============================] - 0s 2ms/step - loss: 0.4310 - val_loss: 0.4068\n",
      "Epoch 22/52\n",
      "56/56 [==============================] - 0s 2ms/step - loss: 0.4297 - val_loss: 0.4053\n",
      "Epoch 23/52\n",
      "56/56 [==============================] - 0s 2ms/step - loss: 0.4293 - val_loss: 0.4037\n",
      "Epoch 24/52\n",
      "56/56 [==============================] - 0s 2ms/step - loss: 0.4266 - val_loss: 0.4021\n",
      "Epoch 25/52\n",
      "56/56 [==============================] - 0s 2ms/step - loss: 0.4256 - val_loss: 0.4005\n",
      "Epoch 26/52\n",
      "56/56 [==============================] - 0s 2ms/step - loss: 0.4235 - val_loss: 0.3989\n",
      "Epoch 27/52\n",
      "56/56 [==============================] - 0s 2ms/step - loss: 0.4221 - val_loss: 0.3972\n",
      "Epoch 28/52\n",
      "56/56 [==============================] - 0s 2ms/step - loss: 0.4210 - val_loss: 0.3955\n",
      "Epoch 29/52\n",
      "56/56 [==============================] - 0s 2ms/step - loss: 0.4187 - val_loss: 0.3938\n",
      "Epoch 30/52\n",
      "56/56 [==============================] - 0s 2ms/step - loss: 0.4164 - val_loss: 0.3921\n",
      "Epoch 31/52\n",
      "56/56 [==============================] - 0s 2ms/step - loss: 0.4145 - val_loss: 0.3904\n",
      "Epoch 32/52\n",
      "56/56 [==============================] - 0s 2ms/step - loss: 0.4129 - val_loss: 0.3886\n",
      "Epoch 33/52\n",
      "56/56 [==============================] - 0s 2ms/step - loss: 0.4118 - val_loss: 0.3868\n",
      "Epoch 34/52\n",
      "56/56 [==============================] - 0s 2ms/step - loss: 0.4111 - val_loss: 0.3850\n",
      "Epoch 35/52\n",
      "56/56 [==============================] - 0s 2ms/step - loss: 0.4076 - val_loss: 0.3832\n",
      "Epoch 36/52\n",
      "56/56 [==============================] - 0s 2ms/step - loss: 0.4061 - val_loss: 0.3814\n",
      "Epoch 37/52\n",
      "56/56 [==============================] - 0s 2ms/step - loss: 0.4045 - val_loss: 0.3795\n",
      "Epoch 38/52\n",
      "56/56 [==============================] - 0s 2ms/step - loss: 0.4018 - val_loss: 0.3776\n",
      "Epoch 39/52\n",
      "56/56 [==============================] - 0s 2ms/step - loss: 0.4007 - val_loss: 0.3757\n",
      "Epoch 40/52\n",
      "56/56 [==============================] - 0s 2ms/step - loss: 0.3991 - val_loss: 0.3738\n",
      "Epoch 41/52\n",
      "56/56 [==============================] - 0s 2ms/step - loss: 0.3963 - val_loss: 0.3719\n",
      "Epoch 42/52\n",
      "56/56 [==============================] - 0s 2ms/step - loss: 0.3937 - val_loss: 0.3699\n",
      "Epoch 43/52\n",
      "56/56 [==============================] - 0s 2ms/step - loss: 0.3927 - val_loss: 0.3679\n",
      "Epoch 44/52\n",
      "56/56 [==============================] - 0s 2ms/step - loss: 0.3913 - val_loss: 0.3660\n",
      "Epoch 45/52\n",
      "56/56 [==============================] - 0s 2ms/step - loss: 0.3890 - val_loss: 0.3640\n",
      "Epoch 46/52\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 0.3874 - val_loss: 0.3619\n",
      "Epoch 47/52\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 0.3850 - val_loss: 0.3599\n",
      "Epoch 48/52\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 0.3823 - val_loss: 0.3578\n",
      "Epoch 49/52\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 0.3812 - val_loss: 0.3558\n",
      "Epoch 50/52\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 0.3785 - val_loss: 0.3537\n",
      "Epoch 51/52\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 0.3766 - val_loss: 0.3516\n",
      "Epoch 52/52\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 0.3744 - val_loss: 0.3494\n",
      "Execution time:  7.529304504394531\n",
      "DNN:\n",
      "Mean Absolute Error: 0.3681\n",
      "Root Mean Square Error: 0.3706\n",
      "Mean Square Error: 0.1374\n",
      "\n",
      "Train RMSE: 0.371\n",
      "Train MSE: 0.137\n",
      "Train MAE: 0.368\n",
      "###########################\n",
      "\n",
      "MODEL:  DNN\n",
      "sequence:  3h\n",
      "units:  87\n",
      "dropout1:  0.40519643149940265\n",
      "optimizer: adadelta\n",
      "activationDense: sigmoid\n",
      "epochs: 80\n",
      "batchsize: 31\n",
      "validation_split: 0.1\n",
      "Model: \"sequential_54\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_162 (Dense)            (None, 18, 87)            174       \n",
      "_________________________________________________________________\n",
      "dense_163 (Dense)            (None, 18, 16)            1408      \n",
      "_________________________________________________________________\n",
      "dropout_54 (Dropout)         (None, 18, 16)            0         \n",
      "_________________________________________________________________\n",
      "dense_164 (Dense)            (None, 18, 1)             17        \n",
      "=================================================================\n",
      "Total params: 1,599\n",
      "Trainable params: 1,599\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/80\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "116/116 [==============================] - 1s 5ms/step - loss: 0.0875 - val_loss: 0.1214\n",
      "Epoch 2/80\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.0873 - val_loss: 0.1210\n",
      "Epoch 3/80\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.0868 - val_loss: 0.1205\n",
      "Epoch 4/80\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.0863 - val_loss: 0.1200\n",
      "Epoch 5/80\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.0859 - val_loss: 0.1195\n",
      "Epoch 6/80\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.0854 - val_loss: 0.1190\n",
      "Epoch 7/80\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.0848 - val_loss: 0.1184\n",
      "Epoch 8/80\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.0844 - val_loss: 0.1178\n",
      "Epoch 9/80\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.0838 - val_loss: 0.1172\n",
      "Epoch 10/80\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.0832 - val_loss: 0.1166\n",
      "Epoch 11/80\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.0826 - val_loss: 0.1159\n",
      "Epoch 12/80\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.0819 - val_loss: 0.1153\n",
      "Epoch 13/80\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.0815 - val_loss: 0.1146\n",
      "Epoch 14/80\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.0807 - val_loss: 0.1139\n",
      "Epoch 15/80\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.0801 - val_loss: 0.1132\n",
      "Epoch 16/80\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.0795 - val_loss: 0.1125\n",
      "Epoch 17/80\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.0788 - val_loss: 0.1117\n",
      "Epoch 18/80\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.0781 - val_loss: 0.1110\n",
      "Epoch 19/80\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.0775 - val_loss: 0.1102\n",
      "Epoch 20/80\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.0768 - val_loss: 0.1094\n",
      "Epoch 21/80\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.0762 - val_loss: 0.1087\n",
      "Epoch 22/80\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.0754 - val_loss: 0.1079\n",
      "Epoch 23/80\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.0748 - val_loss: 0.1071\n",
      "Epoch 24/80\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.0740 - val_loss: 0.1063\n",
      "Epoch 25/80\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.0733 - val_loss: 0.1055\n",
      "Epoch 26/80\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.0728 - val_loss: 0.1047\n",
      "Epoch 27/80\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.0720 - val_loss: 0.1040\n",
      "Epoch 28/80\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.0714 - val_loss: 0.1033\n",
      "Epoch 29/80\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.0709 - val_loss: 0.1026\n",
      "Epoch 30/80\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.0703 - val_loss: 0.1019\n",
      "Epoch 31/80\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.0698 - val_loss: 0.1013\n",
      "Epoch 32/80\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.0692 - val_loss: 0.1006\n",
      "Epoch 33/80\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.0688 - val_loss: 0.0999\n",
      "Epoch 34/80\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.0681 - val_loss: 0.0993\n",
      "Epoch 35/80\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.0677 - val_loss: 0.0986\n",
      "Epoch 36/80\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.0670 - val_loss: 0.0980\n",
      "Epoch 37/80\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.0668 - val_loss: 0.0974\n",
      "Epoch 38/80\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.0660 - val_loss: 0.0967\n",
      "Epoch 39/80\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.0657 - val_loss: 0.0961\n",
      "Epoch 40/80\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.0653 - val_loss: 0.0955\n",
      "Epoch 41/80\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.0648 - val_loss: 0.0949\n",
      "Epoch 42/80\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.0645 - val_loss: 0.0943\n",
      "Epoch 43/80\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.0641 - val_loss: 0.0937\n",
      "Epoch 44/80\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.0636 - val_loss: 0.0931\n",
      "Epoch 45/80\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.0632 - val_loss: 0.0925\n",
      "Epoch 46/80\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.0627 - val_loss: 0.0919\n",
      "Epoch 47/80\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.0623 - val_loss: 0.0914\n",
      "Epoch 48/80\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.0621 - val_loss: 0.0908\n",
      "Epoch 49/80\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.0615 - val_loss: 0.0903\n",
      "Epoch 50/80\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.0612 - val_loss: 0.0897\n",
      "Epoch 51/80\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.0607 - val_loss: 0.0892\n",
      "Epoch 52/80\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.0604 - val_loss: 0.0887\n",
      "Epoch 53/80\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.0600 - val_loss: 0.0882\n",
      "Epoch 54/80\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.0597 - val_loss: 0.0876\n",
      "Epoch 55/80\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.0592 - val_loss: 0.0871\n",
      "Epoch 56/80\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.0592 - val_loss: 0.0866\n",
      "Epoch 57/80\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.0588 - val_loss: 0.0861\n",
      "Epoch 58/80\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.0584 - val_loss: 0.0856\n",
      "Epoch 59/80\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.0582 - val_loss: 0.0851\n",
      "Epoch 60/80\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.0579 - val_loss: 0.0846\n",
      "Epoch 61/80\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.0574 - val_loss: 0.0842\n",
      "Epoch 62/80\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.0573 - val_loss: 0.0837\n",
      "Epoch 63/80\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.0570 - val_loss: 0.0832\n",
      "Epoch 64/80\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.0566 - val_loss: 0.0827\n",
      "Epoch 65/80\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.0563 - val_loss: 0.0823\n",
      "Epoch 66/80\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.0559 - val_loss: 0.0818\n",
      "Epoch 67/80\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.0558 - val_loss: 0.0814\n",
      "Epoch 68/80\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.0555 - val_loss: 0.0809\n",
      "Epoch 69/80\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.0551 - val_loss: 0.0805\n",
      "Epoch 70/80\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.0550 - val_loss: 0.0800\n",
      "Epoch 71/80\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.0547 - val_loss: 0.0796\n",
      "Epoch 72/80\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.0544 - val_loss: 0.0792\n",
      "Epoch 73/80\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.0543 - val_loss: 0.0787\n",
      "Epoch 74/80\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.0541 - val_loss: 0.0783\n",
      "Epoch 75/80\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.0537 - val_loss: 0.0779\n",
      "Epoch 76/80\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.0534 - val_loss: 0.0775\n",
      "Epoch 77/80\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.0534 - val_loss: 0.0771\n",
      "Epoch 78/80\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.0531 - val_loss: 0.0766\n",
      "Epoch 79/80\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.0528 - val_loss: 0.0762\n",
      "Epoch 80/80\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.0528 - val_loss: 0.0758\n",
      "Execution time:  21.527066469192505\n",
      "DNN:\n",
      "Mean Absolute Error: 0.0519\n",
      "Root Mean Square Error: 0.0601\n",
      "Mean Square Error: 0.0036\n",
      "\n",
      "Train RMSE: 0.060\n",
      "Train MSE: 0.004\n",
      "Train MAE: 0.052\n",
      "###########################\n",
      "\n",
      "MODEL:  DNN\n",
      "sequence:  3h\n",
      "units:  80\n",
      "dropout1:  0.11814836227952394\n",
      "optimizer: adadelta\n",
      "activationDense: sigmoid\n",
      "epochs: 90\n",
      "batchsize: 25\n",
      "validation_split: 0.1\n",
      "Model: \"sequential_55\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_165 (Dense)            (None, 18, 80)            160       \n",
      "_________________________________________________________________\n",
      "dense_166 (Dense)            (None, 18, 16)            1296      \n",
      "_________________________________________________________________\n",
      "dropout_55 (Dropout)         (None, 18, 16)            0         \n",
      "_________________________________________________________________\n",
      "dense_167 (Dense)            (None, 18, 1)             17        \n",
      "=================================================================\n",
      "Total params: 1,473\n",
      "Trainable params: 1,473\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/90\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "143/143 [==============================] - 0s 3ms/step - loss: 0.0817 - val_loss: 0.1154\n",
      "Epoch 2/90\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.0809 - val_loss: 0.1145\n",
      "Epoch 3/90\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.0800 - val_loss: 0.1136\n",
      "Epoch 4/90\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.0791 - val_loss: 0.1125\n",
      "Epoch 5/90\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.0781 - val_loss: 0.1114\n",
      "Epoch 6/90\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.0771 - val_loss: 0.1103\n",
      "Epoch 7/90\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.0760 - val_loss: 0.1091\n",
      "Epoch 8/90\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.0750 - val_loss: 0.1080\n",
      "Epoch 9/90\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.0741 - val_loss: 0.1070\n",
      "Epoch 10/90\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.0732 - val_loss: 0.1060\n",
      "Epoch 11/90\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.0722 - val_loss: 0.1050\n",
      "Epoch 12/90\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.0713 - val_loss: 0.1040\n",
      "Epoch 13/90\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.0704 - val_loss: 0.1029\n",
      "Epoch 14/90\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.0695 - val_loss: 0.1018\n",
      "Epoch 15/90\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.0685 - val_loss: 0.1007\n",
      "Epoch 16/90\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.0676 - val_loss: 0.0996\n",
      "Epoch 17/90\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.0666 - val_loss: 0.0985\n",
      "Epoch 18/90\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.0657 - val_loss: 0.0974\n",
      "Epoch 19/90\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.0648 - val_loss: 0.0963\n",
      "Epoch 20/90\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.0639 - val_loss: 0.0952\n",
      "Epoch 21/90\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.0629 - val_loss: 0.0940\n",
      "Epoch 22/90\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.0621 - val_loss: 0.0929\n",
      "Epoch 23/90\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.0611 - val_loss: 0.0918\n",
      "Epoch 24/90\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.0602 - val_loss: 0.0906\n",
      "Epoch 25/90\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.0593 - val_loss: 0.0895\n",
      "Epoch 26/90\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.0585 - val_loss: 0.0883\n",
      "Epoch 27/90\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.0575 - val_loss: 0.0872\n",
      "Epoch 28/90\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.0567 - val_loss: 0.0861\n",
      "Epoch 29/90\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.0560 - val_loss: 0.0850\n",
      "Epoch 30/90\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.0552 - val_loss: 0.0840\n",
      "Epoch 31/90\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.0545 - val_loss: 0.0829\n",
      "Epoch 32/90\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.0537 - val_loss: 0.0819\n",
      "Epoch 33/90\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.0531 - val_loss: 0.0809\n",
      "Epoch 34/90\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.0524 - val_loss: 0.0799\n",
      "Epoch 35/90\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.0518 - val_loss: 0.0789\n",
      "Epoch 36/90\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.0511 - val_loss: 0.0779\n",
      "Epoch 37/90\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.0505 - val_loss: 0.0770\n",
      "Epoch 38/90\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.0499 - val_loss: 0.0760\n",
      "Epoch 39/90\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.0492 - val_loss: 0.0751\n",
      "Epoch 40/90\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.0487 - val_loss: 0.0742\n",
      "Epoch 41/90\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.0482 - val_loss: 0.0733\n",
      "Epoch 42/90\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.0477 - val_loss: 0.0724\n",
      "Epoch 43/90\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.0472 - val_loss: 0.0715\n",
      "Epoch 44/90\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.0466 - val_loss: 0.0707\n",
      "Epoch 45/90\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.0462 - val_loss: 0.0698\n",
      "Epoch 46/90\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.0458 - val_loss: 0.0690\n",
      "Epoch 47/90\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.0453 - val_loss: 0.0682\n",
      "Epoch 48/90\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.0449 - val_loss: 0.0674\n",
      "Epoch 49/90\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.0445 - val_loss: 0.0666\n",
      "Epoch 50/90\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.0441 - val_loss: 0.0658\n",
      "Epoch 51/90\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.0436 - val_loss: 0.0650\n",
      "Epoch 52/90\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.0433 - val_loss: 0.0642\n",
      "Epoch 53/90\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.0429 - val_loss: 0.0635\n",
      "Epoch 54/90\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.0424 - val_loss: 0.0627\n",
      "Epoch 55/90\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.0421 - val_loss: 0.0619\n",
      "Epoch 56/90\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.0418 - val_loss: 0.0612\n",
      "Epoch 57/90\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.0414 - val_loss: 0.0604\n",
      "Epoch 58/90\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.0412 - val_loss: 0.0597\n",
      "Epoch 59/90\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.0408 - val_loss: 0.0590\n",
      "Epoch 60/90\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.0404 - val_loss: 0.0582\n",
      "Epoch 61/90\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.0401 - val_loss: 0.0575\n",
      "Epoch 62/90\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.0398 - val_loss: 0.0568\n",
      "Epoch 63/90\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.0394 - val_loss: 0.0561\n",
      "Epoch 64/90\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.0391 - val_loss: 0.0554\n",
      "Epoch 65/90\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.0389 - val_loss: 0.0548\n",
      "Epoch 66/90\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.0386 - val_loss: 0.0541\n",
      "Epoch 67/90\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.0384 - val_loss: 0.0535\n",
      "Epoch 68/90\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.0381 - val_loss: 0.0528\n",
      "Epoch 69/90\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.0378 - val_loss: 0.0522\n",
      "Epoch 70/90\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.0376 - val_loss: 0.0516\n",
      "Epoch 71/90\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.0375 - val_loss: 0.0510\n",
      "Epoch 72/90\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.0373 - val_loss: 0.0504\n",
      "Epoch 73/90\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.0370 - val_loss: 0.0498\n",
      "Epoch 74/90\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.0368 - val_loss: 0.0493\n",
      "Epoch 75/90\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.0366 - val_loss: 0.0487\n",
      "Epoch 76/90\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.0363 - val_loss: 0.0481\n",
      "Epoch 77/90\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.0363 - val_loss: 0.0476\n",
      "Epoch 78/90\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.0360 - val_loss: 0.0470\n",
      "Epoch 79/90\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.0359 - val_loss: 0.0465\n",
      "Epoch 80/90\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.0357 - val_loss: 0.0459\n",
      "Epoch 81/90\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.0355 - val_loss: 0.0454\n",
      "Epoch 82/90\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "143/143 [==============================] - 0s 1ms/step - loss: 0.0354 - val_loss: 0.0449\n",
      "Epoch 83/90\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.0351 - val_loss: 0.0444\n",
      "Epoch 84/90\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.0350 - val_loss: 0.0439\n",
      "Epoch 85/90\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.0349 - val_loss: 0.0435\n",
      "Epoch 86/90\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.0347 - val_loss: 0.0430\n",
      "Epoch 87/90\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.0347 - val_loss: 0.0426\n",
      "Epoch 88/90\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.0346 - val_loss: 0.0422\n",
      "Epoch 89/90\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.0344 - val_loss: 0.0418\n",
      "Epoch 90/90\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.0343 - val_loss: 0.0413\n",
      "Execution time:  21.147061347961426\n",
      "DNN:\n",
      "Mean Absolute Error: 0.0344\n",
      "Root Mean Square Error: 0.0466\n",
      "Mean Square Error: 0.0022\n",
      "\n",
      "Train RMSE: 0.047\n",
      "Train MSE: 0.002\n",
      "Train MAE: 0.034\n",
      "###########################\n",
      "\n",
      "MODEL:  DNN\n",
      "sequence:  3h\n",
      "units:  12\n",
      "dropout1:  0.48476373451509647\n",
      "optimizer: adadelta\n",
      "activationDense: sigmoid\n",
      "epochs: 52\n",
      "batchsize: 57\n",
      "validation_split: 0.1\n",
      "Model: \"sequential_56\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_168 (Dense)            (None, 18, 12)            24        \n",
      "_________________________________________________________________\n",
      "dense_169 (Dense)            (None, 18, 16)            208       \n",
      "_________________________________________________________________\n",
      "dropout_56 (Dropout)         (None, 18, 16)            0         \n",
      "_________________________________________________________________\n",
      "dense_170 (Dense)            (None, 18, 1)             17        \n",
      "=================================================================\n",
      "Total params: 249\n",
      "Trainable params: 249\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/52\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.1188 - val_loss: 0.1508\n",
      "Epoch 2/52\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.1183 - val_loss: 0.1506\n",
      "Epoch 3/52\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.1183 - val_loss: 0.1503\n",
      "Epoch 4/52\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.1178 - val_loss: 0.1501\n",
      "Epoch 5/52\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.1176 - val_loss: 0.1498\n",
      "Epoch 6/52\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.1174 - val_loss: 0.1495\n",
      "Epoch 7/52\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.1169 - val_loss: 0.1492\n",
      "Epoch 8/52\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.1167 - val_loss: 0.1489\n",
      "Epoch 9/52\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.1166 - val_loss: 0.1486\n",
      "Epoch 10/52\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.1159 - val_loss: 0.1482\n",
      "Epoch 11/52\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.1155 - val_loss: 0.1479\n",
      "Epoch 12/52\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.1153 - val_loss: 0.1476\n",
      "Epoch 13/52\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.1149 - val_loss: 0.1472\n",
      "Epoch 14/52\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.1144 - val_loss: 0.1468\n",
      "Epoch 15/52\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.1143 - val_loss: 0.1465\n",
      "Epoch 16/52\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.1137 - val_loss: 0.1461\n",
      "Epoch 17/52\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.1133 - val_loss: 0.1457\n",
      "Epoch 18/52\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.1130 - val_loss: 0.1453\n",
      "Epoch 19/52\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.1126 - val_loss: 0.1449\n",
      "Epoch 20/52\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.1123 - val_loss: 0.1445\n",
      "Epoch 21/52\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.1121 - val_loss: 0.1441\n",
      "Epoch 22/52\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.1113 - val_loss: 0.1436\n",
      "Epoch 23/52\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.1111 - val_loss: 0.1432\n",
      "Epoch 24/52\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.1107 - val_loss: 0.1428\n",
      "Epoch 25/52\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.1103 - val_loss: 0.1423\n",
      "Epoch 26/52\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.1097 - val_loss: 0.1419\n",
      "Epoch 27/52\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.1093 - val_loss: 0.1414\n",
      "Epoch 28/52\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.1091 - val_loss: 0.1410\n",
      "Epoch 29/52\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.1084 - val_loss: 0.1405\n",
      "Epoch 30/52\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.1080 - val_loss: 0.1401\n",
      "Epoch 31/52\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.1076 - val_loss: 0.1396\n",
      "Epoch 32/52\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.1070 - val_loss: 0.1392\n",
      "Epoch 33/52\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.1066 - val_loss: 0.1388\n",
      "Epoch 34/52\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.1062 - val_loss: 0.1383\n",
      "Epoch 35/52\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.1058 - val_loss: 0.1379\n",
      "Epoch 36/52\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.1053 - val_loss: 0.1374\n",
      "Epoch 37/52\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.1050 - val_loss: 0.1370\n",
      "Epoch 38/52\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.1044 - val_loss: 0.1365\n",
      "Epoch 39/52\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.1040 - val_loss: 0.1360\n",
      "Epoch 40/52\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.1035 - val_loss: 0.1356\n",
      "Epoch 41/52\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.1031 - val_loss: 0.1351\n",
      "Epoch 42/52\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.1025 - val_loss: 0.1346\n",
      "Epoch 43/52\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.1022 - val_loss: 0.1342\n",
      "Epoch 44/52\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.1017 - val_loss: 0.1337\n",
      "Epoch 45/52\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.1013 - val_loss: 0.1332\n",
      "Epoch 46/52\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.1008 - val_loss: 0.1327\n",
      "Epoch 47/52\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.1003 - val_loss: 0.1323\n",
      "Epoch 48/52\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.1000 - val_loss: 0.1318\n",
      "Epoch 49/52\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0994 - val_loss: 0.1313\n",
      "Epoch 50/52\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0989 - val_loss: 0.1308\n",
      "Epoch 51/52\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0985 - val_loss: 0.1303\n",
      "Epoch 52/52\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0979 - val_loss: 0.1298\n",
      "Execution time:  7.990282773971558\n",
      "DNN:\n",
      "Mean Absolute Error: 0.1000\n",
      "Root Mean Square Error: 0.1060\n",
      "Mean Square Error: 0.0112\n",
      "\n",
      "Train RMSE: 0.106\n",
      "Train MSE: 0.011\n",
      "Train MAE: 0.100\n",
      "###########################\n",
      "\n",
      "MODEL:  DNN\n",
      "sequence:  3h\n",
      "units:  87\n",
      "dropout1:  0.40519643149940265\n",
      "optimizer: adadelta\n",
      "activationDense: sigmoid\n",
      "epochs: 80\n",
      "batchsize: 31\n",
      "validation_split: 0.2\n",
      "Model: \"sequential_57\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_171 (Dense)            (None, 18, 87)            174       \n",
      "_________________________________________________________________\n",
      "dense_172 (Dense)            (None, 18, 16)            1408      \n",
      "_________________________________________________________________\n",
      "dropout_57 (Dropout)         (None, 18, 16)            0         \n",
      "_________________________________________________________________\n",
      "dense_173 (Dense)            (None, 18, 1)             17        \n",
      "=================================================================\n",
      "Total params: 1,599\n",
      "Trainable params: 1,599\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/80\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "103/103 [==============================] - 0s 4ms/step - loss: 0.0883 - val_loss: 0.1094\n",
      "Epoch 2/80\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.0877 - val_loss: 0.1088\n",
      "Epoch 3/80\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.0871 - val_loss: 0.1082\n",
      "Epoch 4/80\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.0863 - val_loss: 0.1075\n",
      "Epoch 5/80\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.0857 - val_loss: 0.1068\n",
      "Epoch 6/80\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 0.0848 - val_loss: 0.1060\n",
      "Epoch 7/80\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.0842 - val_loss: 0.1052\n",
      "Epoch 8/80\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.0833 - val_loss: 0.1044\n",
      "Epoch 9/80\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.0825 - val_loss: 0.1036\n",
      "Epoch 10/80\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.0817 - val_loss: 0.1028\n",
      "Epoch 11/80\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.0808 - val_loss: 0.1019\n",
      "Epoch 12/80\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.0799 - val_loss: 0.1010\n",
      "Epoch 13/80\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.0792 - val_loss: 0.1001\n",
      "Epoch 14/80\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.0783 - val_loss: 0.0991\n",
      "Epoch 15/80\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.0773 - val_loss: 0.0982\n",
      "Epoch 16/80\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.0764 - val_loss: 0.0973\n",
      "Epoch 17/80\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.0755 - val_loss: 0.0963\n",
      "Epoch 18/80\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.0746 - val_loss: 0.0954\n",
      "Epoch 19/80\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.0737 - val_loss: 0.0944\n",
      "Epoch 20/80\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.0727 - val_loss: 0.0934\n",
      "Epoch 21/80\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.0719 - val_loss: 0.0925\n",
      "Epoch 22/80\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.0709 - val_loss: 0.0915\n",
      "Epoch 23/80\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.0700 - val_loss: 0.0905\n",
      "Epoch 24/80\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.0692 - val_loss: 0.0895\n",
      "Epoch 25/80\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.0685 - val_loss: 0.0886\n",
      "Epoch 26/80\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.0675 - val_loss: 0.0876\n",
      "Epoch 27/80\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.0667 - val_loss: 0.0867\n",
      "Epoch 28/80\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.0659 - val_loss: 0.0858\n",
      "Epoch 29/80\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.0651 - val_loss: 0.0849\n",
      "Epoch 30/80\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.0646 - val_loss: 0.0841\n",
      "Epoch 31/80\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.0638 - val_loss: 0.0834\n",
      "Epoch 32/80\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.0634 - val_loss: 0.0826\n",
      "Epoch 33/80\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.0626 - val_loss: 0.0819\n",
      "Epoch 34/80\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.0622 - val_loss: 0.0812\n",
      "Epoch 35/80\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.0615 - val_loss: 0.0805\n",
      "Epoch 36/80\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.0611 - val_loss: 0.0798\n",
      "Epoch 37/80\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.0605 - val_loss: 0.0792\n",
      "Epoch 38/80\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.0600 - val_loss: 0.0785\n",
      "Epoch 39/80\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.0595 - val_loss: 0.0779\n",
      "Epoch 40/80\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.0590 - val_loss: 0.0773\n",
      "Epoch 41/80\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.0587 - val_loss: 0.0767\n",
      "Epoch 42/80\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.0583 - val_loss: 0.0761\n",
      "Epoch 43/80\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.0579 - val_loss: 0.0755\n",
      "Epoch 44/80\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.0575 - val_loss: 0.0749\n",
      "Epoch 45/80\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.0570 - val_loss: 0.0744\n",
      "Epoch 46/80\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 0.0568 - val_loss: 0.0738\n",
      "Epoch 47/80\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 0.0562 - val_loss: 0.0733\n",
      "Epoch 48/80\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 0.0561 - val_loss: 0.0727\n",
      "Epoch 49/80\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.0556 - val_loss: 0.0722\n",
      "Epoch 50/80\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.0552 - val_loss: 0.0717\n",
      "Epoch 51/80\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.0548 - val_loss: 0.0712\n",
      "Epoch 52/80\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.0546 - val_loss: 0.0707\n",
      "Epoch 53/80\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.0544 - val_loss: 0.0702\n",
      "Epoch 54/80\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.0541 - val_loss: 0.0697\n",
      "Epoch 55/80\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.0539 - val_loss: 0.0692\n",
      "Epoch 56/80\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.0532 - val_loss: 0.0687\n",
      "Epoch 57/80\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.0531 - val_loss: 0.0682\n",
      "Epoch 58/80\n",
      "103/103 [==============================] - ETA: 0s - loss: 0.049 - 0s 2ms/step - loss: 0.0529 - val_loss: 0.0678\n",
      "Epoch 59/80\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.0524 - val_loss: 0.0673\n",
      "Epoch 60/80\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.0522 - val_loss: 0.0668\n",
      "Epoch 61/80\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.0519 - val_loss: 0.0664\n",
      "Epoch 62/80\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.0520 - val_loss: 0.0660\n",
      "Epoch 63/80\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.0514 - val_loss: 0.0655\n",
      "Epoch 64/80\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.0513 - val_loss: 0.0651\n",
      "Epoch 65/80\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.0509 - val_loss: 0.0646\n",
      "Epoch 66/80\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.0506 - val_loss: 0.0642\n",
      "Epoch 67/80\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.0505 - val_loss: 0.0638\n",
      "Epoch 68/80\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.0503 - val_loss: 0.0634\n",
      "Epoch 69/80\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.0501 - val_loss: 0.0630\n",
      "Epoch 70/80\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.0498 - val_loss: 0.0626\n",
      "Epoch 71/80\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.0498 - val_loss: 0.0622\n",
      "Epoch 72/80\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.0495 - val_loss: 0.0618\n",
      "Epoch 73/80\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.0494 - val_loss: 0.0614\n",
      "Epoch 74/80\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.0491 - val_loss: 0.0610\n",
      "Epoch 75/80\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.0490 - val_loss: 0.0607\n",
      "Epoch 76/80\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.0488 - val_loss: 0.0603\n",
      "Epoch 77/80\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.0486 - val_loss: 0.0599\n",
      "Epoch 78/80\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.0485 - val_loss: 0.0596\n",
      "Epoch 79/80\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.0481 - val_loss: 0.0592\n",
      "Epoch 80/80\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.0483 - val_loss: 0.0588\n",
      "Execution time:  19.68028450012207\n",
      "DNN:\n",
      "Mean Absolute Error: 0.0467\n",
      "Root Mean Square Error: 0.0551\n",
      "Mean Square Error: 0.0030\n",
      "\n",
      "Train RMSE: 0.055\n",
      "Train MSE: 0.003\n",
      "Train MAE: 0.047\n",
      "###########################\n",
      "\n",
      "MODEL:  DNN\n",
      "sequence:  3h\n",
      "units:  80\n",
      "dropout1:  0.11814836227952394\n",
      "optimizer: adadelta\n",
      "activationDense: sigmoid\n",
      "epochs: 90\n",
      "batchsize: 25\n",
      "validation_split: 0.2\n",
      "Model: \"sequential_58\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_174 (Dense)            (None, 18, 80)            160       \n",
      "_________________________________________________________________\n",
      "dense_175 (Dense)            (None, 18, 16)            1296      \n",
      "_________________________________________________________________\n",
      "dropout_58 (Dropout)         (None, 18, 16)            0         \n",
      "_________________________________________________________________\n",
      "dense_176 (Dense)            (None, 18, 1)             17        \n",
      "=================================================================\n",
      "Total params: 1,473\n",
      "Trainable params: 1,473\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/90\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "128/128 [==============================] - 0s 3ms/step - loss: 0.1157 - val_loss: 0.1349\n",
      "Epoch 2/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.1147 - val_loss: 0.1338\n",
      "Epoch 3/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.1135 - val_loss: 0.1327\n",
      "Epoch 4/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.1123 - val_loss: 0.1315\n",
      "Epoch 5/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.1109 - val_loss: 0.1302\n",
      "Epoch 6/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.1096 - val_loss: 0.1288\n",
      "Epoch 7/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.1081 - val_loss: 0.1274\n",
      "Epoch 8/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.1066 - val_loss: 0.1259\n",
      "Epoch 9/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.1049 - val_loss: 0.1243\n",
      "Epoch 10/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.1033 - val_loss: 0.1227\n",
      "Epoch 11/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.1015 - val_loss: 0.1210\n",
      "Epoch 12/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0998 - val_loss: 0.1193\n",
      "Epoch 13/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0981 - val_loss: 0.1179\n",
      "Epoch 14/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0967 - val_loss: 0.1166\n",
      "Epoch 15/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0954 - val_loss: 0.1154\n",
      "Epoch 16/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0940 - val_loss: 0.1141\n",
      "Epoch 17/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0927 - val_loss: 0.1128\n",
      "Epoch 18/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0913 - val_loss: 0.1115\n",
      "Epoch 19/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0899 - val_loss: 0.1101\n",
      "Epoch 20/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0885 - val_loss: 0.1088\n",
      "Epoch 21/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0871 - val_loss: 0.1074\n",
      "Epoch 22/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0857 - val_loss: 0.1061\n",
      "Epoch 23/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0843 - val_loss: 0.1047\n",
      "Epoch 24/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0830 - val_loss: 0.1033\n",
      "Epoch 25/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0816 - val_loss: 0.1019\n",
      "Epoch 26/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0801 - val_loss: 0.1005\n",
      "Epoch 27/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0786 - val_loss: 0.0991\n",
      "Epoch 28/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0773 - val_loss: 0.0977\n",
      "Epoch 29/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0759 - val_loss: 0.0963\n",
      "Epoch 30/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0745 - val_loss: 0.0949\n",
      "Epoch 31/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0731 - val_loss: 0.0935\n",
      "Epoch 32/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0717 - val_loss: 0.0921\n",
      "Epoch 33/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0704 - val_loss: 0.0908\n",
      "Epoch 34/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0690 - val_loss: 0.0894\n",
      "Epoch 35/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0677 - val_loss: 0.0880\n",
      "Epoch 36/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0664 - val_loss: 0.0865\n",
      "Epoch 37/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0650 - val_loss: 0.0852\n",
      "Epoch 38/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0638 - val_loss: 0.0838\n",
      "Epoch 39/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0625 - val_loss: 0.0824\n",
      "Epoch 40/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0613 - val_loss: 0.0811\n",
      "Epoch 41/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0602 - val_loss: 0.0798\n",
      "Epoch 42/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0590 - val_loss: 0.0785\n",
      "Epoch 43/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0579 - val_loss: 0.0772\n",
      "Epoch 44/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0569 - val_loss: 0.0759\n",
      "Epoch 45/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0557 - val_loss: 0.0747\n",
      "Epoch 46/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0549 - val_loss: 0.0735\n",
      "Epoch 47/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0538 - val_loss: 0.0723\n",
      "Epoch 48/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0529 - val_loss: 0.0712\n",
      "Epoch 49/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0522 - val_loss: 0.0701\n",
      "Epoch 50/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0514 - val_loss: 0.0691\n",
      "Epoch 51/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0507 - val_loss: 0.0681\n",
      "Epoch 52/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0500 - val_loss: 0.0671\n",
      "Epoch 53/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0494 - val_loss: 0.0661\n",
      "Epoch 54/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0487 - val_loss: 0.0652\n",
      "Epoch 55/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0480 - val_loss: 0.0643\n",
      "Epoch 56/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0474 - val_loss: 0.0634\n",
      "Epoch 57/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0469 - val_loss: 0.0625\n",
      "Epoch 58/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0463 - val_loss: 0.0617\n",
      "Epoch 59/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0459 - val_loss: 0.0609\n",
      "Epoch 60/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0455 - val_loss: 0.0601\n",
      "Epoch 61/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0451 - val_loss: 0.0594\n",
      "Epoch 62/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0446 - val_loss: 0.0586\n",
      "Epoch 63/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0441 - val_loss: 0.0579\n",
      "Epoch 64/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0437 - val_loss: 0.0572\n",
      "Epoch 65/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0435 - val_loss: 0.0565\n",
      "Epoch 66/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0431 - val_loss: 0.0558\n",
      "Epoch 67/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0426 - val_loss: 0.0551\n",
      "Epoch 68/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0423 - val_loss: 0.0545\n",
      "Epoch 69/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0421 - val_loss: 0.0538\n",
      "Epoch 70/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0417 - val_loss: 0.0532\n",
      "Epoch 71/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0415 - val_loss: 0.0526\n",
      "Epoch 72/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0409 - val_loss: 0.0520\n",
      "Epoch 73/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0408 - val_loss: 0.0514\n",
      "Epoch 74/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0405 - val_loss: 0.0508\n",
      "Epoch 75/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0401 - val_loss: 0.0503\n",
      "Epoch 76/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0400 - val_loss: 0.0498\n",
      "Epoch 77/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0397 - val_loss: 0.0493\n",
      "Epoch 78/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0396 - val_loss: 0.0488\n",
      "Epoch 79/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0393 - val_loss: 0.0483\n",
      "Epoch 80/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0392 - val_loss: 0.0479\n",
      "Epoch 81/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0389 - val_loss: 0.0474\n",
      "Epoch 82/90\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0386 - val_loss: 0.0470\n",
      "Epoch 83/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0385 - val_loss: 0.0465\n",
      "Epoch 84/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0385 - val_loss: 0.0461\n",
      "Epoch 85/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0382 - val_loss: 0.0457\n",
      "Epoch 86/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0380 - val_loss: 0.0453\n",
      "Epoch 87/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0380 - val_loss: 0.0449\n",
      "Epoch 88/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0377 - val_loss: 0.0446\n",
      "Epoch 89/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0377 - val_loss: 0.0442\n",
      "Epoch 90/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0375 - val_loss: 0.0438\n",
      "Execution time:  25.082218647003174\n",
      "DNN:\n",
      "Mean Absolute Error: 0.0375\n",
      "Root Mean Square Error: 0.0468\n",
      "Mean Square Error: 0.0022\n",
      "\n",
      "Train RMSE: 0.047\n",
      "Train MSE: 0.002\n",
      "Train MAE: 0.037\n",
      "###########################\n",
      "\n",
      "MODEL:  DNN\n",
      "sequence:  3h\n",
      "units:  12\n",
      "dropout1:  0.48476373451509647\n",
      "optimizer: adadelta\n",
      "activationDense: sigmoid\n",
      "epochs: 52\n",
      "batchsize: 57\n",
      "validation_split: 0.2\n",
      "Model: \"sequential_59\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_177 (Dense)            (None, 18, 12)            24        \n",
      "_________________________________________________________________\n",
      "dense_178 (Dense)            (None, 18, 16)            208       \n",
      "_________________________________________________________________\n",
      "dropout_59 (Dropout)         (None, 18, 16)            0         \n",
      "_________________________________________________________________\n",
      "dense_179 (Dense)            (None, 18, 1)             17        \n",
      "=================================================================\n",
      "Total params: 249\n",
      "Trainable params: 249\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/52\n",
      "56/56 [==============================] - 0s 5ms/step - loss: 0.1027 - val_loss: 0.1233\n",
      "Epoch 2/52\n",
      "56/56 [==============================] - 0s 2ms/step - loss: 0.1026 - val_loss: 0.1232\n",
      "Epoch 3/52\n",
      "56/56 [==============================] - 0s 2ms/step - loss: 0.1025 - val_loss: 0.1231\n",
      "Epoch 4/52\n",
      "56/56 [==============================] - 0s 2ms/step - loss: 0.1024 - val_loss: 0.1230\n",
      "Epoch 5/52\n",
      "56/56 [==============================] - 0s 2ms/step - loss: 0.1023 - val_loss: 0.1229\n",
      "Epoch 6/52\n",
      "56/56 [==============================] - 0s 2ms/step - loss: 0.1021 - val_loss: 0.1227\n",
      "Epoch 7/52\n",
      "56/56 [==============================] - 0s 2ms/step - loss: 0.1020 - val_loss: 0.1226\n",
      "Epoch 8/52\n",
      "56/56 [==============================] - 0s 2ms/step - loss: 0.1019 - val_loss: 0.1225\n",
      "Epoch 9/52\n",
      "56/56 [==============================] - 0s 2ms/step - loss: 0.1017 - val_loss: 0.1223\n",
      "Epoch 10/52\n",
      "56/56 [==============================] - 0s 2ms/step - loss: 0.1016 - val_loss: 0.1222\n",
      "Epoch 11/52\n",
      "56/56 [==============================] - 0s 2ms/step - loss: 0.1015 - val_loss: 0.1220\n",
      "Epoch 12/52\n",
      "56/56 [==============================] - 0s 2ms/step - loss: 0.1013 - val_loss: 0.1219\n",
      "Epoch 13/52\n",
      "56/56 [==============================] - 0s 2ms/step - loss: 0.1011 - val_loss: 0.1217\n",
      "Epoch 14/52\n",
      "56/56 [==============================] - 0s 2ms/step - loss: 0.1009 - val_loss: 0.1216\n",
      "Epoch 15/52\n",
      "56/56 [==============================] - 0s 2ms/step - loss: 0.1008 - val_loss: 0.1214\n",
      "Epoch 16/52\n",
      "56/56 [==============================] - 0s 2ms/step - loss: 0.1007 - val_loss: 0.1212\n",
      "Epoch 17/52\n",
      "56/56 [==============================] - 0s 2ms/step - loss: 0.1005 - val_loss: 0.1211\n",
      "Epoch 18/52\n",
      "56/56 [==============================] - 0s 2ms/step - loss: 0.1002 - val_loss: 0.1209\n",
      "Epoch 19/52\n",
      "56/56 [==============================] - 0s 2ms/step - loss: 0.1002 - val_loss: 0.1207\n",
      "Epoch 20/52\n",
      "56/56 [==============================] - 0s 2ms/step - loss: 0.1000 - val_loss: 0.1206\n",
      "Epoch 21/52\n",
      "56/56 [==============================] - 0s 2ms/step - loss: 0.0997 - val_loss: 0.1204\n",
      "Epoch 22/52\n",
      "56/56 [==============================] - 0s 2ms/step - loss: 0.0996 - val_loss: 0.1202\n",
      "Epoch 23/52\n",
      "56/56 [==============================] - 0s 2ms/step - loss: 0.0994 - val_loss: 0.1200\n",
      "Epoch 24/52\n",
      "56/56 [==============================] - 0s 2ms/step - loss: 0.0992 - val_loss: 0.1198\n",
      "Epoch 25/52\n",
      "56/56 [==============================] - 0s 2ms/step - loss: 0.0990 - val_loss: 0.1196\n",
      "Epoch 26/52\n",
      "56/56 [==============================] - 0s 2ms/step - loss: 0.0988 - val_loss: 0.1194\n",
      "Epoch 27/52\n",
      "56/56 [==============================] - 0s 2ms/step - loss: 0.0986 - val_loss: 0.1193\n",
      "Epoch 28/52\n",
      "56/56 [==============================] - 0s 2ms/step - loss: 0.0984 - val_loss: 0.1191\n",
      "Epoch 29/52\n",
      "56/56 [==============================] - 0s 2ms/step - loss: 0.0982 - val_loss: 0.1189\n",
      "Epoch 30/52\n",
      "56/56 [==============================] - 0s 2ms/step - loss: 0.0981 - val_loss: 0.1187\n",
      "Epoch 31/52\n",
      "56/56 [==============================] - 0s 2ms/step - loss: 0.0978 - val_loss: 0.1185\n",
      "Epoch 32/52\n",
      "56/56 [==============================] - 0s 2ms/step - loss: 0.0976 - val_loss: 0.1183\n",
      "Epoch 33/52\n",
      "56/56 [==============================] - 0s 2ms/step - loss: 0.0974 - val_loss: 0.1181\n",
      "Epoch 34/52\n",
      "56/56 [==============================] - 0s 2ms/step - loss: 0.0972 - val_loss: 0.1178\n",
      "Epoch 35/52\n",
      "56/56 [==============================] - 0s 2ms/step - loss: 0.0970 - val_loss: 0.1176\n",
      "Epoch 36/52\n",
      "56/56 [==============================] - 0s 2ms/step - loss: 0.0968 - val_loss: 0.1174\n",
      "Epoch 37/52\n",
      "56/56 [==============================] - 0s 2ms/step - loss: 0.0966 - val_loss: 0.1172\n",
      "Epoch 38/52\n",
      "56/56 [==============================] - 0s 2ms/step - loss: 0.0963 - val_loss: 0.1170\n",
      "Epoch 39/52\n",
      "56/56 [==============================] - 0s 2ms/step - loss: 0.0961 - val_loss: 0.1168\n",
      "Epoch 40/52\n",
      "56/56 [==============================] - 0s 2ms/step - loss: 0.0958 - val_loss: 0.1166\n",
      "Epoch 41/52\n",
      "56/56 [==============================] - 0s 2ms/step - loss: 0.0957 - val_loss: 0.1163\n",
      "Epoch 42/52\n",
      "56/56 [==============================] - 0s 2ms/step - loss: 0.0955 - val_loss: 0.1161\n",
      "Epoch 43/52\n",
      "56/56 [==============================] - 0s 2ms/step - loss: 0.0952 - val_loss: 0.1159\n",
      "Epoch 44/52\n",
      "56/56 [==============================] - 0s 2ms/step - loss: 0.0950 - val_loss: 0.1157\n",
      "Epoch 45/52\n",
      "56/56 [==============================] - 0s 2ms/step - loss: 0.0948 - val_loss: 0.1155\n",
      "Epoch 46/52\n",
      "56/56 [==============================] - 0s 2ms/step - loss: 0.0946 - val_loss: 0.1152\n",
      "Epoch 47/52\n",
      "56/56 [==============================] - 0s 2ms/step - loss: 0.0943 - val_loss: 0.1150\n",
      "Epoch 48/52\n",
      "56/56 [==============================] - 0s 2ms/step - loss: 0.0941 - val_loss: 0.1148\n",
      "Epoch 49/52\n",
      "56/56 [==============================] - 0s 2ms/step - loss: 0.0938 - val_loss: 0.1145\n",
      "Epoch 50/52\n",
      "56/56 [==============================] - 0s 2ms/step - loss: 0.0936 - val_loss: 0.1143\n",
      "Epoch 51/52\n",
      "56/56 [==============================] - 0s 2ms/step - loss: 0.0934 - val_loss: 0.1141\n",
      "Epoch 52/52\n",
      "56/56 [==============================] - 0s 2ms/step - loss: 0.0932 - val_loss: 0.1138\n",
      "Execution time:  7.3392980098724365\n",
      "DNN:\n",
      "Mean Absolute Error: 0.0970\n",
      "Root Mean Square Error: 0.1032\n",
      "Mean Square Error: 0.0107\n",
      "\n",
      "Train RMSE: 0.103\n",
      "Train MSE: 0.011\n",
      "Train MAE: 0.097\n",
      "###########################\n",
      "\n",
      "MODEL:  DNN\n",
      "sequence:  3h\n",
      "units:  87\n",
      "dropout1:  0.40519643149940265\n",
      "optimizer: adamax\n",
      "activationDense: tanh\n",
      "epochs: 80\n",
      "batchsize: 31\n",
      "validation_split: 0.1\n",
      "Model: \"sequential_60\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_180 (Dense)            (None, 18, 87)            174       \n",
      "_________________________________________________________________\n",
      "dense_181 (Dense)            (None, 18, 16)            1408      \n",
      "_________________________________________________________________\n",
      "dropout_60 (Dropout)         (None, 18, 16)            0         \n",
      "_________________________________________________________________\n",
      "dense_182 (Dense)            (None, 18, 1)             17        \n",
      "=================================================================\n",
      "Total params: 1,599\n",
      "Trainable params: 1,599\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/80\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  1/116 [..............................] - ETA: 0s - loss: 0.4556WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0000s vs `on_train_batch_end` time: 0.0124s). Check your callbacks.\n",
      "116/116 [==============================] - 0s 4ms/step - loss: 0.2122 - val_loss: 0.0837\n",
      "Epoch 2/80\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.1231 - val_loss: 0.0507\n",
      "Epoch 3/80\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.1042 - val_loss: 0.0309\n",
      "Epoch 4/80\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.0857 - val_loss: 0.0128\n",
      "Epoch 5/80\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.0685 - val_loss: 0.0062\n",
      "Epoch 6/80\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.0522 - val_loss: 0.0157\n",
      "Epoch 7/80\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.0396 - val_loss: 0.0073\n",
      "Epoch 8/80\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.0341 - val_loss: 0.0086\n",
      "Epoch 9/80\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.0305 - val_loss: 0.0100\n",
      "Epoch 10/80\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.0288 - val_loss: 0.0115\n",
      "Epoch 11/80\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.0284 - val_loss: 0.0114\n",
      "Epoch 12/80\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.0282 - val_loss: 0.0122\n",
      "Epoch 13/80\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.0282 - val_loss: 0.0122\n",
      "Epoch 14/80\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.0283 - val_loss: 0.0128\n",
      "Epoch 15/80\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.0282 - val_loss: 0.0130\n",
      "Epoch 16/80\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.0283 - val_loss: 0.0144\n",
      "Epoch 17/80\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.0280 - val_loss: 0.0144\n",
      "Epoch 18/80\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.0276 - val_loss: 0.0116\n",
      "Epoch 19/80\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.0281 - val_loss: 0.0107\n",
      "Epoch 20/80\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.0282 - val_loss: 0.0138\n",
      "Epoch 21/80\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.0270 - val_loss: 0.0155\n",
      "Epoch 22/80\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.0269 - val_loss: 0.0116\n",
      "Epoch 23/80\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.0281 - val_loss: 0.0137\n",
      "Epoch 24/80\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.0273 - val_loss: 0.0124\n",
      "Epoch 25/80\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.0271 - val_loss: 0.0123\n",
      "Epoch 26/80\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.0264 - val_loss: 0.0115\n",
      "Epoch 27/80\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.0267 - val_loss: 0.0110\n",
      "Epoch 28/80\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.0261 - val_loss: 0.0119\n",
      "Epoch 29/80\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.0257 - val_loss: 0.0107\n",
      "Epoch 30/80\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.0258 - val_loss: 0.0109\n",
      "Epoch 31/80\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.0254 - val_loss: 0.0105\n",
      "Epoch 32/80\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.0253 - val_loss: 0.0107\n",
      "Epoch 33/80\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.0248 - val_loss: 0.0105\n",
      "Epoch 34/80\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.0246 - val_loss: 0.0108\n",
      "Epoch 35/80\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.0243 - val_loss: 0.0107\n",
      "Epoch 36/80\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.0237 - val_loss: 0.0107\n",
      "Epoch 37/80\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.0234 - val_loss: 0.0106\n",
      "Epoch 38/80\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.0231 - val_loss: 0.0105\n",
      "Epoch 39/80\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.0225 - val_loss: 0.0105\n",
      "Epoch 40/80\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.0221 - val_loss: 0.0103\n",
      "Epoch 41/80\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.0216 - val_loss: 0.0105\n",
      "Epoch 42/80\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.0211 - val_loss: 0.0101\n",
      "Epoch 43/80\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.0209 - val_loss: 0.0106\n",
      "Epoch 44/80\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.0206 - val_loss: 0.0103\n",
      "Epoch 45/80\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.0203 - val_loss: 0.0107\n",
      "Epoch 46/80\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.0201 - val_loss: 0.0119\n",
      "Epoch 47/80\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.0199 - val_loss: 0.0108\n",
      "Epoch 48/80\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.0198 - val_loss: 0.0105\n",
      "Epoch 49/80\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.0197 - val_loss: 0.0113\n",
      "Epoch 50/80\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.0195 - val_loss: 0.0114\n",
      "Epoch 51/80\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.0193 - val_loss: 0.0117\n",
      "Epoch 52/80\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.0192 - val_loss: 0.0145\n",
      "Epoch 53/80\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.0193 - val_loss: 0.0102\n",
      "Epoch 54/80\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.0192 - val_loss: 0.0116\n",
      "Epoch 55/80\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.0191 - val_loss: 0.0118\n",
      "Epoch 56/80\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.0192 - val_loss: 0.0110\n",
      "Epoch 57/80\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.0192 - val_loss: 0.0118\n",
      "Epoch 58/80\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.0192 - val_loss: 0.0112\n",
      "Epoch 59/80\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.0192 - val_loss: 0.0113\n",
      "Epoch 60/80\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.0191 - val_loss: 0.0110\n",
      "Epoch 61/80\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.0189 - val_loss: 0.0152\n",
      "Epoch 62/80\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.0191 - val_loss: 0.0126\n",
      "Epoch 63/80\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.0194 - val_loss: 0.0113\n",
      "Epoch 64/80\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.0191 - val_loss: 0.0111\n",
      "Epoch 65/80\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.0190 - val_loss: 0.0116\n",
      "Epoch 66/80\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.0191 - val_loss: 0.0122\n",
      "Epoch 67/80\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.0192 - val_loss: 0.0115\n",
      "Epoch 68/80\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.0192 - val_loss: 0.0118\n",
      "Epoch 69/80\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.0193 - val_loss: 0.0110\n",
      "Epoch 70/80\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.0191 - val_loss: 0.0117\n",
      "Epoch 71/80\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.0189 - val_loss: 0.0118\n",
      "Epoch 72/80\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.0191 - val_loss: 0.0119\n",
      "Epoch 73/80\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.0190 - val_loss: 0.0118\n",
      "Epoch 74/80\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.0189 - val_loss: 0.0117\n",
      "Epoch 75/80\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.0190 - val_loss: 0.0118\n",
      "Epoch 76/80\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.0191 - val_loss: 0.0119\n",
      "Epoch 77/80\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.0190 - val_loss: 0.0110\n",
      "Epoch 78/80\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.0190 - val_loss: 0.0117\n",
      "Epoch 79/80\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.0190 - val_loss: 0.0118\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 80/80\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.0190 - val_loss: 0.0117\n",
      "Execution time:  21.28831934928894\n",
      "DNN:\n",
      "Mean Absolute Error: 0.0124\n",
      "Root Mean Square Error: 0.0214\n",
      "Mean Square Error: 0.0005\n",
      "\n",
      "Train RMSE: 0.021\n",
      "Train MSE: 0.000\n",
      "Train MAE: 0.012\n",
      "###########################\n",
      "\n",
      "MODEL:  DNN\n",
      "sequence:  3h\n",
      "units:  80\n",
      "dropout1:  0.11814836227952394\n",
      "optimizer: adamax\n",
      "activationDense: tanh\n",
      "epochs: 90\n",
      "batchsize: 25\n",
      "validation_split: 0.1\n",
      "Model: \"sequential_61\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_183 (Dense)            (None, 18, 80)            160       \n",
      "_________________________________________________________________\n",
      "dense_184 (Dense)            (None, 18, 16)            1296      \n",
      "_________________________________________________________________\n",
      "dropout_61 (Dropout)         (None, 18, 16)            0         \n",
      "_________________________________________________________________\n",
      "dense_185 (Dense)            (None, 18, 1)             17        \n",
      "=================================================================\n",
      "Total params: 1,473\n",
      "Trainable params: 1,473\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/90\n",
      "143/143 [==============================] - 1s 5ms/step - loss: 0.0938 - val_loss: 0.0126\n",
      "Epoch 2/90\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.0476 - val_loss: 0.0132\n",
      "Epoch 3/90\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.0459 - val_loss: 0.0140\n",
      "Epoch 4/90\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.0440 - val_loss: 0.0102\n",
      "Epoch 5/90\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.0423 - val_loss: 0.0108\n",
      "Epoch 6/90\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.0407 - val_loss: 0.0090\n",
      "Epoch 7/90\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.0392 - val_loss: 0.0056\n",
      "Epoch 8/90\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.0372 - val_loss: 0.0047\n",
      "Epoch 9/90\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.0354 - val_loss: 0.0066\n",
      "Epoch 10/90\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.0340 - val_loss: 0.0077\n",
      "Epoch 11/90\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.0325 - val_loss: 0.0080\n",
      "Epoch 12/90\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.0316 - val_loss: 0.0095\n",
      "Epoch 13/90\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.0304 - val_loss: 0.0095\n",
      "Epoch 14/90\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.0295 - val_loss: 0.0106\n",
      "Epoch 15/90\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.0285 - val_loss: 0.0113\n",
      "Epoch 16/90\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.0276 - val_loss: 0.0112\n",
      "Epoch 17/90\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.0267 - val_loss: 0.0127\n",
      "Epoch 18/90\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.0254 - val_loss: 0.0124\n",
      "Epoch 19/90\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.0244 - val_loss: 0.0123\n",
      "Epoch 20/90\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.0237 - val_loss: 0.0119\n",
      "Epoch 21/90\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.0231 - val_loss: 0.0126\n",
      "Epoch 22/90\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.0222 - val_loss: 0.0111\n",
      "Epoch 23/90\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.0216 - val_loss: 0.0121\n",
      "Epoch 24/90\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.0209 - val_loss: 0.0117\n",
      "Epoch 25/90\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.0201 - val_loss: 0.0103\n",
      "Epoch 26/90\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.0198 - val_loss: 0.0092\n",
      "Epoch 27/90\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.0191 - val_loss: 0.0115\n",
      "Epoch 28/90\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.0186 - val_loss: 0.0119\n",
      "Epoch 29/90\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.0180 - val_loss: 0.0105\n",
      "Epoch 30/90\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.0177 - val_loss: 0.0122\n",
      "Epoch 31/90\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.0174 - val_loss: 0.0133\n",
      "Epoch 32/90\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.0170 - val_loss: 0.0137\n",
      "Epoch 33/90\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.0168 - val_loss: 0.0136\n",
      "Epoch 34/90\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.0166 - val_loss: 0.0136\n",
      "Epoch 35/90\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.0164 - val_loss: 0.0141\n",
      "Epoch 36/90\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.0163 - val_loss: 0.0151\n",
      "Epoch 37/90\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.0163 - val_loss: 0.0147\n",
      "Epoch 38/90\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.0166 - val_loss: 0.0142\n",
      "Epoch 39/90\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.0160 - val_loss: 0.0138\n",
      "Epoch 40/90\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.0160 - val_loss: 0.0147\n",
      "Epoch 41/90\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.0159 - val_loss: 0.0146\n",
      "Epoch 42/90\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.0158 - val_loss: 0.0132\n",
      "Epoch 43/90\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.0157 - val_loss: 0.0157\n",
      "Epoch 44/90\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.0156 - val_loss: 0.0126\n",
      "Epoch 45/90\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.0158 - val_loss: 0.0131\n",
      "Epoch 46/90\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.0158 - val_loss: 0.0138\n",
      "Epoch 47/90\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.0158 - val_loss: 0.0146\n",
      "Epoch 48/90\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.0156 - val_loss: 0.0131\n",
      "Epoch 49/90\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.0156 - val_loss: 0.0136\n",
      "Epoch 50/90\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.0155 - val_loss: 0.0137\n",
      "Epoch 51/90\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.0154 - val_loss: 0.0137\n",
      "Epoch 52/90\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.0156 - val_loss: 0.0137\n",
      "Epoch 53/90\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.0155 - val_loss: 0.0142\n",
      "Epoch 54/90\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.0156 - val_loss: 0.0135\n",
      "Epoch 55/90\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.0155 - val_loss: 0.0138\n",
      "Epoch 56/90\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.0154 - val_loss: 0.0123\n",
      "Epoch 57/90\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.0154 - val_loss: 0.0130\n",
      "Epoch 58/90\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.0156 - val_loss: 0.0123\n",
      "Epoch 59/90\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.0155 - val_loss: 0.0145\n",
      "Epoch 60/90\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.0153 - val_loss: 0.0147\n",
      "Epoch 61/90\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.0153 - val_loss: 0.0151\n",
      "Epoch 62/90\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.0153 - val_loss: 0.0140\n",
      "Epoch 63/90\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.0154 - val_loss: 0.0135\n",
      "Epoch 64/90\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.0154 - val_loss: 0.0135\n",
      "Epoch 65/90\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.0153 - val_loss: 0.0137\n",
      "Epoch 66/90\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.0154 - val_loss: 0.0138\n",
      "Epoch 67/90\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.0156 - val_loss: 0.0130\n",
      "Epoch 68/90\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.0153 - val_loss: 0.0141\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 69/90\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.0153 - val_loss: 0.0122\n",
      "Epoch 70/90\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.0153 - val_loss: 0.0132\n",
      "Epoch 71/90\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.0153 - val_loss: 0.0121\n",
      "Epoch 72/90\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.0152 - val_loss: 0.0134\n",
      "Epoch 73/90\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.0153 - val_loss: 0.0134\n",
      "Epoch 74/90\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.0151 - val_loss: 0.0152\n",
      "Epoch 75/90\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.0151 - val_loss: 0.0121\n",
      "Epoch 76/90\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.0151 - val_loss: 0.0141\n",
      "Epoch 77/90\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.0152 - val_loss: 0.0116\n",
      "Epoch 78/90\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.0152 - val_loss: 0.0139\n",
      "Epoch 79/90\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.0151 - val_loss: 0.0120\n",
      "Epoch 80/90\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.0150 - val_loss: 0.0138\n",
      "Epoch 81/90\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.0152 - val_loss: 0.0119\n",
      "Epoch 82/90\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.0154 - val_loss: 0.0116\n",
      "Epoch 83/90\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.0153 - val_loss: 0.0136\n",
      "Epoch 84/90\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.0152 - val_loss: 0.0130\n",
      "Epoch 85/90\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.0152 - val_loss: 0.0129\n",
      "Epoch 86/90\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.0151 - val_loss: 0.0136\n",
      "Epoch 87/90\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.0149 - val_loss: 0.0147\n",
      "Epoch 88/90\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.0150 - val_loss: 0.0136\n",
      "Epoch 89/90\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.0152 - val_loss: 0.0124\n",
      "Epoch 90/90\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.0152 - val_loss: 0.0139\n",
      "Execution time:  21.43317699432373\n",
      "DNN:\n",
      "Mean Absolute Error: 0.0098\n",
      "Root Mean Square Error: 0.0160\n",
      "Mean Square Error: 0.0003\n",
      "\n",
      "Train RMSE: 0.016\n",
      "Train MSE: 0.000\n",
      "Train MAE: 0.010\n",
      "###########################\n",
      "\n",
      "MODEL:  DNN\n",
      "sequence:  3h\n",
      "units:  12\n",
      "dropout1:  0.48476373451509647\n",
      "optimizer: adamax\n",
      "activationDense: tanh\n",
      "epochs: 52\n",
      "batchsize: 57\n",
      "validation_split: 0.1\n",
      "Model: \"sequential_62\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_186 (Dense)            (None, 18, 12)            24        \n",
      "_________________________________________________________________\n",
      "dense_187 (Dense)            (None, 18, 16)            208       \n",
      "_________________________________________________________________\n",
      "dropout_62 (Dropout)         (None, 18, 16)            0         \n",
      "_________________________________________________________________\n",
      "dense_188 (Dense)            (None, 18, 1)             17        \n",
      "=================================================================\n",
      "Total params: 249\n",
      "Trainable params: 249\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/52\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.2113 - val_loss: 0.0525\n",
      "Epoch 2/52\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.1138 - val_loss: 0.0060\n",
      "Epoch 3/52\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0971 - val_loss: 0.0071\n",
      "Epoch 4/52\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0861 - val_loss: 0.0084\n",
      "Epoch 5/52\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0788 - val_loss: 0.0061\n",
      "Epoch 6/52\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0733 - val_loss: 0.0064\n",
      "Epoch 7/52\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0686 - val_loss: 0.0069\n",
      "Epoch 8/52\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0641 - val_loss: 0.0055\n",
      "Epoch 9/52\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0594 - val_loss: 0.0049\n",
      "Epoch 10/52\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0555 - val_loss: 0.0061\n",
      "Epoch 11/52\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0514 - val_loss: 0.0061\n",
      "Epoch 12/52\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0476 - val_loss: 0.0077\n",
      "Epoch 13/52\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0442 - val_loss: 0.0089\n",
      "Epoch 14/52\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0412 - val_loss: 0.0096\n",
      "Epoch 15/52\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0384 - val_loss: 0.0093\n",
      "Epoch 16/52\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0361 - val_loss: 0.0093\n",
      "Epoch 17/52\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0341 - val_loss: 0.0099\n",
      "Epoch 18/52\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0322 - val_loss: 0.0104\n",
      "Epoch 19/52\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0305 - val_loss: 0.0094\n",
      "Epoch 20/52\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0293 - val_loss: 0.0088\n",
      "Epoch 21/52\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0282 - val_loss: 0.0093\n",
      "Epoch 22/52\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0273 - val_loss: 0.0096\n",
      "Epoch 23/52\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0267 - val_loss: 0.0102\n",
      "Epoch 24/52\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0261 - val_loss: 0.0101\n",
      "Epoch 25/52\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0258 - val_loss: 0.0105\n",
      "Epoch 26/52\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0255 - val_loss: 0.0105\n",
      "Epoch 27/52\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0253 - val_loss: 0.0105\n",
      "Epoch 28/52\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0252 - val_loss: 0.0102\n",
      "Epoch 29/52\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0251 - val_loss: 0.0106\n",
      "Epoch 30/52\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0248 - val_loss: 0.0101\n",
      "Epoch 31/52\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0248 - val_loss: 0.0101\n",
      "Epoch 32/52\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0247 - val_loss: 0.0100\n",
      "Epoch 33/52\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0248 - val_loss: 0.0105\n",
      "Epoch 34/52\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0243 - val_loss: 0.0101\n",
      "Epoch 35/52\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0244 - val_loss: 0.0102\n",
      "Epoch 36/52\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0243 - val_loss: 0.0103\n",
      "Epoch 37/52\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0239 - val_loss: 0.0101\n",
      "Epoch 38/52\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0241 - val_loss: 0.0103\n",
      "Epoch 39/52\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0237 - val_loss: 0.0103\n",
      "Epoch 40/52\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0234 - val_loss: 0.0101\n",
      "Epoch 41/52\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0234 - val_loss: 0.0101\n",
      "Epoch 42/52\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0230 - val_loss: 0.0099\n",
      "Epoch 43/52\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0231 - val_loss: 0.0100\n",
      "Epoch 44/52\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0226 - val_loss: 0.0099\n",
      "Epoch 45/52\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0228 - val_loss: 0.0101\n",
      "Epoch 46/52\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0222 - val_loss: 0.0099\n",
      "Epoch 47/52\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0221 - val_loss: 0.0099\n",
      "Epoch 48/52\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0219 - val_loss: 0.0100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 49/52\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0217 - val_loss: 0.0100\n",
      "Epoch 50/52\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0216 - val_loss: 0.0101\n",
      "Epoch 51/52\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0211 - val_loss: 0.0099\n",
      "Epoch 52/52\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0211 - val_loss: 0.0100\n",
      "Execution time:  7.91131591796875\n",
      "DNN:\n",
      "Mean Absolute Error: 0.0188\n",
      "Root Mean Square Error: 0.0300\n",
      "Mean Square Error: 0.0009\n",
      "\n",
      "Train RMSE: 0.030\n",
      "Train MSE: 0.001\n",
      "Train MAE: 0.019\n",
      "###########################\n",
      "\n",
      "MODEL:  DNN\n",
      "sequence:  3h\n",
      "units:  87\n",
      "dropout1:  0.40519643149940265\n",
      "optimizer: adamax\n",
      "activationDense: tanh\n",
      "epochs: 80\n",
      "batchsize: 31\n",
      "validation_split: 0.2\n",
      "Model: \"sequential_63\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_189 (Dense)            (None, 18, 87)            174       \n",
      "_________________________________________________________________\n",
      "dense_190 (Dense)            (None, 18, 16)            1408      \n",
      "_________________________________________________________________\n",
      "dropout_63 (Dropout)         (None, 18, 16)            0         \n",
      "_________________________________________________________________\n",
      "dense_191 (Dense)            (None, 18, 1)             17        \n",
      "=================================================================\n",
      "Total params: 1,599\n",
      "Trainable params: 1,599\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/80\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 0.1202 - val_loss: 0.0254\n",
      "Epoch 2/80\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.0885 - val_loss: 0.0378\n",
      "Epoch 3/80\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.0791 - val_loss: 0.0319\n",
      "Epoch 4/80\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.0737 - val_loss: 0.0297\n",
      "Epoch 5/80\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.0675 - val_loss: 0.0293\n",
      "Epoch 6/80\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.0602 - val_loss: 0.0230\n",
      "Epoch 7/80\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.0527 - val_loss: 0.0192\n",
      "Epoch 8/80\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.0459 - val_loss: 0.0187\n",
      "Epoch 9/80\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.0409 - val_loss: 0.0194\n",
      "Epoch 10/80\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 0.0368 - val_loss: 0.0175\n",
      "Epoch 11/80\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 0.0331 - val_loss: 0.0136\n",
      "Epoch 12/80\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 0.0304 - val_loss: 0.0131\n",
      "Epoch 13/80\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 0.0279 - val_loss: 0.0124\n",
      "Epoch 14/80\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.0263 - val_loss: 0.0140\n",
      "Epoch 15/80\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.0273 - val_loss: 0.0156\n",
      "Epoch 16/80\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.0295 - val_loss: 0.0144\n",
      "Epoch 17/80\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.0281 - val_loss: 0.0152\n",
      "Epoch 18/80\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.0289 - val_loss: 0.0151\n",
      "Epoch 19/80\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.0289 - val_loss: 0.0147\n",
      "Epoch 20/80\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.0273 - val_loss: 0.0152\n",
      "Epoch 21/80\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.0291 - val_loss: 0.0151\n",
      "Epoch 22/80\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.0263 - val_loss: 0.0150\n",
      "Epoch 23/80\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.0283 - val_loss: 0.0151\n",
      "Epoch 24/80\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 0.0256 - val_loss: 0.0148\n",
      "Epoch 25/80\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.0261 - val_loss: 0.0146\n",
      "Epoch 26/80\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.0252 - val_loss: 0.0146\n",
      "Epoch 27/80\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.0251 - val_loss: 0.0145\n",
      "Epoch 28/80\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.0245 - val_loss: 0.0143\n",
      "Epoch 29/80\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.0243 - val_loss: 0.0142\n",
      "Epoch 30/80\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.0237 - val_loss: 0.0141\n",
      "Epoch 31/80\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.0233 - val_loss: 0.0141\n",
      "Epoch 32/80\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.0230 - val_loss: 0.0139\n",
      "Epoch 33/80\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.0221 - val_loss: 0.0140\n",
      "Epoch 34/80\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.0215 - val_loss: 0.0138\n",
      "Epoch 35/80\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.0206 - val_loss: 0.0139\n",
      "Epoch 36/80\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.0202 - val_loss: 0.0139\n",
      "Epoch 37/80\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.0198 - val_loss: 0.0137\n",
      "Epoch 38/80\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.0195 - val_loss: 0.0137\n",
      "Epoch 39/80\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.0193 - val_loss: 0.0134\n",
      "Epoch 40/80\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.0193 - val_loss: 0.0134\n",
      "Epoch 41/80\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.0189 - val_loss: 0.0132\n",
      "Epoch 42/80\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 0.0190 - val_loss: 0.0133\n",
      "Epoch 43/80\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.0185 - val_loss: 0.0132\n",
      "Epoch 44/80\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.0183 - val_loss: 0.0129\n",
      "Epoch 45/80\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.0183 - val_loss: 0.0128\n",
      "Epoch 46/80\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.0184 - val_loss: 0.0130\n",
      "Epoch 47/80\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.0181 - val_loss: 0.0130\n",
      "Epoch 48/80\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.0182 - val_loss: 0.0128\n",
      "Epoch 49/80\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.0181 - val_loss: 0.0127\n",
      "Epoch 50/80\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.0177 - val_loss: 0.0127\n",
      "Epoch 51/80\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.0180 - val_loss: 0.0128\n",
      "Epoch 52/80\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.0178 - val_loss: 0.0128\n",
      "Epoch 53/80\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.0180 - val_loss: 0.0127\n",
      "Epoch 54/80\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.0177 - val_loss: 0.0125\n",
      "Epoch 55/80\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.0176 - val_loss: 0.0128\n",
      "Epoch 56/80\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.0178 - val_loss: 0.0128\n",
      "Epoch 57/80\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.0179 - val_loss: 0.0128\n",
      "Epoch 58/80\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.0177 - val_loss: 0.0127\n",
      "Epoch 59/80\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.0177 - val_loss: 0.0127\n",
      "Epoch 60/80\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.0177 - val_loss: 0.0126\n",
      "Epoch 61/80\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.0178 - val_loss: 0.0125\n",
      "Epoch 62/80\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.0176 - val_loss: 0.0126\n",
      "Epoch 63/80\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.0178 - val_loss: 0.0126\n",
      "Epoch 64/80\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.0176 - val_loss: 0.0129\n",
      "Epoch 65/80\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.0177 - val_loss: 0.0127\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 66/80\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.0177 - val_loss: 0.0125\n",
      "Epoch 67/80\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.0175 - val_loss: 0.0127\n",
      "Epoch 68/80\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.0176 - val_loss: 0.0127\n",
      "Epoch 69/80\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.0178 - val_loss: 0.0125\n",
      "Epoch 70/80\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.0176 - val_loss: 0.0126\n",
      "Epoch 71/80\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.0175 - val_loss: 0.0127\n",
      "Epoch 72/80\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.0175 - val_loss: 0.0128\n",
      "Epoch 73/80\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.0176 - val_loss: 0.0127\n",
      "Epoch 74/80\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.0176 - val_loss: 0.0128\n",
      "Epoch 75/80\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.0176 - val_loss: 0.0126\n",
      "Epoch 76/80\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 0.0176 - val_loss: 0.0125\n",
      "Epoch 77/80\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 0.0175 - val_loss: 0.0125\n",
      "Epoch 78/80\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 0.0175 - val_loss: 0.0124\n",
      "Epoch 79/80\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 0.0175 - val_loss: 0.0127\n",
      "Epoch 80/80\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.0176 - val_loss: 0.0126\n",
      "Execution time:  20.29176354408264\n",
      "DNN:\n",
      "Mean Absolute Error: 0.0156\n",
      "Root Mean Square Error: 0.0240\n",
      "Mean Square Error: 0.0006\n",
      "\n",
      "Train RMSE: 0.024\n",
      "Train MSE: 0.001\n",
      "Train MAE: 0.016\n",
      "###########################\n",
      "\n",
      "MODEL:  DNN\n",
      "sequence:  3h\n",
      "units:  80\n",
      "dropout1:  0.11814836227952394\n",
      "optimizer: adamax\n",
      "activationDense: tanh\n",
      "epochs: 90\n",
      "batchsize: 25\n",
      "validation_split: 0.2\n",
      "Model: \"sequential_64\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_192 (Dense)            (None, 18, 80)            160       \n",
      "_________________________________________________________________\n",
      "dense_193 (Dense)            (None, 18, 16)            1296      \n",
      "_________________________________________________________________\n",
      "dropout_64 (Dropout)         (None, 18, 16)            0         \n",
      "_________________________________________________________________\n",
      "dense_194 (Dense)            (None, 18, 1)             17        \n",
      "=================================================================\n",
      "Total params: 1,473\n",
      "Trainable params: 1,473\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/90\n",
      "128/128 [==============================] - 0s 3ms/step - loss: 0.1042 - val_loss: 0.0433\n",
      "Epoch 2/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0504 - val_loss: 0.0380\n",
      "Epoch 3/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0482 - val_loss: 0.0378\n",
      "Epoch 4/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0464 - val_loss: 0.0348\n",
      "Epoch 5/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0447 - val_loss: 0.0324\n",
      "Epoch 6/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0433 - val_loss: 0.0280\n",
      "Epoch 7/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0414 - val_loss: 0.0253\n",
      "Epoch 8/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0400 - val_loss: 0.0223\n",
      "Epoch 9/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0386 - val_loss: 0.0177\n",
      "Epoch 10/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0371 - val_loss: 0.0227\n",
      "Epoch 11/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0362 - val_loss: 0.0192\n",
      "Epoch 12/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0342 - val_loss: 0.0232\n",
      "Epoch 13/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0329 - val_loss: 0.0234\n",
      "Epoch 14/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0317 - val_loss: 0.0231\n",
      "Epoch 15/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0309 - val_loss: 0.0193\n",
      "Epoch 16/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0299 - val_loss: 0.0183\n",
      "Epoch 17/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0291 - val_loss: 0.0177\n",
      "Epoch 18/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0285 - val_loss: 0.0144\n",
      "Epoch 19/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0273 - val_loss: 0.0140\n",
      "Epoch 20/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0267 - val_loss: 0.0151\n",
      "Epoch 21/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0263 - val_loss: 0.0123\n",
      "Epoch 22/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0259 - val_loss: 0.0123\n",
      "Epoch 23/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0250 - val_loss: 0.0114\n",
      "Epoch 24/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0243 - val_loss: 0.0111\n",
      "Epoch 25/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0236 - val_loss: 0.0108\n",
      "Epoch 26/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0228 - val_loss: 0.0106\n",
      "Epoch 27/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0223 - val_loss: 0.0103\n",
      "Epoch 28/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0216 - val_loss: 0.0106\n",
      "Epoch 29/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0210 - val_loss: 0.0103\n",
      "Epoch 30/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0206 - val_loss: 0.0102\n",
      "Epoch 31/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0200 - val_loss: 0.0100\n",
      "Epoch 32/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0195 - val_loss: 0.0096\n",
      "Epoch 33/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0189 - val_loss: 0.0095\n",
      "Epoch 34/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0188 - val_loss: 0.0095\n",
      "Epoch 35/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0183 - val_loss: 0.0096\n",
      "Epoch 36/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0178 - val_loss: 0.0096\n",
      "Epoch 37/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0178 - val_loss: 0.0095\n",
      "Epoch 38/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0173 - val_loss: 0.0102\n",
      "Epoch 39/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0170 - val_loss: 0.0104\n",
      "Epoch 40/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0169 - val_loss: 0.0109\n",
      "Epoch 41/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0166 - val_loss: 0.0111\n",
      "Epoch 42/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0164 - val_loss: 0.0111\n",
      "Epoch 43/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0163 - val_loss: 0.0111\n",
      "Epoch 44/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0161 - val_loss: 0.0117\n",
      "Epoch 45/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0160 - val_loss: 0.0118\n",
      "Epoch 46/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0158 - val_loss: 0.0121\n",
      "Epoch 47/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0158 - val_loss: 0.0126\n",
      "Epoch 48/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0160 - val_loss: 0.0125\n",
      "Epoch 49/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0157 - val_loss: 0.0125\n",
      "Epoch 50/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0157 - val_loss: 0.0125\n",
      "Epoch 51/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0155 - val_loss: 0.0123\n",
      "Epoch 52/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0156 - val_loss: 0.0125\n",
      "Epoch 53/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0155 - val_loss: 0.0123\n",
      "Epoch 54/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0154 - val_loss: 0.0124\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 55/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0155 - val_loss: 0.0123\n",
      "Epoch 56/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0154 - val_loss: 0.0126\n",
      "Epoch 57/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0155 - val_loss: 0.0126\n",
      "Epoch 58/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0156 - val_loss: 0.0124\n",
      "Epoch 59/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0154 - val_loss: 0.0125\n",
      "Epoch 60/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0154 - val_loss: 0.0125\n",
      "Epoch 61/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0154 - val_loss: 0.0124\n",
      "Epoch 62/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0152 - val_loss: 0.0127\n",
      "Epoch 63/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0155 - val_loss: 0.0126\n",
      "Epoch 64/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0153 - val_loss: 0.0124\n",
      "Epoch 65/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0153 - val_loss: 0.0125\n",
      "Epoch 66/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0153 - val_loss: 0.0122\n",
      "Epoch 67/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0151 - val_loss: 0.0127\n",
      "Epoch 68/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0154 - val_loss: 0.0126\n",
      "Epoch 69/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0153 - val_loss: 0.0125\n",
      "Epoch 70/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0152 - val_loss: 0.0125\n",
      "Epoch 71/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0152 - val_loss: 0.0123\n",
      "Epoch 72/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0150 - val_loss: 0.0125\n",
      "Epoch 73/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0153 - val_loss: 0.0125\n",
      "Epoch 74/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0152 - val_loss: 0.0124\n",
      "Epoch 75/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0152 - val_loss: 0.0123\n",
      "Epoch 76/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0152 - val_loss: 0.0125\n",
      "Epoch 77/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0152 - val_loss: 0.0124\n",
      "Epoch 78/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0151 - val_loss: 0.0126\n",
      "Epoch 79/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0152 - val_loss: 0.0124\n",
      "Epoch 80/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0152 - val_loss: 0.0128\n",
      "Epoch 81/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0151 - val_loss: 0.0127\n",
      "Epoch 82/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0151 - val_loss: 0.0128\n",
      "Epoch 83/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0151 - val_loss: 0.0126\n",
      "Epoch 84/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0150 - val_loss: 0.0128\n",
      "Epoch 85/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0152 - val_loss: 0.0126\n",
      "Epoch 86/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0150 - val_loss: 0.0126\n",
      "Epoch 87/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0150 - val_loss: 0.0128\n",
      "Epoch 88/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0151 - val_loss: 0.0121\n",
      "Epoch 89/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0149 - val_loss: 0.0125\n",
      "Epoch 90/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0149 - val_loss: 0.0127\n",
      "Execution time:  24.604466676712036\n",
      "DNN:\n",
      "Mean Absolute Error: 0.0143\n",
      "Root Mean Square Error: 0.0230\n",
      "Mean Square Error: 0.0005\n",
      "\n",
      "Train RMSE: 0.023\n",
      "Train MSE: 0.001\n",
      "Train MAE: 0.014\n",
      "###########################\n",
      "\n",
      "MODEL:  DNN\n",
      "sequence:  3h\n",
      "units:  12\n",
      "dropout1:  0.48476373451509647\n",
      "optimizer: adamax\n",
      "activationDense: tanh\n",
      "epochs: 52\n",
      "batchsize: 57\n",
      "validation_split: 0.2\n",
      "Model: \"sequential_65\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_195 (Dense)            (None, 18, 12)            24        \n",
      "_________________________________________________________________\n",
      "dense_196 (Dense)            (None, 18, 16)            208       \n",
      "_________________________________________________________________\n",
      "dropout_65 (Dropout)         (None, 18, 16)            0         \n",
      "_________________________________________________________________\n",
      "dense_197 (Dense)            (None, 18, 1)             17        \n",
      "=================================================================\n",
      "Total params: 249\n",
      "Trainable params: 249\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/52\n",
      "56/56 [==============================] - 0s 5ms/step - loss: 0.4759 - val_loss: 0.2638\n",
      "Epoch 2/52\n",
      "56/56 [==============================] - 0s 2ms/step - loss: 0.1996 - val_loss: 0.0840\n",
      "Epoch 3/52\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 0.1209 - val_loss: 0.0278\n",
      "Epoch 4/52\n",
      "56/56 [==============================] - 0s 2ms/step - loss: 0.1044 - val_loss: 0.0294\n",
      "Epoch 5/52\n",
      "56/56 [==============================] - 0s 2ms/step - loss: 0.0957 - val_loss: 0.0303\n",
      "Epoch 6/52\n",
      "56/56 [==============================] - 0s 2ms/step - loss: 0.0873 - val_loss: 0.0308\n",
      "Epoch 7/52\n",
      "56/56 [==============================] - 0s 2ms/step - loss: 0.0805 - val_loss: 0.0284\n",
      "Epoch 8/52\n",
      "56/56 [==============================] - 0s 2ms/step - loss: 0.0733 - val_loss: 0.0242\n",
      "Epoch 9/52\n",
      "56/56 [==============================] - 0s 2ms/step - loss: 0.0664 - val_loss: 0.0192\n",
      "Epoch 10/52\n",
      "56/56 [==============================] - 0s 2ms/step - loss: 0.0598 - val_loss: 0.0158\n",
      "Epoch 11/52\n",
      "56/56 [==============================] - 0s 2ms/step - loss: 0.0535 - val_loss: 0.0141\n",
      "Epoch 12/52\n",
      "56/56 [==============================] - 0s 2ms/step - loss: 0.0463 - val_loss: 0.0140\n",
      "Epoch 13/52\n",
      "56/56 [==============================] - 0s 2ms/step - loss: 0.0397 - val_loss: 0.0155\n",
      "Epoch 14/52\n",
      "56/56 [==============================] - 0s 2ms/step - loss: 0.0356 - val_loss: 0.0147\n",
      "Epoch 15/52\n",
      "56/56 [==============================] - 0s 2ms/step - loss: 0.0330 - val_loss: 0.0151\n",
      "Epoch 16/52\n",
      "56/56 [==============================] - 0s 2ms/step - loss: 0.0310 - val_loss: 0.0156\n",
      "Epoch 17/52\n",
      "56/56 [==============================] - 0s 2ms/step - loss: 0.0292 - val_loss: 0.0157\n",
      "Epoch 18/52\n",
      "56/56 [==============================] - 0s 2ms/step - loss: 0.0279 - val_loss: 0.0155\n",
      "Epoch 19/52\n",
      "56/56 [==============================] - 0s 2ms/step - loss: 0.0270 - val_loss: 0.0151\n",
      "Epoch 20/52\n",
      "56/56 [==============================] - 0s 2ms/step - loss: 0.0262 - val_loss: 0.0147\n",
      "Epoch 21/52\n",
      "56/56 [==============================] - 0s 2ms/step - loss: 0.0258 - val_loss: 0.0146\n",
      "Epoch 22/52\n",
      "56/56 [==============================] - 0s 2ms/step - loss: 0.0254 - val_loss: 0.0146\n",
      "Epoch 23/52\n",
      "56/56 [==============================] - 0s 2ms/step - loss: 0.0252 - val_loss: 0.0148\n",
      "Epoch 24/52\n",
      "56/56 [==============================] - 0s 2ms/step - loss: 0.0249 - val_loss: 0.0147\n",
      "Epoch 25/52\n",
      "56/56 [==============================] - 0s 2ms/step - loss: 0.0247 - val_loss: 0.0147\n",
      "Epoch 26/52\n",
      "56/56 [==============================] - 0s 2ms/step - loss: 0.0244 - val_loss: 0.0146\n",
      "Epoch 27/52\n",
      "56/56 [==============================] - 0s 2ms/step - loss: 0.0241 - val_loss: 0.0143\n",
      "Epoch 28/52\n",
      "56/56 [==============================] - 0s 2ms/step - loss: 0.0239 - val_loss: 0.0142\n",
      "Epoch 29/52\n",
      "56/56 [==============================] - 0s 2ms/step - loss: 0.0235 - val_loss: 0.0143\n",
      "Epoch 30/52\n",
      "56/56 [==============================] - 0s 2ms/step - loss: 0.0231 - val_loss: 0.0143\n",
      "Epoch 31/52\n",
      "56/56 [==============================] - 0s 2ms/step - loss: 0.0228 - val_loss: 0.0141\n",
      "Epoch 32/52\n",
      "56/56 [==============================] - 0s 2ms/step - loss: 0.0224 - val_loss: 0.0141\n",
      "Epoch 33/52\n",
      "56/56 [==============================] - 0s 2ms/step - loss: 0.0221 - val_loss: 0.0139\n",
      "Epoch 34/52\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "56/56 [==============================] - 0s 2ms/step - loss: 0.0215 - val_loss: 0.0139\n",
      "Epoch 35/52\n",
      "56/56 [==============================] - 0s 2ms/step - loss: 0.0212 - val_loss: 0.0138\n",
      "Epoch 36/52\n",
      "56/56 [==============================] - 0s 2ms/step - loss: 0.0209 - val_loss: 0.0135\n",
      "Epoch 37/52\n",
      "56/56 [==============================] - 0s 2ms/step - loss: 0.0205 - val_loss: 0.0135\n",
      "Epoch 38/52\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 0.0203 - val_loss: 0.0132\n",
      "Epoch 39/52\n",
      "56/56 [==============================] - 0s 2ms/step - loss: 0.0200 - val_loss: 0.0131\n",
      "Epoch 40/52\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 0.0198 - val_loss: 0.0128\n",
      "Epoch 41/52\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 0.0196 - val_loss: 0.0128\n",
      "Epoch 42/52\n",
      "56/56 [==============================] - 0s 2ms/step - loss: 0.0194 - val_loss: 0.0125\n",
      "Epoch 43/52\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 0.0193 - val_loss: 0.0124\n",
      "Epoch 44/52\n",
      "56/56 [==============================] - 0s 2ms/step - loss: 0.0189 - val_loss: 0.0124\n",
      "Epoch 45/52\n",
      "56/56 [==============================] - 0s 2ms/step - loss: 0.0187 - val_loss: 0.0126\n",
      "Epoch 46/52\n",
      "56/56 [==============================] - 0s 2ms/step - loss: 0.0187 - val_loss: 0.0124\n",
      "Epoch 47/52\n",
      "56/56 [==============================] - 0s 2ms/step - loss: 0.0184 - val_loss: 0.0122\n",
      "Epoch 48/52\n",
      "56/56 [==============================] - 0s 2ms/step - loss: 0.0186 - val_loss: 0.0121\n",
      "Epoch 49/52\n",
      "56/56 [==============================] - 0s 2ms/step - loss: 0.0183 - val_loss: 0.0117\n",
      "Epoch 50/52\n",
      "56/56 [==============================] - 0s 2ms/step - loss: 0.0183 - val_loss: 0.0117\n",
      "Epoch 51/52\n",
      "56/56 [==============================] - 0s 2ms/step - loss: 0.0183 - val_loss: 0.0116\n",
      "Epoch 52/52\n",
      "56/56 [==============================] - 0s 2ms/step - loss: 0.0184 - val_loss: 0.0115\n",
      "Execution time:  7.554470777511597\n",
      "DNN:\n",
      "Mean Absolute Error: 0.0106\n",
      "Root Mean Square Error: 0.0198\n",
      "Mean Square Error: 0.0004\n",
      "\n",
      "Train RMSE: 0.020\n",
      "Train MSE: 0.000\n",
      "Train MAE: 0.011\n",
      "###########################\n",
      "\n",
      "MODEL:  DNN\n",
      "sequence:  3h\n",
      "units:  87\n",
      "dropout1:  0.40519643149940265\n",
      "optimizer: adamax\n",
      "activationDense: sigmoid\n",
      "epochs: 80\n",
      "batchsize: 31\n",
      "validation_split: 0.1\n",
      "Model: \"sequential_66\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_198 (Dense)            (None, 18, 87)            174       \n",
      "_________________________________________________________________\n",
      "dense_199 (Dense)            (None, 18, 16)            1408      \n",
      "_________________________________________________________________\n",
      "dropout_66 (Dropout)         (None, 18, 16)            0         \n",
      "_________________________________________________________________\n",
      "dense_200 (Dense)            (None, 18, 1)             17        \n",
      "=================================================================\n",
      "Total params: 1,599\n",
      "Trainable params: 1,599\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/80\n",
      "116/116 [==============================] - 0s 4ms/step - loss: 0.0583 - val_loss: 0.0418\n",
      "Epoch 2/80\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.0425 - val_loss: 0.0377\n",
      "Epoch 3/80\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.0402 - val_loss: 0.0332\n",
      "Epoch 4/80\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.0387 - val_loss: 0.0309\n",
      "Epoch 5/80\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.0374 - val_loss: 0.0292\n",
      "Epoch 6/80\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.0362 - val_loss: 0.0266\n",
      "Epoch 7/80\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.0353 - val_loss: 0.0242\n",
      "Epoch 8/80\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.0344 - val_loss: 0.0226\n",
      "Epoch 9/80\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.0337 - val_loss: 0.0218\n",
      "Epoch 10/80\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.0329 - val_loss: 0.0208\n",
      "Epoch 11/80\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.0323 - val_loss: 0.0200\n",
      "Epoch 12/80\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.0316 - val_loss: 0.0190\n",
      "Epoch 13/80\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.0310 - val_loss: 0.0179\n",
      "Epoch 14/80\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.0305 - val_loss: 0.0176\n",
      "Epoch 15/80\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.0299 - val_loss: 0.0170\n",
      "Epoch 16/80\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.0295 - val_loss: 0.0164\n",
      "Epoch 17/80\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.0290 - val_loss: 0.0160\n",
      "Epoch 18/80\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.0286 - val_loss: 0.0156\n",
      "Epoch 19/80\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.0282 - val_loss: 0.0153\n",
      "Epoch 20/80\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.0278 - val_loss: 0.0149\n",
      "Epoch 21/80\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.0275 - val_loss: 0.0145\n",
      "Epoch 22/80\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.0272 - val_loss: 0.0143\n",
      "Epoch 23/80\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.0269 - val_loss: 0.0139\n",
      "Epoch 24/80\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.0266 - val_loss: 0.0134\n",
      "Epoch 25/80\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.0264 - val_loss: 0.0131\n",
      "Epoch 26/80\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.0262 - val_loss: 0.0128\n",
      "Epoch 27/80\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.0260 - val_loss: 0.0126\n",
      "Epoch 28/80\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.0258 - val_loss: 0.0124\n",
      "Epoch 29/80\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.0258 - val_loss: 0.0125\n",
      "Epoch 30/80\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.0254 - val_loss: 0.0122\n",
      "Epoch 31/80\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.0253 - val_loss: 0.0122\n",
      "Epoch 32/80\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.0251 - val_loss: 0.0119\n",
      "Epoch 33/80\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.0249 - val_loss: 0.0121\n",
      "Epoch 34/80\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.0247 - val_loss: 0.0120\n",
      "Epoch 35/80\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.0245 - val_loss: 0.0121\n",
      "Epoch 36/80\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.0242 - val_loss: 0.0118\n",
      "Epoch 37/80\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.0239 - val_loss: 0.0119\n",
      "Epoch 38/80\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.0237 - val_loss: 0.0120\n",
      "Epoch 39/80\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.0233 - val_loss: 0.0121\n",
      "Epoch 40/80\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.0231 - val_loss: 0.0122\n",
      "Epoch 41/80\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.0228 - val_loss: 0.0122\n",
      "Epoch 42/80\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.0225 - val_loss: 0.0121\n",
      "Epoch 43/80\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.0223 - val_loss: 0.0122\n",
      "Epoch 44/80\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.0219 - val_loss: 0.0121\n",
      "Epoch 45/80\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.0216 - val_loss: 0.0123\n",
      "Epoch 46/80\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.0213 - val_loss: 0.0121\n",
      "Epoch 47/80\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.0209 - val_loss: 0.0126\n",
      "Epoch 48/80\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.0207 - val_loss: 0.0125\n",
      "Epoch 49/80\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.0204 - val_loss: 0.0126\n",
      "Epoch 50/80\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.0202 - val_loss: 0.0124\n",
      "Epoch 51/80\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "116/116 [==============================] - 0s 2ms/step - loss: 0.0198 - val_loss: 0.0126\n",
      "Epoch 52/80\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.0197 - val_loss: 0.0124\n",
      "Epoch 53/80\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.0195 - val_loss: 0.0121\n",
      "Epoch 54/80\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.0193 - val_loss: 0.0129\n",
      "Epoch 55/80\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.0191 - val_loss: 0.0128\n",
      "Epoch 56/80\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.0189 - val_loss: 0.0125\n",
      "Epoch 57/80\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.0187 - val_loss: 0.0127\n",
      "Epoch 58/80\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.0186 - val_loss: 0.0127\n",
      "Epoch 59/80\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.0184 - val_loss: 0.0126\n",
      "Epoch 60/80\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.0183 - val_loss: 0.0131\n",
      "Epoch 61/80\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.0181 - val_loss: 0.0127\n",
      "Epoch 62/80\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.0181 - val_loss: 0.0126\n",
      "Epoch 63/80\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.0180 - val_loss: 0.0125\n",
      "Epoch 64/80\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.0179 - val_loss: 0.0125\n",
      "Epoch 65/80\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.0180 - val_loss: 0.0123\n",
      "Epoch 66/80\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.0179 - val_loss: 0.0125\n",
      "Epoch 67/80\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.0179 - val_loss: 0.0120\n",
      "Epoch 68/80\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.0178 - val_loss: 0.0122\n",
      "Epoch 69/80\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.0178 - val_loss: 0.0121\n",
      "Epoch 70/80\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.0178 - val_loss: 0.0122\n",
      "Epoch 71/80\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.0179 - val_loss: 0.0119\n",
      "Epoch 72/80\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.0178 - val_loss: 0.0120\n",
      "Epoch 73/80\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.0177 - val_loss: 0.0121\n",
      "Epoch 74/80\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.0178 - val_loss: 0.0119\n",
      "Epoch 75/80\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.0177 - val_loss: 0.0118\n",
      "Epoch 76/80\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.0177 - val_loss: 0.0118\n",
      "Epoch 77/80\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.0177 - val_loss: 0.0118\n",
      "Epoch 78/80\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.0176 - val_loss: 0.0116\n",
      "Epoch 79/80\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.0176 - val_loss: 0.0120\n",
      "Epoch 80/80\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.0176 - val_loss: 0.0118\n",
      "Execution time:  21.08873200416565\n",
      "DNN:\n",
      "Mean Absolute Error: 0.0108\n",
      "Root Mean Square Error: 0.0199\n",
      "Mean Square Error: 0.0004\n",
      "\n",
      "Train RMSE: 0.020\n",
      "Train MSE: 0.000\n",
      "Train MAE: 0.011\n",
      "###########################\n",
      "\n",
      "MODEL:  DNN\n",
      "sequence:  3h\n",
      "units:  80\n",
      "dropout1:  0.11814836227952394\n",
      "optimizer: adamax\n",
      "activationDense: sigmoid\n",
      "epochs: 90\n",
      "batchsize: 25\n",
      "validation_split: 0.1\n",
      "Model: \"sequential_67\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_201 (Dense)            (None, 18, 80)            160       \n",
      "_________________________________________________________________\n",
      "dense_202 (Dense)            (None, 18, 16)            1296      \n",
      "_________________________________________________________________\n",
      "dropout_67 (Dropout)         (None, 18, 16)            0         \n",
      "_________________________________________________________________\n",
      "dense_203 (Dense)            (None, 18, 1)             17        \n",
      "=================================================================\n",
      "Total params: 1,473\n",
      "Trainable params: 1,473\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/90\n",
      "143/143 [==============================] - 0s 3ms/step - loss: 0.0372 - val_loss: 0.0236\n",
      "Epoch 2/90\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.0365 - val_loss: 0.0203\n",
      "Epoch 3/90\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.0359 - val_loss: 0.0191\n",
      "Epoch 4/90\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.0354 - val_loss: 0.0187\n",
      "Epoch 5/90\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.0349 - val_loss: 0.0189\n",
      "Epoch 6/90\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.0344 - val_loss: 0.0189\n",
      "Epoch 7/90\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.0337 - val_loss: 0.0180\n",
      "Epoch 8/90\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.0332 - val_loss: 0.0185\n",
      "Epoch 9/90\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.0327 - val_loss: 0.0182\n",
      "Epoch 10/90\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.0323 - val_loss: 0.0171\n",
      "Epoch 11/90\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.0318 - val_loss: 0.0185\n",
      "Epoch 12/90\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.0316 - val_loss: 0.0173\n",
      "Epoch 13/90\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.0309 - val_loss: 0.0168\n",
      "Epoch 14/90\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.0306 - val_loss: 0.0169\n",
      "Epoch 15/90\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.0302 - val_loss: 0.0164\n",
      "Epoch 16/90\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.0298 - val_loss: 0.0164\n",
      "Epoch 17/90\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.0289 - val_loss: 0.0165\n",
      "Epoch 18/90\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.0286 - val_loss: 0.0160\n",
      "Epoch 19/90\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.0279 - val_loss: 0.0164\n",
      "Epoch 20/90\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.0271 - val_loss: 0.0162\n",
      "Epoch 21/90\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.0266 - val_loss: 0.0148\n",
      "Epoch 22/90\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.0258 - val_loss: 0.0161\n",
      "Epoch 23/90\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.0253 - val_loss: 0.0156\n",
      "Epoch 24/90\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.0241 - val_loss: 0.0157\n",
      "Epoch 25/90\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.0235 - val_loss: 0.0148\n",
      "Epoch 26/90\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.0227 - val_loss: 0.0140\n",
      "Epoch 27/90\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.0222 - val_loss: 0.0135\n",
      "Epoch 28/90\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.0213 - val_loss: 0.0136\n",
      "Epoch 29/90\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.0203 - val_loss: 0.0148\n",
      "Epoch 30/90\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.0197 - val_loss: 0.0158\n",
      "Epoch 31/90\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.0191 - val_loss: 0.0145\n",
      "Epoch 32/90\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.0184 - val_loss: 0.0139\n",
      "Epoch 33/90\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.0178 - val_loss: 0.0137\n",
      "Epoch 34/90\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.0171 - val_loss: 0.0147\n",
      "Epoch 35/90\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.0166 - val_loss: 0.0128\n",
      "Epoch 36/90\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.0163 - val_loss: 0.0121\n",
      "Epoch 37/90\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.0160 - val_loss: 0.0115\n",
      "Epoch 38/90\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.0159 - val_loss: 0.0113\n",
      "Epoch 39/90\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.0158 - val_loss: 0.0112\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 40/90\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.0155 - val_loss: 0.0100\n",
      "Epoch 41/90\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.0155 - val_loss: 0.0094\n",
      "Epoch 42/90\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.0154 - val_loss: 0.0093\n",
      "Epoch 43/90\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.0154 - val_loss: 0.0082\n",
      "Epoch 44/90\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.0153 - val_loss: 0.0088\n",
      "Epoch 45/90\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.0153 - val_loss: 0.0087\n",
      "Epoch 46/90\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.0152 - val_loss: 0.0078\n",
      "Epoch 47/90\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.0153 - val_loss: 0.0084\n",
      "Epoch 48/90\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.0152 - val_loss: 0.0078\n",
      "Epoch 49/90\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.0152 - val_loss: 0.0086\n",
      "Epoch 50/90\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.0152 - val_loss: 0.0074\n",
      "Epoch 51/90\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.0152 - val_loss: 0.0082\n",
      "Epoch 52/90\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.0152 - val_loss: 0.0080\n",
      "Epoch 53/90\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.0151 - val_loss: 0.0080\n",
      "Epoch 54/90\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.0151 - val_loss: 0.0075\n",
      "Epoch 55/90\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.0151 - val_loss: 0.0086\n",
      "Epoch 56/90\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.0150 - val_loss: 0.0074\n",
      "Epoch 57/90\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.0150 - val_loss: 0.0074\n",
      "Epoch 58/90\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.0150 - val_loss: 0.0074\n",
      "Epoch 59/90\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.0151 - val_loss: 0.0087\n",
      "Epoch 60/90\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.0150 - val_loss: 0.0077\n",
      "Epoch 61/90\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.0150 - val_loss: 0.0075\n",
      "Epoch 62/90\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.0150 - val_loss: 0.0079\n",
      "Epoch 63/90\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.0149 - val_loss: 0.0084\n",
      "Epoch 64/90\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.0149 - val_loss: 0.0076\n",
      "Epoch 65/90\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.0149 - val_loss: 0.0087\n",
      "Epoch 66/90\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.0149 - val_loss: 0.0078\n",
      "Epoch 67/90\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.0148 - val_loss: 0.0089\n",
      "Epoch 68/90\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.0149 - val_loss: 0.0091\n",
      "Epoch 69/90\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.0149 - val_loss: 0.0079\n",
      "Epoch 70/90\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.0149 - val_loss: 0.0089\n",
      "Epoch 71/90\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.0149 - val_loss: 0.0091\n",
      "Epoch 72/90\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.0148 - val_loss: 0.0089\n",
      "Epoch 73/90\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.0148 - val_loss: 0.0094\n",
      "Epoch 74/90\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.0149 - val_loss: 0.0093\n",
      "Epoch 75/90\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.0149 - val_loss: 0.0085\n",
      "Epoch 76/90\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.0149 - val_loss: 0.0089\n",
      "Epoch 77/90\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.0148 - val_loss: 0.0084\n",
      "Epoch 78/90\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.0149 - val_loss: 0.0092\n",
      "Epoch 79/90\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.0148 - val_loss: 0.0086\n",
      "Epoch 80/90\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.0149 - val_loss: 0.0084\n",
      "Epoch 81/90\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.0148 - val_loss: 0.0084\n",
      "Epoch 82/90\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.0149 - val_loss: 0.0084\n",
      "Epoch 83/90\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.0149 - val_loss: 0.0083\n",
      "Epoch 84/90\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.0148 - val_loss: 0.0093\n",
      "Epoch 85/90\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.0147 - val_loss: 0.0083\n",
      "Epoch 86/90\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.0148 - val_loss: 0.0092\n",
      "Epoch 87/90\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.0147 - val_loss: 0.0097\n",
      "Epoch 88/90\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.0148 - val_loss: 0.0094\n",
      "Epoch 89/90\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.0148 - val_loss: 0.0092\n",
      "Epoch 90/90\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.0147 - val_loss: 0.0095\n",
      "Execution time:  21.09965682029724\n",
      "DNN:\n",
      "Mean Absolute Error: 0.0066\n",
      "Root Mean Square Error: 0.0163\n",
      "Mean Square Error: 0.0003\n",
      "\n",
      "Train RMSE: 0.016\n",
      "Train MSE: 0.000\n",
      "Train MAE: 0.007\n",
      "###########################\n",
      "\n",
      "MODEL:  DNN\n",
      "sequence:  3h\n",
      "units:  12\n",
      "dropout1:  0.48476373451509647\n",
      "optimizer: adamax\n",
      "activationDense: sigmoid\n",
      "epochs: 52\n",
      "batchsize: 57\n",
      "validation_split: 0.1\n",
      "Model: \"sequential_68\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_204 (Dense)            (None, 18, 12)            24        \n",
      "_________________________________________________________________\n",
      "dense_205 (Dense)            (None, 18, 16)            208       \n",
      "_________________________________________________________________\n",
      "dropout_68 (Dropout)         (None, 18, 16)            0         \n",
      "_________________________________________________________________\n",
      "dense_206 (Dense)            (None, 18, 1)             17        \n",
      "=================================================================\n",
      "Total params: 249\n",
      "Trainable params: 249\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/52\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.0548 - val_loss: 0.0596\n",
      "Epoch 2/52\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0499 - val_loss: 0.0534\n",
      "Epoch 3/52\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0483 - val_loss: 0.0502\n",
      "Epoch 4/52\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0462 - val_loss: 0.0480\n",
      "Epoch 5/52\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0446 - val_loss: 0.0463\n",
      "Epoch 6/52\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0434 - val_loss: 0.0448\n",
      "Epoch 7/52\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0423 - val_loss: 0.0439\n",
      "Epoch 8/52\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0410 - val_loss: 0.0427\n",
      "Epoch 9/52\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0400 - val_loss: 0.0423\n",
      "Epoch 10/52\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0391 - val_loss: 0.0412\n",
      "Epoch 11/52\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0380 - val_loss: 0.0403\n",
      "Epoch 12/52\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0374 - val_loss: 0.0394\n",
      "Epoch 13/52\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0363 - val_loss: 0.0385\n",
      "Epoch 14/52\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0356 - val_loss: 0.0376\n",
      "Epoch 15/52\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0350 - val_loss: 0.0365\n",
      "Epoch 16/52\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0342 - val_loss: 0.0354\n",
      "Epoch 17/52\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0337 - val_loss: 0.0332\n",
      "Epoch 18/52\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0331 - val_loss: 0.0321\n",
      "Epoch 19/52\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0326 - val_loss: 0.0307\n",
      "Epoch 20/52\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0323 - val_loss: 0.0297\n",
      "Epoch 21/52\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0319 - val_loss: 0.0290\n",
      "Epoch 22/52\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0316 - val_loss: 0.0281\n",
      "Epoch 23/52\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0313 - val_loss: 0.0274\n",
      "Epoch 24/52\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0308 - val_loss: 0.0266\n",
      "Epoch 25/52\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0306 - val_loss: 0.0261\n",
      "Epoch 26/52\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0303 - val_loss: 0.0256\n",
      "Epoch 27/52\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0300 - val_loss: 0.0250\n",
      "Epoch 28/52\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0298 - val_loss: 0.0248\n",
      "Epoch 29/52\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0294 - val_loss: 0.0242\n",
      "Epoch 30/52\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0293 - val_loss: 0.0240\n",
      "Epoch 31/52\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0290 - val_loss: 0.0236\n",
      "Epoch 32/52\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0289 - val_loss: 0.0232\n",
      "Epoch 33/52\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0288 - val_loss: 0.0229\n",
      "Epoch 34/52\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0287 - val_loss: 0.0226\n",
      "Epoch 35/52\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0285 - val_loss: 0.0222\n",
      "Epoch 36/52\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0284 - val_loss: 0.0221\n",
      "Epoch 37/52\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0282 - val_loss: 0.0218\n",
      "Epoch 38/52\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0282 - val_loss: 0.0218\n",
      "Epoch 39/52\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0281 - val_loss: 0.0219\n",
      "Epoch 40/52\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0280 - val_loss: 0.0217\n",
      "Epoch 41/52\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0279 - val_loss: 0.0206\n",
      "Epoch 42/52\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0279 - val_loss: 0.0206\n",
      "Epoch 43/52\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0278 - val_loss: 0.0205\n",
      "Epoch 44/52\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0277 - val_loss: 0.0203\n",
      "Epoch 45/52\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0277 - val_loss: 0.0202\n",
      "Epoch 46/52\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0276 - val_loss: 0.0201\n",
      "Epoch 47/52\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0276 - val_loss: 0.0200\n",
      "Epoch 48/52\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0275 - val_loss: 0.0199\n",
      "Epoch 49/52\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0275 - val_loss: 0.0196\n",
      "Epoch 50/52\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0274 - val_loss: 0.0196\n",
      "Epoch 51/52\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0274 - val_loss: 0.0194\n",
      "Epoch 52/52\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0273 - val_loss: 0.0198\n",
      "Execution time:  8.262229681015015\n",
      "DNN:\n",
      "Mean Absolute Error: 0.0262\n",
      "Root Mean Square Error: 0.0430\n",
      "Mean Square Error: 0.0019\n",
      "\n",
      "Train RMSE: 0.043\n",
      "Train MSE: 0.002\n",
      "Train MAE: 0.026\n",
      "###########################\n",
      "\n",
      "MODEL:  DNN\n",
      "sequence:  3h\n",
      "units:  87\n",
      "dropout1:  0.40519643149940265\n",
      "optimizer: adamax\n",
      "activationDense: sigmoid\n",
      "epochs: 80\n",
      "batchsize: 31\n",
      "validation_split: 0.2\n",
      "Model: \"sequential_69\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_207 (Dense)            (None, 18, 87)            174       \n",
      "_________________________________________________________________\n",
      "dense_208 (Dense)            (None, 18, 16)            1408      \n",
      "_________________________________________________________________\n",
      "dropout_69 (Dropout)         (None, 18, 16)            0         \n",
      "_________________________________________________________________\n",
      "dense_209 (Dense)            (None, 18, 1)             17        \n",
      "=================================================================\n",
      "Total params: 1,599\n",
      "Trainable params: 1,599\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/80\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 0.0480 - val_loss: 0.0365\n",
      "Epoch 2/80\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.0435 - val_loss: 0.0339\n",
      "Epoch 3/80\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.0419 - val_loss: 0.0317\n",
      "Epoch 4/80\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.0407 - val_loss: 0.0296\n",
      "Epoch 5/80\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.0393 - val_loss: 0.0276\n",
      "Epoch 6/80\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 0.0386 - val_loss: 0.0263\n",
      "Epoch 7/80\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.0376 - val_loss: 0.0254\n",
      "Epoch 8/80\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.0369 - val_loss: 0.0249\n",
      "Epoch 9/80\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.0360 - val_loss: 0.0235\n",
      "Epoch 10/80\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.0353 - val_loss: 0.0226\n",
      "Epoch 11/80\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.0346 - val_loss: 0.0221\n",
      "Epoch 12/80\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.0341 - val_loss: 0.0215\n",
      "Epoch 13/80\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.0336 - val_loss: 0.0210\n",
      "Epoch 14/80\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.0330 - val_loss: 0.0205\n",
      "Epoch 15/80\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.0325 - val_loss: 0.0202\n",
      "Epoch 16/80\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.0321 - val_loss: 0.0195\n",
      "Epoch 17/80\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.0317 - val_loss: 0.0194\n",
      "Epoch 18/80\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.0313 - val_loss: 0.0189\n",
      "Epoch 19/80\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.0309 - val_loss: 0.0188\n",
      "Epoch 20/80\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.0305 - val_loss: 0.0183\n",
      "Epoch 21/80\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.0302 - val_loss: 0.0183\n",
      "Epoch 22/80\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.0298 - val_loss: 0.0180\n",
      "Epoch 23/80\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.0294 - val_loss: 0.0176\n",
      "Epoch 24/80\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.0291 - val_loss: 0.0174\n",
      "Epoch 25/80\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.0288 - val_loss: 0.0172\n",
      "Epoch 26/80\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.0286 - val_loss: 0.0168\n",
      "Epoch 27/80\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.0282 - val_loss: 0.0165\n",
      "Epoch 28/80\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.0279 - val_loss: 0.0162\n",
      "Epoch 29/80\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.0277 - val_loss: 0.0159\n",
      "Epoch 30/80\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.0275 - val_loss: 0.0157\n",
      "Epoch 31/80\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.0274 - val_loss: 0.0156\n",
      "Epoch 32/80\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.0271 - val_loss: 0.0147\n",
      "Epoch 33/80\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.0267 - val_loss: 0.0148\n",
      "Epoch 34/80\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.0266 - val_loss: 0.0151\n",
      "Epoch 35/80\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.0264 - val_loss: 0.0147\n",
      "Epoch 36/80\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "103/103 [==============================] - 0s 2ms/step - loss: 0.0262 - val_loss: 0.0144\n",
      "Epoch 37/80\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.0259 - val_loss: 0.0138\n",
      "Epoch 38/80\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.0256 - val_loss: 0.0137\n",
      "Epoch 39/80\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.0252 - val_loss: 0.0137\n",
      "Epoch 40/80\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.0250 - val_loss: 0.0137\n",
      "Epoch 41/80\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 0.0247 - val_loss: 0.0136\n",
      "Epoch 42/80\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 0.0244 - val_loss: 0.0134\n",
      "Epoch 43/80\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 0.0241 - val_loss: 0.0134\n",
      "Epoch 44/80\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 0.0237 - val_loss: 0.0133\n",
      "Epoch 45/80\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.0232 - val_loss: 0.0133\n",
      "Epoch 46/80\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.0230 - val_loss: 0.0132\n",
      "Epoch 47/80\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.0228 - val_loss: 0.0131\n",
      "Epoch 48/80\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.0223 - val_loss: 0.0130\n",
      "Epoch 49/80\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.0220 - val_loss: 0.0129\n",
      "Epoch 50/80\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.0217 - val_loss: 0.0127\n",
      "Epoch 51/80\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.0213 - val_loss: 0.0126\n",
      "Epoch 52/80\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.0211 - val_loss: 0.0125\n",
      "Epoch 53/80\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.0208 - val_loss: 0.0124\n",
      "Epoch 54/80\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.0206 - val_loss: 0.0124\n",
      "Epoch 55/80\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.0203 - val_loss: 0.0122\n",
      "Epoch 56/80\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.0201 - val_loss: 0.0119\n",
      "Epoch 57/80\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.0198 - val_loss: 0.0117\n",
      "Epoch 58/80\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.0198 - val_loss: 0.0117\n",
      "Epoch 59/80\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.0195 - val_loss: 0.0116\n",
      "Epoch 60/80\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.0195 - val_loss: 0.0115\n",
      "Epoch 61/80\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.0193 - val_loss: 0.0114\n",
      "Epoch 62/80\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.0192 - val_loss: 0.0114\n",
      "Epoch 63/80\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.0190 - val_loss: 0.0113\n",
      "Epoch 64/80\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.0190 - val_loss: 0.0112\n",
      "Epoch 65/80\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.0189 - val_loss: 0.0111\n",
      "Epoch 66/80\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.0188 - val_loss: 0.0112\n",
      "Epoch 67/80\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.0188 - val_loss: 0.0111\n",
      "Epoch 68/80\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.0188 - val_loss: 0.0110\n",
      "Epoch 69/80\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.0188 - val_loss: 0.0109\n",
      "Epoch 70/80\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.0187 - val_loss: 0.0108\n",
      "Epoch 71/80\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.0187 - val_loss: 0.0107\n",
      "Epoch 72/80\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.0187 - val_loss: 0.0110\n",
      "Epoch 73/80\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.0187 - val_loss: 0.0109\n",
      "Epoch 74/80\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.0186 - val_loss: 0.0113\n",
      "Epoch 75/80\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.0186 - val_loss: 0.0110\n",
      "Epoch 76/80\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.0186 - val_loss: 0.0109\n",
      "Epoch 77/80\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.0187 - val_loss: 0.0110\n",
      "Epoch 78/80\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.0187 - val_loss: 0.0108\n",
      "Epoch 79/80\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.0186 - val_loss: 0.0108\n",
      "Epoch 80/80\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.0186 - val_loss: 0.0110\n",
      "Execution time:  20.035155773162842\n",
      "DNN:\n",
      "Mean Absolute Error: 0.0096\n",
      "Root Mean Square Error: 0.0269\n",
      "Mean Square Error: 0.0007\n",
      "\n",
      "Train RMSE: 0.027\n",
      "Train MSE: 0.001\n",
      "Train MAE: 0.010\n",
      "###########################\n",
      "\n",
      "MODEL:  DNN\n",
      "sequence:  3h\n",
      "units:  80\n",
      "dropout1:  0.11814836227952394\n",
      "optimizer: adamax\n",
      "activationDense: sigmoid\n",
      "epochs: 90\n",
      "batchsize: 25\n",
      "validation_split: 0.2\n",
      "Model: \"sequential_70\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_210 (Dense)            (None, 18, 80)            160       \n",
      "_________________________________________________________________\n",
      "dense_211 (Dense)            (None, 18, 16)            1296      \n",
      "_________________________________________________________________\n",
      "dropout_70 (Dropout)         (None, 18, 16)            0         \n",
      "_________________________________________________________________\n",
      "dense_212 (Dense)            (None, 18, 1)             17        \n",
      "=================================================================\n",
      "Total params: 1,473\n",
      "Trainable params: 1,473\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/90\n",
      "128/128 [==============================] - 0s 4ms/step - loss: 0.0413 - val_loss: 0.0194\n",
      "Epoch 2/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0373 - val_loss: 0.0194\n",
      "Epoch 3/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0372 - val_loss: 0.0191\n",
      "Epoch 4/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0363 - val_loss: 0.0191\n",
      "Epoch 5/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0360 - val_loss: 0.0188\n",
      "Epoch 6/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0357 - val_loss: 0.0188\n",
      "Epoch 7/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0354 - val_loss: 0.0187\n",
      "Epoch 8/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0350 - val_loss: 0.0187\n",
      "Epoch 9/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0351 - val_loss: 0.0186\n",
      "Epoch 10/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0341 - val_loss: 0.0185\n",
      "Epoch 11/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0339 - val_loss: 0.0182\n",
      "Epoch 12/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0337 - val_loss: 0.0184\n",
      "Epoch 13/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0333 - val_loss: 0.0182\n",
      "Epoch 14/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0334 - val_loss: 0.0181\n",
      "Epoch 15/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0326 - val_loss: 0.0178\n",
      "Epoch 16/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0324 - val_loss: 0.0179\n",
      "Epoch 17/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0322 - val_loss: 0.0178\n",
      "Epoch 18/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0320 - val_loss: 0.0175\n",
      "Epoch 19/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0315 - val_loss: 0.0164\n",
      "Epoch 20/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0321 - val_loss: 0.0164\n",
      "Epoch 21/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0314 - val_loss: 0.0172\n",
      "Epoch 22/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0308 - val_loss: 0.0169\n",
      "Epoch 23/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0306 - val_loss: 0.0169\n",
      "Epoch 24/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0305 - val_loss: 0.0169\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 25/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0303 - val_loss: 0.0166\n",
      "Epoch 26/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0301 - val_loss: 0.0166\n",
      "Epoch 27/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0299 - val_loss: 0.0164\n",
      "Epoch 28/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0297 - val_loss: 0.0165\n",
      "Epoch 29/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0294 - val_loss: 0.0162\n",
      "Epoch 30/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0291 - val_loss: 0.0161\n",
      "Epoch 31/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0289 - val_loss: 0.0160\n",
      "Epoch 32/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0287 - val_loss: 0.0158\n",
      "Epoch 33/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0284 - val_loss: 0.0155\n",
      "Epoch 34/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0281 - val_loss: 0.0150\n",
      "Epoch 35/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0279 - val_loss: 0.0148\n",
      "Epoch 36/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0277 - val_loss: 0.0145\n",
      "Epoch 37/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0274 - val_loss: 0.0142\n",
      "Epoch 38/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0271 - val_loss: 0.0140\n",
      "Epoch 39/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0269 - val_loss: 0.0138\n",
      "Epoch 40/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0265 - val_loss: 0.0137\n",
      "Epoch 41/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0263 - val_loss: 0.0136\n",
      "Epoch 42/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0261 - val_loss: 0.0135\n",
      "Epoch 43/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0256 - val_loss: 0.0133\n",
      "Epoch 44/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0253 - val_loss: 0.0131\n",
      "Epoch 45/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0248 - val_loss: 0.0129\n",
      "Epoch 46/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0244 - val_loss: 0.0129\n",
      "Epoch 47/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0239 - val_loss: 0.0128\n",
      "Epoch 48/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0235 - val_loss: 0.0127\n",
      "Epoch 49/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0231 - val_loss: 0.0126\n",
      "Epoch 50/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0227 - val_loss: 0.0124\n",
      "Epoch 51/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0223 - val_loss: 0.0123\n",
      "Epoch 52/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0219 - val_loss: 0.0122\n",
      "Epoch 53/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0214 - val_loss: 0.0119\n",
      "Epoch 54/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0210 - val_loss: 0.0118\n",
      "Epoch 55/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0204 - val_loss: 0.0116\n",
      "Epoch 56/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0198 - val_loss: 0.0115\n",
      "Epoch 57/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0193 - val_loss: 0.0113\n",
      "Epoch 58/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0188 - val_loss: 0.0110\n",
      "Epoch 59/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0184 - val_loss: 0.0109\n",
      "Epoch 60/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0181 - val_loss: 0.0106\n",
      "Epoch 61/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0177 - val_loss: 0.0105\n",
      "Epoch 62/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0174 - val_loss: 0.0106\n",
      "Epoch 63/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0172 - val_loss: 0.0103\n",
      "Epoch 64/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0169 - val_loss: 0.0102\n",
      "Epoch 65/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0166 - val_loss: 0.0105\n",
      "Epoch 66/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0164 - val_loss: 0.0102\n",
      "Epoch 67/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0162 - val_loss: 0.0100\n",
      "Epoch 68/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0162 - val_loss: 0.0105\n",
      "Epoch 69/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0160 - val_loss: 0.0105\n",
      "Epoch 70/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0159 - val_loss: 0.0100\n",
      "Epoch 71/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0159 - val_loss: 0.0100\n",
      "Epoch 72/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0158 - val_loss: 0.0098\n",
      "Epoch 73/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0157 - val_loss: 0.0106\n",
      "Epoch 74/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0157 - val_loss: 0.0100\n",
      "Epoch 75/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0157 - val_loss: 0.0099\n",
      "Epoch 76/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0156 - val_loss: 0.0103\n",
      "Epoch 77/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0156 - val_loss: 0.0100\n",
      "Epoch 78/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0156 - val_loss: 0.0103\n",
      "Epoch 79/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0156 - val_loss: 0.0099\n",
      "Epoch 80/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0156 - val_loss: 0.0101\n",
      "Epoch 81/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0155 - val_loss: 0.0097\n",
      "Epoch 82/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0156 - val_loss: 0.0099\n",
      "Epoch 83/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0155 - val_loss: 0.0098\n",
      "Epoch 84/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0155 - val_loss: 0.0099\n",
      "Epoch 85/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0155 - val_loss: 0.0099\n",
      "Epoch 86/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0154 - val_loss: 0.0098\n",
      "Epoch 87/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0155 - val_loss: 0.0098\n",
      "Epoch 88/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0154 - val_loss: 0.0097\n",
      "Epoch 89/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0154 - val_loss: 0.0098\n",
      "Epoch 90/90\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0154 - val_loss: 0.0098\n",
      "Execution time:  25.04784393310547\n",
      "DNN:\n",
      "Mean Absolute Error: 0.0066\n",
      "Root Mean Square Error: 0.0214\n",
      "Mean Square Error: 0.0005\n",
      "\n",
      "Train RMSE: 0.021\n",
      "Train MSE: 0.000\n",
      "Train MAE: 0.007\n",
      "###########################\n",
      "\n",
      "MODEL:  DNN\n",
      "sequence:  3h\n",
      "units:  12\n",
      "dropout1:  0.48476373451509647\n",
      "optimizer: adamax\n",
      "activationDense: sigmoid\n",
      "epochs: 52\n",
      "batchsize: 57\n",
      "validation_split: 0.2\n",
      "Model: \"sequential_71\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_213 (Dense)            (None, 18, 12)            24        \n",
      "_________________________________________________________________\n",
      "dense_214 (Dense)            (None, 18, 16)            208       \n",
      "_________________________________________________________________\n",
      "dropout_71 (Dropout)         (None, 18, 16)            0         \n",
      "_________________________________________________________________\n",
      "dense_215 (Dense)            (None, 18, 1)             17        \n",
      "=================================================================\n",
      "Total params: 249\n",
      "Trainable params: 249\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/52\n",
      "56/56 [==============================] - 1s 9ms/step - loss: 0.0492 - val_loss: 0.0416\n",
      "Epoch 2/52\n",
      "56/56 [==============================] - 0s 2ms/step - loss: 0.0443 - val_loss: 0.0383\n",
      "Epoch 3/52\n",
      "56/56 [==============================] - 0s 2ms/step - loss: 0.0429 - val_loss: 0.0370\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/52\n",
      "56/56 [==============================] - 0s 2ms/step - loss: 0.0418 - val_loss: 0.0363\n",
      "Epoch 5/52\n",
      "56/56 [==============================] - 0s 2ms/step - loss: 0.0410 - val_loss: 0.0353\n",
      "Epoch 6/52\n",
      "56/56 [==============================] - 0s 2ms/step - loss: 0.0405 - val_loss: 0.0346\n",
      "Epoch 7/52\n",
      "56/56 [==============================] - 0s 2ms/step - loss: 0.0400 - val_loss: 0.0339\n",
      "Epoch 8/52\n",
      "56/56 [==============================] - 0s 2ms/step - loss: 0.0394 - val_loss: 0.0332\n",
      "Epoch 9/52\n",
      "56/56 [==============================] - 0s 2ms/step - loss: 0.0391 - val_loss: 0.0327\n",
      "Epoch 10/52\n",
      "56/56 [==============================] - 0s 2ms/step - loss: 0.0386 - val_loss: 0.0321\n",
      "Epoch 11/52\n",
      "56/56 [==============================] - 0s 2ms/step - loss: 0.0381 - val_loss: 0.0317\n",
      "Epoch 12/52\n",
      "56/56 [==============================] - 0s 2ms/step - loss: 0.0375 - val_loss: 0.0311\n",
      "Epoch 13/52\n",
      "56/56 [==============================] - 0s 2ms/step - loss: 0.0373 - val_loss: 0.0308\n",
      "Epoch 14/52\n",
      "56/56 [==============================] - 0s 2ms/step - loss: 0.0369 - val_loss: 0.0308\n",
      "Epoch 15/52\n",
      "56/56 [==============================] - 0s 2ms/step - loss: 0.0365 - val_loss: 0.0301\n",
      "Epoch 16/52\n",
      "56/56 [==============================] - 0s 2ms/step - loss: 0.0363 - val_loss: 0.0299\n",
      "Epoch 17/52\n",
      "56/56 [==============================] - 0s 2ms/step - loss: 0.0356 - val_loss: 0.0296\n",
      "Epoch 18/52\n",
      "56/56 [==============================] - 0s 2ms/step - loss: 0.0355 - val_loss: 0.0294\n",
      "Epoch 19/52\n",
      "56/56 [==============================] - 0s 2ms/step - loss: 0.0350 - val_loss: 0.0290\n",
      "Epoch 20/52\n",
      "56/56 [==============================] - 0s 2ms/step - loss: 0.0347 - val_loss: 0.0287\n",
      "Epoch 21/52\n",
      "56/56 [==============================] - 0s 2ms/step - loss: 0.0343 - val_loss: 0.0286\n",
      "Epoch 22/52\n",
      "56/56 [==============================] - 0s 2ms/step - loss: 0.0341 - val_loss: 0.0285\n",
      "Epoch 23/52\n",
      "56/56 [==============================] - 0s 2ms/step - loss: 0.0337 - val_loss: 0.0282\n",
      "Epoch 24/52\n",
      "56/56 [==============================] - 0s 2ms/step - loss: 0.0334 - val_loss: 0.0279\n",
      "Epoch 25/52\n",
      "56/56 [==============================] - 0s 2ms/step - loss: 0.0332 - val_loss: 0.0276\n",
      "Epoch 26/52\n",
      "56/56 [==============================] - 0s 2ms/step - loss: 0.0329 - val_loss: 0.0273\n",
      "Epoch 27/52\n",
      "56/56 [==============================] - 0s 2ms/step - loss: 0.0326 - val_loss: 0.0269\n",
      "Epoch 28/52\n",
      "56/56 [==============================] - 0s 2ms/step - loss: 0.0323 - val_loss: 0.0267\n",
      "Epoch 29/52\n",
      "56/56 [==============================] - 0s 2ms/step - loss: 0.0320 - val_loss: 0.0263\n",
      "Epoch 30/52\n",
      "56/56 [==============================] - 0s 2ms/step - loss: 0.0318 - val_loss: 0.0258\n",
      "Epoch 31/52\n",
      "56/56 [==============================] - 0s 2ms/step - loss: 0.0315 - val_loss: 0.0254\n",
      "Epoch 32/52\n",
      "56/56 [==============================] - 0s 2ms/step - loss: 0.0313 - val_loss: 0.0249\n",
      "Epoch 33/52\n",
      "56/56 [==============================] - 0s 2ms/step - loss: 0.0310 - val_loss: 0.0246\n",
      "Epoch 34/52\n",
      "56/56 [==============================] - 0s 2ms/step - loss: 0.0308 - val_loss: 0.0242\n",
      "Epoch 35/52\n",
      "56/56 [==============================] - 0s 2ms/step - loss: 0.0306 - val_loss: 0.0238\n",
      "Epoch 36/52\n",
      "56/56 [==============================] - 0s 2ms/step - loss: 0.0304 - val_loss: 0.0235\n",
      "Epoch 37/52\n",
      "56/56 [==============================] - 0s 2ms/step - loss: 0.0301 - val_loss: 0.0232\n",
      "Epoch 38/52\n",
      "56/56 [==============================] - 0s 2ms/step - loss: 0.0300 - val_loss: 0.0228\n",
      "Epoch 39/52\n",
      "56/56 [==============================] - 0s 2ms/step - loss: 0.0298 - val_loss: 0.0226\n",
      "Epoch 40/52\n",
      "56/56 [==============================] - 0s 2ms/step - loss: 0.0296 - val_loss: 0.0223\n",
      "Epoch 41/52\n",
      "56/56 [==============================] - 0s 2ms/step - loss: 0.0293 - val_loss: 0.0220\n",
      "Epoch 42/52\n",
      "56/56 [==============================] - 0s 2ms/step - loss: 0.0292 - val_loss: 0.0218\n",
      "Epoch 43/52\n",
      "56/56 [==============================] - 0s 2ms/step - loss: 0.0290 - val_loss: 0.0215\n",
      "Epoch 44/52\n",
      "56/56 [==============================] - 0s 2ms/step - loss: 0.0287 - val_loss: 0.0210\n",
      "Epoch 45/52\n",
      "56/56 [==============================] - 0s 2ms/step - loss: 0.0285 - val_loss: 0.0206\n",
      "Epoch 46/52\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 0.0283 - val_loss: 0.0204\n",
      "Epoch 47/52\n",
      "56/56 [==============================] - 0s 2ms/step - loss: 0.0282 - val_loss: 0.0201\n",
      "Epoch 48/52\n",
      "56/56 [==============================] - 0s 2ms/step - loss: 0.0280 - val_loss: 0.0199\n",
      "Epoch 49/52\n",
      "56/56 [==============================] - 0s 2ms/step - loss: 0.0279 - val_loss: 0.0197\n",
      "Epoch 50/52\n",
      "56/56 [==============================] - 0s 2ms/step - loss: 0.0277 - val_loss: 0.0195\n",
      "Epoch 51/52\n",
      "56/56 [==============================] - 0s 2ms/step - loss: 0.0275 - val_loss: 0.0194\n",
      "Epoch 52/52\n",
      "56/56 [==============================] - 0s 2ms/step - loss: 0.0273 - val_loss: 0.0189\n",
      "Execution time:  7.5913403034210205\n",
      "DNN:\n",
      "Mean Absolute Error: 0.0239\n",
      "Root Mean Square Error: 0.0387\n",
      "Mean Square Error: 0.0015\n",
      "\n",
      "Train RMSE: 0.039\n",
      "Train MSE: 0.001\n",
      "Train MAE: 0.024\n",
      "###########################\n",
      "\n",
      "MODEL:  DNN\n",
      "sequence:  6h\n",
      "units:  87\n",
      "dropout1:  0.40519643149940265\n",
      "optimizer: adam\n",
      "activationDense: tanh\n",
      "epochs: 80\n",
      "batchsize: 31\n",
      "validation_split: 0.1\n",
      "Model: \"sequential_72\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_216 (Dense)            (None, 36, 87)            174       \n",
      "_________________________________________________________________\n",
      "dense_217 (Dense)            (None, 36, 16)            1408      \n",
      "_________________________________________________________________\n",
      "dropout_72 (Dropout)         (None, 36, 16)            0         \n",
      "_________________________________________________________________\n",
      "dense_218 (Dense)            (None, 36, 1)             17        \n",
      "=================================================================\n",
      "Total params: 1,599\n",
      "Trainable params: 1,599\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/80\n",
      "115/115 [==============================] - 0s 4ms/step - loss: 0.1246 - val_loss: 0.0171\n",
      "Epoch 2/80\n",
      "115/115 [==============================] - 0s 3ms/step - loss: 0.0781 - val_loss: 0.0158\n",
      "Epoch 3/80\n",
      "115/115 [==============================] - 0s 3ms/step - loss: 0.0654 - val_loss: 0.0096\n",
      "Epoch 4/80\n",
      "115/115 [==============================] - 0s 3ms/step - loss: 0.0524 - val_loss: 0.0063\n",
      "Epoch 5/80\n",
      "115/115 [==============================] - 0s 3ms/step - loss: 0.0417 - val_loss: 0.0112\n",
      "Epoch 6/80\n",
      "115/115 [==============================] - 0s 3ms/step - loss: 0.0339 - val_loss: 0.0126\n",
      "Epoch 7/80\n",
      "115/115 [==============================] - 0s 3ms/step - loss: 0.0298 - val_loss: 0.0202\n",
      "Epoch 8/80\n",
      "115/115 [==============================] - 0s 3ms/step - loss: 0.0297 - val_loss: 0.0099\n",
      "Epoch 9/80\n",
      "115/115 [==============================] - 0s 3ms/step - loss: 0.0293 - val_loss: 0.0102\n",
      "Epoch 10/80\n",
      "115/115 [==============================] - 0s 3ms/step - loss: 0.0290 - val_loss: 0.0103\n",
      "Epoch 11/80\n",
      "115/115 [==============================] - 0s 3ms/step - loss: 0.0288 - val_loss: 0.0103\n",
      "Epoch 12/80\n",
      "115/115 [==============================] - 0s 3ms/step - loss: 0.0290 - val_loss: 0.0105\n",
      "Epoch 13/80\n",
      "115/115 [==============================] - 0s 3ms/step - loss: 0.0287 - val_loss: 0.0105\n",
      "Epoch 14/80\n",
      "115/115 [==============================] - 0s 3ms/step - loss: 0.0286 - val_loss: 0.0107\n",
      "Epoch 15/80\n",
      "115/115 [==============================] - 0s 3ms/step - loss: 0.0285 - val_loss: 0.0109\n",
      "Epoch 16/80\n",
      "115/115 [==============================] - 0s 3ms/step - loss: 0.0285 - val_loss: 0.0114\n",
      "Epoch 17/80\n",
      "115/115 [==============================] - 0s 3ms/step - loss: 0.0285 - val_loss: 0.0114\n",
      "Epoch 18/80\n",
      "115/115 [==============================] - 0s 3ms/step - loss: 0.0285 - val_loss: 0.0118\n",
      "Epoch 19/80\n",
      "115/115 [==============================] - 0s 3ms/step - loss: 0.0284 - val_loss: 0.0118\n",
      "Epoch 20/80\n",
      "115/115 [==============================] - 0s 3ms/step - loss: 0.0284 - val_loss: 0.0120\n",
      "Epoch 21/80\n",
      "115/115 [==============================] - 0s 3ms/step - loss: 0.0284 - val_loss: 0.0120\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 22/80\n",
      "115/115 [==============================] - 0s 3ms/step - loss: 0.0284 - val_loss: 0.0118\n",
      "Epoch 23/80\n",
      "115/115 [==============================] - 0s 3ms/step - loss: 0.0284 - val_loss: 0.0120\n",
      "Epoch 24/80\n",
      "115/115 [==============================] - 0s 3ms/step - loss: 0.0284 - val_loss: 0.0116\n",
      "Epoch 25/80\n",
      "115/115 [==============================] - 0s 3ms/step - loss: 0.0284 - val_loss: 0.0116\n",
      "Epoch 26/80\n",
      "115/115 [==============================] - 0s 3ms/step - loss: 0.0283 - val_loss: 0.0116\n",
      "Epoch 27/80\n",
      "115/115 [==============================] - 0s 3ms/step - loss: 0.0285 - val_loss: 0.0114\n",
      "Epoch 28/80\n",
      "115/115 [==============================] - 0s 3ms/step - loss: 0.0284 - val_loss: 0.0112\n",
      "Epoch 29/80\n",
      "115/115 [==============================] - 0s 3ms/step - loss: 0.0284 - val_loss: 0.0111\n",
      "Epoch 30/80\n",
      "115/115 [==============================] - 0s 3ms/step - loss: 0.0284 - val_loss: 0.0113\n",
      "Epoch 31/80\n",
      "115/115 [==============================] - 0s 3ms/step - loss: 0.0284 - val_loss: 0.0112\n",
      "Epoch 32/80\n",
      "115/115 [==============================] - 0s 3ms/step - loss: 0.0284 - val_loss: 0.0112\n",
      "Epoch 33/80\n",
      "115/115 [==============================] - 0s 3ms/step - loss: 0.0283 - val_loss: 0.0109\n",
      "Epoch 34/80\n",
      "115/115 [==============================] - 0s 3ms/step - loss: 0.0283 - val_loss: 0.0107\n",
      "Epoch 35/80\n",
      "115/115 [==============================] - 0s 3ms/step - loss: 0.0282 - val_loss: 0.0107\n",
      "Epoch 36/80\n",
      "115/115 [==============================] - 0s 3ms/step - loss: 0.0282 - val_loss: 0.0105\n",
      "Epoch 37/80\n",
      "115/115 [==============================] - 0s 3ms/step - loss: 0.0281 - val_loss: 0.0105\n",
      "Epoch 38/80\n",
      "115/115 [==============================] - 0s 3ms/step - loss: 0.0281 - val_loss: 0.0107\n",
      "Epoch 39/80\n",
      "115/115 [==============================] - 0s 3ms/step - loss: 0.0280 - val_loss: 0.0106\n",
      "Epoch 40/80\n",
      "115/115 [==============================] - 0s 3ms/step - loss: 0.0279 - val_loss: 0.0105\n",
      "Epoch 41/80\n",
      "115/115 [==============================] - 0s 3ms/step - loss: 0.0278 - val_loss: 0.0106\n",
      "Epoch 42/80\n",
      "115/115 [==============================] - 0s 3ms/step - loss: 0.0277 - val_loss: 0.0105\n",
      "Epoch 43/80\n",
      "115/115 [==============================] - 0s 3ms/step - loss: 0.0274 - val_loss: 0.0105\n",
      "Epoch 44/80\n",
      "115/115 [==============================] - 0s 3ms/step - loss: 0.0274 - val_loss: 0.0106\n",
      "Epoch 45/80\n",
      "115/115 [==============================] - 0s 3ms/step - loss: 0.0272 - val_loss: 0.0105\n",
      "Epoch 46/80\n",
      "115/115 [==============================] - 0s 3ms/step - loss: 0.0268 - val_loss: 0.0106\n",
      "Epoch 47/80\n",
      "115/115 [==============================] - 0s 3ms/step - loss: 0.0265 - val_loss: 0.0105\n",
      "Epoch 48/80\n",
      "115/115 [==============================] - 0s 3ms/step - loss: 0.0261 - val_loss: 0.0107\n",
      "Epoch 49/80\n",
      "115/115 [==============================] - 0s 3ms/step - loss: 0.0257 - val_loss: 0.0106\n",
      "Epoch 50/80\n",
      "115/115 [==============================] - 0s 3ms/step - loss: 0.0253 - val_loss: 0.0110\n",
      "Epoch 51/80\n",
      "115/115 [==============================] - 0s 3ms/step - loss: 0.0250 - val_loss: 0.0114\n",
      "Epoch 52/80\n",
      "115/115 [==============================] - 0s 3ms/step - loss: 0.0243 - val_loss: 0.0099\n",
      "Epoch 53/80\n",
      "115/115 [==============================] - 0s 3ms/step - loss: 0.0242 - val_loss: 0.0105\n",
      "Epoch 54/80\n",
      "115/115 [==============================] - 0s 3ms/step - loss: 0.0236 - val_loss: 0.0102\n",
      "Epoch 55/80\n",
      "115/115 [==============================] - 0s 3ms/step - loss: 0.0230 - val_loss: 0.0101\n",
      "Epoch 56/80\n",
      "115/115 [==============================] - 0s 3ms/step - loss: 0.0231 - val_loss: 0.0094\n",
      "Epoch 57/80\n",
      "115/115 [==============================] - 0s 3ms/step - loss: 0.0226 - val_loss: 0.0113\n",
      "Epoch 58/80\n",
      "115/115 [==============================] - 0s 3ms/step - loss: 0.0227 - val_loss: 0.0099\n",
      "Epoch 59/80\n",
      "115/115 [==============================] - 0s 3ms/step - loss: 0.0225 - val_loss: 0.0103\n",
      "Epoch 60/80\n",
      "115/115 [==============================] - 0s 3ms/step - loss: 0.0228 - val_loss: 0.0099\n",
      "Epoch 61/80\n",
      "115/115 [==============================] - 0s 3ms/step - loss: 0.0226 - val_loss: 0.0104\n",
      "Epoch 62/80\n",
      "115/115 [==============================] - 0s 3ms/step - loss: 0.0227 - val_loss: 0.0098\n",
      "Epoch 63/80\n",
      "115/115 [==============================] - 0s 3ms/step - loss: 0.0225 - val_loss: 0.0101\n",
      "Epoch 64/80\n",
      "115/115 [==============================] - 0s 3ms/step - loss: 0.0227 - val_loss: 0.0099\n",
      "Epoch 65/80\n",
      "115/115 [==============================] - 0s 3ms/step - loss: 0.0228 - val_loss: 0.0099\n",
      "Epoch 66/80\n",
      "115/115 [==============================] - 0s 3ms/step - loss: 0.0225 - val_loss: 0.0104\n",
      "Epoch 67/80\n",
      "115/115 [==============================] - 0s 3ms/step - loss: 0.0227 - val_loss: 0.0097\n",
      "Epoch 68/80\n",
      "115/115 [==============================] - 0s 3ms/step - loss: 0.0226 - val_loss: 0.0102\n",
      "Epoch 69/80\n",
      "115/115 [==============================] - 0s 3ms/step - loss: 0.0225 - val_loss: 0.0104\n",
      "Epoch 70/80\n",
      "115/115 [==============================] - 0s 3ms/step - loss: 0.0227 - val_loss: 0.0098\n",
      "Epoch 71/80\n",
      "115/115 [==============================] - 0s 3ms/step - loss: 0.0227 - val_loss: 0.0104\n",
      "Epoch 72/80\n",
      "115/115 [==============================] - 0s 3ms/step - loss: 0.0226 - val_loss: 0.0098\n",
      "Epoch 73/80\n",
      "115/115 [==============================] - 0s 3ms/step - loss: 0.0227 - val_loss: 0.0097\n",
      "Epoch 74/80\n",
      "115/115 [==============================] - 0s 3ms/step - loss: 0.0225 - val_loss: 0.0102\n",
      "Epoch 75/80\n",
      "115/115 [==============================] - 0s 3ms/step - loss: 0.0226 - val_loss: 0.0098\n",
      "Epoch 76/80\n",
      "115/115 [==============================] - 0s 3ms/step - loss: 0.0225 - val_loss: 0.0103\n",
      "Epoch 77/80\n",
      "115/115 [==============================] - 0s 3ms/step - loss: 0.0226 - val_loss: 0.0098\n",
      "Epoch 78/80\n",
      "115/115 [==============================] - 0s 3ms/step - loss: 0.0223 - val_loss: 0.0111\n",
      "Epoch 79/80\n",
      "115/115 [==============================] - 0s 3ms/step - loss: 0.0225 - val_loss: 0.0098\n",
      "Epoch 80/80\n",
      "115/115 [==============================] - 0s 3ms/step - loss: 0.0224 - val_loss: 0.0101\n",
      "Execution time:  26.171632766723633\n",
      "DNN:\n",
      "Mean Absolute Error: 0.0212\n",
      "Root Mean Square Error: 0.0330\n",
      "Mean Square Error: 0.0011\n",
      "\n",
      "Train RMSE: 0.033\n",
      "Train MSE: 0.001\n",
      "Train MAE: 0.021\n",
      "###########################\n",
      "\n",
      "MODEL:  DNN\n",
      "sequence:  6h\n",
      "units:  80\n",
      "dropout1:  0.11814836227952394\n",
      "optimizer: adam\n",
      "activationDense: tanh\n",
      "epochs: 90\n",
      "batchsize: 25\n",
      "validation_split: 0.1\n",
      "Model: \"sequential_73\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_219 (Dense)            (None, 36, 80)            160       \n",
      "_________________________________________________________________\n",
      "dense_220 (Dense)            (None, 36, 16)            1296      \n",
      "_________________________________________________________________\n",
      "dropout_73 (Dropout)         (None, 36, 16)            0         \n",
      "_________________________________________________________________\n",
      "dense_221 (Dense)            (None, 36, 1)             17        \n",
      "=================================================================\n",
      "Total params: 1,473\n",
      "Trainable params: 1,473\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/90\n",
      "143/143 [==============================] - 1s 4ms/step - loss: 0.0766 - val_loss: 0.0160\n",
      "Epoch 2/90\n",
      "143/143 [==============================] - 0s 3ms/step - loss: 0.0480 - val_loss: 0.0113\n",
      "Epoch 3/90\n",
      "143/143 [==============================] - 0s 3ms/step - loss: 0.0448 - val_loss: 0.0128\n",
      "Epoch 4/90\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.0414 - val_loss: 0.0051\n",
      "Epoch 5/90\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.0385 - val_loss: 0.0054\n",
      "Epoch 6/90\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.0364 - val_loss: 0.0077\n",
      "Epoch 7/90\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.0343 - val_loss: 0.0093\n",
      "Epoch 8/90\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.0322 - val_loss: 0.0068\n",
      "Epoch 9/90\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.0318 - val_loss: 0.0078\n",
      "Epoch 10/90\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.0298 - val_loss: 0.0089\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11/90\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.0287 - val_loss: 0.0094\n",
      "Epoch 12/90\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.0278 - val_loss: 0.0101\n",
      "Epoch 13/90\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.0270 - val_loss: 0.0113\n",
      "Epoch 14/90\n",
      "143/143 [==============================] - 0s 3ms/step - loss: 0.0267 - val_loss: 0.0144\n",
      "Epoch 15/90\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.0267 - val_loss: 0.0125\n",
      "Epoch 16/90\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.0259 - val_loss: 0.0133\n",
      "Epoch 17/90\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.0258 - val_loss: 0.0116\n",
      "Epoch 18/90\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.0255 - val_loss: 0.0119\n",
      "Epoch 19/90\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.0253 - val_loss: 0.0123\n",
      "Epoch 20/90\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.0253 - val_loss: 0.0129\n",
      "Epoch 21/90\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.0251 - val_loss: 0.0144\n",
      "Epoch 22/90\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.0252 - val_loss: 0.0171\n",
      "Epoch 23/90\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.0257 - val_loss: 0.0209\n",
      "Epoch 24/90\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.0253 - val_loss: 0.0213\n",
      "Epoch 25/90\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.0257 - val_loss: 0.0204\n",
      "Epoch 26/90\n",
      "143/143 [==============================] - 0s 3ms/step - loss: 0.0259 - val_loss: 0.0167\n",
      "Epoch 27/90\n",
      "143/143 [==============================] - 0s 3ms/step - loss: 0.0260 - val_loss: 0.0159\n",
      "Epoch 28/90\n",
      "143/143 [==============================] - 0s 3ms/step - loss: 0.0262 - val_loss: 0.0124\n",
      "Epoch 29/90\n",
      "143/143 [==============================] - 0s 3ms/step - loss: 0.0262 - val_loss: 0.0118\n",
      "Epoch 30/90\n",
      "143/143 [==============================] - 0s 3ms/step - loss: 0.0259 - val_loss: 0.0117\n",
      "Epoch 31/90\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.0254 - val_loss: 0.0101\n",
      "Epoch 32/90\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.0255 - val_loss: 0.0096\n",
      "Epoch 33/90\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.0247 - val_loss: 0.0124\n",
      "Epoch 34/90\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.0242 - val_loss: 0.0102\n",
      "Epoch 35/90\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.0239 - val_loss: 0.0124\n",
      "Epoch 36/90\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.0237 - val_loss: 0.0096\n",
      "Epoch 37/90\n",
      "143/143 [==============================] - 0s 3ms/step - loss: 0.0243 - val_loss: 0.0103\n",
      "Epoch 38/90\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.0236 - val_loss: 0.0106\n",
      "Epoch 39/90\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.0234 - val_loss: 0.0112\n",
      "Epoch 40/90\n",
      "143/143 [==============================] - 0s 3ms/step - loss: 0.0228 - val_loss: 0.0113\n",
      "Epoch 41/90\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.0216 - val_loss: 0.0146\n",
      "Epoch 42/90\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.0210 - val_loss: 0.0156\n",
      "Epoch 43/90\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.0212 - val_loss: 0.0147\n",
      "Epoch 44/90\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.0209 - val_loss: 0.0158\n",
      "Epoch 45/90\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.0210 - val_loss: 0.0148\n",
      "Epoch 46/90\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.0202 - val_loss: 0.0164\n",
      "Epoch 47/90\n",
      "143/143 [==============================] - 0s 3ms/step - loss: 0.0204 - val_loss: 0.0157\n",
      "Epoch 48/90\n",
      "143/143 [==============================] - 0s 3ms/step - loss: 0.0203 - val_loss: 0.0166\n",
      "Epoch 49/90\n",
      "143/143 [==============================] - 0s 3ms/step - loss: 0.0198 - val_loss: 0.0159\n",
      "Epoch 50/90\n",
      "143/143 [==============================] - 0s 3ms/step - loss: 0.0199 - val_loss: 0.0169\n",
      "Epoch 51/90\n",
      "143/143 [==============================] - 0s 3ms/step - loss: 0.0196 - val_loss: 0.0175\n",
      "Epoch 52/90\n",
      "143/143 [==============================] - 0s 3ms/step - loss: 0.0195 - val_loss: 0.0174\n",
      "Epoch 53/90\n",
      "143/143 [==============================] - 0s 3ms/step - loss: 0.0195 - val_loss: 0.0173\n",
      "Epoch 54/90\n",
      "143/143 [==============================] - 0s 3ms/step - loss: 0.0193 - val_loss: 0.0171\n",
      "Epoch 55/90\n",
      "143/143 [==============================] - 0s 3ms/step - loss: 0.0193 - val_loss: 0.0156\n",
      "Epoch 56/90\n",
      "143/143 [==============================] - 0s 3ms/step - loss: 0.0194 - val_loss: 0.0136\n",
      "Epoch 57/90\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.0193 - val_loss: 0.0149\n",
      "Epoch 58/90\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.0194 - val_loss: 0.0151\n",
      "Epoch 59/90\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.0195 - val_loss: 0.0174\n",
      "Epoch 60/90\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.0192 - val_loss: 0.0152\n",
      "Epoch 61/90\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.0192 - val_loss: 0.0153\n",
      "Epoch 62/90\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.0193 - val_loss: 0.0150\n",
      "Epoch 63/90\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.0192 - val_loss: 0.0131\n",
      "Epoch 64/90\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.0191 - val_loss: 0.0126\n",
      "Epoch 65/90\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.0190 - val_loss: 0.0142\n",
      "Epoch 66/90\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.0192 - val_loss: 0.0130\n",
      "Epoch 67/90\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.0189 - val_loss: 0.0150\n",
      "Epoch 68/90\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.0191 - val_loss: 0.0131\n",
      "Epoch 69/90\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.0190 - val_loss: 0.0131\n",
      "Epoch 70/90\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.0190 - val_loss: 0.0134\n",
      "Epoch 71/90\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.0190 - val_loss: 0.0125\n",
      "Epoch 72/90\n",
      "143/143 [==============================] - 0s 3ms/step - loss: 0.0187 - val_loss: 0.0131\n",
      "Epoch 73/90\n",
      "143/143 [==============================] - 0s 3ms/step - loss: 0.0188 - val_loss: 0.0152\n",
      "Epoch 74/90\n",
      "143/143 [==============================] - 0s 3ms/step - loss: 0.0189 - val_loss: 0.0125\n",
      "Epoch 75/90\n",
      "143/143 [==============================] - 0s 3ms/step - loss: 0.0188 - val_loss: 0.0146\n",
      "Epoch 76/90\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.0189 - val_loss: 0.0126\n",
      "Epoch 77/90\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.0187 - val_loss: 0.0145\n",
      "Epoch 78/90\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.0187 - val_loss: 0.0145\n",
      "Epoch 79/90\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.0187 - val_loss: 0.0126\n",
      "Epoch 80/90\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.0187 - val_loss: 0.0146\n",
      "Epoch 81/90\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.0188 - val_loss: 0.0134\n",
      "Epoch 82/90\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.0187 - val_loss: 0.0128\n",
      "Epoch 83/90\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.0189 - val_loss: 0.0126\n",
      "Epoch 84/90\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.0186 - val_loss: 0.0135\n",
      "Epoch 85/90\n",
      "143/143 [==============================] - 0s 3ms/step - loss: 0.0187 - val_loss: 0.0151\n",
      "Epoch 86/90\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.0187 - val_loss: 0.0150\n",
      "Epoch 87/90\n",
      "143/143 [==============================] - 0s 3ms/step - loss: 0.0186 - val_loss: 0.0151\n",
      "Epoch 88/90\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.0186 - val_loss: 0.0150\n",
      "Epoch 89/90\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.0187 - val_loss: 0.0146\n",
      "Epoch 90/90\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.0186 - val_loss: 0.0152\n",
      "Execution time:  33.37441921234131\n",
      "DNN:\n",
      "Mean Absolute Error: 0.0178\n",
      "Root Mean Square Error: 0.0301\n",
      "Mean Square Error: 0.0009\n",
      "\n",
      "Train RMSE: 0.030\n",
      "Train MSE: 0.001\n",
      "Train MAE: 0.018\n",
      "###########################\n",
      "\n",
      "MODEL:  DNN\n",
      "sequence:  6h\n",
      "units:  12\n",
      "dropout1:  0.48476373451509647\n",
      "optimizer: adam\n",
      "activationDense: tanh\n",
      "epochs: 52\n",
      "batchsize: 57\n",
      "validation_split: 0.1\n",
      "Model: \"sequential_74\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_222 (Dense)            (None, 36, 12)            24        \n",
      "_________________________________________________________________\n",
      "dense_223 (Dense)            (None, 36, 16)            208       \n",
      "_________________________________________________________________\n",
      "dropout_74 (Dropout)         (None, 36, 16)            0         \n",
      "_________________________________________________________________\n",
      "dense_224 (Dense)            (None, 36, 1)             17        \n",
      "=================================================================\n",
      "Total params: 249\n",
      "Trainable params: 249\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/52\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63/63 [==============================] - 0s 5ms/step - loss: 0.1848 - val_loss: 0.0090\n",
      "Epoch 2/52\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.1053 - val_loss: 0.0150\n",
      "Epoch 3/52\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.0915 - val_loss: 0.0055\n",
      "Epoch 4/52\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0812 - val_loss: 0.0102\n",
      "Epoch 5/52\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0723 - val_loss: 0.0086\n",
      "Epoch 6/52\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0636 - val_loss: 0.0084\n",
      "Epoch 7/52\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0543 - val_loss: 0.0055\n",
      "Epoch 8/52\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0470 - val_loss: 0.0066\n",
      "Epoch 9/52\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0406 - val_loss: 0.0057\n",
      "Epoch 10/52\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0362 - val_loss: 0.0057\n",
      "Epoch 11/52\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0327 - val_loss: 0.0062\n",
      "Epoch 12/52\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.0300 - val_loss: 0.0071\n",
      "Epoch 13/52\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0279 - val_loss: 0.0085\n",
      "Epoch 14/52\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0277 - val_loss: 0.0096\n",
      "Epoch 15/52\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0270 - val_loss: 0.0097\n",
      "Epoch 16/52\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0274 - val_loss: 0.0097\n",
      "Epoch 17/52\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0271 - val_loss: 0.0096\n",
      "Epoch 18/52\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0274 - val_loss: 0.0102\n",
      "Epoch 19/52\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0268 - val_loss: 0.0097\n",
      "Epoch 20/52\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0259 - val_loss: 0.0100\n",
      "Epoch 21/52\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0265 - val_loss: 0.0099\n",
      "Epoch 22/52\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0262 - val_loss: 0.0098\n",
      "Epoch 23/52\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0255 - val_loss: 0.0098\n",
      "Epoch 24/52\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0262 - val_loss: 0.0110\n",
      "Epoch 25/52\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0257 - val_loss: 0.0099\n",
      "Epoch 26/52\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0260 - val_loss: 0.0099\n",
      "Epoch 27/52\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0261 - val_loss: 0.0103\n",
      "Epoch 28/52\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0254 - val_loss: 0.0101\n",
      "Epoch 29/52\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0253 - val_loss: 0.0098\n",
      "Epoch 30/52\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0245 - val_loss: 0.0098\n",
      "Epoch 31/52\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0249 - val_loss: 0.0100\n",
      "Epoch 32/52\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0245 - val_loss: 0.0098\n",
      "Epoch 33/52\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0249 - val_loss: 0.0107\n",
      "Epoch 34/52\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0235 - val_loss: 0.0096\n",
      "Epoch 35/52\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0250 - val_loss: 0.0109\n",
      "Epoch 36/52\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0232 - val_loss: 0.0097\n",
      "Epoch 37/52\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0243 - val_loss: 0.0107\n",
      "Epoch 38/52\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0233 - val_loss: 0.0097\n",
      "Epoch 39/52\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0241 - val_loss: 0.0106\n",
      "Epoch 40/52\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0227 - val_loss: 0.0097\n",
      "Epoch 41/52\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0242 - val_loss: 0.0111\n",
      "Epoch 42/52\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0223 - val_loss: 0.0099\n",
      "Epoch 43/52\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.0239 - val_loss: 0.0105\n",
      "Epoch 44/52\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0221 - val_loss: 0.0099\n",
      "Epoch 45/52\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0237 - val_loss: 0.0104\n",
      "Epoch 46/52\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0219 - val_loss: 0.0098\n",
      "Epoch 47/52\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0231 - val_loss: 0.0105\n",
      "Epoch 48/52\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0216 - val_loss: 0.0098\n",
      "Epoch 49/52\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0229 - val_loss: 0.0104\n",
      "Epoch 50/52\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.0218 - val_loss: 0.0100\n",
      "Epoch 51/52\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.0227 - val_loss: 0.0097\n",
      "Epoch 52/52\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.0222 - val_loss: 0.0098\n",
      "Execution time:  9.253444910049438\n",
      "DNN:\n",
      "Mean Absolute Error: 0.0188\n",
      "Root Mean Square Error: 0.0288\n",
      "Mean Square Error: 0.0008\n",
      "\n",
      "Train RMSE: 0.029\n",
      "Train MSE: 0.001\n",
      "Train MAE: 0.019\n",
      "###########################\n",
      "\n",
      "MODEL:  DNN\n",
      "sequence:  6h\n",
      "units:  87\n",
      "dropout1:  0.40519643149940265\n",
      "optimizer: adam\n",
      "activationDense: tanh\n",
      "epochs: 80\n",
      "batchsize: 31\n",
      "validation_split: 0.2\n",
      "Model: \"sequential_75\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_225 (Dense)            (None, 36, 87)            174       \n",
      "_________________________________________________________________\n",
      "dense_226 (Dense)            (None, 36, 16)            1408      \n",
      "_________________________________________________________________\n",
      "dropout_75 (Dropout)         (None, 36, 16)            0         \n",
      "_________________________________________________________________\n",
      "dense_227 (Dense)            (None, 36, 1)             17        \n",
      "=================================================================\n",
      "Total params: 1,599\n",
      "Trainable params: 1,599\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/80\n",
      "103/103 [==============================] - 0s 5ms/step - loss: 0.1451 - val_loss: 0.0381\n",
      "Epoch 2/80\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 0.0862 - val_loss: 0.0128\n",
      "Epoch 3/80\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 0.0726 - val_loss: 0.0130\n",
      "Epoch 4/80\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 0.0594 - val_loss: 0.0153\n",
      "Epoch 5/80\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 0.0482 - val_loss: 0.0161\n",
      "Epoch 6/80\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 0.0404 - val_loss: 0.0144\n",
      "Epoch 7/80\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 0.0345 - val_loss: 0.0149\n",
      "Epoch 8/80\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 0.0323 - val_loss: 0.0174\n",
      "Epoch 9/80\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 0.0315 - val_loss: 0.0160\n",
      "Epoch 10/80\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 0.0310 - val_loss: 0.0156\n",
      "Epoch 11/80\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 0.0304 - val_loss: 0.0156\n",
      "Epoch 12/80\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 0.0302 - val_loss: 0.0156\n",
      "Epoch 13/80\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 0.0300 - val_loss: 0.0160\n",
      "Epoch 14/80\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 0.0298 - val_loss: 0.0159\n",
      "Epoch 15/80\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 0.0296 - val_loss: 0.0161\n",
      "Epoch 16/80\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 0.0295 - val_loss: 0.0160\n",
      "Epoch 17/80\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 0.0295 - val_loss: 0.0160\n",
      "Epoch 18/80\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 0.0295 - val_loss: 0.0160\n",
      "Epoch 19/80\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "103/103 [==============================] - 0s 3ms/step - loss: 0.0294 - val_loss: 0.0159\n",
      "Epoch 20/80\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 0.0294 - val_loss: 0.0161\n",
      "Epoch 21/80\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 0.0295 - val_loss: 0.0161\n",
      "Epoch 22/80\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 0.0293 - val_loss: 0.0158\n",
      "Epoch 23/80\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 0.0293 - val_loss: 0.0162\n",
      "Epoch 24/80\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 0.0292 - val_loss: 0.0157\n",
      "Epoch 25/80\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 0.0293 - val_loss: 0.0160\n",
      "Epoch 26/80\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 0.0292 - val_loss: 0.0157\n",
      "Epoch 27/80\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 0.0293 - val_loss: 0.0161\n",
      "Epoch 28/80\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 0.0292 - val_loss: 0.0156\n",
      "Epoch 29/80\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 0.0292 - val_loss: 0.0159\n",
      "Epoch 30/80\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 0.0292 - val_loss: 0.0155\n",
      "Epoch 31/80\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 0.0292 - val_loss: 0.0159\n",
      "Epoch 32/80\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 0.0290 - val_loss: 0.0154\n",
      "Epoch 33/80\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 0.0292 - val_loss: 0.0160\n",
      "Epoch 34/80\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 0.0289 - val_loss: 0.0154\n",
      "Epoch 35/80\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 0.0290 - val_loss: 0.0158\n",
      "Epoch 36/80\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 0.0288 - val_loss: 0.0154\n",
      "Epoch 37/80\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 0.0289 - val_loss: 0.0160\n",
      "Epoch 38/80\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 0.0283 - val_loss: 0.0154\n",
      "Epoch 39/80\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 0.0287 - val_loss: 0.0161\n",
      "Epoch 40/80\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 0.0279 - val_loss: 0.0153\n",
      "Epoch 41/80\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 0.0284 - val_loss: 0.0158\n",
      "Epoch 42/80\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 0.0277 - val_loss: 0.0153\n",
      "Epoch 43/80\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 0.0280 - val_loss: 0.0160\n",
      "Epoch 44/80\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 0.0270 - val_loss: 0.0153\n",
      "Epoch 45/80\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 0.0276 - val_loss: 0.0156\n",
      "Epoch 46/80\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 0.0268 - val_loss: 0.0152\n",
      "Epoch 47/80\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 0.0274 - val_loss: 0.0158\n",
      "Epoch 48/80\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 0.0259 - val_loss: 0.0151\n",
      "Epoch 49/80\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 0.0264 - val_loss: 0.0154\n",
      "Epoch 50/80\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 0.0252 - val_loss: 0.0150\n",
      "Epoch 51/80\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 0.0258 - val_loss: 0.0150\n",
      "Epoch 52/80\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 0.0249 - val_loss: 0.0149\n",
      "Epoch 53/80\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 0.0247 - val_loss: 0.0148\n",
      "Epoch 54/80\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 0.0244 - val_loss: 0.0147\n",
      "Epoch 55/80\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 0.0237 - val_loss: 0.0149\n",
      "Epoch 56/80\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 0.0242 - val_loss: 0.0146\n",
      "Epoch 57/80\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 0.0232 - val_loss: 0.0148\n",
      "Epoch 58/80\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 0.0236 - val_loss: 0.0147\n",
      "Epoch 59/80\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 0.0230 - val_loss: 0.0148\n",
      "Epoch 60/80\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 0.0237 - val_loss: 0.0146\n",
      "Epoch 61/80\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 0.0227 - val_loss: 0.0147\n",
      "Epoch 62/80\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 0.0232 - val_loss: 0.0145\n",
      "Epoch 63/80\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 0.0217 - val_loss: 0.0150\n",
      "Epoch 64/80\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 0.0237 - val_loss: 0.0146\n",
      "Epoch 65/80\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 0.0225 - val_loss: 0.0148\n",
      "Epoch 66/80\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 0.0234 - val_loss: 0.0147\n",
      "Epoch 67/80\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 0.0222 - val_loss: 0.0148\n",
      "Epoch 68/80\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 0.0226 - val_loss: 0.0147\n",
      "Epoch 69/80\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 0.0226 - val_loss: 0.0148\n",
      "Epoch 70/80\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 0.0231 - val_loss: 0.0147\n",
      "Epoch 71/80\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 0.0226 - val_loss: 0.0147\n",
      "Epoch 72/80\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 0.0226 - val_loss: 0.0147\n",
      "Epoch 73/80\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 0.0225 - val_loss: 0.0148\n",
      "Epoch 74/80\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 0.0230 - val_loss: 0.0147\n",
      "Epoch 75/80\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 0.0222 - val_loss: 0.0147\n",
      "Epoch 76/80\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 0.0224 - val_loss: 0.0147\n",
      "Epoch 77/80\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 0.0227 - val_loss: 0.0147\n",
      "Epoch 78/80\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 0.0222 - val_loss: 0.0147\n",
      "Epoch 79/80\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 0.0223 - val_loss: 0.0148\n",
      "Epoch 80/80\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 0.0220 - val_loss: 0.0147\n",
      "Execution time:  25.21869421005249\n",
      "DNN:\n",
      "Mean Absolute Error: 0.0218\n",
      "Root Mean Square Error: 0.0335\n",
      "Mean Square Error: 0.0011\n",
      "\n",
      "Train RMSE: 0.033\n",
      "Train MSE: 0.001\n",
      "Train MAE: 0.022\n",
      "###########################\n",
      "\n",
      "MODEL:  DNN\n",
      "sequence:  6h\n",
      "units:  80\n",
      "dropout1:  0.11814836227952394\n",
      "optimizer: adam\n",
      "activationDense: tanh\n",
      "epochs: 90\n",
      "batchsize: 25\n",
      "validation_split: 0.2\n",
      "Model: \"sequential_76\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_228 (Dense)            (None, 36, 80)            160       \n",
      "_________________________________________________________________\n",
      "dense_229 (Dense)            (None, 36, 16)            1296      \n",
      "_________________________________________________________________\n",
      "dropout_76 (Dropout)         (None, 36, 16)            0         \n",
      "_________________________________________________________________\n",
      "dense_230 (Dense)            (None, 36, 1)             17        \n",
      "=================================================================\n",
      "Total params: 1,473\n",
      "Trainable params: 1,473\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/90\n",
      "127/127 [==============================] - 0s 4ms/step - loss: 0.1364 - val_loss: 0.0269\n",
      "Epoch 2/90\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 0.0551 - val_loss: 0.0304\n",
      "Epoch 3/90\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 0.0529 - val_loss: 0.0259\n",
      "Epoch 4/90\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 0.0503 - val_loss: 0.0244\n",
      "Epoch 5/90\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 0.0477 - val_loss: 0.0247\n",
      "Epoch 6/90\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 0.0457 - val_loss: 0.0214\n",
      "Epoch 7/90\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 0.0434 - val_loss: 0.0235\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/90\n",
      "127/127 [==============================] - 0s 2ms/step - loss: 0.0417 - val_loss: 0.0231\n",
      "Epoch 9/90\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 0.0395 - val_loss: 0.0241\n",
      "Epoch 10/90\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 0.0372 - val_loss: 0.0147\n",
      "Epoch 11/90\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 0.0348 - val_loss: 0.0223\n",
      "Epoch 12/90\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 0.0334 - val_loss: 0.0174\n",
      "Epoch 13/90\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 0.0320 - val_loss: 0.0180\n",
      "Epoch 14/90\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 0.0313 - val_loss: 0.0161\n",
      "Epoch 15/90\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 0.0306 - val_loss: 0.0160\n",
      "Epoch 16/90\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 0.0301 - val_loss: 0.0157\n",
      "Epoch 17/90\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 0.0297 - val_loss: 0.0156\n",
      "Epoch 18/90\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 0.0293 - val_loss: 0.0154\n",
      "Epoch 19/90\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 0.0287 - val_loss: 0.0154\n",
      "Epoch 20/90\n",
      "127/127 [==============================] - 0s 2ms/step - loss: 0.0289 - val_loss: 0.0147\n",
      "Epoch 21/90\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 0.0302 - val_loss: 0.0165\n",
      "Epoch 22/90\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 0.0301 - val_loss: 0.0156\n",
      "Epoch 23/90\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 0.0294 - val_loss: 0.0159\n",
      "Epoch 24/90\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 0.0296 - val_loss: 0.0153\n",
      "Epoch 25/90\n",
      "127/127 [==============================] - 0s 2ms/step - loss: 0.0289 - val_loss: 0.0159\n",
      "Epoch 26/90\n",
      "127/127 [==============================] - 0s 2ms/step - loss: 0.0295 - val_loss: 0.0154\n",
      "Epoch 27/90\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 0.0287 - val_loss: 0.0156\n",
      "Epoch 28/90\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 0.0291 - val_loss: 0.0154\n",
      "Epoch 29/90\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 0.0283 - val_loss: 0.0157\n",
      "Epoch 30/90\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 0.0293 - val_loss: 0.0154\n",
      "Epoch 31/90\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 0.0282 - val_loss: 0.0156\n",
      "Epoch 32/90\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 0.0291 - val_loss: 0.0153\n",
      "Epoch 33/90\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 0.0278 - val_loss: 0.0156\n",
      "Epoch 34/90\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 0.0288 - val_loss: 0.0152\n",
      "Epoch 35/90\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 0.0272 - val_loss: 0.0156\n",
      "Epoch 36/90\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 0.0281 - val_loss: 0.0151\n",
      "Epoch 37/90\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 0.0266 - val_loss: 0.0155\n",
      "Epoch 38/90\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 0.0270 - val_loss: 0.0153\n",
      "Epoch 39/90\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 0.0266 - val_loss: 0.0153\n",
      "Epoch 40/90\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 0.0272 - val_loss: 0.0151\n",
      "Epoch 41/90\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 0.0257 - val_loss: 0.0154\n",
      "Epoch 42/90\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 0.0271 - val_loss: 0.0151\n",
      "Epoch 43/90\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 0.0252 - val_loss: 0.0153\n",
      "Epoch 44/90\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 0.0264 - val_loss: 0.0151\n",
      "Epoch 45/90\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 0.0247 - val_loss: 0.0153\n",
      "Epoch 46/90\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 0.0256 - val_loss: 0.0152\n",
      "Epoch 47/90\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 0.0249 - val_loss: 0.0151\n",
      "Epoch 48/90\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 0.0249 - val_loss: 0.0151\n",
      "Epoch 49/90\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 0.0245 - val_loss: 0.0150\n",
      "Epoch 50/90\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 0.0236 - val_loss: 0.0151\n",
      "Epoch 51/90\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 0.0234 - val_loss: 0.0150\n",
      "Epoch 52/90\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 0.0228 - val_loss: 0.0150\n",
      "Epoch 53/90\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 0.0232 - val_loss: 0.0149\n",
      "Epoch 54/90\n",
      "127/127 [==============================] - 0s 2ms/step - loss: 0.0224 - val_loss: 0.0150\n",
      "Epoch 55/90\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 0.0218 - val_loss: 0.0147\n",
      "Epoch 56/90\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 0.0209 - val_loss: 0.0146\n",
      "Epoch 57/90\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 0.0208 - val_loss: 0.0148\n",
      "Epoch 58/90\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 0.0203 - val_loss: 0.0149\n",
      "Epoch 59/90\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 0.0200 - val_loss: 0.0149\n",
      "Epoch 60/90\n",
      "127/127 [==============================] - 0s 2ms/step - loss: 0.0196 - val_loss: 0.0150\n",
      "Epoch 61/90\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 0.0195 - val_loss: 0.0150\n",
      "Epoch 62/90\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 0.0191 - val_loss: 0.0148\n",
      "Epoch 63/90\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 0.0192 - val_loss: 0.0147\n",
      "Epoch 64/90\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 0.0189 - val_loss: 0.0146\n",
      "Epoch 65/90\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 0.0187 - val_loss: 0.0147\n",
      "Epoch 66/90\n",
      "127/127 [==============================] - 0s 2ms/step - loss: 0.0189 - val_loss: 0.0150\n",
      "Epoch 67/90\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 0.0189 - val_loss: 0.0147\n",
      "Epoch 68/90\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 0.0188 - val_loss: 0.0150\n",
      "Epoch 69/90\n",
      "127/127 [==============================] - 0s 2ms/step - loss: 0.0186 - val_loss: 0.0146\n",
      "Epoch 70/90\n",
      "127/127 [==============================] - 0s 2ms/step - loss: 0.0186 - val_loss: 0.0147\n",
      "Epoch 71/90\n",
      "127/127 [==============================] - 0s 2ms/step - loss: 0.0188 - val_loss: 0.0149\n",
      "Epoch 72/90\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 0.0186 - val_loss: 0.0146\n",
      "Epoch 73/90\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 0.0185 - val_loss: 0.0147\n",
      "Epoch 74/90\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 0.0189 - val_loss: 0.0146\n",
      "Epoch 75/90\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 0.0186 - val_loss: 0.0149\n",
      "Epoch 76/90\n",
      "127/127 [==============================] - 0s 2ms/step - loss: 0.0184 - val_loss: 0.0146\n",
      "Epoch 77/90\n",
      "127/127 [==============================] - 0s 2ms/step - loss: 0.0187 - val_loss: 0.0146\n",
      "Epoch 78/90\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 0.0186 - val_loss: 0.0145\n",
      "Epoch 79/90\n",
      "127/127 [==============================] - 0s 2ms/step - loss: 0.0185 - val_loss: 0.0146\n",
      "Epoch 80/90\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 0.0185 - val_loss: 0.0146\n",
      "Epoch 81/90\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 0.0187 - val_loss: 0.0150\n",
      "Epoch 82/90\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 0.0184 - val_loss: 0.0146\n",
      "Epoch 83/90\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 0.0185 - val_loss: 0.0146\n",
      "Epoch 84/90\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 0.0183 - val_loss: 0.0146\n",
      "Epoch 85/90\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 0.0186 - val_loss: 0.0147\n",
      "Epoch 86/90\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 0.0184 - val_loss: 0.0146\n",
      "Epoch 87/90\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 0.0184 - val_loss: 0.0150\n",
      "Epoch 88/90\n",
      "127/127 [==============================] - 0s 2ms/step - loss: 0.0184 - val_loss: 0.0146\n",
      "Epoch 89/90\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "127/127 [==============================] - 0s 2ms/step - loss: 0.0184 - val_loss: 0.0146\n",
      "Epoch 90/90\n",
      "127/127 [==============================] - 0s 2ms/step - loss: 0.0184 - val_loss: 0.0149\n",
      "Execution time:  31.463290214538574\n",
      "DNN:\n",
      "Mean Absolute Error: 0.0164\n",
      "Root Mean Square Error: 0.0300\n",
      "Mean Square Error: 0.0009\n",
      "\n",
      "Train RMSE: 0.030\n",
      "Train MSE: 0.001\n",
      "Train MAE: 0.016\n",
      "###########################\n",
      "\n",
      "MODEL:  DNN\n",
      "sequence:  6h\n",
      "units:  12\n",
      "dropout1:  0.48476373451509647\n",
      "optimizer: adam\n",
      "activationDense: tanh\n",
      "epochs: 52\n",
      "batchsize: 57\n",
      "validation_split: 0.2\n",
      "Model: \"sequential_77\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_231 (Dense)            (None, 36, 12)            24        \n",
      "_________________________________________________________________\n",
      "dense_232 (Dense)            (None, 36, 16)            208       \n",
      "_________________________________________________________________\n",
      "dropout_77 (Dropout)         (None, 36, 16)            0         \n",
      "_________________________________________________________________\n",
      "dense_233 (Dense)            (None, 36, 1)             17        \n",
      "=================================================================\n",
      "Total params: 249\n",
      "Trainable params: 249\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/52\n",
      "56/56 [==============================] - 0s 6ms/step - loss: 0.2332 - val_loss: 0.0476\n",
      "Epoch 2/52\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 0.1069 - val_loss: 0.0161\n",
      "Epoch 3/52\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 0.0888 - val_loss: 0.0176\n",
      "Epoch 4/52\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 0.0816 - val_loss: 0.0189\n",
      "Epoch 5/52\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 0.0744 - val_loss: 0.0161\n",
      "Epoch 6/52\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 0.0674 - val_loss: 0.0136\n",
      "Epoch 7/52\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 0.0612 - val_loss: 0.0135\n",
      "Epoch 8/52\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 0.0556 - val_loss: 0.0138\n",
      "Epoch 9/52\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 0.0509 - val_loss: 0.0138\n",
      "Epoch 10/52\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 0.0461 - val_loss: 0.0137\n",
      "Epoch 11/52\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 0.0421 - val_loss: 0.0135\n",
      "Epoch 12/52\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 0.0382 - val_loss: 0.0135\n",
      "Epoch 13/52\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 0.0353 - val_loss: 0.0137\n",
      "Epoch 14/52\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 0.0328 - val_loss: 0.0135\n",
      "Epoch 15/52\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 0.0311 - val_loss: 0.0137\n",
      "Epoch 16/52\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 0.0301 - val_loss: 0.0142\n",
      "Epoch 17/52\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 0.0291 - val_loss: 0.0140\n",
      "Epoch 18/52\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 0.0274 - val_loss: 0.0143\n",
      "Epoch 19/52\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 0.0276 - val_loss: 0.0146\n",
      "Epoch 20/52\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 0.0278 - val_loss: 0.0147\n",
      "Epoch 21/52\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 0.0267 - val_loss: 0.0147\n",
      "Epoch 22/52\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 0.0276 - val_loss: 0.0150\n",
      "Epoch 23/52\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 0.0260 - val_loss: 0.0147\n",
      "Epoch 24/52\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 0.0271 - val_loss: 0.0146\n",
      "Epoch 25/52\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 0.0256 - val_loss: 0.0147\n",
      "Epoch 26/52\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 0.0267 - val_loss: 0.0150\n",
      "Epoch 27/52\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 0.0256 - val_loss: 0.0146\n",
      "Epoch 28/52\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 0.0260 - val_loss: 0.0145\n",
      "Epoch 29/52\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 0.0252 - val_loss: 0.0146\n",
      "Epoch 30/52\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 0.0257 - val_loss: 0.0144\n",
      "Epoch 31/52\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 0.0251 - val_loss: 0.0145\n",
      "Epoch 32/52\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 0.0252 - val_loss: 0.0144\n",
      "Epoch 33/52\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 0.0246 - val_loss: 0.0145\n",
      "Epoch 34/52\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 0.0246 - val_loss: 0.0142\n",
      "Epoch 35/52\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 0.0242 - val_loss: 0.0144\n",
      "Epoch 36/52\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 0.0243 - val_loss: 0.0141\n",
      "Epoch 37/52\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 0.0237 - val_loss: 0.0144\n",
      "Epoch 38/52\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 0.0239 - val_loss: 0.0140\n",
      "Epoch 39/52\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 0.0231 - val_loss: 0.0145\n",
      "Epoch 40/52\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 0.0233 - val_loss: 0.0141\n",
      "Epoch 41/52\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 0.0231 - val_loss: 0.0144\n",
      "Epoch 42/52\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 0.0231 - val_loss: 0.0141\n",
      "Epoch 43/52\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 0.0229 - val_loss: 0.0145\n",
      "Epoch 44/52\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 0.0227 - val_loss: 0.0140\n",
      "Epoch 45/52\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 0.0225 - val_loss: 0.0143\n",
      "Epoch 46/52\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 0.0223 - val_loss: 0.0140\n",
      "Epoch 47/52\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 0.0224 - val_loss: 0.0142\n",
      "Epoch 48/52\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 0.0222 - val_loss: 0.0141\n",
      "Epoch 49/52\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 0.0224 - val_loss: 0.0142\n",
      "Epoch 50/52\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 0.0216 - val_loss: 0.0142\n",
      "Epoch 51/52\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 0.0222 - val_loss: 0.0140\n",
      "Epoch 52/52\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 0.0211 - val_loss: 0.0143\n",
      "Execution time:  9.001029968261719\n",
      "DNN:\n",
      "Mean Absolute Error: 0.0178\n",
      "Root Mean Square Error: 0.0268\n",
      "Mean Square Error: 0.0007\n",
      "\n",
      "Train RMSE: 0.027\n",
      "Train MSE: 0.001\n",
      "Train MAE: 0.018\n",
      "###########################\n",
      "\n",
      "MODEL:  DNN\n",
      "sequence:  6h\n",
      "units:  87\n",
      "dropout1:  0.40519643149940265\n",
      "optimizer: adam\n",
      "activationDense: sigmoid\n",
      "epochs: 80\n",
      "batchsize: 31\n",
      "validation_split: 0.1\n",
      "Model: \"sequential_78\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_234 (Dense)            (None, 36, 87)            174       \n",
      "_________________________________________________________________\n",
      "dense_235 (Dense)            (None, 36, 16)            1408      \n",
      "_________________________________________________________________\n",
      "dropout_78 (Dropout)         (None, 36, 16)            0         \n",
      "_________________________________________________________________\n",
      "dense_236 (Dense)            (None, 36, 1)             17        \n",
      "=================================================================\n",
      "Total params: 1,599\n",
      "Trainable params: 1,599\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/80\n",
      "115/115 [==============================] - 0s 4ms/step - loss: 0.0459 - val_loss: 0.0261\n",
      "Epoch 2/80\n",
      "115/115 [==============================] - 0s 3ms/step - loss: 0.0424 - val_loss: 0.0221\n",
      "Epoch 3/80\n",
      "115/115 [==============================] - 0s 3ms/step - loss: 0.0405 - val_loss: 0.0218\n",
      "Epoch 4/80\n",
      "115/115 [==============================] - 0s 3ms/step - loss: 0.0388 - val_loss: 0.0204\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/80\n",
      "115/115 [==============================] - 0s 3ms/step - loss: 0.0373 - val_loss: 0.0199\n",
      "Epoch 6/80\n",
      "115/115 [==============================] - 0s 3ms/step - loss: 0.0362 - val_loss: 0.0190\n",
      "Epoch 7/80\n",
      "115/115 [==============================] - 0s 3ms/step - loss: 0.0351 - val_loss: 0.0191\n",
      "Epoch 8/80\n",
      "115/115 [==============================] - 0s 3ms/step - loss: 0.0340 - val_loss: 0.0180\n",
      "Epoch 9/80\n",
      "115/115 [==============================] - 0s 3ms/step - loss: 0.0331 - val_loss: 0.0177\n",
      "Epoch 10/80\n",
      "115/115 [==============================] - 0s 3ms/step - loss: 0.0323 - val_loss: 0.0174\n",
      "Epoch 11/80\n",
      "115/115 [==============================] - 0s 3ms/step - loss: 0.0316 - val_loss: 0.0171\n",
      "Epoch 12/80\n",
      "115/115 [==============================] - 0s 3ms/step - loss: 0.0310 - val_loss: 0.0167\n",
      "Epoch 13/80\n",
      "115/115 [==============================] - 0s 3ms/step - loss: 0.0304 - val_loss: 0.0160\n",
      "Epoch 14/80\n",
      "115/115 [==============================] - 0s 3ms/step - loss: 0.0298 - val_loss: 0.0157\n",
      "Epoch 15/80\n",
      "115/115 [==============================] - 0s 3ms/step - loss: 0.0294 - val_loss: 0.0175\n",
      "Epoch 16/80\n",
      "115/115 [==============================] - 0s 3ms/step - loss: 0.0296 - val_loss: 0.0153\n",
      "Epoch 17/80\n",
      "115/115 [==============================] - 0s 3ms/step - loss: 0.0286 - val_loss: 0.0144\n",
      "Epoch 18/80\n",
      "115/115 [==============================] - 0s 3ms/step - loss: 0.0283 - val_loss: 0.0145\n",
      "Epoch 19/80\n",
      "115/115 [==============================] - 0s 3ms/step - loss: 0.0280 - val_loss: 0.0141\n",
      "Epoch 20/80\n",
      "115/115 [==============================] - 0s 3ms/step - loss: 0.0279 - val_loss: 0.0139\n",
      "Epoch 21/80\n",
      "115/115 [==============================] - 0s 3ms/step - loss: 0.0274 - val_loss: 0.0137\n",
      "Epoch 22/80\n",
      "115/115 [==============================] - 0s 3ms/step - loss: 0.0272 - val_loss: 0.0136\n",
      "Epoch 23/80\n",
      "115/115 [==============================] - 0s 3ms/step - loss: 0.0271 - val_loss: 0.0134\n",
      "Epoch 24/80\n",
      "115/115 [==============================] - 0s 3ms/step - loss: 0.0269 - val_loss: 0.0132\n",
      "Epoch 25/80\n",
      "115/115 [==============================] - 0s 3ms/step - loss: 0.0268 - val_loss: 0.0131\n",
      "Epoch 26/80\n",
      "115/115 [==============================] - 0s 3ms/step - loss: 0.0267 - val_loss: 0.0129\n",
      "Epoch 27/80\n",
      "115/115 [==============================] - 0s 3ms/step - loss: 0.0266 - val_loss: 0.0128\n",
      "Epoch 28/80\n",
      "115/115 [==============================] - 0s 3ms/step - loss: 0.0264 - val_loss: 0.0126\n",
      "Epoch 29/80\n",
      "115/115 [==============================] - 0s 3ms/step - loss: 0.0263 - val_loss: 0.0126\n",
      "Epoch 30/80\n",
      "115/115 [==============================] - 0s 3ms/step - loss: 0.0263 - val_loss: 0.0126\n",
      "Epoch 31/80\n",
      "115/115 [==============================] - 0s 3ms/step - loss: 0.0261 - val_loss: 0.0126\n",
      "Epoch 32/80\n",
      "115/115 [==============================] - 0s 3ms/step - loss: 0.0260 - val_loss: 0.0125\n",
      "Epoch 33/80\n",
      "115/115 [==============================] - 0s 3ms/step - loss: 0.0259 - val_loss: 0.0122\n",
      "Epoch 34/80\n",
      "115/115 [==============================] - 0s 3ms/step - loss: 0.0257 - val_loss: 0.0123\n",
      "Epoch 35/80\n",
      "115/115 [==============================] - 0s 3ms/step - loss: 0.0256 - val_loss: 0.0125\n",
      "Epoch 36/80\n",
      "115/115 [==============================] - 0s 3ms/step - loss: 0.0254 - val_loss: 0.0123\n",
      "Epoch 37/80\n",
      "115/115 [==============================] - 0s 3ms/step - loss: 0.0253 - val_loss: 0.0123\n",
      "Epoch 38/80\n",
      "115/115 [==============================] - 0s 3ms/step - loss: 0.0251 - val_loss: 0.0125\n",
      "Epoch 39/80\n",
      "115/115 [==============================] - 0s 3ms/step - loss: 0.0250 - val_loss: 0.0129\n",
      "Epoch 40/80\n",
      "115/115 [==============================] - 0s 3ms/step - loss: 0.0247 - val_loss: 0.0126\n",
      "Epoch 41/80\n",
      "115/115 [==============================] - 0s 3ms/step - loss: 0.0246 - val_loss: 0.0127\n",
      "Epoch 42/80\n",
      "115/115 [==============================] - 0s 3ms/step - loss: 0.0243 - val_loss: 0.0127\n",
      "Epoch 43/80\n",
      "115/115 [==============================] - 0s 3ms/step - loss: 0.0242 - val_loss: 0.0121\n",
      "Epoch 44/80\n",
      "115/115 [==============================] - 0s 3ms/step - loss: 0.0242 - val_loss: 0.0124\n",
      "Epoch 45/80\n",
      "115/115 [==============================] - 0s 3ms/step - loss: 0.0241 - val_loss: 0.0119\n",
      "Epoch 46/80\n",
      "115/115 [==============================] - 0s 3ms/step - loss: 0.0239 - val_loss: 0.0120\n",
      "Epoch 47/80\n",
      "115/115 [==============================] - 0s 3ms/step - loss: 0.0238 - val_loss: 0.0125\n",
      "Epoch 48/80\n",
      "115/115 [==============================] - 0s 3ms/step - loss: 0.0237 - val_loss: 0.0124\n",
      "Epoch 49/80\n",
      "115/115 [==============================] - 0s 3ms/step - loss: 0.0236 - val_loss: 0.0129\n",
      "Epoch 50/80\n",
      "115/115 [==============================] - 0s 3ms/step - loss: 0.0236 - val_loss: 0.0128\n",
      "Epoch 51/80\n",
      "115/115 [==============================] - 0s 3ms/step - loss: 0.0234 - val_loss: 0.0132\n",
      "Epoch 52/80\n",
      "115/115 [==============================] - 0s 3ms/step - loss: 0.0232 - val_loss: 0.0124\n",
      "Epoch 53/80\n",
      "115/115 [==============================] - 0s 3ms/step - loss: 0.0231 - val_loss: 0.0136\n",
      "Epoch 54/80\n",
      "115/115 [==============================] - 0s 3ms/step - loss: 0.0230 - val_loss: 0.0130\n",
      "Epoch 55/80\n",
      "115/115 [==============================] - 0s 3ms/step - loss: 0.0230 - val_loss: 0.0133\n",
      "Epoch 56/80\n",
      "115/115 [==============================] - 0s 3ms/step - loss: 0.0229 - val_loss: 0.0135\n",
      "Epoch 57/80\n",
      "115/115 [==============================] - 0s 3ms/step - loss: 0.0227 - val_loss: 0.0131\n",
      "Epoch 58/80\n",
      "115/115 [==============================] - 0s 3ms/step - loss: 0.0228 - val_loss: 0.0138\n",
      "Epoch 59/80\n",
      "115/115 [==============================] - 0s 3ms/step - loss: 0.0226 - val_loss: 0.0127\n",
      "Epoch 60/80\n",
      "115/115 [==============================] - 0s 3ms/step - loss: 0.0225 - val_loss: 0.0137\n",
      "Epoch 61/80\n",
      "115/115 [==============================] - 0s 3ms/step - loss: 0.0225 - val_loss: 0.0140\n",
      "Epoch 62/80\n",
      "115/115 [==============================] - 0s 3ms/step - loss: 0.0225 - val_loss: 0.0135\n",
      "Epoch 63/80\n",
      "115/115 [==============================] - 0s 3ms/step - loss: 0.0224 - val_loss: 0.0138\n",
      "Epoch 64/80\n",
      "115/115 [==============================] - 0s 3ms/step - loss: 0.0224 - val_loss: 0.0135\n",
      "Epoch 65/80\n",
      "115/115 [==============================] - 0s 3ms/step - loss: 0.0223 - val_loss: 0.0144\n",
      "Epoch 66/80\n",
      "115/115 [==============================] - 0s 3ms/step - loss: 0.0221 - val_loss: 0.0134\n",
      "Epoch 67/80\n",
      "115/115 [==============================] - 0s 3ms/step - loss: 0.0221 - val_loss: 0.0143\n",
      "Epoch 68/80\n",
      "115/115 [==============================] - 0s 3ms/step - loss: 0.0221 - val_loss: 0.0146\n",
      "Epoch 69/80\n",
      "115/115 [==============================] - 0s 3ms/step - loss: 0.0221 - val_loss: 0.0140\n",
      "Epoch 70/80\n",
      "115/115 [==============================] - 0s 3ms/step - loss: 0.0220 - val_loss: 0.0148\n",
      "Epoch 71/80\n",
      "115/115 [==============================] - 0s 3ms/step - loss: 0.0220 - val_loss: 0.0139\n",
      "Epoch 72/80\n",
      "115/115 [==============================] - 0s 3ms/step - loss: 0.0219 - val_loss: 0.0146\n",
      "Epoch 73/80\n",
      "115/115 [==============================] - 0s 3ms/step - loss: 0.0220 - val_loss: 0.0145\n",
      "Epoch 74/80\n",
      "115/115 [==============================] - 0s 3ms/step - loss: 0.0220 - val_loss: 0.0146\n",
      "Epoch 75/80\n",
      "115/115 [==============================] - 0s 3ms/step - loss: 0.0221 - val_loss: 0.0144\n",
      "Epoch 76/80\n",
      "115/115 [==============================] - 0s 3ms/step - loss: 0.0220 - val_loss: 0.0141\n",
      "Epoch 77/80\n",
      "115/115 [==============================] - 0s 3ms/step - loss: 0.0220 - val_loss: 0.0145\n",
      "Epoch 78/80\n",
      "115/115 [==============================] - 0s 3ms/step - loss: 0.0219 - val_loss: 0.0149\n",
      "Epoch 79/80\n",
      "115/115 [==============================] - 0s 3ms/step - loss: 0.0219 - val_loss: 0.0172\n",
      "Epoch 80/80\n",
      "115/115 [==============================] - 0s 3ms/step - loss: 0.0221 - val_loss: 0.0139\n",
      "Execution time:  26.19046950340271\n",
      "DNN:\n",
      "Mean Absolute Error: 0.0178\n",
      "Root Mean Square Error: 0.0315\n",
      "Mean Square Error: 0.0010\n",
      "\n",
      "Train RMSE: 0.032\n",
      "Train MSE: 0.001\n",
      "Train MAE: 0.018\n",
      "###########################\n",
      "\n",
      "MODEL:  DNN\n",
      "sequence:  6h\n",
      "units:  80\n",
      "dropout1:  0.11814836227952394\n",
      "optimizer: adam\n",
      "activationDense: sigmoid\n",
      "epochs: 90\n",
      "batchsize: 25\n",
      "validation_split: 0.1\n",
      "Model: \"sequential_79\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_237 (Dense)            (None, 36, 80)            160       \n",
      "_________________________________________________________________\n",
      "dense_238 (Dense)            (None, 36, 16)            1296      \n",
      "_________________________________________________________________\n",
      "dropout_79 (Dropout)         (None, 36, 16)            0         \n",
      "_________________________________________________________________\n",
      "dense_239 (Dense)            (None, 36, 1)             17        \n",
      "=================================================================\n",
      "Total params: 1,473\n",
      "Trainable params: 1,473\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/90\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "143/143 [==============================] - 1s 4ms/step - loss: 0.0385 - val_loss: 0.0292\n",
      "Epoch 2/90\n",
      "143/143 [==============================] - 0s 3ms/step - loss: 0.0363 - val_loss: 0.0229\n",
      "Epoch 3/90\n",
      "143/143 [==============================] - 0s 3ms/step - loss: 0.0357 - val_loss: 0.0222\n",
      "Epoch 4/90\n",
      "143/143 [==============================] - 0s 3ms/step - loss: 0.0351 - val_loss: 0.0199\n",
      "Epoch 5/90\n",
      "143/143 [==============================] - 0s 3ms/step - loss: 0.0344 - val_loss: 0.0199\n",
      "Epoch 6/90\n",
      "143/143 [==============================] - 0s 3ms/step - loss: 0.0340 - val_loss: 0.0211\n",
      "Epoch 7/90\n",
      "143/143 [==============================] - 0s 3ms/step - loss: 0.0332 - val_loss: 0.0248\n",
      "Epoch 8/90\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.0338 - val_loss: 0.0223\n",
      "Epoch 9/90\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.0328 - val_loss: 0.0211\n",
      "Epoch 10/90\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.0323 - val_loss: 0.0187\n",
      "Epoch 11/90\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.0318 - val_loss: 0.0183\n",
      "Epoch 12/90\n",
      "143/143 [==============================] - 0s 3ms/step - loss: 0.0312 - val_loss: 0.0174\n",
      "Epoch 13/90\n",
      "143/143 [==============================] - 0s 3ms/step - loss: 0.0310 - val_loss: 0.0175\n",
      "Epoch 14/90\n",
      "143/143 [==============================] - 0s 3ms/step - loss: 0.0307 - val_loss: 0.0165\n",
      "Epoch 15/90\n",
      "143/143 [==============================] - 0s 3ms/step - loss: 0.0305 - val_loss: 0.0165\n",
      "Epoch 16/90\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.0303 - val_loss: 0.0163\n",
      "Epoch 17/90\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.0300 - val_loss: 0.0154\n",
      "Epoch 18/90\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.0298 - val_loss: 0.0155\n",
      "Epoch 19/90\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.0290 - val_loss: 0.0240\n",
      "Epoch 20/90\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.0287 - val_loss: 0.0151\n",
      "Epoch 21/90\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.0292 - val_loss: 0.0144\n",
      "Epoch 22/90\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.0290 - val_loss: 0.0152\n",
      "Epoch 23/90\n",
      "143/143 [==============================] - 0s 3ms/step - loss: 0.0288 - val_loss: 0.0168\n",
      "Epoch 24/90\n",
      "143/143 [==============================] - 0s 3ms/step - loss: 0.0293 - val_loss: 0.0143\n",
      "Epoch 25/90\n",
      "143/143 [==============================] - 0s 3ms/step - loss: 0.0290 - val_loss: 0.0138\n",
      "Epoch 26/90\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.0286 - val_loss: 0.0143\n",
      "Epoch 27/90\n",
      "143/143 [==============================] - 0s 3ms/step - loss: 0.0282 - val_loss: 0.0140\n",
      "Epoch 28/90\n",
      "143/143 [==============================] - 0s 3ms/step - loss: 0.0280 - val_loss: 0.0138\n",
      "Epoch 29/90\n",
      "143/143 [==============================] - 0s 3ms/step - loss: 0.0280 - val_loss: 0.0137\n",
      "Epoch 30/90\n",
      "143/143 [==============================] - 0s 3ms/step - loss: 0.0278 - val_loss: 0.0132\n",
      "Epoch 31/90\n",
      "143/143 [==============================] - 0s 3ms/step - loss: 0.0277 - val_loss: 0.0135\n",
      "Epoch 32/90\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.0273 - val_loss: 0.0132\n",
      "Epoch 33/90\n",
      "143/143 [==============================] - 0s 3ms/step - loss: 0.0269 - val_loss: 0.0130\n",
      "Epoch 34/90\n",
      "143/143 [==============================] - 0s 3ms/step - loss: 0.0271 - val_loss: 0.0134\n",
      "Epoch 35/90\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.0270 - val_loss: 0.0136\n",
      "Epoch 36/90\n",
      "143/143 [==============================] - 0s 3ms/step - loss: 0.0267 - val_loss: 0.0135\n",
      "Epoch 37/90\n",
      "143/143 [==============================] - 0s 3ms/step - loss: 0.0265 - val_loss: 0.0129\n",
      "Epoch 38/90\n",
      "143/143 [==============================] - 0s 3ms/step - loss: 0.0263 - val_loss: 0.0133\n",
      "Epoch 39/90\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.0260 - val_loss: 0.0133\n",
      "Epoch 40/90\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.0258 - val_loss: 0.0134\n",
      "Epoch 41/90\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.0256 - val_loss: 0.0129\n",
      "Epoch 42/90\n",
      "143/143 [==============================] - 0s 3ms/step - loss: 0.0254 - val_loss: 0.0134\n",
      "Epoch 43/90\n",
      "143/143 [==============================] - 0s 3ms/step - loss: 0.0250 - val_loss: 0.0138\n",
      "Epoch 44/90\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.0248 - val_loss: 0.0129\n",
      "Epoch 45/90\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.0245 - val_loss: 0.0133\n",
      "Epoch 46/90\n",
      "143/143 [==============================] - 0s 3ms/step - loss: 0.0241 - val_loss: 0.0136\n",
      "Epoch 47/90\n",
      "143/143 [==============================] - 0s 3ms/step - loss: 0.0236 - val_loss: 0.0134\n",
      "Epoch 48/90\n",
      "143/143 [==============================] - 0s 3ms/step - loss: 0.0233 - val_loss: 0.0128\n",
      "Epoch 49/90\n",
      "143/143 [==============================] - 0s 3ms/step - loss: 0.0226 - val_loss: 0.0128\n",
      "Epoch 50/90\n",
      "143/143 [==============================] - 0s 3ms/step - loss: 0.0219 - val_loss: 0.0135\n",
      "Epoch 51/90\n",
      "143/143 [==============================] - 0s 3ms/step - loss: 0.0213 - val_loss: 0.0176\n",
      "Epoch 52/90\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.0208 - val_loss: 0.0160\n",
      "Epoch 53/90\n",
      "143/143 [==============================] - 0s 3ms/step - loss: 0.0206 - val_loss: 0.0154\n",
      "Epoch 54/90\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.0201 - val_loss: 0.0156\n",
      "Epoch 55/90\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.0199 - val_loss: 0.0152\n",
      "Epoch 56/90\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.0197 - val_loss: 0.0155\n",
      "Epoch 57/90\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.0195 - val_loss: 0.0158\n",
      "Epoch 58/90\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.0193 - val_loss: 0.0165\n",
      "Epoch 59/90\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.0191 - val_loss: 0.0160\n",
      "Epoch 60/90\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.0190 - val_loss: 0.0160\n",
      "Epoch 61/90\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.0190 - val_loss: 0.0200\n",
      "Epoch 62/90\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.0190 - val_loss: 0.0160\n",
      "Epoch 63/90\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.0189 - val_loss: 0.0158\n",
      "Epoch 64/90\n",
      "143/143 [==============================] - 0s 3ms/step - loss: 0.0188 - val_loss: 0.0196\n",
      "Epoch 65/90\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.0189 - val_loss: 0.0158\n",
      "Epoch 66/90\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.0188 - val_loss: 0.0158\n",
      "Epoch 67/90\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.0188 - val_loss: 0.0168\n",
      "Epoch 68/90\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.0186 - val_loss: 0.0191\n",
      "Epoch 69/90\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.0188 - val_loss: 0.0165\n",
      "Epoch 70/90\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.0187 - val_loss: 0.0167\n",
      "Epoch 71/90\n",
      "143/143 [==============================] - 0s 3ms/step - loss: 0.0185 - val_loss: 0.0158\n",
      "Epoch 72/90\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.0187 - val_loss: 0.0171\n",
      "Epoch 73/90\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.0188 - val_loss: 0.0158\n",
      "Epoch 74/90\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.0186 - val_loss: 0.0159\n",
      "Epoch 75/90\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.0186 - val_loss: 0.0163\n",
      "Epoch 76/90\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.0185 - val_loss: 0.0160\n",
      "Epoch 77/90\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.0186 - val_loss: 0.0155\n",
      "Epoch 78/90\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.0186 - val_loss: 0.0163\n",
      "Epoch 79/90\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.0184 - val_loss: 0.0167\n",
      "Epoch 80/90\n",
      "143/143 [==============================] - 0s 3ms/step - loss: 0.0184 - val_loss: 0.0165\n",
      "Epoch 81/90\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.0185 - val_loss: 0.0155\n",
      "Epoch 82/90\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "143/143 [==============================] - 0s 2ms/step - loss: 0.0186 - val_loss: 0.0158\n",
      "Epoch 83/90\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.0185 - val_loss: 0.0156\n",
      "Epoch 84/90\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.0185 - val_loss: 0.0156\n",
      "Epoch 85/90\n",
      "143/143 [==============================] - 0s 3ms/step - loss: 0.0185 - val_loss: 0.0164\n",
      "Epoch 86/90\n",
      "143/143 [==============================] - 0s 3ms/step - loss: 0.0185 - val_loss: 0.0156\n",
      "Epoch 87/90\n",
      "143/143 [==============================] - 0s 3ms/step - loss: 0.0186 - val_loss: 0.0155\n",
      "Epoch 88/90\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.0185 - val_loss: 0.0162\n",
      "Epoch 89/90\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.0184 - val_loss: 0.0156\n",
      "Epoch 90/90\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.0185 - val_loss: 0.0158\n",
      "Execution time:  33.45890426635742\n",
      "DNN:\n",
      "Mean Absolute Error: 0.0162\n",
      "Root Mean Square Error: 0.0258\n",
      "Mean Square Error: 0.0007\n",
      "\n",
      "Train RMSE: 0.026\n",
      "Train MSE: 0.001\n",
      "Train MAE: 0.016\n",
      "###########################\n",
      "\n",
      "MODEL:  DNN\n",
      "sequence:  6h\n",
      "units:  12\n",
      "dropout1:  0.48476373451509647\n",
      "optimizer: adam\n",
      "activationDense: sigmoid\n",
      "epochs: 52\n",
      "batchsize: 57\n",
      "validation_split: 0.1\n",
      "Model: \"sequential_80\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_240 (Dense)            (None, 36, 12)            24        \n",
      "_________________________________________________________________\n",
      "dense_241 (Dense)            (None, 36, 16)            208       \n",
      "_________________________________________________________________\n",
      "dropout_80 (Dropout)         (None, 36, 16)            0         \n",
      "_________________________________________________________________\n",
      "dense_242 (Dense)            (None, 36, 1)             17        \n",
      "=================================================================\n",
      "Total params: 249\n",
      "Trainable params: 249\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/52\n",
      "63/63 [==============================] - 0s 7ms/step - loss: 0.0782 - val_loss: 0.0818\n",
      "Epoch 2/52\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.0469 - val_loss: 0.0383\n",
      "Epoch 3/52\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.0417 - val_loss: 0.0346\n",
      "Epoch 4/52\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.0394 - val_loss: 0.0331\n",
      "Epoch 5/52\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.0379 - val_loss: 0.0325\n",
      "Epoch 6/52\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0368 - val_loss: 0.0317\n",
      "Epoch 7/52\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0359 - val_loss: 0.0309\n",
      "Epoch 8/52\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0349 - val_loss: 0.0295\n",
      "Epoch 9/52\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.0342 - val_loss: 0.0276\n",
      "Epoch 10/52\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0334 - val_loss: 0.0264\n",
      "Epoch 11/52\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0328 - val_loss: 0.0254\n",
      "Epoch 12/52\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.0322 - val_loss: 0.0245\n",
      "Epoch 13/52\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0317 - val_loss: 0.0235\n",
      "Epoch 14/52\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0312 - val_loss: 0.0226\n",
      "Epoch 15/52\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.0306 - val_loss: 0.0217\n",
      "Epoch 16/52\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0303 - val_loss: 0.0212\n",
      "Epoch 17/52\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.0299 - val_loss: 0.0204\n",
      "Epoch 18/52\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.0294 - val_loss: 0.0196\n",
      "Epoch 19/52\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0292 - val_loss: 0.0190\n",
      "Epoch 20/52\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.0288 - val_loss: 0.0181\n",
      "Epoch 21/52\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.0285 - val_loss: 0.0175\n",
      "Epoch 22/52\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.0283 - val_loss: 0.0170\n",
      "Epoch 23/52\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0279 - val_loss: 0.0164\n",
      "Epoch 24/52\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0278 - val_loss: 0.0157\n",
      "Epoch 25/52\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.0276 - val_loss: 0.0150\n",
      "Epoch 26/52\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0274 - val_loss: 0.0147\n",
      "Epoch 27/52\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0272 - val_loss: 0.0143\n",
      "Epoch 28/52\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.0271 - val_loss: 0.0141\n",
      "Epoch 29/52\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.0269 - val_loss: 0.0137\n",
      "Epoch 30/52\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0268 - val_loss: 0.0137\n",
      "Epoch 31/52\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0266 - val_loss: 0.0133\n",
      "Epoch 32/52\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0265 - val_loss: 0.0131\n",
      "Epoch 33/52\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0264 - val_loss: 0.0129\n",
      "Epoch 34/52\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0263 - val_loss: 0.0128\n",
      "Epoch 35/52\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.0262 - val_loss: 0.0126\n",
      "Epoch 36/52\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.0261 - val_loss: 0.0125\n",
      "Epoch 37/52\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.0260 - val_loss: 0.0126\n",
      "Epoch 38/52\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0259 - val_loss: 0.0123\n",
      "Epoch 39/52\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.0258 - val_loss: 0.0122\n",
      "Epoch 40/52\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0257 - val_loss: 0.0128\n",
      "Epoch 41/52\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0256 - val_loss: 0.0129\n",
      "Epoch 42/52\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0254 - val_loss: 0.0128\n",
      "Epoch 43/52\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0254 - val_loss: 0.0125\n",
      "Epoch 44/52\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.0253 - val_loss: 0.0123\n",
      "Epoch 45/52\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.0252 - val_loss: 0.0125\n",
      "Epoch 46/52\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.0251 - val_loss: 0.0126\n",
      "Epoch 47/52\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0251 - val_loss: 0.0123\n",
      "Epoch 48/52\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0250 - val_loss: 0.0128\n",
      "Epoch 49/52\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0249 - val_loss: 0.0126\n",
      "Epoch 50/52\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0248 - val_loss: 0.0124\n",
      "Epoch 51/52\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.0247 - val_loss: 0.0124\n",
      "Epoch 52/52\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.0247 - val_loss: 0.0122\n",
      "Execution time:  9.482357501983643\n",
      "DNN:\n",
      "Mean Absolute Error: 0.0212\n",
      "Root Mean Square Error: 0.0367\n",
      "Mean Square Error: 0.0013\n",
      "\n",
      "Train RMSE: 0.037\n",
      "Train MSE: 0.001\n",
      "Train MAE: 0.021\n",
      "###########################\n",
      "\n",
      "MODEL:  DNN\n",
      "sequence:  6h\n",
      "units:  87\n",
      "dropout1:  0.40519643149940265\n",
      "optimizer: adam\n",
      "activationDense: sigmoid\n",
      "epochs: 80\n",
      "batchsize: 31\n",
      "validation_split: 0.2\n",
      "Model: \"sequential_81\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_243 (Dense)            (None, 36, 87)            174       \n",
      "_________________________________________________________________\n",
      "dense_244 (Dense)            (None, 36, 16)            1408      \n",
      "_________________________________________________________________\n",
      "dropout_81 (Dropout)         (None, 36, 16)            0         \n",
      "_________________________________________________________________\n",
      "dense_245 (Dense)            (None, 36, 1)             17        \n",
      "=================================================================\n",
      "Total params: 1,599\n",
      "Trainable params: 1,599\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/80\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "103/103 [==============================] - 0s 5ms/step - loss: 0.0485 - val_loss: 0.0283\n",
      "Epoch 2/80\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 0.0429 - val_loss: 0.0188\n",
      "Epoch 3/80\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 0.0428 - val_loss: 0.0273\n",
      "Epoch 4/80\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 0.0404 - val_loss: 0.0260\n",
      "Epoch 5/80\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 0.0389 - val_loss: 0.0251\n",
      "Epoch 6/80\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 0.0378 - val_loss: 0.0243\n",
      "Epoch 7/80\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 0.0364 - val_loss: 0.0236\n",
      "Epoch 8/80\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 0.0356 - val_loss: 0.0234\n",
      "Epoch 9/80\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 0.0344 - val_loss: 0.0223\n",
      "Epoch 10/80\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 0.0338 - val_loss: 0.0220\n",
      "Epoch 11/80\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 0.0329 - val_loss: 0.0214\n",
      "Epoch 12/80\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 0.0323 - val_loss: 0.0210\n",
      "Epoch 13/80\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 0.0318 - val_loss: 0.0207\n",
      "Epoch 14/80\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 0.0313 - val_loss: 0.0205\n",
      "Epoch 15/80\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 0.0308 - val_loss: 0.0201\n",
      "Epoch 16/80\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 0.0304 - val_loss: 0.0185\n",
      "Epoch 17/80\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 0.0302 - val_loss: 0.0194\n",
      "Epoch 18/80\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 0.0298 - val_loss: 0.0191\n",
      "Epoch 19/80\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 0.0296 - val_loss: 0.0190\n",
      "Epoch 20/80\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 0.0294 - val_loss: 0.0188\n",
      "Epoch 21/80\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 0.0292 - val_loss: 0.0186\n",
      "Epoch 22/80\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 0.0290 - val_loss: 0.0184\n",
      "Epoch 23/80\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 0.0289 - val_loss: 0.0182\n",
      "Epoch 24/80\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 0.0287 - val_loss: 0.0181\n",
      "Epoch 25/80\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 0.0287 - val_loss: 0.0189\n",
      "Epoch 26/80\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 0.0284 - val_loss: 0.0180\n",
      "Epoch 27/80\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 0.0284 - val_loss: 0.0177\n",
      "Epoch 28/80\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 0.0283 - val_loss: 0.0175\n",
      "Epoch 29/80\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 0.0282 - val_loss: 0.0173\n",
      "Epoch 30/80\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 0.0281 - val_loss: 0.0171\n",
      "Epoch 31/80\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 0.0281 - val_loss: 0.0170\n",
      "Epoch 32/80\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 0.0280 - val_loss: 0.0169\n",
      "Epoch 33/80\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 0.0280 - val_loss: 0.0169\n",
      "Epoch 34/80\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 0.0279 - val_loss: 0.0168\n",
      "Epoch 35/80\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 0.0278 - val_loss: 0.0167\n",
      "Epoch 36/80\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 0.0278 - val_loss: 0.0167\n",
      "Epoch 37/80\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 0.0277 - val_loss: 0.0166\n",
      "Epoch 38/80\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 0.0277 - val_loss: 0.0166\n",
      "Epoch 39/80\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 0.0276 - val_loss: 0.0162\n",
      "Epoch 40/80\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 0.0275 - val_loss: 0.0166\n",
      "Epoch 41/80\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 0.0275 - val_loss: 0.0166\n",
      "Epoch 42/80\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 0.0275 - val_loss: 0.0166\n",
      "Epoch 43/80\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 0.0274 - val_loss: 0.0162\n",
      "Epoch 44/80\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 0.0273 - val_loss: 0.0165\n",
      "Epoch 45/80\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 0.0272 - val_loss: 0.0165\n",
      "Epoch 46/80\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 0.0271 - val_loss: 0.0164\n",
      "Epoch 47/80\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 0.0270 - val_loss: 0.0164\n",
      "Epoch 48/80\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 0.0270 - val_loss: 0.0164\n",
      "Epoch 49/80\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 0.0268 - val_loss: 0.0164\n",
      "Epoch 50/80\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 0.0267 - val_loss: 0.0164\n",
      "Epoch 51/80\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 0.0266 - val_loss: 0.0164\n",
      "Epoch 52/80\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 0.0265 - val_loss: 0.0164\n",
      "Epoch 53/80\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 0.0263 - val_loss: 0.0164\n",
      "Epoch 54/80\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 0.0262 - val_loss: 0.0164\n",
      "Epoch 55/80\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 0.0261 - val_loss: 0.0165\n",
      "Epoch 56/80\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 0.0259 - val_loss: 0.0154\n",
      "Epoch 57/80\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 0.0259 - val_loss: 0.0165\n",
      "Epoch 58/80\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 0.0257 - val_loss: 0.0166\n",
      "Epoch 59/80\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 0.0255 - val_loss: 0.0167\n",
      "Epoch 60/80\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 0.0253 - val_loss: 0.0167\n",
      "Epoch 61/80\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 0.0251 - val_loss: 0.0168\n",
      "Epoch 62/80\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 0.0249 - val_loss: 0.0167\n",
      "Epoch 63/80\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 0.0248 - val_loss: 0.0167\n",
      "Epoch 64/80\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 0.0245 - val_loss: 0.0165\n",
      "Epoch 65/80\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 0.0244 - val_loss: 0.0165\n",
      "Epoch 66/80\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 0.0243 - val_loss: 0.0165\n",
      "Epoch 67/80\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 0.0240 - val_loss: 0.0164\n",
      "Epoch 68/80\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 0.0240 - val_loss: 0.0165\n",
      "Epoch 69/80\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 0.0238 - val_loss: 0.0165\n",
      "Epoch 70/80\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 0.0237 - val_loss: 0.0164\n",
      "Epoch 71/80\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 0.0236 - val_loss: 0.0165\n",
      "Epoch 72/80\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 0.0236 - val_loss: 0.0163\n",
      "Epoch 73/80\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 0.0235 - val_loss: 0.0163\n",
      "Epoch 74/80\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 0.0235 - val_loss: 0.0166\n",
      "Epoch 75/80\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 0.0234 - val_loss: 0.0165\n",
      "Epoch 76/80\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 0.0235 - val_loss: 0.0166\n",
      "Epoch 77/80\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 0.0234 - val_loss: 0.0167\n",
      "Epoch 78/80\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 0.0232 - val_loss: 0.0169\n",
      "Epoch 79/80\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 0.0232 - val_loss: 0.0169\n",
      "Epoch 80/80\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 0.0231 - val_loss: 0.0169\n",
      "Execution time:  24.69905686378479\n",
      "DNN:\n",
      "Mean Absolute Error: 0.0187\n",
      "Root Mean Square Error: 0.0328\n",
      "Mean Square Error: 0.0011\n",
      "\n",
      "Train RMSE: 0.033\n",
      "Train MSE: 0.001\n",
      "Train MAE: 0.019\n",
      "###########################\n",
      "\n",
      "MODEL:  DNN\n",
      "sequence:  6h\n",
      "units:  80\n",
      "dropout1:  0.11814836227952394\n",
      "optimizer: adam\n",
      "activationDense: sigmoid\n",
      "epochs: 90\n",
      "batchsize: 25\n",
      "validation_split: 0.2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_82\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_246 (Dense)            (None, 36, 80)            160       \n",
      "_________________________________________________________________\n",
      "dense_247 (Dense)            (None, 36, 16)            1296      \n",
      "_________________________________________________________________\n",
      "dropout_82 (Dropout)         (None, 36, 16)            0         \n",
      "_________________________________________________________________\n",
      "dense_248 (Dense)            (None, 36, 1)             17        \n",
      "=================================================================\n",
      "Total params: 1,473\n",
      "Trainable params: 1,473\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/90\n",
      "127/127 [==============================] - 1s 4ms/step - loss: 0.0422 - val_loss: 0.0180\n",
      "Epoch 2/90\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 0.0379 - val_loss: 0.0185\n",
      "Epoch 3/90\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 0.0376 - val_loss: 0.0178\n",
      "Epoch 4/90\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 0.0365 - val_loss: 0.0180\n",
      "Epoch 5/90\n",
      "127/127 [==============================] - 0s 2ms/step - loss: 0.0358 - val_loss: 0.0180\n",
      "Epoch 6/90\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 0.0352 - val_loss: 0.0183\n",
      "Epoch 7/90\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 0.0346 - val_loss: 0.0182\n",
      "Epoch 8/90\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 0.0341 - val_loss: 0.0179\n",
      "Epoch 9/90\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 0.0337 - val_loss: 0.0180\n",
      "Epoch 10/90\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 0.0332 - val_loss: 0.0178\n",
      "Epoch 11/90\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 0.0330 - val_loss: 0.0175\n",
      "Epoch 12/90\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 0.0327 - val_loss: 0.0176\n",
      "Epoch 13/90\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 0.0324 - val_loss: 0.0176\n",
      "Epoch 14/90\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 0.0320 - val_loss: 0.0175\n",
      "Epoch 15/90\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 0.0318 - val_loss: 0.0175\n",
      "Epoch 16/90\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 0.0316 - val_loss: 0.0175\n",
      "Epoch 17/90\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 0.0313 - val_loss: 0.0174\n",
      "Epoch 18/90\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 0.0311 - val_loss: 0.0175\n",
      "Epoch 19/90\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 0.0309 - val_loss: 0.0174\n",
      "Epoch 20/90\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 0.0307 - val_loss: 0.0173\n",
      "Epoch 21/90\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 0.0306 - val_loss: 0.0171\n",
      "Epoch 22/90\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 0.0305 - val_loss: 0.0171\n",
      "Epoch 23/90\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 0.0303 - val_loss: 0.0171\n",
      "Epoch 24/90\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 0.0301 - val_loss: 0.0170\n",
      "Epoch 25/90\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 0.0300 - val_loss: 0.0169\n",
      "Epoch 26/90\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 0.0299 - val_loss: 0.0168\n",
      "Epoch 27/90\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 0.0297 - val_loss: 0.0167\n",
      "Epoch 28/90\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 0.0295 - val_loss: 0.0166\n",
      "Epoch 29/90\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 0.0294 - val_loss: 0.0165\n",
      "Epoch 30/90\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 0.0292 - val_loss: 0.0164\n",
      "Epoch 31/90\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 0.0291 - val_loss: 0.0164\n",
      "Epoch 32/90\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 0.0288 - val_loss: 0.0162\n",
      "Epoch 33/90\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 0.0288 - val_loss: 0.0161\n",
      "Epoch 34/90\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 0.0286 - val_loss: 0.0159\n",
      "Epoch 35/90\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 0.0284 - val_loss: 0.0157\n",
      "Epoch 36/90\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 0.0282 - val_loss: 0.0156\n",
      "Epoch 37/90\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 0.0280 - val_loss: 0.0153\n",
      "Epoch 38/90\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 0.0278 - val_loss: 0.0152\n",
      "Epoch 39/90\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 0.0276 - val_loss: 0.0150\n",
      "Epoch 40/90\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 0.0273 - val_loss: 0.0151\n",
      "Epoch 41/90\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 0.0270 - val_loss: 0.0149\n",
      "Epoch 42/90\n",
      "127/127 [==============================] - 0s 2ms/step - loss: 0.0267 - val_loss: 0.0148\n",
      "Epoch 43/90\n",
      "127/127 [==============================] - 0s 2ms/step - loss: 0.0264 - val_loss: 0.0147\n",
      "Epoch 44/90\n",
      "127/127 [==============================] - 0s 2ms/step - loss: 0.0262 - val_loss: 0.0147\n",
      "Epoch 45/90\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 0.0260 - val_loss: 0.0147\n",
      "Epoch 46/90\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 0.0257 - val_loss: 0.0146\n",
      "Epoch 47/90\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 0.0254 - val_loss: 0.0145\n",
      "Epoch 48/90\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 0.0251 - val_loss: 0.0146\n",
      "Epoch 49/90\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 0.0247 - val_loss: 0.0144\n",
      "Epoch 50/90\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 0.0245 - val_loss: 0.0144\n",
      "Epoch 51/90\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 0.0242 - val_loss: 0.0144\n",
      "Epoch 52/90\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 0.0237 - val_loss: 0.0144\n",
      "Epoch 53/90\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 0.0235 - val_loss: 0.0143\n",
      "Epoch 54/90\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 0.0229 - val_loss: 0.0142\n",
      "Epoch 55/90\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 0.0227 - val_loss: 0.0141\n",
      "Epoch 56/90\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 0.0223 - val_loss: 0.0141\n",
      "Epoch 57/90\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 0.0219 - val_loss: 0.0141\n",
      "Epoch 58/90\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 0.0219 - val_loss: 0.0141\n",
      "Epoch 59/90\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 0.0214 - val_loss: 0.0142\n",
      "Epoch 60/90\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 0.0214 - val_loss: 0.0142\n",
      "Epoch 61/90\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 0.0210 - val_loss: 0.0143\n",
      "Epoch 62/90\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 0.0209 - val_loss: 0.0142\n",
      "Epoch 63/90\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 0.0206 - val_loss: 0.0144\n",
      "Epoch 64/90\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 0.0204 - val_loss: 0.0146\n",
      "Epoch 65/90\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 0.0201 - val_loss: 0.0151\n",
      "Epoch 66/90\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 0.0200 - val_loss: 0.0151\n",
      "Epoch 67/90\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 0.0198 - val_loss: 0.0158\n",
      "Epoch 68/90\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 0.0199 - val_loss: 0.0145\n",
      "Epoch 69/90\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 0.0197 - val_loss: 0.0146\n",
      "Epoch 70/90\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 0.0195 - val_loss: 0.0157\n",
      "Epoch 71/90\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 0.0196 - val_loss: 0.0157\n",
      "Epoch 72/90\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 0.0196 - val_loss: 0.0157\n",
      "Epoch 73/90\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "127/127 [==============================] - 0s 3ms/step - loss: 0.0195 - val_loss: 0.0155\n",
      "Epoch 74/90\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 0.0194 - val_loss: 0.0158\n",
      "Epoch 75/90\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 0.0195 - val_loss: 0.0156\n",
      "Epoch 76/90\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 0.0196 - val_loss: 0.0146\n",
      "Epoch 77/90\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 0.0193 - val_loss: 0.0153\n",
      "Epoch 78/90\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 0.0195 - val_loss: 0.0148\n",
      "Epoch 79/90\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 0.0192 - val_loss: 0.0149\n",
      "Epoch 80/90\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 0.0192 - val_loss: 0.0151\n",
      "Epoch 81/90\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 0.0193 - val_loss: 0.0157\n",
      "Epoch 82/90\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 0.0194 - val_loss: 0.0154\n",
      "Epoch 83/90\n",
      "127/127 [==============================] - ETA: 0s - loss: 0.020 - 0s 3ms/step - loss: 0.0193 - val_loss: 0.0151\n",
      "Epoch 84/90\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 0.0192 - val_loss: 0.0164\n",
      "Epoch 85/90\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 0.0193 - val_loss: 0.0164\n",
      "Epoch 86/90\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 0.0193 - val_loss: 0.0153\n",
      "Epoch 87/90\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 0.0192 - val_loss: 0.0153\n",
      "Epoch 88/90\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 0.0192 - val_loss: 0.0148\n",
      "Epoch 89/90\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 0.0191 - val_loss: 0.0165\n",
      "Epoch 90/90\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 0.0194 - val_loss: 0.0157\n",
      "Execution time:  32.04720616340637\n",
      "DNN:\n",
      "Mean Absolute Error: 0.0146\n",
      "Root Mean Square Error: 0.0283\n",
      "Mean Square Error: 0.0008\n",
      "\n",
      "Train RMSE: 0.028\n",
      "Train MSE: 0.001\n",
      "Train MAE: 0.015\n",
      "###########################\n",
      "\n",
      "MODEL:  DNN\n",
      "sequence:  6h\n",
      "units:  12\n",
      "dropout1:  0.48476373451509647\n",
      "optimizer: adam\n",
      "activationDense: sigmoid\n",
      "epochs: 52\n",
      "batchsize: 57\n",
      "validation_split: 0.2\n",
      "Model: \"sequential_83\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_249 (Dense)            (None, 36, 12)            24        \n",
      "_________________________________________________________________\n",
      "dense_250 (Dense)            (None, 36, 16)            208       \n",
      "_________________________________________________________________\n",
      "dropout_83 (Dropout)         (None, 36, 16)            0         \n",
      "_________________________________________________________________\n",
      "dense_251 (Dense)            (None, 36, 1)             17        \n",
      "=================================================================\n",
      "Total params: 249\n",
      "Trainable params: 249\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/52\n",
      "56/56 [==============================] - 0s 6ms/step - loss: 0.0646 - val_loss: 0.0628\n",
      "Epoch 2/52\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 0.0560 - val_loss: 0.0530\n",
      "Epoch 3/52\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 0.0502 - val_loss: 0.0431\n",
      "Epoch 4/52\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 0.0441 - val_loss: 0.0379\n",
      "Epoch 5/52\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 0.0406 - val_loss: 0.0344\n",
      "Epoch 6/52\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 0.0393 - val_loss: 0.0321\n",
      "Epoch 7/52\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 0.0377 - val_loss: 0.0262\n",
      "Epoch 8/52\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 0.0362 - val_loss: 0.0214\n",
      "Epoch 9/52\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 0.0359 - val_loss: 0.0246\n",
      "Epoch 10/52\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 0.0344 - val_loss: 0.0245\n",
      "Epoch 11/52\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 0.0337 - val_loss: 0.0244\n",
      "Epoch 12/52\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 0.0331 - val_loss: 0.0241\n",
      "Epoch 13/52\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 0.0327 - val_loss: 0.0239\n",
      "Epoch 14/52\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 0.0323 - val_loss: 0.0235\n",
      "Epoch 15/52\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 0.0318 - val_loss: 0.0231\n",
      "Epoch 16/52\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 0.0314 - val_loss: 0.0229\n",
      "Epoch 17/52\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 0.0310 - val_loss: 0.0223\n",
      "Epoch 18/52\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 0.0307 - val_loss: 0.0219\n",
      "Epoch 19/52\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 0.0303 - val_loss: 0.0213\n",
      "Epoch 20/52\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 0.0301 - val_loss: 0.0208\n",
      "Epoch 21/52\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 0.0299 - val_loss: 0.0204\n",
      "Epoch 22/52\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 0.0296 - val_loss: 0.0200\n",
      "Epoch 23/52\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 0.0293 - val_loss: 0.0196\n",
      "Epoch 24/52\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 0.0291 - val_loss: 0.0193\n",
      "Epoch 25/52\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 0.0289 - val_loss: 0.0189\n",
      "Epoch 26/52\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 0.0287 - val_loss: 0.0186\n",
      "Epoch 27/52\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 0.0285 - val_loss: 0.0183\n",
      "Epoch 28/52\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 0.0283 - val_loss: 0.0181\n",
      "Epoch 29/52\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 0.0281 - val_loss: 0.0177\n",
      "Epoch 30/52\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 0.0279 - val_loss: 0.0175\n",
      "Epoch 31/52\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 0.0278 - val_loss: 0.0173\n",
      "Epoch 32/52\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 0.0276 - val_loss: 0.0171\n",
      "Epoch 33/52\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 0.0275 - val_loss: 0.0170\n",
      "Epoch 34/52\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 0.0273 - val_loss: 0.0168\n",
      "Epoch 35/52\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 0.0272 - val_loss: 0.0167\n",
      "Epoch 36/52\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 0.0270 - val_loss: 0.0165\n",
      "Epoch 37/52\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 0.0269 - val_loss: 0.0164\n",
      "Epoch 38/52\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 0.0268 - val_loss: 0.0162\n",
      "Epoch 39/52\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 0.0266 - val_loss: 0.0156\n",
      "Epoch 40/52\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 0.0265 - val_loss: 0.0156\n",
      "Epoch 41/52\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 0.0264 - val_loss: 0.0155\n",
      "Epoch 42/52\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 0.0262 - val_loss: 0.0154\n",
      "Epoch 43/52\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 0.0261 - val_loss: 0.0153\n",
      "Epoch 44/52\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 0.0261 - val_loss: 0.0153\n",
      "Epoch 45/52\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 0.0260 - val_loss: 0.0152\n",
      "Epoch 46/52\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 0.0259 - val_loss: 0.0151\n",
      "Epoch 47/52\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 0.0258 - val_loss: 0.0151\n",
      "Epoch 48/52\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 0.0258 - val_loss: 0.0150\n",
      "Epoch 49/52\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 0.0257 - val_loss: 0.0150\n",
      "Epoch 50/52\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 0.0256 - val_loss: 0.0149\n",
      "Epoch 51/52\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 0.0256 - val_loss: 0.0149\n",
      "Epoch 52/52\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 0.0255 - val_loss: 0.0148\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Execution time:  8.913937091827393\n",
      "DNN:\n",
      "Mean Absolute Error: 0.0198\n",
      "Root Mean Square Error: 0.0366\n",
      "Mean Square Error: 0.0013\n",
      "\n",
      "Train RMSE: 0.037\n",
      "Train MSE: 0.001\n",
      "Train MAE: 0.020\n",
      "###########################\n",
      "\n",
      "MODEL:  DNN\n",
      "sequence:  6h\n",
      "units:  87\n",
      "dropout1:  0.40519643149940265\n",
      "optimizer: adadelta\n",
      "activationDense: tanh\n",
      "epochs: 80\n",
      "batchsize: 31\n",
      "validation_split: 0.1\n",
      "Model: \"sequential_84\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_252 (Dense)            (None, 36, 87)            174       \n",
      "_________________________________________________________________\n",
      "dense_253 (Dense)            (None, 36, 16)            1408      \n",
      "_________________________________________________________________\n",
      "dropout_84 (Dropout)         (None, 36, 16)            0         \n",
      "_________________________________________________________________\n",
      "dense_254 (Dense)            (None, 36, 1)             17        \n",
      "=================================================================\n",
      "Total params: 1,599\n",
      "Trainable params: 1,599\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/80\n",
      "115/115 [==============================] - 0s 4ms/step - loss: 0.3305 - val_loss: 0.2991\n",
      "Epoch 2/80\n",
      "115/115 [==============================] - 0s 3ms/step - loss: 0.3272 - val_loss: 0.2957\n",
      "Epoch 3/80\n",
      "115/115 [==============================] - 0s 3ms/step - loss: 0.3234 - val_loss: 0.2919\n",
      "Epoch 4/80\n",
      "115/115 [==============================] - 0s 3ms/step - loss: 0.3189 - val_loss: 0.2879\n",
      "Epoch 5/80\n",
      "115/115 [==============================] - 0s 3ms/step - loss: 0.3150 - val_loss: 0.2835\n",
      "Epoch 6/80\n",
      "115/115 [==============================] - 0s 3ms/step - loss: 0.3103 - val_loss: 0.2790\n",
      "Epoch 7/80\n",
      "115/115 [==============================] - 0s 3ms/step - loss: 0.3054 - val_loss: 0.2742\n",
      "Epoch 8/80\n",
      "115/115 [==============================] - 0s 3ms/step - loss: 0.3004 - val_loss: 0.2691\n",
      "Epoch 9/80\n",
      "115/115 [==============================] - 0s 3ms/step - loss: 0.2947 - val_loss: 0.2638\n",
      "Epoch 10/80\n",
      "115/115 [==============================] - 0s 3ms/step - loss: 0.2891 - val_loss: 0.2583\n",
      "Epoch 11/80\n",
      "115/115 [==============================] - 0s 3ms/step - loss: 0.2837 - val_loss: 0.2526\n",
      "Epoch 12/80\n",
      "115/115 [==============================] - 0s 3ms/step - loss: 0.2777 - val_loss: 0.2467\n",
      "Epoch 13/80\n",
      "115/115 [==============================] - 0s 3ms/step - loss: 0.2715 - val_loss: 0.2406\n",
      "Epoch 14/80\n",
      "115/115 [==============================] - 0s 3ms/step - loss: 0.2647 - val_loss: 0.2344\n",
      "Epoch 15/80\n",
      "115/115 [==============================] - 0s 3ms/step - loss: 0.2586 - val_loss: 0.2283\n",
      "Epoch 16/80\n",
      "115/115 [==============================] - 0s 3ms/step - loss: 0.2521 - val_loss: 0.2221\n",
      "Epoch 17/80\n",
      "115/115 [==============================] - 0s 3ms/step - loss: 0.2455 - val_loss: 0.2158\n",
      "Epoch 18/80\n",
      "115/115 [==============================] - 0s 3ms/step - loss: 0.2390 - val_loss: 0.2092\n",
      "Epoch 19/80\n",
      "115/115 [==============================] - 0s 3ms/step - loss: 0.2321 - val_loss: 0.2025\n",
      "Epoch 20/80\n",
      "115/115 [==============================] - 0s 3ms/step - loss: 0.2249 - val_loss: 0.1956\n",
      "Epoch 21/80\n",
      "115/115 [==============================] - 0s 3ms/step - loss: 0.2180 - val_loss: 0.1895\n",
      "Epoch 22/80\n",
      "115/115 [==============================] - 0s 3ms/step - loss: 0.2116 - val_loss: 0.1833\n",
      "Epoch 23/80\n",
      "115/115 [==============================] - 0s 3ms/step - loss: 0.2051 - val_loss: 0.1770\n",
      "Epoch 24/80\n",
      "115/115 [==============================] - 0s 3ms/step - loss: 0.1983 - val_loss: 0.1705\n",
      "Epoch 25/80\n",
      "115/115 [==============================] - 0s 3ms/step - loss: 0.1916 - val_loss: 0.1640\n",
      "Epoch 26/80\n",
      "115/115 [==============================] - 0s 3ms/step - loss: 0.1850 - val_loss: 0.1573\n",
      "Epoch 27/80\n",
      "115/115 [==============================] - 0s 3ms/step - loss: 0.1782 - val_loss: 0.1505\n",
      "Epoch 28/80\n",
      "115/115 [==============================] - 0s 3ms/step - loss: 0.1712 - val_loss: 0.1436\n",
      "Epoch 29/80\n",
      "115/115 [==============================] - 0s 3ms/step - loss: 0.1639 - val_loss: 0.1368\n",
      "Epoch 30/80\n",
      "115/115 [==============================] - 0s 3ms/step - loss: 0.1572 - val_loss: 0.1304\n",
      "Epoch 31/80\n",
      "115/115 [==============================] - 0s 3ms/step - loss: 0.1508 - val_loss: 0.1240\n",
      "Epoch 32/80\n",
      "115/115 [==============================] - 0s 3ms/step - loss: 0.1451 - val_loss: 0.1177\n",
      "Epoch 33/80\n",
      "115/115 [==============================] - 0s 3ms/step - loss: 0.1401 - val_loss: 0.1115\n",
      "Epoch 34/80\n",
      "115/115 [==============================] - 0s 3ms/step - loss: 0.1345 - val_loss: 0.1055\n",
      "Epoch 35/80\n",
      "115/115 [==============================] - 0s 3ms/step - loss: 0.1306 - val_loss: 0.0997\n",
      "Epoch 36/80\n",
      "115/115 [==============================] - 0s 3ms/step - loss: 0.1252 - val_loss: 0.0942\n",
      "Epoch 37/80\n",
      "115/115 [==============================] - 0s 3ms/step - loss: 0.1216 - val_loss: 0.0888\n",
      "Epoch 38/80\n",
      "115/115 [==============================] - 0s 3ms/step - loss: 0.1175 - val_loss: 0.0839\n",
      "Epoch 39/80\n",
      "115/115 [==============================] - 0s 3ms/step - loss: 0.1147 - val_loss: 0.0791\n",
      "Epoch 40/80\n",
      "115/115 [==============================] - 0s 3ms/step - loss: 0.1119 - val_loss: 0.0746\n",
      "Epoch 41/80\n",
      "115/115 [==============================] - 0s 3ms/step - loss: 0.1095 - val_loss: 0.0703\n",
      "Epoch 42/80\n",
      "115/115 [==============================] - 0s 3ms/step - loss: 0.1071 - val_loss: 0.0663\n",
      "Epoch 43/80\n",
      "115/115 [==============================] - 0s 3ms/step - loss: 0.1048 - val_loss: 0.0625\n",
      "Epoch 44/80\n",
      "115/115 [==============================] - 0s 3ms/step - loss: 0.1033 - val_loss: 0.0590\n",
      "Epoch 45/80\n",
      "115/115 [==============================] - 0s 3ms/step - loss: 0.1018 - val_loss: 0.0558\n",
      "Epoch 46/80\n",
      "115/115 [==============================] - 0s 3ms/step - loss: 0.1010 - val_loss: 0.0528\n",
      "Epoch 47/80\n",
      "115/115 [==============================] - 0s 3ms/step - loss: 0.0996 - val_loss: 0.0501\n",
      "Epoch 48/80\n",
      "115/115 [==============================] - 0s 3ms/step - loss: 0.0988 - val_loss: 0.0475\n",
      "Epoch 49/80\n",
      "115/115 [==============================] - 0s 3ms/step - loss: 0.0975 - val_loss: 0.0451\n",
      "Epoch 50/80\n",
      "115/115 [==============================] - 0s 3ms/step - loss: 0.0973 - val_loss: 0.0429\n",
      "Epoch 51/80\n",
      "115/115 [==============================] - 0s 3ms/step - loss: 0.0964 - val_loss: 0.0409\n",
      "Epoch 52/80\n",
      "115/115 [==============================] - 0s 3ms/step - loss: 0.0961 - val_loss: 0.0390\n",
      "Epoch 53/80\n",
      "115/115 [==============================] - 0s 3ms/step - loss: 0.0950 - val_loss: 0.0372\n",
      "Epoch 54/80\n",
      "115/115 [==============================] - 0s 3ms/step - loss: 0.0946 - val_loss: 0.0356\n",
      "Epoch 55/80\n",
      "115/115 [==============================] - 0s 3ms/step - loss: 0.0944 - val_loss: 0.0341\n",
      "Epoch 56/80\n",
      "115/115 [==============================] - 0s 3ms/step - loss: 0.0942 - val_loss: 0.0327\n",
      "Epoch 57/80\n",
      "115/115 [==============================] - 0s 3ms/step - loss: 0.0942 - val_loss: 0.0313\n",
      "Epoch 58/80\n",
      "115/115 [==============================] - 0s 3ms/step - loss: 0.0939 - val_loss: 0.0301\n",
      "Epoch 59/80\n",
      "115/115 [==============================] - 0s 3ms/step - loss: 0.0933 - val_loss: 0.0289\n",
      "Epoch 60/80\n",
      "115/115 [==============================] - 0s 3ms/step - loss: 0.0933 - val_loss: 0.0277\n",
      "Epoch 61/80\n",
      "115/115 [==============================] - 0s 3ms/step - loss: 0.0930 - val_loss: 0.0267\n",
      "Epoch 62/80\n",
      "115/115 [==============================] - 0s 3ms/step - loss: 0.0927 - val_loss: 0.0258\n",
      "Epoch 63/80\n",
      "115/115 [==============================] - 0s 3ms/step - loss: 0.0923 - val_loss: 0.0248\n",
      "Epoch 64/80\n",
      "115/115 [==============================] - 0s 3ms/step - loss: 0.0921 - val_loss: 0.0239\n",
      "Epoch 65/80\n",
      "115/115 [==============================] - 0s 3ms/step - loss: 0.0918 - val_loss: 0.0230\n",
      "Epoch 66/80\n",
      "115/115 [==============================] - 0s 3ms/step - loss: 0.0918 - val_loss: 0.0222\n",
      "Epoch 67/80\n",
      "115/115 [==============================] - 0s 3ms/step - loss: 0.0917 - val_loss: 0.0215\n",
      "Epoch 68/80\n",
      "115/115 [==============================] - 0s 3ms/step - loss: 0.0914 - val_loss: 0.0208\n",
      "Epoch 69/80\n",
      "115/115 [==============================] - 0s 3ms/step - loss: 0.0912 - val_loss: 0.0201\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 70/80\n",
      "115/115 [==============================] - 0s 3ms/step - loss: 0.0909 - val_loss: 0.0195\n",
      "Epoch 71/80\n",
      "115/115 [==============================] - 0s 3ms/step - loss: 0.0909 - val_loss: 0.0189\n",
      "Epoch 72/80\n",
      "115/115 [==============================] - 0s 3ms/step - loss: 0.0907 - val_loss: 0.0184\n",
      "Epoch 73/80\n",
      "115/115 [==============================] - 0s 3ms/step - loss: 0.0907 - val_loss: 0.0178\n",
      "Epoch 74/80\n",
      "115/115 [==============================] - 0s 3ms/step - loss: 0.0907 - val_loss: 0.0173\n",
      "Epoch 75/80\n",
      "115/115 [==============================] - 0s 3ms/step - loss: 0.0904 - val_loss: 0.0168\n",
      "Epoch 76/80\n",
      "115/115 [==============================] - 0s 3ms/step - loss: 0.0905 - val_loss: 0.0164\n",
      "Epoch 77/80\n",
      "115/115 [==============================] - 0s 3ms/step - loss: 0.0903 - val_loss: 0.0160\n",
      "Epoch 78/80\n",
      "115/115 [==============================] - 0s 3ms/step - loss: 0.0904 - val_loss: 0.0156\n",
      "Epoch 79/80\n",
      "115/115 [==============================] - 0s 3ms/step - loss: 0.0900 - val_loss: 0.0153\n",
      "Epoch 80/80\n",
      "115/115 [==============================] - 0s 3ms/step - loss: 0.0899 - val_loss: 0.0149\n",
      "Execution time:  25.81791377067566\n",
      "DNN:\n",
      "Mean Absolute Error: 0.0310\n",
      "Root Mean Square Error: 0.0374\n",
      "Mean Square Error: 0.0014\n",
      "\n",
      "Train RMSE: 0.037\n",
      "Train MSE: 0.001\n",
      "Train MAE: 0.031\n",
      "###########################\n",
      "\n",
      "MODEL:  DNN\n",
      "sequence:  6h\n",
      "units:  80\n",
      "dropout1:  0.11814836227952394\n",
      "optimizer: adadelta\n",
      "activationDense: tanh\n",
      "epochs: 90\n",
      "batchsize: 25\n",
      "validation_split: 0.1\n",
      "Model: \"sequential_85\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_255 (Dense)            (None, 36, 80)            160       \n",
      "_________________________________________________________________\n",
      "dense_256 (Dense)            (None, 36, 16)            1296      \n",
      "_________________________________________________________________\n",
      "dropout_85 (Dropout)         (None, 36, 16)            0         \n",
      "_________________________________________________________________\n",
      "dense_257 (Dense)            (None, 36, 1)             17        \n",
      "=================================================================\n",
      "Total params: 1,473\n",
      "Trainable params: 1,473\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/90\n",
      "143/143 [==============================] - 1s 4ms/step - loss: 0.3511 - val_loss: 0.3186\n",
      "Epoch 2/90\n",
      "143/143 [==============================] - 0s 3ms/step - loss: 0.3489 - val_loss: 0.3163\n",
      "Epoch 3/90\n",
      "143/143 [==============================] - 0s 3ms/step - loss: 0.3464 - val_loss: 0.3138\n",
      "Epoch 4/90\n",
      "143/143 [==============================] - 0s 3ms/step - loss: 0.3435 - val_loss: 0.3110\n",
      "Epoch 5/90\n",
      "143/143 [==============================] - 0s 3ms/step - loss: 0.3405 - val_loss: 0.3080\n",
      "Epoch 6/90\n",
      "143/143 [==============================] - 0s 3ms/step - loss: 0.3373 - val_loss: 0.3047\n",
      "Epoch 7/90\n",
      "143/143 [==============================] - 0s 3ms/step - loss: 0.3339 - val_loss: 0.3013\n",
      "Epoch 8/90\n",
      "143/143 [==============================] - 0s 3ms/step - loss: 0.3303 - val_loss: 0.2977\n",
      "Epoch 9/90\n",
      "143/143 [==============================] - 0s 3ms/step - loss: 0.3263 - val_loss: 0.2940\n",
      "Epoch 10/90\n",
      "143/143 [==============================] - 0s 3ms/step - loss: 0.3225 - val_loss: 0.2903\n",
      "Epoch 11/90\n",
      "143/143 [==============================] - 0s 3ms/step - loss: 0.3186 - val_loss: 0.2865\n",
      "Epoch 12/90\n",
      "143/143 [==============================] - 0s 3ms/step - loss: 0.3146 - val_loss: 0.2826\n",
      "Epoch 13/90\n",
      "143/143 [==============================] - 0s 3ms/step - loss: 0.3104 - val_loss: 0.2785\n",
      "Epoch 14/90\n",
      "143/143 [==============================] - 0s 3ms/step - loss: 0.3061 - val_loss: 0.2742\n",
      "Epoch 15/90\n",
      "143/143 [==============================] - 0s 3ms/step - loss: 0.3016 - val_loss: 0.2698\n",
      "Epoch 16/90\n",
      "143/143 [==============================] - 0s 3ms/step - loss: 0.2969 - val_loss: 0.2652\n",
      "Epoch 17/90\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.2921 - val_loss: 0.2605\n",
      "Epoch 18/90\n",
      "143/143 [==============================] - 0s 3ms/step - loss: 0.2871 - val_loss: 0.2556\n",
      "Epoch 19/90\n",
      "143/143 [==============================] - 0s 3ms/step - loss: 0.2819 - val_loss: 0.2506\n",
      "Epoch 20/90\n",
      "143/143 [==============================] - 0s 3ms/step - loss: 0.2767 - val_loss: 0.2454\n",
      "Epoch 21/90\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.2711 - val_loss: 0.2400\n",
      "Epoch 22/90\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.2655 - val_loss: 0.2345\n",
      "Epoch 23/90\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.2595 - val_loss: 0.2287\n",
      "Epoch 24/90\n",
      "143/143 [==============================] - 0s 3ms/step - loss: 0.2537 - val_loss: 0.2228\n",
      "Epoch 25/90\n",
      "143/143 [==============================] - 0s 3ms/step - loss: 0.2474 - val_loss: 0.2166\n",
      "Epoch 26/90\n",
      "143/143 [==============================] - 0s 3ms/step - loss: 0.2408 - val_loss: 0.2103\n",
      "Epoch 27/90\n",
      "143/143 [==============================] - 0s 3ms/step - loss: 0.2343 - val_loss: 0.2037\n",
      "Epoch 28/90\n",
      "143/143 [==============================] - 0s 3ms/step - loss: 0.2272 - val_loss: 0.1969\n",
      "Epoch 29/90\n",
      "143/143 [==============================] - 0s 3ms/step - loss: 0.2203 - val_loss: 0.1900\n",
      "Epoch 30/90\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.2129 - val_loss: 0.1828\n",
      "Epoch 31/90\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.2053 - val_loss: 0.1754\n",
      "Epoch 32/90\n",
      "143/143 [==============================] - 0s 3ms/step - loss: 0.1975 - val_loss: 0.1678\n",
      "Epoch 33/90\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.1895 - val_loss: 0.1598\n",
      "Epoch 34/90\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.1812 - val_loss: 0.1516\n",
      "Epoch 35/90\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.1726 - val_loss: 0.1431\n",
      "Epoch 36/90\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.1638 - val_loss: 0.1344\n",
      "Epoch 37/90\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.1547 - val_loss: 0.1253\n",
      "Epoch 38/90\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.1450 - val_loss: 0.1160\n",
      "Epoch 39/90\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.1354 - val_loss: 0.1063\n",
      "Epoch 40/90\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.1253 - val_loss: 0.0963\n",
      "Epoch 41/90\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.1149 - val_loss: 0.0860\n",
      "Epoch 42/90\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.1043 - val_loss: 0.0755\n",
      "Epoch 43/90\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.0936 - val_loss: 0.0649\n",
      "Epoch 44/90\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.0831 - val_loss: 0.0540\n",
      "Epoch 45/90\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.0723 - val_loss: 0.0432\n",
      "Epoch 46/90\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.0624 - val_loss: 0.0333\n",
      "Epoch 47/90\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.0564 - val_loss: 0.0274\n",
      "Epoch 48/90\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.0541 - val_loss: 0.0238\n",
      "Epoch 49/90\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.0531 - val_loss: 0.0214\n",
      "Epoch 50/90\n",
      "143/143 [==============================] - 0s 3ms/step - loss: 0.0526 - val_loss: 0.0197\n",
      "Epoch 51/90\n",
      "143/143 [==============================] - 0s 3ms/step - loss: 0.0522 - val_loss: 0.0185\n",
      "Epoch 52/90\n",
      "143/143 [==============================] - 0s 3ms/step - loss: 0.0519 - val_loss: 0.0175\n",
      "Epoch 53/90\n",
      "143/143 [==============================] - 0s 3ms/step - loss: 0.0517 - val_loss: 0.0168\n",
      "Epoch 54/90\n",
      "143/143 [==============================] - 0s 3ms/step - loss: 0.0516 - val_loss: 0.0161\n",
      "Epoch 55/90\n",
      "143/143 [==============================] - 0s 3ms/step - loss: 0.0513 - val_loss: 0.0155\n",
      "Epoch 56/90\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.0512 - val_loss: 0.0149\n",
      "Epoch 57/90\n",
      "143/143 [==============================] - 0s 3ms/step - loss: 0.0513 - val_loss: 0.0144\n",
      "Epoch 58/90\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.0512 - val_loss: 0.0139\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 59/90\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.0509 - val_loss: 0.0134\n",
      "Epoch 60/90\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.0510 - val_loss: 0.0129\n",
      "Epoch 61/90\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.0510 - val_loss: 0.0125\n",
      "Epoch 62/90\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.0508 - val_loss: 0.0121\n",
      "Epoch 63/90\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.0509 - val_loss: 0.0117\n",
      "Epoch 64/90\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.0506 - val_loss: 0.0113\n",
      "Epoch 65/90\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.0507 - val_loss: 0.0109\n",
      "Epoch 66/90\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.0505 - val_loss: 0.0106\n",
      "Epoch 67/90\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.0505 - val_loss: 0.0102\n",
      "Epoch 68/90\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.0508 - val_loss: 0.0099\n",
      "Epoch 69/90\n",
      "143/143 [==============================] - 0s 3ms/step - loss: 0.0504 - val_loss: 0.0096\n",
      "Epoch 70/90\n",
      "143/143 [==============================] - 0s 3ms/step - loss: 0.0505 - val_loss: 0.0093\n",
      "Epoch 71/90\n",
      "143/143 [==============================] - 0s 3ms/step - loss: 0.0503 - val_loss: 0.0090\n",
      "Epoch 72/90\n",
      "143/143 [==============================] - 0s 3ms/step - loss: 0.0504 - val_loss: 0.0088\n",
      "Epoch 73/90\n",
      "143/143 [==============================] - 0s 3ms/step - loss: 0.0502 - val_loss: 0.0085\n",
      "Epoch 74/90\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.0499 - val_loss: 0.0083\n",
      "Epoch 75/90\n",
      "143/143 [==============================] - 0s 3ms/step - loss: 0.0501 - val_loss: 0.0081\n",
      "Epoch 76/90\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.0501 - val_loss: 0.0079\n",
      "Epoch 77/90\n",
      "143/143 [==============================] - 0s 3ms/step - loss: 0.0503 - val_loss: 0.0077\n",
      "Epoch 78/90\n",
      "143/143 [==============================] - 0s 3ms/step - loss: 0.0501 - val_loss: 0.0075\n",
      "Epoch 79/90\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.0499 - val_loss: 0.0073\n",
      "Epoch 80/90\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.0499 - val_loss: 0.0072\n",
      "Epoch 81/90\n",
      "143/143 [==============================] - 0s 3ms/step - loss: 0.0499 - val_loss: 0.0070\n",
      "Epoch 82/90\n",
      "143/143 [==============================] - 0s 3ms/step - loss: 0.0499 - val_loss: 0.0069\n",
      "Epoch 83/90\n",
      "143/143 [==============================] - 0s 3ms/step - loss: 0.0502 - val_loss: 0.0067\n",
      "Epoch 84/90\n",
      "143/143 [==============================] - 0s 3ms/step - loss: 0.0500 - val_loss: 0.0066\n",
      "Epoch 85/90\n",
      "143/143 [==============================] - 0s 3ms/step - loss: 0.0499 - val_loss: 0.0064\n",
      "Epoch 86/90\n",
      "143/143 [==============================] - 0s 3ms/step - loss: 0.0500 - val_loss: 0.0063\n",
      "Epoch 87/90\n",
      "143/143 [==============================] - 0s 3ms/step - loss: 0.0497 - val_loss: 0.0062\n",
      "Epoch 88/90\n",
      "143/143 [==============================] - 0s 3ms/step - loss: 0.0501 - val_loss: 0.0061\n",
      "Epoch 89/90\n",
      "143/143 [==============================] - 0s 3ms/step - loss: 0.0500 - val_loss: 0.0060\n",
      "Epoch 90/90\n",
      "143/143 [==============================] - 0s 3ms/step - loss: 0.0498 - val_loss: 0.0058\n",
      "Execution time:  33.890835762023926\n",
      "DNN:\n",
      "Mean Absolute Error: 0.0229\n",
      "Root Mean Square Error: 0.0328\n",
      "Mean Square Error: 0.0011\n",
      "\n",
      "Train RMSE: 0.033\n",
      "Train MSE: 0.001\n",
      "Train MAE: 0.023\n",
      "###########################\n",
      "\n",
      "MODEL:  DNN\n",
      "sequence:  6h\n",
      "units:  12\n",
      "dropout1:  0.48476373451509647\n",
      "optimizer: adadelta\n",
      "activationDense: tanh\n",
      "epochs: 52\n",
      "batchsize: 57\n",
      "validation_split: 0.1\n",
      "Model: \"sequential_86\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_258 (Dense)            (None, 36, 12)            24        \n",
      "_________________________________________________________________\n",
      "dense_259 (Dense)            (None, 36, 16)            208       \n",
      "_________________________________________________________________\n",
      "dropout_86 (Dropout)         (None, 36, 16)            0         \n",
      "_________________________________________________________________\n",
      "dense_260 (Dense)            (None, 36, 1)             17        \n",
      "=================================================================\n",
      "Total params: 249\n",
      "Trainable params: 249\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/52\n",
      " 1/63 [..............................] - ETA: 0s - loss: 0.2465WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0000s vs `on_train_batch_end` time: 0.0131s). Check your callbacks.\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.2205 - val_loss: 0.1973\n",
      "Epoch 2/52\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.2202 - val_loss: 0.1967\n",
      "Epoch 3/52\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.2191 - val_loss: 0.1960\n",
      "Epoch 4/52\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.2184 - val_loss: 0.1952\n",
      "Epoch 5/52\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.2178 - val_loss: 0.1945\n",
      "Epoch 6/52\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.2173 - val_loss: 0.1937\n",
      "Epoch 7/52\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.2171 - val_loss: 0.1929\n",
      "Epoch 8/52\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.2157 - val_loss: 0.1920\n",
      "Epoch 9/52\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.2150 - val_loss: 0.1911\n",
      "Epoch 10/52\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.2140 - val_loss: 0.1902\n",
      "Epoch 11/52\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.2138 - val_loss: 0.1893\n",
      "Epoch 12/52\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.2122 - val_loss: 0.1884\n",
      "Epoch 13/52\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.2119 - val_loss: 0.1874\n",
      "Epoch 14/52\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.2108 - val_loss: 0.1864\n",
      "Epoch 15/52\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.2100 - val_loss: 0.1854\n",
      "Epoch 16/52\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.2093 - val_loss: 0.1844\n",
      "Epoch 17/52\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.2079 - val_loss: 0.1833\n",
      "Epoch 18/52\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.2070 - val_loss: 0.1822\n",
      "Epoch 19/52\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.2058 - val_loss: 0.1811\n",
      "Epoch 20/52\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.2051 - val_loss: 0.1800\n",
      "Epoch 21/52\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.2036 - val_loss: 0.1789\n",
      "Epoch 22/52\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.2034 - val_loss: 0.1777\n",
      "Epoch 23/52\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.2020 - val_loss: 0.1765\n",
      "Epoch 24/52\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.2005 - val_loss: 0.1754\n",
      "Epoch 25/52\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.2002 - val_loss: 0.1742\n",
      "Epoch 26/52\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.1986 - val_loss: 0.1730\n",
      "Epoch 27/52\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.1977 - val_loss: 0.1718\n",
      "Epoch 28/52\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.1968 - val_loss: 0.1705\n",
      "Epoch 29/52\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.1964 - val_loss: 0.1693\n",
      "Epoch 30/52\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.1952 - val_loss: 0.1680\n",
      "Epoch 31/52\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.1936 - val_loss: 0.1668\n",
      "Epoch 32/52\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.1929 - val_loss: 0.1655\n",
      "Epoch 33/52\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.1916 - val_loss: 0.1643\n",
      "Epoch 34/52\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.1908 - val_loss: 0.1630\n",
      "Epoch 35/52\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.1900 - val_loss: 0.1617\n",
      "Epoch 36/52\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63/63 [==============================] - 0s 2ms/step - loss: 0.1887 - val_loss: 0.1604\n",
      "Epoch 37/52\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.1881 - val_loss: 0.1591\n",
      "Epoch 38/52\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.1862 - val_loss: 0.1578\n",
      "Epoch 39/52\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.1856 - val_loss: 0.1565\n",
      "Epoch 40/52\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.1847 - val_loss: 0.1552\n",
      "Epoch 41/52\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.1838 - val_loss: 0.1538\n",
      "Epoch 42/52\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.1823 - val_loss: 0.1525\n",
      "Epoch 43/52\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.1820 - val_loss: 0.1512\n",
      "Epoch 44/52\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.1811 - val_loss: 0.1498\n",
      "Epoch 45/52\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.1797 - val_loss: 0.1485\n",
      "Epoch 46/52\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.1785 - val_loss: 0.1471\n",
      "Epoch 47/52\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.1779 - val_loss: 0.1457\n",
      "Epoch 48/52\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.1775 - val_loss: 0.1444\n",
      "Epoch 49/52\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.1762 - val_loss: 0.1430\n",
      "Epoch 50/52\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.1753 - val_loss: 0.1416\n",
      "Epoch 51/52\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.1735 - val_loss: 0.1401\n",
      "Epoch 52/52\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.1726 - val_loss: 0.1385\n",
      "Execution time:  9.555951118469238\n",
      "DNN:\n",
      "Mean Absolute Error: 0.1553\n",
      "Root Mean Square Error: 0.1567\n",
      "Mean Square Error: 0.0246\n",
      "\n",
      "Train RMSE: 0.157\n",
      "Train MSE: 0.025\n",
      "Train MAE: 0.155\n",
      "###########################\n",
      "\n",
      "MODEL:  DNN\n",
      "sequence:  6h\n",
      "units:  87\n",
      "dropout1:  0.40519643149940265\n",
      "optimizer: adadelta\n",
      "activationDense: tanh\n",
      "epochs: 80\n",
      "batchsize: 31\n",
      "validation_split: 0.2\n",
      "Model: \"sequential_87\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_261 (Dense)            (None, 36, 87)            174       \n",
      "_________________________________________________________________\n",
      "dense_262 (Dense)            (None, 36, 16)            1408      \n",
      "_________________________________________________________________\n",
      "dropout_87 (Dropout)         (None, 36, 16)            0         \n",
      "_________________________________________________________________\n",
      "dense_263 (Dense)            (None, 36, 1)             17        \n",
      "=================================================================\n",
      "Total params: 1,599\n",
      "Trainable params: 1,599\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/80\n",
      "103/103 [==============================] - 0s 5ms/step - loss: 0.3936 - val_loss: 0.3709\n",
      "Epoch 2/80\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 0.3911 - val_loss: 0.3684\n",
      "Epoch 3/80\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 0.3884 - val_loss: 0.3657\n",
      "Epoch 4/80\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 0.3857 - val_loss: 0.3628\n",
      "Epoch 5/80\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 0.3826 - val_loss: 0.3597\n",
      "Epoch 6/80\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 0.3794 - val_loss: 0.3565\n",
      "Epoch 7/80\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 0.3758 - val_loss: 0.3530\n",
      "Epoch 8/80\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 0.3723 - val_loss: 0.3495\n",
      "Epoch 9/80\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 0.3685 - val_loss: 0.3458\n",
      "Epoch 10/80\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 0.3649 - val_loss: 0.3423\n",
      "Epoch 11/80\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 0.3611 - val_loss: 0.3388\n",
      "Epoch 12/80\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 0.3576 - val_loss: 0.3351\n",
      "Epoch 13/80\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 0.3538 - val_loss: 0.3317\n",
      "Epoch 14/80\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 0.3501 - val_loss: 0.3281\n",
      "Epoch 15/80\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 0.3465 - val_loss: 0.3245\n",
      "Epoch 16/80\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 0.3429 - val_loss: 0.3208\n",
      "Epoch 17/80\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 0.3392 - val_loss: 0.3171\n",
      "Epoch 18/80\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 0.3355 - val_loss: 0.3132\n",
      "Epoch 19/80\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 0.3314 - val_loss: 0.3093\n",
      "Epoch 20/80\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 0.3273 - val_loss: 0.3053\n",
      "Epoch 21/80\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 0.3231 - val_loss: 0.3013\n",
      "Epoch 22/80\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 0.3191 - val_loss: 0.2971\n",
      "Epoch 23/80\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 0.3144 - val_loss: 0.2929\n",
      "Epoch 24/80\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 0.3102 - val_loss: 0.2885\n",
      "Epoch 25/80\n",
      "103/103 [==============================] - ETA: 0s - loss: 0.310 - 0s 3ms/step - loss: 0.3057 - val_loss: 0.2841\n",
      "Epoch 26/80\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 0.3014 - val_loss: 0.2796\n",
      "Epoch 27/80\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 0.2964 - val_loss: 0.2739\n",
      "Epoch 28/80\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 0.2901 - val_loss: 0.2678\n",
      "Epoch 29/80\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 0.2841 - val_loss: 0.2616\n",
      "Epoch 30/80\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 0.2774 - val_loss: 0.2553\n",
      "Epoch 31/80\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 0.2712 - val_loss: 0.2491\n",
      "Epoch 32/80\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 0.2649 - val_loss: 0.2428\n",
      "Epoch 33/80\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 0.2582 - val_loss: 0.2365\n",
      "Epoch 34/80\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 0.2516 - val_loss: 0.2300\n",
      "Epoch 35/80\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 0.2448 - val_loss: 0.2234\n",
      "Epoch 36/80\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 0.2381 - val_loss: 0.2166\n",
      "Epoch 37/80\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 0.2318 - val_loss: 0.2098\n",
      "Epoch 38/80\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 0.2242 - val_loss: 0.2027\n",
      "Epoch 39/80\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 0.2176 - val_loss: 0.1956\n",
      "Epoch 40/80\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 0.2102 - val_loss: 0.1882\n",
      "Epoch 41/80\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 0.2026 - val_loss: 0.1807\n",
      "Epoch 42/80\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 0.1951 - val_loss: 0.1731\n",
      "Epoch 43/80\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 0.1873 - val_loss: 0.1653\n",
      "Epoch 44/80\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 0.1796 - val_loss: 0.1573\n",
      "Epoch 45/80\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 0.1711 - val_loss: 0.1491\n",
      "Epoch 46/80\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 0.1633 - val_loss: 0.1411\n",
      "Epoch 47/80\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 0.1562 - val_loss: 0.1337\n",
      "Epoch 48/80\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 0.1496 - val_loss: 0.1265\n",
      "Epoch 49/80\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 0.1437 - val_loss: 0.1195\n",
      "Epoch 50/80\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 0.1385 - val_loss: 0.1129\n",
      "Epoch 51/80\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 0.1330 - val_loss: 0.1068\n",
      "Epoch 52/80\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 0.1294 - val_loss: 0.1011\n",
      "Epoch 53/80\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "103/103 [==============================] - 0s 3ms/step - loss: 0.1260 - val_loss: 0.0959\n",
      "Epoch 54/80\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 0.1233 - val_loss: 0.0910\n",
      "Epoch 55/80\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 0.1211 - val_loss: 0.0867\n",
      "Epoch 56/80\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 0.1186 - val_loss: 0.0827\n",
      "Epoch 57/80\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 0.1166 - val_loss: 0.0791\n",
      "Epoch 58/80\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 0.1150 - val_loss: 0.0758\n",
      "Epoch 59/80\n",
      "103/103 [==============================] - ETA: 0s - loss: 0.117 - 0s 3ms/step - loss: 0.1146 - val_loss: 0.0726\n",
      "Epoch 60/80\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 0.1133 - val_loss: 0.0698\n",
      "Epoch 61/80\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 0.1121 - val_loss: 0.0671\n",
      "Epoch 62/80\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 0.1112 - val_loss: 0.0646\n",
      "Epoch 63/80\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 0.1104 - val_loss: 0.0622\n",
      "Epoch 64/80\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 0.1094 - val_loss: 0.0599\n",
      "Epoch 65/80\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 0.1092 - val_loss: 0.0578\n",
      "Epoch 66/80\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 0.1081 - val_loss: 0.0558\n",
      "Epoch 67/80\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 0.1073 - val_loss: 0.0539\n",
      "Epoch 68/80\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 0.1071 - val_loss: 0.0521\n",
      "Epoch 69/80\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 0.1062 - val_loss: 0.0504\n",
      "Epoch 70/80\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 0.1062 - val_loss: 0.0488\n",
      "Epoch 71/80\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 0.1058 - val_loss: 0.0473\n",
      "Epoch 72/80\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 0.1051 - val_loss: 0.0459\n",
      "Epoch 73/80\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 0.1050 - val_loss: 0.0446\n",
      "Epoch 74/80\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 0.1044 - val_loss: 0.0433\n",
      "Epoch 75/80\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 0.1038 - val_loss: 0.0421\n",
      "Epoch 76/80\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 0.1036 - val_loss: 0.0409\n",
      "Epoch 77/80\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 0.1034 - val_loss: 0.0399\n",
      "Epoch 78/80\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 0.1030 - val_loss: 0.0390\n",
      "Epoch 79/80\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 0.1028 - val_loss: 0.0382\n",
      "Epoch 80/80\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 0.1024 - val_loss: 0.0374\n",
      "Execution time:  24.300387620925903\n",
      "DNN:\n",
      "Mean Absolute Error: 0.0479\n",
      "Root Mean Square Error: 0.0539\n",
      "Mean Square Error: 0.0029\n",
      "\n",
      "Train RMSE: 0.054\n",
      "Train MSE: 0.003\n",
      "Train MAE: 0.048\n",
      "###########################\n",
      "\n",
      "MODEL:  DNN\n",
      "sequence:  6h\n",
      "units:  80\n",
      "dropout1:  0.11814836227952394\n",
      "optimizer: adadelta\n",
      "activationDense: tanh\n",
      "epochs: 90\n",
      "batchsize: 25\n",
      "validation_split: 0.2\n",
      "Model: \"sequential_88\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_264 (Dense)            (None, 36, 80)            160       \n",
      "_________________________________________________________________\n",
      "dense_265 (Dense)            (None, 36, 16)            1296      \n",
      "_________________________________________________________________\n",
      "dropout_88 (Dropout)         (None, 36, 16)            0         \n",
      "_________________________________________________________________\n",
      "dense_266 (Dense)            (None, 36, 1)             17        \n",
      "=================================================================\n",
      "Total params: 1,473\n",
      "Trainable params: 1,473\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/90\n",
      "127/127 [==============================] - 0s 4ms/step - loss: 0.2590 - val_loss: 0.2422\n",
      "Epoch 2/90\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 0.2543 - val_loss: 0.2374\n",
      "Epoch 3/90\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 0.2490 - val_loss: 0.2321\n",
      "Epoch 4/90\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 0.2436 - val_loss: 0.2263\n",
      "Epoch 5/90\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 0.2374 - val_loss: 0.2202\n",
      "Epoch 6/90\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 0.2310 - val_loss: 0.2136\n",
      "Epoch 7/90\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 0.2239 - val_loss: 0.2067\n",
      "Epoch 8/90\n",
      "127/127 [==============================] - 0s 2ms/step - loss: 0.2170 - val_loss: 0.1994\n",
      "Epoch 9/90\n",
      "127/127 [==============================] - 0s 2ms/step - loss: 0.2094 - val_loss: 0.1918\n",
      "Epoch 10/90\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 0.2015 - val_loss: 0.1839\n",
      "Epoch 11/90\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 0.1933 - val_loss: 0.1757\n",
      "Epoch 12/90\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 0.1847 - val_loss: 0.1672\n",
      "Epoch 13/90\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 0.1761 - val_loss: 0.1585\n",
      "Epoch 14/90\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 0.1670 - val_loss: 0.1501\n",
      "Epoch 15/90\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 0.1584 - val_loss: 0.1416\n",
      "Epoch 16/90\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 0.1498 - val_loss: 0.1329\n",
      "Epoch 17/90\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 0.1409 - val_loss: 0.1240\n",
      "Epoch 18/90\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 0.1316 - val_loss: 0.1148\n",
      "Epoch 19/90\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 0.1224 - val_loss: 0.1054\n",
      "Epoch 20/90\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 0.1128 - val_loss: 0.0957\n",
      "Epoch 21/90\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 0.1030 - val_loss: 0.0859\n",
      "Epoch 22/90\n",
      "127/127 [==============================] - 0s 2ms/step - loss: 0.0931 - val_loss: 0.0759\n",
      "Epoch 23/90\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 0.0833 - val_loss: 0.0658\n",
      "Epoch 24/90\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 0.0737 - val_loss: 0.0559\n",
      "Epoch 25/90\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 0.0650 - val_loss: 0.0466\n",
      "Epoch 26/90\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 0.0581 - val_loss: 0.0396\n",
      "Epoch 27/90\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 0.0541 - val_loss: 0.0340\n",
      "Epoch 28/90\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 0.0512 - val_loss: 0.0296\n",
      "Epoch 29/90\n",
      "127/127 [==============================] - 0s 2ms/step - loss: 0.0495 - val_loss: 0.0261\n",
      "Epoch 30/90\n",
      "127/127 [==============================] - 0s 2ms/step - loss: 0.0484 - val_loss: 0.0235\n",
      "Epoch 31/90\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 0.0477 - val_loss: 0.0214\n",
      "Epoch 32/90\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 0.0470 - val_loss: 0.0197\n",
      "Epoch 33/90\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 0.0464 - val_loss: 0.0182\n",
      "Epoch 34/90\n",
      "127/127 [==============================] - 0s 2ms/step - loss: 0.0462 - val_loss: 0.0170\n",
      "Epoch 35/90\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 0.0457 - val_loss: 0.0160\n",
      "Epoch 36/90\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 0.0457 - val_loss: 0.0151\n",
      "Epoch 37/90\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 0.0454 - val_loss: 0.0144\n",
      "Epoch 38/90\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 0.0450 - val_loss: 0.0136\n",
      "Epoch 39/90\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 0.0451 - val_loss: 0.0131\n",
      "Epoch 40/90\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 0.0449 - val_loss: 0.0126\n",
      "Epoch 41/90\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "127/127 [==============================] - 0s 3ms/step - loss: 0.0448 - val_loss: 0.0121\n",
      "Epoch 42/90\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 0.0448 - val_loss: 0.0120\n",
      "Epoch 43/90\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 0.0447 - val_loss: 0.0119\n",
      "Epoch 44/90\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 0.0447 - val_loss: 0.0119\n",
      "Epoch 45/90\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 0.0446 - val_loss: 0.0119\n",
      "Epoch 46/90\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 0.0443 - val_loss: 0.0118\n",
      "Epoch 47/90\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 0.0445 - val_loss: 0.0118\n",
      "Epoch 48/90\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 0.0443 - val_loss: 0.0118\n",
      "Epoch 49/90\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 0.0446 - val_loss: 0.0118\n",
      "Epoch 50/90\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 0.0443 - val_loss: 0.0118\n",
      "Epoch 51/90\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 0.0443 - val_loss: 0.0118\n",
      "Epoch 52/90\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 0.0442 - val_loss: 0.0117\n",
      "Epoch 53/90\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 0.0444 - val_loss: 0.0117\n",
      "Epoch 54/90\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 0.0442 - val_loss: 0.0117\n",
      "Epoch 55/90\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 0.0442 - val_loss: 0.0117\n",
      "Epoch 56/90\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 0.0439 - val_loss: 0.0117\n",
      "Epoch 57/90\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 0.0443 - val_loss: 0.0117\n",
      "Epoch 58/90\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 0.0443 - val_loss: 0.0117\n",
      "Epoch 59/90\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 0.0442 - val_loss: 0.0117\n",
      "Epoch 60/90\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 0.0441 - val_loss: 0.0117\n",
      "Epoch 61/90\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 0.0441 - val_loss: 0.0117\n",
      "Epoch 62/90\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 0.0441 - val_loss: 0.0117\n",
      "Epoch 63/90\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 0.0440 - val_loss: 0.0117\n",
      "Epoch 64/90\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 0.0441 - val_loss: 0.0117\n",
      "Epoch 65/90\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 0.0441 - val_loss: 0.0117\n",
      "Epoch 66/90\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 0.0439 - val_loss: 0.0117\n",
      "Epoch 67/90\n",
      "127/127 [==============================] - 0s 2ms/step - loss: 0.0440 - val_loss: 0.0117\n",
      "Epoch 68/90\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 0.0439 - val_loss: 0.0117\n",
      "Epoch 69/90\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 0.0438 - val_loss: 0.0117\n",
      "Epoch 70/90\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 0.0439 - val_loss: 0.0117\n",
      "Epoch 71/90\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 0.0438 - val_loss: 0.0117\n",
      "Epoch 72/90\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 0.0438 - val_loss: 0.0117\n",
      "Epoch 73/90\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 0.0437 - val_loss: 0.0117\n",
      "Epoch 74/90\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 0.0437 - val_loss: 0.0117\n",
      "Epoch 75/90\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 0.0438 - val_loss: 0.0117\n",
      "Epoch 76/90\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 0.0435 - val_loss: 0.0117\n",
      "Epoch 77/90\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 0.0435 - val_loss: 0.0117\n",
      "Epoch 78/90\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 0.0437 - val_loss: 0.0117\n",
      "Epoch 79/90\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 0.0436 - val_loss: 0.0117\n",
      "Epoch 80/90\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 0.0437 - val_loss: 0.0117\n",
      "Epoch 81/90\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 0.0436 - val_loss: 0.0117\n",
      "Epoch 82/90\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 0.0434 - val_loss: 0.0117\n",
      "Epoch 83/90\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 0.0434 - val_loss: 0.0117\n",
      "Epoch 84/90\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 0.0435 - val_loss: 0.0117\n",
      "Epoch 85/90\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 0.0434 - val_loss: 0.0117\n",
      "Epoch 86/90\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 0.0435 - val_loss: 0.0117\n",
      "Epoch 87/90\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 0.0435 - val_loss: 0.0117\n",
      "Epoch 88/90\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 0.0433 - val_loss: 0.0117\n",
      "Epoch 89/90\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 0.0433 - val_loss: 0.0117\n",
      "Epoch 90/90\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 0.0435 - val_loss: 0.0117\n",
      "Execution time:  31.515806436538696\n",
      "DNN:\n",
      "Mean Absolute Error: 0.0121\n",
      "Root Mean Square Error: 0.0214\n",
      "Mean Square Error: 0.0005\n",
      "\n",
      "Train RMSE: 0.021\n",
      "Train MSE: 0.000\n",
      "Train MAE: 0.012\n",
      "###########################\n",
      "\n",
      "MODEL:  DNN\n",
      "sequence:  6h\n",
      "units:  12\n",
      "dropout1:  0.48476373451509647\n",
      "optimizer: adadelta\n",
      "activationDense: tanh\n",
      "epochs: 52\n",
      "batchsize: 57\n",
      "validation_split: 0.2\n",
      "Model: \"sequential_89\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_267 (Dense)            (None, 36, 12)            24        \n",
      "_________________________________________________________________\n",
      "dense_268 (Dense)            (None, 36, 16)            208       \n",
      "_________________________________________________________________\n",
      "dropout_89 (Dropout)         (None, 36, 16)            0         \n",
      "_________________________________________________________________\n",
      "dense_269 (Dense)            (None, 36, 1)             17        \n",
      "=================================================================\n",
      "Total params: 249\n",
      "Trainable params: 249\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/52\n",
      "56/56 [==============================] - 0s 6ms/step - loss: 0.5175 - val_loss: 0.4909\n",
      "Epoch 2/52\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 0.5167 - val_loss: 0.4903\n",
      "Epoch 3/52\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 0.5164 - val_loss: 0.4896\n",
      "Epoch 4/52\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 0.5152 - val_loss: 0.4889\n",
      "Epoch 5/52\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 0.5148 - val_loss: 0.4881\n",
      "Epoch 6/52\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 0.5141 - val_loss: 0.4873\n",
      "Epoch 7/52\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 0.5125 - val_loss: 0.4865\n",
      "Epoch 8/52\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 0.5113 - val_loss: 0.4856\n",
      "Epoch 9/52\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 0.5114 - val_loss: 0.4848\n",
      "Epoch 10/52\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 0.5104 - val_loss: 0.4838\n",
      "Epoch 11/52\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 0.5100 - val_loss: 0.4829\n",
      "Epoch 12/52\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 0.5085 - val_loss: 0.4820\n",
      "Epoch 13/52\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 0.5073 - val_loss: 0.4810\n",
      "Epoch 14/52\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 0.5065 - val_loss: 0.4800\n",
      "Epoch 15/52\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 0.5055 - val_loss: 0.4790\n",
      "Epoch 16/52\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 0.5048 - val_loss: 0.4779\n",
      "Epoch 17/52\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 0.5031 - val_loss: 0.4768\n",
      "Epoch 18/52\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 0.5027 - val_loss: 0.4757\n",
      "Epoch 19/52\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 0.5017 - val_loss: 0.4746\n",
      "Epoch 20/52\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "56/56 [==============================] - 0s 3ms/step - loss: 0.5001 - val_loss: 0.4735\n",
      "Epoch 21/52\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 0.4995 - val_loss: 0.4723\n",
      "Epoch 22/52\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 0.4976 - val_loss: 0.4712\n",
      "Epoch 23/52\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 0.4974 - val_loss: 0.4700\n",
      "Epoch 24/52\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 0.4956 - val_loss: 0.4688\n",
      "Epoch 25/52\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 0.4942 - val_loss: 0.4675\n",
      "Epoch 26/52\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 0.4932 - val_loss: 0.4663\n",
      "Epoch 27/52\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 0.4912 - val_loss: 0.4650\n",
      "Epoch 28/52\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 0.4899 - val_loss: 0.4637\n",
      "Epoch 29/52\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 0.4896 - val_loss: 0.4624\n",
      "Epoch 30/52\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 0.4877 - val_loss: 0.4611\n",
      "Epoch 31/52\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 0.4867 - val_loss: 0.4597\n",
      "Epoch 32/52\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 0.4851 - val_loss: 0.4584\n",
      "Epoch 33/52\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 0.4834 - val_loss: 0.4570\n",
      "Epoch 34/52\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 0.4827 - val_loss: 0.4556\n",
      "Epoch 35/52\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 0.4806 - val_loss: 0.4542\n",
      "Epoch 36/52\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 0.4796 - val_loss: 0.4528\n",
      "Epoch 37/52\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 0.4780 - val_loss: 0.4513\n",
      "Epoch 38/52\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 0.4772 - val_loss: 0.4498\n",
      "Epoch 39/52\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 0.4754 - val_loss: 0.4484\n",
      "Epoch 40/52\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 0.4731 - val_loss: 0.4469\n",
      "Epoch 41/52\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 0.4729 - val_loss: 0.4454\n",
      "Epoch 42/52\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 0.4701 - val_loss: 0.4438\n",
      "Epoch 43/52\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 0.4689 - val_loss: 0.4423\n",
      "Epoch 44/52\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 0.4676 - val_loss: 0.4407\n",
      "Epoch 45/52\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 0.4658 - val_loss: 0.4392\n",
      "Epoch 46/52\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 0.4650 - val_loss: 0.4376\n",
      "Epoch 47/52\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 0.4630 - val_loss: 0.4360\n",
      "Epoch 48/52\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 0.4613 - val_loss: 0.4343\n",
      "Epoch 49/52\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 0.4593 - val_loss: 0.4327\n",
      "Epoch 50/52\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 0.4582 - val_loss: 0.4311\n",
      "Epoch 51/52\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 0.4565 - val_loss: 0.4294\n",
      "Epoch 52/52\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 0.4545 - val_loss: 0.4277\n",
      "Execution time:  9.281136751174927\n",
      "DNN:\n",
      "Mean Absolute Error: 0.4495\n",
      "Root Mean Square Error: 0.4523\n",
      "Mean Square Error: 0.2046\n",
      "\n",
      "Train RMSE: 0.452\n",
      "Train MSE: 0.205\n",
      "Train MAE: 0.449\n",
      "###########################\n",
      "\n",
      "MODEL:  DNN\n",
      "sequence:  6h\n",
      "units:  87\n",
      "dropout1:  0.40519643149940265\n",
      "optimizer: adadelta\n",
      "activationDense: sigmoid\n",
      "epochs: 80\n",
      "batchsize: 31\n",
      "validation_split: 0.1\n",
      "Model: \"sequential_90\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_270 (Dense)            (None, 36, 87)            174       \n",
      "_________________________________________________________________\n",
      "dense_271 (Dense)            (None, 36, 16)            1408      \n",
      "_________________________________________________________________\n",
      "dropout_90 (Dropout)         (None, 36, 16)            0         \n",
      "_________________________________________________________________\n",
      "dense_272 (Dense)            (None, 36, 1)             17        \n",
      "=================================================================\n",
      "Total params: 1,599\n",
      "Trainable params: 1,599\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/80\n",
      "115/115 [==============================] - 0s 4ms/step - loss: 0.0944 - val_loss: 0.1280\n",
      "Epoch 2/80\n",
      "115/115 [==============================] - 0s 3ms/step - loss: 0.0938 - val_loss: 0.1274\n",
      "Epoch 3/80\n",
      "115/115 [==============================] - 0s 3ms/step - loss: 0.0931 - val_loss: 0.1267\n",
      "Epoch 4/80\n",
      "115/115 [==============================] - 0s 3ms/step - loss: 0.0925 - val_loss: 0.1259\n",
      "Epoch 5/80\n",
      "115/115 [==============================] - 0s 3ms/step - loss: 0.0917 - val_loss: 0.1252\n",
      "Epoch 6/80\n",
      "115/115 [==============================] - 0s 3ms/step - loss: 0.0910 - val_loss: 0.1244\n",
      "Epoch 7/80\n",
      "115/115 [==============================] - 0s 3ms/step - loss: 0.0902 - val_loss: 0.1235\n",
      "Epoch 8/80\n",
      "115/115 [==============================] - 0s 3ms/step - loss: 0.0894 - val_loss: 0.1226\n",
      "Epoch 9/80\n",
      "115/115 [==============================] - 0s 3ms/step - loss: 0.0885 - val_loss: 0.1217\n",
      "Epoch 10/80\n",
      "115/115 [==============================] - 0s 3ms/step - loss: 0.0876 - val_loss: 0.1208\n",
      "Epoch 11/80\n",
      "115/115 [==============================] - 0s 3ms/step - loss: 0.0866 - val_loss: 0.1198\n",
      "Epoch 12/80\n",
      "115/115 [==============================] - 0s 3ms/step - loss: 0.0857 - val_loss: 0.1188\n",
      "Epoch 13/80\n",
      "115/115 [==============================] - 0s 3ms/step - loss: 0.0848 - val_loss: 0.1178\n",
      "Epoch 14/80\n",
      "115/115 [==============================] - 0s 3ms/step - loss: 0.0838 - val_loss: 0.1167\n",
      "Epoch 15/80\n",
      "115/115 [==============================] - 0s 3ms/step - loss: 0.0828 - val_loss: 0.1157\n",
      "Epoch 16/80\n",
      "115/115 [==============================] - 0s 3ms/step - loss: 0.0818 - val_loss: 0.1146\n",
      "Epoch 17/80\n",
      "115/115 [==============================] - 0s 3ms/step - loss: 0.0808 - val_loss: 0.1135\n",
      "Epoch 18/80\n",
      "115/115 [==============================] - 0s 3ms/step - loss: 0.0798 - val_loss: 0.1124\n",
      "Epoch 19/80\n",
      "115/115 [==============================] - 0s 3ms/step - loss: 0.0788 - val_loss: 0.1114\n",
      "Epoch 20/80\n",
      "115/115 [==============================] - 0s 3ms/step - loss: 0.0779 - val_loss: 0.1104\n",
      "Epoch 21/80\n",
      "115/115 [==============================] - 0s 3ms/step - loss: 0.0770 - val_loss: 0.1095\n",
      "Epoch 22/80\n",
      "115/115 [==============================] - 0s 3ms/step - loss: 0.0762 - val_loss: 0.1087\n",
      "Epoch 23/80\n",
      "115/115 [==============================] - 0s 3ms/step - loss: 0.0755 - val_loss: 0.1078\n",
      "Epoch 24/80\n",
      "115/115 [==============================] - 0s 3ms/step - loss: 0.0747 - val_loss: 0.1070\n",
      "Epoch 25/80\n",
      "115/115 [==============================] - 0s 3ms/step - loss: 0.0740 - val_loss: 0.1061\n",
      "Epoch 26/80\n",
      "115/115 [==============================] - 0s 3ms/step - loss: 0.0733 - val_loss: 0.1053\n",
      "Epoch 27/80\n",
      "115/115 [==============================] - 0s 3ms/step - loss: 0.0725 - val_loss: 0.1045\n",
      "Epoch 28/80\n",
      "115/115 [==============================] - 0s 3ms/step - loss: 0.0718 - val_loss: 0.1036\n",
      "Epoch 29/80\n",
      "115/115 [==============================] - 0s 3ms/step - loss: 0.0711 - val_loss: 0.1028\n",
      "Epoch 30/80\n",
      "115/115 [==============================] - 0s 3ms/step - loss: 0.0704 - val_loss: 0.1020\n",
      "Epoch 31/80\n",
      "115/115 [==============================] - 0s 3ms/step - loss: 0.0698 - val_loss: 0.1012\n",
      "Epoch 32/80\n",
      "115/115 [==============================] - 0s 3ms/step - loss: 0.0692 - val_loss: 0.1004\n",
      "Epoch 33/80\n",
      "115/115 [==============================] - 0s 3ms/step - loss: 0.0686 - val_loss: 0.0997\n",
      "Epoch 34/80\n",
      "115/115 [==============================] - 0s 3ms/step - loss: 0.0678 - val_loss: 0.0989\n",
      "Epoch 35/80\n",
      "115/115 [==============================] - 0s 3ms/step - loss: 0.0672 - val_loss: 0.0981\n",
      "Epoch 36/80\n",
      "115/115 [==============================] - 0s 3ms/step - loss: 0.0667 - val_loss: 0.0974\n",
      "Epoch 37/80\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "115/115 [==============================] - 0s 3ms/step - loss: 0.0661 - val_loss: 0.0966\n",
      "Epoch 38/80\n",
      "115/115 [==============================] - 0s 3ms/step - loss: 0.0656 - val_loss: 0.0959\n",
      "Epoch 39/80\n",
      "115/115 [==============================] - 0s 3ms/step - loss: 0.0650 - val_loss: 0.0951\n",
      "Epoch 40/80\n",
      "115/115 [==============================] - 0s 3ms/step - loss: 0.0644 - val_loss: 0.0944\n",
      "Epoch 41/80\n",
      "115/115 [==============================] - 0s 3ms/step - loss: 0.0639 - val_loss: 0.0936\n",
      "Epoch 42/80\n",
      "115/115 [==============================] - 0s 3ms/step - loss: 0.0634 - val_loss: 0.0929\n",
      "Epoch 43/80\n",
      "115/115 [==============================] - 0s 3ms/step - loss: 0.0629 - val_loss: 0.0922\n",
      "Epoch 44/80\n",
      "115/115 [==============================] - 0s 3ms/step - loss: 0.0624 - val_loss: 0.0915\n",
      "Epoch 45/80\n",
      "115/115 [==============================] - 0s 3ms/step - loss: 0.0618 - val_loss: 0.0908\n",
      "Epoch 46/80\n",
      "115/115 [==============================] - 0s 3ms/step - loss: 0.0614 - val_loss: 0.0901\n",
      "Epoch 47/80\n",
      "115/115 [==============================] - 0s 3ms/step - loss: 0.0609 - val_loss: 0.0894\n",
      "Epoch 48/80\n",
      "115/115 [==============================] - 0s 3ms/step - loss: 0.0603 - val_loss: 0.0888\n",
      "Epoch 49/80\n",
      "115/115 [==============================] - 0s 3ms/step - loss: 0.0600 - val_loss: 0.0881\n",
      "Epoch 50/80\n",
      "115/115 [==============================] - 0s 3ms/step - loss: 0.0595 - val_loss: 0.0875\n",
      "Epoch 51/80\n",
      "115/115 [==============================] - 0s 3ms/step - loss: 0.0591 - val_loss: 0.0868\n",
      "Epoch 52/80\n",
      "115/115 [==============================] - 0s 3ms/step - loss: 0.0588 - val_loss: 0.0862\n",
      "Epoch 53/80\n",
      "115/115 [==============================] - 0s 3ms/step - loss: 0.0582 - val_loss: 0.0856\n",
      "Epoch 54/80\n",
      "115/115 [==============================] - 0s 3ms/step - loss: 0.0579 - val_loss: 0.0850\n",
      "Epoch 55/80\n",
      "115/115 [==============================] - 0s 3ms/step - loss: 0.0575 - val_loss: 0.0844\n",
      "Epoch 56/80\n",
      "115/115 [==============================] - 0s 3ms/step - loss: 0.0571 - val_loss: 0.0838\n",
      "Epoch 57/80\n",
      "115/115 [==============================] - 0s 3ms/step - loss: 0.0569 - val_loss: 0.0832\n",
      "Epoch 58/80\n",
      "115/115 [==============================] - 0s 3ms/step - loss: 0.0564 - val_loss: 0.0826\n",
      "Epoch 59/80\n",
      "115/115 [==============================] - 0s 3ms/step - loss: 0.0560 - val_loss: 0.0820\n",
      "Epoch 60/80\n",
      "115/115 [==============================] - 0s 3ms/step - loss: 0.0558 - val_loss: 0.0814\n",
      "Epoch 61/80\n",
      "115/115 [==============================] - 0s 3ms/step - loss: 0.0553 - val_loss: 0.0809\n",
      "Epoch 62/80\n",
      "115/115 [==============================] - 0s 3ms/step - loss: 0.0551 - val_loss: 0.0803\n",
      "Epoch 63/80\n",
      "115/115 [==============================] - 0s 3ms/step - loss: 0.0548 - val_loss: 0.0797\n",
      "Epoch 64/80\n",
      "115/115 [==============================] - 0s 3ms/step - loss: 0.0543 - val_loss: 0.0792\n",
      "Epoch 65/80\n",
      "115/115 [==============================] - 0s 3ms/step - loss: 0.0540 - val_loss: 0.0787\n",
      "Epoch 66/80\n",
      "115/115 [==============================] - 0s 3ms/step - loss: 0.0538 - val_loss: 0.0781\n",
      "Epoch 67/80\n",
      "115/115 [==============================] - 0s 3ms/step - loss: 0.0535 - val_loss: 0.0776\n",
      "Epoch 68/80\n",
      "115/115 [==============================] - 0s 3ms/step - loss: 0.0532 - val_loss: 0.0771\n",
      "Epoch 69/80\n",
      "115/115 [==============================] - 0s 3ms/step - loss: 0.0529 - val_loss: 0.0766\n",
      "Epoch 70/80\n",
      "115/115 [==============================] - 0s 3ms/step - loss: 0.0526 - val_loss: 0.0761\n",
      "Epoch 71/80\n",
      "115/115 [==============================] - 0s 3ms/step - loss: 0.0524 - val_loss: 0.0756\n",
      "Epoch 72/80\n",
      "115/115 [==============================] - 0s 3ms/step - loss: 0.0520 - val_loss: 0.0751\n",
      "Epoch 73/80\n",
      "115/115 [==============================] - 0s 3ms/step - loss: 0.0518 - val_loss: 0.0746\n",
      "Epoch 74/80\n",
      "115/115 [==============================] - 0s 3ms/step - loss: 0.0516 - val_loss: 0.0741\n",
      "Epoch 75/80\n",
      "115/115 [==============================] - 0s 3ms/step - loss: 0.0513 - val_loss: 0.0736\n",
      "Epoch 76/80\n",
      "115/115 [==============================] - 0s 3ms/step - loss: 0.0512 - val_loss: 0.0732\n",
      "Epoch 77/80\n",
      "115/115 [==============================] - 0s 3ms/step - loss: 0.0508 - val_loss: 0.0727\n",
      "Epoch 78/80\n",
      "115/115 [==============================] - 0s 3ms/step - loss: 0.0507 - val_loss: 0.0722\n",
      "Epoch 79/80\n",
      "115/115 [==============================] - 0s 3ms/step - loss: 0.0504 - val_loss: 0.0718\n",
      "Epoch 80/80\n",
      "115/115 [==============================] - 0s 3ms/step - loss: 0.0503 - val_loss: 0.0713\n",
      "Execution time:  25.624168395996094\n",
      "DNN:\n",
      "Mean Absolute Error: 0.0491\n",
      "Root Mean Square Error: 0.0573\n",
      "Mean Square Error: 0.0033\n",
      "\n",
      "Train RMSE: 0.057\n",
      "Train MSE: 0.003\n",
      "Train MAE: 0.049\n",
      "###########################\n",
      "\n",
      "MODEL:  DNN\n",
      "sequence:  6h\n",
      "units:  80\n",
      "dropout1:  0.11814836227952394\n",
      "optimizer: adadelta\n",
      "activationDense: sigmoid\n",
      "epochs: 90\n",
      "batchsize: 25\n",
      "validation_split: 0.1\n",
      "Model: \"sequential_91\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_273 (Dense)            (None, 36, 80)            160       \n",
      "_________________________________________________________________\n",
      "dense_274 (Dense)            (None, 36, 16)            1296      \n",
      "_________________________________________________________________\n",
      "dropout_91 (Dropout)         (None, 36, 16)            0         \n",
      "_________________________________________________________________\n",
      "dense_275 (Dense)            (None, 36, 1)             17        \n",
      "=================================================================\n",
      "Total params: 1,473\n",
      "Trainable params: 1,473\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/90\n",
      "143/143 [==============================] - 1s 4ms/step - loss: 0.0901 - val_loss: 0.1238\n",
      "Epoch 2/90\n",
      "143/143 [==============================] - 0s 3ms/step - loss: 0.0894 - val_loss: 0.1231\n",
      "Epoch 3/90\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.0886 - val_loss: 0.1222\n",
      "Epoch 4/90\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.0878 - val_loss: 0.1214\n",
      "Epoch 5/90\n",
      "143/143 [==============================] - 0s 3ms/step - loss: 0.0870 - val_loss: 0.1204\n",
      "Epoch 6/90\n",
      "143/143 [==============================] - 0s 3ms/step - loss: 0.0860 - val_loss: 0.1195\n",
      "Epoch 7/90\n",
      "143/143 [==============================] - 0s 3ms/step - loss: 0.0851 - val_loss: 0.1184\n",
      "Epoch 8/90\n",
      "143/143 [==============================] - 0s 3ms/step - loss: 0.0841 - val_loss: 0.1173\n",
      "Epoch 9/90\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.0830 - val_loss: 0.1162\n",
      "Epoch 10/90\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.0819 - val_loss: 0.1152\n",
      "Epoch 11/90\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.0810 - val_loss: 0.1143\n",
      "Epoch 12/90\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.0801 - val_loss: 0.1134\n",
      "Epoch 13/90\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.0792 - val_loss: 0.1125\n",
      "Epoch 14/90\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.0784 - val_loss: 0.1115\n",
      "Epoch 15/90\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.0775 - val_loss: 0.1106\n",
      "Epoch 16/90\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.0764 - val_loss: 0.1091\n",
      "Epoch 17/90\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.0751 - val_loss: 0.1077\n",
      "Epoch 18/90\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.0738 - val_loss: 0.1063\n",
      "Epoch 19/90\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.0726 - val_loss: 0.1049\n",
      "Epoch 20/90\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.0713 - val_loss: 0.1036\n",
      "Epoch 21/90\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.0701 - val_loss: 0.1022\n",
      "Epoch 22/90\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.0690 - val_loss: 0.1008\n",
      "Epoch 23/90\n",
      "143/143 [==============================] - 0s 3ms/step - loss: 0.0678 - val_loss: 0.0995\n",
      "Epoch 24/90\n",
      "143/143 [==============================] - 0s 3ms/step - loss: 0.0667 - val_loss: 0.0982\n",
      "Epoch 25/90\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.0656 - val_loss: 0.0969\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 26/90\n",
      "143/143 [==============================] - 0s 3ms/step - loss: 0.0644 - val_loss: 0.0956\n",
      "Epoch 27/90\n",
      "143/143 [==============================] - 0s 3ms/step - loss: 0.0634 - val_loss: 0.0943\n",
      "Epoch 28/90\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.0623 - val_loss: 0.0929\n",
      "Epoch 29/90\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.0611 - val_loss: 0.0914\n",
      "Epoch 30/90\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.0600 - val_loss: 0.0898\n",
      "Epoch 31/90\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.0588 - val_loss: 0.0883\n",
      "Epoch 32/90\n",
      "143/143 [==============================] - 0s 3ms/step - loss: 0.0576 - val_loss: 0.0869\n",
      "Epoch 33/90\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.0565 - val_loss: 0.0854\n",
      "Epoch 34/90\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.0555 - val_loss: 0.0840\n",
      "Epoch 35/90\n",
      "143/143 [==============================] - 0s 3ms/step - loss: 0.0544 - val_loss: 0.0827\n",
      "Epoch 36/90\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.0535 - val_loss: 0.0813\n",
      "Epoch 37/90\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.0526 - val_loss: 0.0800\n",
      "Epoch 38/90\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.0517 - val_loss: 0.0788\n",
      "Epoch 39/90\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.0509 - val_loss: 0.0775\n",
      "Epoch 40/90\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.0501 - val_loss: 0.0763\n",
      "Epoch 41/90\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.0493 - val_loss: 0.0751\n",
      "Epoch 42/90\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.0486 - val_loss: 0.0739\n",
      "Epoch 43/90\n",
      "143/143 [==============================] - 0s 3ms/step - loss: 0.0479 - val_loss: 0.0728\n",
      "Epoch 44/90\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.0472 - val_loss: 0.0717\n",
      "Epoch 45/90\n",
      "143/143 [==============================] - 0s 3ms/step - loss: 0.0466 - val_loss: 0.0706\n",
      "Epoch 46/90\n",
      "143/143 [==============================] - 0s 3ms/step - loss: 0.0460 - val_loss: 0.0695\n",
      "Epoch 47/90\n",
      "143/143 [==============================] - 0s 3ms/step - loss: 0.0454 - val_loss: 0.0685\n",
      "Epoch 48/90\n",
      "143/143 [==============================] - 0s 3ms/step - loss: 0.0448 - val_loss: 0.0675\n",
      "Epoch 49/90\n",
      "143/143 [==============================] - 0s 3ms/step - loss: 0.0443 - val_loss: 0.0665\n",
      "Epoch 50/90\n",
      "143/143 [==============================] - 0s 3ms/step - loss: 0.0437 - val_loss: 0.0655\n",
      "Epoch 51/90\n",
      "143/143 [==============================] - 0s 3ms/step - loss: 0.0432 - val_loss: 0.0645\n",
      "Epoch 52/90\n",
      "143/143 [==============================] - 0s 3ms/step - loss: 0.0427 - val_loss: 0.0635\n",
      "Epoch 53/90\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.0422 - val_loss: 0.0626\n",
      "Epoch 54/90\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.0418 - val_loss: 0.0616\n",
      "Epoch 55/90\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.0413 - val_loss: 0.0607\n",
      "Epoch 56/90\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.0409 - val_loss: 0.0598\n",
      "Epoch 57/90\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.0405 - val_loss: 0.0589\n",
      "Epoch 58/90\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.0400 - val_loss: 0.0580\n",
      "Epoch 59/90\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.0396 - val_loss: 0.0571\n",
      "Epoch 60/90\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.0392 - val_loss: 0.0562\n",
      "Epoch 61/90\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.0389 - val_loss: 0.0554\n",
      "Epoch 62/90\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.0385 - val_loss: 0.0545\n",
      "Epoch 63/90\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.0381 - val_loss: 0.0537\n",
      "Epoch 64/90\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.0379 - val_loss: 0.0529\n",
      "Epoch 65/90\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.0375 - val_loss: 0.0522\n",
      "Epoch 66/90\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.0372 - val_loss: 0.0514\n",
      "Epoch 67/90\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.0370 - val_loss: 0.0507\n",
      "Epoch 68/90\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.0367 - val_loss: 0.0500\n",
      "Epoch 69/90\n",
      "143/143 [==============================] - 0s 3ms/step - loss: 0.0364 - val_loss: 0.0493\n",
      "Epoch 70/90\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.0361 - val_loss: 0.0486\n",
      "Epoch 71/90\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.0359 - val_loss: 0.0479\n",
      "Epoch 72/90\n",
      "143/143 [==============================] - 0s 3ms/step - loss: 0.0357 - val_loss: 0.0472\n",
      "Epoch 73/90\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.0354 - val_loss: 0.0466\n",
      "Epoch 74/90\n",
      "143/143 [==============================] - 0s 3ms/step - loss: 0.0352 - val_loss: 0.0459\n",
      "Epoch 75/90\n",
      "143/143 [==============================] - 0s 3ms/step - loss: 0.0350 - val_loss: 0.0453\n",
      "Epoch 76/90\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.0348 - val_loss: 0.0447\n",
      "Epoch 77/90\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.0346 - val_loss: 0.0441\n",
      "Epoch 78/90\n",
      "143/143 [==============================] - 0s 3ms/step - loss: 0.0344 - val_loss: 0.0436\n",
      "Epoch 79/90\n",
      "143/143 [==============================] - 0s 3ms/step - loss: 0.0343 - val_loss: 0.0431\n",
      "Epoch 80/90\n",
      "143/143 [==============================] - 0s 3ms/step - loss: 0.0341 - val_loss: 0.0426\n",
      "Epoch 81/90\n",
      "143/143 [==============================] - 0s 3ms/step - loss: 0.0340 - val_loss: 0.0421\n",
      "Epoch 82/90\n",
      "143/143 [==============================] - 0s 3ms/step - loss: 0.0339 - val_loss: 0.0416\n",
      "Epoch 83/90\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.0337 - val_loss: 0.0411\n",
      "Epoch 84/90\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.0337 - val_loss: 0.0407\n",
      "Epoch 85/90\n",
      "143/143 [==============================] - 0s 3ms/step - loss: 0.0336 - val_loss: 0.0402\n",
      "Epoch 86/90\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.0334 - val_loss: 0.0398\n",
      "Epoch 87/90\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.0333 - val_loss: 0.0394\n",
      "Epoch 88/90\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.0332 - val_loss: 0.0390\n",
      "Epoch 89/90\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.0332 - val_loss: 0.0386\n",
      "Epoch 90/90\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.0331 - val_loss: 0.0383\n",
      "Execution time:  33.28885006904602\n",
      "DNN:\n",
      "Mean Absolute Error: 0.0330\n",
      "Root Mean Square Error: 0.0457\n",
      "Mean Square Error: 0.0021\n",
      "\n",
      "Train RMSE: 0.046\n",
      "Train MSE: 0.002\n",
      "Train MAE: 0.033\n",
      "###########################\n",
      "\n",
      "MODEL:  DNN\n",
      "sequence:  6h\n",
      "units:  12\n",
      "dropout1:  0.48476373451509647\n",
      "optimizer: adadelta\n",
      "activationDense: sigmoid\n",
      "epochs: 52\n",
      "batchsize: 57\n",
      "validation_split: 0.1\n",
      "Model: \"sequential_92\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_276 (Dense)            (None, 36, 12)            24        \n",
      "_________________________________________________________________\n",
      "dense_277 (Dense)            (None, 36, 16)            208       \n",
      "_________________________________________________________________\n",
      "dropout_92 (Dropout)         (None, 36, 16)            0         \n",
      "_________________________________________________________________\n",
      "dense_278 (Dense)            (None, 36, 1)             17        \n",
      "=================================================================\n",
      "Total params: 249\n",
      "Trainable params: 249\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/52\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.1066 - val_loss: 0.1391\n",
      "Epoch 2/52\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.1065 - val_loss: 0.1389\n",
      "Epoch 3/52\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.1064 - val_loss: 0.1388\n",
      "Epoch 4/52\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.1062 - val_loss: 0.1386\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/52\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.1060 - val_loss: 0.1384\n",
      "Epoch 6/52\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.1059 - val_loss: 0.1382\n",
      "Epoch 7/52\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.1057 - val_loss: 0.1380\n",
      "Epoch 8/52\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.1054 - val_loss: 0.1378\n",
      "Epoch 9/52\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.1053 - val_loss: 0.1376\n",
      "Epoch 10/52\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.1052 - val_loss: 0.1374\n",
      "Epoch 11/52\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.1047 - val_loss: 0.1372\n",
      "Epoch 12/52\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.1047 - val_loss: 0.1370\n",
      "Epoch 13/52\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.1044 - val_loss: 0.1368\n",
      "Epoch 14/52\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.1042 - val_loss: 0.1365\n",
      "Epoch 15/52\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.1040 - val_loss: 0.1363\n",
      "Epoch 16/52\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.1037 - val_loss: 0.1360\n",
      "Epoch 17/52\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.1034 - val_loss: 0.1358\n",
      "Epoch 18/52\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.1031 - val_loss: 0.1355\n",
      "Epoch 19/52\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.1031 - val_loss: 0.1353\n",
      "Epoch 20/52\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.1027 - val_loss: 0.1350\n",
      "Epoch 21/52\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.1026 - val_loss: 0.1348\n",
      "Epoch 22/52\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.1022 - val_loss: 0.1345\n",
      "Epoch 23/52\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.1020 - val_loss: 0.1342\n",
      "Epoch 24/52\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.1018 - val_loss: 0.1340\n",
      "Epoch 25/52\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.1014 - val_loss: 0.1337\n",
      "Epoch 26/52\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.1011 - val_loss: 0.1334\n",
      "Epoch 27/52\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.1009 - val_loss: 0.1331\n",
      "Epoch 28/52\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.1007 - val_loss: 0.1328\n",
      "Epoch 29/52\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.1003 - val_loss: 0.1326\n",
      "Epoch 30/52\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.1001 - val_loss: 0.1323\n",
      "Epoch 31/52\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0998 - val_loss: 0.1320\n",
      "Epoch 32/52\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.0995 - val_loss: 0.1317\n",
      "Epoch 33/52\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.0993 - val_loss: 0.1314\n",
      "Epoch 34/52\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0990 - val_loss: 0.1311\n",
      "Epoch 35/52\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.0987 - val_loss: 0.1308\n",
      "Epoch 36/52\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.0984 - val_loss: 0.1305\n",
      "Epoch 37/52\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.0980 - val_loss: 0.1302\n",
      "Epoch 38/52\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0978 - val_loss: 0.1299\n",
      "Epoch 39/52\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.0974 - val_loss: 0.1295\n",
      "Epoch 40/52\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.0972 - val_loss: 0.1292\n",
      "Epoch 41/52\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0969 - val_loss: 0.1289\n",
      "Epoch 42/52\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0966 - val_loss: 0.1286\n",
      "Epoch 43/52\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0963 - val_loss: 0.1283\n",
      "Epoch 44/52\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.0959 - val_loss: 0.1280\n",
      "Epoch 45/52\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0956 - val_loss: 0.1276\n",
      "Epoch 46/52\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0952 - val_loss: 0.1273\n",
      "Epoch 47/52\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.0950 - val_loss: 0.1270\n",
      "Epoch 48/52\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0947 - val_loss: 0.1267\n",
      "Epoch 49/52\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0946 - val_loss: 0.1263\n",
      "Epoch 50/52\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.0941 - val_loss: 0.1260\n",
      "Epoch 51/52\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.0939 - val_loss: 0.1257\n",
      "Epoch 52/52\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0934 - val_loss: 0.1253\n",
      "Execution time:  9.504527568817139\n",
      "DNN:\n",
      "Mean Absolute Error: 0.0951\n",
      "Root Mean Square Error: 0.1015\n",
      "Mean Square Error: 0.0103\n",
      "\n",
      "Train RMSE: 0.102\n",
      "Train MSE: 0.010\n",
      "Train MAE: 0.095\n",
      "###########################\n",
      "\n",
      "MODEL:  DNN\n",
      "sequence:  6h\n",
      "units:  87\n",
      "dropout1:  0.40519643149940265\n",
      "optimizer: adadelta\n",
      "activationDense: sigmoid\n",
      "epochs: 80\n",
      "batchsize: 31\n",
      "validation_split: 0.2\n",
      "Model: \"sequential_93\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_279 (Dense)            (None, 36, 87)            174       \n",
      "_________________________________________________________________\n",
      "dense_280 (Dense)            (None, 36, 16)            1408      \n",
      "_________________________________________________________________\n",
      "dropout_93 (Dropout)         (None, 36, 16)            0         \n",
      "_________________________________________________________________\n",
      "dense_281 (Dense)            (None, 36, 1)             17        \n",
      "=================================================================\n",
      "Total params: 1,599\n",
      "Trainable params: 1,599\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/80\n",
      "103/103 [==============================] - 0s 5ms/step - loss: 0.1103 - val_loss: 0.1302\n",
      "Epoch 2/80\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 0.1099 - val_loss: 0.1298\n",
      "Epoch 3/80\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 0.1095 - val_loss: 0.1294\n",
      "Epoch 4/80\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 0.1091 - val_loss: 0.1289\n",
      "Epoch 5/80\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 0.1086 - val_loss: 0.1285\n",
      "Epoch 6/80\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 0.1082 - val_loss: 0.1280\n",
      "Epoch 7/80\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 0.1076 - val_loss: 0.1275\n",
      "Epoch 8/80\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 0.1071 - val_loss: 0.1270\n",
      "Epoch 9/80\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 0.1065 - val_loss: 0.1264\n",
      "Epoch 10/80\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 0.1059 - val_loss: 0.1259\n",
      "Epoch 11/80\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 0.1053 - val_loss: 0.1253\n",
      "Epoch 12/80\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 0.1048 - val_loss: 0.1247\n",
      "Epoch 13/80\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 0.1041 - val_loss: 0.1241\n",
      "Epoch 14/80\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 0.1035 - val_loss: 0.1235\n",
      "Epoch 15/80\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 0.1028 - val_loss: 0.1228\n",
      "Epoch 16/80\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 0.1022 - val_loss: 0.1222\n",
      "Epoch 17/80\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 0.1015 - val_loss: 0.1215\n",
      "Epoch 18/80\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 0.1008 - val_loss: 0.1208\n",
      "Epoch 19/80\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 0.1001 - val_loss: 0.1204\n",
      "Epoch 20/80\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 0.0997 - val_loss: 0.1200\n",
      "Epoch 21/80\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 0.0993 - val_loss: 0.1197\n",
      "Epoch 22/80\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 0.0989 - val_loss: 0.1194\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 23/80\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 0.0986 - val_loss: 0.1190\n",
      "Epoch 24/80\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 0.0982 - val_loss: 0.1187\n",
      "Epoch 25/80\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 0.0979 - val_loss: 0.1183\n",
      "Epoch 26/80\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 0.0975 - val_loss: 0.1180\n",
      "Epoch 27/80\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 0.0971 - val_loss: 0.1176\n",
      "Epoch 28/80\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 0.0968 - val_loss: 0.1173\n",
      "Epoch 29/80\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 0.0964 - val_loss: 0.1169\n",
      "Epoch 30/80\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 0.0960 - val_loss: 0.1166\n",
      "Epoch 31/80\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 0.0956 - val_loss: 0.1162\n",
      "Epoch 32/80\n",
      "103/103 [==============================] - ETA: 0s - loss: 0.090 - 0s 3ms/step - loss: 0.0953 - val_loss: 0.1158\n",
      "Epoch 33/80\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 0.0949 - val_loss: 0.1155\n",
      "Epoch 34/80\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 0.0945 - val_loss: 0.1151\n",
      "Epoch 35/80\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 0.0941 - val_loss: 0.1147\n",
      "Epoch 36/80\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 0.0937 - val_loss: 0.1144\n",
      "Epoch 37/80\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 0.0933 - val_loss: 0.1140\n",
      "Epoch 38/80\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 0.0931 - val_loss: 0.1138\n",
      "Epoch 39/80\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 0.0928 - val_loss: 0.1136\n",
      "Epoch 40/80\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 0.0925 - val_loss: 0.1133\n",
      "Epoch 41/80\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 0.0922 - val_loss: 0.1131\n",
      "Epoch 42/80\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 0.0920 - val_loss: 0.1128\n",
      "Epoch 43/80\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 0.0917 - val_loss: 0.1126\n",
      "Epoch 44/80\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 0.0915 - val_loss: 0.1123\n",
      "Epoch 45/80\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 0.0912 - val_loss: 0.1121\n",
      "Epoch 46/80\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 0.0910 - val_loss: 0.1118\n",
      "Epoch 47/80\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 0.0907 - val_loss: 0.1116\n",
      "Epoch 48/80\n",
      "103/103 [==============================] - ETA: 0s - loss: 0.085 - 0s 3ms/step - loss: 0.0904 - val_loss: 0.1113\n",
      "Epoch 49/80\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 0.0902 - val_loss: 0.1111\n",
      "Epoch 50/80\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 0.0899 - val_loss: 0.1108\n",
      "Epoch 51/80\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 0.0896 - val_loss: 0.1105\n",
      "Epoch 52/80\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 0.0894 - val_loss: 0.1102\n",
      "Epoch 53/80\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 0.0891 - val_loss: 0.1100\n",
      "Epoch 54/80\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 0.0888 - val_loss: 0.1097\n",
      "Epoch 55/80\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 0.0885 - val_loss: 0.1094\n",
      "Epoch 56/80\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 0.0882 - val_loss: 0.1091\n",
      "Epoch 57/80\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 0.0879 - val_loss: 0.1088\n",
      "Epoch 58/80\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 0.0876 - val_loss: 0.1086\n",
      "Epoch 59/80\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 0.0874 - val_loss: 0.1083\n",
      "Epoch 60/80\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 0.0871 - val_loss: 0.1080\n",
      "Epoch 61/80\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 0.0868 - val_loss: 0.1077\n",
      "Epoch 62/80\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 0.0865 - val_loss: 0.1074\n",
      "Epoch 63/80\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 0.0861 - val_loss: 0.1071\n",
      "Epoch 64/80\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 0.0859 - val_loss: 0.1068\n",
      "Epoch 65/80\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 0.0856 - val_loss: 0.1065\n",
      "Epoch 66/80\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 0.0852 - val_loss: 0.1062\n",
      "Epoch 67/80\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 0.0849 - val_loss: 0.1059\n",
      "Epoch 68/80\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 0.0846 - val_loss: 0.1056\n",
      "Epoch 69/80\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 0.0843 - val_loss: 0.1052\n",
      "Epoch 70/80\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 0.0840 - val_loss: 0.1049\n",
      "Epoch 71/80\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 0.0837 - val_loss: 0.1046\n",
      "Epoch 72/80\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 0.0833 - val_loss: 0.1043\n",
      "Epoch 73/80\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 0.0830 - val_loss: 0.1040\n",
      "Epoch 74/80\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 0.0827 - val_loss: 0.1036\n",
      "Epoch 75/80\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 0.0823 - val_loss: 0.1033\n",
      "Epoch 76/80\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 0.0820 - val_loss: 0.1030\n",
      "Epoch 77/80\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 0.0816 - val_loss: 0.1026\n",
      "Epoch 78/80\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 0.0813 - val_loss: 0.1023\n",
      "Epoch 79/80\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 0.0810 - val_loss: 0.1020\n",
      "Epoch 80/80\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 0.0806 - val_loss: 0.1017\n",
      "Execution time:  24.770567655563354\n",
      "DNN:\n",
      "Mean Absolute Error: 0.0845\n",
      "Root Mean Square Error: 0.0914\n",
      "Mean Square Error: 0.0084\n",
      "\n",
      "Train RMSE: 0.091\n",
      "Train MSE: 0.008\n",
      "Train MAE: 0.085\n",
      "###########################\n",
      "\n",
      "MODEL:  DNN\n",
      "sequence:  6h\n",
      "units:  80\n",
      "dropout1:  0.11814836227952394\n",
      "optimizer: adadelta\n",
      "activationDense: sigmoid\n",
      "epochs: 90\n",
      "batchsize: 25\n",
      "validation_split: 0.2\n",
      "Model: \"sequential_94\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_282 (Dense)            (None, 36, 80)            160       \n",
      "_________________________________________________________________\n",
      "dense_283 (Dense)            (None, 36, 16)            1296      \n",
      "_________________________________________________________________\n",
      "dropout_94 (Dropout)         (None, 36, 16)            0         \n",
      "_________________________________________________________________\n",
      "dense_284 (Dense)            (None, 36, 1)             17        \n",
      "=================================================================\n",
      "Total params: 1,473\n",
      "Trainable params: 1,473\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/90\n",
      "127/127 [==============================] - 1s 4ms/step - loss: 0.0906 - val_loss: 0.1117\n",
      "Epoch 2/90\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 0.0900 - val_loss: 0.1111\n",
      "Epoch 3/90\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 0.0893 - val_loss: 0.1104\n",
      "Epoch 4/90\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 0.0886 - val_loss: 0.1096\n",
      "Epoch 5/90\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 0.0878 - val_loss: 0.1089\n",
      "Epoch 6/90\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 0.0870 - val_loss: 0.1081\n",
      "Epoch 7/90\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 0.0861 - val_loss: 0.1072\n",
      "Epoch 8/90\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 0.0853 - val_loss: 0.1064\n",
      "Epoch 9/90\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 0.0844 - val_loss: 0.1056\n",
      "Epoch 10/90\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 0.0836 - val_loss: 0.1048\n",
      "Epoch 11/90\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "127/127 [==============================] - 0s 3ms/step - loss: 0.0827 - val_loss: 0.1039\n",
      "Epoch 12/90\n",
      "127/127 [==============================] - 0s 2ms/step - loss: 0.0820 - val_loss: 0.1033\n",
      "Epoch 13/90\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 0.0814 - val_loss: 0.1028\n",
      "Epoch 14/90\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 0.0807 - val_loss: 0.1022\n",
      "Epoch 15/90\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 0.0801 - val_loss: 0.1016\n",
      "Epoch 16/90\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 0.0795 - val_loss: 0.1010\n",
      "Epoch 17/90\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 0.0789 - val_loss: 0.1004\n",
      "Epoch 18/90\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 0.0783 - val_loss: 0.0997\n",
      "Epoch 19/90\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 0.0777 - val_loss: 0.0991\n",
      "Epoch 20/90\n",
      "127/127 [==============================] - 0s 2ms/step - loss: 0.0770 - val_loss: 0.0985\n",
      "Epoch 21/90\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 0.0763 - val_loss: 0.0978\n",
      "Epoch 22/90\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 0.0757 - val_loss: 0.0972\n",
      "Epoch 23/90\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 0.0751 - val_loss: 0.0965\n",
      "Epoch 24/90\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 0.0744 - val_loss: 0.0958\n",
      "Epoch 25/90\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 0.0738 - val_loss: 0.0951\n",
      "Epoch 26/90\n",
      "127/127 [==============================] - 0s 2ms/step - loss: 0.0731 - val_loss: 0.0944\n",
      "Epoch 27/90\n",
      "127/127 [==============================] - 0s 2ms/step - loss: 0.0724 - val_loss: 0.0937\n",
      "Epoch 28/90\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 0.0717 - val_loss: 0.0930\n",
      "Epoch 29/90\n",
      "127/127 [==============================] - ETA: 0s - loss: 0.068 - 0s 2ms/step - loss: 0.0711 - val_loss: 0.0923\n",
      "Epoch 30/90\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 0.0704 - val_loss: 0.0916\n",
      "Epoch 31/90\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 0.0697 - val_loss: 0.0909\n",
      "Epoch 32/90\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 0.0690 - val_loss: 0.0901\n",
      "Epoch 33/90\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 0.0683 - val_loss: 0.0894\n",
      "Epoch 34/90\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 0.0676 - val_loss: 0.0886\n",
      "Epoch 35/90\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 0.0668 - val_loss: 0.0879\n",
      "Epoch 36/90\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 0.0661 - val_loss: 0.0871\n",
      "Epoch 37/90\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 0.0654 - val_loss: 0.0864\n",
      "Epoch 38/90\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 0.0647 - val_loss: 0.0856\n",
      "Epoch 39/90\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 0.0640 - val_loss: 0.0848\n",
      "Epoch 40/90\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 0.0634 - val_loss: 0.0841\n",
      "Epoch 41/90\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 0.0627 - val_loss: 0.0833\n",
      "Epoch 42/90\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 0.0620 - val_loss: 0.0826\n",
      "Epoch 43/90\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 0.0614 - val_loss: 0.0819\n",
      "Epoch 44/90\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 0.0608 - val_loss: 0.0812\n",
      "Epoch 45/90\n",
      "127/127 [==============================] - 0s 2ms/step - loss: 0.0602 - val_loss: 0.0805\n",
      "Epoch 46/90\n",
      "127/127 [==============================] - 0s 2ms/step - loss: 0.0596 - val_loss: 0.0798\n",
      "Epoch 47/90\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 0.0590 - val_loss: 0.0791\n",
      "Epoch 48/90\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 0.0583 - val_loss: 0.0784\n",
      "Epoch 49/90\n",
      "127/127 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0777\n",
      "Epoch 50/90\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 0.0572 - val_loss: 0.0770\n",
      "Epoch 51/90\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 0.0566 - val_loss: 0.0763\n",
      "Epoch 52/90\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 0.0561 - val_loss: 0.0757\n",
      "Epoch 53/90\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 0.0555 - val_loss: 0.0750\n",
      "Epoch 54/90\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 0.0550 - val_loss: 0.0743\n",
      "Epoch 55/90\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 0.0545 - val_loss: 0.0737\n",
      "Epoch 56/90\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 0.0540 - val_loss: 0.0731\n",
      "Epoch 57/90\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 0.0536 - val_loss: 0.0724\n",
      "Epoch 58/90\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 0.0532 - val_loss: 0.0718\n",
      "Epoch 59/90\n",
      "127/127 [==============================] - 0s 2ms/step - loss: 0.0527 - val_loss: 0.0712\n",
      "Epoch 60/90\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 0.0522 - val_loss: 0.0707\n",
      "Epoch 61/90\n",
      "127/127 [==============================] - 0s 2ms/step - loss: 0.0519 - val_loss: 0.0701\n",
      "Epoch 62/90\n",
      "127/127 [==============================] - 0s 2ms/step - loss: 0.0515 - val_loss: 0.0695\n",
      "Epoch 63/90\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 0.0511 - val_loss: 0.0689\n",
      "Epoch 64/90\n",
      "127/127 [==============================] - 0s 2ms/step - loss: 0.0507 - val_loss: 0.0684\n",
      "Epoch 65/90\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 0.0504 - val_loss: 0.0678\n",
      "Epoch 66/90\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 0.0499 - val_loss: 0.0673\n",
      "Epoch 67/90\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 0.0495 - val_loss: 0.0667\n",
      "Epoch 68/90\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 0.0493 - val_loss: 0.0662\n",
      "Epoch 69/90\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 0.0489 - val_loss: 0.0657\n",
      "Epoch 70/90\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 0.0485 - val_loss: 0.0652\n",
      "Epoch 71/90\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 0.0482 - val_loss: 0.0646\n",
      "Epoch 72/90\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 0.0479 - val_loss: 0.0641\n",
      "Epoch 73/90\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 0.0477 - val_loss: 0.0636\n",
      "Epoch 74/90\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 0.0473 - val_loss: 0.0632\n",
      "Epoch 75/90\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 0.0470 - val_loss: 0.0627\n",
      "Epoch 76/90\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 0.0467 - val_loss: 0.0622\n",
      "Epoch 77/90\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 0.0465 - val_loss: 0.0617\n",
      "Epoch 78/90\n",
      "127/127 [==============================] - 0s 2ms/step - loss: 0.0462 - val_loss: 0.0612\n",
      "Epoch 79/90\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 0.0458 - val_loss: 0.0608\n",
      "Epoch 80/90\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 0.0457 - val_loss: 0.0603\n",
      "Epoch 81/90\n",
      "127/127 [==============================] - 0s 2ms/step - loss: 0.0454 - val_loss: 0.0598\n",
      "Epoch 82/90\n",
      "127/127 [==============================] - 0s 2ms/step - loss: 0.0451 - val_loss: 0.0594\n",
      "Epoch 83/90\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 0.0449 - val_loss: 0.0589\n",
      "Epoch 84/90\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 0.0446 - val_loss: 0.0585\n",
      "Epoch 85/90\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 0.0444 - val_loss: 0.0580\n",
      "Epoch 86/90\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 0.0442 - val_loss: 0.0576\n",
      "Epoch 87/90\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 0.0439 - val_loss: 0.0571\n",
      "Epoch 88/90\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 0.0437 - val_loss: 0.0567\n",
      "Epoch 89/90\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 0.0435 - val_loss: 0.0562\n",
      "Epoch 90/90\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 0.0432 - val_loss: 0.0558\n",
      "Execution time:  31.344316482543945\n",
      "DNN:\n",
      "Mean Absolute Error: 0.0449\n",
      "Root Mean Square Error: 0.0534\n",
      "Mean Square Error: 0.0028\n",
      "\n",
      "Train RMSE: 0.053\n",
      "Train MSE: 0.003\n",
      "Train MAE: 0.045\n",
      "###########################\n",
      "\n",
      "MODEL:  DNN\n",
      "sequence:  6h\n",
      "units:  12\n",
      "dropout1:  0.48476373451509647\n",
      "optimizer: adadelta\n",
      "activationDense: sigmoid\n",
      "epochs: 52\n",
      "batchsize: 57\n",
      "validation_split: 0.2\n",
      "Model: \"sequential_95\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_285 (Dense)            (None, 36, 12)            24        \n",
      "_________________________________________________________________\n",
      "dense_286 (Dense)            (None, 36, 16)            208       \n",
      "_________________________________________________________________\n",
      "dropout_95 (Dropout)         (None, 36, 16)            0         \n",
      "_________________________________________________________________\n",
      "dense_287 (Dense)            (None, 36, 1)             17        \n",
      "=================================================================\n",
      "Total params: 249\n",
      "Trainable params: 249\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/52\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "56/56 [==============================] - 0s 6ms/step - loss: 0.0869 - val_loss: 0.1066\n",
      "Epoch 2/52\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 0.0866 - val_loss: 0.1064\n",
      "Epoch 3/52\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 0.0865 - val_loss: 0.1061\n",
      "Epoch 4/52\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 0.0864 - val_loss: 0.1059\n",
      "Epoch 5/52\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 0.0861 - val_loss: 0.1057\n",
      "Epoch 6/52\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 0.0858 - val_loss: 0.1054\n",
      "Epoch 7/52\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 0.0855 - val_loss: 0.1052\n",
      "Epoch 8/52\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 0.0852 - val_loss: 0.1049\n",
      "Epoch 9/52\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 0.0851 - val_loss: 0.1047\n",
      "Epoch 10/52\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 0.0850 - val_loss: 0.1044\n",
      "Epoch 11/52\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 0.0846 - val_loss: 0.1042\n",
      "Epoch 12/52\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 0.0841 - val_loss: 0.1039\n",
      "Epoch 13/52\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 0.0840 - val_loss: 0.1036\n",
      "Epoch 14/52\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 0.0839 - val_loss: 0.1033\n",
      "Epoch 15/52\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 0.0834 - val_loss: 0.1031\n",
      "Epoch 16/52\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 0.0834 - val_loss: 0.1028\n",
      "Epoch 17/52\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 0.0830 - val_loss: 0.1025\n",
      "Epoch 18/52\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 0.0828 - val_loss: 0.1022\n",
      "Epoch 19/52\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 0.0825 - val_loss: 0.1019\n",
      "Epoch 20/52\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 0.0823 - val_loss: 0.1016\n",
      "Epoch 21/52\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 0.0819 - val_loss: 0.1013\n",
      "Epoch 22/52\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 0.0816 - val_loss: 0.1010\n",
      "Epoch 23/52\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 0.0814 - val_loss: 0.1007\n",
      "Epoch 24/52\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 0.0809 - val_loss: 0.1004\n",
      "Epoch 25/52\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 0.0808 - val_loss: 0.1001\n",
      "Epoch 26/52\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 0.0806 - val_loss: 0.0998\n",
      "Epoch 27/52\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 0.0800 - val_loss: 0.0995\n",
      "Epoch 28/52\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 0.0799 - val_loss: 0.0991\n",
      "Epoch 29/52\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 0.0795 - val_loss: 0.0988\n",
      "Epoch 30/52\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 0.0795 - val_loss: 0.0985\n",
      "Epoch 31/52\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 0.0791 - val_loss: 0.0982\n",
      "Epoch 32/52\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 0.0789 - val_loss: 0.0979\n",
      "Epoch 33/52\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 0.0783 - val_loss: 0.0976\n",
      "Epoch 34/52\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 0.0782 - val_loss: 0.0972\n",
      "Epoch 35/52\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 0.0778 - val_loss: 0.0969\n",
      "Epoch 36/52\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 0.0777 - val_loss: 0.0966\n",
      "Epoch 37/52\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 0.0771 - val_loss: 0.0963\n",
      "Epoch 38/52\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 0.0771 - val_loss: 0.0960\n",
      "Epoch 39/52\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 0.0769 - val_loss: 0.0956\n",
      "Epoch 40/52\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 0.0764 - val_loss: 0.0953\n",
      "Epoch 41/52\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 0.0761 - val_loss: 0.0950\n",
      "Epoch 42/52\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 0.0757 - val_loss: 0.0947\n",
      "Epoch 43/52\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 0.0756 - val_loss: 0.0944\n",
      "Epoch 44/52\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 0.0752 - val_loss: 0.0940\n",
      "Epoch 45/52\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 0.0751 - val_loss: 0.0937\n",
      "Epoch 46/52\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 0.0749 - val_loss: 0.0934\n",
      "Epoch 47/52\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 0.0743 - val_loss: 0.0931\n",
      "Epoch 48/52\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 0.0740 - val_loss: 0.0928\n",
      "Epoch 49/52\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 0.0738 - val_loss: 0.0924\n",
      "Epoch 50/52\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 0.0736 - val_loss: 0.0921\n",
      "Epoch 51/52\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 0.0733 - val_loss: 0.0918\n",
      "Epoch 52/52\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 0.0730 - val_loss: 0.0915\n",
      "Execution time:  8.825892448425293\n",
      "DNN:\n",
      "Mean Absolute Error: 0.0742\n",
      "Root Mean Square Error: 0.0819\n",
      "Mean Square Error: 0.0067\n",
      "\n",
      "Train RMSE: 0.082\n",
      "Train MSE: 0.007\n",
      "Train MAE: 0.074\n",
      "###########################\n",
      "\n",
      "MODEL:  DNN\n",
      "sequence:  6h\n",
      "units:  87\n",
      "dropout1:  0.40519643149940265\n",
      "optimizer: adamax\n",
      "activationDense: tanh\n",
      "epochs: 80\n",
      "batchsize: 31\n",
      "validation_split: 0.1\n",
      "Model: \"sequential_96\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_288 (Dense)            (None, 36, 87)            174       \n",
      "_________________________________________________________________\n",
      "dense_289 (Dense)            (None, 36, 16)            1408      \n",
      "_________________________________________________________________\n",
      "dropout_96 (Dropout)         (None, 36, 16)            0         \n",
      "_________________________________________________________________\n",
      "dense_290 (Dense)            (None, 36, 1)             17        \n",
      "=================================================================\n",
      "Total params: 1,599\n",
      "Trainable params: 1,599\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/80\n",
      "115/115 [==============================] - 0s 4ms/step - loss: 0.1477 - val_loss: 0.0349\n",
      "Epoch 2/80\n",
      "115/115 [==============================] - 0s 3ms/step - loss: 0.1003 - val_loss: 0.0322\n",
      "Epoch 3/80\n",
      "115/115 [==============================] - 0s 3ms/step - loss: 0.0901 - val_loss: 0.0288\n",
      "Epoch 4/80\n",
      "115/115 [==============================] - 0s 3ms/step - loss: 0.0796 - val_loss: 0.0225\n",
      "Epoch 5/80\n",
      "115/115 [==============================] - 0s 3ms/step - loss: 0.0697 - val_loss: 0.0104\n",
      "Epoch 6/80\n",
      "115/115 [==============================] - 0s 3ms/step - loss: 0.0597 - val_loss: 0.0061\n",
      "Epoch 7/80\n",
      "115/115 [==============================] - 0s 3ms/step - loss: 0.0505 - val_loss: 0.0052\n",
      "Epoch 8/80\n",
      "115/115 [==============================] - 0s 3ms/step - loss: 0.0440 - val_loss: 0.0063\n",
      "Epoch 9/80\n",
      "115/115 [==============================] - 0s 3ms/step - loss: 0.0385 - val_loss: 0.0081\n",
      "Epoch 10/80\n",
      "115/115 [==============================] - 0s 3ms/step - loss: 0.0344 - val_loss: 0.0111\n",
      "Epoch 11/80\n",
      "115/115 [==============================] - 0s 3ms/step - loss: 0.0313 - val_loss: 0.0155\n",
      "Epoch 12/80\n",
      "115/115 [==============================] - 0s 3ms/step - loss: 0.0291 - val_loss: 0.0158\n",
      "Epoch 13/80\n",
      "115/115 [==============================] - 0s 3ms/step - loss: 0.0288 - val_loss: 0.0102\n",
      "Epoch 14/80\n",
      "115/115 [==============================] - 0s 3ms/step - loss: 0.0288 - val_loss: 0.0105\n",
      "Epoch 15/80\n",
      "115/115 [==============================] - 0s 3ms/step - loss: 0.0286 - val_loss: 0.0104\n",
      "Epoch 16/80\n",
      "115/115 [==============================] - 0s 3ms/step - loss: 0.0283 - val_loss: 0.0105\n",
      "Epoch 17/80\n",
      "115/115 [==============================] - 0s 3ms/step - loss: 0.0286 - val_loss: 0.0117\n",
      "Epoch 18/80\n",
      "115/115 [==============================] - 0s 3ms/step - loss: 0.0285 - val_loss: 0.0142\n",
      "Epoch 19/80\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "115/115 [==============================] - 0s 3ms/step - loss: 0.0279 - val_loss: 0.0115\n",
      "Epoch 20/80\n",
      "115/115 [==============================] - 0s 3ms/step - loss: 0.0287 - val_loss: 0.0138\n",
      "Epoch 21/80\n",
      "115/115 [==============================] - 0s 3ms/step - loss: 0.0275 - val_loss: 0.0113\n",
      "Epoch 22/80\n",
      "115/115 [==============================] - 0s 3ms/step - loss: 0.0285 - val_loss: 0.0130\n",
      "Epoch 23/80\n",
      "115/115 [==============================] - 0s 3ms/step - loss: 0.0274 - val_loss: 0.0111\n",
      "Epoch 24/80\n",
      "115/115 [==============================] - 0s 3ms/step - loss: 0.0283 - val_loss: 0.0128\n",
      "Epoch 25/80\n",
      "115/115 [==============================] - 0s 3ms/step - loss: 0.0272 - val_loss: 0.0112\n",
      "Epoch 26/80\n",
      "115/115 [==============================] - 0s 3ms/step - loss: 0.0276 - val_loss: 0.0122\n",
      "Epoch 27/80\n",
      "115/115 [==============================] - 0s 3ms/step - loss: 0.0277 - val_loss: 0.0110\n",
      "Epoch 28/80\n",
      "115/115 [==============================] - 0s 3ms/step - loss: 0.0273 - val_loss: 0.0112\n",
      "Epoch 29/80\n",
      "115/115 [==============================] - 0s 3ms/step - loss: 0.0274 - val_loss: 0.0114\n",
      "Epoch 30/80\n",
      "115/115 [==============================] - 0s 3ms/step - loss: 0.0272 - val_loss: 0.0113\n",
      "Epoch 31/80\n",
      "115/115 [==============================] - 0s 3ms/step - loss: 0.0270 - val_loss: 0.0110\n",
      "Epoch 32/80\n",
      "115/115 [==============================] - 0s 3ms/step - loss: 0.0271 - val_loss: 0.0111\n",
      "Epoch 33/80\n",
      "115/115 [==============================] - 0s 3ms/step - loss: 0.0269 - val_loss: 0.0109\n",
      "Epoch 34/80\n",
      "115/115 [==============================] - 0s 3ms/step - loss: 0.0269 - val_loss: 0.0111\n",
      "Epoch 35/80\n",
      "115/115 [==============================] - 0s 3ms/step - loss: 0.0267 - val_loss: 0.0111\n",
      "Epoch 36/80\n",
      "115/115 [==============================] - 0s 3ms/step - loss: 0.0261 - val_loss: 0.0106\n",
      "Epoch 37/80\n",
      "115/115 [==============================] - 0s 3ms/step - loss: 0.0267 - val_loss: 0.0115\n",
      "Epoch 38/80\n",
      "115/115 [==============================] - 0s 3ms/step - loss: 0.0256 - val_loss: 0.0105\n",
      "Epoch 39/80\n",
      "115/115 [==============================] - 0s 3ms/step - loss: 0.0262 - val_loss: 0.0115\n",
      "Epoch 40/80\n",
      "115/115 [==============================] - 0s 3ms/step - loss: 0.0254 - val_loss: 0.0104\n",
      "Epoch 41/80\n",
      "115/115 [==============================] - 0s 3ms/step - loss: 0.0259 - val_loss: 0.0116\n",
      "Epoch 42/80\n",
      "115/115 [==============================] - 0s 3ms/step - loss: 0.0250 - val_loss: 0.0103\n",
      "Epoch 43/80\n",
      "115/115 [==============================] - 0s 3ms/step - loss: 0.0255 - val_loss: 0.0111\n",
      "Epoch 44/80\n",
      "115/115 [==============================] - 0s 3ms/step - loss: 0.0247 - val_loss: 0.0103\n",
      "Epoch 45/80\n",
      "115/115 [==============================] - 0s 3ms/step - loss: 0.0251 - val_loss: 0.0108\n",
      "Epoch 46/80\n",
      "115/115 [==============================] - 0s 3ms/step - loss: 0.0246 - val_loss: 0.0105\n",
      "Epoch 47/80\n",
      "115/115 [==============================] - 0s 3ms/step - loss: 0.0245 - val_loss: 0.0105\n",
      "Epoch 48/80\n",
      "115/115 [==============================] - 0s 3ms/step - loss: 0.0243 - val_loss: 0.0104\n",
      "Epoch 49/80\n",
      "115/115 [==============================] - 0s 3ms/step - loss: 0.0242 - val_loss: 0.0108\n",
      "Epoch 50/80\n",
      "115/115 [==============================] - 0s 3ms/step - loss: 0.0238 - val_loss: 0.0106\n",
      "Epoch 51/80\n",
      "115/115 [==============================] - 0s 3ms/step - loss: 0.0236 - val_loss: 0.0106\n",
      "Epoch 52/80\n",
      "115/115 [==============================] - 0s 3ms/step - loss: 0.0236 - val_loss: 0.0107\n",
      "Epoch 53/80\n",
      "115/115 [==============================] - 0s 3ms/step - loss: 0.0233 - val_loss: 0.0106\n",
      "Epoch 54/80\n",
      "115/115 [==============================] - 0s 3ms/step - loss: 0.0232 - val_loss: 0.0105\n",
      "Epoch 55/80\n",
      "115/115 [==============================] - 0s 3ms/step - loss: 0.0229 - val_loss: 0.0104\n",
      "Epoch 56/80\n",
      "115/115 [==============================] - 0s 3ms/step - loss: 0.0227 - val_loss: 0.0101\n",
      "Epoch 57/80\n",
      "115/115 [==============================] - 0s 3ms/step - loss: 0.0228 - val_loss: 0.0100\n",
      "Epoch 58/80\n",
      "115/115 [==============================] - 0s 3ms/step - loss: 0.0227 - val_loss: 0.0098\n",
      "Epoch 59/80\n",
      "115/115 [==============================] - 0s 3ms/step - loss: 0.0229 - val_loss: 0.0097\n",
      "Epoch 60/80\n",
      "115/115 [==============================] - 0s 3ms/step - loss: 0.0225 - val_loss: 0.0101\n",
      "Epoch 61/80\n",
      "115/115 [==============================] - 0s 3ms/step - loss: 0.0227 - val_loss: 0.0098\n",
      "Epoch 62/80\n",
      "115/115 [==============================] - 0s 3ms/step - loss: 0.0224 - val_loss: 0.0101\n",
      "Epoch 63/80\n",
      "115/115 [==============================] - 0s 3ms/step - loss: 0.0225 - val_loss: 0.0099\n",
      "Epoch 64/80\n",
      "115/115 [==============================] - 0s 3ms/step - loss: 0.0224 - val_loss: 0.0101\n",
      "Epoch 65/80\n",
      "115/115 [==============================] - 0s 3ms/step - loss: 0.0225 - val_loss: 0.0097\n",
      "Epoch 66/80\n",
      "115/115 [==============================] - 0s 3ms/step - loss: 0.0224 - val_loss: 0.0099\n",
      "Epoch 67/80\n",
      "115/115 [==============================] - 0s 3ms/step - loss: 0.0223 - val_loss: 0.0100\n",
      "Epoch 68/80\n",
      "115/115 [==============================] - 0s 3ms/step - loss: 0.0225 - val_loss: 0.0096\n",
      "Epoch 69/80\n",
      "115/115 [==============================] - 0s 3ms/step - loss: 0.0224 - val_loss: 0.0106\n",
      "Epoch 70/80\n",
      "115/115 [==============================] - 0s 3ms/step - loss: 0.0225 - val_loss: 0.0097\n",
      "Epoch 71/80\n",
      "115/115 [==============================] - 0s 3ms/step - loss: 0.0223 - val_loss: 0.0105\n",
      "Epoch 72/80\n",
      "115/115 [==============================] - 0s 3ms/step - loss: 0.0224 - val_loss: 0.0098\n",
      "Epoch 73/80\n",
      "115/115 [==============================] - 0s 3ms/step - loss: 0.0223 - val_loss: 0.0099\n",
      "Epoch 74/80\n",
      "115/115 [==============================] - 0s 3ms/step - loss: 0.0223 - val_loss: 0.0102\n",
      "Epoch 75/80\n",
      "115/115 [==============================] - 0s 3ms/step - loss: 0.0223 - val_loss: 0.0102\n",
      "Epoch 76/80\n",
      "115/115 [==============================] - 0s 3ms/step - loss: 0.0223 - val_loss: 0.0096\n",
      "Epoch 77/80\n",
      "115/115 [==============================] - 0s 3ms/step - loss: 0.0222 - val_loss: 0.0105\n",
      "Epoch 78/80\n",
      "115/115 [==============================] - 0s 3ms/step - loss: 0.0223 - val_loss: 0.0097\n",
      "Epoch 79/80\n",
      "115/115 [==============================] - 0s 3ms/step - loss: 0.0223 - val_loss: 0.0099\n",
      "Epoch 80/80\n",
      "115/115 [==============================] - 0s 3ms/step - loss: 0.0222 - val_loss: 0.0100\n",
      "Execution time:  26.248983144760132\n",
      "DNN:\n",
      "Mean Absolute Error: 0.0212\n",
      "Root Mean Square Error: 0.0333\n",
      "Mean Square Error: 0.0011\n",
      "\n",
      "Train RMSE: 0.033\n",
      "Train MSE: 0.001\n",
      "Train MAE: 0.021\n",
      "###########################\n",
      "\n",
      "MODEL:  DNN\n",
      "sequence:  6h\n",
      "units:  80\n",
      "dropout1:  0.11814836227952394\n",
      "optimizer: adamax\n",
      "activationDense: tanh\n",
      "epochs: 90\n",
      "batchsize: 25\n",
      "validation_split: 0.1\n",
      "Model: \"sequential_97\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_291 (Dense)            (None, 36, 80)            160       \n",
      "_________________________________________________________________\n",
      "dense_292 (Dense)            (None, 36, 16)            1296      \n",
      "_________________________________________________________________\n",
      "dropout_97 (Dropout)         (None, 36, 16)            0         \n",
      "_________________________________________________________________\n",
      "dense_293 (Dense)            (None, 36, 1)             17        \n",
      "=================================================================\n",
      "Total params: 1,473\n",
      "Trainable params: 1,473\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/90\n",
      "143/143 [==============================] - 1s 4ms/step - loss: 0.0973 - val_loss: 0.0191\n",
      "Epoch 2/90\n",
      "143/143 [==============================] - 0s 3ms/step - loss: 0.0486 - val_loss: 0.0167\n",
      "Epoch 3/90\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.0468 - val_loss: 0.0144\n",
      "Epoch 4/90\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.0449 - val_loss: 0.0135\n",
      "Epoch 5/90\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.0435 - val_loss: 0.0107\n",
      "Epoch 6/90\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.0421 - val_loss: 0.0091\n",
      "Epoch 7/90\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.0407 - val_loss: 0.0064\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/90\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.0391 - val_loss: 0.0054\n",
      "Epoch 9/90\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.0379 - val_loss: 0.0050\n",
      "Epoch 10/90\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.0366 - val_loss: 0.0058\n",
      "Epoch 11/90\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.0354 - val_loss: 0.0067\n",
      "Epoch 12/90\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.0343 - val_loss: 0.0078\n",
      "Epoch 13/90\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.0332 - val_loss: 0.0085\n",
      "Epoch 14/90\n",
      "143/143 [==============================] - 0s 3ms/step - loss: 0.0322 - val_loss: 0.0091\n",
      "Epoch 15/90\n",
      "143/143 [==============================] - 0s 3ms/step - loss: 0.0315 - val_loss: 0.0101\n",
      "Epoch 16/90\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.0306 - val_loss: 0.0118\n",
      "Epoch 17/90\n",
      "143/143 [==============================] - 0s 3ms/step - loss: 0.0296 - val_loss: 0.0127\n",
      "Epoch 18/90\n",
      "143/143 [==============================] - 0s 3ms/step - loss: 0.0287 - val_loss: 0.0130\n",
      "Epoch 19/90\n",
      "143/143 [==============================] - 0s 3ms/step - loss: 0.0281 - val_loss: 0.0142\n",
      "Epoch 20/90\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.0274 - val_loss: 0.0138\n",
      "Epoch 21/90\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.0270 - val_loss: 0.0141\n",
      "Epoch 22/90\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.0265 - val_loss: 0.0158\n",
      "Epoch 23/90\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.0260 - val_loss: 0.0151\n",
      "Epoch 24/90\n",
      "143/143 [==============================] - 0s 3ms/step - loss: 0.0257 - val_loss: 0.0150\n",
      "Epoch 25/90\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.0254 - val_loss: 0.0154\n",
      "Epoch 26/90\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.0253 - val_loss: 0.0160\n",
      "Epoch 27/90\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.0248 - val_loss: 0.0151\n",
      "Epoch 28/90\n",
      "143/143 [==============================] - 0s 3ms/step - loss: 0.0245 - val_loss: 0.0154\n",
      "Epoch 29/90\n",
      "143/143 [==============================] - 0s 3ms/step - loss: 0.0242 - val_loss: 0.0151\n",
      "Epoch 30/90\n",
      "143/143 [==============================] - 0s 3ms/step - loss: 0.0241 - val_loss: 0.0149\n",
      "Epoch 31/90\n",
      "143/143 [==============================] - 0s 3ms/step - loss: 0.0238 - val_loss: 0.0148\n",
      "Epoch 32/90\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.0236 - val_loss: 0.0150\n",
      "Epoch 33/90\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.0233 - val_loss: 0.0139\n",
      "Epoch 34/90\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.0232 - val_loss: 0.0139\n",
      "Epoch 35/90\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.0229 - val_loss: 0.0140\n",
      "Epoch 36/90\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.0227 - val_loss: 0.0143\n",
      "Epoch 37/90\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.0225 - val_loss: 0.0164\n",
      "Epoch 38/90\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.0223 - val_loss: 0.0185\n",
      "Epoch 39/90\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.0224 - val_loss: 0.0197\n",
      "Epoch 40/90\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.0219 - val_loss: 0.0194\n",
      "Epoch 41/90\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.0218 - val_loss: 0.0208\n",
      "Epoch 42/90\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.0218 - val_loss: 0.0201\n",
      "Epoch 43/90\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.0212 - val_loss: 0.0194\n",
      "Epoch 44/90\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.0212 - val_loss: 0.0179\n",
      "Epoch 45/90\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.0213 - val_loss: 0.0184\n",
      "Epoch 46/90\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.0209 - val_loss: 0.0175\n",
      "Epoch 47/90\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.0205 - val_loss: 0.0166\n",
      "Epoch 48/90\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.0203 - val_loss: 0.0162\n",
      "Epoch 49/90\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.0202 - val_loss: 0.0170\n",
      "Epoch 50/90\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.0200 - val_loss: 0.0169\n",
      "Epoch 51/90\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.0198 - val_loss: 0.0154\n",
      "Epoch 52/90\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.0197 - val_loss: 0.0150\n",
      "Epoch 53/90\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.0195 - val_loss: 0.0143\n",
      "Epoch 54/90\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.0194 - val_loss: 0.0128\n",
      "Epoch 55/90\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.0192 - val_loss: 0.0122\n",
      "Epoch 56/90\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.0190 - val_loss: 0.0139\n",
      "Epoch 57/90\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.0192 - val_loss: 0.0126\n",
      "Epoch 58/90\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.0190 - val_loss: 0.0124\n",
      "Epoch 59/90\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.0190 - val_loss: 0.0123\n",
      "Epoch 60/90\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.0189 - val_loss: 0.0123\n",
      "Epoch 61/90\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.0190 - val_loss: 0.0124\n",
      "Epoch 62/90\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.0189 - val_loss: 0.0125\n",
      "Epoch 63/90\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.0188 - val_loss: 0.0124\n",
      "Epoch 64/90\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.0188 - val_loss: 0.0140\n",
      "Epoch 65/90\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.0188 - val_loss: 0.0121\n",
      "Epoch 66/90\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.0187 - val_loss: 0.0132\n",
      "Epoch 67/90\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.0187 - val_loss: 0.0129\n",
      "Epoch 68/90\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.0188 - val_loss: 0.0128\n",
      "Epoch 69/90\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.0187 - val_loss: 0.0123\n",
      "Epoch 70/90\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.0187 - val_loss: 0.0133\n",
      "Epoch 71/90\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.0186 - val_loss: 0.0143\n",
      "Epoch 72/90\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.0187 - val_loss: 0.0120\n",
      "Epoch 73/90\n",
      "143/143 [==============================] - 0s 3ms/step - loss: 0.0186 - val_loss: 0.0134\n",
      "Epoch 74/90\n",
      "143/143 [==============================] - 0s 3ms/step - loss: 0.0185 - val_loss: 0.0123\n",
      "Epoch 75/90\n",
      "143/143 [==============================] - 0s 3ms/step - loss: 0.0185 - val_loss: 0.0123\n",
      "Epoch 76/90\n",
      "143/143 [==============================] - 0s 3ms/step - loss: 0.0185 - val_loss: 0.0132\n",
      "Epoch 77/90\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.0185 - val_loss: 0.0123\n",
      "Epoch 78/90\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.0185 - val_loss: 0.0132\n",
      "Epoch 79/90\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.0186 - val_loss: 0.0126\n",
      "Epoch 80/90\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.0184 - val_loss: 0.0132\n",
      "Epoch 81/90\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.0184 - val_loss: 0.0139\n",
      "Epoch 82/90\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.0185 - val_loss: 0.0126\n",
      "Epoch 83/90\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.0184 - val_loss: 0.0135\n",
      "Epoch 84/90\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.0184 - val_loss: 0.0129\n",
      "Epoch 85/90\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.0184 - val_loss: 0.0139\n",
      "Epoch 86/90\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.0184 - val_loss: 0.0125\n",
      "Epoch 87/90\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.0183 - val_loss: 0.0123\n",
      "Epoch 88/90\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.0182 - val_loss: 0.0135\n",
      "Epoch 89/90\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "143/143 [==============================] - 0s 2ms/step - loss: 0.0181 - val_loss: 0.0124\n",
      "Epoch 90/90\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.0183 - val_loss: 0.0145\n",
      "Execution time:  32.98895621299744\n",
      "DNN:\n",
      "Mean Absolute Error: 0.0167\n",
      "Root Mean Square Error: 0.0272\n",
      "Mean Square Error: 0.0007\n",
      "\n",
      "Train RMSE: 0.027\n",
      "Train MSE: 0.001\n",
      "Train MAE: 0.017\n",
      "###########################\n",
      "\n",
      "MODEL:  DNN\n",
      "sequence:  6h\n",
      "units:  12\n",
      "dropout1:  0.48476373451509647\n",
      "optimizer: adamax\n",
      "activationDense: tanh\n",
      "epochs: 52\n",
      "batchsize: 57\n",
      "validation_split: 0.1\n",
      "Model: \"sequential_98\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_294 (Dense)            (None, 36, 12)            24        \n",
      "_________________________________________________________________\n",
      "dense_295 (Dense)            (None, 36, 16)            208       \n",
      "_________________________________________________________________\n",
      "dropout_98 (Dropout)         (None, 36, 16)            0         \n",
      "_________________________________________________________________\n",
      "dense_296 (Dense)            (None, 36, 1)             17        \n",
      "=================================================================\n",
      "Total params: 249\n",
      "Trainable params: 249\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/52\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.4063 - val_loss: 0.2297\n",
      "Epoch 2/52\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.1793 - val_loss: 0.0595\n",
      "Epoch 3/52\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.1049 - val_loss: 0.0205\n",
      "Epoch 4/52\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.0934 - val_loss: 0.0204\n",
      "Epoch 5/52\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0854 - val_loss: 0.0149\n",
      "Epoch 6/52\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0767 - val_loss: 0.0070\n",
      "Epoch 7/52\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.0684 - val_loss: 0.0062\n",
      "Epoch 8/52\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.0612 - val_loss: 0.0083\n",
      "Epoch 9/52\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.0548 - val_loss: 0.0091\n",
      "Epoch 10/52\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0493 - val_loss: 0.0085\n",
      "Epoch 11/52\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.0450 - val_loss: 0.0079\n",
      "Epoch 12/52\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.0415 - val_loss: 0.0084\n",
      "Epoch 13/52\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0385 - val_loss: 0.0100\n",
      "Epoch 14/52\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0356 - val_loss: 0.0109\n",
      "Epoch 15/52\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.0333 - val_loss: 0.0120\n",
      "Epoch 16/52\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.0313 - val_loss: 0.0135\n",
      "Epoch 17/52\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.0297 - val_loss: 0.0139\n",
      "Epoch 18/52\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0285 - val_loss: 0.0134\n",
      "Epoch 19/52\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.0279 - val_loss: 0.0127\n",
      "Epoch 20/52\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.0276 - val_loss: 0.0127\n",
      "Epoch 21/52\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0273 - val_loss: 0.0124\n",
      "Epoch 22/52\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0272 - val_loss: 0.0123\n",
      "Epoch 23/52\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.0271 - val_loss: 0.0126\n",
      "Epoch 24/52\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0270 - val_loss: 0.0131\n",
      "Epoch 25/52\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.0268 - val_loss: 0.0130\n",
      "Epoch 26/52\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.0268 - val_loss: 0.0130\n",
      "Epoch 27/52\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.0267 - val_loss: 0.0130\n",
      "Epoch 28/52\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.0265 - val_loss: 0.0131\n",
      "Epoch 29/52\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0264 - val_loss: 0.0127\n",
      "Epoch 30/52\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0264 - val_loss: 0.0127\n",
      "Epoch 31/52\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.0262 - val_loss: 0.0121\n",
      "Epoch 32/52\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0262 - val_loss: 0.0124\n",
      "Epoch 33/52\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0260 - val_loss: 0.0123\n",
      "Epoch 34/52\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.0260 - val_loss: 0.0128\n",
      "Epoch 35/52\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.0258 - val_loss: 0.0129\n",
      "Epoch 36/52\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0257 - val_loss: 0.0135\n",
      "Epoch 37/52\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0255 - val_loss: 0.0134\n",
      "Epoch 38/52\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.0252 - val_loss: 0.0129\n",
      "Epoch 39/52\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.0251 - val_loss: 0.0129\n",
      "Epoch 40/52\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0250 - val_loss: 0.0125\n",
      "Epoch 41/52\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.0249 - val_loss: 0.0126\n",
      "Epoch 42/52\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.0246 - val_loss: 0.0121\n",
      "Epoch 43/52\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.0245 - val_loss: 0.0121\n",
      "Epoch 44/52\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0242 - val_loss: 0.0118\n",
      "Epoch 45/52\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.0241 - val_loss: 0.0113\n",
      "Epoch 46/52\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.0239 - val_loss: 0.0108\n",
      "Epoch 47/52\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0239 - val_loss: 0.0106\n",
      "Epoch 48/52\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0236 - val_loss: 0.0105\n",
      "Epoch 49/52\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0234 - val_loss: 0.0103\n",
      "Epoch 50/52\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.0232 - val_loss: 0.0104\n",
      "Epoch 51/52\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0229 - val_loss: 0.0100\n",
      "Epoch 52/52\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.0228 - val_loss: 0.0106\n",
      "Execution time:  9.37382435798645\n",
      "DNN:\n",
      "Mean Absolute Error: 0.0190\n",
      "Root Mean Square Error: 0.0316\n",
      "Mean Square Error: 0.0010\n",
      "\n",
      "Train RMSE: 0.032\n",
      "Train MSE: 0.001\n",
      "Train MAE: 0.019\n",
      "###########################\n",
      "\n",
      "MODEL:  DNN\n",
      "sequence:  6h\n",
      "units:  87\n",
      "dropout1:  0.40519643149940265\n",
      "optimizer: adamax\n",
      "activationDense: tanh\n",
      "epochs: 80\n",
      "batchsize: 31\n",
      "validation_split: 0.2\n",
      "Model: \"sequential_99\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_297 (Dense)            (None, 36, 87)            174       \n",
      "_________________________________________________________________\n",
      "dense_298 (Dense)            (None, 36, 16)            1408      \n",
      "_________________________________________________________________\n",
      "dropout_99 (Dropout)         (None, 36, 16)            0         \n",
      "_________________________________________________________________\n",
      "dense_299 (Dense)            (None, 36, 1)             17        \n",
      "=================================================================\n",
      "Total params: 1,599\n",
      "Trainable params: 1,599\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/80\n",
      "103/103 [==============================] - 0s 5ms/step - loss: 0.1290 - val_loss: 0.0330\n",
      "Epoch 2/80\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 0.0862 - val_loss: 0.0371\n",
      "Epoch 3/80\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 0.0807 - val_loss: 0.0358\n",
      "Epoch 4/80\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 0.0751 - val_loss: 0.0344\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/80\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 0.0693 - val_loss: 0.0308\n",
      "Epoch 6/80\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 0.0631 - val_loss: 0.0280\n",
      "Epoch 7/80\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 0.0578 - val_loss: 0.0229\n",
      "Epoch 8/80\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 0.0523 - val_loss: 0.0202\n",
      "Epoch 9/80\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 0.0476 - val_loss: 0.0215\n",
      "Epoch 10/80\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 0.0423 - val_loss: 0.0224\n",
      "Epoch 11/80\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 0.0389 - val_loss: 0.0198\n",
      "Epoch 12/80\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 0.0363 - val_loss: 0.0180\n",
      "Epoch 13/80\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 0.0339 - val_loss: 0.0180\n",
      "Epoch 14/80\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 0.0321 - val_loss: 0.0170\n",
      "Epoch 15/80\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 0.0306 - val_loss: 0.0164\n",
      "Epoch 16/80\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 0.0298 - val_loss: 0.0158\n",
      "Epoch 17/80\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 0.0288 - val_loss: 0.0156\n",
      "Epoch 18/80\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 0.0283 - val_loss: 0.0155\n",
      "Epoch 19/80\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 0.0277 - val_loss: 0.0154\n",
      "Epoch 20/80\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 0.0275 - val_loss: 0.0152\n",
      "Epoch 21/80\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 0.0275 - val_loss: 0.0150\n",
      "Epoch 22/80\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 0.0279 - val_loss: 0.0149\n",
      "Epoch 23/80\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 0.0273 - val_loss: 0.0150\n",
      "Epoch 24/80\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 0.0268 - val_loss: 0.0150\n",
      "Epoch 25/80\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 0.0265 - val_loss: 0.0150\n",
      "Epoch 26/80\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 0.0265 - val_loss: 0.0151\n",
      "Epoch 27/80\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 0.0272 - val_loss: 0.0151\n",
      "Epoch 28/80\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 0.0260 - val_loss: 0.0151\n",
      "Epoch 29/80\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 0.0266 - val_loss: 0.0153\n",
      "Epoch 30/80\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 0.0248 - val_loss: 0.0150\n",
      "Epoch 31/80\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 0.0259 - val_loss: 0.0148\n",
      "Epoch 32/80\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 0.0249 - val_loss: 0.0149\n",
      "Epoch 33/80\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 0.0250 - val_loss: 0.0149\n",
      "Epoch 34/80\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 0.0247 - val_loss: 0.0148\n",
      "Epoch 35/80\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 0.0247 - val_loss: 0.0148\n",
      "Epoch 36/80\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 0.0241 - val_loss: 0.0147\n",
      "Epoch 37/80\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 0.0240 - val_loss: 0.0148\n",
      "Epoch 38/80\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 0.0239 - val_loss: 0.0147\n",
      "Epoch 39/80\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 0.0235 - val_loss: 0.0147\n",
      "Epoch 40/80\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 0.0233 - val_loss: 0.0147\n",
      "Epoch 41/80\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 0.0232 - val_loss: 0.0146\n",
      "Epoch 42/80\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 0.0230 - val_loss: 0.0146\n",
      "Epoch 43/80\n",
      "103/103 [==============================] - ETA: 0s - loss: 0.026 - 0s 3ms/step - loss: 0.0227 - val_loss: 0.0147\n",
      "Epoch 44/80\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 0.0226 - val_loss: 0.0146\n",
      "Epoch 45/80\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 0.0223 - val_loss: 0.0146\n",
      "Epoch 46/80\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 0.0223 - val_loss: 0.0146\n",
      "Epoch 47/80\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 0.0218 - val_loss: 0.0146\n",
      "Epoch 48/80\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 0.0217 - val_loss: 0.0146\n",
      "Epoch 49/80\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 0.0217 - val_loss: 0.0145\n",
      "Epoch 50/80\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 0.0216 - val_loss: 0.0146\n",
      "Epoch 51/80\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 0.0216 - val_loss: 0.0146\n",
      "Epoch 52/80\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 0.0215 - val_loss: 0.0146\n",
      "Epoch 53/80\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 0.0212 - val_loss: 0.0145\n",
      "Epoch 54/80\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 0.0213 - val_loss: 0.0146\n",
      "Epoch 55/80\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 0.0213 - val_loss: 0.0146\n",
      "Epoch 56/80\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 0.0214 - val_loss: 0.0146\n",
      "Epoch 57/80\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 0.0211 - val_loss: 0.0145\n",
      "Epoch 58/80\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 0.0212 - val_loss: 0.0146\n",
      "Epoch 59/80\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 0.0209 - val_loss: 0.0145\n",
      "Epoch 60/80\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 0.0210 - val_loss: 0.0146\n",
      "Epoch 61/80\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 0.0210 - val_loss: 0.0145\n",
      "Epoch 62/80\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 0.0211 - val_loss: 0.0146\n",
      "Epoch 63/80\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 0.0209 - val_loss: 0.0145\n",
      "Epoch 64/80\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 0.0211 - val_loss: 0.0146\n",
      "Epoch 65/80\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 0.0210 - val_loss: 0.0145\n",
      "Epoch 66/80\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 0.0211 - val_loss: 0.0146\n",
      "Epoch 67/80\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 0.0207 - val_loss: 0.0145\n",
      "Epoch 68/80\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 0.0208 - val_loss: 0.0145\n",
      "Epoch 69/80\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 0.0209 - val_loss: 0.0146\n",
      "Epoch 70/80\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 0.0209 - val_loss: 0.0146\n",
      "Epoch 71/80\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 0.0210 - val_loss: 0.0146\n",
      "Epoch 72/80\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 0.0209 - val_loss: 0.0145\n",
      "Epoch 73/80\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 0.0209 - val_loss: 0.0146\n",
      "Epoch 74/80\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 0.0207 - val_loss: 0.0145\n",
      "Epoch 75/80\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 0.0210 - val_loss: 0.0146\n",
      "Epoch 76/80\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 0.0207 - val_loss: 0.0145\n",
      "Epoch 77/80\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 0.0208 - val_loss: 0.0146\n",
      "Epoch 78/80\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 0.0206 - val_loss: 0.0145\n",
      "Epoch 79/80\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 0.0207 - val_loss: 0.0146\n",
      "Epoch 80/80\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 0.0205 - val_loss: 0.0145\n",
      "Execution time:  24.636602640151978\n",
      "DNN:\n",
      "Mean Absolute Error: 0.0196\n",
      "Root Mean Square Error: 0.0306\n",
      "Mean Square Error: 0.0009\n",
      "\n",
      "Train RMSE: 0.031\n",
      "Train MSE: 0.001\n",
      "Train MAE: 0.020\n",
      "###########################\n",
      "\n",
      "MODEL:  DNN\n",
      "sequence:  6h\n",
      "units:  80\n",
      "dropout1:  0.11814836227952394\n",
      "optimizer: adamax\n",
      "activationDense: tanh\n",
      "epochs: 90\n",
      "batchsize: 25\n",
      "validation_split: 0.2\n",
      "Model: \"sequential_100\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_300 (Dense)            (None, 36, 80)            160       \n",
      "_________________________________________________________________\n",
      "dense_301 (Dense)            (None, 36, 16)            1296      \n",
      "_________________________________________________________________\n",
      "dropout_100 (Dropout)        (None, 36, 16)            0         \n",
      "_________________________________________________________________\n",
      "dense_302 (Dense)            (None, 36, 1)             17        \n",
      "=================================================================\n",
      "Total params: 1,473\n",
      "Trainable params: 1,473\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/90\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  1/127 [..............................] - ETA: 0s - loss: 0.4089WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0000s vs `on_train_batch_end` time: 0.0106s). Check your callbacks.\n",
      "127/127 [==============================] - 1s 4ms/step - loss: 0.0867 - val_loss: 0.0394\n",
      "Epoch 2/90\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 0.0498 - val_loss: 0.0387\n",
      "Epoch 3/90\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 0.0474 - val_loss: 0.0363\n",
      "Epoch 4/90\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 0.0453 - val_loss: 0.0318\n",
      "Epoch 5/90\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 0.0431 - val_loss: 0.0268\n",
      "Epoch 6/90\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 0.0409 - val_loss: 0.0250\n",
      "Epoch 7/90\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 0.0395 - val_loss: 0.0230\n",
      "Epoch 8/90\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 0.0384 - val_loss: 0.0193\n",
      "Epoch 9/90\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 0.0372 - val_loss: 0.0187\n",
      "Epoch 10/90\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 0.0366 - val_loss: 0.0191\n",
      "Epoch 11/90\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 0.0358 - val_loss: 0.0181\n",
      "Epoch 12/90\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 0.0348 - val_loss: 0.0192\n",
      "Epoch 13/90\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 0.0344 - val_loss: 0.0194\n",
      "Epoch 14/90\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 0.0337 - val_loss: 0.0242\n",
      "Epoch 15/90\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 0.0329 - val_loss: 0.0173\n",
      "Epoch 16/90\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 0.0318 - val_loss: 0.0162\n",
      "Epoch 17/90\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 0.0313 - val_loss: 0.0167\n",
      "Epoch 18/90\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 0.0307 - val_loss: 0.0160\n",
      "Epoch 19/90\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 0.0301 - val_loss: 0.0148\n",
      "Epoch 20/90\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 0.0296 - val_loss: 0.0155\n",
      "Epoch 21/90\n",
      "127/127 [==============================] - 0s 2ms/step - loss: 0.0290 - val_loss: 0.0151\n",
      "Epoch 22/90\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 0.0286 - val_loss: 0.0134\n",
      "Epoch 23/90\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 0.0277 - val_loss: 0.0130\n",
      "Epoch 24/90\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 0.0273 - val_loss: 0.0129\n",
      "Epoch 25/90\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 0.0269 - val_loss: 0.0129\n",
      "Epoch 26/90\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 0.0264 - val_loss: 0.0130\n",
      "Epoch 27/90\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 0.0262 - val_loss: 0.0128\n",
      "Epoch 28/90\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 0.0258 - val_loss: 0.0124\n",
      "Epoch 29/90\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 0.0253 - val_loss: 0.0127\n",
      "Epoch 30/90\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 0.0250 - val_loss: 0.0129\n",
      "Epoch 31/90\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 0.0247 - val_loss: 0.0129\n",
      "Epoch 32/90\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 0.0242 - val_loss: 0.0129\n",
      "Epoch 33/90\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 0.0240 - val_loss: 0.0129\n",
      "Epoch 34/90\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 0.0237 - val_loss: 0.0131\n",
      "Epoch 35/90\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 0.0235 - val_loss: 0.0131\n",
      "Epoch 36/90\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 0.0233 - val_loss: 0.0133\n",
      "Epoch 37/90\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 0.0231 - val_loss: 0.0133\n",
      "Epoch 38/90\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 0.0227 - val_loss: 0.0134\n",
      "Epoch 39/90\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 0.0227 - val_loss: 0.0132\n",
      "Epoch 40/90\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 0.0222 - val_loss: 0.0131\n",
      "Epoch 41/90\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 0.0220 - val_loss: 0.0133\n",
      "Epoch 42/90\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 0.0218 - val_loss: 0.0133\n",
      "Epoch 43/90\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 0.0215 - val_loss: 0.0133\n",
      "Epoch 44/90\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 0.0212 - val_loss: 0.0128\n",
      "Epoch 45/90\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 0.0211 - val_loss: 0.0128\n",
      "Epoch 46/90\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 0.0211 - val_loss: 0.0131\n",
      "Epoch 47/90\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 0.0208 - val_loss: 0.0131\n",
      "Epoch 48/90\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 0.0206 - val_loss: 0.0140\n",
      "Epoch 49/90\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 0.0209 - val_loss: 0.0140\n",
      "Epoch 50/90\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 0.0208 - val_loss: 0.0140\n",
      "Epoch 51/90\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 0.0205 - val_loss: 0.0137\n",
      "Epoch 52/90\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 0.0203 - val_loss: 0.0138\n",
      "Epoch 53/90\n",
      "127/127 [==============================] - 0s 2ms/step - loss: 0.0203 - val_loss: 0.0141\n",
      "Epoch 54/90\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 0.0202 - val_loss: 0.0142\n",
      "Epoch 55/90\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 0.0202 - val_loss: 0.0144\n",
      "Epoch 56/90\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 0.0202 - val_loss: 0.0143\n",
      "Epoch 57/90\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 0.0200 - val_loss: 0.0143\n",
      "Epoch 58/90\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 0.0199 - val_loss: 0.0146\n",
      "Epoch 59/90\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 0.0198 - val_loss: 0.0146\n",
      "Epoch 60/90\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 0.0197 - val_loss: 0.0147\n",
      "Epoch 61/90\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 0.0196 - val_loss: 0.0144\n",
      "Epoch 62/90\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 0.0193 - val_loss: 0.0146\n",
      "Epoch 63/90\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 0.0193 - val_loss: 0.0144\n",
      "Epoch 64/90\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 0.0192 - val_loss: 0.0143\n",
      "Epoch 65/90\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 0.0192 - val_loss: 0.0145\n",
      "Epoch 66/90\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 0.0192 - val_loss: 0.0145\n",
      "Epoch 67/90\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 0.0190 - val_loss: 0.0143\n",
      "Epoch 68/90\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 0.0189 - val_loss: 0.0143\n",
      "Epoch 69/90\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 0.0190 - val_loss: 0.0144\n",
      "Epoch 70/90\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 0.0188 - val_loss: 0.0144\n",
      "Epoch 71/90\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 0.0189 - val_loss: 0.0144\n",
      "Epoch 72/90\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 0.0189 - val_loss: 0.0144\n",
      "Epoch 73/90\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 0.0187 - val_loss: 0.0146\n",
      "Epoch 74/90\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 0.0187 - val_loss: 0.0145\n",
      "Epoch 75/90\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 0.0187 - val_loss: 0.0145\n",
      "Epoch 76/90\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 0.0188 - val_loss: 0.0145\n",
      "Epoch 77/90\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 0.0188 - val_loss: 0.0147\n",
      "Epoch 78/90\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 0.0187 - val_loss: 0.0145\n",
      "Epoch 79/90\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 0.0186 - val_loss: 0.0145\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 80/90\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 0.0186 - val_loss: 0.0146\n",
      "Epoch 81/90\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 0.0188 - val_loss: 0.0145\n",
      "Epoch 82/90\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 0.0186 - val_loss: 0.0145\n",
      "Epoch 83/90\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 0.0185 - val_loss: 0.0146\n",
      "Epoch 84/90\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 0.0186 - val_loss: 0.0145\n",
      "Epoch 85/90\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 0.0186 - val_loss: 0.0145\n",
      "Epoch 86/90\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 0.0186 - val_loss: 0.0147\n",
      "Epoch 87/90\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 0.0185 - val_loss: 0.0145\n",
      "Epoch 88/90\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 0.0186 - val_loss: 0.0145\n",
      "Epoch 89/90\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 0.0185 - val_loss: 0.0145\n",
      "Epoch 90/90\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 0.0186 - val_loss: 0.0147\n",
      "Execution time:  32.414623975753784\n",
      "DNN:\n",
      "Mean Absolute Error: 0.0175\n",
      "Root Mean Square Error: 0.0285\n",
      "Mean Square Error: 0.0008\n",
      "\n",
      "Train RMSE: 0.029\n",
      "Train MSE: 0.001\n",
      "Train MAE: 0.017\n",
      "###########################\n",
      "\n",
      "MODEL:  DNN\n",
      "sequence:  6h\n",
      "units:  12\n",
      "dropout1:  0.48476373451509647\n",
      "optimizer: adamax\n",
      "activationDense: tanh\n",
      "epochs: 52\n",
      "batchsize: 57\n",
      "validation_split: 0.2\n",
      "Model: \"sequential_101\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_303 (Dense)            (None, 36, 12)            24        \n",
      "_________________________________________________________________\n",
      "dense_304 (Dense)            (None, 36, 16)            208       \n",
      "_________________________________________________________________\n",
      "dropout_101 (Dropout)        (None, 36, 16)            0         \n",
      "_________________________________________________________________\n",
      "dense_305 (Dense)            (None, 36, 1)             17        \n",
      "=================================================================\n",
      "Total params: 249\n",
      "Trainable params: 249\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/52\n",
      "56/56 [==============================] - 0s 6ms/step - loss: 0.4200 - val_loss: 0.2630\n",
      "Epoch 2/52\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 0.1976 - val_loss: 0.0851\n",
      "Epoch 3/52\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 0.1028 - val_loss: 0.0239\n",
      "Epoch 4/52\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 0.0914 - val_loss: 0.0166\n",
      "Epoch 5/52\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 0.0843 - val_loss: 0.0150\n",
      "Epoch 6/52\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 0.0783 - val_loss: 0.0146\n",
      "Epoch 7/52\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 0.0727 - val_loss: 0.0154\n",
      "Epoch 8/52\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 0.0668 - val_loss: 0.0156\n",
      "Epoch 9/52\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 0.0616 - val_loss: 0.0151\n",
      "Epoch 10/52\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 0.0568 - val_loss: 0.0147\n",
      "Epoch 11/52\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 0.0522 - val_loss: 0.0147\n",
      "Epoch 12/52\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 0.0485 - val_loss: 0.0147\n",
      "Epoch 13/52\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 0.0451 - val_loss: 0.0153\n",
      "Epoch 14/52\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 0.0420 - val_loss: 0.0160\n",
      "Epoch 15/52\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 0.0391 - val_loss: 0.0166\n",
      "Epoch 16/52\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 0.0366 - val_loss: 0.0171\n",
      "Epoch 17/52\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 0.0344 - val_loss: 0.0178\n",
      "Epoch 18/52\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 0.0327 - val_loss: 0.0182\n",
      "Epoch 19/52\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 0.0312 - val_loss: 0.0184\n",
      "Epoch 20/52\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 0.0300 - val_loss: 0.0184\n",
      "Epoch 21/52\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 0.0290 - val_loss: 0.0178\n",
      "Epoch 22/52\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 0.0285 - val_loss: 0.0175\n",
      "Epoch 23/52\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 0.0282 - val_loss: 0.0172\n",
      "Epoch 24/52\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 0.0280 - val_loss: 0.0172\n",
      "Epoch 25/52\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 0.0277 - val_loss: 0.0172\n",
      "Epoch 26/52\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 0.0275 - val_loss: 0.0170\n",
      "Epoch 27/52\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 0.0274 - val_loss: 0.0170\n",
      "Epoch 28/52\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 0.0273 - val_loss: 0.0170\n",
      "Epoch 29/52\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 0.0272 - val_loss: 0.0169\n",
      "Epoch 30/52\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 0.0271 - val_loss: 0.0168\n",
      "Epoch 31/52\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 0.0270 - val_loss: 0.0168\n",
      "Epoch 32/52\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 0.0268 - val_loss: 0.0168\n",
      "Epoch 33/52\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 0.0268 - val_loss: 0.0169\n",
      "Epoch 34/52\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 0.0266 - val_loss: 0.0169\n",
      "Epoch 35/52\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 0.0264 - val_loss: 0.0168\n",
      "Epoch 36/52\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 0.0264 - val_loss: 0.0168\n",
      "Epoch 37/52\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 0.0262 - val_loss: 0.0169\n",
      "Epoch 38/52\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 0.0261 - val_loss: 0.0169\n",
      "Epoch 39/52\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 0.0259 - val_loss: 0.0168\n",
      "Epoch 40/52\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 0.0258 - val_loss: 0.0168\n",
      "Epoch 41/52\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 0.0256 - val_loss: 0.0166\n",
      "Epoch 42/52\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 0.0255 - val_loss: 0.0164\n",
      "Epoch 43/52\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 0.0255 - val_loss: 0.0163\n",
      "Epoch 44/52\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 0.0252 - val_loss: 0.0162\n",
      "Epoch 45/52\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 0.0250 - val_loss: 0.0161\n",
      "Epoch 46/52\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 0.0249 - val_loss: 0.0159\n",
      "Epoch 47/52\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 0.0247 - val_loss: 0.0158\n",
      "Epoch 48/52\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 0.0245 - val_loss: 0.0156\n",
      "Epoch 49/52\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 0.0244 - val_loss: 0.0154\n",
      "Epoch 50/52\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 0.0243 - val_loss: 0.0153\n",
      "Epoch 51/52\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 0.0240 - val_loss: 0.0151\n",
      "Epoch 52/52\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 0.0239 - val_loss: 0.0149\n",
      "Execution time:  9.131410360336304\n",
      "DNN:\n",
      "Mean Absolute Error: 0.0193\n",
      "Root Mean Square Error: 0.0324\n",
      "Mean Square Error: 0.0010\n",
      "\n",
      "Train RMSE: 0.032\n",
      "Train MSE: 0.001\n",
      "Train MAE: 0.019\n",
      "###########################\n",
      "\n",
      "MODEL:  DNN\n",
      "sequence:  6h\n",
      "units:  87\n",
      "dropout1:  0.40519643149940265\n",
      "optimizer: adamax\n",
      "activationDense: sigmoid\n",
      "epochs: 80\n",
      "batchsize: 31\n",
      "validation_split: 0.1\n",
      "Model: \"sequential_102\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_306 (Dense)            (None, 36, 87)            174       \n",
      "_________________________________________________________________\n",
      "dense_307 (Dense)            (None, 36, 16)            1408      \n",
      "_________________________________________________________________\n",
      "dropout_102 (Dropout)        (None, 36, 16)            0         \n",
      "_________________________________________________________________\n",
      "dense_308 (Dense)            (None, 36, 1)             17        \n",
      "=================================================================\n",
      "Total params: 1,599\n",
      "Trainable params: 1,599\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/80\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "115/115 [==============================] - 0s 4ms/step - loss: 0.0484 - val_loss: 0.0313\n",
      "Epoch 2/80\n",
      "115/115 [==============================] - 0s 3ms/step - loss: 0.0411 - val_loss: 0.0271\n",
      "Epoch 3/80\n",
      "115/115 [==============================] - 0s 3ms/step - loss: 0.0397 - val_loss: 0.0260\n",
      "Epoch 4/80\n",
      "115/115 [==============================] - 0s 3ms/step - loss: 0.0386 - val_loss: 0.0252\n",
      "Epoch 5/80\n",
      "115/115 [==============================] - 0s 3ms/step - loss: 0.0377 - val_loss: 0.0240\n",
      "Epoch 6/80\n",
      "115/115 [==============================] - 0s 3ms/step - loss: 0.0370 - val_loss: 0.0228\n",
      "Epoch 7/80\n",
      "115/115 [==============================] - 0s 3ms/step - loss: 0.0361 - val_loss: 0.0220\n",
      "Epoch 8/80\n",
      "115/115 [==============================] - 0s 3ms/step - loss: 0.0353 - val_loss: 0.0208\n",
      "Epoch 9/80\n",
      "115/115 [==============================] - 0s 3ms/step - loss: 0.0347 - val_loss: 0.0201\n",
      "Epoch 10/80\n",
      "115/115 [==============================] - 0s 3ms/step - loss: 0.0339 - val_loss: 0.0195\n",
      "Epoch 11/80\n",
      "115/115 [==============================] - 0s 3ms/step - loss: 0.0333 - val_loss: 0.0192\n",
      "Epoch 12/80\n",
      "115/115 [==============================] - 0s 3ms/step - loss: 0.0328 - val_loss: 0.0183\n",
      "Epoch 13/80\n",
      "115/115 [==============================] - 0s 3ms/step - loss: 0.0320 - val_loss: 0.0178\n",
      "Epoch 14/80\n",
      "115/115 [==============================] - 0s 3ms/step - loss: 0.0316 - val_loss: 0.0171\n",
      "Epoch 15/80\n",
      "115/115 [==============================] - 0s 3ms/step - loss: 0.0312 - val_loss: 0.0165\n",
      "Epoch 16/80\n",
      "115/115 [==============================] - 0s 3ms/step - loss: 0.0308 - val_loss: 0.0160\n",
      "Epoch 17/80\n",
      "115/115 [==============================] - 0s 3ms/step - loss: 0.0303 - val_loss: 0.0156\n",
      "Epoch 18/80\n",
      "115/115 [==============================] - 0s 3ms/step - loss: 0.0298 - val_loss: 0.0153\n",
      "Epoch 19/80\n",
      "115/115 [==============================] - 0s 3ms/step - loss: 0.0294 - val_loss: 0.0149\n",
      "Epoch 20/80\n",
      "115/115 [==============================] - 0s 3ms/step - loss: 0.0290 - val_loss: 0.0147\n",
      "Epoch 21/80\n",
      "115/115 [==============================] - 0s 3ms/step - loss: 0.0287 - val_loss: 0.0144\n",
      "Epoch 22/80\n",
      "115/115 [==============================] - 0s 3ms/step - loss: 0.0283 - val_loss: 0.0143\n",
      "Epoch 23/80\n",
      "115/115 [==============================] - 0s 3ms/step - loss: 0.0280 - val_loss: 0.0139\n",
      "Epoch 24/80\n",
      "115/115 [==============================] - 0s 3ms/step - loss: 0.0278 - val_loss: 0.0136\n",
      "Epoch 25/80\n",
      "115/115 [==============================] - 0s 3ms/step - loss: 0.0275 - val_loss: 0.0133\n",
      "Epoch 26/80\n",
      "115/115 [==============================] - 0s 3ms/step - loss: 0.0272 - val_loss: 0.0132\n",
      "Epoch 27/80\n",
      "115/115 [==============================] - 0s 3ms/step - loss: 0.0270 - val_loss: 0.0128\n",
      "Epoch 28/80\n",
      "115/115 [==============================] - 0s 3ms/step - loss: 0.0268 - val_loss: 0.0128\n",
      "Epoch 29/80\n",
      "115/115 [==============================] - 0s 3ms/step - loss: 0.0265 - val_loss: 0.0123\n",
      "Epoch 30/80\n",
      "115/115 [==============================] - 0s 3ms/step - loss: 0.0264 - val_loss: 0.0121\n",
      "Epoch 31/80\n",
      "115/115 [==============================] - 0s 3ms/step - loss: 0.0262 - val_loss: 0.0119\n",
      "Epoch 32/80\n",
      "115/115 [==============================] - 0s 3ms/step - loss: 0.0261 - val_loss: 0.0123\n",
      "Epoch 33/80\n",
      "115/115 [==============================] - 0s 3ms/step - loss: 0.0261 - val_loss: 0.0114\n",
      "Epoch 34/80\n",
      "115/115 [==============================] - 0s 3ms/step - loss: 0.0258 - val_loss: 0.0116\n",
      "Epoch 35/80\n",
      "115/115 [==============================] - 0s 3ms/step - loss: 0.0257 - val_loss: 0.0114\n",
      "Epoch 36/80\n",
      "115/115 [==============================] - 0s 3ms/step - loss: 0.0258 - val_loss: 0.0113\n",
      "Epoch 37/80\n",
      "115/115 [==============================] - 0s 3ms/step - loss: 0.0255 - val_loss: 0.0114\n",
      "Epoch 38/80\n",
      "115/115 [==============================] - 0s 3ms/step - loss: 0.0254 - val_loss: 0.0112\n",
      "Epoch 39/80\n",
      "115/115 [==============================] - 0s 3ms/step - loss: 0.0253 - val_loss: 0.0115\n",
      "Epoch 40/80\n",
      "115/115 [==============================] - 0s 3ms/step - loss: 0.0251 - val_loss: 0.0111\n",
      "Epoch 41/80\n",
      "115/115 [==============================] - 0s 3ms/step - loss: 0.0249 - val_loss: 0.0109\n",
      "Epoch 42/80\n",
      "115/115 [==============================] - 0s 3ms/step - loss: 0.0248 - val_loss: 0.0109\n",
      "Epoch 43/80\n",
      "115/115 [==============================] - 0s 3ms/step - loss: 0.0247 - val_loss: 0.0109\n",
      "Epoch 44/80\n",
      "115/115 [==============================] - 0s 3ms/step - loss: 0.0246 - val_loss: 0.0108\n",
      "Epoch 45/80\n",
      "115/115 [==============================] - 0s 3ms/step - loss: 0.0244 - val_loss: 0.0105\n",
      "Epoch 46/80\n",
      "115/115 [==============================] - 0s 3ms/step - loss: 0.0243 - val_loss: 0.0108\n",
      "Epoch 47/80\n",
      "115/115 [==============================] - 0s 3ms/step - loss: 0.0241 - val_loss: 0.0106\n",
      "Epoch 48/80\n",
      "115/115 [==============================] - 0s 3ms/step - loss: 0.0240 - val_loss: 0.0107\n",
      "Epoch 49/80\n",
      "115/115 [==============================] - 0s 3ms/step - loss: 0.0239 - val_loss: 0.0107\n",
      "Epoch 50/80\n",
      "115/115 [==============================] - 0s 3ms/step - loss: 0.0237 - val_loss: 0.0108\n",
      "Epoch 51/80\n",
      "115/115 [==============================] - 0s 3ms/step - loss: 0.0236 - val_loss: 0.0107\n",
      "Epoch 52/80\n",
      "115/115 [==============================] - 0s 3ms/step - loss: 0.0234 - val_loss: 0.0108\n",
      "Epoch 53/80\n",
      "115/115 [==============================] - 0s 3ms/step - loss: 0.0232 - val_loss: 0.0107\n",
      "Epoch 54/80\n",
      "115/115 [==============================] - 0s 3ms/step - loss: 0.0232 - val_loss: 0.0109\n",
      "Epoch 55/80\n",
      "115/115 [==============================] - 0s 3ms/step - loss: 0.0230 - val_loss: 0.0108\n",
      "Epoch 56/80\n",
      "115/115 [==============================] - 0s 3ms/step - loss: 0.0229 - val_loss: 0.0108\n",
      "Epoch 57/80\n",
      "115/115 [==============================] - 0s 3ms/step - loss: 0.0227 - val_loss: 0.0108\n",
      "Epoch 58/80\n",
      "115/115 [==============================] - 0s 3ms/step - loss: 0.0227 - val_loss: 0.0109\n",
      "Epoch 59/80\n",
      "115/115 [==============================] - 0s 3ms/step - loss: 0.0225 - val_loss: 0.0110\n",
      "Epoch 60/80\n",
      "115/115 [==============================] - 0s 3ms/step - loss: 0.0223 - val_loss: 0.0113\n",
      "Epoch 61/80\n",
      "115/115 [==============================] - 0s 3ms/step - loss: 0.0222 - val_loss: 0.0112\n",
      "Epoch 62/80\n",
      "115/115 [==============================] - 0s 3ms/step - loss: 0.0222 - val_loss: 0.0113\n",
      "Epoch 63/80\n",
      "115/115 [==============================] - 0s 3ms/step - loss: 0.0221 - val_loss: 0.0113\n",
      "Epoch 64/80\n",
      "115/115 [==============================] - 0s 3ms/step - loss: 0.0220 - val_loss: 0.0114\n",
      "Epoch 65/80\n",
      "115/115 [==============================] - 0s 3ms/step - loss: 0.0218 - val_loss: 0.0113\n",
      "Epoch 66/80\n",
      "115/115 [==============================] - 0s 3ms/step - loss: 0.0218 - val_loss: 0.0119\n",
      "Epoch 67/80\n",
      "115/115 [==============================] - 0s 3ms/step - loss: 0.0217 - val_loss: 0.0115\n",
      "Epoch 68/80\n",
      "115/115 [==============================] - 0s 3ms/step - loss: 0.0217 - val_loss: 0.0119\n",
      "Epoch 69/80\n",
      "115/115 [==============================] - 0s 3ms/step - loss: 0.0216 - val_loss: 0.0116\n",
      "Epoch 70/80\n",
      "115/115 [==============================] - 0s 3ms/step - loss: 0.0214 - val_loss: 0.0117\n",
      "Epoch 71/80\n",
      "115/115 [==============================] - 0s 3ms/step - loss: 0.0214 - val_loss: 0.0115\n",
      "Epoch 72/80\n",
      "115/115 [==============================] - 0s 3ms/step - loss: 0.0214 - val_loss: 0.0118\n",
      "Epoch 73/80\n",
      "115/115 [==============================] - 0s 3ms/step - loss: 0.0214 - val_loss: 0.0118\n",
      "Epoch 74/80\n",
      "115/115 [==============================] - 0s 3ms/step - loss: 0.0213 - val_loss: 0.0117\n",
      "Epoch 75/80\n",
      "115/115 [==============================] - 0s 3ms/step - loss: 0.0213 - val_loss: 0.0117\n",
      "Epoch 76/80\n",
      "115/115 [==============================] - 0s 3ms/step - loss: 0.0212 - val_loss: 0.0120\n",
      "Epoch 77/80\n",
      "115/115 [==============================] - 0s 3ms/step - loss: 0.0212 - val_loss: 0.0119\n",
      "Epoch 78/80\n",
      "115/115 [==============================] - 0s 3ms/step - loss: 0.0212 - val_loss: 0.0116\n",
      "Epoch 79/80\n",
      "115/115 [==============================] - 0s 3ms/step - loss: 0.0211 - val_loss: 0.0119\n",
      "Epoch 80/80\n",
      "115/115 [==============================] - 0s 3ms/step - loss: 0.0211 - val_loss: 0.0117\n",
      "Execution time:  25.96048378944397\n",
      "DNN:\n",
      "Mean Absolute Error: 0.0154\n",
      "Root Mean Square Error: 0.0276\n",
      "Mean Square Error: 0.0008\n",
      "\n",
      "Train RMSE: 0.028\n",
      "Train MSE: 0.001\n",
      "Train MAE: 0.015\n",
      "###########################\n",
      "\n",
      "MODEL:  DNN\n",
      "sequence:  6h\n",
      "units:  80\n",
      "dropout1:  0.11814836227952394\n",
      "optimizer: adamax\n",
      "activationDense: sigmoid\n",
      "epochs: 90\n",
      "batchsize: 25\n",
      "validation_split: 0.1\n",
      "Model: \"sequential_103\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_309 (Dense)            (None, 36, 80)            160       \n",
      "_________________________________________________________________\n",
      "dense_310 (Dense)            (None, 36, 16)            1296      \n",
      "_________________________________________________________________\n",
      "dropout_103 (Dropout)        (None, 36, 16)            0         \n",
      "_________________________________________________________________\n",
      "dense_311 (Dense)            (None, 36, 1)             17        \n",
      "=================================================================\n",
      "Total params: 1,473\n",
      "Trainable params: 1,473\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/90\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "143/143 [==============================] - 1s 5ms/step - loss: 0.0835 - val_loss: 0.0922\n",
      "Epoch 2/90\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.0431 - val_loss: 0.0388\n",
      "Epoch 3/90\n",
      "143/143 [==============================] - 0s 3ms/step - loss: 0.0311 - val_loss: 0.0217\n",
      "Epoch 4/90\n",
      "143/143 [==============================] - 0s 3ms/step - loss: 0.0316 - val_loss: 0.0204\n",
      "Epoch 5/90\n",
      "143/143 [==============================] - 0s 3ms/step - loss: 0.0314 - val_loss: 0.0203\n",
      "Epoch 6/90\n",
      "143/143 [==============================] - 0s 3ms/step - loss: 0.0310 - val_loss: 0.0203\n",
      "Epoch 7/90\n",
      "143/143 [==============================] - 0s 3ms/step - loss: 0.0306 - val_loss: 0.0185\n",
      "Epoch 8/90\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.0302 - val_loss: 0.0157\n",
      "Epoch 9/90\n",
      "143/143 [==============================] - 0s 3ms/step - loss: 0.0306 - val_loss: 0.0205\n",
      "Epoch 10/90\n",
      "143/143 [==============================] - 0s 3ms/step - loss: 0.0299 - val_loss: 0.0196\n",
      "Epoch 11/90\n",
      "143/143 [==============================] - 0s 3ms/step - loss: 0.0297 - val_loss: 0.0193\n",
      "Epoch 12/90\n",
      "143/143 [==============================] - 0s 3ms/step - loss: 0.0296 - val_loss: 0.0191\n",
      "Epoch 13/90\n",
      "143/143 [==============================] - 0s 3ms/step - loss: 0.0294 - val_loss: 0.0190\n",
      "Epoch 14/90\n",
      "143/143 [==============================] - 0s 3ms/step - loss: 0.0292 - val_loss: 0.0187\n",
      "Epoch 15/90\n",
      "143/143 [==============================] - 0s 3ms/step - loss: 0.0290 - val_loss: 0.0193\n",
      "Epoch 16/90\n",
      "143/143 [==============================] - 0s 3ms/step - loss: 0.0291 - val_loss: 0.0173\n",
      "Epoch 17/90\n",
      "143/143 [==============================] - 0s 3ms/step - loss: 0.0288 - val_loss: 0.0184\n",
      "Epoch 18/90\n",
      "143/143 [==============================] - 0s 3ms/step - loss: 0.0286 - val_loss: 0.0183\n",
      "Epoch 19/90\n",
      "143/143 [==============================] - 0s 3ms/step - loss: 0.0284 - val_loss: 0.0183\n",
      "Epoch 20/90\n",
      "143/143 [==============================] - 0s 3ms/step - loss: 0.0283 - val_loss: 0.0181\n",
      "Epoch 21/90\n",
      "143/143 [==============================] - 0s 3ms/step - loss: 0.0282 - val_loss: 0.0180\n",
      "Epoch 22/90\n",
      "143/143 [==============================] - 0s 3ms/step - loss: 0.0285 - val_loss: 0.0211\n",
      "Epoch 23/90\n",
      "143/143 [==============================] - 0s 3ms/step - loss: 0.0277 - val_loss: 0.0180\n",
      "Epoch 24/90\n",
      "143/143 [==============================] - 0s 3ms/step - loss: 0.0279 - val_loss: 0.0182\n",
      "Epoch 25/90\n",
      "143/143 [==============================] - 0s 3ms/step - loss: 0.0278 - val_loss: 0.0179\n",
      "Epoch 26/90\n",
      "143/143 [==============================] - 0s 3ms/step - loss: 0.0278 - val_loss: 0.0180\n",
      "Epoch 27/90\n",
      "143/143 [==============================] - 0s 3ms/step - loss: 0.0277 - val_loss: 0.0176\n",
      "Epoch 28/90\n",
      "143/143 [==============================] - 0s 3ms/step - loss: 0.0277 - val_loss: 0.0180\n",
      "Epoch 29/90\n",
      "143/143 [==============================] - 0s 3ms/step - loss: 0.0276 - val_loss: 0.0176\n",
      "Epoch 30/90\n",
      "143/143 [==============================] - 0s 3ms/step - loss: 0.0276 - val_loss: 0.0177\n",
      "Epoch 31/90\n",
      "143/143 [==============================] - 0s 3ms/step - loss: 0.0276 - val_loss: 0.0175\n",
      "Epoch 32/90\n",
      "143/143 [==============================] - 0s 3ms/step - loss: 0.0275 - val_loss: 0.0178\n",
      "Epoch 33/90\n",
      "143/143 [==============================] - 0s 3ms/step - loss: 0.0274 - val_loss: 0.0177\n",
      "Epoch 34/90\n",
      "143/143 [==============================] - 0s 3ms/step - loss: 0.0274 - val_loss: 0.0177\n",
      "Epoch 35/90\n",
      "143/143 [==============================] - 0s 3ms/step - loss: 0.0274 - val_loss: 0.0176\n",
      "Epoch 36/90\n",
      "143/143 [==============================] - 0s 3ms/step - loss: 0.0274 - val_loss: 0.0175\n",
      "Epoch 37/90\n",
      "143/143 [==============================] - 0s 3ms/step - loss: 0.0274 - val_loss: 0.0175\n",
      "Epoch 38/90\n",
      "143/143 [==============================] - 0s 3ms/step - loss: 0.0273 - val_loss: 0.0174\n",
      "Epoch 39/90\n",
      "143/143 [==============================] - 0s 3ms/step - loss: 0.0274 - val_loss: 0.0173\n",
      "Epoch 40/90\n",
      "143/143 [==============================] - 0s 3ms/step - loss: 0.0273 - val_loss: 0.0172\n",
      "Epoch 41/90\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.0273 - val_loss: 0.0173\n",
      "Epoch 42/90\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.0273 - val_loss: 0.0172\n",
      "Epoch 43/90\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.0273 - val_loss: 0.0170\n",
      "Epoch 44/90\n",
      "143/143 [==============================] - 0s 3ms/step - loss: 0.0273 - val_loss: 0.0171\n",
      "Epoch 45/90\n",
      "143/143 [==============================] - 0s 3ms/step - loss: 0.0273 - val_loss: 0.0171\n",
      "Epoch 46/90\n",
      "143/143 [==============================] - 0s 3ms/step - loss: 0.0273 - val_loss: 0.0170\n",
      "Epoch 47/90\n",
      "143/143 [==============================] - 0s 3ms/step - loss: 0.0273 - val_loss: 0.0170\n",
      "Epoch 48/90\n",
      "143/143 [==============================] - 0s 3ms/step - loss: 0.0273 - val_loss: 0.0171\n",
      "Epoch 49/90\n",
      "143/143 [==============================] - 0s 3ms/step - loss: 0.0273 - val_loss: 0.0171\n",
      "Epoch 50/90\n",
      "143/143 [==============================] - 0s 3ms/step - loss: 0.0273 - val_loss: 0.0171\n",
      "Epoch 51/90\n",
      "143/143 [==============================] - 0s 3ms/step - loss: 0.0273 - val_loss: 0.0182\n",
      "Epoch 52/90\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.0276 - val_loss: 0.0143\n",
      "Epoch 53/90\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.0277 - val_loss: 0.0173\n",
      "Epoch 54/90\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.0276 - val_loss: 0.0138\n",
      "Epoch 55/90\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.0276 - val_loss: 0.0172\n",
      "Epoch 56/90\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.0271 - val_loss: 0.0173\n",
      "Epoch 57/90\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.0272 - val_loss: 0.0169\n",
      "Epoch 58/90\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.0271 - val_loss: 0.0168\n",
      "Epoch 59/90\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.0272 - val_loss: 0.0148\n",
      "Epoch 60/90\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.0273 - val_loss: 0.0168\n",
      "Epoch 61/90\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.0271 - val_loss: 0.0147\n",
      "Epoch 62/90\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.0272 - val_loss: 0.0163\n",
      "Epoch 63/90\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.0272 - val_loss: 0.0145\n",
      "Epoch 64/90\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.0272 - val_loss: 0.0157\n",
      "Epoch 65/90\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.0271 - val_loss: 0.0146\n",
      "Epoch 66/90\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.0272 - val_loss: 0.0146\n",
      "Epoch 67/90\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.0271 - val_loss: 0.0138\n",
      "Epoch 68/90\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.0272 - val_loss: 0.0137\n",
      "Epoch 69/90\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.0271 - val_loss: 0.0135\n",
      "Epoch 70/90\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.0271 - val_loss: 0.0132\n",
      "Epoch 71/90\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.0271 - val_loss: 0.0128\n",
      "Epoch 72/90\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.0271 - val_loss: 0.0128\n",
      "Epoch 73/90\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.0270 - val_loss: 0.0124\n",
      "Epoch 74/90\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.0270 - val_loss: 0.0123\n",
      "Epoch 75/90\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.0270 - val_loss: 0.0119\n",
      "Epoch 76/90\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.0270 - val_loss: 0.0117\n",
      "Epoch 77/90\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.0270 - val_loss: 0.0115\n",
      "Epoch 78/90\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.0269 - val_loss: 0.0114\n",
      "Epoch 79/90\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.0269 - val_loss: 0.0113\n",
      "Epoch 80/90\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.0268 - val_loss: 0.0113\n",
      "Epoch 81/90\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.0268 - val_loss: 0.0113\n",
      "Epoch 82/90\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "143/143 [==============================] - 0s 2ms/step - loss: 0.0267 - val_loss: 0.0112\n",
      "Epoch 83/90\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.0267 - val_loss: 0.0111\n",
      "Epoch 84/90\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.0266 - val_loss: 0.0111\n",
      "Epoch 85/90\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.0265 - val_loss: 0.0111\n",
      "Epoch 86/90\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.0265 - val_loss: 0.0110\n",
      "Epoch 87/90\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.0264 - val_loss: 0.0111\n",
      "Epoch 88/90\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.0264 - val_loss: 0.0110\n",
      "Epoch 89/90\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.0263 - val_loss: 0.0109\n",
      "Epoch 90/90\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.0263 - val_loss: 0.0108\n",
      "Execution time:  33.86900043487549\n",
      "DNN:\n",
      "Mean Absolute Error: 0.0244\n",
      "Root Mean Square Error: 0.0419\n",
      "Mean Square Error: 0.0018\n",
      "\n",
      "Train RMSE: 0.042\n",
      "Train MSE: 0.002\n",
      "Train MAE: 0.024\n",
      "###########################\n",
      "\n",
      "MODEL:  DNN\n",
      "sequence:  6h\n",
      "units:  12\n",
      "dropout1:  0.48476373451509647\n",
      "optimizer: adamax\n",
      "activationDense: sigmoid\n",
      "epochs: 52\n",
      "batchsize: 57\n",
      "validation_split: 0.1\n",
      "Model: \"sequential_104\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_312 (Dense)            (None, 36, 12)            24        \n",
      "_________________________________________________________________\n",
      "dense_313 (Dense)            (None, 36, 16)            208       \n",
      "_________________________________________________________________\n",
      "dropout_104 (Dropout)        (None, 36, 16)            0         \n",
      "_________________________________________________________________\n",
      "dense_314 (Dense)            (None, 36, 1)             17        \n",
      "=================================================================\n",
      "Total params: 249\n",
      "Trainable params: 249\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/52\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.0593 - val_loss: 0.0412\n",
      "Epoch 2/52\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.0488 - val_loss: 0.0414\n",
      "Epoch 3/52\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.0447 - val_loss: 0.0404\n",
      "Epoch 4/52\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.0428 - val_loss: 0.0410\n",
      "Epoch 5/52\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.0417 - val_loss: 0.0393\n",
      "Epoch 6/52\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0409 - val_loss: 0.0382\n",
      "Epoch 7/52\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.0401 - val_loss: 0.0373\n",
      "Epoch 8/52\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.0393 - val_loss: 0.0364\n",
      "Epoch 9/52\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.0387 - val_loss: 0.0362\n",
      "Epoch 10/52\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.0379 - val_loss: 0.0354\n",
      "Epoch 11/52\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.0373 - val_loss: 0.0348\n",
      "Epoch 12/52\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.0367 - val_loss: 0.0342\n",
      "Epoch 13/52\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.0359 - val_loss: 0.0333\n",
      "Epoch 14/52\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.0355 - val_loss: 0.0329\n",
      "Epoch 15/52\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.0348 - val_loss: 0.0320\n",
      "Epoch 16/52\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.0342 - val_loss: 0.0315\n",
      "Epoch 17/52\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0337 - val_loss: 0.0309\n",
      "Epoch 18/52\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0332 - val_loss: 0.0302\n",
      "Epoch 19/52\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.0327 - val_loss: 0.0294\n",
      "Epoch 20/52\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.0322 - val_loss: 0.0284\n",
      "Epoch 21/52\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.0318 - val_loss: 0.0279\n",
      "Epoch 22/52\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.0313 - val_loss: 0.0273\n",
      "Epoch 23/52\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.0309 - val_loss: 0.0264\n",
      "Epoch 24/52\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.0305 - val_loss: 0.0259\n",
      "Epoch 25/52\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.0301 - val_loss: 0.0252\n",
      "Epoch 26/52\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.0297 - val_loss: 0.0245\n",
      "Epoch 27/52\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.0293 - val_loss: 0.0240\n",
      "Epoch 28/52\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.0289 - val_loss: 0.0232\n",
      "Epoch 29/52\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.0286 - val_loss: 0.0227\n",
      "Epoch 30/52\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.0283 - val_loss: 0.0220\n",
      "Epoch 31/52\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.0279 - val_loss: 0.0215\n",
      "Epoch 32/52\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.0277 - val_loss: 0.0209\n",
      "Epoch 33/52\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.0273 - val_loss: 0.0202\n",
      "Epoch 34/52\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.0270 - val_loss: 0.0198\n",
      "Epoch 35/52\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.0267 - val_loss: 0.0192\n",
      "Epoch 36/52\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0265 - val_loss: 0.0190\n",
      "Epoch 37/52\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.0262 - val_loss: 0.0185\n",
      "Epoch 38/52\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.0260 - val_loss: 0.0181\n",
      "Epoch 39/52\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.0258 - val_loss: 0.0177\n",
      "Epoch 40/52\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.0255 - val_loss: 0.0172\n",
      "Epoch 41/52\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.0253 - val_loss: 0.0168\n",
      "Epoch 42/52\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.0252 - val_loss: 0.0165\n",
      "Epoch 43/52\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.0249 - val_loss: 0.0161\n",
      "Epoch 44/52\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.0247 - val_loss: 0.0157\n",
      "Epoch 45/52\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.0245 - val_loss: 0.0154\n",
      "Epoch 46/52\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.0244 - val_loss: 0.0150\n",
      "Epoch 47/52\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.0241 - val_loss: 0.0146\n",
      "Epoch 48/52\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.0241 - val_loss: 0.0144\n",
      "Epoch 49/52\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.0239 - val_loss: 0.0139\n",
      "Epoch 50/52\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.0237 - val_loss: 0.0138\n",
      "Epoch 51/52\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.0235 - val_loss: 0.0131\n",
      "Epoch 52/52\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.0234 - val_loss: 0.0131\n",
      "Execution time:  9.73934292793274\n",
      "DNN:\n",
      "Mean Absolute Error: 0.0203\n",
      "Root Mean Square Error: 0.0327\n",
      "Mean Square Error: 0.0011\n",
      "\n",
      "Train RMSE: 0.033\n",
      "Train MSE: 0.001\n",
      "Train MAE: 0.020\n",
      "###########################\n",
      "\n",
      "MODEL:  DNN\n",
      "sequence:  6h\n",
      "units:  87\n",
      "dropout1:  0.40519643149940265\n",
      "optimizer: adamax\n",
      "activationDense: sigmoid\n",
      "epochs: 80\n",
      "batchsize: 31\n",
      "validation_split: 0.2\n",
      "Model: \"sequential_105\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_315 (Dense)            (None, 36, 87)            174       \n",
      "_________________________________________________________________\n",
      "dense_316 (Dense)            (None, 36, 16)            1408      \n",
      "_________________________________________________________________\n",
      "dropout_105 (Dropout)        (None, 36, 16)            0         \n",
      "_________________________________________________________________\n",
      "dense_317 (Dense)            (None, 36, 1)             17        \n",
      "=================================================================\n",
      "Total params: 1,599\n",
      "Trainable params: 1,599\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/80\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  1/103 [..............................] - ETA: 0s - loss: 0.0732WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0000s vs `on_train_batch_end` time: 0.0090s). Check your callbacks.\n",
      "103/103 [==============================] - 0s 5ms/step - loss: 0.0501 - val_loss: 0.0287\n",
      "Epoch 2/80\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 0.0418 - val_loss: 0.0273\n",
      "Epoch 3/80\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 0.0402 - val_loss: 0.0257\n",
      "Epoch 4/80\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 0.0394 - val_loss: 0.0249\n",
      "Epoch 5/80\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 0.0386 - val_loss: 0.0241\n",
      "Epoch 6/80\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 0.0380 - val_loss: 0.0237\n",
      "Epoch 7/80\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 0.0371 - val_loss: 0.0230\n",
      "Epoch 8/80\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 0.0366 - val_loss: 0.0225\n",
      "Epoch 9/80\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 0.0360 - val_loss: 0.0221\n",
      "Epoch 10/80\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 0.0353 - val_loss: 0.0217\n",
      "Epoch 11/80\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 0.0348 - val_loss: 0.0215\n",
      "Epoch 12/80\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 0.0343 - val_loss: 0.0212\n",
      "Epoch 13/80\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 0.0338 - val_loss: 0.0208\n",
      "Epoch 14/80\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 0.0332 - val_loss: 0.0205\n",
      "Epoch 15/80\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 0.0327 - val_loss: 0.0199\n",
      "Epoch 16/80\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 0.0323 - val_loss: 0.0196\n",
      "Epoch 17/80\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 0.0319 - val_loss: 0.0192\n",
      "Epoch 18/80\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 0.0316 - val_loss: 0.0189\n",
      "Epoch 19/80\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 0.0312 - val_loss: 0.0185\n",
      "Epoch 20/80\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 0.0310 - val_loss: 0.0184\n",
      "Epoch 21/80\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 0.0305 - val_loss: 0.0180\n",
      "Epoch 22/80\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 0.0303 - val_loss: 0.0178\n",
      "Epoch 23/80\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 0.0300 - val_loss: 0.0176\n",
      "Epoch 24/80\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 0.0297 - val_loss: 0.0173\n",
      "Epoch 25/80\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 0.0295 - val_loss: 0.0171\n",
      "Epoch 26/80\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 0.0291 - val_loss: 0.0168\n",
      "Epoch 27/80\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 0.0289 - val_loss: 0.0165\n",
      "Epoch 28/80\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 0.0287 - val_loss: 0.0163\n",
      "Epoch 29/80\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 0.0284 - val_loss: 0.0161\n",
      "Epoch 30/80\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 0.0282 - val_loss: 0.0159\n",
      "Epoch 31/80\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 0.0280 - val_loss: 0.0157\n",
      "Epoch 32/80\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 0.0278 - val_loss: 0.0155\n",
      "Epoch 33/80\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 0.0277 - val_loss: 0.0154\n",
      "Epoch 34/80\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 0.0274 - val_loss: 0.0152\n",
      "Epoch 35/80\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 0.0272 - val_loss: 0.0151\n",
      "Epoch 36/80\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 0.0270 - val_loss: 0.0150\n",
      "Epoch 37/80\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 0.0269 - val_loss: 0.0149\n",
      "Epoch 38/80\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 0.0267 - val_loss: 0.0149\n",
      "Epoch 39/80\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 0.0266 - val_loss: 0.0148\n",
      "Epoch 40/80\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 0.0264 - val_loss: 0.0147\n",
      "Epoch 41/80\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 0.0262 - val_loss: 0.0145\n",
      "Epoch 42/80\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 0.0261 - val_loss: 0.0145\n",
      "Epoch 43/80\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 0.0259 - val_loss: 0.0144\n",
      "Epoch 44/80\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 0.0258 - val_loss: 0.0144\n",
      "Epoch 45/80\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 0.0256 - val_loss: 0.0144\n",
      "Epoch 46/80\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 0.0254 - val_loss: 0.0143\n",
      "Epoch 47/80\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 0.0252 - val_loss: 0.0143\n",
      "Epoch 48/80\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 0.0251 - val_loss: 0.0142\n",
      "Epoch 49/80\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 0.0249 - val_loss: 0.0141\n",
      "Epoch 50/80\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 0.0248 - val_loss: 0.0141\n",
      "Epoch 51/80\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 0.0246 - val_loss: 0.0140\n",
      "Epoch 52/80\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 0.0244 - val_loss: 0.0140\n",
      "Epoch 53/80\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 0.0243 - val_loss: 0.0139\n",
      "Epoch 54/80\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 0.0242 - val_loss: 0.0138\n",
      "Epoch 55/80\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 0.0239 - val_loss: 0.0138\n",
      "Epoch 56/80\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 0.0237 - val_loss: 0.0138\n",
      "Epoch 57/80\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 0.0236 - val_loss: 0.0138\n",
      "Epoch 58/80\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 0.0235 - val_loss: 0.0137\n",
      "Epoch 59/80\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 0.0233 - val_loss: 0.0137\n",
      "Epoch 60/80\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 0.0232 - val_loss: 0.0137\n",
      "Epoch 61/80\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 0.0230 - val_loss: 0.0137\n",
      "Epoch 62/80\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 0.0230 - val_loss: 0.0137\n",
      "Epoch 63/80\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 0.0229 - val_loss: 0.0137\n",
      "Epoch 64/80\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 0.0228 - val_loss: 0.0136\n",
      "Epoch 65/80\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 0.0227 - val_loss: 0.0136\n",
      "Epoch 66/80\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 0.0226 - val_loss: 0.0136\n",
      "Epoch 67/80\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 0.0225 - val_loss: 0.0136\n",
      "Epoch 68/80\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 0.0223 - val_loss: 0.0136\n",
      "Epoch 69/80\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 0.0222 - val_loss: 0.0136\n",
      "Epoch 70/80\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 0.0222 - val_loss: 0.0137\n",
      "Epoch 71/80\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 0.0221 - val_loss: 0.0137\n",
      "Epoch 72/80\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 0.0220 - val_loss: 0.0138\n",
      "Epoch 73/80\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 0.0219 - val_loss: 0.0138\n",
      "Epoch 74/80\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 0.0220 - val_loss: 0.0138\n",
      "Epoch 75/80\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 0.0218 - val_loss: 0.0138\n",
      "Epoch 76/80\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 0.0218 - val_loss: 0.0138\n",
      "Epoch 77/80\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 0.0217 - val_loss: 0.0139\n",
      "Epoch 78/80\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 0.0216 - val_loss: 0.0138\n",
      "Epoch 79/80\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 0.0216 - val_loss: 0.0139\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 80/80\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 0.0216 - val_loss: 0.0138\n",
      "Execution time:  24.764704942703247\n",
      "DNN:\n",
      "Mean Absolute Error: 0.0143\n",
      "Root Mean Square Error: 0.0296\n",
      "Mean Square Error: 0.0009\n",
      "\n",
      "Train RMSE: 0.030\n",
      "Train MSE: 0.001\n",
      "Train MAE: 0.014\n",
      "###########################\n",
      "\n",
      "MODEL:  DNN\n",
      "sequence:  6h\n",
      "units:  80\n",
      "dropout1:  0.11814836227952394\n",
      "optimizer: adamax\n",
      "activationDense: sigmoid\n",
      "epochs: 90\n",
      "batchsize: 25\n",
      "validation_split: 0.2\n",
      "Model: \"sequential_106\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_318 (Dense)            (None, 36, 80)            160       \n",
      "_________________________________________________________________\n",
      "dense_319 (Dense)            (None, 36, 16)            1296      \n",
      "_________________________________________________________________\n",
      "dropout_106 (Dropout)        (None, 36, 16)            0         \n",
      "_________________________________________________________________\n",
      "dense_320 (Dense)            (None, 36, 1)             17        \n",
      "=================================================================\n",
      "Total params: 1,473\n",
      "Trainable params: 1,473\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/90\n",
      "127/127 [==============================] - 1s 4ms/step - loss: 0.0397 - val_loss: 0.0201\n",
      "Epoch 2/90\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 0.0380 - val_loss: 0.0199\n",
      "Epoch 3/90\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 0.0376 - val_loss: 0.0193\n",
      "Epoch 4/90\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 0.0372 - val_loss: 0.0196\n",
      "Epoch 5/90\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 0.0368 - val_loss: 0.0194\n",
      "Epoch 6/90\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 0.0364 - val_loss: 0.0192\n",
      "Epoch 7/90\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 0.0361 - val_loss: 0.0190\n",
      "Epoch 8/90\n",
      "127/127 [==============================] - 0s 2ms/step - loss: 0.0357 - val_loss: 0.0189\n",
      "Epoch 9/90\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 0.0352 - val_loss: 0.0189\n",
      "Epoch 10/90\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 0.0348 - val_loss: 0.0188\n",
      "Epoch 11/90\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 0.0347 - val_loss: 0.0188\n",
      "Epoch 12/90\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 0.0339 - val_loss: 0.0185\n",
      "Epoch 13/90\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 0.0337 - val_loss: 0.0184\n",
      "Epoch 14/90\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 0.0333 - val_loss: 0.0184\n",
      "Epoch 15/90\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 0.0330 - val_loss: 0.0182\n",
      "Epoch 16/90\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 0.0329 - val_loss: 0.0180\n",
      "Epoch 17/90\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 0.0326 - val_loss: 0.0181\n",
      "Epoch 18/90\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 0.0323 - val_loss: 0.0179\n",
      "Epoch 19/90\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 0.0321 - val_loss: 0.0178\n",
      "Epoch 20/90\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 0.0316 - val_loss: 0.0176\n",
      "Epoch 21/90\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 0.0315 - val_loss: 0.0177\n",
      "Epoch 22/90\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 0.0314 - val_loss: 0.0175\n",
      "Epoch 23/90\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 0.0310 - val_loss: 0.0176\n",
      "Epoch 24/90\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 0.0308 - val_loss: 0.0174\n",
      "Epoch 25/90\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 0.0306 - val_loss: 0.0174\n",
      "Epoch 26/90\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 0.0304 - val_loss: 0.0173\n",
      "Epoch 27/90\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 0.0302 - val_loss: 0.0172\n",
      "Epoch 28/90\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 0.0299 - val_loss: 0.0172\n",
      "Epoch 29/90\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 0.0298 - val_loss: 0.0171\n",
      "Epoch 30/90\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 0.0295 - val_loss: 0.0169\n",
      "Epoch 31/90\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 0.0294 - val_loss: 0.0168\n",
      "Epoch 32/90\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 0.0293 - val_loss: 0.0168\n",
      "Epoch 33/90\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 0.0290 - val_loss: 0.0166\n",
      "Epoch 34/90\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 0.0288 - val_loss: 0.0164\n",
      "Epoch 35/90\n",
      "127/127 [==============================] - 0s 2ms/step - loss: 0.0286 - val_loss: 0.0163\n",
      "Epoch 36/90\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 0.0284 - val_loss: 0.0161\n",
      "Epoch 37/90\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 0.0283 - val_loss: 0.0160\n",
      "Epoch 38/90\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 0.0281 - val_loss: 0.0158\n",
      "Epoch 39/90\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 0.0279 - val_loss: 0.0158\n",
      "Epoch 40/90\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 0.0276 - val_loss: 0.0154\n",
      "Epoch 41/90\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 0.0274 - val_loss: 0.0153\n",
      "Epoch 42/90\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 0.0271 - val_loss: 0.0151\n",
      "Epoch 43/90\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 0.0270 - val_loss: 0.0150\n",
      "Epoch 44/90\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 0.0268 - val_loss: 0.0147\n",
      "Epoch 45/90\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 0.0265 - val_loss: 0.0146\n",
      "Epoch 46/90\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 0.0264 - val_loss: 0.0146\n",
      "Epoch 47/90\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 0.0262 - val_loss: 0.0144\n",
      "Epoch 48/90\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 0.0260 - val_loss: 0.0143\n",
      "Epoch 49/90\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 0.0258 - val_loss: 0.0142\n",
      "Epoch 50/90\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 0.0256 - val_loss: 0.0143\n",
      "Epoch 51/90\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 0.0255 - val_loss: 0.0141\n",
      "Epoch 52/90\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 0.0250 - val_loss: 0.0140\n",
      "Epoch 53/90\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 0.0248 - val_loss: 0.0139\n",
      "Epoch 54/90\n",
      "127/127 [==============================] - 0s 2ms/step - loss: 0.0244 - val_loss: 0.0139\n",
      "Epoch 55/90\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 0.0241 - val_loss: 0.0137\n",
      "Epoch 56/90\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 0.0237 - val_loss: 0.0137\n",
      "Epoch 57/90\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 0.0235 - val_loss: 0.0137\n",
      "Epoch 58/90\n",
      "127/127 [==============================] - 0s 2ms/step - loss: 0.0233 - val_loss: 0.0136\n",
      "Epoch 59/90\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 0.0230 - val_loss: 0.0135\n",
      "Epoch 60/90\n",
      "127/127 [==============================] - 0s 2ms/step - loss: 0.0227 - val_loss: 0.0135\n",
      "Epoch 61/90\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 0.0223 - val_loss: 0.0134\n",
      "Epoch 62/90\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 0.0220 - val_loss: 0.0134\n",
      "Epoch 63/90\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 0.0217 - val_loss: 0.0133\n",
      "Epoch 64/90\n",
      "127/127 [==============================] - 0s 2ms/step - loss: 0.0215 - val_loss: 0.0133\n",
      "Epoch 65/90\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 0.0212 - val_loss: 0.0133\n",
      "Epoch 66/90\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 0.0208 - val_loss: 0.0132\n",
      "Epoch 67/90\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 0.0206 - val_loss: 0.0132\n",
      "Epoch 68/90\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 0.0203 - val_loss: 0.0131\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 69/90\n",
      "127/127 [==============================] - 0s 2ms/step - loss: 0.0200 - val_loss: 0.0131\n",
      "Epoch 70/90\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 0.0199 - val_loss: 0.0131\n",
      "Epoch 71/90\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 0.0198 - val_loss: 0.0131\n",
      "Epoch 72/90\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 0.0197 - val_loss: 0.0130\n",
      "Epoch 73/90\n",
      "127/127 [==============================] - 0s 2ms/step - loss: 0.0195 - val_loss: 0.0131\n",
      "Epoch 74/90\n",
      "127/127 [==============================] - 0s 2ms/step - loss: 0.0194 - val_loss: 0.0131\n",
      "Epoch 75/90\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 0.0192 - val_loss: 0.0130\n",
      "Epoch 76/90\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 0.0192 - val_loss: 0.0129\n",
      "Epoch 77/90\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 0.0190 - val_loss: 0.0133\n",
      "Epoch 78/90\n",
      "127/127 [==============================] - 0s 2ms/step - loss: 0.0190 - val_loss: 0.0129\n",
      "Epoch 79/90\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 0.0189 - val_loss: 0.0132\n",
      "Epoch 80/90\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 0.0188 - val_loss: 0.0131\n",
      "Epoch 81/90\n",
      "127/127 [==============================] - 0s 2ms/step - loss: 0.0187 - val_loss: 0.0131\n",
      "Epoch 82/90\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 0.0187 - val_loss: 0.0131\n",
      "Epoch 83/90\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 0.0187 - val_loss: 0.0130\n",
      "Epoch 84/90\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 0.0186 - val_loss: 0.0129\n",
      "Epoch 85/90\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 0.0185 - val_loss: 0.0131\n",
      "Epoch 86/90\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 0.0185 - val_loss: 0.0129\n",
      "Epoch 87/90\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 0.0185 - val_loss: 0.0130\n",
      "Epoch 88/90\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 0.0184 - val_loss: 0.0130\n",
      "Epoch 89/90\n",
      "127/127 [==============================] - 0s 2ms/step - loss: 0.0184 - val_loss: 0.0131\n",
      "Epoch 90/90\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 0.0184 - val_loss: 0.0129\n",
      "Execution time:  31.256271839141846\n",
      "DNN:\n",
      "Mean Absolute Error: 0.0109\n",
      "Root Mean Square Error: 0.0232\n",
      "Mean Square Error: 0.0005\n",
      "\n",
      "Train RMSE: 0.023\n",
      "Train MSE: 0.001\n",
      "Train MAE: 0.011\n",
      "###########################\n",
      "\n",
      "MODEL:  DNN\n",
      "sequence:  6h\n",
      "units:  12\n",
      "dropout1:  0.48476373451509647\n",
      "optimizer: adamax\n",
      "activationDense: sigmoid\n",
      "epochs: 52\n",
      "batchsize: 57\n",
      "validation_split: 0.2\n",
      "Model: \"sequential_107\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_321 (Dense)            (None, 36, 12)            24        \n",
      "_________________________________________________________________\n",
      "dense_322 (Dense)            (None, 36, 16)            208       \n",
      "_________________________________________________________________\n",
      "dropout_107 (Dropout)        (None, 36, 16)            0         \n",
      "_________________________________________________________________\n",
      "dense_323 (Dense)            (None, 36, 1)             17        \n",
      "=================================================================\n",
      "Total params: 249\n",
      "Trainable params: 249\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/52\n",
      "56/56 [==============================] - 0s 6ms/step - loss: 0.0647 - val_loss: 0.0504\n",
      "Epoch 2/52\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 0.0431 - val_loss: 0.0398\n",
      "Epoch 3/52\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 0.0421 - val_loss: 0.0380\n",
      "Epoch 4/52\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 0.0412 - val_loss: 0.0366\n",
      "Epoch 5/52\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 0.0403 - val_loss: 0.0358\n",
      "Epoch 6/52\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 0.0395 - val_loss: 0.0352\n",
      "Epoch 7/52\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 0.0386 - val_loss: 0.0344\n",
      "Epoch 8/52\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 0.0380 - val_loss: 0.0336\n",
      "Epoch 9/52\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 0.0375 - val_loss: 0.0328\n",
      "Epoch 10/52\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 0.0368 - val_loss: 0.0321\n",
      "Epoch 11/52\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 0.0363 - val_loss: 0.0317\n",
      "Epoch 12/52\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 0.0359 - val_loss: 0.0314\n",
      "Epoch 13/52\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 0.0355 - val_loss: 0.0309\n",
      "Epoch 14/52\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 0.0351 - val_loss: 0.0303\n",
      "Epoch 15/52\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 0.0348 - val_loss: 0.0300\n",
      "Epoch 16/52\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 0.0343 - val_loss: 0.0297\n",
      "Epoch 17/52\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 0.0339 - val_loss: 0.0291\n",
      "Epoch 18/52\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 0.0336 - val_loss: 0.0285\n",
      "Epoch 19/52\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 0.0332 - val_loss: 0.0281\n",
      "Epoch 20/52\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 0.0329 - val_loss: 0.0279\n",
      "Epoch 21/52\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 0.0326 - val_loss: 0.0274\n",
      "Epoch 22/52\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 0.0322 - val_loss: 0.0272\n",
      "Epoch 23/52\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 0.0320 - val_loss: 0.0268\n",
      "Epoch 24/52\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 0.0316 - val_loss: 0.0265\n",
      "Epoch 25/52\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 0.0313 - val_loss: 0.0258\n",
      "Epoch 26/52\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 0.0312 - val_loss: 0.0254\n",
      "Epoch 27/52\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 0.0308 - val_loss: 0.0250\n",
      "Epoch 28/52\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 0.0306 - val_loss: 0.0245\n",
      "Epoch 29/52\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 0.0303 - val_loss: 0.0242\n",
      "Epoch 30/52\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 0.0301 - val_loss: 0.0238\n",
      "Epoch 31/52\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 0.0300 - val_loss: 0.0234\n",
      "Epoch 32/52\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 0.0298 - val_loss: 0.0231\n",
      "Epoch 33/52\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 0.0296 - val_loss: 0.0228\n",
      "Epoch 34/52\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 0.0294 - val_loss: 0.0225\n",
      "Epoch 35/52\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 0.0292 - val_loss: 0.0222\n",
      "Epoch 36/52\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 0.0291 - val_loss: 0.0219\n",
      "Epoch 37/52\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 0.0289 - val_loss: 0.0217\n",
      "Epoch 38/52\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 0.0287 - val_loss: 0.0214\n",
      "Epoch 39/52\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 0.0285 - val_loss: 0.0211\n",
      "Epoch 40/52\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 0.0284 - val_loss: 0.0209\n",
      "Epoch 41/52\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 0.0282 - val_loss: 0.0207\n",
      "Epoch 42/52\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 0.0280 - val_loss: 0.0204\n",
      "Epoch 43/52\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 0.0279 - val_loss: 0.0202\n",
      "Epoch 44/52\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 0.0277 - val_loss: 0.0200\n",
      "Epoch 45/52\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 0.0276 - val_loss: 0.0198\n",
      "Epoch 46/52\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 0.0274 - val_loss: 0.0196\n",
      "Epoch 47/52\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 0.0273 - val_loss: 0.0194\n",
      "Epoch 48/52\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 0.0272 - val_loss: 0.0193\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 49/52\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 0.0270 - val_loss: 0.0191\n",
      "Epoch 50/52\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 0.0269 - val_loss: 0.0189\n",
      "Epoch 51/52\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 0.0268 - val_loss: 0.0188\n",
      "Epoch 52/52\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 0.0267 - val_loss: 0.0187\n",
      "Execution time:  9.233843326568604\n",
      "DNN:\n",
      "Mean Absolute Error: 0.0232\n",
      "Root Mean Square Error: 0.0372\n",
      "Mean Square Error: 0.0014\n",
      "\n",
      "Train RMSE: 0.037\n",
      "Train MSE: 0.001\n",
      "Train MAE: 0.023\n",
      "###########################\n",
      "\n",
      "MODEL:  DNN\n",
      "sequence:  12h\n",
      "units:  87\n",
      "dropout1:  0.40519643149940265\n",
      "optimizer: adam\n",
      "activationDense: tanh\n",
      "epochs: 80\n",
      "batchsize: 31\n",
      "validation_split: 0.1\n",
      "Model: \"sequential_108\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_324 (Dense)            (None, 72, 87)            174       \n",
      "_________________________________________________________________\n",
      "dense_325 (Dense)            (None, 72, 16)            1408      \n",
      "_________________________________________________________________\n",
      "dropout_108 (Dropout)        (None, 72, 16)            0         \n",
      "_________________________________________________________________\n",
      "dense_326 (Dense)            (None, 72, 1)             17        \n",
      "=================================================================\n",
      "Total params: 1,599\n",
      "Trainable params: 1,599\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/80\n",
      "114/114 [==============================] - 1s 5ms/step - loss: 0.1999 - val_loss: 0.0273\n",
      "Epoch 2/80\n",
      "114/114 [==============================] - 0s 3ms/step - loss: 0.0860 - val_loss: 0.0096\n",
      "Epoch 3/80\n",
      "114/114 [==============================] - 0s 3ms/step - loss: 0.0733 - val_loss: 0.0105\n",
      "Epoch 4/80\n",
      "114/114 [==============================] - 0s 3ms/step - loss: 0.0622 - val_loss: 0.0135\n",
      "Epoch 5/80\n",
      "114/114 [==============================] - 0s 3ms/step - loss: 0.0490 - val_loss: 0.0171\n",
      "Epoch 6/80\n",
      "114/114 [==============================] - 0s 3ms/step - loss: 0.0418 - val_loss: 0.0166\n",
      "Epoch 7/80\n",
      "114/114 [==============================] - 0s 3ms/step - loss: 0.0359 - val_loss: 0.0199\n",
      "Epoch 8/80\n",
      "114/114 [==============================] - 0s 3ms/step - loss: 0.0326 - val_loss: 0.0150\n",
      "Epoch 9/80\n",
      "114/114 [==============================] - 0s 4ms/step - loss: 0.0307 - val_loss: 0.0084\n",
      "Epoch 10/80\n",
      "114/114 [==============================] - 0s 4ms/step - loss: 0.0318 - val_loss: 0.0094\n",
      "Epoch 11/80\n",
      "114/114 [==============================] - 0s 4ms/step - loss: 0.0293 - val_loss: 0.0100\n",
      "Epoch 12/80\n",
      "114/114 [==============================] - 0s 4ms/step - loss: 0.0288 - val_loss: 0.0098\n",
      "Epoch 13/80\n",
      "114/114 [==============================] - 0s 4ms/step - loss: 0.0289 - val_loss: 0.0102\n",
      "Epoch 14/80\n",
      "114/114 [==============================] - 0s 3ms/step - loss: 0.0287 - val_loss: 0.0102\n",
      "Epoch 15/80\n",
      "114/114 [==============================] - 0s 3ms/step - loss: 0.0285 - val_loss: 0.0107\n",
      "Epoch 16/80\n",
      "114/114 [==============================] - 0s 3ms/step - loss: 0.0285 - val_loss: 0.0105\n",
      "Epoch 17/80\n",
      "114/114 [==============================] - 0s 3ms/step - loss: 0.0283 - val_loss: 0.0115\n",
      "Epoch 18/80\n",
      "114/114 [==============================] - 0s 3ms/step - loss: 0.0283 - val_loss: 0.0108\n",
      "Epoch 19/80\n",
      "114/114 [==============================] - 0s 3ms/step - loss: 0.0283 - val_loss: 0.0119\n",
      "Epoch 20/80\n",
      "114/114 [==============================] - 0s 3ms/step - loss: 0.0283 - val_loss: 0.0106\n",
      "Epoch 21/80\n",
      "114/114 [==============================] - 0s 3ms/step - loss: 0.0283 - val_loss: 0.0130\n",
      "Epoch 22/80\n",
      "114/114 [==============================] - 0s 3ms/step - loss: 0.0281 - val_loss: 0.0109\n",
      "Epoch 23/80\n",
      "114/114 [==============================] - 0s 3ms/step - loss: 0.0282 - val_loss: 0.0122\n",
      "Epoch 24/80\n",
      "114/114 [==============================] - 0s 3ms/step - loss: 0.0281 - val_loss: 0.0109\n",
      "Epoch 25/80\n",
      "114/114 [==============================] - 0s 3ms/step - loss: 0.0281 - val_loss: 0.0132\n",
      "Epoch 26/80\n",
      "114/114 [==============================] - 0s 3ms/step - loss: 0.0280 - val_loss: 0.0119\n",
      "Epoch 27/80\n",
      "114/114 [==============================] - 0s 3ms/step - loss: 0.0281 - val_loss: 0.0124\n",
      "Epoch 28/80\n",
      "114/114 [==============================] - 0s 3ms/step - loss: 0.0281 - val_loss: 0.0117\n",
      "Epoch 29/80\n",
      "114/114 [==============================] - 0s 3ms/step - loss: 0.0281 - val_loss: 0.0136\n",
      "Epoch 30/80\n",
      "114/114 [==============================] - 0s 3ms/step - loss: 0.0280 - val_loss: 0.0117\n",
      "Epoch 31/80\n",
      "114/114 [==============================] - 0s 3ms/step - loss: 0.0281 - val_loss: 0.0135\n",
      "Epoch 32/80\n",
      "114/114 [==============================] - 0s 3ms/step - loss: 0.0280 - val_loss: 0.0118\n",
      "Epoch 33/80\n",
      "114/114 [==============================] - 0s 3ms/step - loss: 0.0281 - val_loss: 0.0136\n",
      "Epoch 34/80\n",
      "114/114 [==============================] - 0s 3ms/step - loss: 0.0280 - val_loss: 0.0118\n",
      "Epoch 35/80\n",
      "114/114 [==============================] - 0s 3ms/step - loss: 0.0280 - val_loss: 0.0135\n",
      "Epoch 36/80\n",
      "114/114 [==============================] - 0s 3ms/step - loss: 0.0280 - val_loss: 0.0114\n",
      "Epoch 37/80\n",
      "114/114 [==============================] - 0s 3ms/step - loss: 0.0281 - val_loss: 0.0136\n",
      "Epoch 38/80\n",
      "114/114 [==============================] - 0s 3ms/step - loss: 0.0280 - val_loss: 0.0122\n",
      "Epoch 39/80\n",
      "114/114 [==============================] - 0s 3ms/step - loss: 0.0280 - val_loss: 0.0130\n",
      "Epoch 40/80\n",
      "114/114 [==============================] - 0s 3ms/step - loss: 0.0280 - val_loss: 0.0123\n",
      "Epoch 41/80\n",
      "114/114 [==============================] - 0s 3ms/step - loss: 0.0280 - val_loss: 0.0132\n",
      "Epoch 42/80\n",
      "114/114 [==============================] - 0s 3ms/step - loss: 0.0280 - val_loss: 0.0122\n",
      "Epoch 43/80\n",
      "114/114 [==============================] - 0s 3ms/step - loss: 0.0280 - val_loss: 0.0128\n",
      "Epoch 44/80\n",
      "114/114 [==============================] - 0s 3ms/step - loss: 0.0280 - val_loss: 0.0124\n",
      "Epoch 45/80\n",
      "114/114 [==============================] - 0s 3ms/step - loss: 0.0280 - val_loss: 0.0128\n",
      "Epoch 46/80\n",
      "114/114 [==============================] - 0s 3ms/step - loss: 0.0280 - val_loss: 0.0125\n",
      "Epoch 47/80\n",
      "114/114 [==============================] - 0s 3ms/step - loss: 0.0280 - val_loss: 0.0124\n",
      "Epoch 48/80\n",
      "114/114 [==============================] - 0s 3ms/step - loss: 0.0280 - val_loss: 0.0128\n",
      "Epoch 49/80\n",
      "114/114 [==============================] - 0s 4ms/step - loss: 0.0280 - val_loss: 0.0124\n",
      "Epoch 50/80\n",
      "114/114 [==============================] - 0s 4ms/step - loss: 0.0280 - val_loss: 0.0123\n",
      "Epoch 51/80\n",
      "114/114 [==============================] - 0s 4ms/step - loss: 0.0280 - val_loss: 0.0125\n",
      "Epoch 52/80\n",
      "114/114 [==============================] - 0s 4ms/step - loss: 0.0280 - val_loss: 0.0123\n",
      "Epoch 53/80\n",
      "114/114 [==============================] - 0s 4ms/step - loss: 0.0280 - val_loss: 0.0127\n",
      "Epoch 54/80\n",
      "114/114 [==============================] - 0s 3ms/step - loss: 0.0280 - val_loss: 0.0121\n",
      "Epoch 55/80\n",
      "114/114 [==============================] - 0s 3ms/step - loss: 0.0280 - val_loss: 0.0122\n",
      "Epoch 56/80\n",
      "114/114 [==============================] - 0s 3ms/step - loss: 0.0280 - val_loss: 0.0121\n",
      "Epoch 57/80\n",
      "114/114 [==============================] - 0s 3ms/step - loss: 0.0280 - val_loss: 0.0122\n",
      "Epoch 58/80\n",
      "114/114 [==============================] - 0s 3ms/step - loss: 0.0280 - val_loss: 0.0121\n",
      "Epoch 59/80\n",
      "114/114 [==============================] - 0s 3ms/step - loss: 0.0280 - val_loss: 0.0117\n",
      "Epoch 60/80\n",
      "114/114 [==============================] - 0s 3ms/step - loss: 0.0280 - val_loss: 0.0119\n",
      "Epoch 61/80\n",
      "114/114 [==============================] - 0s 3ms/step - loss: 0.0280 - val_loss: 0.0116\n",
      "Epoch 62/80\n",
      "114/114 [==============================] - 0s 3ms/step - loss: 0.0280 - val_loss: 0.0118\n",
      "Epoch 63/80\n",
      "114/114 [==============================] - 0s 3ms/step - loss: 0.0280 - val_loss: 0.0117\n",
      "Epoch 64/80\n",
      "114/114 [==============================] - 0s 3ms/step - loss: 0.0280 - val_loss: 0.0120\n",
      "Epoch 65/80\n",
      "114/114 [==============================] - 0s 3ms/step - loss: 0.0279 - val_loss: 0.0117\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 66/80\n",
      "114/114 [==============================] - 0s 3ms/step - loss: 0.0279 - val_loss: 0.0117\n",
      "Epoch 67/80\n",
      "114/114 [==============================] - 0s 4ms/step - loss: 0.0279 - val_loss: 0.0116\n",
      "Epoch 68/80\n",
      "114/114 [==============================] - 0s 3ms/step - loss: 0.0279 - val_loss: 0.0112\n",
      "Epoch 69/80\n",
      "114/114 [==============================] - 0s 3ms/step - loss: 0.0279 - val_loss: 0.0112\n",
      "Epoch 70/80\n",
      "114/114 [==============================] - 0s 3ms/step - loss: 0.0279 - val_loss: 0.0113\n",
      "Epoch 71/80\n",
      "114/114 [==============================] - 0s 3ms/step - loss: 0.0279 - val_loss: 0.0108\n",
      "Epoch 72/80\n",
      "114/114 [==============================] - 0s 3ms/step - loss: 0.0279 - val_loss: 0.0111\n",
      "Epoch 73/80\n",
      "114/114 [==============================] - 0s 3ms/step - loss: 0.0278 - val_loss: 0.0109\n",
      "Epoch 74/80\n",
      "114/114 [==============================] - 0s 3ms/step - loss: 0.0279 - val_loss: 0.0107\n",
      "Epoch 75/80\n",
      "114/114 [==============================] - 0s 3ms/step - loss: 0.0278 - val_loss: 0.0108\n",
      "Epoch 76/80\n",
      "114/114 [==============================] - 0s 3ms/step - loss: 0.0278 - val_loss: 0.0107\n",
      "Epoch 77/80\n",
      "114/114 [==============================] - 0s 3ms/step - loss: 0.0278 - val_loss: 0.0105\n",
      "Epoch 78/80\n",
      "114/114 [==============================] - 0s 3ms/step - loss: 0.0278 - val_loss: 0.0108\n",
      "Epoch 79/80\n",
      "114/114 [==============================] - 0s 3ms/step - loss: 0.0276 - val_loss: 0.0112\n",
      "Epoch 80/80\n",
      "114/114 [==============================] - 0s 3ms/step - loss: 0.0273 - val_loss: 0.0106\n",
      "Execution time:  32.62877941131592\n",
      "DNN:\n",
      "Mean Absolute Error: 0.0257\n",
      "Root Mean Square Error: 0.0446\n",
      "Mean Square Error: 0.0020\n",
      "\n",
      "Train RMSE: 0.045\n",
      "Train MSE: 0.002\n",
      "Train MAE: 0.026\n",
      "###########################\n",
      "\n",
      "MODEL:  DNN\n",
      "sequence:  12h\n",
      "units:  80\n",
      "dropout1:  0.11814836227952394\n",
      "optimizer: adam\n",
      "activationDense: tanh\n",
      "epochs: 90\n",
      "batchsize: 25\n",
      "validation_split: 0.1\n",
      "Model: \"sequential_109\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_327 (Dense)            (None, 72, 80)            160       \n",
      "_________________________________________________________________\n",
      "dense_328 (Dense)            (None, 72, 16)            1296      \n",
      "_________________________________________________________________\n",
      "dropout_109 (Dropout)        (None, 72, 16)            0         \n",
      "_________________________________________________________________\n",
      "dense_329 (Dense)            (None, 72, 1)             17        \n",
      "=================================================================\n",
      "Total params: 1,473\n",
      "Trainable params: 1,473\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/90\n",
      "142/142 [==============================] - 1s 4ms/step - loss: 0.1127 - val_loss: 0.0126\n",
      "Epoch 2/90\n",
      "142/142 [==============================] - 0s 3ms/step - loss: 0.0547 - val_loss: 0.0073\n",
      "Epoch 3/90\n",
      "142/142 [==============================] - 0s 3ms/step - loss: 0.0519 - val_loss: 0.0189\n",
      "Epoch 4/90\n",
      "142/142 [==============================] - 0s 3ms/step - loss: 0.0493 - val_loss: 0.0170\n",
      "Epoch 5/90\n",
      "142/142 [==============================] - 0s 3ms/step - loss: 0.0467 - val_loss: 0.0108\n",
      "Epoch 6/90\n",
      "142/142 [==============================] - 0s 3ms/step - loss: 0.0439 - val_loss: 0.0080\n",
      "Epoch 7/90\n",
      "142/142 [==============================] - 0s 3ms/step - loss: 0.0416 - val_loss: 0.0068\n",
      "Epoch 8/90\n",
      "142/142 [==============================] - 0s 3ms/step - loss: 0.0389 - val_loss: 0.0079\n",
      "Epoch 9/90\n",
      "142/142 [==============================] - 0s 3ms/step - loss: 0.0360 - val_loss: 0.0053\n",
      "Epoch 10/90\n",
      "142/142 [==============================] - 0s 3ms/step - loss: 0.0365 - val_loss: 0.0129\n",
      "Epoch 11/90\n",
      "142/142 [==============================] - 0s 3ms/step - loss: 0.0325 - val_loss: 0.0120\n",
      "Epoch 12/90\n",
      "142/142 [==============================] - 0s 3ms/step - loss: 0.0316 - val_loss: 0.0132\n",
      "Epoch 13/90\n",
      "142/142 [==============================] - 0s 3ms/step - loss: 0.0308 - val_loss: 0.0157\n",
      "Epoch 14/90\n",
      "142/142 [==============================] - 0s 3ms/step - loss: 0.0305 - val_loss: 0.0190\n",
      "Epoch 15/90\n",
      "142/142 [==============================] - 0s 3ms/step - loss: 0.0301 - val_loss: 0.0197\n",
      "Epoch 16/90\n",
      "142/142 [==============================] - 0s 3ms/step - loss: 0.0297 - val_loss: 0.0216\n",
      "Epoch 17/90\n",
      "142/142 [==============================] - 0s 3ms/step - loss: 0.0292 - val_loss: 0.0216\n",
      "Epoch 18/90\n",
      "142/142 [==============================] - 0s 3ms/step - loss: 0.0290 - val_loss: 0.0194\n",
      "Epoch 19/90\n",
      "142/142 [==============================] - 0s 3ms/step - loss: 0.0288 - val_loss: 0.0190\n",
      "Epoch 20/90\n",
      "142/142 [==============================] - 0s 3ms/step - loss: 0.0286 - val_loss: 0.0190\n",
      "Epoch 21/90\n",
      "142/142 [==============================] - 0s 3ms/step - loss: 0.0284 - val_loss: 0.0187\n",
      "Epoch 22/90\n",
      "142/142 [==============================] - 0s 3ms/step - loss: 0.0285 - val_loss: 0.0161\n",
      "Epoch 23/90\n",
      "142/142 [==============================] - 0s 3ms/step - loss: 0.0285 - val_loss: 0.0138\n",
      "Epoch 24/90\n",
      "142/142 [==============================] - 0s 3ms/step - loss: 0.0289 - val_loss: 0.0108\n",
      "Epoch 25/90\n",
      "142/142 [==============================] - 0s 3ms/step - loss: 0.0293 - val_loss: 0.0105\n",
      "Epoch 26/90\n",
      "142/142 [==============================] - 0s 3ms/step - loss: 0.0286 - val_loss: 0.0106\n",
      "Epoch 27/90\n",
      "142/142 [==============================] - 0s 3ms/step - loss: 0.0287 - val_loss: 0.0103\n",
      "Epoch 28/90\n",
      "142/142 [==============================] - 0s 3ms/step - loss: 0.0285 - val_loss: 0.0105\n",
      "Epoch 29/90\n",
      "142/142 [==============================] - 0s 3ms/step - loss: 0.0284 - val_loss: 0.0103\n",
      "Epoch 30/90\n",
      "142/142 [==============================] - 0s 3ms/step - loss: 0.0283 - val_loss: 0.0114\n",
      "Epoch 31/90\n",
      "142/142 [==============================] - 0s 3ms/step - loss: 0.0282 - val_loss: 0.0104\n",
      "Epoch 32/90\n",
      "142/142 [==============================] - 0s 3ms/step - loss: 0.0282 - val_loss: 0.0108\n",
      "Epoch 33/90\n",
      "142/142 [==============================] - 0s 3ms/step - loss: 0.0283 - val_loss: 0.0107\n",
      "Epoch 34/90\n",
      "142/142 [==============================] - 0s 3ms/step - loss: 0.0283 - val_loss: 0.0109\n",
      "Epoch 35/90\n",
      "142/142 [==============================] - 0s 3ms/step - loss: 0.0283 - val_loss: 0.0114\n",
      "Epoch 36/90\n",
      "142/142 [==============================] - 0s 3ms/step - loss: 0.0282 - val_loss: 0.0109\n",
      "Epoch 37/90\n",
      "142/142 [==============================] - 0s 3ms/step - loss: 0.0283 - val_loss: 0.0111\n",
      "Epoch 38/90\n",
      "142/142 [==============================] - 0s 3ms/step - loss: 0.0282 - val_loss: 0.0110\n",
      "Epoch 39/90\n",
      "142/142 [==============================] - 0s 3ms/step - loss: 0.0282 - val_loss: 0.0109\n",
      "Epoch 40/90\n",
      "142/142 [==============================] - 0s 3ms/step - loss: 0.0282 - val_loss: 0.0111\n",
      "Epoch 41/90\n",
      "142/142 [==============================] - 0s 3ms/step - loss: 0.0282 - val_loss: 0.0112\n",
      "Epoch 42/90\n",
      "142/142 [==============================] - 0s 3ms/step - loss: 0.0282 - val_loss: 0.0113\n",
      "Epoch 43/90\n",
      "142/142 [==============================] - 0s 3ms/step - loss: 0.0282 - val_loss: 0.0111\n",
      "Epoch 44/90\n",
      "142/142 [==============================] - 0s 3ms/step - loss: 0.0282 - val_loss: 0.0111\n",
      "Epoch 45/90\n",
      "142/142 [==============================] - 0s 3ms/step - loss: 0.0282 - val_loss: 0.0113\n",
      "Epoch 46/90\n",
      "142/142 [==============================] - 0s 3ms/step - loss: 0.0282 - val_loss: 0.0112\n",
      "Epoch 47/90\n",
      "142/142 [==============================] - 0s 3ms/step - loss: 0.0282 - val_loss: 0.0112\n",
      "Epoch 48/90\n",
      "142/142 [==============================] - 0s 3ms/step - loss: 0.0282 - val_loss: 0.0110\n",
      "Epoch 49/90\n",
      "142/142 [==============================] - 0s 3ms/step - loss: 0.0282 - val_loss: 0.0104\n",
      "Epoch 50/90\n",
      "142/142 [==============================] - 0s 3ms/step - loss: 0.0282 - val_loss: 0.0109\n",
      "Epoch 51/90\n",
      "142/142 [==============================] - 0s 3ms/step - loss: 0.0283 - val_loss: 0.0102\n",
      "Epoch 52/90\n",
      "142/142 [==============================] - 0s 3ms/step - loss: 0.0283 - val_loss: 0.0111\n",
      "Epoch 53/90\n",
      "142/142 [==============================] - 0s 3ms/step - loss: 0.0282 - val_loss: 0.0110\n",
      "Epoch 54/90\n",
      "142/142 [==============================] - 0s 3ms/step - loss: 0.0282 - val_loss: 0.0112\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 55/90\n",
      "142/142 [==============================] - 0s 3ms/step - loss: 0.0282 - val_loss: 0.0111\n",
      "Epoch 56/90\n",
      "142/142 [==============================] - 0s 3ms/step - loss: 0.0282 - val_loss: 0.0112\n",
      "Epoch 57/90\n",
      "142/142 [==============================] - 0s 3ms/step - loss: 0.0282 - val_loss: 0.0112\n",
      "Epoch 58/90\n",
      "142/142 [==============================] - 0s 3ms/step - loss: 0.0281 - val_loss: 0.0111\n",
      "Epoch 59/90\n",
      "142/142 [==============================] - 0s 3ms/step - loss: 0.0282 - val_loss: 0.0111\n",
      "Epoch 60/90\n",
      "142/142 [==============================] - 0s 3ms/step - loss: 0.0281 - val_loss: 0.0113\n",
      "Epoch 61/90\n",
      "142/142 [==============================] - 0s 3ms/step - loss: 0.0281 - val_loss: 0.0111\n",
      "Epoch 62/90\n",
      "142/142 [==============================] - 0s 3ms/step - loss: 0.0281 - val_loss: 0.0111\n",
      "Epoch 63/90\n",
      "142/142 [==============================] - 0s 3ms/step - loss: 0.0280 - val_loss: 0.0111\n",
      "Epoch 64/90\n",
      "142/142 [==============================] - 0s 3ms/step - loss: 0.0280 - val_loss: 0.0111\n",
      "Epoch 65/90\n",
      "142/142 [==============================] - 0s 3ms/step - loss: 0.0280 - val_loss: 0.0109\n",
      "Epoch 66/90\n",
      "142/142 [==============================] - 0s 3ms/step - loss: 0.0280 - val_loss: 0.0111\n",
      "Epoch 67/90\n",
      "142/142 [==============================] - 0s 3ms/step - loss: 0.0281 - val_loss: 0.0110\n",
      "Epoch 68/90\n",
      "142/142 [==============================] - 0s 3ms/step - loss: 0.0281 - val_loss: 0.0108\n",
      "Epoch 69/90\n",
      "142/142 [==============================] - 0s 3ms/step - loss: 0.0280 - val_loss: 0.0110\n",
      "Epoch 70/90\n",
      "142/142 [==============================] - 0s 3ms/step - loss: 0.0279 - val_loss: 0.0109\n",
      "Epoch 71/90\n",
      "142/142 [==============================] - 0s 3ms/step - loss: 0.0279 - val_loss: 0.0108\n",
      "Epoch 72/90\n",
      "142/142 [==============================] - 0s 3ms/step - loss: 0.0279 - val_loss: 0.0107\n",
      "Epoch 73/90\n",
      "142/142 [==============================] - 0s 3ms/step - loss: 0.0279 - val_loss: 0.0107\n",
      "Epoch 74/90\n",
      "142/142 [==============================] - 0s 3ms/step - loss: 0.0278 - val_loss: 0.0106\n",
      "Epoch 75/90\n",
      "142/142 [==============================] - 0s 3ms/step - loss: 0.0278 - val_loss: 0.0104\n",
      "Epoch 76/90\n",
      "142/142 [==============================] - 0s 3ms/step - loss: 0.0277 - val_loss: 0.0104\n",
      "Epoch 77/90\n",
      "142/142 [==============================] - 0s 3ms/step - loss: 0.0277 - val_loss: 0.0103\n",
      "Epoch 78/90\n",
      "142/142 [==============================] - 0s 3ms/step - loss: 0.0277 - val_loss: 0.0103\n",
      "Epoch 79/90\n",
      "142/142 [==============================] - 0s 3ms/step - loss: 0.0277 - val_loss: 0.0103\n",
      "Epoch 80/90\n",
      "142/142 [==============================] - 0s 3ms/step - loss: 0.0276 - val_loss: 0.0101\n",
      "Epoch 81/90\n",
      "142/142 [==============================] - 0s 3ms/step - loss: 0.0276 - val_loss: 0.0100\n",
      "Epoch 82/90\n",
      "142/142 [==============================] - 0s 3ms/step - loss: 0.0276 - val_loss: 0.0104\n",
      "Epoch 83/90\n",
      "142/142 [==============================] - 0s 3ms/step - loss: 0.0274 - val_loss: 0.0100\n",
      "Epoch 84/90\n",
      "142/142 [==============================] - 0s 3ms/step - loss: 0.0274 - val_loss: 0.0101\n",
      "Epoch 85/90\n",
      "142/142 [==============================] - 0s 3ms/step - loss: 0.0273 - val_loss: 0.0099\n",
      "Epoch 86/90\n",
      "142/142 [==============================] - 0s 3ms/step - loss: 0.0273 - val_loss: 0.0099\n",
      "Epoch 87/90\n",
      "142/142 [==============================] - 0s 3ms/step - loss: 0.0271 - val_loss: 0.0098\n",
      "Epoch 88/90\n",
      "142/142 [==============================] - 0s 3ms/step - loss: 0.0271 - val_loss: 0.0098\n",
      "Epoch 89/90\n",
      "142/142 [==============================] - 0s 3ms/step - loss: 0.0270 - val_loss: 0.0103\n",
      "Epoch 90/90\n",
      "142/142 [==============================] - 0s 3ms/step - loss: 0.0268 - val_loss: 0.0103\n",
      "Execution time:  38.99303841590881\n",
      "DNN:\n",
      "Mean Absolute Error: 0.0247\n",
      "Root Mean Square Error: 0.0426\n",
      "Mean Square Error: 0.0018\n",
      "\n",
      "Train RMSE: 0.043\n",
      "Train MSE: 0.002\n",
      "Train MAE: 0.025\n",
      "###########################\n",
      "\n",
      "MODEL:  DNN\n",
      "sequence:  12h\n",
      "units:  12\n",
      "dropout1:  0.48476373451509647\n",
      "optimizer: adam\n",
      "activationDense: tanh\n",
      "epochs: 52\n",
      "batchsize: 57\n",
      "validation_split: 0.1\n",
      "Model: \"sequential_110\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_330 (Dense)            (None, 72, 12)            24        \n",
      "_________________________________________________________________\n",
      "dense_331 (Dense)            (None, 72, 16)            208       \n",
      "_________________________________________________________________\n",
      "dropout_110 (Dropout)        (None, 72, 16)            0         \n",
      "_________________________________________________________________\n",
      "dense_332 (Dense)            (None, 72, 1)             17        \n",
      "=================================================================\n",
      "Total params: 249\n",
      "Trainable params: 249\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/52\n",
      "62/62 [==============================] - 0s 6ms/step - loss: 0.2038 - val_loss: 0.0484\n",
      "Epoch 2/52\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.1167 - val_loss: 0.0214\n",
      "Epoch 3/52\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.1021 - val_loss: 0.0163\n",
      "Epoch 4/52\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.0892 - val_loss: 0.0214\n",
      "Epoch 5/52\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.0807 - val_loss: 0.0155\n",
      "Epoch 6/52\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.0690 - val_loss: 0.0076\n",
      "Epoch 7/52\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.0603 - val_loss: 0.0075\n",
      "Epoch 8/52\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.0535 - val_loss: 0.0068\n",
      "Epoch 9/52\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.0473 - val_loss: 0.0066\n",
      "Epoch 10/52\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.0419 - val_loss: 0.0070\n",
      "Epoch 11/52\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.0374 - val_loss: 0.0071\n",
      "Epoch 12/52\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.0338 - val_loss: 0.0079\n",
      "Epoch 13/52\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.0311 - val_loss: 0.0083\n",
      "Epoch 14/52\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.0294 - val_loss: 0.0080\n",
      "Epoch 15/52\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.0285 - val_loss: 0.0084\n",
      "Epoch 16/52\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.0279 - val_loss: 0.0095\n",
      "Epoch 17/52\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.0275 - val_loss: 0.0098\n",
      "Epoch 18/52\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.0277 - val_loss: 0.0125\n",
      "Epoch 19/52\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.0272 - val_loss: 0.0128\n",
      "Epoch 20/52\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.0268 - val_loss: 0.0102\n",
      "Epoch 21/52\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.0276 - val_loss: 0.0147\n",
      "Epoch 22/52\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.0267 - val_loss: 0.0126\n",
      "Epoch 23/52\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.0272 - val_loss: 0.0155\n",
      "Epoch 24/52\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.0266 - val_loss: 0.0138\n",
      "Epoch 25/52\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.0266 - val_loss: 0.0125\n",
      "Epoch 26/52\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.0268 - val_loss: 0.0119\n",
      "Epoch 27/52\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.0272 - val_loss: 0.0147\n",
      "Epoch 28/52\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.0266 - val_loss: 0.0136\n",
      "Epoch 29/52\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.0266 - val_loss: 0.0134\n",
      "Epoch 30/52\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.0265 - val_loss: 0.0124\n",
      "Epoch 31/52\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.0269 - val_loss: 0.0141\n",
      "Epoch 32/52\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.0264 - val_loss: 0.0132\n",
      "Epoch 33/52\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.0266 - val_loss: 0.0137\n",
      "Epoch 34/52\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "62/62 [==============================] - 0s 3ms/step - loss: 0.0266 - val_loss: 0.0142\n",
      "Epoch 35/52\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.0265 - val_loss: 0.0150\n",
      "Epoch 36/52\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.0263 - val_loss: 0.0146\n",
      "Epoch 37/52\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.0261 - val_loss: 0.0129\n",
      "Epoch 38/52\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.0263 - val_loss: 0.0123\n",
      "Epoch 39/52\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.0263 - val_loss: 0.0117\n",
      "Epoch 40/52\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.0267 - val_loss: 0.0130\n",
      "Epoch 41/52\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.0265 - val_loss: 0.0144\n",
      "Epoch 42/52\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.0262 - val_loss: 0.0147\n",
      "Epoch 43/52\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.0260 - val_loss: 0.0131\n",
      "Epoch 44/52\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.0260 - val_loss: 0.0118\n",
      "Epoch 45/52\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.0261 - val_loss: 0.0111\n",
      "Epoch 46/52\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.0262 - val_loss: 0.0108\n",
      "Epoch 47/52\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.0265 - val_loss: 0.0122\n",
      "Epoch 48/52\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.0264 - val_loss: 0.0135\n",
      "Epoch 49/52\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.0261 - val_loss: 0.0140\n",
      "Epoch 50/52\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.0259 - val_loss: 0.0139\n",
      "Epoch 51/52\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.0255 - val_loss: 0.0114\n",
      "Epoch 52/52\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.0258 - val_loss: 0.0105\n",
      "Execution time:  12.056646823883057\n",
      "DNN:\n",
      "Mean Absolute Error: 0.0231\n",
      "Root Mean Square Error: 0.0385\n",
      "Mean Square Error: 0.0015\n",
      "\n",
      "Train RMSE: 0.039\n",
      "Train MSE: 0.001\n",
      "Train MAE: 0.023\n",
      "###########################\n",
      "\n",
      "MODEL:  DNN\n",
      "sequence:  12h\n",
      "units:  87\n",
      "dropout1:  0.40519643149940265\n",
      "optimizer: adam\n",
      "activationDense: tanh\n",
      "epochs: 80\n",
      "batchsize: 31\n",
      "validation_split: 0.2\n",
      "Model: \"sequential_111\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_333 (Dense)            (None, 72, 87)            174       \n",
      "_________________________________________________________________\n",
      "dense_334 (Dense)            (None, 72, 16)            1408      \n",
      "_________________________________________________________________\n",
      "dropout_111 (Dropout)        (None, 72, 16)            0         \n",
      "_________________________________________________________________\n",
      "dense_335 (Dense)            (None, 72, 1)             17        \n",
      "=================================================================\n",
      "Total params: 1,599\n",
      "Trainable params: 1,599\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/80\n",
      "102/102 [==============================] - 1s 6ms/step - loss: 0.1279 - val_loss: 0.0304\n",
      "Epoch 2/80\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.0825 - val_loss: 0.0221\n",
      "Epoch 3/80\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.0713 - val_loss: 0.0182\n",
      "Epoch 4/80\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.0599 - val_loss: 0.0151\n",
      "Epoch 5/80\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.0495 - val_loss: 0.0153\n",
      "Epoch 6/80\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.0432 - val_loss: 0.0155\n",
      "Epoch 7/80\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.0375 - val_loss: 0.0160\n",
      "Epoch 8/80\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.0345 - val_loss: 0.0154\n",
      "Epoch 9/80\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.0327 - val_loss: 0.0169\n",
      "Epoch 10/80\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.0325 - val_loss: 0.0180\n",
      "Epoch 11/80\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.0325 - val_loss: 0.0172\n",
      "Epoch 12/80\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.0315 - val_loss: 0.0164\n",
      "Epoch 13/80\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.0309 - val_loss: 0.0162\n",
      "Epoch 14/80\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.0305 - val_loss: 0.0160\n",
      "Epoch 15/80\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.0312 - val_loss: 0.0160\n",
      "Epoch 16/80\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.0297 - val_loss: 0.0175\n",
      "Epoch 17/80\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.0292 - val_loss: 0.0179\n",
      "Epoch 18/80\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.0293 - val_loss: 0.0170\n",
      "Epoch 19/80\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.0294 - val_loss: 0.0179\n",
      "Epoch 20/80\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.0291 - val_loss: 0.0173\n",
      "Epoch 21/80\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.0295 - val_loss: 0.0169\n",
      "Epoch 22/80\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.0293 - val_loss: 0.0164\n",
      "Epoch 23/80\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.0293 - val_loss: 0.0172\n",
      "Epoch 24/80\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.0292 - val_loss: 0.0177\n",
      "Epoch 25/80\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.0289 - val_loss: 0.0173\n",
      "Epoch 26/80\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.0290 - val_loss: 0.0172\n",
      "Epoch 27/80\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.0291 - val_loss: 0.0175\n",
      "Epoch 28/80\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.0289 - val_loss: 0.0174\n",
      "Epoch 29/80\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.0289 - val_loss: 0.0173\n",
      "Epoch 30/80\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.0290 - val_loss: 0.0174\n",
      "Epoch 31/80\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.0289 - val_loss: 0.0174\n",
      "Epoch 32/80\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.0289 - val_loss: 0.0174\n",
      "Epoch 33/80\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.0289 - val_loss: 0.0172\n",
      "Epoch 34/80\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.0290 - val_loss: 0.0174\n",
      "Epoch 35/80\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.0289 - val_loss: 0.0175\n",
      "Epoch 36/80\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.0288 - val_loss: 0.0174\n",
      "Epoch 37/80\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.0288 - val_loss: 0.0173\n",
      "Epoch 38/80\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.0289 - val_loss: 0.0172\n",
      "Epoch 39/80\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.0289 - val_loss: 0.0173\n",
      "Epoch 40/80\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.0289 - val_loss: 0.0173\n",
      "Epoch 41/80\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.0288 - val_loss: 0.0173\n",
      "Epoch 42/80\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.0288 - val_loss: 0.0172\n",
      "Epoch 43/80\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.0289 - val_loss: 0.0172\n",
      "Epoch 44/80\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.0289 - val_loss: 0.0172\n",
      "Epoch 45/80\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.0288 - val_loss: 0.0172\n",
      "Epoch 46/80\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.0289 - val_loss: 0.0172\n",
      "Epoch 47/80\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.0288 - val_loss: 0.0170\n",
      "Epoch 48/80\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.0289 - val_loss: 0.0170\n",
      "Epoch 49/80\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.0288 - val_loss: 0.0171\n",
      "Epoch 50/80\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.0288 - val_loss: 0.0171\n",
      "Epoch 51/80\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "102/102 [==============================] - 0s 4ms/step - loss: 0.0288 - val_loss: 0.0170\n",
      "Epoch 52/80\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.0288 - val_loss: 0.0171\n",
      "Epoch 53/80\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.0288 - val_loss: 0.0171\n",
      "Epoch 54/80\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.0288 - val_loss: 0.0171\n",
      "Epoch 55/80\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.0287 - val_loss: 0.0170\n",
      "Epoch 56/80\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.0288 - val_loss: 0.0169\n",
      "Epoch 57/80\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.0288 - val_loss: 0.0169\n",
      "Epoch 58/80\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.0287 - val_loss: 0.0168\n",
      "Epoch 59/80\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.0288 - val_loss: 0.0169\n",
      "Epoch 60/80\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.0287 - val_loss: 0.0168\n",
      "Epoch 61/80\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.0287 - val_loss: 0.0167\n",
      "Epoch 62/80\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.0287 - val_loss: 0.0167\n",
      "Epoch 63/80\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.0287 - val_loss: 0.0167\n",
      "Epoch 64/80\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.0287 - val_loss: 0.0167\n",
      "Epoch 65/80\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.0286 - val_loss: 0.0167\n",
      "Epoch 66/80\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.0286 - val_loss: 0.0166\n",
      "Epoch 67/80\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.0286 - val_loss: 0.0167\n",
      "Epoch 68/80\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.0286 - val_loss: 0.0166\n",
      "Epoch 69/80\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.0286 - val_loss: 0.0167\n",
      "Epoch 70/80\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.0285 - val_loss: 0.0164\n",
      "Epoch 71/80\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.0285 - val_loss: 0.0167\n",
      "Epoch 72/80\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.0284 - val_loss: 0.0163\n",
      "Epoch 73/80\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.0284 - val_loss: 0.0166\n",
      "Epoch 74/80\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.0284 - val_loss: 0.0165\n",
      "Epoch 75/80\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.0283 - val_loss: 0.0165\n",
      "Epoch 76/80\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.0283 - val_loss: 0.0164\n",
      "Epoch 77/80\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.0282 - val_loss: 0.0166\n",
      "Epoch 78/80\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.0281 - val_loss: 0.0164\n",
      "Epoch 79/80\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.0281 - val_loss: 0.0164\n",
      "Epoch 80/80\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.0280 - val_loss: 0.0165\n",
      "Execution time:  31.652584075927734\n",
      "DNN:\n",
      "Mean Absolute Error: 0.0241\n",
      "Root Mean Square Error: 0.0407\n",
      "Mean Square Error: 0.0017\n",
      "\n",
      "Train RMSE: 0.041\n",
      "Train MSE: 0.002\n",
      "Train MAE: 0.024\n",
      "###########################\n",
      "\n",
      "MODEL:  DNN\n",
      "sequence:  12h\n",
      "units:  80\n",
      "dropout1:  0.11814836227952394\n",
      "optimizer: adam\n",
      "activationDense: tanh\n",
      "epochs: 90\n",
      "batchsize: 25\n",
      "validation_split: 0.2\n",
      "Model: \"sequential_112\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_336 (Dense)            (None, 72, 80)            160       \n",
      "_________________________________________________________________\n",
      "dense_337 (Dense)            (None, 72, 16)            1296      \n",
      "_________________________________________________________________\n",
      "dropout_112 (Dropout)        (None, 72, 16)            0         \n",
      "_________________________________________________________________\n",
      "dense_338 (Dense)            (None, 72, 1)             17        \n",
      "=================================================================\n",
      "Total params: 1,473\n",
      "Trainable params: 1,473\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/90\n",
      "126/126 [==============================] - 1s 5ms/step - loss: 0.0997 - val_loss: 0.0307\n",
      "Epoch 2/90\n",
      "126/126 [==============================] - 0s 3ms/step - loss: 0.0556 - val_loss: 0.0290\n",
      "Epoch 3/90\n",
      "126/126 [==============================] - 0s 3ms/step - loss: 0.0532 - val_loss: 0.0328\n",
      "Epoch 4/90\n",
      "126/126 [==============================] - 0s 3ms/step - loss: 0.0508 - val_loss: 0.0240\n",
      "Epoch 5/90\n",
      "126/126 [==============================] - 0s 3ms/step - loss: 0.0480 - val_loss: 0.0219\n",
      "Epoch 6/90\n",
      "126/126 [==============================] - 0s 3ms/step - loss: 0.0456 - val_loss: 0.0172\n",
      "Epoch 7/90\n",
      "126/126 [==============================] - 0s 3ms/step - loss: 0.0428 - val_loss: 0.0176\n",
      "Epoch 8/90\n",
      "126/126 [==============================] - 0s 3ms/step - loss: 0.0406 - val_loss: 0.0159\n",
      "Epoch 9/90\n",
      "126/126 [==============================] - 0s 3ms/step - loss: 0.0385 - val_loss: 0.0164\n",
      "Epoch 10/90\n",
      "126/126 [==============================] - 0s 3ms/step - loss: 0.0366 - val_loss: 0.0161\n",
      "Epoch 11/90\n",
      "126/126 [==============================] - 0s 3ms/step - loss: 0.0345 - val_loss: 0.0156\n",
      "Epoch 12/90\n",
      "126/126 [==============================] - 0s 3ms/step - loss: 0.0332 - val_loss: 0.0156\n",
      "Epoch 13/90\n",
      "126/126 [==============================] - 0s 3ms/step - loss: 0.0323 - val_loss: 0.0157\n",
      "Epoch 14/90\n",
      "126/126 [==============================] - 0s 3ms/step - loss: 0.0315 - val_loss: 0.0156\n",
      "Epoch 15/90\n",
      "126/126 [==============================] - 0s 3ms/step - loss: 0.0310 - val_loss: 0.0154\n",
      "Epoch 16/90\n",
      "126/126 [==============================] - 0s 3ms/step - loss: 0.0305 - val_loss: 0.0163\n",
      "Epoch 17/90\n",
      "126/126 [==============================] - 0s 3ms/step - loss: 0.0304 - val_loss: 0.0158\n",
      "Epoch 18/90\n",
      "126/126 [==============================] - 0s 3ms/step - loss: 0.0300 - val_loss: 0.0157\n",
      "Epoch 19/90\n",
      "126/126 [==============================] - 0s 3ms/step - loss: 0.0298 - val_loss: 0.0165\n",
      "Epoch 20/90\n",
      "126/126 [==============================] - 0s 3ms/step - loss: 0.0307 - val_loss: 0.0152\n",
      "Epoch 21/90\n",
      "126/126 [==============================] - 0s 3ms/step - loss: 0.0293 - val_loss: 0.0163\n",
      "Epoch 22/90\n",
      "126/126 [==============================] - 0s 3ms/step - loss: 0.0296 - val_loss: 0.0163\n",
      "Epoch 23/90\n",
      "126/126 [==============================] - 0s 3ms/step - loss: 0.0295 - val_loss: 0.0159\n",
      "Epoch 24/90\n",
      "126/126 [==============================] - 0s 3ms/step - loss: 0.0294 - val_loss: 0.0159\n",
      "Epoch 25/90\n",
      "126/126 [==============================] - 0s 3ms/step - loss: 0.0296 - val_loss: 0.0159\n",
      "Epoch 26/90\n",
      "126/126 [==============================] - 0s 3ms/step - loss: 0.0300 - val_loss: 0.0160\n",
      "Epoch 27/90\n",
      "126/126 [==============================] - 0s 3ms/step - loss: 0.0299 - val_loss: 0.0160\n",
      "Epoch 28/90\n",
      "126/126 [==============================] - 0s 3ms/step - loss: 0.0298 - val_loss: 0.0161\n",
      "Epoch 29/90\n",
      "126/126 [==============================] - 0s 3ms/step - loss: 0.0296 - val_loss: 0.0161\n",
      "Epoch 30/90\n",
      "126/126 [==============================] - 0s 3ms/step - loss: 0.0296 - val_loss: 0.0161\n",
      "Epoch 31/90\n",
      "126/126 [==============================] - 0s 3ms/step - loss: 0.0296 - val_loss: 0.0160\n",
      "Epoch 32/90\n",
      "126/126 [==============================] - 0s 3ms/step - loss: 0.0296 - val_loss: 0.0160\n",
      "Epoch 33/90\n",
      "126/126 [==============================] - 0s 3ms/step - loss: 0.0295 - val_loss: 0.0160\n",
      "Epoch 34/90\n",
      "126/126 [==============================] - 0s 3ms/step - loss: 0.0296 - val_loss: 0.0160\n",
      "Epoch 35/90\n",
      "126/126 [==============================] - 0s 3ms/step - loss: 0.0296 - val_loss: 0.0160\n",
      "Epoch 36/90\n",
      "126/126 [==============================] - 0s 3ms/step - loss: 0.0294 - val_loss: 0.0160\n",
      "Epoch 37/90\n",
      "126/126 [==============================] - 0s 3ms/step - loss: 0.0294 - val_loss: 0.0160\n",
      "Epoch 38/90\n",
      "126/126 [==============================] - 0s 4ms/step - loss: 0.0294 - val_loss: 0.0160\n",
      "Epoch 39/90\n",
      "126/126 [==============================] - 0s 3ms/step - loss: 0.0317 - val_loss: 0.0161\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 40/90\n",
      "126/126 [==============================] - 0s 3ms/step - loss: 0.0293 - val_loss: 0.0160\n",
      "Epoch 41/90\n",
      "126/126 [==============================] - 0s 3ms/step - loss: 0.0293 - val_loss: 0.0159\n",
      "Epoch 42/90\n",
      "126/126 [==============================] - 0s 3ms/step - loss: 0.0293 - val_loss: 0.0162\n",
      "Epoch 43/90\n",
      "126/126 [==============================] - 0s 3ms/step - loss: 0.0292 - val_loss: 0.0159\n",
      "Epoch 44/90\n",
      "126/126 [==============================] - 0s 3ms/step - loss: 0.0293 - val_loss: 0.0161\n",
      "Epoch 45/90\n",
      "126/126 [==============================] - 0s 3ms/step - loss: 0.0293 - val_loss: 0.0160\n",
      "Epoch 46/90\n",
      "126/126 [==============================] - 0s 3ms/step - loss: 0.0293 - val_loss: 0.0162\n",
      "Epoch 47/90\n",
      "126/126 [==============================] - 0s 3ms/step - loss: 0.0292 - val_loss: 0.0160\n",
      "Epoch 48/90\n",
      "126/126 [==============================] - 0s 3ms/step - loss: 0.0292 - val_loss: 0.0161\n",
      "Epoch 49/90\n",
      "126/126 [==============================] - 0s 3ms/step - loss: 0.0292 - val_loss: 0.0161\n",
      "Epoch 50/90\n",
      "126/126 [==============================] - 0s 3ms/step - loss: 0.0292 - val_loss: 0.0161\n",
      "Epoch 51/90\n",
      "126/126 [==============================] - 0s 3ms/step - loss: 0.0292 - val_loss: 0.0162\n",
      "Epoch 52/90\n",
      "126/126 [==============================] - 0s 3ms/step - loss: 0.0292 - val_loss: 0.0160\n",
      "Epoch 53/90\n",
      "126/126 [==============================] - 0s 3ms/step - loss: 0.0292 - val_loss: 0.0162\n",
      "Epoch 54/90\n",
      "126/126 [==============================] - 0s 3ms/step - loss: 0.0291 - val_loss: 0.0161\n",
      "Epoch 55/90\n",
      "126/126 [==============================] - 0s 3ms/step - loss: 0.0291 - val_loss: 0.0162\n",
      "Epoch 56/90\n",
      "126/126 [==============================] - 0s 3ms/step - loss: 0.0291 - val_loss: 0.0161\n",
      "Epoch 57/90\n",
      "126/126 [==============================] - 0s 3ms/step - loss: 0.0291 - val_loss: 0.0161\n",
      "Epoch 58/90\n",
      "126/126 [==============================] - 0s 3ms/step - loss: 0.0291 - val_loss: 0.0162\n",
      "Epoch 59/90\n",
      "126/126 [==============================] - ETA: 0s - loss: 0.031 - 0s 3ms/step - loss: 0.0291 - val_loss: 0.0161\n",
      "Epoch 60/90\n",
      "126/126 [==============================] - 0s 3ms/step - loss: 0.0291 - val_loss: 0.0161\n",
      "Epoch 61/90\n",
      "126/126 [==============================] - 0s 3ms/step - loss: 0.0291 - val_loss: 0.0160\n",
      "Epoch 62/90\n",
      "126/126 [==============================] - 0s 3ms/step - loss: 0.0291 - val_loss: 0.0162\n",
      "Epoch 63/90\n",
      "126/126 [==============================] - 0s 3ms/step - loss: 0.0290 - val_loss: 0.0160\n",
      "Epoch 64/90\n",
      "126/126 [==============================] - 0s 3ms/step - loss: 0.0291 - val_loss: 0.0161\n",
      "Epoch 65/90\n",
      "126/126 [==============================] - 0s 3ms/step - loss: 0.0290 - val_loss: 0.0159\n",
      "Epoch 66/90\n",
      "126/126 [==============================] - 0s 3ms/step - loss: 0.0291 - val_loss: 0.0160\n",
      "Epoch 67/90\n",
      "126/126 [==============================] - 0s 3ms/step - loss: 0.0290 - val_loss: 0.0159\n",
      "Epoch 68/90\n",
      "126/126 [==============================] - 0s 3ms/step - loss: 0.0290 - val_loss: 0.0160\n",
      "Epoch 69/90\n",
      "126/126 [==============================] - 0s 3ms/step - loss: 0.0290 - val_loss: 0.0159\n",
      "Epoch 70/90\n",
      "126/126 [==============================] - 0s 3ms/step - loss: 0.0290 - val_loss: 0.0160\n",
      "Epoch 71/90\n",
      "126/126 [==============================] - 0s 3ms/step - loss: 0.0289 - val_loss: 0.0159\n",
      "Epoch 72/90\n",
      "126/126 [==============================] - 0s 3ms/step - loss: 0.0289 - val_loss: 0.0159\n",
      "Epoch 73/90\n",
      "126/126 [==============================] - 0s 3ms/step - loss: 0.0289 - val_loss: 0.0159\n",
      "Epoch 74/90\n",
      "126/126 [==============================] - 0s 3ms/step - loss: 0.0289 - val_loss: 0.0161\n",
      "Epoch 75/90\n",
      "126/126 [==============================] - 0s 3ms/step - loss: 0.0288 - val_loss: 0.0160\n",
      "Epoch 76/90\n",
      "126/126 [==============================] - 0s 4ms/step - loss: 0.0288 - val_loss: 0.0159\n",
      "Epoch 77/90\n",
      "126/126 [==============================] - 0s 3ms/step - loss: 0.0287 - val_loss: 0.0159\n",
      "Epoch 78/90\n",
      "126/126 [==============================] - 0s 3ms/step - loss: 0.0287 - val_loss: 0.0159\n",
      "Epoch 79/90\n",
      "126/126 [==============================] - 0s 3ms/step - loss: 0.0286 - val_loss: 0.0159\n",
      "Epoch 80/90\n",
      "126/126 [==============================] - 0s 3ms/step - loss: 0.0287 - val_loss: 0.0159\n",
      "Epoch 81/90\n",
      "126/126 [==============================] - 0s 3ms/step - loss: 0.0285 - val_loss: 0.0160\n",
      "Epoch 82/90\n",
      "126/126 [==============================] - 0s 3ms/step - loss: 0.0285 - val_loss: 0.0160\n",
      "Epoch 83/90\n",
      "126/126 [==============================] - 0s 3ms/step - loss: 0.0284 - val_loss: 0.0160\n",
      "Epoch 84/90\n",
      "126/126 [==============================] - 0s 3ms/step - loss: 0.0284 - val_loss: 0.0160\n",
      "Epoch 85/90\n",
      "126/126 [==============================] - 0s 3ms/step - loss: 0.0283 - val_loss: 0.0160\n",
      "Epoch 86/90\n",
      "126/126 [==============================] - 0s 3ms/step - loss: 0.0281 - val_loss: 0.0160\n",
      "Epoch 87/90\n",
      "126/126 [==============================] - 0s 3ms/step - loss: 0.0281 - val_loss: 0.0160\n",
      "Epoch 88/90\n",
      "126/126 [==============================] - 0s 3ms/step - loss: 0.0280 - val_loss: 0.0160\n",
      "Epoch 89/90\n",
      "126/126 [==============================] - 0s 3ms/step - loss: 0.0279 - val_loss: 0.0160\n",
      "Epoch 90/90\n",
      "126/126 [==============================] - 0s 3ms/step - loss: 0.0279 - val_loss: 0.0160\n",
      "Execution time:  37.655999183654785\n",
      "DNN:\n",
      "Mean Absolute Error: 0.0252\n",
      "Root Mean Square Error: 0.0428\n",
      "Mean Square Error: 0.0018\n",
      "\n",
      "Train RMSE: 0.043\n",
      "Train MSE: 0.002\n",
      "Train MAE: 0.025\n",
      "###########################\n",
      "\n",
      "MODEL:  DNN\n",
      "sequence:  12h\n",
      "units:  12\n",
      "dropout1:  0.48476373451509647\n",
      "optimizer: adam\n",
      "activationDense: tanh\n",
      "epochs: 52\n",
      "batchsize: 57\n",
      "validation_split: 0.2\n",
      "Model: \"sequential_113\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_339 (Dense)            (None, 72, 12)            24        \n",
      "_________________________________________________________________\n",
      "dense_340 (Dense)            (None, 72, 16)            208       \n",
      "_________________________________________________________________\n",
      "dropout_113 (Dropout)        (None, 72, 16)            0         \n",
      "_________________________________________________________________\n",
      "dense_341 (Dense)            (None, 72, 1)             17        \n",
      "=================================================================\n",
      "Total params: 249\n",
      "Trainable params: 249\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/52\n",
      "55/55 [==============================] - 0s 7ms/step - loss: 0.1432 - val_loss: 0.0198\n",
      "Epoch 2/52\n",
      "55/55 [==============================] - 0s 3ms/step - loss: 0.0967 - val_loss: 0.0214\n",
      "Epoch 3/52\n",
      "55/55 [==============================] - 0s 3ms/step - loss: 0.0828 - val_loss: 0.0148\n",
      "Epoch 4/52\n",
      "55/55 [==============================] - 0s 3ms/step - loss: 0.0742 - val_loss: 0.0147\n",
      "Epoch 5/52\n",
      "55/55 [==============================] - 0s 3ms/step - loss: 0.0668 - val_loss: 0.0152\n",
      "Epoch 6/52\n",
      "55/55 [==============================] - 0s 3ms/step - loss: 0.0595 - val_loss: 0.0177\n",
      "Epoch 7/52\n",
      "55/55 [==============================] - 0s 3ms/step - loss: 0.0528 - val_loss: 0.0248\n",
      "Epoch 8/52\n",
      "55/55 [==============================] - 0s 3ms/step - loss: 0.0476 - val_loss: 0.0158\n",
      "Epoch 9/52\n",
      "55/55 [==============================] - 0s 3ms/step - loss: 0.0429 - val_loss: 0.0153\n",
      "Epoch 10/52\n",
      "55/55 [==============================] - 0s 3ms/step - loss: 0.0391 - val_loss: 0.0150\n",
      "Epoch 11/52\n",
      "55/55 [==============================] - 0s 3ms/step - loss: 0.0360 - val_loss: 0.0149\n",
      "Epoch 12/52\n",
      "55/55 [==============================] - 0s 3ms/step - loss: 0.0338 - val_loss: 0.0150\n",
      "Epoch 13/52\n",
      "55/55 [==============================] - 0s 3ms/step - loss: 0.0320 - val_loss: 0.0148\n",
      "Epoch 14/52\n",
      "55/55 [==============================] - 0s 3ms/step - loss: 0.0305 - val_loss: 0.0153\n",
      "Epoch 15/52\n",
      "55/55 [==============================] - 0s 3ms/step - loss: 0.0304 - val_loss: 0.0154\n",
      "Epoch 16/52\n",
      "55/55 [==============================] - 0s 4ms/step - loss: 0.0300 - val_loss: 0.0151\n",
      "Epoch 17/52\n",
      "55/55 [==============================] - 0s 3ms/step - loss: 0.0285 - val_loss: 0.0156\n",
      "Epoch 18/52\n",
      "55/55 [==============================] - 0s 3ms/step - loss: 0.0284 - val_loss: 0.0157\n",
      "Epoch 19/52\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "55/55 [==============================] - 0s 3ms/step - loss: 0.0289 - val_loss: 0.0164\n",
      "Epoch 20/52\n",
      "55/55 [==============================] - 0s 3ms/step - loss: 0.0280 - val_loss: 0.0155\n",
      "Epoch 21/52\n",
      "55/55 [==============================] - 0s 3ms/step - loss: 0.0283 - val_loss: 0.0159\n",
      "Epoch 22/52\n",
      "55/55 [==============================] - 0s 3ms/step - loss: 0.0280 - val_loss: 0.0170\n",
      "Epoch 23/52\n",
      "55/55 [==============================] - 0s 3ms/step - loss: 0.0279 - val_loss: 0.0158\n",
      "Epoch 24/52\n",
      "55/55 [==============================] - 0s 3ms/step - loss: 0.0274 - val_loss: 0.0159\n",
      "Epoch 25/52\n",
      "55/55 [==============================] - 0s 3ms/step - loss: 0.0276 - val_loss: 0.0158\n",
      "Epoch 26/52\n",
      "55/55 [==============================] - 0s 3ms/step - loss: 0.0276 - val_loss: 0.0159\n",
      "Epoch 27/52\n",
      "55/55 [==============================] - 0s 3ms/step - loss: 0.0272 - val_loss: 0.0156\n",
      "Epoch 28/52\n",
      "55/55 [==============================] - 0s 3ms/step - loss: 0.0271 - val_loss: 0.0158\n",
      "Epoch 29/52\n",
      "55/55 [==============================] - 0s 3ms/step - loss: 0.0273 - val_loss: 0.0156\n",
      "Epoch 30/52\n",
      "55/55 [==============================] - 0s 3ms/step - loss: 0.0269 - val_loss: 0.0159\n",
      "Epoch 31/52\n",
      "55/55 [==============================] - 0s 3ms/step - loss: 0.0266 - val_loss: 0.0157\n",
      "Epoch 32/52\n",
      "55/55 [==============================] - 0s 3ms/step - loss: 0.0266 - val_loss: 0.0157\n",
      "Epoch 33/52\n",
      "55/55 [==============================] - 0s 3ms/step - loss: 0.0264 - val_loss: 0.0156\n",
      "Epoch 34/52\n",
      "55/55 [==============================] - 0s 3ms/step - loss: 0.0271 - val_loss: 0.0167\n",
      "Epoch 35/52\n",
      "55/55 [==============================] - 0s 3ms/step - loss: 0.0261 - val_loss: 0.0167\n",
      "Epoch 36/52\n",
      "55/55 [==============================] - 0s 3ms/step - loss: 0.0260 - val_loss: 0.0159\n",
      "Epoch 37/52\n",
      "55/55 [==============================] - 0s 3ms/step - loss: 0.0260 - val_loss: 0.0157\n",
      "Epoch 38/52\n",
      "55/55 [==============================] - 0s 3ms/step - loss: 0.0262 - val_loss: 0.0157\n",
      "Epoch 39/52\n",
      "55/55 [==============================] - 0s 3ms/step - loss: 0.0259 - val_loss: 0.0156\n",
      "Epoch 40/52\n",
      "55/55 [==============================] - 0s 3ms/step - loss: 0.0261 - val_loss: 0.0157\n",
      "Epoch 41/52\n",
      "55/55 [==============================] - 0s 3ms/step - loss: 0.0258 - val_loss: 0.0158\n",
      "Epoch 42/52\n",
      "55/55 [==============================] - 0s 3ms/step - loss: 0.0257 - val_loss: 0.0158\n",
      "Epoch 43/52\n",
      "55/55 [==============================] - 0s 3ms/step - loss: 0.0257 - val_loss: 0.0158\n",
      "Epoch 44/52\n",
      "55/55 [==============================] - 0s 3ms/step - loss: 0.0256 - val_loss: 0.0157\n",
      "Epoch 45/52\n",
      "55/55 [==============================] - 0s 3ms/step - loss: 0.0254 - val_loss: 0.0158\n",
      "Epoch 46/52\n",
      "55/55 [==============================] - 0s 3ms/step - loss: 0.0255 - val_loss: 0.0159\n",
      "Epoch 47/52\n",
      "55/55 [==============================] - 0s 3ms/step - loss: 0.0252 - val_loss: 0.0159\n",
      "Epoch 48/52\n",
      "55/55 [==============================] - 0s 4ms/step - loss: 0.0254 - val_loss: 0.0162\n",
      "Epoch 49/52\n",
      "55/55 [==============================] - 0s 4ms/step - loss: 0.0250 - val_loss: 0.0160\n",
      "Epoch 50/52\n",
      "55/55 [==============================] - 0s 4ms/step - loss: 0.0251 - val_loss: 0.0161\n",
      "Epoch 51/52\n",
      "55/55 [==============================] - 0s 4ms/step - loss: 0.0249 - val_loss: 0.0161\n",
      "Epoch 52/52\n",
      "55/55 [==============================] - 0s 4ms/step - loss: 0.0250 - val_loss: 0.0166\n",
      "Execution time:  10.367257595062256\n",
      "DNN:\n",
      "Mean Absolute Error: 0.0182\n",
      "Root Mean Square Error: 0.0291\n",
      "Mean Square Error: 0.0008\n",
      "\n",
      "Train RMSE: 0.029\n",
      "Train MSE: 0.001\n",
      "Train MAE: 0.018\n",
      "###########################\n",
      "\n",
      "MODEL:  DNN\n",
      "sequence:  12h\n",
      "units:  87\n",
      "dropout1:  0.40519643149940265\n",
      "optimizer: adam\n",
      "activationDense: sigmoid\n",
      "epochs: 80\n",
      "batchsize: 31\n",
      "validation_split: 0.1\n",
      "Model: \"sequential_114\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_342 (Dense)            (None, 72, 87)            174       \n",
      "_________________________________________________________________\n",
      "dense_343 (Dense)            (None, 72, 16)            1408      \n",
      "_________________________________________________________________\n",
      "dropout_114 (Dropout)        (None, 72, 16)            0         \n",
      "_________________________________________________________________\n",
      "dense_344 (Dense)            (None, 72, 1)             17        \n",
      "=================================================================\n",
      "Total params: 1,599\n",
      "Trainable params: 1,599\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/80\n",
      "114/114 [==============================] - 1s 5ms/step - loss: 0.0434 - val_loss: 0.0238\n",
      "Epoch 2/80\n",
      "114/114 [==============================] - 0s 3ms/step - loss: 0.0414 - val_loss: 0.0227\n",
      "Epoch 3/80\n",
      "114/114 [==============================] - 0s 3ms/step - loss: 0.0396 - val_loss: 0.0214\n",
      "Epoch 4/80\n",
      "114/114 [==============================] - 0s 3ms/step - loss: 0.0383 - val_loss: 0.0211\n",
      "Epoch 5/80\n",
      "114/114 [==============================] - 0s 3ms/step - loss: 0.0370 - val_loss: 0.0212\n",
      "Epoch 6/80\n",
      "114/114 [==============================] - 0s 3ms/step - loss: 0.0359 - val_loss: 0.0204\n",
      "Epoch 7/80\n",
      "114/114 [==============================] - 0s 3ms/step - loss: 0.0347 - val_loss: 0.0244\n",
      "Epoch 8/80\n",
      "114/114 [==============================] - 0s 3ms/step - loss: 0.0342 - val_loss: 0.0184\n",
      "Epoch 9/80\n",
      "114/114 [==============================] - 0s 3ms/step - loss: 0.0333 - val_loss: 0.0182\n",
      "Epoch 10/80\n",
      "114/114 [==============================] - 0s 3ms/step - loss: 0.0325 - val_loss: 0.0181\n",
      "Epoch 11/80\n",
      "114/114 [==============================] - 0s 3ms/step - loss: 0.0318 - val_loss: 0.0179\n",
      "Epoch 12/80\n",
      "114/114 [==============================] - 0s 3ms/step - loss: 0.0312 - val_loss: 0.0175\n",
      "Epoch 13/80\n",
      "114/114 [==============================] - 0s 3ms/step - loss: 0.0308 - val_loss: 0.0170\n",
      "Epoch 14/80\n",
      "114/114 [==============================] - 0s 3ms/step - loss: 0.0304 - val_loss: 0.0167\n",
      "Epoch 15/80\n",
      "114/114 [==============================] - 0s 3ms/step - loss: 0.0299 - val_loss: 0.0166\n",
      "Epoch 16/80\n",
      "114/114 [==============================] - 0s 3ms/step - loss: 0.0296 - val_loss: 0.0162\n",
      "Epoch 17/80\n",
      "114/114 [==============================] - 0s 3ms/step - loss: 0.0294 - val_loss: 0.0161\n",
      "Epoch 18/80\n",
      "114/114 [==============================] - 0s 3ms/step - loss: 0.0291 - val_loss: 0.0159\n",
      "Epoch 19/80\n",
      "114/114 [==============================] - 0s 3ms/step - loss: 0.0297 - val_loss: 0.0156\n",
      "Epoch 20/80\n",
      "114/114 [==============================] - 0s 3ms/step - loss: 0.0287 - val_loss: 0.0158\n",
      "Epoch 21/80\n",
      "114/114 [==============================] - 0s 3ms/step - loss: 0.0285 - val_loss: 0.0150\n",
      "Epoch 22/80\n",
      "114/114 [==============================] - 0s 3ms/step - loss: 0.0283 - val_loss: 0.0158\n",
      "Epoch 23/80\n",
      "114/114 [==============================] - 0s 3ms/step - loss: 0.0282 - val_loss: 0.0159\n",
      "Epoch 24/80\n",
      "114/114 [==============================] - 0s 3ms/step - loss: 0.0280 - val_loss: 0.0153\n",
      "Epoch 25/80\n",
      "114/114 [==============================] - 0s 3ms/step - loss: 0.0280 - val_loss: 0.0154\n",
      "Epoch 26/80\n",
      "114/114 [==============================] - 0s 3ms/step - loss: 0.0279 - val_loss: 0.0154\n",
      "Epoch 27/80\n",
      "114/114 [==============================] - 0s 4ms/step - loss: 0.0278 - val_loss: 0.0154\n",
      "Epoch 28/80\n",
      "114/114 [==============================] - 0s 3ms/step - loss: 0.0277 - val_loss: 0.0154\n",
      "Epoch 29/80\n",
      "114/114 [==============================] - 0s 3ms/step - loss: 0.0276 - val_loss: 0.0152\n",
      "Epoch 30/80\n",
      "114/114 [==============================] - 0s 3ms/step - loss: 0.0276 - val_loss: 0.0153\n",
      "Epoch 31/80\n",
      "114/114 [==============================] - 0s 3ms/step - loss: 0.0275 - val_loss: 0.0151\n",
      "Epoch 32/80\n",
      "114/114 [==============================] - 0s 3ms/step - loss: 0.0274 - val_loss: 0.0153\n",
      "Epoch 33/80\n",
      "114/114 [==============================] - 0s 4ms/step - loss: 0.0274 - val_loss: 0.0152\n",
      "Epoch 34/80\n",
      "114/114 [==============================] - 0s 3ms/step - loss: 0.0273 - val_loss: 0.0152\n",
      "Epoch 35/80\n",
      "114/114 [==============================] - 0s 3ms/step - loss: 0.0273 - val_loss: 0.0151\n",
      "Epoch 36/80\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "114/114 [==============================] - 0s 4ms/step - loss: 0.0272 - val_loss: 0.0150\n",
      "Epoch 37/80\n",
      "114/114 [==============================] - 0s 4ms/step - loss: 0.0272 - val_loss: 0.0152\n",
      "Epoch 38/80\n",
      "114/114 [==============================] - 0s 4ms/step - loss: 0.0271 - val_loss: 0.0151\n",
      "Epoch 39/80\n",
      "114/114 [==============================] - 0s 4ms/step - loss: 0.0271 - val_loss: 0.0151\n",
      "Epoch 40/80\n",
      "114/114 [==============================] - 0s 4ms/step - loss: 0.0271 - val_loss: 0.0151\n",
      "Epoch 41/80\n",
      "114/114 [==============================] - 0s 3ms/step - loss: 0.0270 - val_loss: 0.0150\n",
      "Epoch 42/80\n",
      "114/114 [==============================] - 0s 3ms/step - loss: 0.0270 - val_loss: 0.0151\n",
      "Epoch 43/80\n",
      "114/114 [==============================] - 0s 3ms/step - loss: 0.0270 - val_loss: 0.0150\n",
      "Epoch 44/80\n",
      "114/114 [==============================] - 0s 3ms/step - loss: 0.0270 - val_loss: 0.0150\n",
      "Epoch 45/80\n",
      "114/114 [==============================] - 0s 3ms/step - loss: 0.0269 - val_loss: 0.0150\n",
      "Epoch 46/80\n",
      "114/114 [==============================] - 0s 3ms/step - loss: 0.0269 - val_loss: 0.0150\n",
      "Epoch 47/80\n",
      "114/114 [==============================] - 0s 3ms/step - loss: 0.0269 - val_loss: 0.0150\n",
      "Epoch 48/80\n",
      "114/114 [==============================] - 0s 3ms/step - loss: 0.0268 - val_loss: 0.0149\n",
      "Epoch 49/80\n",
      "114/114 [==============================] - 0s 3ms/step - loss: 0.0268 - val_loss: 0.0149\n",
      "Epoch 50/80\n",
      "114/114 [==============================] - 0s 4ms/step - loss: 0.0268 - val_loss: 0.0147\n",
      "Epoch 51/80\n",
      "114/114 [==============================] - 0s 3ms/step - loss: 0.0268 - val_loss: 0.0146\n",
      "Epoch 52/80\n",
      "114/114 [==============================] - 0s 3ms/step - loss: 0.0267 - val_loss: 0.0143\n",
      "Epoch 53/80\n",
      "114/114 [==============================] - 0s 3ms/step - loss: 0.0267 - val_loss: 0.0142\n",
      "Epoch 54/80\n",
      "114/114 [==============================] - 0s 3ms/step - loss: 0.0267 - val_loss: 0.0139\n",
      "Epoch 55/80\n",
      "114/114 [==============================] - 0s 3ms/step - loss: 0.0267 - val_loss: 0.0139\n",
      "Epoch 56/80\n",
      "114/114 [==============================] - 0s 3ms/step - loss: 0.0267 - val_loss: 0.0140\n",
      "Epoch 57/80\n",
      "114/114 [==============================] - 0s 3ms/step - loss: 0.0266 - val_loss: 0.0138\n",
      "Epoch 58/80\n",
      "114/114 [==============================] - 0s 3ms/step - loss: 0.0266 - val_loss: 0.0137\n",
      "Epoch 59/80\n",
      "114/114 [==============================] - 0s 3ms/step - loss: 0.0265 - val_loss: 0.0132\n",
      "Epoch 60/80\n",
      "114/114 [==============================] - 0s 3ms/step - loss: 0.0264 - val_loss: 0.0129\n",
      "Epoch 61/80\n",
      "114/114 [==============================] - 0s 3ms/step - loss: 0.0264 - val_loss: 0.0127\n",
      "Epoch 62/80\n",
      "114/114 [==============================] - 0s 3ms/step - loss: 0.0264 - val_loss: 0.0129\n",
      "Epoch 63/80\n",
      "114/114 [==============================] - 0s 3ms/step - loss: 0.0263 - val_loss: 0.0120\n",
      "Epoch 64/80\n",
      "114/114 [==============================] - 0s 3ms/step - loss: 0.0262 - val_loss: 0.0122\n",
      "Epoch 65/80\n",
      "114/114 [==============================] - 0s 3ms/step - loss: 0.0264 - val_loss: 0.0129\n",
      "Epoch 66/80\n",
      "114/114 [==============================] - 0s 3ms/step - loss: 0.0261 - val_loss: 0.0124\n",
      "Epoch 67/80\n",
      "114/114 [==============================] - 0s 3ms/step - loss: 0.0260 - val_loss: 0.0120\n",
      "Epoch 68/80\n",
      "114/114 [==============================] - 0s 3ms/step - loss: 0.0261 - val_loss: 0.0124\n",
      "Epoch 69/80\n",
      "114/114 [==============================] - 0s 3ms/step - loss: 0.0259 - val_loss: 0.0118\n",
      "Epoch 70/80\n",
      "114/114 [==============================] - 0s 3ms/step - loss: 0.0260 - val_loss: 0.0125\n",
      "Epoch 71/80\n",
      "114/114 [==============================] - 0s 3ms/step - loss: 0.0258 - val_loss: 0.0122\n",
      "Epoch 72/80\n",
      "114/114 [==============================] - 0s 3ms/step - loss: 0.0258 - val_loss: 0.0124\n",
      "Epoch 73/80\n",
      "114/114 [==============================] - 0s 3ms/step - loss: 0.0257 - val_loss: 0.0123\n",
      "Epoch 74/80\n",
      "114/114 [==============================] - 0s 3ms/step - loss: 0.0255 - val_loss: 0.0119\n",
      "Epoch 75/80\n",
      "114/114 [==============================] - 0s 3ms/step - loss: 0.0256 - val_loss: 0.0128\n",
      "Epoch 76/80\n",
      "114/114 [==============================] - 0s 4ms/step - loss: 0.0255 - val_loss: 0.0125\n",
      "Epoch 77/80\n",
      "114/114 [==============================] - 0s 4ms/step - loss: 0.0253 - val_loss: 0.0120\n",
      "Epoch 78/80\n",
      "114/114 [==============================] - 0s 4ms/step - loss: 0.0253 - val_loss: 0.0116\n",
      "Epoch 79/80\n",
      "114/114 [==============================] - 0s 4ms/step - loss: 0.0252 - val_loss: 0.0114\n",
      "Epoch 80/80\n",
      "114/114 [==============================] - 0s 4ms/step - loss: 0.0253 - val_loss: 0.0116\n",
      "Execution time:  32.72496724128723\n",
      "DNN:\n",
      "Mean Absolute Error: 0.0210\n",
      "Root Mean Square Error: 0.0372\n",
      "Mean Square Error: 0.0014\n",
      "\n",
      "Train RMSE: 0.037\n",
      "Train MSE: 0.001\n",
      "Train MAE: 0.021\n",
      "###########################\n",
      "\n",
      "MODEL:  DNN\n",
      "sequence:  12h\n",
      "units:  80\n",
      "dropout1:  0.11814836227952394\n",
      "optimizer: adam\n",
      "activationDense: sigmoid\n",
      "epochs: 90\n",
      "batchsize: 25\n",
      "validation_split: 0.1\n",
      "Model: \"sequential_115\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_345 (Dense)            (None, 72, 80)            160       \n",
      "_________________________________________________________________\n",
      "dense_346 (Dense)            (None, 72, 16)            1296      \n",
      "_________________________________________________________________\n",
      "dropout_115 (Dropout)        (None, 72, 16)            0         \n",
      "_________________________________________________________________\n",
      "dense_347 (Dense)            (None, 72, 1)             17        \n",
      "=================================================================\n",
      "Total params: 1,473\n",
      "Trainable params: 1,473\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/90\n",
      "142/142 [==============================] - 1s 4ms/step - loss: 0.0386 - val_loss: 0.0265\n",
      "Epoch 2/90\n",
      "142/142 [==============================] - 0s 3ms/step - loss: 0.0371 - val_loss: 0.0250\n",
      "Epoch 3/90\n",
      "142/142 [==============================] - 0s 3ms/step - loss: 0.0360 - val_loss: 0.0241\n",
      "Epoch 4/90\n",
      "142/142 [==============================] - 0s 3ms/step - loss: 0.0351 - val_loss: 0.0235\n",
      "Epoch 5/90\n",
      "142/142 [==============================] - 0s 3ms/step - loss: 0.0344 - val_loss: 0.0223\n",
      "Epoch 6/90\n",
      "142/142 [==============================] - 0s 3ms/step - loss: 0.0339 - val_loss: 0.0218\n",
      "Epoch 7/90\n",
      "142/142 [==============================] - 0s 3ms/step - loss: 0.0323 - val_loss: 0.0314\n",
      "Epoch 8/90\n",
      "142/142 [==============================] - 0s 3ms/step - loss: 0.0334 - val_loss: 0.0205\n",
      "Epoch 9/90\n",
      "142/142 [==============================] - 0s 3ms/step - loss: 0.0325 - val_loss: 0.0189\n",
      "Epoch 10/90\n",
      "142/142 [==============================] - 0s 3ms/step - loss: 0.0321 - val_loss: 0.0189\n",
      "Epoch 11/90\n",
      "142/142 [==============================] - 0s 3ms/step - loss: 0.0317 - val_loss: 0.0185\n",
      "Epoch 12/90\n",
      "142/142 [==============================] - 0s 3ms/step - loss: 0.0313 - val_loss: 0.0173\n",
      "Epoch 13/90\n",
      "142/142 [==============================] - 0s 3ms/step - loss: 0.0310 - val_loss: 0.0180\n",
      "Epoch 14/90\n",
      "142/142 [==============================] - 0s 3ms/step - loss: 0.0308 - val_loss: 0.0168\n",
      "Epoch 15/90\n",
      "142/142 [==============================] - 0s 3ms/step - loss: 0.0304 - val_loss: 0.0168\n",
      "Epoch 16/90\n",
      "142/142 [==============================] - 0s 3ms/step - loss: 0.0301 - val_loss: 0.0159\n",
      "Epoch 17/90\n",
      "142/142 [==============================] - 0s 3ms/step - loss: 0.0299 - val_loss: 0.0159\n",
      "Epoch 18/90\n",
      "142/142 [==============================] - 0s 3ms/step - loss: 0.0297 - val_loss: 0.0151\n",
      "Epoch 19/90\n",
      "142/142 [==============================] - 0s 3ms/step - loss: 0.0295 - val_loss: 0.0151\n",
      "Epoch 20/90\n",
      "142/142 [==============================] - 0s 3ms/step - loss: 0.0293 - val_loss: 0.0152\n",
      "Epoch 21/90\n",
      "142/142 [==============================] - 0s 3ms/step - loss: 0.0291 - val_loss: 0.0152\n",
      "Epoch 22/90\n",
      "142/142 [==============================] - 0s 3ms/step - loss: 0.0290 - val_loss: 0.0150\n",
      "Epoch 23/90\n",
      "142/142 [==============================] - 0s 3ms/step - loss: 0.0288 - val_loss: 0.0143\n",
      "Epoch 24/90\n",
      "142/142 [==============================] - 0s 3ms/step - loss: 0.0288 - val_loss: 0.0142\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 25/90\n",
      "142/142 [==============================] - 0s 3ms/step - loss: 0.0287 - val_loss: 0.0138\n",
      "Epoch 26/90\n",
      "142/142 [==============================] - 0s 3ms/step - loss: 0.0286 - val_loss: 0.0137\n",
      "Epoch 27/90\n",
      "142/142 [==============================] - 0s 3ms/step - loss: 0.0285 - val_loss: 0.0139\n",
      "Epoch 28/90\n",
      "142/142 [==============================] - 0s 3ms/step - loss: 0.0286 - val_loss: 0.0137\n",
      "Epoch 29/90\n",
      "142/142 [==============================] - 0s 3ms/step - loss: 0.0286 - val_loss: 0.0135\n",
      "Epoch 30/90\n",
      "142/142 [==============================] - 0s 3ms/step - loss: 0.0283 - val_loss: 0.0141\n",
      "Epoch 31/90\n",
      "142/142 [==============================] - 0s 3ms/step - loss: 0.0282 - val_loss: 0.0142\n",
      "Epoch 32/90\n",
      "142/142 [==============================] - 0s 3ms/step - loss: 0.0281 - val_loss: 0.0142\n",
      "Epoch 33/90\n",
      "142/142 [==============================] - 0s 3ms/step - loss: 0.0280 - val_loss: 0.0142\n",
      "Epoch 34/90\n",
      "142/142 [==============================] - 0s 3ms/step - loss: 0.0280 - val_loss: 0.0142\n",
      "Epoch 35/90\n",
      "142/142 [==============================] - 0s 3ms/step - loss: 0.0279 - val_loss: 0.0142\n",
      "Epoch 36/90\n",
      "142/142 [==============================] - 0s 3ms/step - loss: 0.0279 - val_loss: 0.0141\n",
      "Epoch 37/90\n",
      "142/142 [==============================] - 0s 3ms/step - loss: 0.0279 - val_loss: 0.0139\n",
      "Epoch 38/90\n",
      "142/142 [==============================] - 0s 3ms/step - loss: 0.0278 - val_loss: 0.0139\n",
      "Epoch 39/90\n",
      "142/142 [==============================] - 0s 3ms/step - loss: 0.0278 - val_loss: 0.0138\n",
      "Epoch 40/90\n",
      "142/142 [==============================] - 0s 3ms/step - loss: 0.0277 - val_loss: 0.0138\n",
      "Epoch 41/90\n",
      "142/142 [==============================] - 0s 3ms/step - loss: 0.0277 - val_loss: 0.0138\n",
      "Epoch 42/90\n",
      "142/142 [==============================] - 0s 3ms/step - loss: 0.0276 - val_loss: 0.0136\n",
      "Epoch 43/90\n",
      "142/142 [==============================] - 0s 3ms/step - loss: 0.0276 - val_loss: 0.0136\n",
      "Epoch 44/90\n",
      "142/142 [==============================] - 0s 3ms/step - loss: 0.0276 - val_loss: 0.0130\n",
      "Epoch 45/90\n",
      "142/142 [==============================] - 0s 3ms/step - loss: 0.0281 - val_loss: 0.0142\n",
      "Epoch 46/90\n",
      "142/142 [==============================] - 0s 3ms/step - loss: 0.0276 - val_loss: 0.0139\n",
      "Epoch 47/90\n",
      "142/142 [==============================] - 0s 3ms/step - loss: 0.0274 - val_loss: 0.0129\n",
      "Epoch 48/90\n",
      "142/142 [==============================] - 0s 3ms/step - loss: 0.0275 - val_loss: 0.0127\n",
      "Epoch 49/90\n",
      "142/142 [==============================] - 0s 3ms/step - loss: 0.0274 - val_loss: 0.0130\n",
      "Epoch 50/90\n",
      "142/142 [==============================] - 0s 3ms/step - loss: 0.0273 - val_loss: 0.0130\n",
      "Epoch 51/90\n",
      "142/142 [==============================] - 0s 3ms/step - loss: 0.0273 - val_loss: 0.0130\n",
      "Epoch 52/90\n",
      "142/142 [==============================] - 0s 3ms/step - loss: 0.0273 - val_loss: 0.0129\n",
      "Epoch 53/90\n",
      "142/142 [==============================] - 0s 3ms/step - loss: 0.0272 - val_loss: 0.0129\n",
      "Epoch 54/90\n",
      "142/142 [==============================] - 0s 3ms/step - loss: 0.0272 - val_loss: 0.0129\n",
      "Epoch 55/90\n",
      "142/142 [==============================] - 0s 3ms/step - loss: 0.0271 - val_loss: 0.0127\n",
      "Epoch 56/90\n",
      "142/142 [==============================] - 0s 3ms/step - loss: 0.0271 - val_loss: 0.0125\n",
      "Epoch 57/90\n",
      "142/142 [==============================] - 0s 3ms/step - loss: 0.0270 - val_loss: 0.0127\n",
      "Epoch 58/90\n",
      "142/142 [==============================] - 0s 3ms/step - loss: 0.0270 - val_loss: 0.0126\n",
      "Epoch 59/90\n",
      "142/142 [==============================] - 0s 3ms/step - loss: 0.0269 - val_loss: 0.0126\n",
      "Epoch 60/90\n",
      "142/142 [==============================] - 0s 3ms/step - loss: 0.0269 - val_loss: 0.0126\n",
      "Epoch 61/90\n",
      "142/142 [==============================] - 0s 3ms/step - loss: 0.0268 - val_loss: 0.0125\n",
      "Epoch 62/90\n",
      "142/142 [==============================] - 0s 3ms/step - loss: 0.0268 - val_loss: 0.0125\n",
      "Epoch 63/90\n",
      "142/142 [==============================] - 0s 3ms/step - loss: 0.0267 - val_loss: 0.0123\n",
      "Epoch 64/90\n",
      "142/142 [==============================] - 0s 3ms/step - loss: 0.0267 - val_loss: 0.0124\n",
      "Epoch 65/90\n",
      "142/142 [==============================] - 0s 3ms/step - loss: 0.0266 - val_loss: 0.0124\n",
      "Epoch 66/90\n",
      "142/142 [==============================] - 0s 3ms/step - loss: 0.0266 - val_loss: 0.0125\n",
      "Epoch 67/90\n",
      "142/142 [==============================] - 0s 3ms/step - loss: 0.0265 - val_loss: 0.0122\n",
      "Epoch 68/90\n",
      "142/142 [==============================] - 0s 3ms/step - loss: 0.0265 - val_loss: 0.0120\n",
      "Epoch 69/90\n",
      "142/142 [==============================] - 0s 3ms/step - loss: 0.0264 - val_loss: 0.0118\n",
      "Epoch 70/90\n",
      "142/142 [==============================] - 0s 3ms/step - loss: 0.0263 - val_loss: 0.0117\n",
      "Epoch 71/90\n",
      "142/142 [==============================] - 0s 3ms/step - loss: 0.0263 - val_loss: 0.0117\n",
      "Epoch 72/90\n",
      "142/142 [==============================] - 0s 3ms/step - loss: 0.0262 - val_loss: 0.0118\n",
      "Epoch 73/90\n",
      "142/142 [==============================] - 0s 3ms/step - loss: 0.0261 - val_loss: 0.0114\n",
      "Epoch 74/90\n",
      "142/142 [==============================] - 0s 3ms/step - loss: 0.0260 - val_loss: 0.0120\n",
      "Epoch 75/90\n",
      "142/142 [==============================] - 0s 3ms/step - loss: 0.0258 - val_loss: 0.0118\n",
      "Epoch 76/90\n",
      "142/142 [==============================] - 0s 3ms/step - loss: 0.0257 - val_loss: 0.0121\n",
      "Epoch 77/90\n",
      "142/142 [==============================] - 0s 3ms/step - loss: 0.0258 - val_loss: 0.0117\n",
      "Epoch 78/90\n",
      "142/142 [==============================] - 0s 3ms/step - loss: 0.0255 - val_loss: 0.0119\n",
      "Epoch 79/90\n",
      "142/142 [==============================] - 0s 3ms/step - loss: 0.0254 - val_loss: 0.0126\n",
      "Epoch 80/90\n",
      "142/142 [==============================] - 0s 3ms/step - loss: 0.0251 - val_loss: 0.0117\n",
      "Epoch 81/90\n",
      "142/142 [==============================] - 0s 3ms/step - loss: 0.0249 - val_loss: 0.0115\n",
      "Epoch 82/90\n",
      "142/142 [==============================] - 0s 3ms/step - loss: 0.0247 - val_loss: 0.0127\n",
      "Epoch 83/90\n",
      "142/142 [==============================] - 0s 3ms/step - loss: 0.0248 - val_loss: 0.0122\n",
      "Epoch 84/90\n",
      "142/142 [==============================] - 0s 3ms/step - loss: 0.0245 - val_loss: 0.0128\n",
      "Epoch 85/90\n",
      "142/142 [==============================] - 0s 3ms/step - loss: 0.0244 - val_loss: 0.0123\n",
      "Epoch 86/90\n",
      "142/142 [==============================] - 0s 3ms/step - loss: 0.0242 - val_loss: 0.0132\n",
      "Epoch 87/90\n",
      "142/142 [==============================] - 0s 3ms/step - loss: 0.0242 - val_loss: 0.0131\n",
      "Epoch 88/90\n",
      "142/142 [==============================] - 0s 3ms/step - loss: 0.0240 - val_loss: 0.0124\n",
      "Epoch 89/90\n",
      "142/142 [==============================] - 0s 3ms/step - loss: 0.0239 - val_loss: 0.0126\n",
      "Epoch 90/90\n",
      "142/142 [==============================] - 0s 3ms/step - loss: 0.0239 - val_loss: 0.0124\n",
      "Execution time:  39.5747172832489\n",
      "DNN:\n",
      "Mean Absolute Error: 0.0211\n",
      "Root Mean Square Error: 0.0361\n",
      "Mean Square Error: 0.0013\n",
      "\n",
      "Train RMSE: 0.036\n",
      "Train MSE: 0.001\n",
      "Train MAE: 0.021\n",
      "###########################\n",
      "\n",
      "MODEL:  DNN\n",
      "sequence:  12h\n",
      "units:  12\n",
      "dropout1:  0.48476373451509647\n",
      "optimizer: adam\n",
      "activationDense: sigmoid\n",
      "epochs: 52\n",
      "batchsize: 57\n",
      "validation_split: 0.1\n",
      "Model: \"sequential_116\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_348 (Dense)            (None, 72, 12)            24        \n",
      "_________________________________________________________________\n",
      "dense_349 (Dense)            (None, 72, 16)            208       \n",
      "_________________________________________________________________\n",
      "dropout_116 (Dropout)        (None, 72, 16)            0         \n",
      "_________________________________________________________________\n",
      "dense_350 (Dense)            (None, 72, 1)             17        \n",
      "=================================================================\n",
      "Total params: 249\n",
      "Trainable params: 249\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/52\n",
      "62/62 [==============================] - 0s 6ms/step - loss: 0.0759 - val_loss: 0.0721\n",
      "Epoch 2/52\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.0479 - val_loss: 0.0470\n",
      "Epoch 3/52\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.0428 - val_loss: 0.0381\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/52\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.0401 - val_loss: 0.0364\n",
      "Epoch 5/52\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.0383 - val_loss: 0.0337\n",
      "Epoch 6/52\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.0370 - val_loss: 0.0325\n",
      "Epoch 7/52\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.0361 - val_loss: 0.0316\n",
      "Epoch 8/52\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.0351 - val_loss: 0.0307\n",
      "Epoch 9/52\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.0343 - val_loss: 0.0298\n",
      "Epoch 10/52\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.0339 - val_loss: 0.0281\n",
      "Epoch 11/52\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.0331 - val_loss: 0.0270\n",
      "Epoch 12/52\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.0325 - val_loss: 0.0263\n",
      "Epoch 13/52\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.0319 - val_loss: 0.0253\n",
      "Epoch 14/52\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.0314 - val_loss: 0.0246\n",
      "Epoch 15/52\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.0310 - val_loss: 0.0240\n",
      "Epoch 16/52\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.0305 - val_loss: 0.0232\n",
      "Epoch 17/52\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.0302 - val_loss: 0.0228\n",
      "Epoch 18/52\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.0298 - val_loss: 0.0219\n",
      "Epoch 19/52\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.0295 - val_loss: 0.0218\n",
      "Epoch 20/52\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.0292 - val_loss: 0.0207\n",
      "Epoch 21/52\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.0290 - val_loss: 0.0207\n",
      "Epoch 22/52\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.0286 - val_loss: 0.0196\n",
      "Epoch 23/52\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.0285 - val_loss: 0.0195\n",
      "Epoch 24/52\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.0282 - val_loss: 0.0182\n",
      "Epoch 25/52\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.0282 - val_loss: 0.0187\n",
      "Epoch 26/52\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.0279 - val_loss: 0.0176\n",
      "Epoch 27/52\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.0278 - val_loss: 0.0180\n",
      "Epoch 28/52\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.0276 - val_loss: 0.0174\n",
      "Epoch 29/52\n",
      "62/62 [==============================] - ETA: 0s - loss: 0.027 - 0s 4ms/step - loss: 0.0275 - val_loss: 0.0169\n",
      "Epoch 30/52\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.0274 - val_loss: 0.0168\n",
      "Epoch 31/52\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.0272 - val_loss: 0.0163\n",
      "Epoch 32/52\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.0272 - val_loss: 0.0163\n",
      "Epoch 33/52\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.0271 - val_loss: 0.0159\n",
      "Epoch 34/52\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.0270 - val_loss: 0.0158\n",
      "Epoch 35/52\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.0269 - val_loss: 0.0156\n",
      "Epoch 36/52\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.0268 - val_loss: 0.0155\n",
      "Epoch 37/52\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.0267 - val_loss: 0.0151\n",
      "Epoch 38/52\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.0267 - val_loss: 0.0152\n",
      "Epoch 39/52\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.0266 - val_loss: 0.0147\n",
      "Epoch 40/52\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.0266 - val_loss: 0.0148\n",
      "Epoch 41/52\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.0265 - val_loss: 0.0147\n",
      "Epoch 42/52\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.0265 - val_loss: 0.0143\n",
      "Epoch 43/52\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.0265 - val_loss: 0.0145\n",
      "Epoch 44/52\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.0264 - val_loss: 0.0141\n",
      "Epoch 45/52\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.0263 - val_loss: 0.0151\n",
      "Epoch 46/52\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.0261 - val_loss: 0.0146\n",
      "Epoch 47/52\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.0262 - val_loss: 0.0146\n",
      "Epoch 48/52\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.0261 - val_loss: 0.0144\n",
      "Epoch 49/52\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.0261 - val_loss: 0.0143\n",
      "Epoch 50/52\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.0261 - val_loss: 0.0141\n",
      "Epoch 51/52\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.0260 - val_loss: 0.0141\n",
      "Epoch 52/52\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.0261 - val_loss: 0.0140\n",
      "Execution time:  12.363379716873169\n",
      "DNN:\n",
      "Mean Absolute Error: 0.0238\n",
      "Root Mean Square Error: 0.0404\n",
      "Mean Square Error: 0.0016\n",
      "\n",
      "Train RMSE: 0.040\n",
      "Train MSE: 0.002\n",
      "Train MAE: 0.024\n",
      "###########################\n",
      "\n",
      "MODEL:  DNN\n",
      "sequence:  12h\n",
      "units:  87\n",
      "dropout1:  0.40519643149940265\n",
      "optimizer: adam\n",
      "activationDense: sigmoid\n",
      "epochs: 80\n",
      "batchsize: 31\n",
      "validation_split: 0.2\n",
      "Model: \"sequential_117\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_351 (Dense)            (None, 72, 87)            174       \n",
      "_________________________________________________________________\n",
      "dense_352 (Dense)            (None, 72, 16)            1408      \n",
      "_________________________________________________________________\n",
      "dropout_117 (Dropout)        (None, 72, 16)            0         \n",
      "_________________________________________________________________\n",
      "dense_353 (Dense)            (None, 72, 1)             17        \n",
      "=================================================================\n",
      "Total params: 1,599\n",
      "Trainable params: 1,599\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/80\n",
      "102/102 [==============================] - 1s 5ms/step - loss: 0.0432 - val_loss: 0.0190\n",
      "Epoch 2/80\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.0431 - val_loss: 0.0195\n",
      "Epoch 3/80\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.0414 - val_loss: 0.0196\n",
      "Epoch 4/80\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.0400 - val_loss: 0.0198\n",
      "Epoch 5/80\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.0389 - val_loss: 0.0198\n",
      "Epoch 6/80\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.0378 - val_loss: 0.0198\n",
      "Epoch 7/80\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.0368 - val_loss: 0.0198\n",
      "Epoch 8/80\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.0358 - val_loss: 0.0196\n",
      "Epoch 9/80\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.0350 - val_loss: 0.0196\n",
      "Epoch 10/80\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.0343 - val_loss: 0.0195\n",
      "Epoch 11/80\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.0337 - val_loss: 0.0194\n",
      "Epoch 12/80\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.0331 - val_loss: 0.0193\n",
      "Epoch 13/80\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.0326 - val_loss: 0.0193\n",
      "Epoch 14/80\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.0321 - val_loss: 0.0193\n",
      "Epoch 15/80\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.0316 - val_loss: 0.0191\n",
      "Epoch 16/80\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.0312 - val_loss: 0.0190\n",
      "Epoch 17/80\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.0309 - val_loss: 0.0189\n",
      "Epoch 18/80\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.0305 - val_loss: 0.0188\n",
      "Epoch 19/80\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.0303 - val_loss: 0.0186\n",
      "Epoch 20/80\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.0301 - val_loss: 0.0186\n",
      "Epoch 21/80\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "102/102 [==============================] - 0s 4ms/step - loss: 0.0298 - val_loss: 0.0184\n",
      "Epoch 22/80\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.0296 - val_loss: 0.0183\n",
      "Epoch 23/80\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.0294 - val_loss: 0.0182\n",
      "Epoch 24/80\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.0294 - val_loss: 0.0181\n",
      "Epoch 25/80\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.0292 - val_loss: 0.0180\n",
      "Epoch 26/80\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.0291 - val_loss: 0.0178\n",
      "Epoch 27/80\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.0290 - val_loss: 0.0178\n",
      "Epoch 28/80\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.0289 - val_loss: 0.0177\n",
      "Epoch 29/80\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.0287 - val_loss: 0.0176\n",
      "Epoch 30/80\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.0286 - val_loss: 0.0175\n",
      "Epoch 31/80\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.0285 - val_loss: 0.0174\n",
      "Epoch 32/80\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.0285 - val_loss: 0.0173\n",
      "Epoch 33/80\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.0286 - val_loss: 0.0169\n",
      "Epoch 34/80\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.0284 - val_loss: 0.0171\n",
      "Epoch 35/80\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.0282 - val_loss: 0.0170\n",
      "Epoch 36/80\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.0281 - val_loss: 0.0170\n",
      "Epoch 37/80\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.0281 - val_loss: 0.0169\n",
      "Epoch 38/80\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.0280 - val_loss: 0.0169\n",
      "Epoch 39/80\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.0279 - val_loss: 0.0169\n",
      "Epoch 40/80\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.0279 - val_loss: 0.0168\n",
      "Epoch 41/80\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.0278 - val_loss: 0.0168\n",
      "Epoch 42/80\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.0277 - val_loss: 0.0168\n",
      "Epoch 43/80\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.0277 - val_loss: 0.0167\n",
      "Epoch 44/80\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.0276 - val_loss: 0.0167\n",
      "Epoch 45/80\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.0275 - val_loss: 0.0166\n",
      "Epoch 46/80\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.0275 - val_loss: 0.0166\n",
      "Epoch 47/80\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.0274 - val_loss: 0.0166\n",
      "Epoch 48/80\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.0274 - val_loss: 0.0166\n",
      "Epoch 49/80\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.0273 - val_loss: 0.0167\n",
      "Epoch 50/80\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.0272 - val_loss: 0.0167\n",
      "Epoch 51/80\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.0272 - val_loss: 0.0166\n",
      "Epoch 52/80\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.0271 - val_loss: 0.0166\n",
      "Epoch 53/80\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.0270 - val_loss: 0.0166\n",
      "Epoch 54/80\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.0270 - val_loss: 0.0166\n",
      "Epoch 55/80\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.0269 - val_loss: 0.0166\n",
      "Epoch 56/80\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.0268 - val_loss: 0.0166\n",
      "Epoch 57/80\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.0268 - val_loss: 0.0166\n",
      "Epoch 58/80\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.0266 - val_loss: 0.0165\n",
      "Epoch 59/80\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.0266 - val_loss: 0.0166\n",
      "Epoch 60/80\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.0265 - val_loss: 0.0167\n",
      "Epoch 61/80\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.0265 - val_loss: 0.0166\n",
      "Epoch 62/80\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.0264 - val_loss: 0.0167\n",
      "Epoch 63/80\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.0263 - val_loss: 0.0169\n",
      "Epoch 64/80\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.0262 - val_loss: 0.0170\n",
      "Epoch 65/80\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.0261 - val_loss: 0.0168\n",
      "Epoch 66/80\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.0260 - val_loss: 0.0168\n",
      "Epoch 67/80\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.0259 - val_loss: 0.0164\n",
      "Epoch 68/80\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.0257 - val_loss: 0.0159\n",
      "Epoch 69/80\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.0259 - val_loss: 0.0159\n",
      "Epoch 70/80\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.0256 - val_loss: 0.0157\n",
      "Epoch 71/80\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.0257 - val_loss: 0.0157\n",
      "Epoch 72/80\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.0254 - val_loss: 0.0156\n",
      "Epoch 73/80\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.0254 - val_loss: 0.0156\n",
      "Epoch 74/80\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.0254 - val_loss: 0.0156\n",
      "Epoch 75/80\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.0253 - val_loss: 0.0155\n",
      "Epoch 76/80\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.0252 - val_loss: 0.0157\n",
      "Epoch 77/80\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.0253 - val_loss: 0.0157\n",
      "Epoch 78/80\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.0252 - val_loss: 0.0157\n",
      "Epoch 79/80\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.0252 - val_loss: 0.0155\n",
      "Epoch 80/80\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.0250 - val_loss: 0.0156\n",
      "Execution time:  31.187089443206787\n",
      "DNN:\n",
      "Mean Absolute Error: 0.0199\n",
      "Root Mean Square Error: 0.0356\n",
      "Mean Square Error: 0.0013\n",
      "\n",
      "Train RMSE: 0.036\n",
      "Train MSE: 0.001\n",
      "Train MAE: 0.020\n",
      "###########################\n",
      "\n",
      "MODEL:  DNN\n",
      "sequence:  12h\n",
      "units:  80\n",
      "dropout1:  0.11814836227952394\n",
      "optimizer: adam\n",
      "activationDense: sigmoid\n",
      "epochs: 90\n",
      "batchsize: 25\n",
      "validation_split: 0.2\n",
      "Model: \"sequential_118\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_354 (Dense)            (None, 72, 80)            160       \n",
      "_________________________________________________________________\n",
      "dense_355 (Dense)            (None, 72, 16)            1296      \n",
      "_________________________________________________________________\n",
      "dropout_118 (Dropout)        (None, 72, 16)            0         \n",
      "_________________________________________________________________\n",
      "dense_356 (Dense)            (None, 72, 1)             17        \n",
      "=================================================================\n",
      "Total params: 1,473\n",
      "Trainable params: 1,473\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/90\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0383 - val_loss: 0.0205\n",
      "Epoch 2/90\n",
      "126/126 [==============================] - 0s 3ms/step - loss: 0.0405 - val_loss: 0.0192\n",
      "Epoch 3/90\n",
      "126/126 [==============================] - 0s 3ms/step - loss: 0.0389 - val_loss: 0.0185\n",
      "Epoch 4/90\n",
      "126/126 [==============================] - 0s 3ms/step - loss: 0.0377 - val_loss: 0.0182\n",
      "Epoch 5/90\n",
      "126/126 [==============================] - 0s 3ms/step - loss: 0.0371 - val_loss: 0.0179\n",
      "Epoch 6/90\n",
      "126/126 [==============================] - 0s 3ms/step - loss: 0.0362 - val_loss: 0.0177\n",
      "Epoch 7/90\n",
      "126/126 [==============================] - 0s 3ms/step - loss: 0.0356 - val_loss: 0.0175\n",
      "Epoch 8/90\n",
      "126/126 [==============================] - 0s 3ms/step - loss: 0.0350 - val_loss: 0.0174\n",
      "Epoch 9/90\n",
      "126/126 [==============================] - 0s 3ms/step - loss: 0.0345 - val_loss: 0.0172\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/90\n",
      "126/126 [==============================] - 0s 3ms/step - loss: 0.0341 - val_loss: 0.0170\n",
      "Epoch 11/90\n",
      "126/126 [==============================] - 0s 3ms/step - loss: 0.0335 - val_loss: 0.0170\n",
      "Epoch 12/90\n",
      "126/126 [==============================] - 0s 3ms/step - loss: 0.0330 - val_loss: 0.0170\n",
      "Epoch 13/90\n",
      "126/126 [==============================] - 0s 3ms/step - loss: 0.0326 - val_loss: 0.0171\n",
      "Epoch 14/90\n",
      "126/126 [==============================] - 0s 3ms/step - loss: 0.0322 - val_loss: 0.0171\n",
      "Epoch 15/90\n",
      "126/126 [==============================] - 0s 3ms/step - loss: 0.0318 - val_loss: 0.0172\n",
      "Epoch 16/90\n",
      "126/126 [==============================] - 0s 3ms/step - loss: 0.0315 - val_loss: 0.0171\n",
      "Epoch 17/90\n",
      "126/126 [==============================] - 0s 3ms/step - loss: 0.0313 - val_loss: 0.0170\n",
      "Epoch 18/90\n",
      "126/126 [==============================] - 0s 3ms/step - loss: 0.0312 - val_loss: 0.0171\n",
      "Epoch 19/90\n",
      "126/126 [==============================] - 0s 3ms/step - loss: 0.0310 - val_loss: 0.0172\n",
      "Epoch 20/90\n",
      "126/126 [==============================] - 0s 3ms/step - loss: 0.0307 - val_loss: 0.0171\n",
      "Epoch 21/90\n",
      "126/126 [==============================] - 0s 3ms/step - loss: 0.0310 - val_loss: 0.0172\n",
      "Epoch 22/90\n",
      "126/126 [==============================] - 0s 3ms/step - loss: 0.0304 - val_loss: 0.0173\n",
      "Epoch 23/90\n",
      "126/126 [==============================] - 0s 3ms/step - loss: 0.0303 - val_loss: 0.0172\n",
      "Epoch 24/90\n",
      "126/126 [==============================] - 0s 3ms/step - loss: 0.0302 - val_loss: 0.0172\n",
      "Epoch 25/90\n",
      "126/126 [==============================] - 0s 3ms/step - loss: 0.0301 - val_loss: 0.0172\n",
      "Epoch 26/90\n",
      "126/126 [==============================] - 0s 3ms/step - loss: 0.0301 - val_loss: 0.0172\n",
      "Epoch 27/90\n",
      "126/126 [==============================] - 0s 3ms/step - loss: 0.0300 - val_loss: 0.0172\n",
      "Epoch 28/90\n",
      "126/126 [==============================] - 0s 3ms/step - loss: 0.0300 - val_loss: 0.0172\n",
      "Epoch 29/90\n",
      "126/126 [==============================] - 0s 3ms/step - loss: 0.0299 - val_loss: 0.0173\n",
      "Epoch 30/90\n",
      "126/126 [==============================] - 0s 3ms/step - loss: 0.0299 - val_loss: 0.0172\n",
      "Epoch 31/90\n",
      "126/126 [==============================] - 0s 3ms/step - loss: 0.0299 - val_loss: 0.0172\n",
      "Epoch 32/90\n",
      "126/126 [==============================] - 0s 3ms/step - loss: 0.0298 - val_loss: 0.0172\n",
      "Epoch 33/90\n",
      "126/126 [==============================] - 0s 3ms/step - loss: 0.0297 - val_loss: 0.0171\n",
      "Epoch 34/90\n",
      "126/126 [==============================] - 0s 3ms/step - loss: 0.0297 - val_loss: 0.0171\n",
      "Epoch 35/90\n",
      "126/126 [==============================] - 0s 3ms/step - loss: 0.0297 - val_loss: 0.0172\n",
      "Epoch 36/90\n",
      "126/126 [==============================] - 0s 3ms/step - loss: 0.0296 - val_loss: 0.0172\n",
      "Epoch 37/90\n",
      "126/126 [==============================] - 0s 3ms/step - loss: 0.0295 - val_loss: 0.0171\n",
      "Epoch 38/90\n",
      "126/126 [==============================] - 0s 3ms/step - loss: 0.0296 - val_loss: 0.0171\n",
      "Epoch 39/90\n",
      "126/126 [==============================] - 0s 3ms/step - loss: 0.0295 - val_loss: 0.0171\n",
      "Epoch 40/90\n",
      "126/126 [==============================] - 0s 3ms/step - loss: 0.0295 - val_loss: 0.0170\n",
      "Epoch 41/90\n",
      "126/126 [==============================] - 0s 3ms/step - loss: 0.0294 - val_loss: 0.0170\n",
      "Epoch 42/90\n",
      "126/126 [==============================] - 0s 3ms/step - loss: 0.0294 - val_loss: 0.0169\n",
      "Epoch 43/90\n",
      "126/126 [==============================] - 0s 3ms/step - loss: 0.0294 - val_loss: 0.0169\n",
      "Epoch 44/90\n",
      "126/126 [==============================] - 0s 3ms/step - loss: 0.0293 - val_loss: 0.0169\n",
      "Epoch 45/90\n",
      "126/126 [==============================] - 0s 3ms/step - loss: 0.0293 - val_loss: 0.0168\n",
      "Epoch 46/90\n",
      "126/126 [==============================] - 0s 3ms/step - loss: 0.0292 - val_loss: 0.0168\n",
      "Epoch 47/90\n",
      "126/126 [==============================] - 0s 3ms/step - loss: 0.0291 - val_loss: 0.0167\n",
      "Epoch 48/90\n",
      "126/126 [==============================] - 0s 3ms/step - loss: 0.0291 - val_loss: 0.0167\n",
      "Epoch 49/90\n",
      "126/126 [==============================] - 0s 3ms/step - loss: 0.0290 - val_loss: 0.0167\n",
      "Epoch 50/90\n",
      "126/126 [==============================] - 0s 3ms/step - loss: 0.0290 - val_loss: 0.0166\n",
      "Epoch 51/90\n",
      "126/126 [==============================] - 0s 3ms/step - loss: 0.0289 - val_loss: 0.0166\n",
      "Epoch 52/90\n",
      "126/126 [==============================] - 0s 3ms/step - loss: 0.0288 - val_loss: 0.0165\n",
      "Epoch 53/90\n",
      "126/126 [==============================] - 0s 3ms/step - loss: 0.0288 - val_loss: 0.0165\n",
      "Epoch 54/90\n",
      "126/126 [==============================] - 0s 3ms/step - loss: 0.0287 - val_loss: 0.0165\n",
      "Epoch 55/90\n",
      "126/126 [==============================] - 0s 3ms/step - loss: 0.0286 - val_loss: 0.0164\n",
      "Epoch 56/90\n",
      "126/126 [==============================] - 0s 3ms/step - loss: 0.0286 - val_loss: 0.0163\n",
      "Epoch 57/90\n",
      "126/126 [==============================] - 0s 3ms/step - loss: 0.0290 - val_loss: 0.0159\n",
      "Epoch 58/90\n",
      "126/126 [==============================] - 0s 3ms/step - loss: 0.0285 - val_loss: 0.0163\n",
      "Epoch 59/90\n",
      "126/126 [==============================] - 0s 3ms/step - loss: 0.0283 - val_loss: 0.0162\n",
      "Epoch 60/90\n",
      "126/126 [==============================] - 0s 3ms/step - loss: 0.0282 - val_loss: 0.0161\n",
      "Epoch 61/90\n",
      "126/126 [==============================] - 0s 3ms/step - loss: 0.0281 - val_loss: 0.0161\n",
      "Epoch 62/90\n",
      "126/126 [==============================] - 0s 3ms/step - loss: 0.0280 - val_loss: 0.0160\n",
      "Epoch 63/90\n",
      "126/126 [==============================] - 0s 3ms/step - loss: 0.0279 - val_loss: 0.0159\n",
      "Epoch 64/90\n",
      "126/126 [==============================] - 0s 3ms/step - loss: 0.0278 - val_loss: 0.0159\n",
      "Epoch 65/90\n",
      "126/126 [==============================] - 0s 3ms/step - loss: 0.0277 - val_loss: 0.0158\n",
      "Epoch 66/90\n",
      "126/126 [==============================] - 0s 3ms/step - loss: 0.0276 - val_loss: 0.0158\n",
      "Epoch 67/90\n",
      "126/126 [==============================] - 0s 3ms/step - loss: 0.0275 - val_loss: 0.0158\n",
      "Epoch 68/90\n",
      "126/126 [==============================] - 0s 3ms/step - loss: 0.0273 - val_loss: 0.0158\n",
      "Epoch 69/90\n",
      "126/126 [==============================] - 0s 3ms/step - loss: 0.0272 - val_loss: 0.0158\n",
      "Epoch 70/90\n",
      "126/126 [==============================] - 0s 3ms/step - loss: 0.0271 - val_loss: 0.0157\n",
      "Epoch 71/90\n",
      "126/126 [==============================] - 0s 3ms/step - loss: 0.0269 - val_loss: 0.0157\n",
      "Epoch 72/90\n",
      "126/126 [==============================] - 0s 3ms/step - loss: 0.0267 - val_loss: 0.0158\n",
      "Epoch 73/90\n",
      "126/126 [==============================] - 0s 3ms/step - loss: 0.0266 - val_loss: 0.0157\n",
      "Epoch 74/90\n",
      "126/126 [==============================] - 0s 3ms/step - loss: 0.0264 - val_loss: 0.0158\n",
      "Epoch 75/90\n",
      "126/126 [==============================] - 0s 3ms/step - loss: 0.0263 - val_loss: 0.0158\n",
      "Epoch 76/90\n",
      "126/126 [==============================] - 0s 3ms/step - loss: 0.0262 - val_loss: 0.0157\n",
      "Epoch 77/90\n",
      "126/126 [==============================] - 0s 3ms/step - loss: 0.0259 - val_loss: 0.0157\n",
      "Epoch 78/90\n",
      "126/126 [==============================] - 0s 3ms/step - loss: 0.0257 - val_loss: 0.0158\n",
      "Epoch 79/90\n",
      "126/126 [==============================] - 0s 3ms/step - loss: 0.0256 - val_loss: 0.0158\n",
      "Epoch 80/90\n",
      "126/126 [==============================] - 0s 3ms/step - loss: 0.0255 - val_loss: 0.0158\n",
      "Epoch 81/90\n",
      "126/126 [==============================] - 0s 3ms/step - loss: 0.0253 - val_loss: 0.0158\n",
      "Epoch 82/90\n",
      "126/126 [==============================] - 0s 3ms/step - loss: 0.0252 - val_loss: 0.0158\n",
      "Epoch 83/90\n",
      "126/126 [==============================] - 0s 3ms/step - loss: 0.0250 - val_loss: 0.0158\n",
      "Epoch 84/90\n",
      "126/126 [==============================] - 0s 3ms/step - loss: 0.0246 - val_loss: 0.0159\n",
      "Epoch 85/90\n",
      "126/126 [==============================] - 0s 3ms/step - loss: 0.0247 - val_loss: 0.0159\n",
      "Epoch 86/90\n",
      "126/126 [==============================] - 0s 3ms/step - loss: 0.0244 - val_loss: 0.0160\n",
      "Epoch 87/90\n",
      "126/126 [==============================] - 0s 3ms/step - loss: 0.0244 - val_loss: 0.0160\n",
      "Epoch 88/90\n",
      "126/126 [==============================] - 0s 3ms/step - loss: 0.0242 - val_loss: 0.0160\n",
      "Epoch 89/90\n",
      "126/126 [==============================] - 0s 3ms/step - loss: 0.0240 - val_loss: 0.0160\n",
      "Epoch 90/90\n",
      "126/126 [==============================] - 0s 3ms/step - loss: 0.0239 - val_loss: 0.0162\n",
      "Execution time:  37.21115493774414\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DNN:\n",
      "Mean Absolute Error: 0.0211\n",
      "Root Mean Square Error: 0.0355\n",
      "Mean Square Error: 0.0013\n",
      "\n",
      "Train RMSE: 0.035\n",
      "Train MSE: 0.001\n",
      "Train MAE: 0.021\n",
      "###########################\n",
      "\n",
      "MODEL:  DNN\n",
      "sequence:  12h\n",
      "units:  12\n",
      "dropout1:  0.48476373451509647\n",
      "optimizer: adam\n",
      "activationDense: sigmoid\n",
      "epochs: 52\n",
      "batchsize: 57\n",
      "validation_split: 0.2\n",
      "Model: \"sequential_119\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_357 (Dense)            (None, 72, 12)            24        \n",
      "_________________________________________________________________\n",
      "dense_358 (Dense)            (None, 72, 16)            208       \n",
      "_________________________________________________________________\n",
      "dropout_119 (Dropout)        (None, 72, 16)            0         \n",
      "_________________________________________________________________\n",
      "dense_359 (Dense)            (None, 72, 1)             17        \n",
      "=================================================================\n",
      "Total params: 249\n",
      "Trainable params: 249\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/52\n",
      "55/55 [==============================] - 0s 7ms/step - loss: 0.0482 - val_loss: 0.0344\n",
      "Epoch 2/52\n",
      "55/55 [==============================] - 0s 3ms/step - loss: 0.0426 - val_loss: 0.0357\n",
      "Epoch 3/52\n",
      "55/55 [==============================] - 0s 3ms/step - loss: 0.0413 - val_loss: 0.0345\n",
      "Epoch 4/52\n",
      "55/55 [==============================] - 0s 3ms/step - loss: 0.0402 - val_loss: 0.0334\n",
      "Epoch 5/52\n",
      "55/55 [==============================] - 0s 3ms/step - loss: 0.0390 - val_loss: 0.0274\n",
      "Epoch 6/52\n",
      "55/55 [==============================] - 0s 3ms/step - loss: 0.0385 - val_loss: 0.0304\n",
      "Epoch 7/52\n",
      "55/55 [==============================] - 0s 3ms/step - loss: 0.0373 - val_loss: 0.0301\n",
      "Epoch 8/52\n",
      "55/55 [==============================] - 0s 3ms/step - loss: 0.0366 - val_loss: 0.0295\n",
      "Epoch 9/52\n",
      "55/55 [==============================] - 0s 3ms/step - loss: 0.0361 - val_loss: 0.0290\n",
      "Epoch 10/52\n",
      "55/55 [==============================] - 0s 3ms/step - loss: 0.0356 - val_loss: 0.0283\n",
      "Epoch 11/52\n",
      "55/55 [==============================] - 0s 3ms/step - loss: 0.0352 - val_loss: 0.0278\n",
      "Epoch 12/52\n",
      "55/55 [==============================] - 0s 3ms/step - loss: 0.0346 - val_loss: 0.0271\n",
      "Epoch 13/52\n",
      "55/55 [==============================] - 0s 4ms/step - loss: 0.0343 - val_loss: 0.0267\n",
      "Epoch 14/52\n",
      "55/55 [==============================] - 0s 4ms/step - loss: 0.0338 - val_loss: 0.0262\n",
      "Epoch 15/52\n",
      "55/55 [==============================] - 0s 3ms/step - loss: 0.0335 - val_loss: 0.0258\n",
      "Epoch 16/52\n",
      "55/55 [==============================] - 0s 3ms/step - loss: 0.0334 - val_loss: 0.0254\n",
      "Epoch 17/52\n",
      "55/55 [==============================] - 0s 4ms/step - loss: 0.0327 - val_loss: 0.0250\n",
      "Epoch 18/52\n",
      "55/55 [==============================] - 0s 4ms/step - loss: 0.0324 - val_loss: 0.0245\n",
      "Epoch 19/52\n",
      "55/55 [==============================] - 0s 4ms/step - loss: 0.0321 - val_loss: 0.0238\n",
      "Epoch 20/52\n",
      "55/55 [==============================] - 0s 4ms/step - loss: 0.0317 - val_loss: 0.0235\n",
      "Epoch 21/52\n",
      "55/55 [==============================] - 0s 4ms/step - loss: 0.0314 - val_loss: 0.0230\n",
      "Epoch 22/52\n",
      "55/55 [==============================] - 0s 4ms/step - loss: 0.0312 - val_loss: 0.0228\n",
      "Epoch 23/52\n",
      "55/55 [==============================] - 0s 4ms/step - loss: 0.0309 - val_loss: 0.0224\n",
      "Epoch 24/52\n",
      "55/55 [==============================] - 0s 4ms/step - loss: 0.0306 - val_loss: 0.0223\n",
      "Epoch 25/52\n",
      "55/55 [==============================] - 0s 4ms/step - loss: 0.0303 - val_loss: 0.0218\n",
      "Epoch 26/52\n",
      "55/55 [==============================] - 0s 3ms/step - loss: 0.0301 - val_loss: 0.0218\n",
      "Epoch 27/52\n",
      "55/55 [==============================] - 0s 3ms/step - loss: 0.0298 - val_loss: 0.0213\n",
      "Epoch 28/52\n",
      "55/55 [==============================] - 0s 3ms/step - loss: 0.0297 - val_loss: 0.0214\n",
      "Epoch 29/52\n",
      "55/55 [==============================] - 0s 3ms/step - loss: 0.0294 - val_loss: 0.0207\n",
      "Epoch 30/52\n",
      "55/55 [==============================] - 0s 3ms/step - loss: 0.0293 - val_loss: 0.0208\n",
      "Epoch 31/52\n",
      "55/55 [==============================] - 0s 3ms/step - loss: 0.0290 - val_loss: 0.0205\n",
      "Epoch 32/52\n",
      "55/55 [==============================] - 0s 3ms/step - loss: 0.0288 - val_loss: 0.0204\n",
      "Epoch 33/52\n",
      "55/55 [==============================] - 0s 3ms/step - loss: 0.0287 - val_loss: 0.0201\n",
      "Epoch 34/52\n",
      "55/55 [==============================] - 0s 3ms/step - loss: 0.0285 - val_loss: 0.0198\n",
      "Epoch 35/52\n",
      "55/55 [==============================] - 0s 3ms/step - loss: 0.0283 - val_loss: 0.0196\n",
      "Epoch 36/52\n",
      "55/55 [==============================] - 0s 3ms/step - loss: 0.0281 - val_loss: 0.0193\n",
      "Epoch 37/52\n",
      "55/55 [==============================] - 0s 3ms/step - loss: 0.0280 - val_loss: 0.0193\n",
      "Epoch 38/52\n",
      "55/55 [==============================] - 0s 3ms/step - loss: 0.0279 - val_loss: 0.0190\n",
      "Epoch 39/52\n",
      "55/55 [==============================] - 0s 3ms/step - loss: 0.0277 - val_loss: 0.0188\n",
      "Epoch 40/52\n",
      "55/55 [==============================] - 0s 3ms/step - loss: 0.0276 - val_loss: 0.0188\n",
      "Epoch 41/52\n",
      "55/55 [==============================] - 0s 3ms/step - loss: 0.0274 - val_loss: 0.0184\n",
      "Epoch 42/52\n",
      "55/55 [==============================] - 0s 3ms/step - loss: 0.0274 - val_loss: 0.0185\n",
      "Epoch 43/52\n",
      "55/55 [==============================] - 0s 3ms/step - loss: 0.0272 - val_loss: 0.0183\n",
      "Epoch 44/52\n",
      "55/55 [==============================] - 0s 3ms/step - loss: 0.0271 - val_loss: 0.0183\n",
      "Epoch 45/52\n",
      "55/55 [==============================] - 0s 3ms/step - loss: 0.0270 - val_loss: 0.0181\n",
      "Epoch 46/52\n",
      "55/55 [==============================] - 0s 3ms/step - loss: 0.0269 - val_loss: 0.0180\n",
      "Epoch 47/52\n",
      "55/55 [==============================] - 0s 3ms/step - loss: 0.0268 - val_loss: 0.0178\n",
      "Epoch 48/52\n",
      "55/55 [==============================] - 0s 3ms/step - loss: 0.0267 - val_loss: 0.0177\n",
      "Epoch 49/52\n",
      "55/55 [==============================] - 0s 3ms/step - loss: 0.0267 - val_loss: 0.0177\n",
      "Epoch 50/52\n",
      "55/55 [==============================] - 0s 3ms/step - loss: 0.0265 - val_loss: 0.0175\n",
      "Epoch 51/52\n",
      "55/55 [==============================] - 0s 3ms/step - loss: 0.0265 - val_loss: 0.0175\n",
      "Epoch 52/52\n",
      "55/55 [==============================] - 0s 3ms/step - loss: 0.0263 - val_loss: 0.0174\n",
      "Execution time:  11.021506786346436\n",
      "DNN:\n",
      "Mean Absolute Error: 0.0217\n",
      "Root Mean Square Error: 0.0372\n",
      "Mean Square Error: 0.0014\n",
      "\n",
      "Train RMSE: 0.037\n",
      "Train MSE: 0.001\n",
      "Train MAE: 0.022\n",
      "###########################\n",
      "\n",
      "MODEL:  DNN\n",
      "sequence:  12h\n",
      "units:  87\n",
      "dropout1:  0.40519643149940265\n",
      "optimizer: adadelta\n",
      "activationDense: tanh\n",
      "epochs: 80\n",
      "batchsize: 31\n",
      "validation_split: 0.1\n",
      "Model: \"sequential_120\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_360 (Dense)            (None, 72, 87)            174       \n",
      "_________________________________________________________________\n",
      "dense_361 (Dense)            (None, 72, 16)            1408      \n",
      "_________________________________________________________________\n",
      "dropout_120 (Dropout)        (None, 72, 16)            0         \n",
      "_________________________________________________________________\n",
      "dense_362 (Dense)            (None, 72, 1)             17        \n",
      "=================================================================\n",
      "Total params: 1,599\n",
      "Trainable params: 1,599\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/80\n",
      "114/114 [==============================] - 1s 5ms/step - loss: 0.4316 - val_loss: 0.3928\n",
      "Epoch 2/80\n",
      "114/114 [==============================] - 0s 3ms/step - loss: 0.4299 - val_loss: 0.3911\n",
      "Epoch 3/80\n",
      "114/114 [==============================] - 0s 4ms/step - loss: 0.4281 - val_loss: 0.3892\n",
      "Epoch 4/80\n",
      "114/114 [==============================] - 0s 3ms/step - loss: 0.4260 - val_loss: 0.3872\n",
      "Epoch 5/80\n",
      "114/114 [==============================] - 0s 3ms/step - loss: 0.4239 - val_loss: 0.3852\n",
      "Epoch 6/80\n",
      "114/114 [==============================] - 0s 3ms/step - loss: 0.4218 - val_loss: 0.3832\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/80\n",
      "114/114 [==============================] - 0s 3ms/step - loss: 0.4198 - val_loss: 0.3812\n",
      "Epoch 8/80\n",
      "114/114 [==============================] - 0s 3ms/step - loss: 0.4177 - val_loss: 0.3792\n",
      "Epoch 9/80\n",
      "114/114 [==============================] - 0s 3ms/step - loss: 0.4156 - val_loss: 0.3771\n",
      "Epoch 10/80\n",
      "114/114 [==============================] - 0s 3ms/step - loss: 0.4133 - val_loss: 0.3749\n",
      "Epoch 11/80\n",
      "114/114 [==============================] - 0s 3ms/step - loss: 0.4110 - val_loss: 0.3727\n",
      "Epoch 12/80\n",
      "114/114 [==============================] - 0s 3ms/step - loss: 0.4087 - val_loss: 0.3704\n",
      "Epoch 13/80\n",
      "114/114 [==============================] - 0s 3ms/step - loss: 0.4066 - val_loss: 0.3692\n",
      "Epoch 14/80\n",
      "114/114 [==============================] - 0s 3ms/step - loss: 0.4053 - val_loss: 0.3681\n",
      "Epoch 15/80\n",
      "114/114 [==============================] - 0s 3ms/step - loss: 0.4040 - val_loss: 0.3669\n",
      "Epoch 16/80\n",
      "114/114 [==============================] - 0s 4ms/step - loss: 0.4027 - val_loss: 0.3657\n",
      "Epoch 17/80\n",
      "114/114 [==============================] - 0s 3ms/step - loss: 0.4015 - val_loss: 0.3645\n",
      "Epoch 18/80\n",
      "114/114 [==============================] - 0s 3ms/step - loss: 0.4002 - val_loss: 0.3633\n",
      "Epoch 19/80\n",
      "114/114 [==============================] - 0s 3ms/step - loss: 0.3989 - val_loss: 0.3621\n",
      "Epoch 20/80\n",
      "114/114 [==============================] - 0s 3ms/step - loss: 0.3976 - val_loss: 0.3608\n",
      "Epoch 21/80\n",
      "114/114 [==============================] - 0s 4ms/step - loss: 0.3963 - val_loss: 0.3595\n",
      "Epoch 22/80\n",
      "114/114 [==============================] - 0s 4ms/step - loss: 0.3949 - val_loss: 0.3585\n",
      "Epoch 23/80\n",
      "114/114 [==============================] - 0s 4ms/step - loss: 0.3940 - val_loss: 0.3580\n",
      "Epoch 24/80\n",
      "114/114 [==============================] - 0s 4ms/step - loss: 0.3934 - val_loss: 0.3576\n",
      "Epoch 25/80\n",
      "114/114 [==============================] - 0s 4ms/step - loss: 0.3929 - val_loss: 0.3571\n",
      "Epoch 26/80\n",
      "114/114 [==============================] - 0s 4ms/step - loss: 0.3924 - val_loss: 0.3567\n",
      "Epoch 27/80\n",
      "114/114 [==============================] - 0s 3ms/step - loss: 0.3918 - val_loss: 0.3562\n",
      "Epoch 28/80\n",
      "114/114 [==============================] - 0s 3ms/step - loss: 0.3913 - val_loss: 0.3557\n",
      "Epoch 29/80\n",
      "114/114 [==============================] - 0s 3ms/step - loss: 0.3908 - val_loss: 0.3552\n",
      "Epoch 30/80\n",
      "114/114 [==============================] - 0s 4ms/step - loss: 0.3903 - val_loss: 0.3547\n",
      "Epoch 31/80\n",
      "114/114 [==============================] - 0s 3ms/step - loss: 0.3898 - val_loss: 0.3542\n",
      "Epoch 32/80\n",
      "114/114 [==============================] - 0s 3ms/step - loss: 0.3893 - val_loss: 0.3537\n",
      "Epoch 33/80\n",
      "114/114 [==============================] - 0s 4ms/step - loss: 0.3888 - val_loss: 0.3532\n",
      "Epoch 34/80\n",
      "114/114 [==============================] - 0s 3ms/step - loss: 0.3882 - val_loss: 0.3526\n",
      "Epoch 35/80\n",
      "114/114 [==============================] - 0s 3ms/step - loss: 0.3877 - val_loss: 0.3521\n",
      "Epoch 36/80\n",
      "114/114 [==============================] - 0s 3ms/step - loss: 0.3872 - val_loss: 0.3516\n",
      "Epoch 37/80\n",
      "114/114 [==============================] - 0s 4ms/step - loss: 0.3866 - val_loss: 0.3510\n",
      "Epoch 38/80\n",
      "114/114 [==============================] - 0s 3ms/step - loss: 0.3861 - val_loss: 0.3505\n",
      "Epoch 39/80\n",
      "114/114 [==============================] - 0s 4ms/step - loss: 0.3855 - val_loss: 0.3499\n",
      "Epoch 40/80\n",
      "114/114 [==============================] - 0s 3ms/step - loss: 0.3850 - val_loss: 0.3493\n",
      "Epoch 41/80\n",
      "114/114 [==============================] - 0s 3ms/step - loss: 0.3844 - val_loss: 0.3488\n",
      "Epoch 42/80\n",
      "114/114 [==============================] - 0s 3ms/step - loss: 0.3838 - val_loss: 0.3482\n",
      "Epoch 43/80\n",
      "114/114 [==============================] - 0s 4ms/step - loss: 0.3832 - val_loss: 0.3476\n",
      "Epoch 44/80\n",
      "114/114 [==============================] - 0s 3ms/step - loss: 0.3826 - val_loss: 0.3470\n",
      "Epoch 45/80\n",
      "114/114 [==============================] - 0s 4ms/step - loss: 0.3820 - val_loss: 0.3464\n",
      "Epoch 46/80\n",
      "114/114 [==============================] - 0s 3ms/step - loss: 0.3814 - val_loss: 0.3458\n",
      "Epoch 47/80\n",
      "114/114 [==============================] - 0s 3ms/step - loss: 0.3808 - val_loss: 0.3452\n",
      "Epoch 48/80\n",
      "114/114 [==============================] - 0s 4ms/step - loss: 0.3802 - val_loss: 0.3446\n",
      "Epoch 49/80\n",
      "114/114 [==============================] - 0s 3ms/step - loss: 0.3796 - val_loss: 0.3440\n",
      "Epoch 50/80\n",
      "114/114 [==============================] - 0s 4ms/step - loss: 0.3790 - val_loss: 0.3433\n",
      "Epoch 51/80\n",
      "114/114 [==============================] - 0s 4ms/step - loss: 0.3783 - val_loss: 0.3427\n",
      "Epoch 52/80\n",
      "114/114 [==============================] - 0s 3ms/step - loss: 0.3777 - val_loss: 0.3421\n",
      "Epoch 53/80\n",
      "114/114 [==============================] - 0s 3ms/step - loss: 0.3771 - val_loss: 0.3414\n",
      "Epoch 54/80\n",
      "114/114 [==============================] - 0s 3ms/step - loss: 0.3764 - val_loss: 0.3408\n",
      "Epoch 55/80\n",
      "114/114 [==============================] - 0s 3ms/step - loss: 0.3758 - val_loss: 0.3401\n",
      "Epoch 56/80\n",
      "114/114 [==============================] - 0s 3ms/step - loss: 0.3751 - val_loss: 0.3394\n",
      "Epoch 57/80\n",
      "114/114 [==============================] - 0s 4ms/step - loss: 0.3744 - val_loss: 0.3388\n",
      "Epoch 58/80\n",
      "114/114 [==============================] - 0s 3ms/step - loss: 0.3738 - val_loss: 0.3381\n",
      "Epoch 59/80\n",
      "114/114 [==============================] - 0s 3ms/step - loss: 0.3731 - val_loss: 0.3374\n",
      "Epoch 60/80\n",
      "114/114 [==============================] - 0s 3ms/step - loss: 0.3724 - val_loss: 0.3367\n",
      "Epoch 61/80\n",
      "114/114 [==============================] - 0s 4ms/step - loss: 0.3717 - val_loss: 0.3360\n",
      "Epoch 62/80\n",
      "114/114 [==============================] - 0s 4ms/step - loss: 0.3710 - val_loss: 0.3354\n",
      "Epoch 63/80\n",
      "114/114 [==============================] - 0s 4ms/step - loss: 0.3703 - val_loss: 0.3347\n",
      "Epoch 64/80\n",
      "114/114 [==============================] - 0s 4ms/step - loss: 0.3696 - val_loss: 0.3339\n",
      "Epoch 65/80\n",
      "114/114 [==============================] - 0s 4ms/step - loss: 0.3689 - val_loss: 0.3332\n",
      "Epoch 66/80\n",
      "114/114 [==============================] - 0s 3ms/step - loss: 0.3682 - val_loss: 0.3325\n",
      "Epoch 67/80\n",
      "114/114 [==============================] - 0s 4ms/step - loss: 0.3675 - val_loss: 0.3318\n",
      "Epoch 68/80\n",
      "114/114 [==============================] - 0s 3ms/step - loss: 0.3668 - val_loss: 0.3311\n",
      "Epoch 69/80\n",
      "114/114 [==============================] - 0s 3ms/step - loss: 0.3660 - val_loss: 0.3303\n",
      "Epoch 70/80\n",
      "114/114 [==============================] - 0s 3ms/step - loss: 0.3653 - val_loss: 0.3296\n",
      "Epoch 71/80\n",
      "114/114 [==============================] - 0s 4ms/step - loss: 0.3646 - val_loss: 0.3289\n",
      "Epoch 72/80\n",
      "114/114 [==============================] - 0s 3ms/step - loss: 0.3638 - val_loss: 0.3281\n",
      "Epoch 73/80\n",
      "114/114 [==============================] - 0s 3ms/step - loss: 0.3631 - val_loss: 0.3274\n",
      "Epoch 74/80\n",
      "114/114 [==============================] - 0s 4ms/step - loss: 0.3623 - val_loss: 0.3266\n",
      "Epoch 75/80\n",
      "114/114 [==============================] - 0s 3ms/step - loss: 0.3616 - val_loss: 0.3259\n",
      "Epoch 76/80\n",
      "114/114 [==============================] - 0s 4ms/step - loss: 0.3608 - val_loss: 0.3251\n",
      "Epoch 77/80\n",
      "114/114 [==============================] - 0s 3ms/step - loss: 0.3600 - val_loss: 0.3243\n",
      "Epoch 78/80\n",
      "114/114 [==============================] - 0s 3ms/step - loss: 0.3593 - val_loss: 0.3236\n",
      "Epoch 79/80\n",
      "114/114 [==============================] - 0s 3ms/step - loss: 0.3585 - val_loss: 0.3228\n",
      "Epoch 80/80\n",
      "114/114 [==============================] - 0s 3ms/step - loss: 0.3577 - val_loss: 0.3220\n",
      "Execution time:  33.14318227767944\n",
      "DNN:\n",
      "Mean Absolute Error: 0.3544\n",
      "Root Mean Square Error: 0.3568\n",
      "Mean Square Error: 0.1273\n",
      "\n",
      "Train RMSE: 0.357\n",
      "Train MSE: 0.127\n",
      "Train MAE: 0.354\n",
      "###########################\n",
      "\n",
      "MODEL:  DNN\n",
      "sequence:  12h\n",
      "units:  80\n",
      "dropout1:  0.11814836227952394\n",
      "optimizer: adadelta\n",
      "activationDense: tanh\n",
      "epochs: 90\n",
      "batchsize: 25\n",
      "validation_split: 0.1\n",
      "Model: \"sequential_121\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_363 (Dense)            (None, 72, 80)            160       \n",
      "_________________________________________________________________\n",
      "dense_364 (Dense)            (None, 72, 16)            1296      \n",
      "_________________________________________________________________\n",
      "dropout_121 (Dropout)        (None, 72, 16)            0         \n",
      "_________________________________________________________________\n",
      "dense_365 (Dense)            (None, 72, 1)             17        \n",
      "=================================================================\n",
      "Total params: 1,473\n",
      "Trainable params: 1,473\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/90\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "142/142 [==============================] - 1s 4ms/step - loss: 0.4083 - val_loss: 0.3713\n",
      "Epoch 2/90\n",
      "142/142 [==============================] - 0s 3ms/step - loss: 0.4061 - val_loss: 0.3690\n",
      "Epoch 3/90\n",
      "142/142 [==============================] - 0s 3ms/step - loss: 0.4036 - val_loss: 0.3665\n",
      "Epoch 4/90\n",
      "142/142 [==============================] - 0s 3ms/step - loss: 0.4008 - val_loss: 0.3637\n",
      "Epoch 5/90\n",
      "142/142 [==============================] - 0s 3ms/step - loss: 0.3979 - val_loss: 0.3608\n",
      "Epoch 6/90\n",
      "142/142 [==============================] - 0s 3ms/step - loss: 0.3947 - val_loss: 0.3576\n",
      "Epoch 7/90\n",
      "142/142 [==============================] - 0s 3ms/step - loss: 0.3913 - val_loss: 0.3543\n",
      "Epoch 8/90\n",
      "142/142 [==============================] - 0s 3ms/step - loss: 0.3879 - val_loss: 0.3511\n",
      "Epoch 9/90\n",
      "142/142 [==============================] - 0s 3ms/step - loss: 0.3844 - val_loss: 0.3477\n",
      "Epoch 10/90\n",
      "142/142 [==============================] - 0s 3ms/step - loss: 0.3808 - val_loss: 0.3442\n",
      "Epoch 11/90\n",
      "142/142 [==============================] - 0s 3ms/step - loss: 0.3772 - val_loss: 0.3408\n",
      "Epoch 12/90\n",
      "142/142 [==============================] - 0s 3ms/step - loss: 0.3737 - val_loss: 0.3373\n",
      "Epoch 13/90\n",
      "142/142 [==============================] - 0s 3ms/step - loss: 0.3700 - val_loss: 0.3337\n",
      "Epoch 14/90\n",
      "142/142 [==============================] - 0s 3ms/step - loss: 0.3662 - val_loss: 0.3300\n",
      "Epoch 15/90\n",
      "142/142 [==============================] - 0s 3ms/step - loss: 0.3623 - val_loss: 0.3263\n",
      "Epoch 16/90\n",
      "142/142 [==============================] - 0s 3ms/step - loss: 0.3583 - val_loss: 0.3224\n",
      "Epoch 17/90\n",
      "142/142 [==============================] - 0s 3ms/step - loss: 0.3542 - val_loss: 0.3183\n",
      "Epoch 18/90\n",
      "142/142 [==============================] - 0s 3ms/step - loss: 0.3499 - val_loss: 0.3142\n",
      "Epoch 19/90\n",
      "142/142 [==============================] - 0s 3ms/step - loss: 0.3456 - val_loss: 0.3100\n",
      "Epoch 20/90\n",
      "142/142 [==============================] - 0s 3ms/step - loss: 0.3412 - val_loss: 0.3057\n",
      "Epoch 21/90\n",
      "142/142 [==============================] - 0s 3ms/step - loss: 0.3367 - val_loss: 0.3012\n",
      "Epoch 22/90\n",
      "142/142 [==============================] - 0s 3ms/step - loss: 0.3320 - val_loss: 0.2967\n",
      "Epoch 23/90\n",
      "142/142 [==============================] - 0s 3ms/step - loss: 0.3272 - val_loss: 0.2922\n",
      "Epoch 24/90\n",
      "142/142 [==============================] - 0s 3ms/step - loss: 0.3225 - val_loss: 0.2875\n",
      "Epoch 25/90\n",
      "142/142 [==============================] - 0s 3ms/step - loss: 0.3174 - val_loss: 0.2827\n",
      "Epoch 26/90\n",
      "142/142 [==============================] - 0s 3ms/step - loss: 0.3125 - val_loss: 0.2778\n",
      "Epoch 27/90\n",
      "142/142 [==============================] - 0s 3ms/step - loss: 0.3073 - val_loss: 0.2728\n",
      "Epoch 28/90\n",
      "142/142 [==============================] - 0s 3ms/step - loss: 0.3020 - val_loss: 0.2677\n",
      "Epoch 29/90\n",
      "142/142 [==============================] - 0s 3ms/step - loss: 0.2967 - val_loss: 0.2625\n",
      "Epoch 30/90\n",
      "142/142 [==============================] - 0s 3ms/step - loss: 0.2912 - val_loss: 0.2573\n",
      "Epoch 31/90\n",
      "142/142 [==============================] - 0s 3ms/step - loss: 0.2857 - val_loss: 0.2519\n",
      "Epoch 32/90\n",
      "142/142 [==============================] - 0s 3ms/step - loss: 0.2800 - val_loss: 0.2464\n",
      "Epoch 33/90\n",
      "142/142 [==============================] - 0s 3ms/step - loss: 0.2743 - val_loss: 0.2408\n",
      "Epoch 34/90\n",
      "142/142 [==============================] - 0s 3ms/step - loss: 0.2683 - val_loss: 0.2350\n",
      "Epoch 35/90\n",
      "142/142 [==============================] - 0s 3ms/step - loss: 0.2623 - val_loss: 0.2291\n",
      "Epoch 36/90\n",
      "142/142 [==============================] - 0s 3ms/step - loss: 0.2563 - val_loss: 0.2231\n",
      "Epoch 37/90\n",
      "142/142 [==============================] - 0s 3ms/step - loss: 0.2498 - val_loss: 0.2170\n",
      "Epoch 38/90\n",
      "142/142 [==============================] - 0s 3ms/step - loss: 0.2434 - val_loss: 0.2108\n",
      "Epoch 39/90\n",
      "142/142 [==============================] - 0s 3ms/step - loss: 0.2369 - val_loss: 0.2045\n",
      "Epoch 40/90\n",
      "142/142 [==============================] - 0s 3ms/step - loss: 0.2304 - val_loss: 0.1988\n",
      "Epoch 41/90\n",
      "142/142 [==============================] - 0s 3ms/step - loss: 0.2243 - val_loss: 0.1929\n",
      "Epoch 42/90\n",
      "142/142 [==============================] - 0s 3ms/step - loss: 0.2183 - val_loss: 0.1870\n",
      "Epoch 43/90\n",
      "142/142 [==============================] - 0s 3ms/step - loss: 0.2117 - val_loss: 0.1809\n",
      "Epoch 44/90\n",
      "142/142 [==============================] - 0s 3ms/step - loss: 0.2055 - val_loss: 0.1747\n",
      "Epoch 45/90\n",
      "142/142 [==============================] - 0s 3ms/step - loss: 0.1989 - val_loss: 0.1684\n",
      "Epoch 46/90\n",
      "142/142 [==============================] - 0s 3ms/step - loss: 0.1925 - val_loss: 0.1620\n",
      "Epoch 47/90\n",
      "142/142 [==============================] - 0s 3ms/step - loss: 0.1857 - val_loss: 0.1554\n",
      "Epoch 48/90\n",
      "142/142 [==============================] - 0s 3ms/step - loss: 0.1791 - val_loss: 0.1487\n",
      "Epoch 49/90\n",
      "142/142 [==============================] - 0s 3ms/step - loss: 0.1722 - val_loss: 0.1419\n",
      "Epoch 50/90\n",
      "142/142 [==============================] - 0s 3ms/step - loss: 0.1653 - val_loss: 0.1350\n",
      "Epoch 51/90\n",
      "142/142 [==============================] - 0s 3ms/step - loss: 0.1580 - val_loss: 0.1279\n",
      "Epoch 52/90\n",
      "142/142 [==============================] - 0s 3ms/step - loss: 0.1506 - val_loss: 0.1207\n",
      "Epoch 53/90\n",
      "142/142 [==============================] - 0s 3ms/step - loss: 0.1430 - val_loss: 0.1133\n",
      "Epoch 54/90\n",
      "142/142 [==============================] - 0s 3ms/step - loss: 0.1355 - val_loss: 0.1058\n",
      "Epoch 55/90\n",
      "142/142 [==============================] - 0s 3ms/step - loss: 0.1279 - val_loss: 0.0981\n",
      "Epoch 56/90\n",
      "142/142 [==============================] - 0s 3ms/step - loss: 0.1201 - val_loss: 0.0903\n",
      "Epoch 57/90\n",
      "142/142 [==============================] - 0s 3ms/step - loss: 0.1119 - val_loss: 0.0824\n",
      "Epoch 58/90\n",
      "142/142 [==============================] - 0s 3ms/step - loss: 0.1039 - val_loss: 0.0744\n",
      "Epoch 59/90\n",
      "142/142 [==============================] - 0s 3ms/step - loss: 0.0959 - val_loss: 0.0663\n",
      "Epoch 60/90\n",
      "142/142 [==============================] - 0s 3ms/step - loss: 0.0883 - val_loss: 0.0583\n",
      "Epoch 61/90\n",
      "142/142 [==============================] - 0s 3ms/step - loss: 0.0804 - val_loss: 0.0505\n",
      "Epoch 62/90\n",
      "142/142 [==============================] - 0s 3ms/step - loss: 0.0733 - val_loss: 0.0430\n",
      "Epoch 63/90\n",
      "142/142 [==============================] - 0s 3ms/step - loss: 0.0675 - val_loss: 0.0364\n",
      "Epoch 64/90\n",
      "142/142 [==============================] - 0s 3ms/step - loss: 0.0625 - val_loss: 0.0310\n",
      "Epoch 65/90\n",
      "142/142 [==============================] - 0s 3ms/step - loss: 0.0606 - val_loss: 0.0289\n",
      "Epoch 66/90\n",
      "142/142 [==============================] - 0s 3ms/step - loss: 0.0601 - val_loss: 0.0274\n",
      "Epoch 67/90\n",
      "142/142 [==============================] - 0s 3ms/step - loss: 0.0597 - val_loss: 0.0262\n",
      "Epoch 68/90\n",
      "142/142 [==============================] - 0s 3ms/step - loss: 0.0595 - val_loss: 0.0251\n",
      "Epoch 69/90\n",
      "142/142 [==============================] - 0s 3ms/step - loss: 0.0594 - val_loss: 0.0246\n",
      "Epoch 70/90\n",
      "142/142 [==============================] - 0s 3ms/step - loss: 0.0595 - val_loss: 0.0241\n",
      "Epoch 71/90\n",
      "142/142 [==============================] - 0s 3ms/step - loss: 0.0592 - val_loss: 0.0237\n",
      "Epoch 72/90\n",
      "142/142 [==============================] - 0s 3ms/step - loss: 0.0592 - val_loss: 0.0233\n",
      "Epoch 73/90\n",
      "142/142 [==============================] - 0s 3ms/step - loss: 0.0593 - val_loss: 0.0230\n",
      "Epoch 74/90\n",
      "142/142 [==============================] - 0s 3ms/step - loss: 0.0591 - val_loss: 0.0227\n",
      "Epoch 75/90\n",
      "142/142 [==============================] - 0s 3ms/step - loss: 0.0591 - val_loss: 0.0225\n",
      "Epoch 76/90\n",
      "142/142 [==============================] - 0s 3ms/step - loss: 0.0590 - val_loss: 0.0223\n",
      "Epoch 77/90\n",
      "142/142 [==============================] - 0s 3ms/step - loss: 0.0591 - val_loss: 0.0221\n",
      "Epoch 78/90\n",
      "142/142 [==============================] - 0s 3ms/step - loss: 0.0592 - val_loss: 0.0219\n",
      "Epoch 79/90\n",
      "142/142 [==============================] - 0s 3ms/step - loss: 0.0589 - val_loss: 0.0217\n",
      "Epoch 80/90\n",
      "142/142 [==============================] - 0s 3ms/step - loss: 0.0594 - val_loss: 0.0216\n",
      "Epoch 81/90\n",
      "142/142 [==============================] - 0s 3ms/step - loss: 0.0590 - val_loss: 0.0214\n",
      "Epoch 82/90\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "142/142 [==============================] - 0s 3ms/step - loss: 0.0592 - val_loss: 0.0213\n",
      "Epoch 83/90\n",
      "142/142 [==============================] - 0s 3ms/step - loss: 0.0589 - val_loss: 0.0212\n",
      "Epoch 84/90\n",
      "142/142 [==============================] - 0s 3ms/step - loss: 0.0588 - val_loss: 0.0210\n",
      "Epoch 85/90\n",
      "142/142 [==============================] - 0s 3ms/step - loss: 0.0589 - val_loss: 0.0210\n",
      "Epoch 86/90\n",
      "142/142 [==============================] - 0s 3ms/step - loss: 0.0591 - val_loss: 0.0210\n",
      "Epoch 87/90\n",
      "142/142 [==============================] - 0s 3ms/step - loss: 0.0590 - val_loss: 0.0210\n",
      "Epoch 88/90\n",
      "142/142 [==============================] - 0s 3ms/step - loss: 0.0589 - val_loss: 0.0210\n",
      "Epoch 89/90\n",
      "142/142 [==============================] - 0s 3ms/step - loss: 0.0587 - val_loss: 0.0210\n",
      "Epoch 90/90\n",
      "142/142 [==============================] - 0s 3ms/step - loss: 0.0590 - val_loss: 0.0210\n",
      "Execution time:  39.133760929107666\n",
      "DNN:\n",
      "Mean Absolute Error: 0.0416\n",
      "Root Mean Square Error: 0.0493\n",
      "Mean Square Error: 0.0024\n",
      "\n",
      "Train RMSE: 0.049\n",
      "Train MSE: 0.002\n",
      "Train MAE: 0.042\n",
      "###########################\n",
      "\n",
      "MODEL:  DNN\n",
      "sequence:  12h\n",
      "units:  12\n",
      "dropout1:  0.48476373451509647\n",
      "optimizer: adadelta\n",
      "activationDense: tanh\n",
      "epochs: 52\n",
      "batchsize: 57\n",
      "validation_split: 0.1\n",
      "Model: \"sequential_122\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_366 (Dense)            (None, 72, 12)            24        \n",
      "_________________________________________________________________\n",
      "dense_367 (Dense)            (None, 72, 16)            208       \n",
      "_________________________________________________________________\n",
      "dropout_122 (Dropout)        (None, 72, 16)            0         \n",
      "_________________________________________________________________\n",
      "dense_368 (Dense)            (None, 72, 1)             17        \n",
      "=================================================================\n",
      "Total params: 249\n",
      "Trainable params: 249\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/52\n",
      "62/62 [==============================] - 0s 6ms/step - loss: 0.3775 - val_loss: 0.3432\n",
      "Epoch 2/52\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.3766 - val_loss: 0.3423\n",
      "Epoch 3/52\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.3754 - val_loss: 0.3414\n",
      "Epoch 4/52\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.3749 - val_loss: 0.3404\n",
      "Epoch 5/52\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.3734 - val_loss: 0.3394\n",
      "Epoch 6/52\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.3727 - val_loss: 0.3383\n",
      "Epoch 7/52\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.3713 - val_loss: 0.3372\n",
      "Epoch 8/52\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.3705 - val_loss: 0.3361\n",
      "Epoch 9/52\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.3687 - val_loss: 0.3349\n",
      "Epoch 10/52\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.3680 - val_loss: 0.3337\n",
      "Epoch 11/52\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.3668 - val_loss: 0.3324\n",
      "Epoch 12/52\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.3651 - val_loss: 0.3311\n",
      "Epoch 13/52\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.3636 - val_loss: 0.3298\n",
      "Epoch 14/52\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.3625 - val_loss: 0.3284\n",
      "Epoch 15/52\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.3613 - val_loss: 0.3270\n",
      "Epoch 16/52\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.3596 - val_loss: 0.3256\n",
      "Epoch 17/52\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.3583 - val_loss: 0.3241\n",
      "Epoch 18/52\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.3567 - val_loss: 0.3226\n",
      "Epoch 19/52\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.3555 - val_loss: 0.3211\n",
      "Epoch 20/52\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.3538 - val_loss: 0.3196\n",
      "Epoch 21/52\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.3521 - val_loss: 0.3180\n",
      "Epoch 22/52\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.3505 - val_loss: 0.3164\n",
      "Epoch 23/52\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.3489 - val_loss: 0.3148\n",
      "Epoch 24/52\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.3472 - val_loss: 0.3131\n",
      "Epoch 25/52\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.3456 - val_loss: 0.3114\n",
      "Epoch 26/52\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.3434 - val_loss: 0.3097\n",
      "Epoch 27/52\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.3424 - val_loss: 0.3079\n",
      "Epoch 28/52\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.3400 - val_loss: 0.3062\n",
      "Epoch 29/52\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.3394 - val_loss: 0.3044\n",
      "Epoch 30/52\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.3366 - val_loss: 0.3026\n",
      "Epoch 31/52\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.3340 - val_loss: 0.3007\n",
      "Epoch 32/52\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.3327 - val_loss: 0.2988\n",
      "Epoch 33/52\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.3310 - val_loss: 0.2969\n",
      "Epoch 34/52\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.3287 - val_loss: 0.2950\n",
      "Epoch 35/52\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.3273 - val_loss: 0.2931\n",
      "Epoch 36/52\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.3254 - val_loss: 0.2911\n",
      "Epoch 37/52\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.3230 - val_loss: 0.2891\n",
      "Epoch 38/52\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.3210 - val_loss: 0.2871\n",
      "Epoch 39/52\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.3190 - val_loss: 0.2851\n",
      "Epoch 40/52\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.3172 - val_loss: 0.2830\n",
      "Epoch 41/52\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.3150 - val_loss: 0.2809\n",
      "Epoch 42/52\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.3128 - val_loss: 0.2789\n",
      "Epoch 43/52\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.3113 - val_loss: 0.2771\n",
      "Epoch 44/52\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.3090 - val_loss: 0.2752\n",
      "Epoch 45/52\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.3069 - val_loss: 0.2733\n",
      "Epoch 46/52\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.3050 - val_loss: 0.2714\n",
      "Epoch 47/52\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.3031 - val_loss: 0.2695\n",
      "Epoch 48/52\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.3008 - val_loss: 0.2676\n",
      "Epoch 49/52\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.2993 - val_loss: 0.2656\n",
      "Epoch 50/52\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.2976 - val_loss: 0.2637\n",
      "Epoch 51/52\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.2950 - val_loss: 0.2617\n",
      "Epoch 52/52\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.2934 - val_loss: 0.2598\n",
      "Execution time:  12.370065927505493\n",
      "DNN:\n",
      "Mean Absolute Error: 0.2871\n",
      "Root Mean Square Error: 0.2892\n",
      "Mean Square Error: 0.0836\n",
      "\n",
      "Train RMSE: 0.289\n",
      "Train MSE: 0.084\n",
      "Train MAE: 0.287\n",
      "###########################\n",
      "\n",
      "MODEL:  DNN\n",
      "sequence:  12h\n",
      "units:  87\n",
      "dropout1:  0.40519643149940265\n",
      "optimizer: adadelta\n",
      "activationDense: tanh\n",
      "epochs: 80\n",
      "batchsize: 31\n",
      "validation_split: 0.2\n",
      "Model: \"sequential_123\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_369 (Dense)            (None, 72, 87)            174       \n",
      "_________________________________________________________________\n",
      "dense_370 (Dense)            (None, 72, 16)            1408      \n",
      "_________________________________________________________________\n",
      "dropout_123 (Dropout)        (None, 72, 16)            0         \n",
      "_________________________________________________________________\n",
      "dense_371 (Dense)            (None, 72, 1)             17        \n",
      "=================================================================\n",
      "Total params: 1,599\n",
      "Trainable params: 1,599\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/80\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "102/102 [==============================] - 1s 5ms/step - loss: 0.4704 - val_loss: 0.4441\n",
      "Epoch 2/80\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.4674 - val_loss: 0.4410\n",
      "Epoch 3/80\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.4642 - val_loss: 0.4377\n",
      "Epoch 4/80\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.4607 - val_loss: 0.4342\n",
      "Epoch 5/80\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.4571 - val_loss: 0.4304\n",
      "Epoch 6/80\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.4531 - val_loss: 0.4265\n",
      "Epoch 7/80\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.4490 - val_loss: 0.4224\n",
      "Epoch 8/80\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.4449 - val_loss: 0.4185\n",
      "Epoch 9/80\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.4409 - val_loss: 0.4146\n",
      "Epoch 10/80\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.4366 - val_loss: 0.4105\n",
      "Epoch 11/80\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.4323 - val_loss: 0.4063\n",
      "Epoch 12/80\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.4280 - val_loss: 0.4020\n",
      "Epoch 13/80\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.4235 - val_loss: 0.3976\n",
      "Epoch 14/80\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.4190 - val_loss: 0.3932\n",
      "Epoch 15/80\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.4149 - val_loss: 0.3894\n",
      "Epoch 16/80\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.4109 - val_loss: 0.3857\n",
      "Epoch 17/80\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.4070 - val_loss: 0.3820\n",
      "Epoch 18/80\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.4031 - val_loss: 0.3781\n",
      "Epoch 19/80\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.3990 - val_loss: 0.3742\n",
      "Epoch 20/80\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.3949 - val_loss: 0.3702\n",
      "Epoch 21/80\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.3909 - val_loss: 0.3661\n",
      "Epoch 22/80\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.3866 - val_loss: 0.3619\n",
      "Epoch 23/80\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.3822 - val_loss: 0.3576\n",
      "Epoch 24/80\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.3778 - val_loss: 0.3533\n",
      "Epoch 25/80\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.3735 - val_loss: 0.3493\n",
      "Epoch 26/80\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.3694 - val_loss: 0.3452\n",
      "Epoch 27/80\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.3649 - val_loss: 0.3411\n",
      "Epoch 28/80\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.3607 - val_loss: 0.3369\n",
      "Epoch 29/80\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.3564 - val_loss: 0.3327\n",
      "Epoch 30/80\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.3520 - val_loss: 0.3284\n",
      "Epoch 31/80\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.3476 - val_loss: 0.3245\n",
      "Epoch 32/80\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.3438 - val_loss: 0.3211\n",
      "Epoch 33/80\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.3401 - val_loss: 0.3177\n",
      "Epoch 34/80\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.3367 - val_loss: 0.3143\n",
      "Epoch 35/80\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.3332 - val_loss: 0.3109\n",
      "Epoch 36/80\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.3296 - val_loss: 0.3079\n",
      "Epoch 37/80\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.3266 - val_loss: 0.3055\n",
      "Epoch 38/80\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.3239 - val_loss: 0.3030\n",
      "Epoch 39/80\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.3214 - val_loss: 0.3006\n",
      "Epoch 40/80\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.3188 - val_loss: 0.2982\n",
      "Epoch 41/80\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.3162 - val_loss: 0.2957\n",
      "Epoch 42/80\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.3138 - val_loss: 0.2934\n",
      "Epoch 43/80\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.3112 - val_loss: 0.2909\n",
      "Epoch 44/80\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.3086 - val_loss: 0.2885\n",
      "Epoch 45/80\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.3060 - val_loss: 0.2860\n",
      "Epoch 46/80\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.3033 - val_loss: 0.2834\n",
      "Epoch 47/80\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.3008 - val_loss: 0.2808\n",
      "Epoch 48/80\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.2980 - val_loss: 0.2781\n",
      "Epoch 49/80\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.2953 - val_loss: 0.2754\n",
      "Epoch 50/80\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.2925 - val_loss: 0.2726\n",
      "Epoch 51/80\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.2896 - val_loss: 0.2698\n",
      "Epoch 52/80\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.2865 - val_loss: 0.2669\n",
      "Epoch 53/80\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.2837 - val_loss: 0.2639\n",
      "Epoch 54/80\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.2807 - val_loss: 0.2609\n",
      "Epoch 55/80\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.2778 - val_loss: 0.2579\n",
      "Epoch 56/80\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.2745 - val_loss: 0.2547\n",
      "Epoch 57/80\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.2711 - val_loss: 0.2516\n",
      "Epoch 58/80\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.2680 - val_loss: 0.2483\n",
      "Epoch 59/80\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.2645 - val_loss: 0.2450\n",
      "Epoch 60/80\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.2612 - val_loss: 0.2416\n",
      "Epoch 61/80\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.2579 - val_loss: 0.2381\n",
      "Epoch 62/80\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.2543 - val_loss: 0.2346\n",
      "Epoch 63/80\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.2508 - val_loss: 0.2310\n",
      "Epoch 64/80\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.2469 - val_loss: 0.2273\n",
      "Epoch 65/80\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.2430 - val_loss: 0.2236\n",
      "Epoch 66/80\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.2395 - val_loss: 0.2198\n",
      "Epoch 67/80\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.2355 - val_loss: 0.2159\n",
      "Epoch 68/80\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.2314 - val_loss: 0.2120\n",
      "Epoch 69/80\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.2275 - val_loss: 0.2079\n",
      "Epoch 70/80\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.2236 - val_loss: 0.2038\n",
      "Epoch 71/80\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.2193 - val_loss: 0.1996\n",
      "Epoch 72/80\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.2150 - val_loss: 0.1954\n",
      "Epoch 73/80\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.2110 - val_loss: 0.1910\n",
      "Epoch 74/80\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.2065 - val_loss: 0.1866\n",
      "Epoch 75/80\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.2019 - val_loss: 0.1821\n",
      "Epoch 76/80\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.1976 - val_loss: 0.1775\n",
      "Epoch 77/80\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.1928 - val_loss: 0.1728\n",
      "Epoch 78/80\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.1880 - val_loss: 0.1681\n",
      "Epoch 79/80\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.1834 - val_loss: 0.1633\n",
      "Epoch 80/80\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.1789 - val_loss: 0.1584\n",
      "Execution time:  31.474199771881104\n",
      "DNN:\n",
      "Mean Absolute Error: 0.1714\n",
      "Root Mean Square Error: 0.1742\n",
      "Mean Square Error: 0.0303\n",
      "\n",
      "Train RMSE: 0.174\n",
      "Train MSE: 0.030\n",
      "Train MAE: 0.171\n",
      "###########################\n",
      "\n",
      "MODEL:  DNN\n",
      "sequence:  12h\n",
      "units:  80\n",
      "dropout1:  0.11814836227952394\n",
      "optimizer: adadelta\n",
      "activationDense: tanh\n",
      "epochs: 90\n",
      "batchsize: 25\n",
      "validation_split: 0.2\n",
      "Model: \"sequential_124\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_372 (Dense)            (None, 72, 80)            160       \n",
      "_________________________________________________________________\n",
      "dense_373 (Dense)            (None, 72, 16)            1296      \n",
      "_________________________________________________________________\n",
      "dropout_124 (Dropout)        (None, 72, 16)            0         \n",
      "_________________________________________________________________\n",
      "dense_374 (Dense)            (None, 72, 1)             17        \n",
      "=================================================================\n",
      "Total params: 1,473\n",
      "Trainable params: 1,473\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/90\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "126/126 [==============================] - 1s 4ms/step - loss: 0.4022 - val_loss: 0.3795\n",
      "Epoch 2/90\n",
      "126/126 [==============================] - 0s 3ms/step - loss: 0.3992 - val_loss: 0.3762\n",
      "Epoch 3/90\n",
      "126/126 [==============================] - 0s 3ms/step - loss: 0.3956 - val_loss: 0.3726\n",
      "Epoch 4/90\n",
      "126/126 [==============================] - 0s 3ms/step - loss: 0.3918 - val_loss: 0.3687\n",
      "Epoch 5/90\n",
      "126/126 [==============================] - 0s 3ms/step - loss: 0.3877 - val_loss: 0.3645\n",
      "Epoch 6/90\n",
      "126/126 [==============================] - 0s 3ms/step - loss: 0.3831 - val_loss: 0.3600\n",
      "Epoch 7/90\n",
      "126/126 [==============================] - 0s 3ms/step - loss: 0.3785 - val_loss: 0.3553\n",
      "Epoch 8/90\n",
      "126/126 [==============================] - 0s 3ms/step - loss: 0.3734 - val_loss: 0.3502\n",
      "Epoch 9/90\n",
      "126/126 [==============================] - 0s 4ms/step - loss: 0.3681 - val_loss: 0.3450\n",
      "Epoch 10/90\n",
      "126/126 [==============================] - 0s 3ms/step - loss: 0.3627 - val_loss: 0.3395\n",
      "Epoch 11/90\n",
      "126/126 [==============================] - 0s 3ms/step - loss: 0.3570 - val_loss: 0.3339\n",
      "Epoch 12/90\n",
      "126/126 [==============================] - 0s 3ms/step - loss: 0.3512 - val_loss: 0.3281\n",
      "Epoch 13/90\n",
      "126/126 [==============================] - 0s 3ms/step - loss: 0.3451 - val_loss: 0.3220\n",
      "Epoch 14/90\n",
      "126/126 [==============================] - 0s 3ms/step - loss: 0.3386 - val_loss: 0.3157\n",
      "Epoch 15/90\n",
      "126/126 [==============================] - 0s 3ms/step - loss: 0.3321 - val_loss: 0.3091\n",
      "Epoch 16/90\n",
      "126/126 [==============================] - 0s 3ms/step - loss: 0.3251 - val_loss: 0.3023\n",
      "Epoch 17/90\n",
      "126/126 [==============================] - 0s 3ms/step - loss: 0.3181 - val_loss: 0.2953\n",
      "Epoch 18/90\n",
      "126/126 [==============================] - 0s 3ms/step - loss: 0.3107 - val_loss: 0.2880\n",
      "Epoch 19/90\n",
      "126/126 [==============================] - 0s 3ms/step - loss: 0.3032 - val_loss: 0.2804\n",
      "Epoch 20/90\n",
      "126/126 [==============================] - 0s 3ms/step - loss: 0.2952 - val_loss: 0.2725\n",
      "Epoch 21/90\n",
      "126/126 [==============================] - 0s 3ms/step - loss: 0.2869 - val_loss: 0.2643\n",
      "Epoch 22/90\n",
      "126/126 [==============================] - 0s 3ms/step - loss: 0.2784 - val_loss: 0.2557\n",
      "Epoch 23/90\n",
      "126/126 [==============================] - 0s 3ms/step - loss: 0.2695 - val_loss: 0.2468\n",
      "Epoch 24/90\n",
      "126/126 [==============================] - 0s 3ms/step - loss: 0.2604 - val_loss: 0.2376\n",
      "Epoch 25/90\n",
      "126/126 [==============================] - 0s 3ms/step - loss: 0.2506 - val_loss: 0.2280\n",
      "Epoch 26/90\n",
      "126/126 [==============================] - 0s 3ms/step - loss: 0.2406 - val_loss: 0.2179\n",
      "Epoch 27/90\n",
      "126/126 [==============================] - 0s 3ms/step - loss: 0.2301 - val_loss: 0.2074\n",
      "Epoch 28/90\n",
      "126/126 [==============================] - 0s 3ms/step - loss: 0.2193 - val_loss: 0.1965\n",
      "Epoch 29/90\n",
      "126/126 [==============================] - 0s 3ms/step - loss: 0.2078 - val_loss: 0.1851\n",
      "Epoch 30/90\n",
      "126/126 [==============================] - 0s 3ms/step - loss: 0.1958 - val_loss: 0.1731\n",
      "Epoch 31/90\n",
      "126/126 [==============================] - 0s 3ms/step - loss: 0.1836 - val_loss: 0.1607\n",
      "Epoch 32/90\n",
      "126/126 [==============================] - 0s 3ms/step - loss: 0.1707 - val_loss: 0.1484\n",
      "Epoch 33/90\n",
      "126/126 [==============================] - 0s 3ms/step - loss: 0.1579 - val_loss: 0.1358\n",
      "Epoch 34/90\n",
      "126/126 [==============================] - 0s 3ms/step - loss: 0.1450 - val_loss: 0.1227\n",
      "Epoch 35/90\n",
      "126/126 [==============================] - 0s 3ms/step - loss: 0.1312 - val_loss: 0.1091\n",
      "Epoch 36/90\n",
      "126/126 [==============================] - 0s 3ms/step - loss: 0.1172 - val_loss: 0.0948\n",
      "Epoch 37/90\n",
      "126/126 [==============================] - 0s 3ms/step - loss: 0.1028 - val_loss: 0.0800\n",
      "Epoch 38/90\n",
      "126/126 [==============================] - 0s 3ms/step - loss: 0.0879 - val_loss: 0.0650\n",
      "Epoch 39/90\n",
      "126/126 [==============================] - 0s 3ms/step - loss: 0.0738 - val_loss: 0.0503\n",
      "Epoch 40/90\n",
      "126/126 [==============================] - 0s 3ms/step - loss: 0.0624 - val_loss: 0.0409\n",
      "Epoch 41/90\n",
      "126/126 [==============================] - 0s 3ms/step - loss: 0.0583 - val_loss: 0.0348\n",
      "Epoch 42/90\n",
      "126/126 [==============================] - 0s 3ms/step - loss: 0.0561 - val_loss: 0.0308\n",
      "Epoch 43/90\n",
      "126/126 [==============================] - 0s 3ms/step - loss: 0.0550 - val_loss: 0.0283\n",
      "Epoch 44/90\n",
      "126/126 [==============================] - 0s 3ms/step - loss: 0.0543 - val_loss: 0.0266\n",
      "Epoch 45/90\n",
      "126/126 [==============================] - 0s 3ms/step - loss: 0.0537 - val_loss: 0.0253\n",
      "Epoch 46/90\n",
      "126/126 [==============================] - 0s 3ms/step - loss: 0.0536 - val_loss: 0.0242\n",
      "Epoch 47/90\n",
      "126/126 [==============================] - 0s 4ms/step - loss: 0.0536 - val_loss: 0.0233\n",
      "Epoch 48/90\n",
      "126/126 [==============================] - 0s 3ms/step - loss: 0.0531 - val_loss: 0.0226\n",
      "Epoch 49/90\n",
      "126/126 [==============================] - 0s 3ms/step - loss: 0.0532 - val_loss: 0.0219\n",
      "Epoch 50/90\n",
      "126/126 [==============================] - 0s 3ms/step - loss: 0.0530 - val_loss: 0.0214\n",
      "Epoch 51/90\n",
      "126/126 [==============================] - 0s 4ms/step - loss: 0.0529 - val_loss: 0.0208\n",
      "Epoch 52/90\n",
      "126/126 [==============================] - 0s 3ms/step - loss: 0.0528 - val_loss: 0.0203\n",
      "Epoch 53/90\n",
      "126/126 [==============================] - 0s 3ms/step - loss: 0.0527 - val_loss: 0.0199\n",
      "Epoch 54/90\n",
      "126/126 [==============================] - 0s 3ms/step - loss: 0.0527 - val_loss: 0.0195\n",
      "Epoch 55/90\n",
      "126/126 [==============================] - 0s 3ms/step - loss: 0.0525 - val_loss: 0.0191\n",
      "Epoch 56/90\n",
      "126/126 [==============================] - 0s 3ms/step - loss: 0.0525 - val_loss: 0.0188\n",
      "Epoch 57/90\n",
      "126/126 [==============================] - 0s 3ms/step - loss: 0.0525 - val_loss: 0.0185\n",
      "Epoch 58/90\n",
      "126/126 [==============================] - 0s 3ms/step - loss: 0.0523 - val_loss: 0.0182\n",
      "Epoch 59/90\n",
      "126/126 [==============================] - 0s 3ms/step - loss: 0.0523 - val_loss: 0.0179\n",
      "Epoch 60/90\n",
      "126/126 [==============================] - 0s 3ms/step - loss: 0.0523 - val_loss: 0.0177\n",
      "Epoch 61/90\n",
      "126/126 [==============================] - 0s 3ms/step - loss: 0.0523 - val_loss: 0.0174\n",
      "Epoch 62/90\n",
      "126/126 [==============================] - 0s 3ms/step - loss: 0.0522 - val_loss: 0.0172\n",
      "Epoch 63/90\n",
      "126/126 [==============================] - 0s 3ms/step - loss: 0.0522 - val_loss: 0.0170\n",
      "Epoch 64/90\n",
      "126/126 [==============================] - 0s 3ms/step - loss: 0.0520 - val_loss: 0.0168\n",
      "Epoch 65/90\n",
      "126/126 [==============================] - 0s 3ms/step - loss: 0.0521 - val_loss: 0.0166\n",
      "Epoch 66/90\n",
      "126/126 [==============================] - 0s 3ms/step - loss: 0.0521 - val_loss: 0.0164\n",
      "Epoch 67/90\n",
      "126/126 [==============================] - 0s 3ms/step - loss: 0.0521 - val_loss: 0.0162\n",
      "Epoch 68/90\n",
      "126/126 [==============================] - 0s 3ms/step - loss: 0.0520 - val_loss: 0.0161\n",
      "Epoch 69/90\n",
      "126/126 [==============================] - 0s 3ms/step - loss: 0.0518 - val_loss: 0.0159\n",
      "Epoch 70/90\n",
      "126/126 [==============================] - 0s 3ms/step - loss: 0.0521 - val_loss: 0.0158\n",
      "Epoch 71/90\n",
      "126/126 [==============================] - 0s 3ms/step - loss: 0.0519 - val_loss: 0.0157\n",
      "Epoch 72/90\n",
      "126/126 [==============================] - 0s 3ms/step - loss: 0.0518 - val_loss: 0.0155\n",
      "Epoch 73/90\n",
      "126/126 [==============================] - 0s 3ms/step - loss: 0.0519 - val_loss: 0.0155\n",
      "Epoch 74/90\n",
      "126/126 [==============================] - 0s 3ms/step - loss: 0.0518 - val_loss: 0.0154\n",
      "Epoch 75/90\n",
      "126/126 [==============================] - 0s 3ms/step - loss: 0.0518 - val_loss: 0.0154\n",
      "Epoch 76/90\n",
      "126/126 [==============================] - 0s 3ms/step - loss: 0.0517 - val_loss: 0.0154\n",
      "Epoch 77/90\n",
      "126/126 [==============================] - 0s 3ms/step - loss: 0.0517 - val_loss: 0.0153\n",
      "Epoch 78/90\n",
      "126/126 [==============================] - 0s 3ms/step - loss: 0.0517 - val_loss: 0.0153\n",
      "Epoch 79/90\n",
      "126/126 [==============================] - 0s 3ms/step - loss: 0.0517 - val_loss: 0.0153\n",
      "Epoch 80/90\n",
      "126/126 [==============================] - 0s 3ms/step - loss: 0.0517 - val_loss: 0.0152\n",
      "Epoch 81/90\n",
      "126/126 [==============================] - 0s 3ms/step - loss: 0.0517 - val_loss: 0.0152\n",
      "Epoch 82/90\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "126/126 [==============================] - 0s 3ms/step - loss: 0.0516 - val_loss: 0.0152\n",
      "Epoch 83/90\n",
      "126/126 [==============================] - 0s 3ms/step - loss: 0.0516 - val_loss: 0.0152\n",
      "Epoch 84/90\n",
      "126/126 [==============================] - 0s 3ms/step - loss: 0.0516 - val_loss: 0.0152\n",
      "Epoch 85/90\n",
      "126/126 [==============================] - 0s 3ms/step - loss: 0.0517 - val_loss: 0.0151\n",
      "Epoch 86/90\n",
      "126/126 [==============================] - 0s 3ms/step - loss: 0.0515 - val_loss: 0.0151\n",
      "Epoch 87/90\n",
      "126/126 [==============================] - 0s 3ms/step - loss: 0.0517 - val_loss: 0.0151\n",
      "Epoch 88/90\n",
      "126/126 [==============================] - 0s 3ms/step - loss: 0.0516 - val_loss: 0.0151\n",
      "Epoch 89/90\n",
      "126/126 [==============================] - 0s 3ms/step - loss: 0.0515 - val_loss: 0.0150\n",
      "Epoch 90/90\n",
      "126/126 [==============================] - 0s 3ms/step - loss: 0.0517 - val_loss: 0.0150\n",
      "Execution time:  37.762080907821655\n",
      "DNN:\n",
      "Mean Absolute Error: 0.0201\n",
      "Root Mean Square Error: 0.0313\n",
      "Mean Square Error: 0.0010\n",
      "\n",
      "Train RMSE: 0.031\n",
      "Train MSE: 0.001\n",
      "Train MAE: 0.020\n",
      "###########################\n",
      "\n",
      "MODEL:  DNN\n",
      "sequence:  12h\n",
      "units:  12\n",
      "dropout1:  0.48476373451509647\n",
      "optimizer: adadelta\n",
      "activationDense: tanh\n",
      "epochs: 52\n",
      "batchsize: 57\n",
      "validation_split: 0.2\n",
      "Model: \"sequential_125\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_375 (Dense)            (None, 72, 12)            24        \n",
      "_________________________________________________________________\n",
      "dense_376 (Dense)            (None, 72, 16)            208       \n",
      "_________________________________________________________________\n",
      "dropout_125 (Dropout)        (None, 72, 16)            0         \n",
      "_________________________________________________________________\n",
      "dense_377 (Dense)            (None, 72, 1)             17        \n",
      "=================================================================\n",
      "Total params: 249\n",
      "Trainable params: 249\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/52\n",
      "55/55 [==============================] - 0s 7ms/step - loss: 0.4327 - val_loss: 0.4094\n",
      "Epoch 2/52\n",
      "55/55 [==============================] - 0s 3ms/step - loss: 0.4318 - val_loss: 0.4088\n",
      "Epoch 3/52\n",
      "55/55 [==============================] - 0s 3ms/step - loss: 0.4317 - val_loss: 0.4083\n",
      "Epoch 4/52\n",
      "55/55 [==============================] - 0s 3ms/step - loss: 0.4309 - val_loss: 0.4077\n",
      "Epoch 5/52\n",
      "55/55 [==============================] - 0s 3ms/step - loss: 0.4303 - val_loss: 0.4071\n",
      "Epoch 6/52\n",
      "55/55 [==============================] - 0s 3ms/step - loss: 0.4297 - val_loss: 0.4065\n",
      "Epoch 7/52\n",
      "55/55 [==============================] - 0s 3ms/step - loss: 0.4286 - val_loss: 0.4059\n",
      "Epoch 8/52\n",
      "55/55 [==============================] - 0s 3ms/step - loss: 0.4284 - val_loss: 0.4052\n",
      "Epoch 9/52\n",
      "55/55 [==============================] - 0s 3ms/step - loss: 0.4275 - val_loss: 0.4045\n",
      "Epoch 10/52\n",
      "55/55 [==============================] - 0s 3ms/step - loss: 0.4266 - val_loss: 0.4038\n",
      "Epoch 11/52\n",
      "55/55 [==============================] - 0s 3ms/step - loss: 0.4261 - val_loss: 0.4031\n",
      "Epoch 12/52\n",
      "55/55 [==============================] - 0s 3ms/step - loss: 0.4254 - val_loss: 0.4023\n",
      "Epoch 13/52\n",
      "55/55 [==============================] - 0s 3ms/step - loss: 0.4246 - val_loss: 0.4016\n",
      "Epoch 14/52\n",
      "55/55 [==============================] - 0s 3ms/step - loss: 0.4238 - val_loss: 0.4008\n",
      "Epoch 15/52\n",
      "55/55 [==============================] - 0s 3ms/step - loss: 0.4226 - val_loss: 0.4000\n",
      "Epoch 16/52\n",
      "55/55 [==============================] - 0s 3ms/step - loss: 0.4222 - val_loss: 0.3992\n",
      "Epoch 17/52\n",
      "55/55 [==============================] - 0s 3ms/step - loss: 0.4215 - val_loss: 0.3983\n",
      "Epoch 18/52\n",
      "55/55 [==============================] - 0s 3ms/step - loss: 0.4205 - val_loss: 0.3975\n",
      "Epoch 19/52\n",
      "55/55 [==============================] - 0s 3ms/step - loss: 0.4194 - val_loss: 0.3966\n",
      "Epoch 20/52\n",
      "55/55 [==============================] - 0s 3ms/step - loss: 0.4186 - val_loss: 0.3957\n",
      "Epoch 21/52\n",
      "55/55 [==============================] - 0s 3ms/step - loss: 0.4176 - val_loss: 0.3948\n",
      "Epoch 22/52\n",
      "55/55 [==============================] - 0s 3ms/step - loss: 0.4165 - val_loss: 0.3939\n",
      "Epoch 23/52\n",
      "55/55 [==============================] - 0s 3ms/step - loss: 0.4158 - val_loss: 0.3930\n",
      "Epoch 24/52\n",
      "55/55 [==============================] - 0s 3ms/step - loss: 0.4150 - val_loss: 0.3921\n",
      "Epoch 25/52\n",
      "55/55 [==============================] - 0s 3ms/step - loss: 0.4140 - val_loss: 0.3911\n",
      "Epoch 26/52\n",
      "55/55 [==============================] - 0s 3ms/step - loss: 0.4131 - val_loss: 0.3901\n",
      "Epoch 27/52\n",
      "55/55 [==============================] - 0s 3ms/step - loss: 0.4122 - val_loss: 0.3891\n",
      "Epoch 28/52\n",
      "55/55 [==============================] - 0s 3ms/step - loss: 0.4110 - val_loss: 0.3881\n",
      "Epoch 29/52\n",
      "55/55 [==============================] - 0s 3ms/step - loss: 0.4101 - val_loss: 0.3871\n",
      "Epoch 30/52\n",
      "55/55 [==============================] - 0s 3ms/step - loss: 0.4091 - val_loss: 0.3861\n",
      "Epoch 31/52\n",
      "55/55 [==============================] - 0s 3ms/step - loss: 0.4079 - val_loss: 0.3850\n",
      "Epoch 32/52\n",
      "55/55 [==============================] - 0s 3ms/step - loss: 0.4068 - val_loss: 0.3840\n",
      "Epoch 33/52\n",
      "55/55 [==============================] - 0s 3ms/step - loss: 0.4058 - val_loss: 0.3829\n",
      "Epoch 34/52\n",
      "55/55 [==============================] - 0s 3ms/step - loss: 0.4047 - val_loss: 0.3818\n",
      "Epoch 35/52\n",
      "55/55 [==============================] - 0s 3ms/step - loss: 0.4036 - val_loss: 0.3808\n",
      "Epoch 36/52\n",
      "55/55 [==============================] - 0s 3ms/step - loss: 0.4026 - val_loss: 0.3796\n",
      "Epoch 37/52\n",
      "55/55 [==============================] - 0s 3ms/step - loss: 0.4015 - val_loss: 0.3785\n",
      "Epoch 38/52\n",
      "55/55 [==============================] - 0s 3ms/step - loss: 0.4003 - val_loss: 0.3774\n",
      "Epoch 39/52\n",
      "55/55 [==============================] - 0s 3ms/step - loss: 0.3990 - val_loss: 0.3763\n",
      "Epoch 40/52\n",
      "55/55 [==============================] - 0s 3ms/step - loss: 0.3980 - val_loss: 0.3751\n",
      "Epoch 41/52\n",
      "55/55 [==============================] - 0s 3ms/step - loss: 0.3965 - val_loss: 0.3739\n",
      "Epoch 42/52\n",
      "55/55 [==============================] - 0s 3ms/step - loss: 0.3952 - val_loss: 0.3728\n",
      "Epoch 43/52\n",
      "55/55 [==============================] - 0s 3ms/step - loss: 0.3940 - val_loss: 0.3716\n",
      "Epoch 44/52\n",
      "55/55 [==============================] - 0s 3ms/step - loss: 0.3934 - val_loss: 0.3704\n",
      "Epoch 45/52\n",
      "55/55 [==============================] - 0s 3ms/step - loss: 0.3919 - val_loss: 0.3691\n",
      "Epoch 46/52\n",
      "55/55 [==============================] - 0s 3ms/step - loss: 0.3907 - val_loss: 0.3679\n",
      "Epoch 47/52\n",
      "55/55 [==============================] - 0s 3ms/step - loss: 0.3897 - val_loss: 0.3667\n",
      "Epoch 48/52\n",
      "55/55 [==============================] - 0s 3ms/step - loss: 0.3881 - val_loss: 0.3654\n",
      "Epoch 49/52\n",
      "55/55 [==============================] - 0s 3ms/step - loss: 0.3869 - val_loss: 0.3642\n",
      "Epoch 50/52\n",
      "55/55 [==============================] - 0s 3ms/step - loss: 0.3854 - val_loss: 0.3629\n",
      "Epoch 51/52\n",
      "55/55 [==============================] - 0s 3ms/step - loss: 0.3844 - val_loss: 0.3616\n",
      "Epoch 52/52\n",
      "55/55 [==============================] - 0s 3ms/step - loss: 0.3833 - val_loss: 0.3603\n",
      "Execution time:  10.224256038665771\n",
      "DNN:\n",
      "Mean Absolute Error: 0.3785\n",
      "Root Mean Square Error: 0.3808\n",
      "Mean Square Error: 0.1450\n",
      "\n",
      "Train RMSE: 0.381\n",
      "Train MSE: 0.145\n",
      "Train MAE: 0.378\n",
      "###########################\n",
      "\n",
      "MODEL:  DNN\n",
      "sequence:  12h\n",
      "units:  87\n",
      "dropout1:  0.40519643149940265\n",
      "optimizer: adadelta\n",
      "activationDense: sigmoid\n",
      "epochs: 80\n",
      "batchsize: 31\n",
      "validation_split: 0.1\n",
      "Model: \"sequential_126\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_378 (Dense)            (None, 72, 87)            174       \n",
      "_________________________________________________________________\n",
      "dense_379 (Dense)            (None, 72, 16)            1408      \n",
      "_________________________________________________________________\n",
      "dropout_126 (Dropout)        (None, 72, 16)            0         \n",
      "_________________________________________________________________\n",
      "dense_380 (Dense)            (None, 72, 1)             17        \n",
      "=================================================================\n",
      "Total params: 1,599\n",
      "Trainable params: 1,599\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/80\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "114/114 [==============================] - 1s 5ms/step - loss: 0.0891 - val_loss: 0.1219\n",
      "Epoch 2/80\n",
      "114/114 [==============================] - 0s 3ms/step - loss: 0.0883 - val_loss: 0.1211\n",
      "Epoch 3/80\n",
      "114/114 [==============================] - 0s 3ms/step - loss: 0.0875 - val_loss: 0.1202\n",
      "Epoch 4/80\n",
      "114/114 [==============================] - 0s 3ms/step - loss: 0.0867 - val_loss: 0.1194\n",
      "Epoch 5/80\n",
      "114/114 [==============================] - 0s 3ms/step - loss: 0.0859 - val_loss: 0.1185\n",
      "Epoch 6/80\n",
      "114/114 [==============================] - 0s 4ms/step - loss: 0.0850 - val_loss: 0.1175\n",
      "Epoch 7/80\n",
      "114/114 [==============================] - 0s 4ms/step - loss: 0.0841 - val_loss: 0.1165\n",
      "Epoch 8/80\n",
      "114/114 [==============================] - 0s 4ms/step - loss: 0.0831 - val_loss: 0.1155\n",
      "Epoch 9/80\n",
      "114/114 [==============================] - 0s 4ms/step - loss: 0.0822 - val_loss: 0.1144\n",
      "Epoch 10/80\n",
      "114/114 [==============================] - 0s 4ms/step - loss: 0.0811 - val_loss: 0.1134\n",
      "Epoch 11/80\n",
      "114/114 [==============================] - 0s 3ms/step - loss: 0.0802 - val_loss: 0.1124\n",
      "Epoch 12/80\n",
      "114/114 [==============================] - 0s 3ms/step - loss: 0.0793 - val_loss: 0.1115\n",
      "Epoch 13/80\n",
      "114/114 [==============================] - 0s 3ms/step - loss: 0.0785 - val_loss: 0.1105\n",
      "Epoch 14/80\n",
      "114/114 [==============================] - 0s 3ms/step - loss: 0.0776 - val_loss: 0.1095\n",
      "Epoch 15/80\n",
      "114/114 [==============================] - 0s 3ms/step - loss: 0.0767 - val_loss: 0.1085\n",
      "Epoch 16/80\n",
      "114/114 [==============================] - 0s 3ms/step - loss: 0.0759 - val_loss: 0.1075\n",
      "Epoch 17/80\n",
      "114/114 [==============================] - 0s 3ms/step - loss: 0.0749 - val_loss: 0.1065\n",
      "Epoch 18/80\n",
      "114/114 [==============================] - 0s 3ms/step - loss: 0.0740 - val_loss: 0.1054\n",
      "Epoch 19/80\n",
      "114/114 [==============================] - 0s 3ms/step - loss: 0.0732 - val_loss: 0.1044\n",
      "Epoch 20/80\n",
      "114/114 [==============================] - 0s 3ms/step - loss: 0.0724 - val_loss: 0.1034\n",
      "Epoch 21/80\n",
      "114/114 [==============================] - 0s 3ms/step - loss: 0.0714 - val_loss: 0.1023\n",
      "Epoch 22/80\n",
      "114/114 [==============================] - 0s 3ms/step - loss: 0.0706 - val_loss: 0.1013\n",
      "Epoch 23/80\n",
      "114/114 [==============================] - 0s 3ms/step - loss: 0.0697 - val_loss: 0.1003\n",
      "Epoch 24/80\n",
      "114/114 [==============================] - 0s 3ms/step - loss: 0.0688 - val_loss: 0.0992\n",
      "Epoch 25/80\n",
      "114/114 [==============================] - 0s 3ms/step - loss: 0.0680 - val_loss: 0.0982\n",
      "Epoch 26/80\n",
      "114/114 [==============================] - 0s 3ms/step - loss: 0.0672 - val_loss: 0.0972\n",
      "Epoch 27/80\n",
      "114/114 [==============================] - 0s 3ms/step - loss: 0.0664 - val_loss: 0.0962\n",
      "Epoch 28/80\n",
      "114/114 [==============================] - 0s 3ms/step - loss: 0.0656 - val_loss: 0.0952\n",
      "Epoch 29/80\n",
      "114/114 [==============================] - 0s 3ms/step - loss: 0.0648 - val_loss: 0.0942\n",
      "Epoch 30/80\n",
      "114/114 [==============================] - 0s 3ms/step - loss: 0.0641 - val_loss: 0.0932\n",
      "Epoch 31/80\n",
      "114/114 [==============================] - 0s 3ms/step - loss: 0.0634 - val_loss: 0.0922\n",
      "Epoch 32/80\n",
      "114/114 [==============================] - 0s 3ms/step - loss: 0.0627 - val_loss: 0.0913\n",
      "Epoch 33/80\n",
      "114/114 [==============================] - 0s 3ms/step - loss: 0.0620 - val_loss: 0.0904\n",
      "Epoch 34/80\n",
      "114/114 [==============================] - 0s 4ms/step - loss: 0.0614 - val_loss: 0.0894\n",
      "Epoch 35/80\n",
      "114/114 [==============================] - 0s 3ms/step - loss: 0.0607 - val_loss: 0.0887\n",
      "Epoch 36/80\n",
      "114/114 [==============================] - 0s 3ms/step - loss: 0.0602 - val_loss: 0.0879\n",
      "Epoch 37/80\n",
      "114/114 [==============================] - 0s 3ms/step - loss: 0.0596 - val_loss: 0.0872\n",
      "Epoch 38/80\n",
      "114/114 [==============================] - 0s 3ms/step - loss: 0.0592 - val_loss: 0.0865\n",
      "Epoch 39/80\n",
      "114/114 [==============================] - 0s 3ms/step - loss: 0.0587 - val_loss: 0.0858\n",
      "Epoch 40/80\n",
      "114/114 [==============================] - 0s 3ms/step - loss: 0.0583 - val_loss: 0.0851\n",
      "Epoch 41/80\n",
      "114/114 [==============================] - 0s 3ms/step - loss: 0.0578 - val_loss: 0.0845\n",
      "Epoch 42/80\n",
      "114/114 [==============================] - 0s 3ms/step - loss: 0.0574 - val_loss: 0.0838\n",
      "Epoch 43/80\n",
      "114/114 [==============================] - 0s 3ms/step - loss: 0.0569 - val_loss: 0.0832\n",
      "Epoch 44/80\n",
      "114/114 [==============================] - 0s 3ms/step - loss: 0.0567 - val_loss: 0.0826\n",
      "Epoch 45/80\n",
      "114/114 [==============================] - 0s 3ms/step - loss: 0.0563 - val_loss: 0.0820\n",
      "Epoch 46/80\n",
      "114/114 [==============================] - 0s 4ms/step - loss: 0.0560 - val_loss: 0.0814\n",
      "Epoch 47/80\n",
      "114/114 [==============================] - 0s 4ms/step - loss: 0.0555 - val_loss: 0.0807\n",
      "Epoch 48/80\n",
      "114/114 [==============================] - 0s 4ms/step - loss: 0.0552 - val_loss: 0.0802\n",
      "Epoch 49/80\n",
      "114/114 [==============================] - 0s 4ms/step - loss: 0.0548 - val_loss: 0.0796\n",
      "Epoch 50/80\n",
      "114/114 [==============================] - 0s 4ms/step - loss: 0.0545 - val_loss: 0.0790\n",
      "Epoch 51/80\n",
      "114/114 [==============================] - 0s 4ms/step - loss: 0.0541 - val_loss: 0.0784\n",
      "Epoch 52/80\n",
      "114/114 [==============================] - 0s 3ms/step - loss: 0.0538 - val_loss: 0.0778\n",
      "Epoch 53/80\n",
      "114/114 [==============================] - 0s 3ms/step - loss: 0.0535 - val_loss: 0.0773\n",
      "Epoch 54/80\n",
      "114/114 [==============================] - 0s 3ms/step - loss: 0.0532 - val_loss: 0.0767\n",
      "Epoch 55/80\n",
      "114/114 [==============================] - 0s 3ms/step - loss: 0.0528 - val_loss: 0.0762\n",
      "Epoch 56/80\n",
      "114/114 [==============================] - 0s 4ms/step - loss: 0.0524 - val_loss: 0.0756\n",
      "Epoch 57/80\n",
      "114/114 [==============================] - 0s 3ms/step - loss: 0.0522 - val_loss: 0.0751\n",
      "Epoch 58/80\n",
      "114/114 [==============================] - 0s 4ms/step - loss: 0.0520 - val_loss: 0.0746\n",
      "Epoch 59/80\n",
      "114/114 [==============================] - 0s 3ms/step - loss: 0.0517 - val_loss: 0.0741\n",
      "Epoch 60/80\n",
      "114/114 [==============================] - 0s 3ms/step - loss: 0.0515 - val_loss: 0.0735\n",
      "Epoch 61/80\n",
      "114/114 [==============================] - 0s 3ms/step - loss: 0.0512 - val_loss: 0.0730\n",
      "Epoch 62/80\n",
      "114/114 [==============================] - 0s 3ms/step - loss: 0.0509 - val_loss: 0.0725\n",
      "Epoch 63/80\n",
      "114/114 [==============================] - 0s 3ms/step - loss: 0.0507 - val_loss: 0.0720\n",
      "Epoch 64/80\n",
      "114/114 [==============================] - 0s 4ms/step - loss: 0.0504 - val_loss: 0.0716\n",
      "Epoch 65/80\n",
      "114/114 [==============================] - 0s 3ms/step - loss: 0.0503 - val_loss: 0.0711\n",
      "Epoch 66/80\n",
      "114/114 [==============================] - 0s 3ms/step - loss: 0.0500 - val_loss: 0.0706\n",
      "Epoch 67/80\n",
      "114/114 [==============================] - 0s 3ms/step - loss: 0.0499 - val_loss: 0.0701\n",
      "Epoch 68/80\n",
      "114/114 [==============================] - 0s 3ms/step - loss: 0.0495 - val_loss: 0.0697\n",
      "Epoch 69/80\n",
      "114/114 [==============================] - 0s 3ms/step - loss: 0.0493 - val_loss: 0.0692\n",
      "Epoch 70/80\n",
      "114/114 [==============================] - 0s 3ms/step - loss: 0.0491 - val_loss: 0.0688\n",
      "Epoch 71/80\n",
      "114/114 [==============================] - 0s 3ms/step - loss: 0.0489 - val_loss: 0.0684\n",
      "Epoch 72/80\n",
      "114/114 [==============================] - 0s 3ms/step - loss: 0.0487 - val_loss: 0.0679\n",
      "Epoch 73/80\n",
      "114/114 [==============================] - 0s 3ms/step - loss: 0.0486 - val_loss: 0.0675\n",
      "Epoch 74/80\n",
      "114/114 [==============================] - 0s 3ms/step - loss: 0.0483 - val_loss: 0.0671\n",
      "Epoch 75/80\n",
      "114/114 [==============================] - 0s 3ms/step - loss: 0.0482 - val_loss: 0.0667\n",
      "Epoch 76/80\n",
      "114/114 [==============================] - 0s 3ms/step - loss: 0.0481 - val_loss: 0.0663\n",
      "Epoch 77/80\n",
      "114/114 [==============================] - 0s 3ms/step - loss: 0.0478 - val_loss: 0.0659\n",
      "Epoch 78/80\n",
      "114/114 [==============================] - 0s 3ms/step - loss: 0.0478 - val_loss: 0.0655\n",
      "Epoch 79/80\n",
      "114/114 [==============================] - 0s 3ms/step - loss: 0.0475 - val_loss: 0.0651\n",
      "Epoch 80/80\n",
      "114/114 [==============================] - 0s 3ms/step - loss: 0.0474 - val_loss: 0.0648\n",
      "Execution time:  32.76419496536255\n",
      "DNN:\n",
      "Mean Absolute Error: 0.0454\n",
      "Root Mean Square Error: 0.0539\n",
      "Mean Square Error: 0.0029\n",
      "\n",
      "Train RMSE: 0.054\n",
      "Train MSE: 0.003\n",
      "Train MAE: 0.045\n",
      "###########################\n",
      "\n",
      "MODEL:  DNN\n",
      "sequence:  12h\n",
      "units:  80\n",
      "dropout1:  0.11814836227952394\n",
      "optimizer: adadelta\n",
      "activationDense: sigmoid\n",
      "epochs: 90\n",
      "batchsize: 25\n",
      "validation_split: 0.1\n",
      "Model: \"sequential_127\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_381 (Dense)            (None, 72, 80)            160       \n",
      "_________________________________________________________________\n",
      "dense_382 (Dense)            (None, 72, 16)            1296      \n",
      "_________________________________________________________________\n",
      "dropout_127 (Dropout)        (None, 72, 16)            0         \n",
      "_________________________________________________________________\n",
      "dense_383 (Dense)            (None, 72, 1)             17        \n",
      "=================================================================\n",
      "Total params: 1,473\n",
      "Trainable params: 1,473\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/90\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "142/142 [==============================] - 1s 6ms/step - loss: 0.0777 - val_loss: 0.1106\n",
      "Epoch 2/90\n",
      "142/142 [==============================] - 0s 3ms/step - loss: 0.0769 - val_loss: 0.1097\n",
      "Epoch 3/90\n",
      "142/142 [==============================] - 0s 3ms/step - loss: 0.0761 - val_loss: 0.1088\n",
      "Epoch 4/90\n",
      "142/142 [==============================] - 0s 3ms/step - loss: 0.0752 - val_loss: 0.1077\n",
      "Epoch 5/90\n",
      "142/142 [==============================] - 0s 3ms/step - loss: 0.0742 - val_loss: 0.1067\n",
      "Epoch 6/90\n",
      "142/142 [==============================] - 0s 3ms/step - loss: 0.0732 - val_loss: 0.1055\n",
      "Epoch 7/90\n",
      "142/142 [==============================] - 0s 3ms/step - loss: 0.0722 - val_loss: 0.1043\n",
      "Epoch 8/90\n",
      "142/142 [==============================] - 0s 3ms/step - loss: 0.0711 - val_loss: 0.1031\n",
      "Epoch 9/90\n",
      "142/142 [==============================] - 0s 3ms/step - loss: 0.0700 - val_loss: 0.1019\n",
      "Epoch 10/90\n",
      "142/142 [==============================] - 0s 3ms/step - loss: 0.0689 - val_loss: 0.1006\n",
      "Epoch 11/90\n",
      "142/142 [==============================] - 0s 3ms/step - loss: 0.0678 - val_loss: 0.0993\n",
      "Epoch 12/90\n",
      "142/142 [==============================] - 0s 3ms/step - loss: 0.0667 - val_loss: 0.0980\n",
      "Epoch 13/90\n",
      "142/142 [==============================] - 0s 3ms/step - loss: 0.0656 - val_loss: 0.0966\n",
      "Epoch 14/90\n",
      "142/142 [==============================] - 0s 3ms/step - loss: 0.0645 - val_loss: 0.0953\n",
      "Epoch 15/90\n",
      "142/142 [==============================] - 0s 3ms/step - loss: 0.0634 - val_loss: 0.0939\n",
      "Epoch 16/90\n",
      "142/142 [==============================] - 0s 3ms/step - loss: 0.0622 - val_loss: 0.0925\n",
      "Epoch 17/90\n",
      "142/142 [==============================] - 0s 3ms/step - loss: 0.0611 - val_loss: 0.0911\n",
      "Epoch 18/90\n",
      "142/142 [==============================] - 0s 3ms/step - loss: 0.0600 - val_loss: 0.0898\n",
      "Epoch 19/90\n",
      "142/142 [==============================] - 0s 3ms/step - loss: 0.0589 - val_loss: 0.0884\n",
      "Epoch 20/90\n",
      "142/142 [==============================] - 0s 3ms/step - loss: 0.0579 - val_loss: 0.0870\n",
      "Epoch 21/90\n",
      "142/142 [==============================] - 0s 3ms/step - loss: 0.0569 - val_loss: 0.0857\n",
      "Epoch 22/90\n",
      "142/142 [==============================] - 0s 3ms/step - loss: 0.0558 - val_loss: 0.0843\n",
      "Epoch 23/90\n",
      "142/142 [==============================] - 0s 3ms/step - loss: 0.0549 - val_loss: 0.0830\n",
      "Epoch 24/90\n",
      "142/142 [==============================] - 0s 3ms/step - loss: 0.0540 - val_loss: 0.0818\n",
      "Epoch 25/90\n",
      "142/142 [==============================] - 0s 3ms/step - loss: 0.0531 - val_loss: 0.0805\n",
      "Epoch 26/90\n",
      "142/142 [==============================] - 0s 3ms/step - loss: 0.0522 - val_loss: 0.0793\n",
      "Epoch 27/90\n",
      "142/142 [==============================] - 0s 3ms/step - loss: 0.0514 - val_loss: 0.0781\n",
      "Epoch 28/90\n",
      "142/142 [==============================] - 0s 3ms/step - loss: 0.0506 - val_loss: 0.0769\n",
      "Epoch 29/90\n",
      "142/142 [==============================] - 0s 3ms/step - loss: 0.0499 - val_loss: 0.0757\n",
      "Epoch 30/90\n",
      "142/142 [==============================] - 0s 3ms/step - loss: 0.0491 - val_loss: 0.0746\n",
      "Epoch 31/90\n",
      "142/142 [==============================] - 0s 3ms/step - loss: 0.0484 - val_loss: 0.0734\n",
      "Epoch 32/90\n",
      "142/142 [==============================] - 0s 3ms/step - loss: 0.0477 - val_loss: 0.0724\n",
      "Epoch 33/90\n",
      "142/142 [==============================] - 0s 3ms/step - loss: 0.0471 - val_loss: 0.0713\n",
      "Epoch 34/90\n",
      "142/142 [==============================] - 0s 3ms/step - loss: 0.0465 - val_loss: 0.0702\n",
      "Epoch 35/90\n",
      "142/142 [==============================] - 0s 3ms/step - loss: 0.0459 - val_loss: 0.0691\n",
      "Epoch 36/90\n",
      "142/142 [==============================] - 0s 3ms/step - loss: 0.0453 - val_loss: 0.0681\n",
      "Epoch 37/90\n",
      "142/142 [==============================] - 0s 3ms/step - loss: 0.0447 - val_loss: 0.0671\n",
      "Epoch 38/90\n",
      "142/142 [==============================] - 0s 3ms/step - loss: 0.0442 - val_loss: 0.0661\n",
      "Epoch 39/90\n",
      "142/142 [==============================] - 0s 3ms/step - loss: 0.0436 - val_loss: 0.0651\n",
      "Epoch 40/90\n",
      "142/142 [==============================] - 0s 3ms/step - loss: 0.0431 - val_loss: 0.0641\n",
      "Epoch 41/90\n",
      "142/142 [==============================] - 0s 3ms/step - loss: 0.0426 - val_loss: 0.0631\n",
      "Epoch 42/90\n",
      "142/142 [==============================] - 0s 3ms/step - loss: 0.0422 - val_loss: 0.0621\n",
      "Epoch 43/90\n",
      "142/142 [==============================] - 0s 3ms/step - loss: 0.0416 - val_loss: 0.0612\n",
      "Epoch 44/90\n",
      "142/142 [==============================] - 0s 3ms/step - loss: 0.0412 - val_loss: 0.0603\n",
      "Epoch 45/90\n",
      "142/142 [==============================] - 0s 3ms/step - loss: 0.0407 - val_loss: 0.0593\n",
      "Epoch 46/90\n",
      "142/142 [==============================] - 0s 3ms/step - loss: 0.0403 - val_loss: 0.0584\n",
      "Epoch 47/90\n",
      "142/142 [==============================] - 0s 3ms/step - loss: 0.0398 - val_loss: 0.0575\n",
      "Epoch 48/90\n",
      "142/142 [==============================] - 0s 3ms/step - loss: 0.0395 - val_loss: 0.0566\n",
      "Epoch 49/90\n",
      "142/142 [==============================] - 0s 3ms/step - loss: 0.0391 - val_loss: 0.0557\n",
      "Epoch 50/90\n",
      "142/142 [==============================] - 0s 3ms/step - loss: 0.0388 - val_loss: 0.0549\n",
      "Epoch 51/90\n",
      "142/142 [==============================] - 0s 3ms/step - loss: 0.0384 - val_loss: 0.0540\n",
      "Epoch 52/90\n",
      "142/142 [==============================] - 0s 3ms/step - loss: 0.0380 - val_loss: 0.0532\n",
      "Epoch 53/90\n",
      "142/142 [==============================] - 0s 3ms/step - loss: 0.0377 - val_loss: 0.0524\n",
      "Epoch 54/90\n",
      "142/142 [==============================] - 0s 3ms/step - loss: 0.0374 - val_loss: 0.0516\n",
      "Epoch 55/90\n",
      "142/142 [==============================] - 0s 3ms/step - loss: 0.0370 - val_loss: 0.0508\n",
      "Epoch 56/90\n",
      "142/142 [==============================] - 0s 3ms/step - loss: 0.0368 - val_loss: 0.0500\n",
      "Epoch 57/90\n",
      "142/142 [==============================] - 0s 3ms/step - loss: 0.0364 - val_loss: 0.0493\n",
      "Epoch 58/90\n",
      "142/142 [==============================] - 0s 3ms/step - loss: 0.0362 - val_loss: 0.0485\n",
      "Epoch 59/90\n",
      "142/142 [==============================] - 0s 3ms/step - loss: 0.0359 - val_loss: 0.0478\n",
      "Epoch 60/90\n",
      "142/142 [==============================] - 0s 3ms/step - loss: 0.0357 - val_loss: 0.0471\n",
      "Epoch 61/90\n",
      "142/142 [==============================] - 0s 3ms/step - loss: 0.0354 - val_loss: 0.0464\n",
      "Epoch 62/90\n",
      "142/142 [==============================] - 0s 3ms/step - loss: 0.0352 - val_loss: 0.0458\n",
      "Epoch 63/90\n",
      "142/142 [==============================] - 0s 3ms/step - loss: 0.0350 - val_loss: 0.0451\n",
      "Epoch 64/90\n",
      "142/142 [==============================] - 0s 3ms/step - loss: 0.0348 - val_loss: 0.0445\n",
      "Epoch 65/90\n",
      "142/142 [==============================] - 0s 3ms/step - loss: 0.0347 - val_loss: 0.0439\n",
      "Epoch 66/90\n",
      "142/142 [==============================] - 0s 3ms/step - loss: 0.0346 - val_loss: 0.0433\n",
      "Epoch 67/90\n",
      "142/142 [==============================] - 0s 3ms/step - loss: 0.0344 - val_loss: 0.0428\n",
      "Epoch 68/90\n",
      "142/142 [==============================] - 0s 3ms/step - loss: 0.0342 - val_loss: 0.0423\n",
      "Epoch 69/90\n",
      "142/142 [==============================] - 0s 3ms/step - loss: 0.0340 - val_loss: 0.0418\n",
      "Epoch 70/90\n",
      "142/142 [==============================] - 0s 3ms/step - loss: 0.0339 - val_loss: 0.0413\n",
      "Epoch 71/90\n",
      "142/142 [==============================] - 0s 3ms/step - loss: 0.0338 - val_loss: 0.0408\n",
      "Epoch 72/90\n",
      "142/142 [==============================] - 0s 3ms/step - loss: 0.0337 - val_loss: 0.0404\n",
      "Epoch 73/90\n",
      "142/142 [==============================] - 0s 3ms/step - loss: 0.0336 - val_loss: 0.0399\n",
      "Epoch 74/90\n",
      "142/142 [==============================] - 0s 3ms/step - loss: 0.0335 - val_loss: 0.0395\n",
      "Epoch 75/90\n",
      "142/142 [==============================] - 0s 3ms/step - loss: 0.0334 - val_loss: 0.0391\n",
      "Epoch 76/90\n",
      "142/142 [==============================] - 0s 3ms/step - loss: 0.0334 - val_loss: 0.0388\n",
      "Epoch 77/90\n",
      "142/142 [==============================] - 0s 3ms/step - loss: 0.0333 - val_loss: 0.0384\n",
      "Epoch 78/90\n",
      "142/142 [==============================] - 0s 3ms/step - loss: 0.0332 - val_loss: 0.0381\n",
      "Epoch 79/90\n",
      "142/142 [==============================] - 0s 3ms/step - loss: 0.0332 - val_loss: 0.0377\n",
      "Epoch 80/90\n",
      "142/142 [==============================] - 0s 3ms/step - loss: 0.0331 - val_loss: 0.0374\n",
      "Epoch 81/90\n",
      "142/142 [==============================] - 0s 3ms/step - loss: 0.0330 - val_loss: 0.0371\n",
      "Epoch 82/90\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "142/142 [==============================] - 0s 3ms/step - loss: 0.0330 - val_loss: 0.0368\n",
      "Epoch 83/90\n",
      "142/142 [==============================] - 0s 3ms/step - loss: 0.0329 - val_loss: 0.0366\n",
      "Epoch 84/90\n",
      "142/142 [==============================] - 0s 3ms/step - loss: 0.0329 - val_loss: 0.0363\n",
      "Epoch 85/90\n",
      "142/142 [==============================] - 0s 3ms/step - loss: 0.0329 - val_loss: 0.0360\n",
      "Epoch 86/90\n",
      "142/142 [==============================] - 0s 3ms/step - loss: 0.0328 - val_loss: 0.0358\n",
      "Epoch 87/90\n",
      "142/142 [==============================] - 0s 3ms/step - loss: 0.0328 - val_loss: 0.0356\n",
      "Epoch 88/90\n",
      "142/142 [==============================] - 0s 3ms/step - loss: 0.0328 - val_loss: 0.0354\n",
      "Epoch 89/90\n",
      "142/142 [==============================] - 0s 3ms/step - loss: 0.0328 - val_loss: 0.0352\n",
      "Epoch 90/90\n",
      "142/142 [==============================] - 0s 3ms/step - loss: 0.0327 - val_loss: 0.0350\n",
      "Execution time:  39.81482410430908\n",
      "DNN:\n",
      "Mean Absolute Error: 0.0325\n",
      "Root Mean Square Error: 0.0471\n",
      "Mean Square Error: 0.0022\n",
      "\n",
      "Train RMSE: 0.047\n",
      "Train MSE: 0.002\n",
      "Train MAE: 0.032\n",
      "###########################\n",
      "\n",
      "MODEL:  DNN\n",
      "sequence:  12h\n",
      "units:  12\n",
      "dropout1:  0.48476373451509647\n",
      "optimizer: adadelta\n",
      "activationDense: sigmoid\n",
      "epochs: 52\n",
      "batchsize: 57\n",
      "validation_split: 0.1\n",
      "Model: \"sequential_128\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_384 (Dense)            (None, 72, 12)            24        \n",
      "_________________________________________________________________\n",
      "dense_385 (Dense)            (None, 72, 16)            208       \n",
      "_________________________________________________________________\n",
      "dropout_128 (Dropout)        (None, 72, 16)            0         \n",
      "_________________________________________________________________\n",
      "dense_386 (Dense)            (None, 72, 1)             17        \n",
      "=================================================================\n",
      "Total params: 249\n",
      "Trainable params: 249\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/52\n",
      "62/62 [==============================] - 0s 6ms/step - loss: 0.1020 - val_loss: 0.1350\n",
      "Epoch 2/52\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.1019 - val_loss: 0.1349\n",
      "Epoch 3/52\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.1018 - val_loss: 0.1347\n",
      "Epoch 4/52\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.1017 - val_loss: 0.1346\n",
      "Epoch 5/52\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.1016 - val_loss: 0.1345\n",
      "Epoch 6/52\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.1015 - val_loss: 0.1344\n",
      "Epoch 7/52\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.1013 - val_loss: 0.1342\n",
      "Epoch 8/52\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.1012 - val_loss: 0.1341\n",
      "Epoch 9/52\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.1011 - val_loss: 0.1340\n",
      "Epoch 10/52\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.1009 - val_loss: 0.1338\n",
      "Epoch 11/52\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.1008 - val_loss: 0.1337\n",
      "Epoch 12/52\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.1007 - val_loss: 0.1335\n",
      "Epoch 13/52\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.1005 - val_loss: 0.1333\n",
      "Epoch 14/52\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.1003 - val_loss: 0.1332\n",
      "Epoch 15/52\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.1002 - val_loss: 0.1330\n",
      "Epoch 16/52\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.1000 - val_loss: 0.1328\n",
      "Epoch 17/52\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.0998 - val_loss: 0.1327\n",
      "Epoch 18/52\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.0996 - val_loss: 0.1325\n",
      "Epoch 19/52\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.0995 - val_loss: 0.1323\n",
      "Epoch 20/52\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.0993 - val_loss: 0.1321\n",
      "Epoch 21/52\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.0992 - val_loss: 0.1320\n",
      "Epoch 22/52\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.0990 - val_loss: 0.1318\n",
      "Epoch 23/52\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.0988 - val_loss: 0.1316\n",
      "Epoch 24/52\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.0986 - val_loss: 0.1314\n",
      "Epoch 25/52\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.0984 - val_loss: 0.1312\n",
      "Epoch 26/52\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.0982 - val_loss: 0.1310\n",
      "Epoch 27/52\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.0980 - val_loss: 0.1308\n",
      "Epoch 28/52\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.0978 - val_loss: 0.1306\n",
      "Epoch 29/52\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.0976 - val_loss: 0.1304\n",
      "Epoch 30/52\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.0974 - val_loss: 0.1302\n",
      "Epoch 31/52\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.0972 - val_loss: 0.1299\n",
      "Epoch 32/52\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.0970 - val_loss: 0.1297\n",
      "Epoch 33/52\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.0968 - val_loss: 0.1295\n",
      "Epoch 34/52\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.0965 - val_loss: 0.1293\n",
      "Epoch 35/52\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.0963 - val_loss: 0.1291\n",
      "Epoch 36/52\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.0961 - val_loss: 0.1288\n",
      "Epoch 37/52\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.0959 - val_loss: 0.1286\n",
      "Epoch 38/52\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.0957 - val_loss: 0.1283\n",
      "Epoch 39/52\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.0954 - val_loss: 0.1280\n",
      "Epoch 40/52\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.0951 - val_loss: 0.1277\n",
      "Epoch 41/52\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.0947 - val_loss: 0.1274\n",
      "Epoch 42/52\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.0945 - val_loss: 0.1271\n",
      "Epoch 43/52\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.0942 - val_loss: 0.1268\n",
      "Epoch 44/52\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.0939 - val_loss: 0.1265\n",
      "Epoch 45/52\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.0936 - val_loss: 0.1262\n",
      "Epoch 46/52\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.0933 - val_loss: 0.1259\n",
      "Epoch 47/52\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.0930 - val_loss: 0.1256\n",
      "Epoch 48/52\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.0927 - val_loss: 0.1253\n",
      "Epoch 49/52\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.0924 - val_loss: 0.1250\n",
      "Epoch 50/52\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.0921 - val_loss: 0.1246\n",
      "Epoch 51/52\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.0918 - val_loss: 0.1243\n",
      "Epoch 52/52\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.0915 - val_loss: 0.1240\n",
      "Execution time:  12.301923751831055\n",
      "DNN:\n",
      "Mean Absolute Error: 0.0938\n",
      "Root Mean Square Error: 0.1003\n",
      "Mean Square Error: 0.0101\n",
      "\n",
      "Train RMSE: 0.100\n",
      "Train MSE: 0.010\n",
      "Train MAE: 0.094\n",
      "###########################\n",
      "\n",
      "MODEL:  DNN\n",
      "sequence:  12h\n",
      "units:  87\n",
      "dropout1:  0.40519643149940265\n",
      "optimizer: adadelta\n",
      "activationDense: sigmoid\n",
      "epochs: 80\n",
      "batchsize: 31\n",
      "validation_split: 0.2\n",
      "Model: \"sequential_129\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_387 (Dense)            (None, 72, 87)            174       \n",
      "_________________________________________________________________\n",
      "dense_388 (Dense)            (None, 72, 16)            1408      \n",
      "_________________________________________________________________\n",
      "dropout_129 (Dropout)        (None, 72, 16)            0         \n",
      "_________________________________________________________________\n",
      "dense_389 (Dense)            (None, 72, 1)             17        \n",
      "=================================================================\n",
      "Total params: 1,599\n",
      "Trainable params: 1,599\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/80\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "102/102 [==============================] - 1s 5ms/step - loss: 0.1077 - val_loss: 0.1270\n",
      "Epoch 2/80\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.1072 - val_loss: 0.1265\n",
      "Epoch 3/80\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.1065 - val_loss: 0.1259\n",
      "Epoch 4/80\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.1059 - val_loss: 0.1252\n",
      "Epoch 5/80\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.1053 - val_loss: 0.1246\n",
      "Epoch 6/80\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.1045 - val_loss: 0.1239\n",
      "Epoch 7/80\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.1038 - val_loss: 0.1232\n",
      "Epoch 8/80\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.1030 - val_loss: 0.1224\n",
      "Epoch 9/80\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.1022 - val_loss: 0.1217\n",
      "Epoch 10/80\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.1015 - val_loss: 0.1209\n",
      "Epoch 11/80\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.1006 - val_loss: 0.1200\n",
      "Epoch 12/80\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.0998 - val_loss: 0.1192\n",
      "Epoch 13/80\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.0989 - val_loss: 0.1183\n",
      "Epoch 14/80\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.0980 - val_loss: 0.1175\n",
      "Epoch 15/80\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.0971 - val_loss: 0.1166\n",
      "Epoch 16/80\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.0961 - val_loss: 0.1157\n",
      "Epoch 17/80\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.0953 - val_loss: 0.1150\n",
      "Epoch 18/80\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.0945 - val_loss: 0.1141\n",
      "Epoch 19/80\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.0934 - val_loss: 0.1130\n",
      "Epoch 20/80\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.0923 - val_loss: 0.1120\n",
      "Epoch 21/80\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.0912 - val_loss: 0.1109\n",
      "Epoch 22/80\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.0902 - val_loss: 0.1098\n",
      "Epoch 23/80\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.0891 - val_loss: 0.1088\n",
      "Epoch 24/80\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.0879 - val_loss: 0.1077\n",
      "Epoch 25/80\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.0868 - val_loss: 0.1066\n",
      "Epoch 26/80\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.0857 - val_loss: 0.1055\n",
      "Epoch 27/80\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.0846 - val_loss: 0.1045\n",
      "Epoch 28/80\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.0835 - val_loss: 0.1034\n",
      "Epoch 29/80\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.0824 - val_loss: 0.1023\n",
      "Epoch 30/80\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.0814 - val_loss: 0.1012\n",
      "Epoch 31/80\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.0803 - val_loss: 0.1001\n",
      "Epoch 32/80\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.0793 - val_loss: 0.0991\n",
      "Epoch 33/80\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.0782 - val_loss: 0.0980\n",
      "Epoch 34/80\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.0771 - val_loss: 0.0969\n",
      "Epoch 35/80\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.0761 - val_loss: 0.0958\n",
      "Epoch 36/80\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.0750 - val_loss: 0.0948\n",
      "Epoch 37/80\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.0740 - val_loss: 0.0937\n",
      "Epoch 38/80\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.0729 - val_loss: 0.0927\n",
      "Epoch 39/80\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.0719 - val_loss: 0.0917\n",
      "Epoch 40/80\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.0711 - val_loss: 0.0908\n",
      "Epoch 41/80\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.0702 - val_loss: 0.0900\n",
      "Epoch 42/80\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.0695 - val_loss: 0.0893\n",
      "Epoch 43/80\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.0687 - val_loss: 0.0885\n",
      "Epoch 44/80\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.0680 - val_loss: 0.0878\n",
      "Epoch 45/80\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.0674 - val_loss: 0.0870\n",
      "Epoch 46/80\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.0667 - val_loss: 0.0863\n",
      "Epoch 47/80\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.0661 - val_loss: 0.0856\n",
      "Epoch 48/80\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.0654 - val_loss: 0.0848\n",
      "Epoch 49/80\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.0648 - val_loss: 0.0841\n",
      "Epoch 50/80\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.0642 - val_loss: 0.0834\n",
      "Epoch 51/80\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.0635 - val_loss: 0.0827\n",
      "Epoch 52/80\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.0629 - val_loss: 0.0821\n",
      "Epoch 53/80\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.0624 - val_loss: 0.0814\n",
      "Epoch 54/80\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.0619 - val_loss: 0.0807\n",
      "Epoch 55/80\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.0614 - val_loss: 0.0801\n",
      "Epoch 56/80\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.0609 - val_loss: 0.0794\n",
      "Epoch 57/80\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.0603 - val_loss: 0.0788\n",
      "Epoch 58/80\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.0599 - val_loss: 0.0782\n",
      "Epoch 59/80\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.0593 - val_loss: 0.0776\n",
      "Epoch 60/80\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.0589 - val_loss: 0.0770\n",
      "Epoch 61/80\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.0584 - val_loss: 0.0764\n",
      "Epoch 62/80\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.0580 - val_loss: 0.0758\n",
      "Epoch 63/80\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.0577 - val_loss: 0.0752\n",
      "Epoch 64/80\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.0572 - val_loss: 0.0747\n",
      "Epoch 65/80\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.0568 - val_loss: 0.0741\n",
      "Epoch 66/80\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.0564 - val_loss: 0.0736\n",
      "Epoch 67/80\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.0560 - val_loss: 0.0731\n",
      "Epoch 68/80\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.0556 - val_loss: 0.0725\n",
      "Epoch 69/80\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.0553 - val_loss: 0.0720\n",
      "Epoch 70/80\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.0549 - val_loss: 0.0715\n",
      "Epoch 71/80\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.0545 - val_loss: 0.0710\n",
      "Epoch 72/80\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.0542 - val_loss: 0.0705\n",
      "Epoch 73/80\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.0539 - val_loss: 0.0701\n",
      "Epoch 74/80\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.0536 - val_loss: 0.0696\n",
      "Epoch 75/80\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.0532 - val_loss: 0.0691\n",
      "Epoch 76/80\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.0530 - val_loss: 0.0687\n",
      "Epoch 77/80\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.0527 - val_loss: 0.0682\n",
      "Epoch 78/80\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.0524 - val_loss: 0.0678\n",
      "Epoch 79/80\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.0521 - val_loss: 0.0673\n",
      "Epoch 80/80\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.0519 - val_loss: 0.0669\n",
      "Execution time:  31.24636197090149\n",
      "DNN:\n",
      "Mean Absolute Error: 0.0527\n",
      "Root Mean Square Error: 0.0608\n",
      "Mean Square Error: 0.0037\n",
      "\n",
      "Train RMSE: 0.061\n",
      "Train MSE: 0.004\n",
      "Train MAE: 0.053\n",
      "###########################\n",
      "\n",
      "MODEL:  DNN\n",
      "sequence:  12h\n",
      "units:  80\n",
      "dropout1:  0.11814836227952394\n",
      "optimizer: adadelta\n",
      "activationDense: sigmoid\n",
      "epochs: 90\n",
      "batchsize: 25\n",
      "validation_split: 0.2\n",
      "Model: \"sequential_130\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_390 (Dense)            (None, 72, 80)            160       \n",
      "_________________________________________________________________\n",
      "dense_391 (Dense)            (None, 72, 16)            1296      \n",
      "_________________________________________________________________\n",
      "dropout_130 (Dropout)        (None, 72, 16)            0         \n",
      "_________________________________________________________________\n",
      "dense_392 (Dense)            (None, 72, 1)             17        \n",
      "=================================================================\n",
      "Total params: 1,473\n",
      "Trainable params: 1,473\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/90\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "126/126 [==============================] - 1s 4ms/step - loss: 0.1154 - val_loss: 0.1342\n",
      "Epoch 2/90\n",
      "126/126 [==============================] - 0s 3ms/step - loss: 0.1147 - val_loss: 0.1334\n",
      "Epoch 3/90\n",
      "126/126 [==============================] - 0s 3ms/step - loss: 0.1139 - val_loss: 0.1326\n",
      "Epoch 4/90\n",
      "126/126 [==============================] - 0s 3ms/step - loss: 0.1130 - val_loss: 0.1317\n",
      "Epoch 5/90\n",
      "126/126 [==============================] - 0s 3ms/step - loss: 0.1121 - val_loss: 0.1308\n",
      "Epoch 6/90\n",
      "126/126 [==============================] - 0s 3ms/step - loss: 0.1110 - val_loss: 0.1298\n",
      "Epoch 7/90\n",
      "126/126 [==============================] - 0s 3ms/step - loss: 0.1100 - val_loss: 0.1288\n",
      "Epoch 8/90\n",
      "126/126 [==============================] - 0s 3ms/step - loss: 0.1089 - val_loss: 0.1277\n",
      "Epoch 9/90\n",
      "126/126 [==============================] - 0s 3ms/step - loss: 0.1077 - val_loss: 0.1266\n",
      "Epoch 10/90\n",
      "126/126 [==============================] - 0s 3ms/step - loss: 0.1066 - val_loss: 0.1255\n",
      "Epoch 11/90\n",
      "126/126 [==============================] - 0s 3ms/step - loss: 0.1054 - val_loss: 0.1244\n",
      "Epoch 12/90\n",
      "126/126 [==============================] - 0s 3ms/step - loss: 0.1043 - val_loss: 0.1232\n",
      "Epoch 13/90\n",
      "126/126 [==============================] - 0s 3ms/step - loss: 0.1031 - val_loss: 0.1222\n",
      "Epoch 14/90\n",
      "126/126 [==============================] - 0s 3ms/step - loss: 0.1021 - val_loss: 0.1214\n",
      "Epoch 15/90\n",
      "126/126 [==============================] - 0s 3ms/step - loss: 0.1013 - val_loss: 0.1206\n",
      "Epoch 16/90\n",
      "126/126 [==============================] - 0s 3ms/step - loss: 0.1004 - val_loss: 0.1198\n",
      "Epoch 17/90\n",
      "126/126 [==============================] - 0s 3ms/step - loss: 0.0995 - val_loss: 0.1189\n",
      "Epoch 18/90\n",
      "126/126 [==============================] - 0s 3ms/step - loss: 0.0986 - val_loss: 0.1181\n",
      "Epoch 19/90\n",
      "126/126 [==============================] - 0s 3ms/step - loss: 0.0978 - val_loss: 0.1172\n",
      "Epoch 20/90\n",
      "126/126 [==============================] - 0s 3ms/step - loss: 0.0969 - val_loss: 0.1164\n",
      "Epoch 21/90\n",
      "126/126 [==============================] - 0s 3ms/step - loss: 0.0959 - val_loss: 0.1155\n",
      "Epoch 22/90\n",
      "126/126 [==============================] - 0s 3ms/step - loss: 0.0950 - val_loss: 0.1146\n",
      "Epoch 23/90\n",
      "126/126 [==============================] - 0s 3ms/step - loss: 0.0941 - val_loss: 0.1137\n",
      "Epoch 24/90\n",
      "126/126 [==============================] - 0s 3ms/step - loss: 0.0931 - val_loss: 0.1127\n",
      "Epoch 25/90\n",
      "126/126 [==============================] - 0s 3ms/step - loss: 0.0922 - val_loss: 0.1118\n",
      "Epoch 26/90\n",
      "126/126 [==============================] - 0s 3ms/step - loss: 0.0912 - val_loss: 0.1108\n",
      "Epoch 27/90\n",
      "126/126 [==============================] - 0s 3ms/step - loss: 0.0902 - val_loss: 0.1099\n",
      "Epoch 28/90\n",
      "126/126 [==============================] - 0s 3ms/step - loss: 0.0891 - val_loss: 0.1086\n",
      "Epoch 29/90\n",
      "126/126 [==============================] - 0s 3ms/step - loss: 0.0877 - val_loss: 0.1072\n",
      "Epoch 30/90\n",
      "126/126 [==============================] - 0s 3ms/step - loss: 0.0863 - val_loss: 0.1059\n",
      "Epoch 31/90\n",
      "126/126 [==============================] - 0s 3ms/step - loss: 0.0850 - val_loss: 0.1046\n",
      "Epoch 32/90\n",
      "126/126 [==============================] - 0s 3ms/step - loss: 0.0836 - val_loss: 0.1032\n",
      "Epoch 33/90\n",
      "126/126 [==============================] - 0s 3ms/step - loss: 0.0822 - val_loss: 0.1019\n",
      "Epoch 34/90\n",
      "126/126 [==============================] - 0s 4ms/step - loss: 0.0809 - val_loss: 0.1005\n",
      "Epoch 35/90\n",
      "126/126 [==============================] - 0s 3ms/step - loss: 0.0795 - val_loss: 0.0992\n",
      "Epoch 36/90\n",
      "126/126 [==============================] - 0s 3ms/step - loss: 0.0781 - val_loss: 0.0977\n",
      "Epoch 37/90\n",
      "126/126 [==============================] - 0s 3ms/step - loss: 0.0765 - val_loss: 0.0959\n",
      "Epoch 38/90\n",
      "126/126 [==============================] - 0s 3ms/step - loss: 0.0748 - val_loss: 0.0942\n",
      "Epoch 39/90\n",
      "126/126 [==============================] - 0s 3ms/step - loss: 0.0730 - val_loss: 0.0924\n",
      "Epoch 40/90\n",
      "126/126 [==============================] - 0s 3ms/step - loss: 0.0713 - val_loss: 0.0907\n",
      "Epoch 41/90\n",
      "126/126 [==============================] - 0s 3ms/step - loss: 0.0697 - val_loss: 0.0890\n",
      "Epoch 42/90\n",
      "126/126 [==============================] - 0s 3ms/step - loss: 0.0680 - val_loss: 0.0873\n",
      "Epoch 43/90\n",
      "126/126 [==============================] - 0s 3ms/step - loss: 0.0664 - val_loss: 0.0856\n",
      "Epoch 44/90\n",
      "126/126 [==============================] - 0s 3ms/step - loss: 0.0648 - val_loss: 0.0840\n",
      "Epoch 45/90\n",
      "126/126 [==============================] - 0s 3ms/step - loss: 0.0632 - val_loss: 0.0823\n",
      "Epoch 46/90\n",
      "126/126 [==============================] - 0s 3ms/step - loss: 0.0618 - val_loss: 0.0807\n",
      "Epoch 47/90\n",
      "126/126 [==============================] - 0s 3ms/step - loss: 0.0604 - val_loss: 0.0792\n",
      "Epoch 48/90\n",
      "126/126 [==============================] - 0s 3ms/step - loss: 0.0590 - val_loss: 0.0777\n",
      "Epoch 49/90\n",
      "126/126 [==============================] - 0s 3ms/step - loss: 0.0577 - val_loss: 0.0762\n",
      "Epoch 50/90\n",
      "126/126 [==============================] - 0s 3ms/step - loss: 0.0565 - val_loss: 0.0748\n",
      "Epoch 51/90\n",
      "126/126 [==============================] - 0s 3ms/step - loss: 0.0552 - val_loss: 0.0733\n",
      "Epoch 52/90\n",
      "126/126 [==============================] - 0s 3ms/step - loss: 0.0541 - val_loss: 0.0720\n",
      "Epoch 53/90\n",
      "126/126 [==============================] - ETA: 0s - loss: 0.051 - 0s 3ms/step - loss: 0.0531 - val_loss: 0.0707\n",
      "Epoch 54/90\n",
      "126/126 [==============================] - 0s 3ms/step - loss: 0.0520 - val_loss: 0.0695\n",
      "Epoch 55/90\n",
      "126/126 [==============================] - 0s 3ms/step - loss: 0.0511 - val_loss: 0.0683\n",
      "Epoch 56/90\n",
      "126/126 [==============================] - 0s 3ms/step - loss: 0.0503 - val_loss: 0.0671\n",
      "Epoch 57/90\n",
      "126/126 [==============================] - 0s 3ms/step - loss: 0.0494 - val_loss: 0.0660\n",
      "Epoch 58/90\n",
      "126/126 [==============================] - 0s 3ms/step - loss: 0.0486 - val_loss: 0.0649\n",
      "Epoch 59/90\n",
      "126/126 [==============================] - 0s 3ms/step - loss: 0.0478 - val_loss: 0.0639\n",
      "Epoch 60/90\n",
      "126/126 [==============================] - 0s 3ms/step - loss: 0.0471 - val_loss: 0.0629\n",
      "Epoch 61/90\n",
      "126/126 [==============================] - 0s 3ms/step - loss: 0.0465 - val_loss: 0.0619\n",
      "Epoch 62/90\n",
      "126/126 [==============================] - 0s 3ms/step - loss: 0.0458 - val_loss: 0.0610\n",
      "Epoch 63/90\n",
      "126/126 [==============================] - 0s 3ms/step - loss: 0.0453 - val_loss: 0.0601\n",
      "Epoch 64/90\n",
      "126/126 [==============================] - 0s 3ms/step - loss: 0.0447 - val_loss: 0.0593\n",
      "Epoch 65/90\n",
      "126/126 [==============================] - 0s 3ms/step - loss: 0.0442 - val_loss: 0.0585\n",
      "Epoch 66/90\n",
      "126/126 [==============================] - 0s 3ms/step - loss: 0.0437 - val_loss: 0.0577\n",
      "Epoch 67/90\n",
      "126/126 [==============================] - 0s 3ms/step - loss: 0.0432 - val_loss: 0.0569\n",
      "Epoch 68/90\n",
      "126/126 [==============================] - 0s 3ms/step - loss: 0.0428 - val_loss: 0.0561\n",
      "Epoch 69/90\n",
      "126/126 [==============================] - 0s 3ms/step - loss: 0.0423 - val_loss: 0.0554\n",
      "Epoch 70/90\n",
      "126/126 [==============================] - 0s 3ms/step - loss: 0.0419 - val_loss: 0.0546\n",
      "Epoch 71/90\n",
      "126/126 [==============================] - 0s 3ms/step - loss: 0.0415 - val_loss: 0.0539\n",
      "Epoch 72/90\n",
      "126/126 [==============================] - 0s 3ms/step - loss: 0.0411 - val_loss: 0.0532\n",
      "Epoch 73/90\n",
      "126/126 [==============================] - 0s 3ms/step - loss: 0.0407 - val_loss: 0.0525\n",
      "Epoch 74/90\n",
      "126/126 [==============================] - 0s 3ms/step - loss: 0.0403 - val_loss: 0.0518\n",
      "Epoch 75/90\n",
      "126/126 [==============================] - 0s 3ms/step - loss: 0.0400 - val_loss: 0.0512\n",
      "Epoch 76/90\n",
      "126/126 [==============================] - 0s 3ms/step - loss: 0.0397 - val_loss: 0.0505\n",
      "Epoch 77/90\n",
      "126/126 [==============================] - 0s 3ms/step - loss: 0.0394 - val_loss: 0.0499\n",
      "Epoch 78/90\n",
      "126/126 [==============================] - 0s 3ms/step - loss: 0.0390 - val_loss: 0.0493\n",
      "Epoch 79/90\n",
      "126/126 [==============================] - 0s 3ms/step - loss: 0.0387 - val_loss: 0.0487\n",
      "Epoch 80/90\n",
      "126/126 [==============================] - 0s 3ms/step - loss: 0.0384 - val_loss: 0.0481\n",
      "Epoch 81/90\n",
      "126/126 [==============================] - 0s 3ms/step - loss: 0.0381 - val_loss: 0.0475\n",
      "Epoch 82/90\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "126/126 [==============================] - 0s 3ms/step - loss: 0.0378 - val_loss: 0.0469\n",
      "Epoch 83/90\n",
      "126/126 [==============================] - 0s 3ms/step - loss: 0.0375 - val_loss: 0.0464\n",
      "Epoch 84/90\n",
      "126/126 [==============================] - 0s 3ms/step - loss: 0.0373 - val_loss: 0.0459\n",
      "Epoch 85/90\n",
      "126/126 [==============================] - 0s 3ms/step - loss: 0.0371 - val_loss: 0.0453\n",
      "Epoch 86/90\n",
      "126/126 [==============================] - 0s 3ms/step - loss: 0.0369 - val_loss: 0.0449\n",
      "Epoch 87/90\n",
      "126/126 [==============================] - 0s 3ms/step - loss: 0.0366 - val_loss: 0.0444\n",
      "Epoch 88/90\n",
      "126/126 [==============================] - 0s 3ms/step - loss: 0.0365 - val_loss: 0.0439\n",
      "Epoch 89/90\n",
      "126/126 [==============================] - 0s 3ms/step - loss: 0.0363 - val_loss: 0.0435\n",
      "Epoch 90/90\n",
      "126/126 [==============================] - 0s 3ms/step - loss: 0.0361 - val_loss: 0.0431\n",
      "Execution time:  37.128817558288574\n",
      "DNN:\n",
      "Mean Absolute Error: 0.0373\n",
      "Root Mean Square Error: 0.0466\n",
      "Mean Square Error: 0.0022\n",
      "\n",
      "Train RMSE: 0.047\n",
      "Train MSE: 0.002\n",
      "Train MAE: 0.037\n",
      "###########################\n",
      "\n",
      "MODEL:  DNN\n",
      "sequence:  12h\n",
      "units:  12\n",
      "dropout1:  0.48476373451509647\n",
      "optimizer: adadelta\n",
      "activationDense: sigmoid\n",
      "epochs: 52\n",
      "batchsize: 57\n",
      "validation_split: 0.2\n",
      "Model: \"sequential_131\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_393 (Dense)            (None, 72, 12)            24        \n",
      "_________________________________________________________________\n",
      "dense_394 (Dense)            (None, 72, 16)            208       \n",
      "_________________________________________________________________\n",
      "dropout_131 (Dropout)        (None, 72, 16)            0         \n",
      "_________________________________________________________________\n",
      "dense_395 (Dense)            (None, 72, 1)             17        \n",
      "=================================================================\n",
      "Total params: 249\n",
      "Trainable params: 249\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/52\n",
      "55/55 [==============================] - 0s 6ms/step - loss: 0.0897 - val_loss: 0.1101\n",
      "Epoch 2/52\n",
      "55/55 [==============================] - 0s 3ms/step - loss: 0.0895 - val_loss: 0.1100\n",
      "Epoch 3/52\n",
      "55/55 [==============================] - 0s 3ms/step - loss: 0.0894 - val_loss: 0.1099\n",
      "Epoch 4/52\n",
      "55/55 [==============================] - 0s 3ms/step - loss: 0.0893 - val_loss: 0.1098\n",
      "Epoch 5/52\n",
      "55/55 [==============================] - 0s 3ms/step - loss: 0.0892 - val_loss: 0.1097\n",
      "Epoch 6/52\n",
      "55/55 [==============================] - 0s 3ms/step - loss: 0.0892 - val_loss: 0.1096\n",
      "Epoch 7/52\n",
      "55/55 [==============================] - 0s 3ms/step - loss: 0.0891 - val_loss: 0.1095\n",
      "Epoch 8/52\n",
      "55/55 [==============================] - 0s 3ms/step - loss: 0.0889 - val_loss: 0.1094\n",
      "Epoch 9/52\n",
      "55/55 [==============================] - 0s 3ms/step - loss: 0.0887 - val_loss: 0.1092\n",
      "Epoch 10/52\n",
      "55/55 [==============================] - 0s 3ms/step - loss: 0.0887 - val_loss: 0.1091\n",
      "Epoch 11/52\n",
      "55/55 [==============================] - 0s 3ms/step - loss: 0.0886 - val_loss: 0.1090\n",
      "Epoch 12/52\n",
      "55/55 [==============================] - 0s 3ms/step - loss: 0.0884 - val_loss: 0.1089\n",
      "Epoch 13/52\n",
      "55/55 [==============================] - 0s 3ms/step - loss: 0.0883 - val_loss: 0.1087\n",
      "Epoch 14/52\n",
      "55/55 [==============================] - 0s 3ms/step - loss: 0.0881 - val_loss: 0.1086\n",
      "Epoch 15/52\n",
      "55/55 [==============================] - 0s 3ms/step - loss: 0.0880 - val_loss: 0.1084\n",
      "Epoch 16/52\n",
      "55/55 [==============================] - 0s 3ms/step - loss: 0.0879 - val_loss: 0.1083\n",
      "Epoch 17/52\n",
      "55/55 [==============================] - 0s 3ms/step - loss: 0.0877 - val_loss: 0.1082\n",
      "Epoch 18/52\n",
      "55/55 [==============================] - 0s 3ms/step - loss: 0.0876 - val_loss: 0.1080\n",
      "Epoch 19/52\n",
      "55/55 [==============================] - 0s 3ms/step - loss: 0.0873 - val_loss: 0.1079\n",
      "Epoch 20/52\n",
      "55/55 [==============================] - 0s 3ms/step - loss: 0.0873 - val_loss: 0.1077\n",
      "Epoch 21/52\n",
      "55/55 [==============================] - 0s 3ms/step - loss: 0.0872 - val_loss: 0.1076\n",
      "Epoch 22/52\n",
      "55/55 [==============================] - 0s 3ms/step - loss: 0.0869 - val_loss: 0.1074\n",
      "Epoch 23/52\n",
      "55/55 [==============================] - 0s 3ms/step - loss: 0.0868 - val_loss: 0.1073\n",
      "Epoch 24/52\n",
      "55/55 [==============================] - 0s 3ms/step - loss: 0.0867 - val_loss: 0.1071\n",
      "Epoch 25/52\n",
      "55/55 [==============================] - 0s 3ms/step - loss: 0.0865 - val_loss: 0.1069\n",
      "Epoch 26/52\n",
      "55/55 [==============================] - 0s 3ms/step - loss: 0.0864 - val_loss: 0.1068\n",
      "Epoch 27/52\n",
      "55/55 [==============================] - 0s 3ms/step - loss: 0.0862 - val_loss: 0.1066\n",
      "Epoch 28/52\n",
      "55/55 [==============================] - 0s 3ms/step - loss: 0.0860 - val_loss: 0.1064\n",
      "Epoch 29/52\n",
      "55/55 [==============================] - 0s 3ms/step - loss: 0.0858 - val_loss: 0.1063\n",
      "Epoch 30/52\n",
      "55/55 [==============================] - 0s 3ms/step - loss: 0.0857 - val_loss: 0.1061\n",
      "Epoch 31/52\n",
      "55/55 [==============================] - 0s 3ms/step - loss: 0.0855 - val_loss: 0.1059\n",
      "Epoch 32/52\n",
      "55/55 [==============================] - 0s 3ms/step - loss: 0.0853 - val_loss: 0.1058\n",
      "Epoch 33/52\n",
      "55/55 [==============================] - 0s 3ms/step - loss: 0.0852 - val_loss: 0.1056\n",
      "Epoch 34/52\n",
      "55/55 [==============================] - 0s 3ms/step - loss: 0.0850 - val_loss: 0.1054\n",
      "Epoch 35/52\n",
      "55/55 [==============================] - 0s 3ms/step - loss: 0.0849 - val_loss: 0.1052\n",
      "Epoch 36/52\n",
      "55/55 [==============================] - 0s 3ms/step - loss: 0.0846 - val_loss: 0.1051\n",
      "Epoch 37/52\n",
      "55/55 [==============================] - 0s 3ms/step - loss: 0.0845 - val_loss: 0.1049\n",
      "Epoch 38/52\n",
      "55/55 [==============================] - 0s 3ms/step - loss: 0.0843 - val_loss: 0.1047\n",
      "Epoch 39/52\n",
      "55/55 [==============================] - 0s 3ms/step - loss: 0.0842 - val_loss: 0.1045\n",
      "Epoch 40/52\n",
      "55/55 [==============================] - 0s 3ms/step - loss: 0.0839 - val_loss: 0.1043\n",
      "Epoch 41/52\n",
      "55/55 [==============================] - 0s 3ms/step - loss: 0.0838 - val_loss: 0.1042\n",
      "Epoch 42/52\n",
      "55/55 [==============================] - 0s 3ms/step - loss: 0.0836 - val_loss: 0.1040\n",
      "Epoch 43/52\n",
      "55/55 [==============================] - 0s 4ms/step - loss: 0.0835 - val_loss: 0.1038\n",
      "Epoch 44/52\n",
      "55/55 [==============================] - 0s 4ms/step - loss: 0.0833 - val_loss: 0.1036\n",
      "Epoch 45/52\n",
      "55/55 [==============================] - 0s 4ms/step - loss: 0.0831 - val_loss: 0.1034\n",
      "Epoch 46/52\n",
      "55/55 [==============================] - 0s 4ms/step - loss: 0.0829 - val_loss: 0.1032\n",
      "Epoch 47/52\n",
      "55/55 [==============================] - 0s 4ms/step - loss: 0.0827 - val_loss: 0.1030\n",
      "Epoch 48/52\n",
      "55/55 [==============================] - 0s 3ms/step - loss: 0.0825 - val_loss: 0.1028\n",
      "Epoch 49/52\n",
      "55/55 [==============================] - 0s 4ms/step - loss: 0.0823 - val_loss: 0.1026\n",
      "Epoch 50/52\n",
      "55/55 [==============================] - 0s 3ms/step - loss: 0.0821 - val_loss: 0.1025\n",
      "Epoch 51/52\n",
      "55/55 [==============================] - 0s 3ms/step - loss: 0.0819 - val_loss: 0.1023\n",
      "Epoch 52/52\n",
      "55/55 [==============================] - 0s 3ms/step - loss: 0.0818 - val_loss: 0.1021\n",
      "Execution time:  10.273429155349731\n",
      "DNN:\n",
      "Mean Absolute Error: 0.0849\n",
      "Root Mean Square Error: 0.0920\n",
      "Mean Square Error: 0.0085\n",
      "\n",
      "Train RMSE: 0.092\n",
      "Train MSE: 0.008\n",
      "Train MAE: 0.085\n",
      "###########################\n",
      "\n",
      "MODEL:  DNN\n",
      "sequence:  12h\n",
      "units:  87\n",
      "dropout1:  0.40519643149940265\n",
      "optimizer: adamax\n",
      "activationDense: tanh\n",
      "epochs: 80\n",
      "batchsize: 31\n",
      "validation_split: 0.1\n",
      "Model: \"sequential_132\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_396 (Dense)            (None, 72, 87)            174       \n",
      "_________________________________________________________________\n",
      "dense_397 (Dense)            (None, 72, 16)            1408      \n",
      "_________________________________________________________________\n",
      "dropout_132 (Dropout)        (None, 72, 16)            0         \n",
      "_________________________________________________________________\n",
      "dense_398 (Dense)            (None, 72, 1)             17        \n",
      "=================================================================\n",
      "Total params: 1,599\n",
      "Trainable params: 1,599\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/80\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "114/114 [==============================] - 1s 5ms/step - loss: 0.1883 - val_loss: 0.0435\n",
      "Epoch 2/80\n",
      "114/114 [==============================] - 0s 3ms/step - loss: 0.1075 - val_loss: 0.0260\n",
      "Epoch 3/80\n",
      "114/114 [==============================] - 0s 3ms/step - loss: 0.0817 - val_loss: 0.0095\n",
      "Epoch 4/80\n",
      "114/114 [==============================] - 0s 3ms/step - loss: 0.0692 - val_loss: 0.0064\n",
      "Epoch 5/80\n",
      "114/114 [==============================] - 0s 3ms/step - loss: 0.0616 - val_loss: 0.0061\n",
      "Epoch 6/80\n",
      "114/114 [==============================] - 0s 3ms/step - loss: 0.0555 - val_loss: 0.0056\n",
      "Epoch 7/80\n",
      "114/114 [==============================] - 0s 3ms/step - loss: 0.0499 - val_loss: 0.0059\n",
      "Epoch 8/80\n",
      "114/114 [==============================] - 0s 3ms/step - loss: 0.0449 - val_loss: 0.0061\n",
      "Epoch 9/80\n",
      "114/114 [==============================] - 0s 3ms/step - loss: 0.0405 - val_loss: 0.0072\n",
      "Epoch 10/80\n",
      "114/114 [==============================] - 0s 3ms/step - loss: 0.0368 - val_loss: 0.0077\n",
      "Epoch 11/80\n",
      "114/114 [==============================] - 0s 3ms/step - loss: 0.0336 - val_loss: 0.0142\n",
      "Epoch 12/80\n",
      "114/114 [==============================] - 0s 4ms/step - loss: 0.0319 - val_loss: 0.0129\n",
      "Epoch 13/80\n",
      "114/114 [==============================] - 0s 3ms/step - loss: 0.0309 - val_loss: 0.0118\n",
      "Epoch 14/80\n",
      "114/114 [==============================] - 0s 3ms/step - loss: 0.0300 - val_loss: 0.0120\n",
      "Epoch 15/80\n",
      "114/114 [==============================] - 0s 3ms/step - loss: 0.0303 - val_loss: 0.0100\n",
      "Epoch 16/80\n",
      "114/114 [==============================] - 0s 3ms/step - loss: 0.0297 - val_loss: 0.0098\n",
      "Epoch 17/80\n",
      "114/114 [==============================] - 0s 3ms/step - loss: 0.0284 - val_loss: 0.0093\n",
      "Epoch 18/80\n",
      "114/114 [==============================] - 0s 3ms/step - loss: 0.0285 - val_loss: 0.0097\n",
      "Epoch 19/80\n",
      "114/114 [==============================] - 0s 3ms/step - loss: 0.0284 - val_loss: 0.0096\n",
      "Epoch 20/80\n",
      "114/114 [==============================] - 0s 3ms/step - loss: 0.0282 - val_loss: 0.0118\n",
      "Epoch 21/80\n",
      "114/114 [==============================] - 0s 3ms/step - loss: 0.0285 - val_loss: 0.0130\n",
      "Epoch 22/80\n",
      "114/114 [==============================] - 0s 3ms/step - loss: 0.0278 - val_loss: 0.0132\n",
      "Epoch 23/80\n",
      "114/114 [==============================] - 0s 3ms/step - loss: 0.0277 - val_loss: 0.0121\n",
      "Epoch 24/80\n",
      "114/114 [==============================] - 0s 3ms/step - loss: 0.0280 - val_loss: 0.0136\n",
      "Epoch 25/80\n",
      "114/114 [==============================] - 0s 4ms/step - loss: 0.0279 - val_loss: 0.0114\n",
      "Epoch 26/80\n",
      "114/114 [==============================] - 0s 3ms/step - loss: 0.0280 - val_loss: 0.0147\n",
      "Epoch 27/80\n",
      "114/114 [==============================] - 0s 3ms/step - loss: 0.0274 - val_loss: 0.0123\n",
      "Epoch 28/80\n",
      "114/114 [==============================] - 0s 3ms/step - loss: 0.0276 - val_loss: 0.0110\n",
      "Epoch 29/80\n",
      "114/114 [==============================] - 0s 4ms/step - loss: 0.0279 - val_loss: 0.0117\n",
      "Epoch 30/80\n",
      "114/114 [==============================] - 0s 3ms/step - loss: 0.0280 - val_loss: 0.0121\n",
      "Epoch 31/80\n",
      "114/114 [==============================] - 0s 3ms/step - loss: 0.0273 - val_loss: 0.0113\n",
      "Epoch 32/80\n",
      "114/114 [==============================] - 0s 4ms/step - loss: 0.0280 - val_loss: 0.0121\n",
      "Epoch 33/80\n",
      "114/114 [==============================] - 0s 4ms/step - loss: 0.0273 - val_loss: 0.0113\n",
      "Epoch 34/80\n",
      "114/114 [==============================] - 0s 4ms/step - loss: 0.0279 - val_loss: 0.0122\n",
      "Epoch 35/80\n",
      "114/114 [==============================] - 0s 4ms/step - loss: 0.0271 - val_loss: 0.0106\n",
      "Epoch 36/80\n",
      "114/114 [==============================] - 0s 4ms/step - loss: 0.0279 - val_loss: 0.0104\n",
      "Epoch 37/80\n",
      "114/114 [==============================] - 0s 3ms/step - loss: 0.0277 - val_loss: 0.0111\n",
      "Epoch 38/80\n",
      "114/114 [==============================] - 0s 3ms/step - loss: 0.0275 - val_loss: 0.0111\n",
      "Epoch 39/80\n",
      "114/114 [==============================] - 0s 3ms/step - loss: 0.0274 - val_loss: 0.0107\n",
      "Epoch 40/80\n",
      "114/114 [==============================] - 0s 4ms/step - loss: 0.0274 - val_loss: 0.0104\n",
      "Epoch 41/80\n",
      "114/114 [==============================] - 0s 3ms/step - loss: 0.0269 - val_loss: 0.0109\n",
      "Epoch 42/80\n",
      "114/114 [==============================] - 0s 3ms/step - loss: 0.0274 - val_loss: 0.0104\n",
      "Epoch 43/80\n",
      "114/114 [==============================] - 0s 4ms/step - loss: 0.0272 - val_loss: 0.0104\n",
      "Epoch 44/80\n",
      "114/114 [==============================] - 0s 3ms/step - loss: 0.0272 - val_loss: 0.0103\n",
      "Epoch 45/80\n",
      "114/114 [==============================] - 0s 3ms/step - loss: 0.0267 - val_loss: 0.0105\n",
      "Epoch 46/80\n",
      "114/114 [==============================] - 0s 3ms/step - loss: 0.0271 - val_loss: 0.0104\n",
      "Epoch 47/80\n",
      "114/114 [==============================] - 0s 4ms/step - loss: 0.0267 - val_loss: 0.0109\n",
      "Epoch 48/80\n",
      "114/114 [==============================] - 0s 3ms/step - loss: 0.0269 - val_loss: 0.0103\n",
      "Epoch 49/80\n",
      "114/114 [==============================] - 0s 4ms/step - loss: 0.0266 - val_loss: 0.0108\n",
      "Epoch 50/80\n",
      "114/114 [==============================] - 0s 3ms/step - loss: 0.0269 - val_loss: 0.0104\n",
      "Epoch 51/80\n",
      "114/114 [==============================] - 0s 4ms/step - loss: 0.0266 - val_loss: 0.0110\n",
      "Epoch 52/80\n",
      "114/114 [==============================] - 0s 3ms/step - loss: 0.0265 - val_loss: 0.0103\n",
      "Epoch 53/80\n",
      "114/114 [==============================] - 0s 4ms/step - loss: 0.0264 - val_loss: 0.0107\n",
      "Epoch 54/80\n",
      "114/114 [==============================] - 0s 3ms/step - loss: 0.0264 - val_loss: 0.0100\n",
      "Epoch 55/80\n",
      "114/114 [==============================] - 0s 3ms/step - loss: 0.0263 - val_loss: 0.0107\n",
      "Epoch 56/80\n",
      "114/114 [==============================] - 0s 4ms/step - loss: 0.0264 - val_loss: 0.0108\n",
      "Epoch 57/80\n",
      "114/114 [==============================] - 0s 3ms/step - loss: 0.0263 - val_loss: 0.0110\n",
      "Epoch 58/80\n",
      "114/114 [==============================] - 0s 4ms/step - loss: 0.0257 - val_loss: 0.0098\n",
      "Epoch 59/80\n",
      "114/114 [==============================] - 0s 3ms/step - loss: 0.0267 - val_loss: 0.0108\n",
      "Epoch 60/80\n",
      "114/114 [==============================] - 0s 4ms/step - loss: 0.0256 - val_loss: 0.0100\n",
      "Epoch 61/80\n",
      "114/114 [==============================] - 0s 3ms/step - loss: 0.0264 - val_loss: 0.0110\n",
      "Epoch 62/80\n",
      "114/114 [==============================] - 0s 3ms/step - loss: 0.0256 - val_loss: 0.0102\n",
      "Epoch 63/80\n",
      "114/114 [==============================] - 0s 3ms/step - loss: 0.0261 - val_loss: 0.0105\n",
      "Epoch 64/80\n",
      "114/114 [==============================] - 0s 3ms/step - loss: 0.0257 - val_loss: 0.0102\n",
      "Epoch 65/80\n",
      "114/114 [==============================] - 0s 4ms/step - loss: 0.0259 - val_loss: 0.0105\n",
      "Epoch 66/80\n",
      "114/114 [==============================] - 0s 3ms/step - loss: 0.0256 - val_loss: 0.0103\n",
      "Epoch 67/80\n",
      "114/114 [==============================] - 0s 4ms/step - loss: 0.0258 - val_loss: 0.0105\n",
      "Epoch 68/80\n",
      "114/114 [==============================] - 0s 3ms/step - loss: 0.0255 - val_loss: 0.0102\n",
      "Epoch 69/80\n",
      "114/114 [==============================] - 0s 4ms/step - loss: 0.0256 - val_loss: 0.0105\n",
      "Epoch 70/80\n",
      "114/114 [==============================] - 0s 3ms/step - loss: 0.0250 - val_loss: 0.0097\n",
      "Epoch 71/80\n",
      "114/114 [==============================] - 0s 3ms/step - loss: 0.0259 - val_loss: 0.0104\n",
      "Epoch 72/80\n",
      "114/114 [==============================] - 0s 4ms/step - loss: 0.0250 - val_loss: 0.0098\n",
      "Epoch 73/80\n",
      "114/114 [==============================] - 0s 4ms/step - loss: 0.0257 - val_loss: 0.0105\n",
      "Epoch 74/80\n",
      "114/114 [==============================] - 0s 4ms/step - loss: 0.0248 - val_loss: 0.0097\n",
      "Epoch 75/80\n",
      "114/114 [==============================] - 0s 4ms/step - loss: 0.0255 - val_loss: 0.0105\n",
      "Epoch 76/80\n",
      "114/114 [==============================] - 0s 4ms/step - loss: 0.0247 - val_loss: 0.0100\n",
      "Epoch 77/80\n",
      "114/114 [==============================] - 0s 3ms/step - loss: 0.0254 - val_loss: 0.0107\n",
      "Epoch 78/80\n",
      "114/114 [==============================] - 0s 4ms/step - loss: 0.0245 - val_loss: 0.0100\n",
      "Epoch 79/80\n",
      "114/114 [==============================] - 0s 3ms/step - loss: 0.0255 - val_loss: 0.0108\n",
      "Epoch 80/80\n",
      "114/114 [==============================] - 0s 3ms/step - loss: 0.0245 - val_loss: 0.0096\n",
      "Execution time:  33.429774045944214\n",
      "DNN:\n",
      "Mean Absolute Error: 0.0234\n",
      "Root Mean Square Error: 0.0383\n",
      "Mean Square Error: 0.0015\n",
      "\n",
      "Train RMSE: 0.038\n",
      "Train MSE: 0.001\n",
      "Train MAE: 0.023\n",
      "###########################\n",
      "\n",
      "MODEL:  DNN\n",
      "sequence:  12h\n",
      "units:  80\n",
      "dropout1:  0.11814836227952394\n",
      "optimizer: adamax\n",
      "activationDense: tanh\n",
      "epochs: 90\n",
      "batchsize: 25\n",
      "validation_split: 0.1\n",
      "Model: \"sequential_133\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_399 (Dense)            (None, 72, 80)            160       \n",
      "_________________________________________________________________\n",
      "dense_400 (Dense)            (None, 72, 16)            1296      \n",
      "_________________________________________________________________\n",
      "dropout_133 (Dropout)        (None, 72, 16)            0         \n",
      "_________________________________________________________________\n",
      "dense_401 (Dense)            (None, 72, 1)             17        \n",
      "=================================================================\n",
      "Total params: 1,473\n",
      "Trainable params: 1,473\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/90\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "142/142 [==============================] - 1s 4ms/step - loss: 0.0792 - val_loss: 0.0263\n",
      "Epoch 2/90\n",
      "142/142 [==============================] - 0s 3ms/step - loss: 0.0546 - val_loss: 0.0186\n",
      "Epoch 3/90\n",
      "142/142 [==============================] - 0s 3ms/step - loss: 0.0521 - val_loss: 0.0181\n",
      "Epoch 4/90\n",
      "142/142 [==============================] - 0s 3ms/step - loss: 0.0505 - val_loss: 0.0149\n",
      "Epoch 5/90\n",
      "142/142 [==============================] - 0s 3ms/step - loss: 0.0484 - val_loss: 0.0106\n",
      "Epoch 6/90\n",
      "142/142 [==============================] - 0s 3ms/step - loss: 0.0465 - val_loss: 0.0124\n",
      "Epoch 7/90\n",
      "142/142 [==============================] - 0s 3ms/step - loss: 0.0449 - val_loss: 0.0092\n",
      "Epoch 8/90\n",
      "142/142 [==============================] - 0s 3ms/step - loss: 0.0431 - val_loss: 0.0077\n",
      "Epoch 9/90\n",
      "142/142 [==============================] - 0s 3ms/step - loss: 0.0406 - val_loss: 0.0064\n",
      "Epoch 10/90\n",
      "142/142 [==============================] - 0s 3ms/step - loss: 0.0385 - val_loss: 0.0073\n",
      "Epoch 11/90\n",
      "142/142 [==============================] - 0s 3ms/step - loss: 0.0368 - val_loss: 0.0084\n",
      "Epoch 12/90\n",
      "142/142 [==============================] - 0s 3ms/step - loss: 0.0358 - val_loss: 0.0084\n",
      "Epoch 13/90\n",
      "142/142 [==============================] - 0s 3ms/step - loss: 0.0346 - val_loss: 0.0086\n",
      "Epoch 14/90\n",
      "142/142 [==============================] - 0s 3ms/step - loss: 0.0340 - val_loss: 0.0090\n",
      "Epoch 15/90\n",
      "142/142 [==============================] - 0s 3ms/step - loss: 0.0332 - val_loss: 0.0085\n",
      "Epoch 16/90\n",
      "142/142 [==============================] - 0s 3ms/step - loss: 0.0325 - val_loss: 0.0102\n",
      "Epoch 17/90\n",
      "142/142 [==============================] - 0s 3ms/step - loss: 0.0318 - val_loss: 0.0107\n",
      "Epoch 18/90\n",
      "142/142 [==============================] - 0s 3ms/step - loss: 0.0311 - val_loss: 0.0120\n",
      "Epoch 19/90\n",
      "142/142 [==============================] - 0s 3ms/step - loss: 0.0307 - val_loss: 0.0111\n",
      "Epoch 20/90\n",
      "142/142 [==============================] - 0s 3ms/step - loss: 0.0302 - val_loss: 0.0121\n",
      "Epoch 21/90\n",
      "142/142 [==============================] - 0s 3ms/step - loss: 0.0299 - val_loss: 0.0127\n",
      "Epoch 22/90\n",
      "142/142 [==============================] - 0s 3ms/step - loss: 0.0294 - val_loss: 0.0137\n",
      "Epoch 23/90\n",
      "142/142 [==============================] - 0s 3ms/step - loss: 0.0293 - val_loss: 0.0143\n",
      "Epoch 24/90\n",
      "142/142 [==============================] - 0s 3ms/step - loss: 0.0290 - val_loss: 0.0156\n",
      "Epoch 25/90\n",
      "142/142 [==============================] - 0s 3ms/step - loss: 0.0289 - val_loss: 0.0172\n",
      "Epoch 26/90\n",
      "142/142 [==============================] - 0s 3ms/step - loss: 0.0287 - val_loss: 0.0160\n",
      "Epoch 27/90\n",
      "142/142 [==============================] - 0s 3ms/step - loss: 0.0284 - val_loss: 0.0180\n",
      "Epoch 28/90\n",
      "142/142 [==============================] - 0s 3ms/step - loss: 0.0284 - val_loss: 0.0187\n",
      "Epoch 29/90\n",
      "142/142 [==============================] - 0s 3ms/step - loss: 0.0280 - val_loss: 0.0187\n",
      "Epoch 30/90\n",
      "142/142 [==============================] - 0s 3ms/step - loss: 0.0278 - val_loss: 0.0187\n",
      "Epoch 31/90\n",
      "142/142 [==============================] - 0s 3ms/step - loss: 0.0276 - val_loss: 0.0198\n",
      "Epoch 32/90\n",
      "142/142 [==============================] - 0s 3ms/step - loss: 0.0281 - val_loss: 0.0181\n",
      "Epoch 33/90\n",
      "142/142 [==============================] - 0s 3ms/step - loss: 0.0279 - val_loss: 0.0179\n",
      "Epoch 34/90\n",
      "142/142 [==============================] - 0s 3ms/step - loss: 0.0277 - val_loss: 0.0180\n",
      "Epoch 35/90\n",
      "142/142 [==============================] - 0s 3ms/step - loss: 0.0276 - val_loss: 0.0177\n",
      "Epoch 36/90\n",
      "142/142 [==============================] - 0s 3ms/step - loss: 0.0275 - val_loss: 0.0162\n",
      "Epoch 37/90\n",
      "142/142 [==============================] - 0s 3ms/step - loss: 0.0275 - val_loss: 0.0128\n",
      "Epoch 38/90\n",
      "142/142 [==============================] - 0s 3ms/step - loss: 0.0275 - val_loss: 0.0114\n",
      "Epoch 39/90\n",
      "142/142 [==============================] - 0s 3ms/step - loss: 0.0274 - val_loss: 0.0126\n",
      "Epoch 40/90\n",
      "142/142 [==============================] - 0s 3ms/step - loss: 0.0277 - val_loss: 0.0103\n",
      "Epoch 41/90\n",
      "142/142 [==============================] - 0s 3ms/step - loss: 0.0273 - val_loss: 0.0147\n",
      "Epoch 42/90\n",
      "142/142 [==============================] - 0s 3ms/step - loss: 0.0272 - val_loss: 0.0112\n",
      "Epoch 43/90\n",
      "142/142 [==============================] - 0s 3ms/step - loss: 0.0270 - val_loss: 0.0120\n",
      "Epoch 44/90\n",
      "142/142 [==============================] - 0s 3ms/step - loss: 0.0271 - val_loss: 0.0111\n",
      "Epoch 45/90\n",
      "142/142 [==============================] - 0s 3ms/step - loss: 0.0267 - val_loss: 0.0120\n",
      "Epoch 46/90\n",
      "142/142 [==============================] - 0s 3ms/step - loss: 0.0267 - val_loss: 0.0112\n",
      "Epoch 47/90\n",
      "142/142 [==============================] - 0s 3ms/step - loss: 0.0265 - val_loss: 0.0118\n",
      "Epoch 48/90\n",
      "142/142 [==============================] - 0s 3ms/step - loss: 0.0265 - val_loss: 0.0118\n",
      "Epoch 49/90\n",
      "142/142 [==============================] - 0s 3ms/step - loss: 0.0263 - val_loss: 0.0118\n",
      "Epoch 50/90\n",
      "142/142 [==============================] - 0s 3ms/step - loss: 0.0263 - val_loss: 0.0111\n",
      "Epoch 51/90\n",
      "142/142 [==============================] - 0s 3ms/step - loss: 0.0261 - val_loss: 0.0115\n",
      "Epoch 52/90\n",
      "142/142 [==============================] - 0s 3ms/step - loss: 0.0261 - val_loss: 0.0105\n",
      "Epoch 53/90\n",
      "142/142 [==============================] - 0s 3ms/step - loss: 0.0260 - val_loss: 0.0114\n",
      "Epoch 54/90\n",
      "142/142 [==============================] - 0s 3ms/step - loss: 0.0259 - val_loss: 0.0107\n",
      "Epoch 55/90\n",
      "142/142 [==============================] - 0s 3ms/step - loss: 0.0258 - val_loss: 0.0115\n",
      "Epoch 56/90\n",
      "142/142 [==============================] - 0s 3ms/step - loss: 0.0257 - val_loss: 0.0104\n",
      "Epoch 57/90\n",
      "142/142 [==============================] - 0s 3ms/step - loss: 0.0254 - val_loss: 0.0119\n",
      "Epoch 58/90\n",
      "142/142 [==============================] - 0s 3ms/step - loss: 0.0256 - val_loss: 0.0101\n",
      "Epoch 59/90\n",
      "142/142 [==============================] - 0s 3ms/step - loss: 0.0250 - val_loss: 0.0131\n",
      "Epoch 60/90\n",
      "142/142 [==============================] - 0s 3ms/step - loss: 0.0259 - val_loss: 0.0102\n",
      "Epoch 61/90\n",
      "142/142 [==============================] - 0s 3ms/step - loss: 0.0249 - val_loss: 0.0123\n",
      "Epoch 62/90\n",
      "142/142 [==============================] - 0s 3ms/step - loss: 0.0254 - val_loss: 0.0104\n",
      "Epoch 63/90\n",
      "142/142 [==============================] - 0s 3ms/step - loss: 0.0247 - val_loss: 0.0125\n",
      "Epoch 64/90\n",
      "142/142 [==============================] - 0s 3ms/step - loss: 0.0253 - val_loss: 0.0103\n",
      "Epoch 65/90\n",
      "142/142 [==============================] - 0s 3ms/step - loss: 0.0247 - val_loss: 0.0118\n",
      "Epoch 66/90\n",
      "142/142 [==============================] - 0s 3ms/step - loss: 0.0251 - val_loss: 0.0102\n",
      "Epoch 67/90\n",
      "142/142 [==============================] - 0s 3ms/step - loss: 0.0245 - val_loss: 0.0114\n",
      "Epoch 68/90\n",
      "142/142 [==============================] - 0s 3ms/step - loss: 0.0248 - val_loss: 0.0100\n",
      "Epoch 69/90\n",
      "142/142 [==============================] - 0s 3ms/step - loss: 0.0243 - val_loss: 0.0115\n",
      "Epoch 70/90\n",
      "142/142 [==============================] - 0s 3ms/step - loss: 0.0246 - val_loss: 0.0101\n",
      "Epoch 71/90\n",
      "142/142 [==============================] - 0s 3ms/step - loss: 0.0240 - val_loss: 0.0122\n",
      "Epoch 72/90\n",
      "142/142 [==============================] - 0s 3ms/step - loss: 0.0245 - val_loss: 0.0102\n",
      "Epoch 73/90\n",
      "142/142 [==============================] - 0s 3ms/step - loss: 0.0238 - val_loss: 0.0125\n",
      "Epoch 74/90\n",
      "142/142 [==============================] - 0s 3ms/step - loss: 0.0243 - val_loss: 0.0101\n",
      "Epoch 75/90\n",
      "142/142 [==============================] - 0s 3ms/step - loss: 0.0236 - val_loss: 0.0125\n",
      "Epoch 76/90\n",
      "142/142 [==============================] - 0s 3ms/step - loss: 0.0241 - val_loss: 0.0100\n",
      "Epoch 77/90\n",
      "142/142 [==============================] - 0s 3ms/step - loss: 0.0234 - val_loss: 0.0124\n",
      "Epoch 78/90\n",
      "142/142 [==============================] - 0s 3ms/step - loss: 0.0240 - val_loss: 0.0098\n",
      "Epoch 79/90\n",
      "142/142 [==============================] - 0s 3ms/step - loss: 0.0233 - val_loss: 0.0124\n",
      "Epoch 80/90\n",
      "142/142 [==============================] - 0s 3ms/step - loss: 0.0238 - val_loss: 0.0104\n",
      "Epoch 81/90\n",
      "142/142 [==============================] - 0s 3ms/step - loss: 0.0232 - val_loss: 0.0119\n",
      "Epoch 82/90\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "142/142 [==============================] - 0s 3ms/step - loss: 0.0234 - val_loss: 0.0108\n",
      "Epoch 83/90\n",
      "142/142 [==============================] - 0s 3ms/step - loss: 0.0230 - val_loss: 0.0120\n",
      "Epoch 84/90\n",
      "142/142 [==============================] - 0s 3ms/step - loss: 0.0232 - val_loss: 0.0115\n",
      "Epoch 85/90\n",
      "142/142 [==============================] - 0s 3ms/step - loss: 0.0229 - val_loss: 0.0120\n",
      "Epoch 86/90\n",
      "142/142 [==============================] - 0s 3ms/step - loss: 0.0229 - val_loss: 0.0120\n",
      "Epoch 87/90\n",
      "142/142 [==============================] - 0s 3ms/step - loss: 0.0229 - val_loss: 0.0120\n",
      "Epoch 88/90\n",
      "142/142 [==============================] - 0s 3ms/step - loss: 0.0228 - val_loss: 0.0121\n",
      "Epoch 89/90\n",
      "142/142 [==============================] - 0s 3ms/step - loss: 0.0228 - val_loss: 0.0118\n",
      "Epoch 90/90\n",
      "142/142 [==============================] - 0s 3ms/step - loss: 0.0228 - val_loss: 0.0121\n",
      "Execution time:  39.64670276641846\n",
      "DNN:\n",
      "Mean Absolute Error: 0.0193\n",
      "Root Mean Square Error: 0.0348\n",
      "Mean Square Error: 0.0012\n",
      "\n",
      "Train RMSE: 0.035\n",
      "Train MSE: 0.001\n",
      "Train MAE: 0.019\n",
      "###########################\n",
      "\n",
      "MODEL:  DNN\n",
      "sequence:  12h\n",
      "units:  12\n",
      "dropout1:  0.48476373451509647\n",
      "optimizer: adamax\n",
      "activationDense: tanh\n",
      "epochs: 52\n",
      "batchsize: 57\n",
      "validation_split: 0.1\n",
      "Model: \"sequential_134\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_402 (Dense)            (None, 72, 12)            24        \n",
      "_________________________________________________________________\n",
      "dense_403 (Dense)            (None, 72, 16)            208       \n",
      "_________________________________________________________________\n",
      "dropout_134 (Dropout)        (None, 72, 16)            0         \n",
      "_________________________________________________________________\n",
      "dense_404 (Dense)            (None, 72, 1)             17        \n",
      "=================================================================\n",
      "Total params: 249\n",
      "Trainable params: 249\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/52\n",
      "62/62 [==============================] - 0s 6ms/step - loss: 0.1889 - val_loss: 0.0122\n",
      "Epoch 2/52\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.0988 - val_loss: 0.0120\n",
      "Epoch 3/52\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.0906 - val_loss: 0.0092\n",
      "Epoch 4/52\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.0852 - val_loss: 0.0129\n",
      "Epoch 5/52\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.0807 - val_loss: 0.0153\n",
      "Epoch 6/52\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.0765 - val_loss: 0.0145\n",
      "Epoch 7/52\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.0726 - val_loss: 0.0116\n",
      "Epoch 8/52\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.0683 - val_loss: 0.0100\n",
      "Epoch 9/52\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.0639 - val_loss: 0.0084\n",
      "Epoch 10/52\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.0595 - val_loss: 0.0064\n",
      "Epoch 11/52\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.0553 - val_loss: 0.0057\n",
      "Epoch 12/52\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.0515 - val_loss: 0.0061\n",
      "Epoch 13/52\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.0480 - val_loss: 0.0069\n",
      "Epoch 14/52\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.0448 - val_loss: 0.0075\n",
      "Epoch 15/52\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.0420 - val_loss: 0.0083\n",
      "Epoch 16/52\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.0394 - val_loss: 0.0091\n",
      "Epoch 17/52\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.0370 - val_loss: 0.0098\n",
      "Epoch 18/52\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.0350 - val_loss: 0.0093\n",
      "Epoch 19/52\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.0333 - val_loss: 0.0090\n",
      "Epoch 20/52\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.0318 - val_loss: 0.0085\n",
      "Epoch 21/52\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.0307 - val_loss: 0.0081\n",
      "Epoch 22/52\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.0298 - val_loss: 0.0081\n",
      "Epoch 23/52\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.0290 - val_loss: 0.0082\n",
      "Epoch 24/52\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.0284 - val_loss: 0.0084\n",
      "Epoch 25/52\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.0279 - val_loss: 0.0090\n",
      "Epoch 26/52\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.0277 - val_loss: 0.0091\n",
      "Epoch 27/52\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.0273 - val_loss: 0.0097\n",
      "Epoch 28/52\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.0276 - val_loss: 0.0102\n",
      "Epoch 29/52\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.0272 - val_loss: 0.0116\n",
      "Epoch 30/52\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.0270 - val_loss: 0.0116\n",
      "Epoch 31/52\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.0269 - val_loss: 0.0128\n",
      "Epoch 32/52\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.0269 - val_loss: 0.0133\n",
      "Epoch 33/52\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.0268 - val_loss: 0.0138\n",
      "Epoch 34/52\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.0266 - val_loss: 0.0124\n",
      "Epoch 35/52\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.0267 - val_loss: 0.0125\n",
      "Epoch 36/52\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.0272 - val_loss: 0.0147\n",
      "Epoch 37/52\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.0267 - val_loss: 0.0147\n",
      "Epoch 38/52\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.0265 - val_loss: 0.0147\n",
      "Epoch 39/52\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.0263 - val_loss: 0.0136\n",
      "Epoch 40/52\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.0265 - val_loss: 0.0142\n",
      "Epoch 41/52\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.0262 - val_loss: 0.0133\n",
      "Epoch 42/52\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.0264 - val_loss: 0.0135\n",
      "Epoch 43/52\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.0264 - val_loss: 0.0136\n",
      "Epoch 44/52\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.0262 - val_loss: 0.0129\n",
      "Epoch 45/52\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.0263 - val_loss: 0.0132\n",
      "Epoch 46/52\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.0261 - val_loss: 0.0132\n",
      "Epoch 47/52\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.0261 - val_loss: 0.0127\n",
      "Epoch 48/52\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.0261 - val_loss: 0.0126\n",
      "Epoch 49/52\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.0261 - val_loss: 0.0131\n",
      "Epoch 50/52\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.0259 - val_loss: 0.0125\n",
      "Epoch 51/52\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.0259 - val_loss: 0.0123\n",
      "Epoch 52/52\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.0259 - val_loss: 0.0129\n",
      "Execution time:  12.446700811386108\n",
      "DNN:\n",
      "Mean Absolute Error: 0.0228\n",
      "Root Mean Square Error: 0.0380\n",
      "Mean Square Error: 0.0014\n",
      "\n",
      "Train RMSE: 0.038\n",
      "Train MSE: 0.001\n",
      "Train MAE: 0.023\n",
      "###########################\n",
      "\n",
      "MODEL:  DNN\n",
      "sequence:  12h\n",
      "units:  87\n",
      "dropout1:  0.40519643149940265\n",
      "optimizer: adamax\n",
      "activationDense: tanh\n",
      "epochs: 80\n",
      "batchsize: 31\n",
      "validation_split: 0.2\n",
      "Model: \"sequential_135\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_405 (Dense)            (None, 72, 87)            174       \n",
      "_________________________________________________________________\n",
      "dense_406 (Dense)            (None, 72, 16)            1408      \n",
      "_________________________________________________________________\n",
      "dropout_135 (Dropout)        (None, 72, 16)            0         \n",
      "_________________________________________________________________\n",
      "dense_407 (Dense)            (None, 72, 1)             17        \n",
      "=================================================================\n",
      "Total params: 1,599\n",
      "Trainable params: 1,599\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/80\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "102/102 [==============================] - 1s 5ms/step - loss: 0.1519 - val_loss: 0.0446\n",
      "Epoch 2/80\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.1040 - val_loss: 0.0384\n",
      "Epoch 3/80\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.0928 - val_loss: 0.0337\n",
      "Epoch 4/80\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.0833 - val_loss: 0.0295\n",
      "Epoch 5/80\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.0737 - val_loss: 0.0203\n",
      "Epoch 6/80\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.0648 - val_loss: 0.0172\n",
      "Epoch 7/80\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.0569 - val_loss: 0.0150\n",
      "Epoch 8/80\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.0496 - val_loss: 0.0148\n",
      "Epoch 9/80\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.0437 - val_loss: 0.0165\n",
      "Epoch 10/80\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.0393 - val_loss: 0.0178\n",
      "Epoch 11/80\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.0359 - val_loss: 0.0171\n",
      "Epoch 12/80\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.0334 - val_loss: 0.0172\n",
      "Epoch 13/80\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.0317 - val_loss: 0.0161\n",
      "Epoch 14/80\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.0323 - val_loss: 0.0156\n",
      "Epoch 15/80\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.0301 - val_loss: 0.0158\n",
      "Epoch 16/80\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.0294 - val_loss: 0.0158\n",
      "Epoch 17/80\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.0299 - val_loss: 0.0158\n",
      "Epoch 18/80\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.0293 - val_loss: 0.0170\n",
      "Epoch 19/80\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.0291 - val_loss: 0.0174\n",
      "Epoch 20/80\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.0289 - val_loss: 0.0172\n",
      "Epoch 21/80\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.0290 - val_loss: 0.0173\n",
      "Epoch 22/80\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.0289 - val_loss: 0.0176\n",
      "Epoch 23/80\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.0292 - val_loss: 0.0185\n",
      "Epoch 24/80\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.0288 - val_loss: 0.0176\n",
      "Epoch 25/80\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.0290 - val_loss: 0.0174\n",
      "Epoch 26/80\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.0287 - val_loss: 0.0166\n",
      "Epoch 27/80\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.0289 - val_loss: 0.0161\n",
      "Epoch 28/80\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.0289 - val_loss: 0.0168\n",
      "Epoch 29/80\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.0287 - val_loss: 0.0170\n",
      "Epoch 30/80\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.0278 - val_loss: 0.0163\n",
      "Epoch 31/80\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.0289 - val_loss: 0.0172\n",
      "Epoch 32/80\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.0281 - val_loss: 0.0166\n",
      "Epoch 33/80\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.0285 - val_loss: 0.0164\n",
      "Epoch 34/80\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.0282 - val_loss: 0.0165\n",
      "Epoch 35/80\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.0286 - val_loss: 0.0168\n",
      "Epoch 36/80\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.0278 - val_loss: 0.0162\n",
      "Epoch 37/80\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.0286 - val_loss: 0.0170\n",
      "Epoch 38/80\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.0277 - val_loss: 0.0161\n",
      "Epoch 39/80\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.0283 - val_loss: 0.0168\n",
      "Epoch 40/80\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.0278 - val_loss: 0.0159\n",
      "Epoch 41/80\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.0282 - val_loss: 0.0168\n",
      "Epoch 42/80\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.0273 - val_loss: 0.0158\n",
      "Epoch 43/80\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.0281 - val_loss: 0.0167\n",
      "Epoch 44/80\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.0271 - val_loss: 0.0161\n",
      "Epoch 45/80\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.0275 - val_loss: 0.0165\n",
      "Epoch 46/80\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.0273 - val_loss: 0.0160\n",
      "Epoch 47/80\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.0278 - val_loss: 0.0166\n",
      "Epoch 48/80\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.0269 - val_loss: 0.0160\n",
      "Epoch 49/80\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.0277 - val_loss: 0.0169\n",
      "Epoch 50/80\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.0270 - val_loss: 0.0160\n",
      "Epoch 51/80\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.0276 - val_loss: 0.0167\n",
      "Epoch 52/80\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.0268 - val_loss: 0.0160\n",
      "Epoch 53/80\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.0277 - val_loss: 0.0169\n",
      "Epoch 54/80\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.0268 - val_loss: 0.0160\n",
      "Epoch 55/80\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.0275 - val_loss: 0.0167\n",
      "Epoch 56/80\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.0268 - val_loss: 0.0160\n",
      "Epoch 57/80\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.0273 - val_loss: 0.0168\n",
      "Epoch 58/80\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.0265 - val_loss: 0.0161\n",
      "Epoch 59/80\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.0272 - val_loss: 0.0166\n",
      "Epoch 60/80\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.0267 - val_loss: 0.0160\n",
      "Epoch 61/80\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.0270 - val_loss: 0.0163\n",
      "Epoch 62/80\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.0266 - val_loss: 0.0161\n",
      "Epoch 63/80\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.0266 - val_loss: 0.0160\n",
      "Epoch 64/80\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.0266 - val_loss: 0.0161\n",
      "Epoch 65/80\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.0265 - val_loss: 0.0162\n",
      "Epoch 66/80\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.0264 - val_loss: 0.0161\n",
      "Epoch 67/80\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.0265 - val_loss: 0.0161\n",
      "Epoch 68/80\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.0264 - val_loss: 0.0163\n",
      "Epoch 69/80\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.0261 - val_loss: 0.0161\n",
      "Epoch 70/80\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.0266 - val_loss: 0.0162\n",
      "Epoch 71/80\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.0260 - val_loss: 0.0161\n",
      "Epoch 72/80\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.0263 - val_loss: 0.0163\n",
      "Epoch 73/80\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.0259 - val_loss: 0.0161\n",
      "Epoch 74/80\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.0263 - val_loss: 0.0165\n",
      "Epoch 75/80\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.0257 - val_loss: 0.0161\n",
      "Epoch 76/80\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.0261 - val_loss: 0.0166\n",
      "Epoch 77/80\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.0255 - val_loss: 0.0161\n",
      "Epoch 78/80\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.0260 - val_loss: 0.0163\n",
      "Epoch 79/80\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.0254 - val_loss: 0.0161\n",
      "Epoch 80/80\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.0259 - val_loss: 0.0166\n",
      "Execution time:  31.21041512489319\n",
      "DNN:\n",
      "Mean Absolute Error: 0.0197\n",
      "Root Mean Square Error: 0.0320\n",
      "Mean Square Error: 0.0010\n",
      "\n",
      "Train RMSE: 0.032\n",
      "Train MSE: 0.001\n",
      "Train MAE: 0.020\n",
      "###########################\n",
      "\n",
      "MODEL:  DNN\n",
      "sequence:  12h\n",
      "units:  80\n",
      "dropout1:  0.11814836227952394\n",
      "optimizer: adamax\n",
      "activationDense: tanh\n",
      "epochs: 90\n",
      "batchsize: 25\n",
      "validation_split: 0.2\n",
      "Model: \"sequential_136\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_408 (Dense)            (None, 72, 80)            160       \n",
      "_________________________________________________________________\n",
      "dense_409 (Dense)            (None, 72, 16)            1296      \n",
      "_________________________________________________________________\n",
      "dropout_136 (Dropout)        (None, 72, 16)            0         \n",
      "_________________________________________________________________\n",
      "dense_410 (Dense)            (None, 72, 1)             17        \n",
      "=================================================================\n",
      "Total params: 1,473\n",
      "Trainable params: 1,473\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/90\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  1/126 [..............................] - ETA: 0s - loss: 0.4152WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0000s vs `on_train_batch_end` time: 0.0052s). Check your callbacks.\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.1270 - val_loss: 0.0342\n",
      "Epoch 2/90\n",
      "126/126 [==============================] - 0s 3ms/step - loss: 0.0599 - val_loss: 0.0311\n",
      "Epoch 3/90\n",
      "126/126 [==============================] - 0s 3ms/step - loss: 0.0586 - val_loss: 0.0308\n",
      "Epoch 4/90\n",
      "126/126 [==============================] - 0s 3ms/step - loss: 0.0566 - val_loss: 0.0290\n",
      "Epoch 5/90\n",
      "126/126 [==============================] - 0s 3ms/step - loss: 0.0550 - val_loss: 0.0278\n",
      "Epoch 6/90\n",
      "126/126 [==============================] - 0s 3ms/step - loss: 0.0534 - val_loss: 0.0287\n",
      "Epoch 7/90\n",
      "126/126 [==============================] - 0s 3ms/step - loss: 0.0515 - val_loss: 0.0269\n",
      "Epoch 8/90\n",
      "126/126 [==============================] - 0s 3ms/step - loss: 0.0503 - val_loss: 0.0301\n",
      "Epoch 9/90\n",
      "126/126 [==============================] - 0s 3ms/step - loss: 0.0487 - val_loss: 0.0270\n",
      "Epoch 10/90\n",
      "126/126 [==============================] - 0s 3ms/step - loss: 0.0470 - val_loss: 0.0245\n",
      "Epoch 11/90\n",
      "126/126 [==============================] - 0s 3ms/step - loss: 0.0455 - val_loss: 0.0280\n",
      "Epoch 12/90\n",
      "126/126 [==============================] - 0s 3ms/step - loss: 0.0443 - val_loss: 0.0236\n",
      "Epoch 13/90\n",
      "126/126 [==============================] - 0s 3ms/step - loss: 0.0429 - val_loss: 0.0250\n",
      "Epoch 14/90\n",
      "126/126 [==============================] - 0s 3ms/step - loss: 0.0417 - val_loss: 0.0231\n",
      "Epoch 15/90\n",
      "126/126 [==============================] - 0s 3ms/step - loss: 0.0404 - val_loss: 0.0225\n",
      "Epoch 16/90\n",
      "126/126 [==============================] - 0s 3ms/step - loss: 0.0392 - val_loss: 0.0216\n",
      "Epoch 17/90\n",
      "126/126 [==============================] - 0s 3ms/step - loss: 0.0380 - val_loss: 0.0228\n",
      "Epoch 18/90\n",
      "126/126 [==============================] - 0s 3ms/step - loss: 0.0370 - val_loss: 0.0207\n",
      "Epoch 19/90\n",
      "126/126 [==============================] - 0s 4ms/step - loss: 0.0358 - val_loss: 0.0191\n",
      "Epoch 20/90\n",
      "126/126 [==============================] - 0s 3ms/step - loss: 0.0345 - val_loss: 0.0176\n",
      "Epoch 21/90\n",
      "126/126 [==============================] - 0s 3ms/step - loss: 0.0333 - val_loss: 0.0171\n",
      "Epoch 22/90\n",
      "126/126 [==============================] - 0s 3ms/step - loss: 0.0325 - val_loss: 0.0169\n",
      "Epoch 23/90\n",
      "126/126 [==============================] - 0s 3ms/step - loss: 0.0313 - val_loss: 0.0166\n",
      "Epoch 24/90\n",
      "126/126 [==============================] - 0s 3ms/step - loss: 0.0309 - val_loss: 0.0166\n",
      "Epoch 25/90\n",
      "126/126 [==============================] - 0s 3ms/step - loss: 0.0304 - val_loss: 0.0161\n",
      "Epoch 26/90\n",
      "126/126 [==============================] - 0s 3ms/step - loss: 0.0300 - val_loss: 0.0164\n",
      "Epoch 27/90\n",
      "126/126 [==============================] - 0s 3ms/step - loss: 0.0296 - val_loss: 0.0164\n",
      "Epoch 28/90\n",
      "126/126 [==============================] - 0s 3ms/step - loss: 0.0295 - val_loss: 0.0160\n",
      "Epoch 29/90\n",
      "126/126 [==============================] - 0s 3ms/step - loss: 0.0297 - val_loss: 0.0157\n",
      "Epoch 30/90\n",
      "126/126 [==============================] - 0s 3ms/step - loss: 0.0294 - val_loss: 0.0159\n",
      "Epoch 31/90\n",
      "126/126 [==============================] - 0s 3ms/step - loss: 0.0290 - val_loss: 0.0158\n",
      "Epoch 32/90\n",
      "126/126 [==============================] - 0s 3ms/step - loss: 0.0293 - val_loss: 0.0159\n",
      "Epoch 33/90\n",
      "126/126 [==============================] - 0s 3ms/step - loss: 0.0294 - val_loss: 0.0157\n",
      "Epoch 34/90\n",
      "126/126 [==============================] - 0s 3ms/step - loss: 0.0293 - val_loss: 0.0161\n",
      "Epoch 35/90\n",
      "126/126 [==============================] - 0s 3ms/step - loss: 0.0287 - val_loss: 0.0159\n",
      "Epoch 36/90\n",
      "126/126 [==============================] - 0s 3ms/step - loss: 0.0288 - val_loss: 0.0160\n",
      "Epoch 37/90\n",
      "126/126 [==============================] - 0s 3ms/step - loss: 0.0293 - val_loss: 0.0158\n",
      "Epoch 38/90\n",
      "126/126 [==============================] - 0s 3ms/step - loss: 0.0287 - val_loss: 0.0161\n",
      "Epoch 39/90\n",
      "126/126 [==============================] - 0s 3ms/step - loss: 0.0287 - val_loss: 0.0160\n",
      "Epoch 40/90\n",
      "126/126 [==============================] - 0s 3ms/step - loss: 0.0290 - val_loss: 0.0160\n",
      "Epoch 41/90\n",
      "126/126 [==============================] - 0s 3ms/step - loss: 0.0289 - val_loss: 0.0160\n",
      "Epoch 42/90\n",
      "126/126 [==============================] - 0s 3ms/step - loss: 0.0291 - val_loss: 0.0160\n",
      "Epoch 43/90\n",
      "126/126 [==============================] - 0s 3ms/step - loss: 0.0286 - val_loss: 0.0160\n",
      "Epoch 44/90\n",
      "126/126 [==============================] - 0s 3ms/step - loss: 0.0286 - val_loss: 0.0160\n",
      "Epoch 45/90\n",
      "126/126 [==============================] - 0s 3ms/step - loss: 0.0287 - val_loss: 0.0160\n",
      "Epoch 46/90\n",
      "126/126 [==============================] - 0s 3ms/step - loss: 0.0287 - val_loss: 0.0160\n",
      "Epoch 47/90\n",
      "126/126 [==============================] - 0s 3ms/step - loss: 0.0286 - val_loss: 0.0160\n",
      "Epoch 48/90\n",
      "126/126 [==============================] - 0s 3ms/step - loss: 0.0287 - val_loss: 0.0160\n",
      "Epoch 49/90\n",
      "126/126 [==============================] - 0s 3ms/step - loss: 0.0288 - val_loss: 0.0159\n",
      "Epoch 50/90\n",
      "126/126 [==============================] - 0s 3ms/step - loss: 0.0286 - val_loss: 0.0160\n",
      "Epoch 51/90\n",
      "126/126 [==============================] - 0s 3ms/step - loss: 0.0287 - val_loss: 0.0160\n",
      "Epoch 52/90\n",
      "126/126 [==============================] - 0s 3ms/step - loss: 0.0286 - val_loss: 0.0160\n",
      "Epoch 53/90\n",
      "126/126 [==============================] - 0s 3ms/step - loss: 0.0286 - val_loss: 0.0160\n",
      "Epoch 54/90\n",
      "126/126 [==============================] - 0s 3ms/step - loss: 0.0288 - val_loss: 0.0160\n",
      "Epoch 55/90\n",
      "126/126 [==============================] - 0s 3ms/step - loss: 0.0286 - val_loss: 0.0160\n",
      "Epoch 56/90\n",
      "126/126 [==============================] - 0s 3ms/step - loss: 0.0287 - val_loss: 0.0160\n",
      "Epoch 57/90\n",
      "126/126 [==============================] - 0s 3ms/step - loss: 0.0286 - val_loss: 0.0160\n",
      "Epoch 58/90\n",
      "126/126 [==============================] - 0s 3ms/step - loss: 0.0287 - val_loss: 0.0160\n",
      "Epoch 59/90\n",
      "126/126 [==============================] - 0s 3ms/step - loss: 0.0285 - val_loss: 0.0160\n",
      "Epoch 60/90\n",
      "126/126 [==============================] - 0s 3ms/step - loss: 0.0285 - val_loss: 0.0160\n",
      "Epoch 61/90\n",
      "126/126 [==============================] - 0s 3ms/step - loss: 0.0284 - val_loss: 0.0160\n",
      "Epoch 62/90\n",
      "126/126 [==============================] - 0s 3ms/step - loss: 0.0285 - val_loss: 0.0160\n",
      "Epoch 63/90\n",
      "126/126 [==============================] - 0s 3ms/step - loss: 0.0284 - val_loss: 0.0160\n",
      "Epoch 64/90\n",
      "126/126 [==============================] - 0s 3ms/step - loss: 0.0284 - val_loss: 0.0160\n",
      "Epoch 65/90\n",
      "126/126 [==============================] - 0s 3ms/step - loss: 0.0284 - val_loss: 0.0160\n",
      "Epoch 66/90\n",
      "126/126 [==============================] - 0s 4ms/step - loss: 0.0284 - val_loss: 0.0160\n",
      "Epoch 67/90\n",
      "126/126 [==============================] - 0s 4ms/step - loss: 0.0283 - val_loss: 0.0160\n",
      "Epoch 68/90\n",
      "126/126 [==============================] - 0s 4ms/step - loss: 0.0283 - val_loss: 0.0160\n",
      "Epoch 69/90\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0283 - val_loss: 0.0160\n",
      "Epoch 70/90\n",
      "126/126 [==============================] - 0s 3ms/step - loss: 0.0282 - val_loss: 0.0160\n",
      "Epoch 71/90\n",
      "126/126 [==============================] - 0s 3ms/step - loss: 0.0281 - val_loss: 0.0160\n",
      "Epoch 72/90\n",
      "126/126 [==============================] - 0s 3ms/step - loss: 0.0280 - val_loss: 0.0160\n",
      "Epoch 73/90\n",
      "126/126 [==============================] - 0s 3ms/step - loss: 0.0280 - val_loss: 0.0160\n",
      "Epoch 74/90\n",
      "126/126 [==============================] - 0s 3ms/step - loss: 0.0280 - val_loss: 0.0160\n",
      "Epoch 75/90\n",
      "126/126 [==============================] - 0s 3ms/step - loss: 0.0279 - val_loss: 0.0160\n",
      "Epoch 76/90\n",
      "126/126 [==============================] - 0s 3ms/step - loss: 0.0280 - val_loss: 0.0160\n",
      "Epoch 77/90\n",
      "126/126 [==============================] - 0s 3ms/step - loss: 0.0278 - val_loss: 0.0160\n",
      "Epoch 78/90\n",
      "126/126 [==============================] - 0s 3ms/step - loss: 0.0279 - val_loss: 0.0160\n",
      "Epoch 79/90\n",
      "126/126 [==============================] - 0s 3ms/step - loss: 0.0277 - val_loss: 0.0160\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 80/90\n",
      "126/126 [==============================] - 0s 3ms/step - loss: 0.0276 - val_loss: 0.0160\n",
      "Epoch 81/90\n",
      "126/126 [==============================] - 0s 3ms/step - loss: 0.0276 - val_loss: 0.0160\n",
      "Epoch 82/90\n",
      "126/126 [==============================] - 0s 3ms/step - loss: 0.0276 - val_loss: 0.0160\n",
      "Epoch 83/90\n",
      "126/126 [==============================] - 0s 3ms/step - loss: 0.0275 - val_loss: 0.0160\n",
      "Epoch 84/90\n",
      "126/126 [==============================] - 0s 3ms/step - loss: 0.0275 - val_loss: 0.0160\n",
      "Epoch 85/90\n",
      "126/126 [==============================] - 0s 3ms/step - loss: 0.0274 - val_loss: 0.0160\n",
      "Epoch 86/90\n",
      "126/126 [==============================] - 0s 3ms/step - loss: 0.0272 - val_loss: 0.0161\n",
      "Epoch 87/90\n",
      "126/126 [==============================] - 0s 3ms/step - loss: 0.0273 - val_loss: 0.0160\n",
      "Epoch 88/90\n",
      "126/126 [==============================] - 0s 3ms/step - loss: 0.0272 - val_loss: 0.0161\n",
      "Epoch 89/90\n",
      "126/126 [==============================] - 0s 3ms/step - loss: 0.0271 - val_loss: 0.0161\n",
      "Epoch 90/90\n",
      "126/126 [==============================] - 0s 3ms/step - loss: 0.0271 - val_loss: 0.0161\n",
      "Execution time:  38.35908555984497\n",
      "DNN:\n",
      "Mean Absolute Error: 0.0245\n",
      "Root Mean Square Error: 0.0401\n",
      "Mean Square Error: 0.0016\n",
      "\n",
      "Train RMSE: 0.040\n",
      "Train MSE: 0.002\n",
      "Train MAE: 0.025\n",
      "###########################\n",
      "\n",
      "MODEL:  DNN\n",
      "sequence:  12h\n",
      "units:  12\n",
      "dropout1:  0.48476373451509647\n",
      "optimizer: adamax\n",
      "activationDense: tanh\n",
      "epochs: 52\n",
      "batchsize: 57\n",
      "validation_split: 0.2\n",
      "Model: \"sequential_137\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_411 (Dense)            (None, 72, 12)            24        \n",
      "_________________________________________________________________\n",
      "dense_412 (Dense)            (None, 72, 16)            208       \n",
      "_________________________________________________________________\n",
      "dropout_137 (Dropout)        (None, 72, 16)            0         \n",
      "_________________________________________________________________\n",
      "dense_413 (Dense)            (None, 72, 1)             17        \n",
      "=================================================================\n",
      "Total params: 249\n",
      "Trainable params: 249\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/52\n",
      "55/55 [==============================] - 0s 7ms/step - loss: 0.3019 - val_loss: 0.1354\n",
      "Epoch 2/52\n",
      "55/55 [==============================] - 0s 3ms/step - loss: 0.1348 - val_loss: 0.0388\n",
      "Epoch 3/52\n",
      "55/55 [==============================] - 0s 4ms/step - loss: 0.1139 - val_loss: 0.0320\n",
      "Epoch 4/52\n",
      "55/55 [==============================] - 0s 4ms/step - loss: 0.1026 - val_loss: 0.0243\n",
      "Epoch 5/52\n",
      "55/55 [==============================] - 0s 4ms/step - loss: 0.0937 - val_loss: 0.0186\n",
      "Epoch 6/52\n",
      "55/55 [==============================] - 0s 4ms/step - loss: 0.0856 - val_loss: 0.0169\n",
      "Epoch 7/52\n",
      "55/55 [==============================] - 0s 4ms/step - loss: 0.0789 - val_loss: 0.0186\n",
      "Epoch 8/52\n",
      "55/55 [==============================] - 0s 4ms/step - loss: 0.0734 - val_loss: 0.0190\n",
      "Epoch 9/52\n",
      "55/55 [==============================] - 0s 4ms/step - loss: 0.0686 - val_loss: 0.0171\n",
      "Epoch 10/52\n",
      "55/55 [==============================] - 0s 4ms/step - loss: 0.0633 - val_loss: 0.0158\n",
      "Epoch 11/52\n",
      "55/55 [==============================] - 0s 3ms/step - loss: 0.0583 - val_loss: 0.0153\n",
      "Epoch 12/52\n",
      "55/55 [==============================] - 0s 3ms/step - loss: 0.0539 - val_loss: 0.0148\n",
      "Epoch 13/52\n",
      "55/55 [==============================] - 0s 3ms/step - loss: 0.0496 - val_loss: 0.0148\n",
      "Epoch 14/52\n",
      "55/55 [==============================] - 0s 3ms/step - loss: 0.0456 - val_loss: 0.0153\n",
      "Epoch 15/52\n",
      "55/55 [==============================] - 0s 3ms/step - loss: 0.0423 - val_loss: 0.0164\n",
      "Epoch 16/52\n",
      "55/55 [==============================] - 0s 3ms/step - loss: 0.0393 - val_loss: 0.0176\n",
      "Epoch 17/52\n",
      "55/55 [==============================] - 0s 3ms/step - loss: 0.0365 - val_loss: 0.0169\n",
      "Epoch 18/52\n",
      "55/55 [==============================] - 0s 3ms/step - loss: 0.0347 - val_loss: 0.0169\n",
      "Epoch 19/52\n",
      "55/55 [==============================] - 0s 3ms/step - loss: 0.0333 - val_loss: 0.0172\n",
      "Epoch 20/52\n",
      "55/55 [==============================] - 0s 3ms/step - loss: 0.0319 - val_loss: 0.0174\n",
      "Epoch 21/52\n",
      "55/55 [==============================] - 0s 3ms/step - loss: 0.0308 - val_loss: 0.0173\n",
      "Epoch 22/52\n",
      "55/55 [==============================] - 0s 4ms/step - loss: 0.0299 - val_loss: 0.0172\n",
      "Epoch 23/52\n",
      "55/55 [==============================] - 0s 3ms/step - loss: 0.0291 - val_loss: 0.0168\n",
      "Epoch 24/52\n",
      "55/55 [==============================] - 0s 3ms/step - loss: 0.0286 - val_loss: 0.0166\n",
      "Epoch 25/52\n",
      "55/55 [==============================] - 0s 3ms/step - loss: 0.0280 - val_loss: 0.0166\n",
      "Epoch 26/52\n",
      "55/55 [==============================] - 0s 3ms/step - loss: 0.0271 - val_loss: 0.0169\n",
      "Epoch 27/52\n",
      "55/55 [==============================] - 0s 3ms/step - loss: 0.0267 - val_loss: 0.0167\n",
      "Epoch 28/52\n",
      "55/55 [==============================] - 0s 3ms/step - loss: 0.0266 - val_loss: 0.0169\n",
      "Epoch 29/52\n",
      "55/55 [==============================] - 0s 3ms/step - loss: 0.0264 - val_loss: 0.0171\n",
      "Epoch 30/52\n",
      "55/55 [==============================] - 0s 3ms/step - loss: 0.0263 - val_loss: 0.0173\n",
      "Epoch 31/52\n",
      "55/55 [==============================] - 0s 3ms/step - loss: 0.0262 - val_loss: 0.0173\n",
      "Epoch 32/52\n",
      "55/55 [==============================] - 0s 3ms/step - loss: 0.0262 - val_loss: 0.0175\n",
      "Epoch 33/52\n",
      "55/55 [==============================] - 0s 3ms/step - loss: 0.0261 - val_loss: 0.0175\n",
      "Epoch 34/52\n",
      "55/55 [==============================] - 0s 3ms/step - loss: 0.0260 - val_loss: 0.0176\n",
      "Epoch 35/52\n",
      "55/55 [==============================] - 0s 3ms/step - loss: 0.0260 - val_loss: 0.0176\n",
      "Epoch 36/52\n",
      "55/55 [==============================] - 0s 3ms/step - loss: 0.0259 - val_loss: 0.0175\n",
      "Epoch 37/52\n",
      "55/55 [==============================] - 0s 3ms/step - loss: 0.0259 - val_loss: 0.0175\n",
      "Epoch 38/52\n",
      "55/55 [==============================] - 0s 3ms/step - loss: 0.0258 - val_loss: 0.0175\n",
      "Epoch 39/52\n",
      "55/55 [==============================] - 0s 3ms/step - loss: 0.0258 - val_loss: 0.0174\n",
      "Epoch 40/52\n",
      "55/55 [==============================] - 0s 3ms/step - loss: 0.0257 - val_loss: 0.0174\n",
      "Epoch 41/52\n",
      "55/55 [==============================] - 0s 3ms/step - loss: 0.0256 - val_loss: 0.0173\n",
      "Epoch 42/52\n",
      "55/55 [==============================] - 0s 3ms/step - loss: 0.0256 - val_loss: 0.0173\n",
      "Epoch 43/52\n",
      "55/55 [==============================] - 0s 3ms/step - loss: 0.0255 - val_loss: 0.0173\n",
      "Epoch 44/52\n",
      "55/55 [==============================] - 0s 3ms/step - loss: 0.0255 - val_loss: 0.0173\n",
      "Epoch 45/52\n",
      "55/55 [==============================] - 0s 3ms/step - loss: 0.0254 - val_loss: 0.0172\n",
      "Epoch 46/52\n",
      "55/55 [==============================] - 0s 3ms/step - loss: 0.0254 - val_loss: 0.0172\n",
      "Epoch 47/52\n",
      "55/55 [==============================] - 0s 4ms/step - loss: 0.0254 - val_loss: 0.0172\n",
      "Epoch 48/52\n",
      "55/55 [==============================] - 0s 3ms/step - loss: 0.0253 - val_loss: 0.0172\n",
      "Epoch 49/52\n",
      "55/55 [==============================] - 0s 3ms/step - loss: 0.0252 - val_loss: 0.0172\n",
      "Epoch 50/52\n",
      "55/55 [==============================] - 0s 3ms/step - loss: 0.0252 - val_loss: 0.0172\n",
      "Epoch 51/52\n",
      "55/55 [==============================] - 0s 3ms/step - loss: 0.0251 - val_loss: 0.0171\n",
      "Epoch 52/52\n",
      "55/55 [==============================] - 0s 3ms/step - loss: 0.0250 - val_loss: 0.0171\n",
      "Execution time:  10.70771050453186\n",
      "DNN:\n",
      "Mean Absolute Error: 0.0188\n",
      "Root Mean Square Error: 0.0315\n",
      "Mean Square Error: 0.0010\n",
      "\n",
      "Train RMSE: 0.032\n",
      "Train MSE: 0.001\n",
      "Train MAE: 0.019\n",
      "###########################\n",
      "\n",
      "MODEL:  DNN\n",
      "sequence:  12h\n",
      "units:  87\n",
      "dropout1:  0.40519643149940265\n",
      "optimizer: adamax\n",
      "activationDense: sigmoid\n",
      "epochs: 80\n",
      "batchsize: 31\n",
      "validation_split: 0.1\n",
      "Model: \"sequential_138\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_414 (Dense)            (None, 72, 87)            174       \n",
      "_________________________________________________________________\n",
      "dense_415 (Dense)            (None, 72, 16)            1408      \n",
      "_________________________________________________________________\n",
      "dropout_138 (Dropout)        (None, 72, 16)            0         \n",
      "_________________________________________________________________\n",
      "dense_416 (Dense)            (None, 72, 1)             17        \n",
      "=================================================================\n",
      "Total params: 1,599\n",
      "Trainable params: 1,599\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/80\n",
      "114/114 [==============================] - 1s 5ms/step - loss: 0.0536 - val_loss: 0.0400\n",
      "Epoch 2/80\n",
      "114/114 [==============================] - 0s 3ms/step - loss: 0.0425 - val_loss: 0.0354\n",
      "Epoch 3/80\n",
      "114/114 [==============================] - 0s 4ms/step - loss: 0.0403 - val_loss: 0.0322\n",
      "Epoch 4/80\n",
      "114/114 [==============================] - 0s 4ms/step - loss: 0.0389 - val_loss: 0.0298\n",
      "Epoch 5/80\n",
      "114/114 [==============================] - 0s 3ms/step - loss: 0.0378 - val_loss: 0.0283\n",
      "Epoch 6/80\n",
      "114/114 [==============================] - 0s 4ms/step - loss: 0.0365 - val_loss: 0.0255\n",
      "Epoch 7/80\n",
      "114/114 [==============================] - 0s 3ms/step - loss: 0.0356 - val_loss: 0.0214\n",
      "Epoch 8/80\n",
      "114/114 [==============================] - 0s 3ms/step - loss: 0.0347 - val_loss: 0.0216\n",
      "Epoch 9/80\n",
      "114/114 [==============================] - 0s 3ms/step - loss: 0.0339 - val_loss: 0.0210\n",
      "Epoch 10/80\n",
      "114/114 [==============================] - 0s 3ms/step - loss: 0.0333 - val_loss: 0.0208\n",
      "Epoch 11/80\n",
      "114/114 [==============================] - 0s 3ms/step - loss: 0.0327 - val_loss: 0.0198\n",
      "Epoch 12/80\n",
      "114/114 [==============================] - 0s 3ms/step - loss: 0.0321 - val_loss: 0.0192\n",
      "Epoch 13/80\n",
      "114/114 [==============================] - 0s 4ms/step - loss: 0.0315 - val_loss: 0.0176\n",
      "Epoch 14/80\n",
      "114/114 [==============================] - 0s 4ms/step - loss: 0.0311 - val_loss: 0.0183\n",
      "Epoch 15/80\n",
      "114/114 [==============================] - 0s 4ms/step - loss: 0.0306 - val_loss: 0.0177\n",
      "Epoch 16/80\n",
      "114/114 [==============================] - 0s 4ms/step - loss: 0.0302 - val_loss: 0.0172\n",
      "Epoch 17/80\n",
      "114/114 [==============================] - 0s 4ms/step - loss: 0.0298 - val_loss: 0.0169\n",
      "Epoch 18/80\n",
      "114/114 [==============================] - 0s 4ms/step - loss: 0.0295 - val_loss: 0.0164\n",
      "Epoch 19/80\n",
      "114/114 [==============================] - 0s 3ms/step - loss: 0.0291 - val_loss: 0.0157\n",
      "Epoch 20/80\n",
      "114/114 [==============================] - 0s 3ms/step - loss: 0.0289 - val_loss: 0.0153\n",
      "Epoch 21/80\n",
      "114/114 [==============================] - 0s 3ms/step - loss: 0.0287 - val_loss: 0.0149\n",
      "Epoch 22/80\n",
      "114/114 [==============================] - 0s 4ms/step - loss: 0.0284 - val_loss: 0.0146\n",
      "Epoch 23/80\n",
      "114/114 [==============================] - 0s 3ms/step - loss: 0.0283 - val_loss: 0.0145\n",
      "Epoch 24/80\n",
      "114/114 [==============================] - 0s 3ms/step - loss: 0.0280 - val_loss: 0.0141\n",
      "Epoch 25/80\n",
      "114/114 [==============================] - 0s 3ms/step - loss: 0.0279 - val_loss: 0.0137\n",
      "Epoch 26/80\n",
      "114/114 [==============================] - 0s 3ms/step - loss: 0.0276 - val_loss: 0.0135\n",
      "Epoch 27/80\n",
      "114/114 [==============================] - 0s 4ms/step - loss: 0.0275 - val_loss: 0.0133\n",
      "Epoch 28/80\n",
      "114/114 [==============================] - 0s 4ms/step - loss: 0.0274 - val_loss: 0.0131\n",
      "Epoch 29/80\n",
      "114/114 [==============================] - 0s 4ms/step - loss: 0.0272 - val_loss: 0.0134\n",
      "Epoch 30/80\n",
      "114/114 [==============================] - 0s 4ms/step - loss: 0.0270 - val_loss: 0.0128\n",
      "Epoch 31/80\n",
      "114/114 [==============================] - 0s 4ms/step - loss: 0.0271 - val_loss: 0.0127\n",
      "Epoch 32/80\n",
      "114/114 [==============================] - 0s 3ms/step - loss: 0.0270 - val_loss: 0.0126\n",
      "Epoch 33/80\n",
      "114/114 [==============================] - 0s 3ms/step - loss: 0.0269 - val_loss: 0.0126\n",
      "Epoch 34/80\n",
      "114/114 [==============================] - 0s 3ms/step - loss: 0.0269 - val_loss: 0.0126\n",
      "Epoch 35/80\n",
      "114/114 [==============================] - 0s 3ms/step - loss: 0.0268 - val_loss: 0.0125\n",
      "Epoch 36/80\n",
      "114/114 [==============================] - 0s 3ms/step - loss: 0.0268 - val_loss: 0.0127\n",
      "Epoch 37/80\n",
      "114/114 [==============================] - 0s 4ms/step - loss: 0.0268 - val_loss: 0.0127\n",
      "Epoch 38/80\n",
      "114/114 [==============================] - 0s 3ms/step - loss: 0.0267 - val_loss: 0.0125\n",
      "Epoch 39/80\n",
      "114/114 [==============================] - 0s 4ms/step - loss: 0.0267 - val_loss: 0.0124\n",
      "Epoch 40/80\n",
      "114/114 [==============================] - 0s 3ms/step - loss: 0.0266 - val_loss: 0.0124\n",
      "Epoch 41/80\n",
      "114/114 [==============================] - 0s 4ms/step - loss: 0.0266 - val_loss: 0.0123\n",
      "Epoch 42/80\n",
      "114/114 [==============================] - 0s 3ms/step - loss: 0.0266 - val_loss: 0.0127\n",
      "Epoch 43/80\n",
      "114/114 [==============================] - 0s 3ms/step - loss: 0.0268 - val_loss: 0.0120\n",
      "Epoch 44/80\n",
      "114/114 [==============================] - 0s 3ms/step - loss: 0.0268 - val_loss: 0.0123\n",
      "Epoch 45/80\n",
      "114/114 [==============================] - 0s 3ms/step - loss: 0.0266 - val_loss: 0.0127\n",
      "Epoch 46/80\n",
      "114/114 [==============================] - 0s 3ms/step - loss: 0.0265 - val_loss: 0.0128\n",
      "Epoch 47/80\n",
      "114/114 [==============================] - 0s 4ms/step - loss: 0.0265 - val_loss: 0.0128\n",
      "Epoch 48/80\n",
      "114/114 [==============================] - 0s 4ms/step - loss: 0.0265 - val_loss: 0.0129\n",
      "Epoch 49/80\n",
      "114/114 [==============================] - 0s 3ms/step - loss: 0.0264 - val_loss: 0.0126\n",
      "Epoch 50/80\n",
      "114/114 [==============================] - 0s 4ms/step - loss: 0.0264 - val_loss: 0.0124\n",
      "Epoch 51/80\n",
      "114/114 [==============================] - 0s 3ms/step - loss: 0.0264 - val_loss: 0.0125\n",
      "Epoch 52/80\n",
      "114/114 [==============================] - 0s 4ms/step - loss: 0.0264 - val_loss: 0.0127\n",
      "Epoch 53/80\n",
      "114/114 [==============================] - 0s 4ms/step - loss: 0.0264 - val_loss: 0.0127\n",
      "Epoch 54/80\n",
      "114/114 [==============================] - 0s 4ms/step - loss: 0.0263 - val_loss: 0.0128\n",
      "Epoch 55/80\n",
      "114/114 [==============================] - 0s 4ms/step - loss: 0.0263 - val_loss: 0.0127\n",
      "Epoch 56/80\n",
      "114/114 [==============================] - 0s 4ms/step - loss: 0.0262 - val_loss: 0.0127\n",
      "Epoch 57/80\n",
      "114/114 [==============================] - 0s 4ms/step - loss: 0.0263 - val_loss: 0.0129\n",
      "Epoch 58/80\n",
      "114/114 [==============================] - 0s 4ms/step - loss: 0.0262 - val_loss: 0.0129\n",
      "Epoch 59/80\n",
      "114/114 [==============================] - 0s 4ms/step - loss: 0.0262 - val_loss: 0.0128\n",
      "Epoch 60/80\n",
      "114/114 [==============================] - 0s 4ms/step - loss: 0.0261 - val_loss: 0.0126\n",
      "Epoch 61/80\n",
      "114/114 [==============================] - 0s 3ms/step - loss: 0.0261 - val_loss: 0.0124\n",
      "Epoch 62/80\n",
      "114/114 [==============================] - 0s 3ms/step - loss: 0.0260 - val_loss: 0.0125\n",
      "Epoch 63/80\n",
      "114/114 [==============================] - 0s 4ms/step - loss: 0.0261 - val_loss: 0.0126\n",
      "Epoch 64/80\n",
      "114/114 [==============================] - 0s 3ms/step - loss: 0.0260 - val_loss: 0.0127\n",
      "Epoch 65/80\n",
      "114/114 [==============================] - 0s 3ms/step - loss: 0.0260 - val_loss: 0.0127\n",
      "Epoch 66/80\n",
      "114/114 [==============================] - 0s 4ms/step - loss: 0.0259 - val_loss: 0.0127\n",
      "Epoch 67/80\n",
      "114/114 [==============================] - 0s 3ms/step - loss: 0.0258 - val_loss: 0.0126\n",
      "Epoch 68/80\n",
      "114/114 [==============================] - 0s 3ms/step - loss: 0.0258 - val_loss: 0.0126\n",
      "Epoch 69/80\n",
      "114/114 [==============================] - 0s 4ms/step - loss: 0.0258 - val_loss: 0.0126\n",
      "Epoch 70/80\n",
      "114/114 [==============================] - 0s 3ms/step - loss: 0.0257 - val_loss: 0.0127\n",
      "Epoch 71/80\n",
      "114/114 [==============================] - 0s 4ms/step - loss: 0.0257 - val_loss: 0.0125\n",
      "Epoch 72/80\n",
      "114/114 [==============================] - 0s 3ms/step - loss: 0.0257 - val_loss: 0.0127\n",
      "Epoch 73/80\n",
      "114/114 [==============================] - 0s 4ms/step - loss: 0.0256 - val_loss: 0.0127\n",
      "Epoch 74/80\n",
      "114/114 [==============================] - 0s 3ms/step - loss: 0.0256 - val_loss: 0.0124\n",
      "Epoch 75/80\n",
      "114/114 [==============================] - 0s 3ms/step - loss: 0.0256 - val_loss: 0.0126\n",
      "Epoch 76/80\n",
      "114/114 [==============================] - 0s 4ms/step - loss: 0.0255 - val_loss: 0.0127\n",
      "Epoch 77/80\n",
      "114/114 [==============================] - 0s 4ms/step - loss: 0.0255 - val_loss: 0.0127\n",
      "Epoch 78/80\n",
      "114/114 [==============================] - 0s 4ms/step - loss: 0.0254 - val_loss: 0.0127\n",
      "Epoch 79/80\n",
      "114/114 [==============================] - 0s 3ms/step - loss: 0.0254 - val_loss: 0.0122\n",
      "Epoch 80/80\n",
      "114/114 [==============================] - 0s 3ms/step - loss: 0.0254 - val_loss: 0.0127\n",
      "Execution time:  33.901615619659424\n",
      "DNN:\n",
      "Mean Absolute Error: 0.0225\n",
      "Root Mean Square Error: 0.0390\n",
      "Mean Square Error: 0.0015\n",
      "\n",
      "Train RMSE: 0.039\n",
      "Train MSE: 0.002\n",
      "Train MAE: 0.022\n",
      "###########################\n",
      "\n",
      "MODEL:  DNN\n",
      "sequence:  12h\n",
      "units:  80\n",
      "dropout1:  0.11814836227952394\n",
      "optimizer: adamax\n",
      "activationDense: sigmoid\n",
      "epochs: 90\n",
      "batchsize: 25\n",
      "validation_split: 0.1\n",
      "Model: \"sequential_139\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_417 (Dense)            (None, 72, 80)            160       \n",
      "_________________________________________________________________\n",
      "dense_418 (Dense)            (None, 72, 16)            1296      \n",
      "_________________________________________________________________\n",
      "dropout_139 (Dropout)        (None, 72, 16)            0         \n",
      "_________________________________________________________________\n",
      "dense_419 (Dense)            (None, 72, 1)             17        \n",
      "=================================================================\n",
      "Total params: 1,473\n",
      "Trainable params: 1,473\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/90\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "142/142 [==============================] - 1s 4ms/step - loss: 0.0466 - val_loss: 0.0264\n",
      "Epoch 2/90\n",
      "142/142 [==============================] - 0s 3ms/step - loss: 0.0350 - val_loss: 0.0262\n",
      "Epoch 3/90\n",
      "142/142 [==============================] - 0s 3ms/step - loss: 0.0349 - val_loss: 0.0233\n",
      "Epoch 4/90\n",
      "142/142 [==============================] - 0s 3ms/step - loss: 0.0342 - val_loss: 0.0228\n",
      "Epoch 5/90\n",
      "142/142 [==============================] - 0s 3ms/step - loss: 0.0338 - val_loss: 0.0219\n",
      "Epoch 6/90\n",
      "142/142 [==============================] - 0s 3ms/step - loss: 0.0335 - val_loss: 0.0220\n",
      "Epoch 7/90\n",
      "142/142 [==============================] - 0s 3ms/step - loss: 0.0332 - val_loss: 0.0228\n",
      "Epoch 8/90\n",
      "142/142 [==============================] - 0s 3ms/step - loss: 0.0330 - val_loss: 0.0216\n",
      "Epoch 9/90\n",
      "142/142 [==============================] - 0s 3ms/step - loss: 0.0327 - val_loss: 0.0205\n",
      "Epoch 10/90\n",
      "142/142 [==============================] - 0s 3ms/step - loss: 0.0321 - val_loss: 0.0197\n",
      "Epoch 11/90\n",
      "142/142 [==============================] - 0s 3ms/step - loss: 0.0317 - val_loss: 0.0197\n",
      "Epoch 12/90\n",
      "142/142 [==============================] - 0s 3ms/step - loss: 0.0316 - val_loss: 0.0178\n",
      "Epoch 13/90\n",
      "142/142 [==============================] - 0s 3ms/step - loss: 0.0313 - val_loss: 0.0192\n",
      "Epoch 14/90\n",
      "142/142 [==============================] - 0s 3ms/step - loss: 0.0308 - val_loss: 0.0181\n",
      "Epoch 15/90\n",
      "142/142 [==============================] - 0s 3ms/step - loss: 0.0306 - val_loss: 0.0192\n",
      "Epoch 16/90\n",
      "142/142 [==============================] - 0s 3ms/step - loss: 0.0306 - val_loss: 0.0169\n",
      "Epoch 17/90\n",
      "142/142 [==============================] - 0s 3ms/step - loss: 0.0304 - val_loss: 0.0159\n",
      "Epoch 18/90\n",
      "142/142 [==============================] - 0s 3ms/step - loss: 0.0301 - val_loss: 0.0164\n",
      "Epoch 19/90\n",
      "142/142 [==============================] - 0s 3ms/step - loss: 0.0301 - val_loss: 0.0174\n",
      "Epoch 20/90\n",
      "142/142 [==============================] - 0s 3ms/step - loss: 0.0296 - val_loss: 0.0155\n",
      "Epoch 21/90\n",
      "142/142 [==============================] - 0s 3ms/step - loss: 0.0295 - val_loss: 0.0156\n",
      "Epoch 22/90\n",
      "142/142 [==============================] - 0s 3ms/step - loss: 0.0294 - val_loss: 0.0148\n",
      "Epoch 23/90\n",
      "142/142 [==============================] - 0s 3ms/step - loss: 0.0293 - val_loss: 0.0145\n",
      "Epoch 24/90\n",
      "142/142 [==============================] - 0s 3ms/step - loss: 0.0291 - val_loss: 0.0141\n",
      "Epoch 25/90\n",
      "142/142 [==============================] - 0s 3ms/step - loss: 0.0290 - val_loss: 0.0139\n",
      "Epoch 26/90\n",
      "142/142 [==============================] - 0s 3ms/step - loss: 0.0289 - val_loss: 0.0142\n",
      "Epoch 27/90\n",
      "142/142 [==============================] - 0s 3ms/step - loss: 0.0287 - val_loss: 0.0140\n",
      "Epoch 28/90\n",
      "142/142 [==============================] - 0s 3ms/step - loss: 0.0287 - val_loss: 0.0144\n",
      "Epoch 29/90\n",
      "142/142 [==============================] - 0s 3ms/step - loss: 0.0285 - val_loss: 0.0135\n",
      "Epoch 30/90\n",
      "142/142 [==============================] - 0s 3ms/step - loss: 0.0284 - val_loss: 0.0144\n",
      "Epoch 31/90\n",
      "142/142 [==============================] - ETA: 0s - loss: 0.029 - 0s 3ms/step - loss: 0.0283 - val_loss: 0.0142\n",
      "Epoch 32/90\n",
      "142/142 [==============================] - 0s 3ms/step - loss: 0.0282 - val_loss: 0.0142\n",
      "Epoch 33/90\n",
      "142/142 [==============================] - 0s 3ms/step - loss: 0.0281 - val_loss: 0.0141\n",
      "Epoch 34/90\n",
      "142/142 [==============================] - 0s 3ms/step - loss: 0.0280 - val_loss: 0.0138\n",
      "Epoch 35/90\n",
      "142/142 [==============================] - 0s 3ms/step - loss: 0.0280 - val_loss: 0.0140\n",
      "Epoch 36/90\n",
      "142/142 [==============================] - 0s 3ms/step - loss: 0.0279 - val_loss: 0.0131\n",
      "Epoch 37/90\n",
      "142/142 [==============================] - 0s 3ms/step - loss: 0.0278 - val_loss: 0.0136\n",
      "Epoch 38/90\n",
      "142/142 [==============================] - 0s 3ms/step - loss: 0.0278 - val_loss: 0.0134\n",
      "Epoch 39/90\n",
      "142/142 [==============================] - 0s 3ms/step - loss: 0.0277 - val_loss: 0.0134\n",
      "Epoch 40/90\n",
      "142/142 [==============================] - 0s 3ms/step - loss: 0.0278 - val_loss: 0.0124\n",
      "Epoch 41/90\n",
      "142/142 [==============================] - 0s 3ms/step - loss: 0.0276 - val_loss: 0.0132\n",
      "Epoch 42/90\n",
      "142/142 [==============================] - 0s 3ms/step - loss: 0.0276 - val_loss: 0.0130\n",
      "Epoch 43/90\n",
      "142/142 [==============================] - 0s 3ms/step - loss: 0.0274 - val_loss: 0.0131\n",
      "Epoch 44/90\n",
      "142/142 [==============================] - 0s 3ms/step - loss: 0.0275 - val_loss: 0.0123\n",
      "Epoch 45/90\n",
      "142/142 [==============================] - 0s 3ms/step - loss: 0.0274 - val_loss: 0.0128\n",
      "Epoch 46/90\n",
      "142/142 [==============================] - 0s 3ms/step - loss: 0.0274 - val_loss: 0.0127\n",
      "Epoch 47/90\n",
      "142/142 [==============================] - 0s 3ms/step - loss: 0.0273 - val_loss: 0.0125\n",
      "Epoch 48/90\n",
      "142/142 [==============================] - 0s 3ms/step - loss: 0.0272 - val_loss: 0.0125\n",
      "Epoch 49/90\n",
      "142/142 [==============================] - 0s 3ms/step - loss: 0.0272 - val_loss: 0.0123\n",
      "Epoch 50/90\n",
      "142/142 [==============================] - 0s 3ms/step - loss: 0.0272 - val_loss: 0.0122\n",
      "Epoch 51/90\n",
      "142/142 [==============================] - 0s 3ms/step - loss: 0.0271 - val_loss: 0.0122\n",
      "Epoch 52/90\n",
      "142/142 [==============================] - 0s 3ms/step - loss: 0.0271 - val_loss: 0.0123\n",
      "Epoch 53/90\n",
      "142/142 [==============================] - 0s 3ms/step - loss: 0.0272 - val_loss: 0.0116\n",
      "Epoch 54/90\n",
      "142/142 [==============================] - 0s 3ms/step - loss: 0.0271 - val_loss: 0.0115\n",
      "Epoch 55/90\n",
      "142/142 [==============================] - 0s 3ms/step - loss: 0.0270 - val_loss: 0.0117\n",
      "Epoch 56/90\n",
      "142/142 [==============================] - 0s 3ms/step - loss: 0.0269 - val_loss: 0.0116\n",
      "Epoch 57/90\n",
      "142/142 [==============================] - 0s 3ms/step - loss: 0.0269 - val_loss: 0.0115\n",
      "Epoch 58/90\n",
      "142/142 [==============================] - 0s 3ms/step - loss: 0.0269 - val_loss: 0.0114\n",
      "Epoch 59/90\n",
      "142/142 [==============================] - 0s 3ms/step - loss: 0.0269 - val_loss: 0.0114\n",
      "Epoch 60/90\n",
      "142/142 [==============================] - 0s 3ms/step - loss: 0.0268 - val_loss: 0.0114\n",
      "Epoch 61/90\n",
      "142/142 [==============================] - 0s 3ms/step - loss: 0.0268 - val_loss: 0.0114\n",
      "Epoch 62/90\n",
      "142/142 [==============================] - 0s 3ms/step - loss: 0.0268 - val_loss: 0.0115\n",
      "Epoch 63/90\n",
      "142/142 [==============================] - 0s 3ms/step - loss: 0.0267 - val_loss: 0.0114\n",
      "Epoch 64/90\n",
      "142/142 [==============================] - 0s 3ms/step - loss: 0.0267 - val_loss: 0.0114\n",
      "Epoch 65/90\n",
      "142/142 [==============================] - 0s 3ms/step - loss: 0.0267 - val_loss: 0.0113\n",
      "Epoch 66/90\n",
      "142/142 [==============================] - 0s 3ms/step - loss: 0.0267 - val_loss: 0.0114\n",
      "Epoch 67/90\n",
      "142/142 [==============================] - 0s 3ms/step - loss: 0.0266 - val_loss: 0.0112\n",
      "Epoch 68/90\n",
      "142/142 [==============================] - 0s 3ms/step - loss: 0.0266 - val_loss: 0.0113\n",
      "Epoch 69/90\n",
      "142/142 [==============================] - 0s 3ms/step - loss: 0.0265 - val_loss: 0.0112\n",
      "Epoch 70/90\n",
      "142/142 [==============================] - 0s 3ms/step - loss: 0.0265 - val_loss: 0.0113\n",
      "Epoch 71/90\n",
      "142/142 [==============================] - 0s 3ms/step - loss: 0.0265 - val_loss: 0.0112\n",
      "Epoch 72/90\n",
      "142/142 [==============================] - 0s 3ms/step - loss: 0.0265 - val_loss: 0.0110\n",
      "Epoch 73/90\n",
      "142/142 [==============================] - 0s 3ms/step - loss: 0.0264 - val_loss: 0.0109\n",
      "Epoch 74/90\n",
      "142/142 [==============================] - 0s 3ms/step - loss: 0.0264 - val_loss: 0.0107\n",
      "Epoch 75/90\n",
      "142/142 [==============================] - 0s 3ms/step - loss: 0.0264 - val_loss: 0.0107\n",
      "Epoch 76/90\n",
      "142/142 [==============================] - 0s 3ms/step - loss: 0.0264 - val_loss: 0.0106\n",
      "Epoch 77/90\n",
      "142/142 [==============================] - 0s 3ms/step - loss: 0.0263 - val_loss: 0.0105\n",
      "Epoch 78/90\n",
      "142/142 [==============================] - 0s 3ms/step - loss: 0.0263 - val_loss: 0.0103\n",
      "Epoch 79/90\n",
      "142/142 [==============================] - 0s 3ms/step - loss: 0.0263 - val_loss: 0.0106\n",
      "Epoch 80/90\n",
      "142/142 [==============================] - 0s 3ms/step - loss: 0.0262 - val_loss: 0.0106\n",
      "Epoch 81/90\n",
      "142/142 [==============================] - 0s 3ms/step - loss: 0.0261 - val_loss: 0.0106\n",
      "Epoch 82/90\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "142/142 [==============================] - 0s 3ms/step - loss: 0.0261 - val_loss: 0.0105\n",
      "Epoch 83/90\n",
      "142/142 [==============================] - 0s 3ms/step - loss: 0.0260 - val_loss: 0.0108\n",
      "Epoch 84/90\n",
      "142/142 [==============================] - 0s 3ms/step - loss: 0.0259 - val_loss: 0.0104\n",
      "Epoch 85/90\n",
      "142/142 [==============================] - 0s 3ms/step - loss: 0.0259 - val_loss: 0.0107\n",
      "Epoch 86/90\n",
      "142/142 [==============================] - 0s 3ms/step - loss: 0.0258 - val_loss: 0.0106\n",
      "Epoch 87/90\n",
      "142/142 [==============================] - 0s 3ms/step - loss: 0.0258 - val_loss: 0.0104\n",
      "Epoch 88/90\n",
      "142/142 [==============================] - 0s 3ms/step - loss: 0.0258 - val_loss: 0.0105\n",
      "Epoch 89/90\n",
      "142/142 [==============================] - 0s 3ms/step - loss: 0.0257 - val_loss: 0.0117\n",
      "Epoch 90/90\n",
      "142/142 [==============================] - 0s 3ms/step - loss: 0.0257 - val_loss: 0.0106\n",
      "Execution time:  39.81014561653137\n",
      "DNN:\n",
      "Mean Absolute Error: 0.0227\n",
      "Root Mean Square Error: 0.0394\n",
      "Mean Square Error: 0.0016\n",
      "\n",
      "Train RMSE: 0.039\n",
      "Train MSE: 0.002\n",
      "Train MAE: 0.023\n",
      "###########################\n",
      "\n",
      "MODEL:  DNN\n",
      "sequence:  12h\n",
      "units:  12\n",
      "dropout1:  0.48476373451509647\n",
      "optimizer: adamax\n",
      "activationDense: sigmoid\n",
      "epochs: 52\n",
      "batchsize: 57\n",
      "validation_split: 0.1\n",
      "Model: \"sequential_140\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_420 (Dense)            (None, 72, 12)            24        \n",
      "_________________________________________________________________\n",
      "dense_421 (Dense)            (None, 72, 16)            208       \n",
      "_________________________________________________________________\n",
      "dropout_140 (Dropout)        (None, 72, 16)            0         \n",
      "_________________________________________________________________\n",
      "dense_422 (Dense)            (None, 72, 1)             17        \n",
      "=================================================================\n",
      "Total params: 249\n",
      "Trainable params: 249\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/52\n",
      "62/62 [==============================] - 0s 6ms/step - loss: 0.0749 - val_loss: 0.0770\n",
      "Epoch 2/52\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.0464 - val_loss: 0.0512\n",
      "Epoch 3/52\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.0434 - val_loss: 0.0466\n",
      "Epoch 4/52\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.0416 - val_loss: 0.0444\n",
      "Epoch 5/52\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.0400 - val_loss: 0.0422\n",
      "Epoch 6/52\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.0387 - val_loss: 0.0395\n",
      "Epoch 7/52\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.0377 - val_loss: 0.0376\n",
      "Epoch 8/52\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.0369 - val_loss: 0.0365\n",
      "Epoch 9/52\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.0361 - val_loss: 0.0355\n",
      "Epoch 10/52\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.0355 - val_loss: 0.0348\n",
      "Epoch 11/52\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.0348 - val_loss: 0.0342\n",
      "Epoch 12/52\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.0343 - val_loss: 0.0330\n",
      "Epoch 13/52\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.0338 - val_loss: 0.0322\n",
      "Epoch 14/52\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.0332 - val_loss: 0.0315\n",
      "Epoch 15/52\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.0327 - val_loss: 0.0308\n",
      "Epoch 16/52\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.0323 - val_loss: 0.0302\n",
      "Epoch 17/52\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.0319 - val_loss: 0.0298\n",
      "Epoch 18/52\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.0315 - val_loss: 0.0292\n",
      "Epoch 19/52\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.0311 - val_loss: 0.0288\n",
      "Epoch 20/52\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.0307 - val_loss: 0.0282\n",
      "Epoch 21/52\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.0305 - val_loss: 0.0279\n",
      "Epoch 22/52\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.0301 - val_loss: 0.0274\n",
      "Epoch 23/52\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.0298 - val_loss: 0.0266\n",
      "Epoch 24/52\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.0294 - val_loss: 0.0257\n",
      "Epoch 25/52\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.0291 - val_loss: 0.0252\n",
      "Epoch 26/52\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.0289 - val_loss: 0.0242\n",
      "Epoch 27/52\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.0286 - val_loss: 0.0230\n",
      "Epoch 28/52\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.0283 - val_loss: 0.0221\n",
      "Epoch 29/52\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.0283 - val_loss: 0.0218\n",
      "Epoch 30/52\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.0281 - val_loss: 0.0215\n",
      "Epoch 31/52\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.0279 - val_loss: 0.0207\n",
      "Epoch 32/52\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.0279 - val_loss: 0.0207\n",
      "Epoch 33/52\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.0278 - val_loss: 0.0207\n",
      "Epoch 34/52\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.0276 - val_loss: 0.0204\n",
      "Epoch 35/52\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.0275 - val_loss: 0.0197\n",
      "Epoch 36/52\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.0276 - val_loss: 0.0201\n",
      "Epoch 37/52\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.0273 - val_loss: 0.0193\n",
      "Epoch 38/52\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.0273 - val_loss: 0.0192\n",
      "Epoch 39/52\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.0273 - val_loss: 0.0196\n",
      "Epoch 40/52\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.0272 - val_loss: 0.0189\n",
      "Epoch 41/52\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.0271 - val_loss: 0.0189\n",
      "Epoch 42/52\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.0271 - val_loss: 0.0191\n",
      "Epoch 43/52\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.0270 - val_loss: 0.0190\n",
      "Epoch 44/52\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.0269 - val_loss: 0.0189\n",
      "Epoch 45/52\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.0269 - val_loss: 0.0188\n",
      "Epoch 46/52\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.0268 - val_loss: 0.0188\n",
      "Epoch 47/52\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.0268 - val_loss: 0.0186\n",
      "Epoch 48/52\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.0268 - val_loss: 0.0186\n",
      "Epoch 49/52\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.0267 - val_loss: 0.0184\n",
      "Epoch 50/52\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.0266 - val_loss: 0.0183\n",
      "Epoch 51/52\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.0266 - val_loss: 0.0182\n",
      "Epoch 52/52\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.0265 - val_loss: 0.0181\n",
      "Execution time:  12.661014795303345\n",
      "DNN:\n",
      "Mean Absolute Error: 0.0252\n",
      "Root Mean Square Error: 0.0414\n",
      "Mean Square Error: 0.0017\n",
      "\n",
      "Train RMSE: 0.041\n",
      "Train MSE: 0.002\n",
      "Train MAE: 0.025\n",
      "###########################\n",
      "\n",
      "MODEL:  DNN\n",
      "sequence:  12h\n",
      "units:  87\n",
      "dropout1:  0.40519643149940265\n",
      "optimizer: adamax\n",
      "activationDense: sigmoid\n",
      "epochs: 80\n",
      "batchsize: 31\n",
      "validation_split: 0.2\n",
      "Model: \"sequential_141\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_423 (Dense)            (None, 72, 87)            174       \n",
      "_________________________________________________________________\n",
      "dense_424 (Dense)            (None, 72, 16)            1408      \n",
      "_________________________________________________________________\n",
      "dropout_141 (Dropout)        (None, 72, 16)            0         \n",
      "_________________________________________________________________\n",
      "dense_425 (Dense)            (None, 72, 1)             17        \n",
      "=================================================================\n",
      "Total params: 1,599\n",
      "Trainable params: 1,599\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/80\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "102/102 [==============================] - 1s 5ms/step - loss: 0.0501 - val_loss: 0.0378\n",
      "Epoch 2/80\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.0447 - val_loss: 0.0355\n",
      "Epoch 3/80\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.0430 - val_loss: 0.0345\n",
      "Epoch 4/80\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.0414 - val_loss: 0.0312\n",
      "Epoch 5/80\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.0401 - val_loss: 0.0290\n",
      "Epoch 6/80\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.0389 - val_loss: 0.0282\n",
      "Epoch 7/80\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.0378 - val_loss: 0.0270\n",
      "Epoch 8/80\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.0368 - val_loss: 0.0254\n",
      "Epoch 9/80\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.0360 - val_loss: 0.0243\n",
      "Epoch 10/80\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.0353 - val_loss: 0.0233\n",
      "Epoch 11/80\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.0346 - val_loss: 0.0227\n",
      "Epoch 12/80\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.0338 - val_loss: 0.0216\n",
      "Epoch 13/80\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.0332 - val_loss: 0.0209\n",
      "Epoch 14/80\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.0326 - val_loss: 0.0207\n",
      "Epoch 15/80\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.0320 - val_loss: 0.0201\n",
      "Epoch 16/80\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.0317 - val_loss: 0.0199\n",
      "Epoch 17/80\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.0311 - val_loss: 0.0197\n",
      "Epoch 18/80\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.0307 - val_loss: 0.0194\n",
      "Epoch 19/80\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.0304 - val_loss: 0.0193\n",
      "Epoch 20/80\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.0299 - val_loss: 0.0188\n",
      "Epoch 21/80\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.0297 - val_loss: 0.0188\n",
      "Epoch 22/80\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.0294 - val_loss: 0.0185\n",
      "Epoch 23/80\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.0292 - val_loss: 0.0184\n",
      "Epoch 24/80\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.0290 - val_loss: 0.0183\n",
      "Epoch 25/80\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.0287 - val_loss: 0.0181\n",
      "Epoch 26/80\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.0287 - val_loss: 0.0179\n",
      "Epoch 27/80\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.0285 - val_loss: 0.0177\n",
      "Epoch 28/80\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.0284 - val_loss: 0.0177\n",
      "Epoch 29/80\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.0283 - val_loss: 0.0177\n",
      "Epoch 30/80\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.0282 - val_loss: 0.0175\n",
      "Epoch 31/80\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.0281 - val_loss: 0.0176\n",
      "Epoch 32/80\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.0280 - val_loss: 0.0176\n",
      "Epoch 33/80\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.0279 - val_loss: 0.0175\n",
      "Epoch 34/80\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.0279 - val_loss: 0.0175\n",
      "Epoch 35/80\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.0278 - val_loss: 0.0175\n",
      "Epoch 36/80\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.0278 - val_loss: 0.0174\n",
      "Epoch 37/80\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.0277 - val_loss: 0.0174\n",
      "Epoch 38/80\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.0276 - val_loss: 0.0174\n",
      "Epoch 39/80\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.0276 - val_loss: 0.0173\n",
      "Epoch 40/80\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.0276 - val_loss: 0.0174\n",
      "Epoch 41/80\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.0275 - val_loss: 0.0173\n",
      "Epoch 42/80\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.0275 - val_loss: 0.0173\n",
      "Epoch 43/80\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.0275 - val_loss: 0.0173\n",
      "Epoch 44/80\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.0273 - val_loss: 0.0172\n",
      "Epoch 45/80\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.0273 - val_loss: 0.0172\n",
      "Epoch 46/80\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.0273 - val_loss: 0.0172\n",
      "Epoch 47/80\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.0273 - val_loss: 0.0172\n",
      "Epoch 48/80\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.0272 - val_loss: 0.0172\n",
      "Epoch 49/80\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.0272 - val_loss: 0.0172\n",
      "Epoch 50/80\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.0271 - val_loss: 0.0172\n",
      "Epoch 51/80\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.0271 - val_loss: 0.0171\n",
      "Epoch 52/80\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.0271 - val_loss: 0.0171\n",
      "Epoch 53/80\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.0271 - val_loss: 0.0171\n",
      "Epoch 54/80\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.0270 - val_loss: 0.0170\n",
      "Epoch 55/80\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.0270 - val_loss: 0.0171\n",
      "Epoch 56/80\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.0269 - val_loss: 0.0170\n",
      "Epoch 57/80\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.0268 - val_loss: 0.0170\n",
      "Epoch 58/80\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.0268 - val_loss: 0.0171\n",
      "Epoch 59/80\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.0270 - val_loss: 0.0172\n",
      "Epoch 60/80\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.0267 - val_loss: 0.0170\n",
      "Epoch 61/80\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.0267 - val_loss: 0.0170\n",
      "Epoch 62/80\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.0266 - val_loss: 0.0169\n",
      "Epoch 63/80\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.0266 - val_loss: 0.0169\n",
      "Epoch 64/80\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.0265 - val_loss: 0.0169\n",
      "Epoch 65/80\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.0265 - val_loss: 0.0168\n",
      "Epoch 66/80\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.0265 - val_loss: 0.0169\n",
      "Epoch 67/80\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.0264 - val_loss: 0.0169\n",
      "Epoch 68/80\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.0263 - val_loss: 0.0168\n",
      "Epoch 69/80\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.0264 - val_loss: 0.0169\n",
      "Epoch 70/80\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.0261 - val_loss: 0.0167\n",
      "Epoch 71/80\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.0261 - val_loss: 0.0166\n",
      "Epoch 72/80\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.0260 - val_loss: 0.0166\n",
      "Epoch 73/80\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.0259 - val_loss: 0.0164\n",
      "Epoch 74/80\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.0259 - val_loss: 0.0163\n",
      "Epoch 75/80\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.0259 - val_loss: 0.0162\n",
      "Epoch 76/80\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.0259 - val_loss: 0.0163\n",
      "Epoch 77/80\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.0258 - val_loss: 0.0163\n",
      "Epoch 78/80\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.0258 - val_loss: 0.0160\n",
      "Epoch 79/80\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.0257 - val_loss: 0.0158\n",
      "Epoch 80/80\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.0257 - val_loss: 0.0159\n",
      "Execution time:  31.364622831344604\n",
      "DNN:\n",
      "Mean Absolute Error: 0.0203\n",
      "Root Mean Square Error: 0.0372\n",
      "Mean Square Error: 0.0014\n",
      "\n",
      "Train RMSE: 0.037\n",
      "Train MSE: 0.001\n",
      "Train MAE: 0.020\n",
      "###########################\n",
      "\n",
      "MODEL:  DNN\n",
      "sequence:  12h\n",
      "units:  80\n",
      "dropout1:  0.11814836227952394\n",
      "optimizer: adamax\n",
      "activationDense: sigmoid\n",
      "epochs: 90\n",
      "batchsize: 25\n",
      "validation_split: 0.2\n",
      "Model: \"sequential_142\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_426 (Dense)            (None, 72, 80)            160       \n",
      "_________________________________________________________________\n",
      "dense_427 (Dense)            (None, 72, 16)            1296      \n",
      "_________________________________________________________________\n",
      "dropout_142 (Dropout)        (None, 72, 16)            0         \n",
      "_________________________________________________________________\n",
      "dense_428 (Dense)            (None, 72, 1)             17        \n",
      "=================================================================\n",
      "Total params: 1,473\n",
      "Trainable params: 1,473\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/90\n",
      "126/126 [==============================] - 1s 5ms/step - loss: 0.0555 - val_loss: 0.0207\n",
      "Epoch 2/90\n",
      "126/126 [==============================] - 0s 3ms/step - loss: 0.0351 - val_loss: 0.0192\n",
      "Epoch 3/90\n",
      "126/126 [==============================] - 0s 4ms/step - loss: 0.0345 - val_loss: 0.0192\n",
      "Epoch 4/90\n",
      "126/126 [==============================] - 0s 3ms/step - loss: 0.0343 - val_loss: 0.0189\n",
      "Epoch 5/90\n",
      "126/126 [==============================] - 0s 3ms/step - loss: 0.0340 - val_loss: 0.0190\n",
      "Epoch 6/90\n",
      "126/126 [==============================] - 0s 3ms/step - loss: 0.0336 - val_loss: 0.0190\n",
      "Epoch 7/90\n",
      "126/126 [==============================] - 0s 3ms/step - loss: 0.0338 - val_loss: 0.0187\n",
      "Epoch 8/90\n",
      "126/126 [==============================] - 0s 3ms/step - loss: 0.0332 - val_loss: 0.0189\n",
      "Epoch 9/90\n",
      "126/126 [==============================] - 0s 3ms/step - loss: 0.0330 - val_loss: 0.0187\n",
      "Epoch 10/90\n",
      "126/126 [==============================] - 0s 3ms/step - loss: 0.0328 - val_loss: 0.0186\n",
      "Epoch 11/90\n",
      "126/126 [==============================] - 0s 3ms/step - loss: 0.0325 - val_loss: 0.0186\n",
      "Epoch 12/90\n",
      "126/126 [==============================] - 0s 3ms/step - loss: 0.0323 - val_loss: 0.0184\n",
      "Epoch 13/90\n",
      "126/126 [==============================] - 0s 3ms/step - loss: 0.0321 - val_loss: 0.0184\n",
      "Epoch 14/90\n",
      "126/126 [==============================] - 0s 3ms/step - loss: 0.0319 - val_loss: 0.0183\n",
      "Epoch 15/90\n",
      "126/126 [==============================] - 0s 3ms/step - loss: 0.0317 - val_loss: 0.0184\n",
      "Epoch 16/90\n",
      "126/126 [==============================] - 0s 3ms/step - loss: 0.0315 - val_loss: 0.0183\n",
      "Epoch 17/90\n",
      "126/126 [==============================] - 0s 3ms/step - loss: 0.0314 - val_loss: 0.0183\n",
      "Epoch 18/90\n",
      "126/126 [==============================] - 0s 3ms/step - loss: 0.0312 - val_loss: 0.0182\n",
      "Epoch 19/90\n",
      "126/126 [==============================] - 0s 3ms/step - loss: 0.0311 - val_loss: 0.0181\n",
      "Epoch 20/90\n",
      "126/126 [==============================] - 0s 3ms/step - loss: 0.0309 - val_loss: 0.0181\n",
      "Epoch 21/90\n",
      "126/126 [==============================] - 0s 3ms/step - loss: 0.0308 - val_loss: 0.0180\n",
      "Epoch 22/90\n",
      "126/126 [==============================] - 0s 3ms/step - loss: 0.0306 - val_loss: 0.0180\n",
      "Epoch 23/90\n",
      "126/126 [==============================] - 0s 3ms/step - loss: 0.0305 - val_loss: 0.0180\n",
      "Epoch 24/90\n",
      "126/126 [==============================] - 0s 3ms/step - loss: 0.0303 - val_loss: 0.0179\n",
      "Epoch 25/90\n",
      "126/126 [==============================] - 0s 3ms/step - loss: 0.0302 - val_loss: 0.0179\n",
      "Epoch 26/90\n",
      "126/126 [==============================] - 0s 3ms/step - loss: 0.0301 - val_loss: 0.0178\n",
      "Epoch 27/90\n",
      "126/126 [==============================] - 0s 3ms/step - loss: 0.0299 - val_loss: 0.0178\n",
      "Epoch 28/90\n",
      "126/126 [==============================] - 0s 3ms/step - loss: 0.0299 - val_loss: 0.0178\n",
      "Epoch 29/90\n",
      "126/126 [==============================] - 0s 3ms/step - loss: 0.0298 - val_loss: 0.0178\n",
      "Epoch 30/90\n",
      "126/126 [==============================] - 0s 3ms/step - loss: 0.0296 - val_loss: 0.0178\n",
      "Epoch 31/90\n",
      "126/126 [==============================] - 0s 3ms/step - loss: 0.0296 - val_loss: 0.0178\n",
      "Epoch 32/90\n",
      "126/126 [==============================] - 0s 3ms/step - loss: 0.0295 - val_loss: 0.0178\n",
      "Epoch 33/90\n",
      "126/126 [==============================] - 0s 3ms/step - loss: 0.0294 - val_loss: 0.0179\n",
      "Epoch 34/90\n",
      "126/126 [==============================] - 0s 3ms/step - loss: 0.0292 - val_loss: 0.0177\n",
      "Epoch 35/90\n",
      "126/126 [==============================] - 0s 3ms/step - loss: 0.0291 - val_loss: 0.0177\n",
      "Epoch 36/90\n",
      "126/126 [==============================] - 0s 3ms/step - loss: 0.0290 - val_loss: 0.0177\n",
      "Epoch 37/90\n",
      "126/126 [==============================] - 0s 4ms/step - loss: 0.0289 - val_loss: 0.0177\n",
      "Epoch 38/90\n",
      "126/126 [==============================] - 0s 3ms/step - loss: 0.0289 - val_loss: 0.0176\n",
      "Epoch 39/90\n",
      "126/126 [==============================] - 0s 3ms/step - loss: 0.0287 - val_loss: 0.0177\n",
      "Epoch 40/90\n",
      "126/126 [==============================] - 0s 3ms/step - loss: 0.0286 - val_loss: 0.0175\n",
      "Epoch 41/90\n",
      "126/126 [==============================] - 0s 3ms/step - loss: 0.0285 - val_loss: 0.0176\n",
      "Epoch 42/90\n",
      "126/126 [==============================] - 0s 3ms/step - loss: 0.0285 - val_loss: 0.0174\n",
      "Epoch 43/90\n",
      "126/126 [==============================] - 0s 3ms/step - loss: 0.0284 - val_loss: 0.0175\n",
      "Epoch 44/90\n",
      "126/126 [==============================] - 0s 3ms/step - loss: 0.0283 - val_loss: 0.0174\n",
      "Epoch 45/90\n",
      "126/126 [==============================] - 0s 3ms/step - loss: 0.0282 - val_loss: 0.0174\n",
      "Epoch 46/90\n",
      "126/126 [==============================] - 0s 3ms/step - loss: 0.0282 - val_loss: 0.0174\n",
      "Epoch 47/90\n",
      "126/126 [==============================] - 0s 3ms/step - loss: 0.0281 - val_loss: 0.0173\n",
      "Epoch 48/90\n",
      "126/126 [==============================] - 0s 3ms/step - loss: 0.0280 - val_loss: 0.0173\n",
      "Epoch 49/90\n",
      "126/126 [==============================] - 0s 3ms/step - loss: 0.0280 - val_loss: 0.0173\n",
      "Epoch 50/90\n",
      "126/126 [==============================] - 0s 3ms/step - loss: 0.0279 - val_loss: 0.0171\n",
      "Epoch 51/90\n",
      "126/126 [==============================] - 0s 3ms/step - loss: 0.0279 - val_loss: 0.0171\n",
      "Epoch 52/90\n",
      "126/126 [==============================] - 0s 3ms/step - loss: 0.0278 - val_loss: 0.0171\n",
      "Epoch 53/90\n",
      "126/126 [==============================] - 0s 3ms/step - loss: 0.0277 - val_loss: 0.0171\n",
      "Epoch 54/90\n",
      "126/126 [==============================] - 0s 3ms/step - loss: 0.0276 - val_loss: 0.0170\n",
      "Epoch 55/90\n",
      "126/126 [==============================] - 0s 3ms/step - loss: 0.0276 - val_loss: 0.0169\n",
      "Epoch 56/90\n",
      "126/126 [==============================] - 0s 3ms/step - loss: 0.0275 - val_loss: 0.0169\n",
      "Epoch 57/90\n",
      "126/126 [==============================] - 0s 3ms/step - loss: 0.0275 - val_loss: 0.0168\n",
      "Epoch 58/90\n",
      "126/126 [==============================] - 0s 3ms/step - loss: 0.0274 - val_loss: 0.0168\n",
      "Epoch 59/90\n",
      "126/126 [==============================] - 0s 3ms/step - loss: 0.0273 - val_loss: 0.0167\n",
      "Epoch 60/90\n",
      "126/126 [==============================] - 0s 3ms/step - loss: 0.0272 - val_loss: 0.0168\n",
      "Epoch 61/90\n",
      "126/126 [==============================] - 0s 3ms/step - loss: 0.0272 - val_loss: 0.0166\n",
      "Epoch 62/90\n",
      "126/126 [==============================] - 0s 3ms/step - loss: 0.0270 - val_loss: 0.0167\n",
      "Epoch 63/90\n",
      "126/126 [==============================] - 0s 3ms/step - loss: 0.0270 - val_loss: 0.0166\n",
      "Epoch 64/90\n",
      "126/126 [==============================] - 0s 3ms/step - loss: 0.0269 - val_loss: 0.0166\n",
      "Epoch 65/90\n",
      "126/126 [==============================] - 0s 3ms/step - loss: 0.0268 - val_loss: 0.0166\n",
      "Epoch 66/90\n",
      "126/126 [==============================] - 0s 3ms/step - loss: 0.0267 - val_loss: 0.0166\n",
      "Epoch 67/90\n",
      "126/126 [==============================] - 0s 3ms/step - loss: 0.0267 - val_loss: 0.0166\n",
      "Epoch 68/90\n",
      "126/126 [==============================] - 0s 3ms/step - loss: 0.0265 - val_loss: 0.0166\n",
      "Epoch 69/90\n",
      "126/126 [==============================] - 0s 3ms/step - loss: 0.0264 - val_loss: 0.0166\n",
      "Epoch 70/90\n",
      "126/126 [==============================] - 0s 3ms/step - loss: 0.0263 - val_loss: 0.0166\n",
      "Epoch 71/90\n",
      "126/126 [==============================] - 0s 3ms/step - loss: 0.0262 - val_loss: 0.0166\n",
      "Epoch 72/90\n",
      "126/126 [==============================] - 0s 3ms/step - loss: 0.0261 - val_loss: 0.0165\n",
      "Epoch 73/90\n",
      "126/126 [==============================] - 0s 3ms/step - loss: 0.0259 - val_loss: 0.0165\n",
      "Epoch 74/90\n",
      "126/126 [==============================] - 0s 3ms/step - loss: 0.0257 - val_loss: 0.0166\n",
      "Epoch 75/90\n",
      "126/126 [==============================] - 0s 3ms/step - loss: 0.0257 - val_loss: 0.0161\n",
      "Epoch 76/90\n",
      "126/126 [==============================] - 0s 4ms/step - loss: 0.0255 - val_loss: 0.0163\n",
      "Epoch 77/90\n",
      "126/126 [==============================] - 0s 3ms/step - loss: 0.0253 - val_loss: 0.0159\n",
      "Epoch 78/90\n",
      "126/126 [==============================] - 0s 3ms/step - loss: 0.0251 - val_loss: 0.0160\n",
      "Epoch 79/90\n",
      "126/126 [==============================] - 0s 3ms/step - loss: 0.0249 - val_loss: 0.0159\n",
      "Epoch 80/90\n",
      "126/126 [==============================] - 0s 3ms/step - loss: 0.0247 - val_loss: 0.0159\n",
      "Epoch 81/90\n",
      "126/126 [==============================] - 0s 3ms/step - loss: 0.0245 - val_loss: 0.0159\n",
      "Epoch 82/90\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "126/126 [==============================] - 0s 3ms/step - loss: 0.0243 - val_loss: 0.0159\n",
      "Epoch 83/90\n",
      "126/126 [==============================] - 0s 3ms/step - loss: 0.0242 - val_loss: 0.0159\n",
      "Epoch 84/90\n",
      "126/126 [==============================] - 0s 3ms/step - loss: 0.0240 - val_loss: 0.0158\n",
      "Epoch 85/90\n",
      "126/126 [==============================] - 0s 3ms/step - loss: 0.0238 - val_loss: 0.0158\n",
      "Epoch 86/90\n",
      "126/126 [==============================] - 0s 3ms/step - loss: 0.0237 - val_loss: 0.0158\n",
      "Epoch 87/90\n",
      "126/126 [==============================] - 0s 3ms/step - loss: 0.0237 - val_loss: 0.0158\n",
      "Epoch 88/90\n",
      "126/126 [==============================] - 0s 3ms/step - loss: 0.0235 - val_loss: 0.0159\n",
      "Epoch 89/90\n",
      "126/126 [==============================] - 0s 3ms/step - loss: 0.0234 - val_loss: 0.0158\n",
      "Epoch 90/90\n",
      "126/126 [==============================] - 0s 3ms/step - loss: 0.0233 - val_loss: 0.0158\n",
      "Execution time:  37.747394323349\n",
      "DNN:\n",
      "Mean Absolute Error: 0.0175\n",
      "Root Mean Square Error: 0.0321\n",
      "Mean Square Error: 0.0010\n",
      "\n",
      "Train RMSE: 0.032\n",
      "Train MSE: 0.001\n",
      "Train MAE: 0.018\n",
      "###########################\n",
      "\n",
      "MODEL:  DNN\n",
      "sequence:  12h\n",
      "units:  12\n",
      "dropout1:  0.48476373451509647\n",
      "optimizer: adamax\n",
      "activationDense: sigmoid\n",
      "epochs: 52\n",
      "batchsize: 57\n",
      "validation_split: 0.2\n",
      "Model: \"sequential_143\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_429 (Dense)            (None, 72, 12)            24        \n",
      "_________________________________________________________________\n",
      "dense_430 (Dense)            (None, 72, 16)            208       \n",
      "_________________________________________________________________\n",
      "dropout_143 (Dropout)        (None, 72, 16)            0         \n",
      "_________________________________________________________________\n",
      "dense_431 (Dense)            (None, 72, 1)             17        \n",
      "=================================================================\n",
      "Total params: 249\n",
      "Trainable params: 249\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/52\n",
      " 1/55 [..............................] - ETA: 0s - loss: 0.0661WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0000s vs `on_train_batch_end` time: 0.0033s). Check your callbacks.\n",
      "55/55 [==============================] - 0s 7ms/step - loss: 0.0646 - val_loss: 0.0543\n",
      "Epoch 2/52\n",
      "55/55 [==============================] - 0s 3ms/step - loss: 0.0485 - val_loss: 0.0464\n",
      "Epoch 3/52\n",
      "55/55 [==============================] - 0s 3ms/step - loss: 0.0463 - val_loss: 0.0441\n",
      "Epoch 4/52\n",
      "55/55 [==============================] - 0s 3ms/step - loss: 0.0442 - val_loss: 0.0418\n",
      "Epoch 5/52\n",
      "55/55 [==============================] - 0s 3ms/step - loss: 0.0427 - val_loss: 0.0404\n",
      "Epoch 6/52\n",
      "55/55 [==============================] - 0s 3ms/step - loss: 0.0412 - val_loss: 0.0383\n",
      "Epoch 7/52\n",
      "55/55 [==============================] - 0s 3ms/step - loss: 0.0402 - val_loss: 0.0367\n",
      "Epoch 8/52\n",
      "55/55 [==============================] - 0s 3ms/step - loss: 0.0392 - val_loss: 0.0354\n",
      "Epoch 9/52\n",
      "55/55 [==============================] - 0s 3ms/step - loss: 0.0384 - val_loss: 0.0347\n",
      "Epoch 10/52\n",
      "55/55 [==============================] - 0s 3ms/step - loss: 0.0377 - val_loss: 0.0339\n",
      "Epoch 11/52\n",
      "55/55 [==============================] - 0s 3ms/step - loss: 0.0371 - val_loss: 0.0336\n",
      "Epoch 12/52\n",
      "55/55 [==============================] - 0s 3ms/step - loss: 0.0366 - val_loss: 0.0331\n",
      "Epoch 13/52\n",
      "55/55 [==============================] - 0s 3ms/step - loss: 0.0360 - val_loss: 0.0325\n",
      "Epoch 14/52\n",
      "55/55 [==============================] - 0s 3ms/step - loss: 0.0354 - val_loss: 0.0319\n",
      "Epoch 15/52\n",
      "55/55 [==============================] - 0s 3ms/step - loss: 0.0348 - val_loss: 0.0302\n",
      "Epoch 16/52\n",
      "55/55 [==============================] - 0s 3ms/step - loss: 0.0339 - val_loss: 0.0286\n",
      "Epoch 17/52\n",
      "55/55 [==============================] - 0s 3ms/step - loss: 0.0335 - val_loss: 0.0279\n",
      "Epoch 18/52\n",
      "55/55 [==============================] - 0s 3ms/step - loss: 0.0330 - val_loss: 0.0274\n",
      "Epoch 19/52\n",
      "55/55 [==============================] - 0s 3ms/step - loss: 0.0326 - val_loss: 0.0268\n",
      "Epoch 20/52\n",
      "55/55 [==============================] - 0s 3ms/step - loss: 0.0325 - val_loss: 0.0264\n",
      "Epoch 21/52\n",
      "55/55 [==============================] - 0s 3ms/step - loss: 0.0321 - val_loss: 0.0262\n",
      "Epoch 22/52\n",
      "55/55 [==============================] - 0s 3ms/step - loss: 0.0318 - val_loss: 0.0257\n",
      "Epoch 23/52\n",
      "55/55 [==============================] - 0s 3ms/step - loss: 0.0315 - val_loss: 0.0255\n",
      "Epoch 24/52\n",
      "55/55 [==============================] - 0s 3ms/step - loss: 0.0313 - val_loss: 0.0252\n",
      "Epoch 25/52\n",
      "55/55 [==============================] - 0s 3ms/step - loss: 0.0311 - val_loss: 0.0250\n",
      "Epoch 26/52\n",
      "55/55 [==============================] - 0s 3ms/step - loss: 0.0309 - val_loss: 0.0247\n",
      "Epoch 27/52\n",
      "55/55 [==============================] - 0s 3ms/step - loss: 0.0306 - val_loss: 0.0243\n",
      "Epoch 28/52\n",
      "55/55 [==============================] - 0s 3ms/step - loss: 0.0304 - val_loss: 0.0240\n",
      "Epoch 29/52\n",
      "55/55 [==============================] - 0s 3ms/step - loss: 0.0302 - val_loss: 0.0237\n",
      "Epoch 30/52\n",
      "55/55 [==============================] - 0s 3ms/step - loss: 0.0300 - val_loss: 0.0237\n",
      "Epoch 31/52\n",
      "55/55 [==============================] - 0s 3ms/step - loss: 0.0298 - val_loss: 0.0232\n",
      "Epoch 32/52\n",
      "55/55 [==============================] - 0s 3ms/step - loss: 0.0296 - val_loss: 0.0231\n",
      "Epoch 33/52\n",
      "55/55 [==============================] - 0s 3ms/step - loss: 0.0294 - val_loss: 0.0229\n",
      "Epoch 34/52\n",
      "55/55 [==============================] - 0s 3ms/step - loss: 0.0293 - val_loss: 0.0227\n",
      "Epoch 35/52\n",
      "55/55 [==============================] - 0s 3ms/step - loss: 0.0291 - val_loss: 0.0223\n",
      "Epoch 36/52\n",
      "55/55 [==============================] - 0s 3ms/step - loss: 0.0290 - val_loss: 0.0220\n",
      "Epoch 37/52\n",
      "55/55 [==============================] - 0s 3ms/step - loss: 0.0288 - val_loss: 0.0219\n",
      "Epoch 38/52\n",
      "55/55 [==============================] - 0s 3ms/step - loss: 0.0287 - val_loss: 0.0217\n",
      "Epoch 39/52\n",
      "55/55 [==============================] - 0s 3ms/step - loss: 0.0286 - val_loss: 0.0215\n",
      "Epoch 40/52\n",
      "55/55 [==============================] - 0s 3ms/step - loss: 0.0284 - val_loss: 0.0213\n",
      "Epoch 41/52\n",
      "55/55 [==============================] - 0s 3ms/step - loss: 0.0283 - val_loss: 0.0211\n",
      "Epoch 42/52\n",
      "55/55 [==============================] - 0s 3ms/step - loss: 0.0283 - val_loss: 0.0210\n",
      "Epoch 43/52\n",
      "55/55 [==============================] - 0s 3ms/step - loss: 0.0281 - val_loss: 0.0209\n",
      "Epoch 44/52\n",
      "55/55 [==============================] - 0s 3ms/step - loss: 0.0280 - val_loss: 0.0206\n",
      "Epoch 45/52\n",
      "55/55 [==============================] - 0s 3ms/step - loss: 0.0279 - val_loss: 0.0206\n",
      "Epoch 46/52\n",
      "55/55 [==============================] - 0s 4ms/step - loss: 0.0278 - val_loss: 0.0203\n",
      "Epoch 47/52\n",
      "55/55 [==============================] - 0s 4ms/step - loss: 0.0278 - val_loss: 0.0204\n",
      "Epoch 48/52\n",
      "55/55 [==============================] - 0s 4ms/step - loss: 0.0277 - val_loss: 0.0201\n",
      "Epoch 49/52\n",
      "55/55 [==============================] - 0s 4ms/step - loss: 0.0276 - val_loss: 0.0202\n",
      "Epoch 50/52\n",
      "55/55 [==============================] - 0s 3ms/step - loss: 0.0275 - val_loss: 0.0199\n",
      "Epoch 51/52\n",
      "55/55 [==============================] - 0s 4ms/step - loss: 0.0275 - val_loss: 0.0200\n",
      "Epoch 52/52\n",
      "55/55 [==============================] - 0s 4ms/step - loss: 0.0274 - val_loss: 0.0197\n",
      "Execution time:  10.4955313205719\n",
      "DNN:\n",
      "Mean Absolute Error: 0.0245\n",
      "Root Mean Square Error: 0.0402\n",
      "Mean Square Error: 0.0016\n",
      "\n",
      "Train RMSE: 0.040\n",
      "Train MSE: 0.002\n",
      "Train MAE: 0.024\n",
      "###########################\n",
      "\n",
      "MODEL:  DNN\n",
      "sequence:  1d\n",
      "units:  87\n",
      "dropout1:  0.40519643149940265\n",
      "optimizer: adam\n",
      "activationDense: tanh\n",
      "epochs: 80\n",
      "batchsize: 31\n",
      "validation_split: 0.1\n",
      "Model: \"sequential_144\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_432 (Dense)            (None, 144, 87)           174       \n",
      "_________________________________________________________________\n",
      "dense_433 (Dense)            (None, 144, 16)           1408      \n",
      "_________________________________________________________________\n",
      "dropout_144 (Dropout)        (None, 144, 16)           0         \n",
      "_________________________________________________________________\n",
      "dense_434 (Dense)            (None, 144, 1)            17        \n",
      "=================================================================\n",
      "Total params: 1,599\n",
      "Trainable params: 1,599\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/80\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "112/112 [==============================] - 1s 8ms/step - loss: 0.1217 - val_loss: 0.0079\n",
      "Epoch 2/80\n",
      "112/112 [==============================] - 1s 6ms/step - loss: 0.0728 - val_loss: 0.0096\n",
      "Epoch 3/80\n",
      "112/112 [==============================] - 1s 6ms/step - loss: 0.0630 - val_loss: 0.0080\n",
      "Epoch 4/80\n",
      "112/112 [==============================] - 1s 6ms/step - loss: 0.0540 - val_loss: 0.0091\n",
      "Epoch 5/80\n",
      "112/112 [==============================] - 1s 6ms/step - loss: 0.0459 - val_loss: 0.0114\n",
      "Epoch 6/80\n",
      "112/112 [==============================] - 1s 6ms/step - loss: 0.0394 - val_loss: 0.0127\n",
      "Epoch 7/80\n",
      "112/112 [==============================] - 1s 7ms/step - loss: 0.0352 - val_loss: 0.0126\n",
      "Epoch 8/80\n",
      "112/112 [==============================] - 1s 7ms/step - loss: 0.0324 - val_loss: 0.0205\n",
      "Epoch 9/80\n",
      "112/112 [==============================] - 1s 6ms/step - loss: 0.0327 - val_loss: 0.0232\n",
      "Epoch 10/80\n",
      "112/112 [==============================] - 1s 6ms/step - loss: 0.0314 - val_loss: 0.0154\n",
      "Epoch 11/80\n",
      "112/112 [==============================] - 1s 6ms/step - loss: 0.0303 - val_loss: 0.0099\n",
      "Epoch 12/80\n",
      "112/112 [==============================] - 1s 6ms/step - loss: 0.0289 - val_loss: 0.0098\n",
      "Epoch 13/80\n",
      "112/112 [==============================] - 1s 6ms/step - loss: 0.0286 - val_loss: 0.0098\n",
      "Epoch 14/80\n",
      "112/112 [==============================] - 1s 6ms/step - loss: 0.0283 - val_loss: 0.0102\n",
      "Epoch 15/80\n",
      "112/112 [==============================] - 1s 6ms/step - loss: 0.0281 - val_loss: 0.0107\n",
      "Epoch 16/80\n",
      "112/112 [==============================] - 1s 6ms/step - loss: 0.0281 - val_loss: 0.0107\n",
      "Epoch 17/80\n",
      "112/112 [==============================] - 1s 6ms/step - loss: 0.0280 - val_loss: 0.0120\n",
      "Epoch 18/80\n",
      "112/112 [==============================] - 1s 6ms/step - loss: 0.0278 - val_loss: 0.0126\n",
      "Epoch 19/80\n",
      "112/112 [==============================] - 1s 7ms/step - loss: 0.0277 - val_loss: 0.0130\n",
      "Epoch 20/80\n",
      "112/112 [==============================] - 1s 7ms/step - loss: 0.0277 - val_loss: 0.0131\n",
      "Epoch 21/80\n",
      "112/112 [==============================] - 1s 7ms/step - loss: 0.0277 - val_loss: 0.0129\n",
      "Epoch 22/80\n",
      "112/112 [==============================] - 1s 6ms/step - loss: 0.0277 - val_loss: 0.0134\n",
      "Epoch 23/80\n",
      "112/112 [==============================] - 1s 6ms/step - loss: 0.0277 - val_loss: 0.0131\n",
      "Epoch 24/80\n",
      "112/112 [==============================] - 1s 6ms/step - loss: 0.0277 - val_loss: 0.0129\n",
      "Epoch 25/80\n",
      "112/112 [==============================] - 1s 6ms/step - loss: 0.0277 - val_loss: 0.0136\n",
      "Epoch 26/80\n",
      "112/112 [==============================] - 1s 7ms/step - loss: 0.0276 - val_loss: 0.0137\n",
      "Epoch 27/80\n",
      "112/112 [==============================] - 1s 6ms/step - loss: 0.0276 - val_loss: 0.0139\n",
      "Epoch 28/80\n",
      "112/112 [==============================] - 1s 6ms/step - loss: 0.0277 - val_loss: 0.0167\n",
      "Epoch 29/80\n",
      "112/112 [==============================] - 1s 6ms/step - loss: 0.0274 - val_loss: 0.0126\n",
      "Epoch 30/80\n",
      "112/112 [==============================] - 1s 6ms/step - loss: 0.0277 - val_loss: 0.0140\n",
      "Epoch 31/80\n",
      "112/112 [==============================] - 1s 6ms/step - loss: 0.0275 - val_loss: 0.0137\n",
      "Epoch 32/80\n",
      "112/112 [==============================] - 1s 6ms/step - loss: 0.0275 - val_loss: 0.0140\n",
      "Epoch 33/80\n",
      "112/112 [==============================] - 1s 6ms/step - loss: 0.0276 - val_loss: 0.0130\n",
      "Epoch 34/80\n",
      "112/112 [==============================] - 1s 6ms/step - loss: 0.0276 - val_loss: 0.0142\n",
      "Epoch 35/80\n",
      "112/112 [==============================] - 1s 6ms/step - loss: 0.0275 - val_loss: 0.0137\n",
      "Epoch 36/80\n",
      "112/112 [==============================] - 1s 6ms/step - loss: 0.0275 - val_loss: 0.0140\n",
      "Epoch 37/80\n",
      "112/112 [==============================] - 1s 6ms/step - loss: 0.0276 - val_loss: 0.0132\n",
      "Epoch 38/80\n",
      "112/112 [==============================] - 1s 6ms/step - loss: 0.0276 - val_loss: 0.0141\n",
      "Epoch 39/80\n",
      "112/112 [==============================] - 1s 6ms/step - loss: 0.0275 - val_loss: 0.0138\n",
      "Epoch 40/80\n",
      "112/112 [==============================] - 1s 7ms/step - loss: 0.0275 - val_loss: 0.0137\n",
      "Epoch 41/80\n",
      "112/112 [==============================] - 1s 7ms/step - loss: 0.0275 - val_loss: 0.0139\n",
      "Epoch 42/80\n",
      "112/112 [==============================] - 1s 7ms/step - loss: 0.0275 - val_loss: 0.0136\n",
      "Epoch 43/80\n",
      "112/112 [==============================] - 1s 7ms/step - loss: 0.0276 - val_loss: 0.0139\n",
      "Epoch 44/80\n",
      "112/112 [==============================] - 1s 6ms/step - loss: 0.0275 - val_loss: 0.0139\n",
      "Epoch 45/80\n",
      "112/112 [==============================] - 1s 6ms/step - loss: 0.0276 - val_loss: 0.0139\n",
      "Epoch 46/80\n",
      "112/112 [==============================] - 1s 6ms/step - loss: 0.0276 - val_loss: 0.0138\n",
      "Epoch 47/80\n",
      "112/112 [==============================] - 1s 7ms/step - loss: 0.0276 - val_loss: 0.0138\n",
      "Epoch 48/80\n",
      "112/112 [==============================] - 1s 6ms/step - loss: 0.0276 - val_loss: 0.0139\n",
      "Epoch 49/80\n",
      "112/112 [==============================] - 1s 6ms/step - loss: 0.0276 - val_loss: 0.0138\n",
      "Epoch 50/80\n",
      "112/112 [==============================] - 1s 6ms/step - loss: 0.0276 - val_loss: 0.0139\n",
      "Epoch 51/80\n",
      "112/112 [==============================] - 1s 6ms/step - loss: 0.0276 - val_loss: 0.0137\n",
      "Epoch 52/80\n",
      "112/112 [==============================] - 1s 6ms/step - loss: 0.0276 - val_loss: 0.0139\n",
      "Epoch 53/80\n",
      "112/112 [==============================] - 1s 6ms/step - loss: 0.0276 - val_loss: 0.0136\n",
      "Epoch 54/80\n",
      "112/112 [==============================] - 1s 6ms/step - loss: 0.0276 - val_loss: 0.0137\n",
      "Epoch 55/80\n",
      "112/112 [==============================] - 1s 6ms/step - loss: 0.0276 - val_loss: 0.0138\n",
      "Epoch 56/80\n",
      "112/112 [==============================] - 1s 6ms/step - loss: 0.0276 - val_loss: 0.0138\n",
      "Epoch 57/80\n",
      "112/112 [==============================] - 1s 6ms/step - loss: 0.0276 - val_loss: 0.0138\n",
      "Epoch 58/80\n",
      "112/112 [==============================] - 1s 6ms/step - loss: 0.0276 - val_loss: 0.0137\n",
      "Epoch 59/80\n",
      "112/112 [==============================] - 1s 7ms/step - loss: 0.0276 - val_loss: 0.0137\n",
      "Epoch 60/80\n",
      "112/112 [==============================] - 1s 6ms/step - loss: 0.0276 - val_loss: 0.0139\n",
      "Epoch 61/80\n",
      "112/112 [==============================] - 1s 6ms/step - loss: 0.0276 - val_loss: 0.0138\n",
      "Epoch 62/80\n",
      "112/112 [==============================] - 1s 7ms/step - loss: 0.0276 - val_loss: 0.0137\n",
      "Epoch 63/80\n",
      "112/112 [==============================] - 1s 7ms/step - loss: 0.0276 - val_loss: 0.0137\n",
      "Epoch 64/80\n",
      "112/112 [==============================] - 1s 7ms/step - loss: 0.0276 - val_loss: 0.0139\n",
      "Epoch 65/80\n",
      "112/112 [==============================] - 1s 7ms/step - loss: 0.0276 - val_loss: 0.0136\n",
      "Epoch 66/80\n",
      "112/112 [==============================] - 1s 6ms/step - loss: 0.0276 - val_loss: 0.0139\n",
      "Epoch 67/80\n",
      "112/112 [==============================] - 1s 7ms/step - loss: 0.0276 - val_loss: 0.0138\n",
      "Epoch 68/80\n",
      "112/112 [==============================] - 1s 6ms/step - loss: 0.0276 - val_loss: 0.0137\n",
      "Epoch 69/80\n",
      "112/112 [==============================] - 1s 6ms/step - loss: 0.0275 - val_loss: 0.0138\n",
      "Epoch 70/80\n",
      "112/112 [==============================] - 1s 6ms/step - loss: 0.0276 - val_loss: 0.0140\n",
      "Epoch 71/80\n",
      "112/112 [==============================] - 1s 7ms/step - loss: 0.0276 - val_loss: 0.0137\n",
      "Epoch 72/80\n",
      "112/112 [==============================] - 1s 6ms/step - loss: 0.0276 - val_loss: 0.0136\n",
      "Epoch 73/80\n",
      "112/112 [==============================] - 1s 6ms/step - loss: 0.0276 - val_loss: 0.0136\n",
      "Epoch 74/80\n",
      "112/112 [==============================] - 1s 6ms/step - loss: 0.0275 - val_loss: 0.0139\n",
      "Epoch 75/80\n",
      "112/112 [==============================] - 1s 6ms/step - loss: 0.0276 - val_loss: 0.0136\n",
      "Epoch 76/80\n",
      "112/112 [==============================] - 1s 6ms/step - loss: 0.0276 - val_loss: 0.0136\n",
      "Epoch 77/80\n",
      "112/112 [==============================] - 1s 6ms/step - loss: 0.0275 - val_loss: 0.0139\n",
      "Epoch 78/80\n",
      "112/112 [==============================] - 1s 6ms/step - loss: 0.0276 - val_loss: 0.0135\n",
      "Epoch 79/80\n",
      "112/112 [==============================] - 1s 6ms/step - loss: 0.0276 - val_loss: 0.0137\n",
      "Epoch 80/80\n",
      "112/112 [==============================] - 1s 6ms/step - loss: 0.0275 - val_loss: 0.0138\n",
      "Execution time:  60.13489866256714\n",
      "DNN:\n",
      "Mean Absolute Error: 0.0260\n",
      "Root Mean Square Error: 0.0447\n",
      "Mean Square Error: 0.0020\n",
      "\n",
      "Train RMSE: 0.045\n",
      "Train MSE: 0.002\n",
      "Train MAE: 0.026\n",
      "###########################\n",
      "\n",
      "MODEL:  DNN\n",
      "sequence:  1d\n",
      "units:  80\n",
      "dropout1:  0.11814836227952394\n",
      "optimizer: adam\n",
      "activationDense: tanh\n",
      "epochs: 90\n",
      "batchsize: 25\n",
      "validation_split: 0.1\n",
      "Model: \"sequential_145\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_435 (Dense)            (None, 144, 80)           160       \n",
      "_________________________________________________________________\n",
      "dense_436 (Dense)            (None, 144, 16)           1296      \n",
      "_________________________________________________________________\n",
      "dropout_145 (Dropout)        (None, 144, 16)           0         \n",
      "_________________________________________________________________\n",
      "dense_437 (Dense)            (None, 144, 1)            17        \n",
      "=================================================================\n",
      "Total params: 1,473\n",
      "Trainable params: 1,473\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/90\n",
      "139/139 [==============================] - 1s 7ms/step - loss: 0.1058 - val_loss: 0.0058\n",
      "Epoch 2/90\n",
      "139/139 [==============================] - 1s 6ms/step - loss: 0.0467 - val_loss: 0.0071\n",
      "Epoch 3/90\n",
      "139/139 [==============================] - 1s 5ms/step - loss: 0.0436 - val_loss: 0.0105\n",
      "Epoch 4/90\n",
      "139/139 [==============================] - 1s 5ms/step - loss: 0.0417 - val_loss: 0.0116\n",
      "Epoch 5/90\n",
      "139/139 [==============================] - 1s 5ms/step - loss: 0.0400 - val_loss: 0.0110\n",
      "Epoch 6/90\n",
      "139/139 [==============================] - 1s 5ms/step - loss: 0.0388 - val_loss: 0.0117\n",
      "Epoch 7/90\n",
      "139/139 [==============================] - 1s 5ms/step - loss: 0.0372 - val_loss: 0.0128\n",
      "Epoch 8/90\n",
      "139/139 [==============================] - 1s 5ms/step - loss: 0.0359 - val_loss: 0.0144\n",
      "Epoch 9/90\n",
      "139/139 [==============================] - 1s 5ms/step - loss: 0.0349 - val_loss: 0.0153\n",
      "Epoch 10/90\n",
      "139/139 [==============================] - 1s 5ms/step - loss: 0.0340 - val_loss: 0.0159\n",
      "Epoch 11/90\n",
      "139/139 [==============================] - 1s 5ms/step - loss: 0.0332 - val_loss: 0.0166\n",
      "Epoch 12/90\n",
      "139/139 [==============================] - 1s 5ms/step - loss: 0.0327 - val_loss: 0.0132\n",
      "Epoch 13/90\n",
      "139/139 [==============================] - 1s 5ms/step - loss: 0.0325 - val_loss: 0.0201\n",
      "Epoch 14/90\n",
      "139/139 [==============================] - 1s 5ms/step - loss: 0.0321 - val_loss: 0.0210\n",
      "Epoch 15/90\n",
      "139/139 [==============================] - 1s 5ms/step - loss: 0.0317 - val_loss: 0.0208\n",
      "Epoch 16/90\n",
      "139/139 [==============================] - 1s 5ms/step - loss: 0.0314 - val_loss: 0.0199\n",
      "Epoch 17/90\n",
      "139/139 [==============================] - 1s 5ms/step - loss: 0.0310 - val_loss: 0.0196\n",
      "Epoch 18/90\n",
      "139/139 [==============================] - 1s 5ms/step - loss: 0.0307 - val_loss: 0.0174\n",
      "Epoch 19/90\n",
      "139/139 [==============================] - 1s 5ms/step - loss: 0.0304 - val_loss: 0.0169\n",
      "Epoch 20/90\n",
      "139/139 [==============================] - 1s 5ms/step - loss: 0.0301 - val_loss: 0.0171\n",
      "Epoch 21/90\n",
      "139/139 [==============================] - 1s 5ms/step - loss: 0.0299 - val_loss: 0.0158\n",
      "Epoch 22/90\n",
      "139/139 [==============================] - 1s 5ms/step - loss: 0.0296 - val_loss: 0.0154\n",
      "Epoch 23/90\n",
      "139/139 [==============================] - 1s 6ms/step - loss: 0.0294 - val_loss: 0.0152\n",
      "Epoch 24/90\n",
      "139/139 [==============================] - 1s 6ms/step - loss: 0.0292 - val_loss: 0.0147\n",
      "Epoch 25/90\n",
      "139/139 [==============================] - 1s 5ms/step - loss: 0.0291 - val_loss: 0.0145\n",
      "Epoch 26/90\n",
      "139/139 [==============================] - 1s 5ms/step - loss: 0.0289 - val_loss: 0.0142\n",
      "Epoch 27/90\n",
      "139/139 [==============================] - 1s 5ms/step - loss: 0.0289 - val_loss: 0.0137\n",
      "Epoch 28/90\n",
      "139/139 [==============================] - 1s 5ms/step - loss: 0.0288 - val_loss: 0.0124\n",
      "Epoch 29/90\n",
      "139/139 [==============================] - 1s 5ms/step - loss: 0.0287 - val_loss: 0.0122\n",
      "Epoch 30/90\n",
      "139/139 [==============================] - 1s 5ms/step - loss: 0.0287 - val_loss: 0.0119\n",
      "Epoch 31/90\n",
      "139/139 [==============================] - 1s 5ms/step - loss: 0.0286 - val_loss: 0.0119\n",
      "Epoch 32/90\n",
      "139/139 [==============================] - 1s 5ms/step - loss: 0.0285 - val_loss: 0.0118\n",
      "Epoch 33/90\n",
      "139/139 [==============================] - 1s 5ms/step - loss: 0.0284 - val_loss: 0.0116\n",
      "Epoch 34/90\n",
      "139/139 [==============================] - 1s 5ms/step - loss: 0.0284 - val_loss: 0.0110\n",
      "Epoch 35/90\n",
      "139/139 [==============================] - 1s 5ms/step - loss: 0.0283 - val_loss: 0.0108\n",
      "Epoch 36/90\n",
      "139/139 [==============================] - 1s 5ms/step - loss: 0.0283 - val_loss: 0.0104\n",
      "Epoch 37/90\n",
      "139/139 [==============================] - 1s 5ms/step - loss: 0.0283 - val_loss: 0.0102\n",
      "Epoch 38/90\n",
      "139/139 [==============================] - 1s 5ms/step - loss: 0.0282 - val_loss: 0.0104\n",
      "Epoch 39/90\n",
      "139/139 [==============================] - 1s 5ms/step - loss: 0.0281 - val_loss: 0.0108\n",
      "Epoch 40/90\n",
      "139/139 [==============================] - 1s 5ms/step - loss: 0.0286 - val_loss: 0.0136\n",
      "Epoch 41/90\n",
      "139/139 [==============================] - 1s 5ms/step - loss: 0.0280 - val_loss: 0.0110\n",
      "Epoch 42/90\n",
      "139/139 [==============================] - 1s 5ms/step - loss: 0.0280 - val_loss: 0.0110\n",
      "Epoch 43/90\n",
      "139/139 [==============================] - 1s 5ms/step - loss: 0.0280 - val_loss: 0.0110\n",
      "Epoch 44/90\n",
      "139/139 [==============================] - 1s 6ms/step - loss: 0.0280 - val_loss: 0.0110\n",
      "Epoch 45/90\n",
      "139/139 [==============================] - 1s 6ms/step - loss: 0.0280 - val_loss: 0.0109\n",
      "Epoch 46/90\n",
      "139/139 [==============================] - 1s 6ms/step - loss: 0.0279 - val_loss: 0.0123\n",
      "Epoch 47/90\n",
      "139/139 [==============================] - 1s 5ms/step - loss: 0.0279 - val_loss: 0.0108\n",
      "Epoch 48/90\n",
      "139/139 [==============================] - 1s 5ms/step - loss: 0.0279 - val_loss: 0.0121\n",
      "Epoch 49/90\n",
      "139/139 [==============================] - 1s 5ms/step - loss: 0.0286 - val_loss: 0.0166\n",
      "Epoch 50/90\n",
      "139/139 [==============================] - 1s 5ms/step - loss: 0.0276 - val_loss: 0.0114\n",
      "Epoch 51/90\n",
      "139/139 [==============================] - 1s 5ms/step - loss: 0.0279 - val_loss: 0.0117\n",
      "Epoch 52/90\n",
      "139/139 [==============================] - 1s 5ms/step - loss: 0.0279 - val_loss: 0.0119\n",
      "Epoch 53/90\n",
      "139/139 [==============================] - 1s 5ms/step - loss: 0.0279 - val_loss: 0.0114\n",
      "Epoch 54/90\n",
      "139/139 [==============================] - 1s 5ms/step - loss: 0.0279 - val_loss: 0.0124\n",
      "Epoch 55/90\n",
      "139/139 [==============================] - 1s 5ms/step - loss: 0.0279 - val_loss: 0.0111\n",
      "Epoch 56/90\n",
      "139/139 [==============================] - 1s 5ms/step - loss: 0.0279 - val_loss: 0.0124\n",
      "Epoch 57/90\n",
      "139/139 [==============================] - 1s 5ms/step - loss: 0.0279 - val_loss: 0.0114\n",
      "Epoch 58/90\n",
      "139/139 [==============================] - 1s 5ms/step - loss: 0.0279 - val_loss: 0.0124\n",
      "Epoch 59/90\n",
      "139/139 [==============================] - 1s 5ms/step - loss: 0.0279 - val_loss: 0.0114\n",
      "Epoch 60/90\n",
      "139/139 [==============================] - 1s 5ms/step - loss: 0.0279 - val_loss: 0.0125\n",
      "Epoch 61/90\n",
      "139/139 [==============================] - 1s 5ms/step - loss: 0.0279 - val_loss: 0.0115\n",
      "Epoch 62/90\n",
      "139/139 [==============================] - 1s 5ms/step - loss: 0.0279 - val_loss: 0.0123\n",
      "Epoch 63/90\n",
      "139/139 [==============================] - 1s 5ms/step - loss: 0.0279 - val_loss: 0.0116\n",
      "Epoch 64/90\n",
      "139/139 [==============================] - 1s 5ms/step - loss: 0.0279 - val_loss: 0.0121\n",
      "Epoch 65/90\n",
      "139/139 [==============================] - 1s 5ms/step - loss: 0.0279 - val_loss: 0.0117\n",
      "Epoch 66/90\n",
      "139/139 [==============================] - 1s 6ms/step - loss: 0.0279 - val_loss: 0.0124\n",
      "Epoch 67/90\n",
      "139/139 [==============================] - 1s 6ms/step - loss: 0.0279 - val_loss: 0.0116\n",
      "Epoch 68/90\n",
      "139/139 [==============================] - 1s 5ms/step - loss: 0.0279 - val_loss: 0.0123\n",
      "Epoch 69/90\n",
      "139/139 [==============================] - 1s 5ms/step - loss: 0.0279 - val_loss: 0.0118\n",
      "Epoch 70/90\n",
      "139/139 [==============================] - 1s 5ms/step - loss: 0.0279 - val_loss: 0.0120\n",
      "Epoch 71/90\n",
      "139/139 [==============================] - 1s 5ms/step - loss: 0.0279 - val_loss: 0.0119\n",
      "Epoch 72/90\n",
      "139/139 [==============================] - 1s 5ms/step - loss: 0.0279 - val_loss: 0.0119\n",
      "Epoch 73/90\n",
      "139/139 [==============================] - 1s 5ms/step - loss: 0.0279 - val_loss: 0.0119\n",
      "Epoch 74/90\n",
      "139/139 [==============================] - 1s 5ms/step - loss: 0.0278 - val_loss: 0.0121\n",
      "Epoch 75/90\n",
      "139/139 [==============================] - 1s 5ms/step - loss: 0.0279 - val_loss: 0.0113\n",
      "Epoch 76/90\n",
      "139/139 [==============================] - 1s 5ms/step - loss: 0.0279 - val_loss: 0.0125\n",
      "Epoch 77/90\n",
      "139/139 [==============================] - 1s 5ms/step - loss: 0.0279 - val_loss: 0.0113\n",
      "Epoch 78/90\n",
      "139/139 [==============================] - 1s 5ms/step - loss: 0.0279 - val_loss: 0.0123\n",
      "Epoch 79/90\n",
      "139/139 [==============================] - 1s 5ms/step - loss: 0.0279 - val_loss: 0.0118\n",
      "Epoch 80/90\n",
      "139/139 [==============================] - 1s 5ms/step - loss: 0.0279 - val_loss: 0.0119\n",
      "Epoch 81/90\n",
      "139/139 [==============================] - 1s 5ms/step - loss: 0.0279 - val_loss: 0.0116\n",
      "Epoch 82/90\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "139/139 [==============================] - 1s 5ms/step - loss: 0.0279 - val_loss: 0.0126\n",
      "Epoch 83/90\n",
      "139/139 [==============================] - 1s 5ms/step - loss: 0.0279 - val_loss: 0.0112\n",
      "Epoch 84/90\n",
      "139/139 [==============================] - 1s 5ms/step - loss: 0.0279 - val_loss: 0.0123\n",
      "Epoch 85/90\n",
      "139/139 [==============================] - 1s 5ms/step - loss: 0.0279 - val_loss: 0.0117\n",
      "Epoch 86/90\n",
      "139/139 [==============================] - 1s 5ms/step - loss: 0.0279 - val_loss: 0.0120\n",
      "Epoch 87/90\n",
      "139/139 [==============================] - 1s 6ms/step - loss: 0.0279 - val_loss: 0.0116\n",
      "Epoch 88/90\n",
      "139/139 [==============================] - 1s 6ms/step - loss: 0.0279 - val_loss: 0.0122\n",
      "Epoch 89/90\n",
      "139/139 [==============================] - 1s 5ms/step - loss: 0.0279 - val_loss: 0.0114\n",
      "Epoch 90/90\n",
      "139/139 [==============================] - 1s 5ms/step - loss: 0.0279 - val_loss: 0.0121\n",
      "Execution time:  68.77367877960205\n",
      "DNN:\n",
      "Mean Absolute Error: 0.0262\n",
      "Root Mean Square Error: 0.0457\n",
      "Mean Square Error: 0.0021\n",
      "\n",
      "Train RMSE: 0.046\n",
      "Train MSE: 0.002\n",
      "Train MAE: 0.026\n",
      "###########################\n",
      "\n",
      "MODEL:  DNN\n",
      "sequence:  1d\n",
      "units:  12\n",
      "dropout1:  0.48476373451509647\n",
      "optimizer: adam\n",
      "activationDense: tanh\n",
      "epochs: 52\n",
      "batchsize: 57\n",
      "validation_split: 0.1\n",
      "Model: \"sequential_146\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_438 (Dense)            (None, 144, 12)           24        \n",
      "_________________________________________________________________\n",
      "dense_439 (Dense)            (None, 144, 16)           208       \n",
      "_________________________________________________________________\n",
      "dropout_146 (Dropout)        (None, 144, 16)           0         \n",
      "_________________________________________________________________\n",
      "dense_440 (Dense)            (None, 144, 1)            17        \n",
      "=================================================================\n",
      "Total params: 249\n",
      "Trainable params: 249\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/52\n",
      "61/61 [==============================] - 1s 8ms/step - loss: 0.2083 - val_loss: 0.0307\n",
      "Epoch 2/52\n",
      "61/61 [==============================] - 0s 5ms/step - loss: 0.1147 - val_loss: 0.0149\n",
      "Epoch 3/52\n",
      "61/61 [==============================] - 0s 5ms/step - loss: 0.1004 - val_loss: 0.0300\n",
      "Epoch 4/52\n",
      "61/61 [==============================] - 0s 5ms/step - loss: 0.0904 - val_loss: 0.0266\n",
      "Epoch 5/52\n",
      "61/61 [==============================] - 0s 5ms/step - loss: 0.0812 - val_loss: 0.0234\n",
      "Epoch 6/52\n",
      "61/61 [==============================] - 0s 5ms/step - loss: 0.0720 - val_loss: 0.0175\n",
      "Epoch 7/52\n",
      "61/61 [==============================] - 0s 5ms/step - loss: 0.0630 - val_loss: 0.0102\n",
      "Epoch 8/52\n",
      "61/61 [==============================] - 0s 5ms/step - loss: 0.0525 - val_loss: 0.0059\n",
      "Epoch 9/52\n",
      "61/61 [==============================] - 0s 5ms/step - loss: 0.0455 - val_loss: 0.0058\n",
      "Epoch 10/52\n",
      "61/61 [==============================] - 0s 5ms/step - loss: 0.0401 - val_loss: 0.0064\n",
      "Epoch 11/52\n",
      "61/61 [==============================] - 0s 5ms/step - loss: 0.0358 - val_loss: 0.0069\n",
      "Epoch 12/52\n",
      "61/61 [==============================] - 0s 5ms/step - loss: 0.0331 - val_loss: 0.0073\n",
      "Epoch 13/52\n",
      "61/61 [==============================] - 0s 5ms/step - loss: 0.0311 - val_loss: 0.0078\n",
      "Epoch 14/52\n",
      "61/61 [==============================] - 0s 5ms/step - loss: 0.0292 - val_loss: 0.0095\n",
      "Epoch 15/52\n",
      "61/61 [==============================] - 0s 5ms/step - loss: 0.0280 - val_loss: 0.0104\n",
      "Epoch 16/52\n",
      "61/61 [==============================] - 0s 5ms/step - loss: 0.0277 - val_loss: 0.0100\n",
      "Epoch 17/52\n",
      "61/61 [==============================] - 0s 5ms/step - loss: 0.0276 - val_loss: 0.0126\n",
      "Epoch 18/52\n",
      "61/61 [==============================] - 0s 5ms/step - loss: 0.0272 - val_loss: 0.0133\n",
      "Epoch 19/52\n",
      "61/61 [==============================] - 0s 5ms/step - loss: 0.0272 - val_loss: 0.0140\n",
      "Epoch 20/52\n",
      "61/61 [==============================] - 0s 5ms/step - loss: 0.0270 - val_loss: 0.0145\n",
      "Epoch 21/52\n",
      "61/61 [==============================] - 0s 5ms/step - loss: 0.0270 - val_loss: 0.0145\n",
      "Epoch 22/52\n",
      "61/61 [==============================] - 0s 5ms/step - loss: 0.0269 - val_loss: 0.0150\n",
      "Epoch 23/52\n",
      "61/61 [==============================] - 0s 5ms/step - loss: 0.0268 - val_loss: 0.0148\n",
      "Epoch 24/52\n",
      "61/61 [==============================] - 0s 5ms/step - loss: 0.0268 - val_loss: 0.0150\n",
      "Epoch 25/52\n",
      "61/61 [==============================] - 0s 5ms/step - loss: 0.0268 - val_loss: 0.0151\n",
      "Epoch 26/52\n",
      "61/61 [==============================] - 0s 5ms/step - loss: 0.0268 - val_loss: 0.0153\n",
      "Epoch 27/52\n",
      "61/61 [==============================] - 0s 5ms/step - loss: 0.0267 - val_loss: 0.0154\n",
      "Epoch 28/52\n",
      "61/61 [==============================] - 0s 5ms/step - loss: 0.0267 - val_loss: 0.0155\n",
      "Epoch 29/52\n",
      "61/61 [==============================] - 0s 5ms/step - loss: 0.0267 - val_loss: 0.0156\n",
      "Epoch 30/52\n",
      "61/61 [==============================] - 0s 5ms/step - loss: 0.0267 - val_loss: 0.0157\n",
      "Epoch 31/52\n",
      "61/61 [==============================] - 0s 5ms/step - loss: 0.0267 - val_loss: 0.0156\n",
      "Epoch 32/52\n",
      "61/61 [==============================] - 0s 5ms/step - loss: 0.0267 - val_loss: 0.0158\n",
      "Epoch 33/52\n",
      "61/61 [==============================] - 0s 5ms/step - loss: 0.0266 - val_loss: 0.0159\n",
      "Epoch 34/52\n",
      "61/61 [==============================] - 0s 5ms/step - loss: 0.0266 - val_loss: 0.0157\n",
      "Epoch 35/52\n",
      "61/61 [==============================] - 0s 5ms/step - loss: 0.0266 - val_loss: 0.0159\n",
      "Epoch 36/52\n",
      "61/61 [==============================] - 0s 6ms/step - loss: 0.0266 - val_loss: 0.0160\n",
      "Epoch 37/52\n",
      "61/61 [==============================] - 0s 6ms/step - loss: 0.0266 - val_loss: 0.0164\n",
      "Epoch 38/52\n",
      "61/61 [==============================] - 0s 6ms/step - loss: 0.0265 - val_loss: 0.0157\n",
      "Epoch 39/52\n",
      "61/61 [==============================] - 0s 6ms/step - loss: 0.0267 - val_loss: 0.0163\n",
      "Epoch 40/52\n",
      "61/61 [==============================] - 0s 5ms/step - loss: 0.0266 - val_loss: 0.0165\n",
      "Epoch 41/52\n",
      "61/61 [==============================] - 0s 5ms/step - loss: 0.0265 - val_loss: 0.0157\n",
      "Epoch 42/52\n",
      "61/61 [==============================] - 0s 5ms/step - loss: 0.0267 - val_loss: 0.0166\n",
      "Epoch 43/52\n",
      "61/61 [==============================] - 0s 5ms/step - loss: 0.0265 - val_loss: 0.0161\n",
      "Epoch 44/52\n",
      "61/61 [==============================] - 0s 5ms/step - loss: 0.0266 - val_loss: 0.0161\n",
      "Epoch 45/52\n",
      "61/61 [==============================] - 0s 5ms/step - loss: 0.0266 - val_loss: 0.0165\n",
      "Epoch 46/52\n",
      "61/61 [==============================] - 0s 5ms/step - loss: 0.0265 - val_loss: 0.0159\n",
      "Epoch 47/52\n",
      "61/61 [==============================] - 0s 5ms/step - loss: 0.0266 - val_loss: 0.0161\n",
      "Epoch 48/52\n",
      "61/61 [==============================] - 0s 5ms/step - loss: 0.0266 - val_loss: 0.0166\n",
      "Epoch 49/52\n",
      "61/61 [==============================] - 0s 5ms/step - loss: 0.0265 - val_loss: 0.0160\n",
      "Epoch 50/52\n",
      "61/61 [==============================] - 0s 5ms/step - loss: 0.0266 - val_loss: 0.0161\n",
      "Epoch 51/52\n",
      "61/61 [==============================] - 0s 5ms/step - loss: 0.0266 - val_loss: 0.0167\n",
      "Epoch 52/52\n",
      "61/61 [==============================] - 0s 5ms/step - loss: 0.0264 - val_loss: 0.0159\n",
      "Execution time:  17.93683385848999\n",
      "DNN:\n",
      "Mean Absolute Error: 0.0249\n",
      "Root Mean Square Error: 0.0412\n",
      "Mean Square Error: 0.0017\n",
      "\n",
      "Train RMSE: 0.041\n",
      "Train MSE: 0.002\n",
      "Train MAE: 0.025\n",
      "###########################\n",
      "\n",
      "MODEL:  DNN\n",
      "sequence:  1d\n",
      "units:  87\n",
      "dropout1:  0.40519643149940265\n",
      "optimizer: adam\n",
      "activationDense: tanh\n",
      "epochs: 80\n",
      "batchsize: 31\n",
      "validation_split: 0.2\n",
      "Model: \"sequential_147\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_441 (Dense)            (None, 144, 87)           174       \n",
      "_________________________________________________________________\n",
      "dense_442 (Dense)            (None, 144, 16)           1408      \n",
      "_________________________________________________________________\n",
      "dropout_147 (Dropout)        (None, 144, 16)           0         \n",
      "_________________________________________________________________\n",
      "dense_443 (Dense)            (None, 144, 1)            17        \n",
      "=================================================================\n",
      "Total params: 1,599\n",
      "Trainable params: 1,599\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/80\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100/100 [==============================] - 1s 9ms/step - loss: 0.1031 - val_loss: 0.0328\n",
      "Epoch 2/80\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 0.0739 - val_loss: 0.0187\n",
      "Epoch 3/80\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 0.0641 - val_loss: 0.0158\n",
      "Epoch 4/80\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 0.0559 - val_loss: 0.0156\n",
      "Epoch 5/80\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 0.0484 - val_loss: 0.0159\n",
      "Epoch 6/80\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 0.0425 - val_loss: 0.0162\n",
      "Epoch 7/80\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 0.0380 - val_loss: 0.0167\n",
      "Epoch 8/80\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 0.0349 - val_loss: 0.0157\n",
      "Epoch 9/80\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 0.0341 - val_loss: 0.0181\n",
      "Epoch 10/80\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 0.0324 - val_loss: 0.0176\n",
      "Epoch 11/80\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 0.0316 - val_loss: 0.0168\n",
      "Epoch 12/80\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 0.0307 - val_loss: 0.0166\n",
      "Epoch 13/80\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 0.0304 - val_loss: 0.0165\n",
      "Epoch 14/80\n",
      "100/100 [==============================] - 1s 8ms/step - loss: 0.0298 - val_loss: 0.0163\n",
      "Epoch 15/80\n",
      "100/100 [==============================] - 1s 8ms/step - loss: 0.0293 - val_loss: 0.0173\n",
      "Epoch 16/80\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 0.0290 - val_loss: 0.0178\n",
      "Epoch 17/80\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 0.0289 - val_loss: 0.0177\n",
      "Epoch 18/80\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 0.0288 - val_loss: 0.0181\n",
      "Epoch 19/80\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 0.0287 - val_loss: 0.0184\n",
      "Epoch 20/80\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 0.0286 - val_loss: 0.0182\n",
      "Epoch 21/80\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 0.0286 - val_loss: 0.0185\n",
      "Epoch 22/80\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 0.0285 - val_loss: 0.0184\n",
      "Epoch 23/80\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 0.0285 - val_loss: 0.0187\n",
      "Epoch 24/80\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 0.0284 - val_loss: 0.0183\n",
      "Epoch 25/80\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 0.0285 - val_loss: 0.0188\n",
      "Epoch 26/80\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 0.0284 - val_loss: 0.0184\n",
      "Epoch 27/80\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 0.0286 - val_loss: 0.0182\n",
      "Epoch 28/80\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 0.0285 - val_loss: 0.0187\n",
      "Epoch 29/80\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 0.0284 - val_loss: 0.0187\n",
      "Epoch 30/80\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 0.0284 - val_loss: 0.0186\n",
      "Epoch 31/80\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 0.0284 - val_loss: 0.0188\n",
      "Epoch 32/80\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 0.0283 - val_loss: 0.0187\n",
      "Epoch 33/80\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 0.0284 - val_loss: 0.0187\n",
      "Epoch 34/80\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 0.0284 - val_loss: 0.0186\n",
      "Epoch 35/80\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 0.0284 - val_loss: 0.0187\n",
      "Epoch 36/80\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 0.0283 - val_loss: 0.0188\n",
      "Epoch 37/80\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 0.0283 - val_loss: 0.0185\n",
      "Epoch 38/80\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 0.0284 - val_loss: 0.0188\n",
      "Epoch 39/80\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 0.0283 - val_loss: 0.0186\n",
      "Epoch 40/80\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 0.0284 - val_loss: 0.0188\n",
      "Epoch 41/80\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 0.0283 - val_loss: 0.0187\n",
      "Epoch 42/80\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 0.0284 - val_loss: 0.0186\n",
      "Epoch 43/80\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 0.0284 - val_loss: 0.0187\n",
      "Epoch 44/80\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 0.0283 - val_loss: 0.0188\n",
      "Epoch 45/80\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 0.0283 - val_loss: 0.0185\n",
      "Epoch 46/80\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 0.0284 - val_loss: 0.0187\n",
      "Epoch 47/80\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 0.0283 - val_loss: 0.0187\n",
      "Epoch 48/80\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 0.0283 - val_loss: 0.0188\n",
      "Epoch 49/80\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 0.0284 - val_loss: 0.0184\n",
      "Epoch 50/80\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 0.0284 - val_loss: 0.0188\n",
      "Epoch 51/80\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 0.0283 - val_loss: 0.0186\n",
      "Epoch 52/80\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 0.0284 - val_loss: 0.0188\n",
      "Epoch 53/80\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 0.0283 - val_loss: 0.0187\n",
      "Epoch 54/80\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 0.0284 - val_loss: 0.0186\n",
      "Epoch 55/80\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 0.0284 - val_loss: 0.0185\n",
      "Epoch 56/80\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 0.0284 - val_loss: 0.0187\n",
      "Epoch 57/80\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 0.0283 - val_loss: 0.0188\n",
      "Epoch 58/80\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 0.0283 - val_loss: 0.0186\n",
      "Epoch 59/80\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 0.0284 - val_loss: 0.0186\n",
      "Epoch 60/80\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 0.0284 - val_loss: 0.0185\n",
      "Epoch 61/80\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 0.0284 - val_loss: 0.0187\n",
      "Epoch 62/80\n",
      "100/100 [==============================] - 1s 8ms/step - loss: 0.0283 - val_loss: 0.0187\n",
      "Epoch 63/80\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 0.0284 - val_loss: 0.0186\n",
      "Epoch 64/80\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 0.0284 - val_loss: 0.0186\n",
      "Epoch 65/80\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 0.0284 - val_loss: 0.0186\n",
      "Epoch 66/80\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 0.0284 - val_loss: 0.0185\n",
      "Epoch 67/80\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 0.0284 - val_loss: 0.0187\n",
      "Epoch 68/80\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 0.0283 - val_loss: 0.0186\n",
      "Epoch 69/80\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 0.0284 - val_loss: 0.0187\n",
      "Epoch 70/80\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 0.0284 - val_loss: 0.0185\n",
      "Epoch 71/80\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 0.0284 - val_loss: 0.0187\n",
      "Epoch 72/80\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 0.0284 - val_loss: 0.0185\n",
      "Epoch 73/80\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 0.0284 - val_loss: 0.0187\n",
      "Epoch 74/80\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 0.0284 - val_loss: 0.0186\n",
      "Epoch 75/80\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 0.0284 - val_loss: 0.0187\n",
      "Epoch 76/80\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 0.0283 - val_loss: 0.0186\n",
      "Epoch 77/80\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 0.0284 - val_loss: 0.0186\n",
      "Epoch 78/80\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 0.0284 - val_loss: 0.0186\n",
      "Epoch 79/80\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 0.0284 - val_loss: 0.0186\n",
      "Epoch 80/80\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 0.0284 - val_loss: 0.0186\n",
      "Execution time:  57.299383878707886\n",
      "DNN:\n",
      "Mean Absolute Error: 0.0259\n",
      "Root Mean Square Error: 0.0437\n",
      "Mean Square Error: 0.0019\n",
      "\n",
      "Train RMSE: 0.044\n",
      "Train MSE: 0.002\n",
      "Train MAE: 0.026\n",
      "###########################\n",
      "\n",
      "MODEL:  DNN\n",
      "sequence:  1d\n",
      "units:  80\n",
      "dropout1:  0.11814836227952394\n",
      "optimizer: adam\n",
      "activationDense: tanh\n",
      "epochs: 90\n",
      "batchsize: 25\n",
      "validation_split: 0.2\n",
      "Model: \"sequential_148\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_444 (Dense)            (None, 144, 80)           160       \n",
      "_________________________________________________________________\n",
      "dense_445 (Dense)            (None, 144, 16)           1296      \n",
      "_________________________________________________________________\n",
      "dropout_148 (Dropout)        (None, 144, 16)           0         \n",
      "_________________________________________________________________\n",
      "dense_446 (Dense)            (None, 144, 1)            17        \n",
      "=================================================================\n",
      "Total params: 1,473\n",
      "Trainable params: 1,473\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/90\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "124/124 [==============================] - 1s 8ms/step - loss: 0.1278 - val_loss: 0.0281\n",
      "Epoch 2/90\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.0519 - val_loss: 0.0226\n",
      "Epoch 3/90\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.0485 - val_loss: 0.0260\n",
      "Epoch 4/90\n",
      "124/124 [==============================] - 1s 5ms/step - loss: 0.0457 - val_loss: 0.0225\n",
      "Epoch 5/90\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.0434 - val_loss: 0.0214\n",
      "Epoch 6/90\n",
      "124/124 [==============================] - 1s 5ms/step - loss: 0.0413 - val_loss: 0.0183\n",
      "Epoch 7/90\n",
      "124/124 [==============================] - 1s 5ms/step - loss: 0.0397 - val_loss: 0.0200\n",
      "Epoch 8/90\n",
      "124/124 [==============================] - 1s 5ms/step - loss: 0.0380 - val_loss: 0.0164\n",
      "Epoch 9/90\n",
      "124/124 [==============================] - 1s 5ms/step - loss: 0.0369 - val_loss: 0.0168\n",
      "Epoch 10/90\n",
      "124/124 [==============================] - 1s 5ms/step - loss: 0.0357 - val_loss: 0.0170\n",
      "Epoch 11/90\n",
      "124/124 [==============================] - 1s 5ms/step - loss: 0.0349 - val_loss: 0.0166\n",
      "Epoch 12/90\n",
      "124/124 [==============================] - 1s 5ms/step - loss: 0.0343 - val_loss: 0.0170\n",
      "Epoch 13/90\n",
      "124/124 [==============================] - 1s 5ms/step - loss: 0.0339 - val_loss: 0.0171\n",
      "Epoch 14/90\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.0334 - val_loss: 0.0176\n",
      "Epoch 15/90\n",
      "124/124 [==============================] - 1s 5ms/step - loss: 0.0330 - val_loss: 0.0178\n",
      "Epoch 16/90\n",
      "124/124 [==============================] - 1s 5ms/step - loss: 0.0325 - val_loss: 0.0177\n",
      "Epoch 17/90\n",
      "124/124 [==============================] - 1s 5ms/step - loss: 0.0320 - val_loss: 0.0175\n",
      "Epoch 18/90\n",
      "124/124 [==============================] - 1s 5ms/step - loss: 0.0316 - val_loss: 0.0173\n",
      "Epoch 19/90\n",
      "124/124 [==============================] - 1s 5ms/step - loss: 0.0314 - val_loss: 0.0169\n",
      "Epoch 20/90\n",
      "124/124 [==============================] - 1s 5ms/step - loss: 0.0310 - val_loss: 0.0169\n",
      "Epoch 21/90\n",
      "124/124 [==============================] - 1s 5ms/step - loss: 0.0308 - val_loss: 0.0167\n",
      "Epoch 22/90\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.0305 - val_loss: 0.0165\n",
      "Epoch 23/90\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.0303 - val_loss: 0.0161\n",
      "Epoch 24/90\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.0299 - val_loss: 0.0165\n",
      "Epoch 25/90\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.0301 - val_loss: 0.0165\n",
      "Epoch 26/90\n",
      "124/124 [==============================] - 1s 5ms/step - loss: 0.0299 - val_loss: 0.0164\n",
      "Epoch 27/90\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.0299 - val_loss: 0.0164\n",
      "Epoch 28/90\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.0298 - val_loss: 0.0163\n",
      "Epoch 29/90\n",
      "124/124 [==============================] - 1s 5ms/step - loss: 0.0296 - val_loss: 0.0163\n",
      "Epoch 30/90\n",
      "124/124 [==============================] - 1s 5ms/step - loss: 0.0295 - val_loss: 0.0163\n",
      "Epoch 31/90\n",
      "124/124 [==============================] - 1s 5ms/step - loss: 0.0294 - val_loss: 0.0164\n",
      "Epoch 32/90\n",
      "124/124 [==============================] - 1s 5ms/step - loss: 0.0295 - val_loss: 0.0164\n",
      "Epoch 33/90\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.0292 - val_loss: 0.0162\n",
      "Epoch 34/90\n",
      "124/124 [==============================] - 1s 5ms/step - loss: 0.0293 - val_loss: 0.0162\n",
      "Epoch 35/90\n",
      "124/124 [==============================] - 1s 5ms/step - loss: 0.0292 - val_loss: 0.0163\n",
      "Epoch 36/90\n",
      "124/124 [==============================] - 1s 5ms/step - loss: 0.0290 - val_loss: 0.0164\n",
      "Epoch 37/90\n",
      "124/124 [==============================] - 1s 5ms/step - loss: 0.0290 - val_loss: 0.0166\n",
      "Epoch 38/90\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.0289 - val_loss: 0.0169\n",
      "Epoch 39/90\n",
      "124/124 [==============================] - 1s 5ms/step - loss: 0.0288 - val_loss: 0.0168\n",
      "Epoch 40/90\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.0288 - val_loss: 0.0171\n",
      "Epoch 41/90\n",
      "124/124 [==============================] - 1s 5ms/step - loss: 0.0288 - val_loss: 0.0172\n",
      "Epoch 42/90\n",
      "124/124 [==============================] - 1s 5ms/step - loss: 0.0288 - val_loss: 0.0174\n",
      "Epoch 43/90\n",
      "124/124 [==============================] - 1s 5ms/step - loss: 0.0288 - val_loss: 0.0176\n",
      "Epoch 44/90\n",
      "124/124 [==============================] - 1s 5ms/step - loss: 0.0288 - val_loss: 0.0176\n",
      "Epoch 45/90\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.0287 - val_loss: 0.0177\n",
      "Epoch 46/90\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.0287 - val_loss: 0.0178\n",
      "Epoch 47/90\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.0287 - val_loss: 0.0177\n",
      "Epoch 48/90\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.0287 - val_loss: 0.0178\n",
      "Epoch 49/90\n",
      "124/124 [==============================] - 1s 5ms/step - loss: 0.0287 - val_loss: 0.0178\n",
      "Epoch 50/90\n",
      "124/124 [==============================] - 1s 5ms/step - loss: 0.0287 - val_loss: 0.0178\n",
      "Epoch 51/90\n",
      "124/124 [==============================] - 1s 5ms/step - loss: 0.0287 - val_loss: 0.0178\n",
      "Epoch 52/90\n",
      "124/124 [==============================] - 1s 5ms/step - loss: 0.0287 - val_loss: 0.0178\n",
      "Epoch 53/90\n",
      "124/124 [==============================] - 1s 5ms/step - loss: 0.0287 - val_loss: 0.0178\n",
      "Epoch 54/90\n",
      "124/124 [==============================] - 1s 5ms/step - loss: 0.0288 - val_loss: 0.0178\n",
      "Epoch 55/90\n",
      "124/124 [==============================] - 1s 5ms/step - loss: 0.0286 - val_loss: 0.0178\n",
      "Epoch 56/90\n",
      "124/124 [==============================] - 1s 5ms/step - loss: 0.0288 - val_loss: 0.0176\n",
      "Epoch 57/90\n",
      "124/124 [==============================] - 1s 5ms/step - loss: 0.0288 - val_loss: 0.0180\n",
      "Epoch 58/90\n",
      "124/124 [==============================] - 1s 5ms/step - loss: 0.0287 - val_loss: 0.0178\n",
      "Epoch 59/90\n",
      "124/124 [==============================] - 1s 5ms/step - loss: 0.0287 - val_loss: 0.0179\n",
      "Epoch 60/90\n",
      "124/124 [==============================] - 1s 5ms/step - loss: 0.0287 - val_loss: 0.0179\n",
      "Epoch 61/90\n",
      "124/124 [==============================] - 1s 5ms/step - loss: 0.0288 - val_loss: 0.0179\n",
      "Epoch 62/90\n",
      "124/124 [==============================] - 1s 5ms/step - loss: 0.0287 - val_loss: 0.0180\n",
      "Epoch 63/90\n",
      "124/124 [==============================] - 1s 5ms/step - loss: 0.0287 - val_loss: 0.0180\n",
      "Epoch 64/90\n",
      "124/124 [==============================] - 1s 5ms/step - loss: 0.0288 - val_loss: 0.0179\n",
      "Epoch 65/90\n",
      "124/124 [==============================] - 1s 5ms/step - loss: 0.0288 - val_loss: 0.0180\n",
      "Epoch 66/90\n",
      "124/124 [==============================] - 1s 5ms/step - loss: 0.0287 - val_loss: 0.0180\n",
      "Epoch 67/90\n",
      "124/124 [==============================] - 1s 5ms/step - loss: 0.0288 - val_loss: 0.0180\n",
      "Epoch 68/90\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.0287 - val_loss: 0.0181\n",
      "Epoch 69/90\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.0288 - val_loss: 0.0180\n",
      "Epoch 70/90\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.0288 - val_loss: 0.0181\n",
      "Epoch 71/90\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.0289 - val_loss: 0.0180\n",
      "Epoch 72/90\n",
      "124/124 [==============================] - 1s 5ms/step - loss: 0.0288 - val_loss: 0.0180\n",
      "Epoch 73/90\n",
      "124/124 [==============================] - 1s 5ms/step - loss: 0.0288 - val_loss: 0.0181\n",
      "Epoch 74/90\n",
      "124/124 [==============================] - 1s 5ms/step - loss: 0.0288 - val_loss: 0.0181\n",
      "Epoch 75/90\n",
      "124/124 [==============================] - 1s 5ms/step - loss: 0.0288 - val_loss: 0.0181\n",
      "Epoch 76/90\n",
      "124/124 [==============================] - 1s 5ms/step - loss: 0.0288 - val_loss: 0.0181\n",
      "Epoch 77/90\n",
      "124/124 [==============================] - 1s 5ms/step - loss: 0.0288 - val_loss: 0.0180\n",
      "Epoch 78/90\n",
      "124/124 [==============================] - 1s 5ms/step - loss: 0.0288 - val_loss: 0.0181\n",
      "Epoch 79/90\n",
      "124/124 [==============================] - 1s 5ms/step - loss: 0.0288 - val_loss: 0.0181\n",
      "Epoch 80/90\n",
      "124/124 [==============================] - 1s 5ms/step - loss: 0.0288 - val_loss: 0.0181\n",
      "Epoch 81/90\n",
      "124/124 [==============================] - 1s 5ms/step - loss: 0.0288 - val_loss: 0.0180\n",
      "Epoch 82/90\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "124/124 [==============================] - 1s 5ms/step - loss: 0.0288 - val_loss: 0.0181\n",
      "Epoch 83/90\n",
      "124/124 [==============================] - 1s 5ms/step - loss: 0.0288 - val_loss: 0.0181\n",
      "Epoch 84/90\n",
      "124/124 [==============================] - 1s 5ms/step - loss: 0.0288 - val_loss: 0.0181\n",
      "Epoch 85/90\n",
      "124/124 [==============================] - 1s 5ms/step - loss: 0.0289 - val_loss: 0.0180\n",
      "Epoch 86/90\n",
      "124/124 [==============================] - 1s 5ms/step - loss: 0.0288 - val_loss: 0.0181\n",
      "Epoch 87/90\n",
      "124/124 [==============================] - 1s 5ms/step - loss: 0.0288 - val_loss: 0.0180\n",
      "Epoch 88/90\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.0288 - val_loss: 0.0181\n",
      "Epoch 89/90\n",
      "124/124 [==============================] - 1s 5ms/step - loss: 0.0288 - val_loss: 0.0181\n",
      "Epoch 90/90\n",
      "124/124 [==============================] - 1s 5ms/step - loss: 0.0288 - val_loss: 0.0180\n",
      "Execution time:  64.02716088294983\n",
      "DNN:\n",
      "Mean Absolute Error: 0.0261\n",
      "Root Mean Square Error: 0.0445\n",
      "Mean Square Error: 0.0020\n",
      "\n",
      "Train RMSE: 0.045\n",
      "Train MSE: 0.002\n",
      "Train MAE: 0.026\n",
      "###########################\n",
      "\n",
      "MODEL:  DNN\n",
      "sequence:  1d\n",
      "units:  12\n",
      "dropout1:  0.48476373451509647\n",
      "optimizer: adam\n",
      "activationDense: tanh\n",
      "epochs: 52\n",
      "batchsize: 57\n",
      "validation_split: 0.2\n",
      "Model: \"sequential_149\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_447 (Dense)            (None, 144, 12)           24        \n",
      "_________________________________________________________________\n",
      "dense_448 (Dense)            (None, 144, 16)           208       \n",
      "_________________________________________________________________\n",
      "dropout_149 (Dropout)        (None, 144, 16)           0         \n",
      "_________________________________________________________________\n",
      "dense_449 (Dense)            (None, 144, 1)            17        \n",
      "=================================================================\n",
      "Total params: 249\n",
      "Trainable params: 249\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/52\n",
      "54/54 [==============================] - 0s 9ms/step - loss: 0.3771 - val_loss: 0.2602\n",
      "Epoch 2/52\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 0.1806 - val_loss: 0.0534\n",
      "Epoch 3/52\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 0.1177 - val_loss: 0.0330\n",
      "Epoch 4/52\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 0.1059 - val_loss: 0.0418\n",
      "Epoch 5/52\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 0.0966 - val_loss: 0.0396\n",
      "Epoch 6/52\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 0.0882 - val_loss: 0.0331\n",
      "Epoch 7/52\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 0.0797 - val_loss: 0.0264\n",
      "Epoch 8/52\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 0.0711 - val_loss: 0.0199\n",
      "Epoch 9/52\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 0.0627 - val_loss: 0.0170\n",
      "Epoch 10/52\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 0.0542 - val_loss: 0.0159\n",
      "Epoch 11/52\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 0.0464 - val_loss: 0.0175\n",
      "Epoch 12/52\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 0.0395 - val_loss: 0.0194\n",
      "Epoch 13/52\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 0.0345 - val_loss: 0.0190\n",
      "Epoch 14/52\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 0.0315 - val_loss: 0.0173\n",
      "Epoch 15/52\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 0.0303 - val_loss: 0.0174\n",
      "Epoch 16/52\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 0.0286 - val_loss: 0.0181\n",
      "Epoch 17/52\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 0.0281 - val_loss: 0.0186\n",
      "Epoch 18/52\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 0.0277 - val_loss: 0.0187\n",
      "Epoch 19/52\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 0.0276 - val_loss: 0.0185\n",
      "Epoch 20/52\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 0.0276 - val_loss: 0.0193\n",
      "Epoch 21/52\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 0.0273 - val_loss: 0.0189\n",
      "Epoch 22/52\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 0.0276 - val_loss: 0.0193\n",
      "Epoch 23/52\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 0.0274 - val_loss: 0.0197\n",
      "Epoch 24/52\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 0.0271 - val_loss: 0.0190\n",
      "Epoch 25/52\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 0.0274 - val_loss: 0.0192\n",
      "Epoch 26/52\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 0.0274 - val_loss: 0.0193\n",
      "Epoch 27/52\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 0.0274 - val_loss: 0.0196\n",
      "Epoch 28/52\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 0.0273 - val_loss: 0.0198\n",
      "Epoch 29/52\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 0.0271 - val_loss: 0.0194\n",
      "Epoch 30/52\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 0.0272 - val_loss: 0.0187\n",
      "Epoch 31/52\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 0.0277 - val_loss: 0.0195\n",
      "Epoch 32/52\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 0.0272 - val_loss: 0.0196\n",
      "Epoch 33/52\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 0.0271 - val_loss: 0.0188\n",
      "Epoch 34/52\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 0.0275 - val_loss: 0.0195\n",
      "Epoch 35/52\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 0.0271 - val_loss: 0.0192\n",
      "Epoch 36/52\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 0.0274 - val_loss: 0.0194\n",
      "Epoch 37/52\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 0.0273 - val_loss: 0.0196\n",
      "Epoch 38/52\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 0.0271 - val_loss: 0.0194\n",
      "Epoch 39/52\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 0.0271 - val_loss: 0.0192\n",
      "Epoch 40/52\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 0.0272 - val_loss: 0.0192\n",
      "Epoch 41/52\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 0.0273 - val_loss: 0.0192\n",
      "Epoch 42/52\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 0.0274 - val_loss: 0.0196\n",
      "Epoch 43/52\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 0.0271 - val_loss: 0.0197\n",
      "Epoch 44/52\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 0.0270 - val_loss: 0.0193\n",
      "Epoch 45/52\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 0.0271 - val_loss: 0.0191\n",
      "Epoch 46/52\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 0.0273 - val_loss: 0.0193\n",
      "Epoch 47/52\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 0.0272 - val_loss: 0.0195\n",
      "Epoch 48/52\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 0.0271 - val_loss: 0.0194\n",
      "Epoch 49/52\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 0.0271 - val_loss: 0.0192\n",
      "Epoch 50/52\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 0.0272 - val_loss: 0.0191\n",
      "Epoch 51/52\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 0.0272 - val_loss: 0.0194\n",
      "Epoch 52/52\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 0.0271 - val_loss: 0.0192\n",
      "Execution time:  17.335540771484375\n",
      "DNN:\n",
      "Mean Absolute Error: 0.0239\n",
      "Root Mean Square Error: 0.0395\n",
      "Mean Square Error: 0.0016\n",
      "\n",
      "Train RMSE: 0.040\n",
      "Train MSE: 0.002\n",
      "Train MAE: 0.024\n",
      "###########################\n",
      "\n",
      "MODEL:  DNN\n",
      "sequence:  1d\n",
      "units:  87\n",
      "dropout1:  0.40519643149940265\n",
      "optimizer: adam\n",
      "activationDense: sigmoid\n",
      "epochs: 80\n",
      "batchsize: 31\n",
      "validation_split: 0.1\n",
      "Model: \"sequential_150\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_450 (Dense)            (None, 144, 87)           174       \n",
      "_________________________________________________________________\n",
      "dense_451 (Dense)            (None, 144, 16)           1408      \n",
      "_________________________________________________________________\n",
      "dropout_150 (Dropout)        (None, 144, 16)           0         \n",
      "_________________________________________________________________\n",
      "dense_452 (Dense)            (None, 144, 1)            17        \n",
      "=================================================================\n",
      "Total params: 1,599\n",
      "Trainable params: 1,599\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/80\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "112/112 [==============================] - 1s 8ms/step - loss: 0.0452 - val_loss: 0.0252\n",
      "Epoch 2/80\n",
      "112/112 [==============================] - 1s 6ms/step - loss: 0.0425 - val_loss: 0.0247\n",
      "Epoch 3/80\n",
      "112/112 [==============================] - 1s 6ms/step - loss: 0.0401 - val_loss: 0.0234\n",
      "Epoch 4/80\n",
      "112/112 [==============================] - 1s 6ms/step - loss: 0.0386 - val_loss: 0.0208\n",
      "Epoch 5/80\n",
      "112/112 [==============================] - 1s 6ms/step - loss: 0.0371 - val_loss: 0.0203\n",
      "Epoch 6/80\n",
      "112/112 [==============================] - 1s 7ms/step - loss: 0.0360 - val_loss: 0.0193\n",
      "Epoch 7/80\n",
      "112/112 [==============================] - 1s 6ms/step - loss: 0.0348 - val_loss: 0.0194\n",
      "Epoch 8/80\n",
      "112/112 [==============================] - 1s 6ms/step - loss: 0.0336 - val_loss: 0.0189\n",
      "Epoch 9/80\n",
      "112/112 [==============================] - 1s 6ms/step - loss: 0.0327 - val_loss: 0.0183\n",
      "Epoch 10/80\n",
      "112/112 [==============================] - 1s 6ms/step - loss: 0.0319 - val_loss: 0.0184\n",
      "Epoch 11/80\n",
      "112/112 [==============================] - 1s 6ms/step - loss: 0.0312 - val_loss: 0.0180\n",
      "Epoch 12/80\n",
      "112/112 [==============================] - 1s 7ms/step - loss: 0.0306 - val_loss: 0.0178\n",
      "Epoch 13/80\n",
      "112/112 [==============================] - 1s 6ms/step - loss: 0.0301 - val_loss: 0.0171\n",
      "Epoch 14/80\n",
      "112/112 [==============================] - 1s 6ms/step - loss: 0.0296 - val_loss: 0.0171\n",
      "Epoch 15/80\n",
      "112/112 [==============================] - 1s 6ms/step - loss: 0.0292 - val_loss: 0.0166\n",
      "Epoch 16/80\n",
      "112/112 [==============================] - 1s 6ms/step - loss: 0.0288 - val_loss: 0.0163\n",
      "Epoch 17/80\n",
      "112/112 [==============================] - 1s 6ms/step - loss: 0.0286 - val_loss: 0.0161\n",
      "Epoch 18/80\n",
      "112/112 [==============================] - 1s 6ms/step - loss: 0.0283 - val_loss: 0.0159\n",
      "Epoch 19/80\n",
      "112/112 [==============================] - 1s 7ms/step - loss: 0.0281 - val_loss: 0.0158\n",
      "Epoch 20/80\n",
      "112/112 [==============================] - 1s 7ms/step - loss: 0.0279 - val_loss: 0.0158\n",
      "Epoch 21/80\n",
      "112/112 [==============================] - 1s 7ms/step - loss: 0.0278 - val_loss: 0.0157\n",
      "Epoch 22/80\n",
      "112/112 [==============================] - 1s 7ms/step - loss: 0.0276 - val_loss: 0.0160\n",
      "Epoch 23/80\n",
      "112/112 [==============================] - 1s 6ms/step - loss: 0.0275 - val_loss: 0.0158\n",
      "Epoch 24/80\n",
      "112/112 [==============================] - 1s 7ms/step - loss: 0.0274 - val_loss: 0.0158\n",
      "Epoch 25/80\n",
      "112/112 [==============================] - 1s 6ms/step - loss: 0.0274 - val_loss: 0.0157\n",
      "Epoch 26/80\n",
      "112/112 [==============================] - 1s 7ms/step - loss: 0.0275 - val_loss: 0.0155\n",
      "Epoch 27/80\n",
      "112/112 [==============================] - 1s 6ms/step - loss: 0.0273 - val_loss: 0.0155\n",
      "Epoch 28/80\n",
      "112/112 [==============================] - 1s 6ms/step - loss: 0.0272 - val_loss: 0.0156\n",
      "Epoch 29/80\n",
      "112/112 [==============================] - 1s 7ms/step - loss: 0.0272 - val_loss: 0.0155\n",
      "Epoch 30/80\n",
      "112/112 [==============================] - 1s 6ms/step - loss: 0.0272 - val_loss: 0.0158\n",
      "Epoch 31/80\n",
      "112/112 [==============================] - 1s 6ms/step - loss: 0.0271 - val_loss: 0.0156\n",
      "Epoch 32/80\n",
      "112/112 [==============================] - 1s 7ms/step - loss: 0.0271 - val_loss: 0.0156\n",
      "Epoch 33/80\n",
      "112/112 [==============================] - 1s 7ms/step - loss: 0.0270 - val_loss: 0.0156\n",
      "Epoch 34/80\n",
      "112/112 [==============================] - 1s 7ms/step - loss: 0.0270 - val_loss: 0.0158\n",
      "Epoch 35/80\n",
      "112/112 [==============================] - 1s 6ms/step - loss: 0.0269 - val_loss: 0.0157\n",
      "Epoch 36/80\n",
      "112/112 [==============================] - 1s 6ms/step - loss: 0.0269 - val_loss: 0.0156\n",
      "Epoch 37/80\n",
      "112/112 [==============================] - 1s 6ms/step - loss: 0.0269 - val_loss: 0.0164\n",
      "Epoch 38/80\n",
      "112/112 [==============================] - 1s 7ms/step - loss: 0.0268 - val_loss: 0.0165\n",
      "Epoch 39/80\n",
      "112/112 [==============================] - 1s 6ms/step - loss: 0.0267 - val_loss: 0.0161\n",
      "Epoch 40/80\n",
      "112/112 [==============================] - 1s 7ms/step - loss: 0.0267 - val_loss: 0.0161\n",
      "Epoch 41/80\n",
      "112/112 [==============================] - 1s 7ms/step - loss: 0.0267 - val_loss: 0.0160\n",
      "Epoch 42/80\n",
      "112/112 [==============================] - 1s 7ms/step - loss: 0.0267 - val_loss: 0.0166\n",
      "Epoch 43/80\n",
      "112/112 [==============================] - 1s 7ms/step - loss: 0.0266 - val_loss: 0.0171\n",
      "Epoch 44/80\n",
      "112/112 [==============================] - 1s 6ms/step - loss: 0.0266 - val_loss: 0.0172\n",
      "Epoch 45/80\n",
      "112/112 [==============================] - 1s 6ms/step - loss: 0.0265 - val_loss: 0.0173\n",
      "Epoch 46/80\n",
      "112/112 [==============================] - 1s 7ms/step - loss: 0.0265 - val_loss: 0.0177\n",
      "Epoch 47/80\n",
      "112/112 [==============================] - 1s 6ms/step - loss: 0.0265 - val_loss: 0.0176\n",
      "Epoch 48/80\n",
      "112/112 [==============================] - 1s 7ms/step - loss: 0.0265 - val_loss: 0.0176\n",
      "Epoch 49/80\n",
      "112/112 [==============================] - 1s 6ms/step - loss: 0.0264 - val_loss: 0.0172\n",
      "Epoch 50/80\n",
      "112/112 [==============================] - 1s 6ms/step - loss: 0.0264 - val_loss: 0.0172\n",
      "Epoch 51/80\n",
      "112/112 [==============================] - 1s 6ms/step - loss: 0.0264 - val_loss: 0.0173\n",
      "Epoch 52/80\n",
      "112/112 [==============================] - 1s 7ms/step - loss: 0.0265 - val_loss: 0.0177\n",
      "Epoch 53/80\n",
      "112/112 [==============================] - 1s 6ms/step - loss: 0.0264 - val_loss: 0.0173\n",
      "Epoch 54/80\n",
      "112/112 [==============================] - 1s 6ms/step - loss: 0.0264 - val_loss: 0.0173\n",
      "Epoch 55/80\n",
      "112/112 [==============================] - 1s 6ms/step - loss: 0.0264 - val_loss: 0.0173\n",
      "Epoch 56/80\n",
      "112/112 [==============================] - 1s 6ms/step - loss: 0.0264 - val_loss: 0.0173\n",
      "Epoch 57/80\n",
      "112/112 [==============================] - 1s 6ms/step - loss: 0.0264 - val_loss: 0.0173\n",
      "Epoch 58/80\n",
      "112/112 [==============================] - 1s 7ms/step - loss: 0.0264 - val_loss: 0.0173\n",
      "Epoch 59/80\n",
      "112/112 [==============================] - 1s 6ms/step - loss: 0.0264 - val_loss: 0.0173\n",
      "Epoch 60/80\n",
      "112/112 [==============================] - 1s 7ms/step - loss: 0.0264 - val_loss: 0.0173\n",
      "Epoch 61/80\n",
      "112/112 [==============================] - 1s 7ms/step - loss: 0.0264 - val_loss: 0.0173\n",
      "Epoch 62/80\n",
      "112/112 [==============================] - 1s 7ms/step - loss: 0.0264 - val_loss: 0.0173\n",
      "Epoch 63/80\n",
      "112/112 [==============================] - 1s 7ms/step - loss: 0.0264 - val_loss: 0.0173\n",
      "Epoch 64/80\n",
      "112/112 [==============================] - 1s 7ms/step - loss: 0.0264 - val_loss: 0.0173\n",
      "Epoch 65/80\n",
      "112/112 [==============================] - 1s 6ms/step - loss: 0.0264 - val_loss: 0.0172\n",
      "Epoch 66/80\n",
      "112/112 [==============================] - 1s 7ms/step - loss: 0.0264 - val_loss: 0.0173\n",
      "Epoch 67/80\n",
      "112/112 [==============================] - 1s 7ms/step - loss: 0.0265 - val_loss: 0.0178\n",
      "Epoch 68/80\n",
      "112/112 [==============================] - 1s 6ms/step - loss: 0.0264 - val_loss: 0.0173\n",
      "Epoch 69/80\n",
      "112/112 [==============================] - 1s 7ms/step - loss: 0.0264 - val_loss: 0.0173\n",
      "Epoch 70/80\n",
      "112/112 [==============================] - 1s 6ms/step - loss: 0.0264 - val_loss: 0.0172\n",
      "Epoch 71/80\n",
      "112/112 [==============================] - 1s 6ms/step - loss: 0.0264 - val_loss: 0.0173\n",
      "Epoch 72/80\n",
      "112/112 [==============================] - 1s 7ms/step - loss: 0.0264 - val_loss: 0.0173\n",
      "Epoch 73/80\n",
      "112/112 [==============================] - 1s 6ms/step - loss: 0.0264 - val_loss: 0.0173\n",
      "Epoch 74/80\n",
      "112/112 [==============================] - 1s 7ms/step - loss: 0.0264 - val_loss: 0.0173\n",
      "Epoch 75/80\n",
      "112/112 [==============================] - 1s 6ms/step - loss: 0.0264 - val_loss: 0.0173\n",
      "Epoch 76/80\n",
      "112/112 [==============================] - 1s 6ms/step - loss: 0.0264 - val_loss: 0.0173\n",
      "Epoch 77/80\n",
      "112/112 [==============================] - 1s 6ms/step - loss: 0.0264 - val_loss: 0.0172\n",
      "Epoch 78/80\n",
      "112/112 [==============================] - 1s 7ms/step - loss: 0.0264 - val_loss: 0.0172\n",
      "Epoch 79/80\n",
      "112/112 [==============================] - 1s 7ms/step - loss: 0.0264 - val_loss: 0.0172\n",
      "Epoch 80/80\n",
      "112/112 [==============================] - 1s 6ms/step - loss: 0.0264 - val_loss: 0.0172\n",
      "Execution time:  60.753777265548706\n",
      "DNN:\n",
      "Mean Absolute Error: 0.0258\n",
      "Root Mean Square Error: 0.0435\n",
      "Mean Square Error: 0.0019\n",
      "\n",
      "Train RMSE: 0.043\n",
      "Train MSE: 0.002\n",
      "Train MAE: 0.026\n",
      "###########################\n",
      "\n",
      "MODEL:  DNN\n",
      "sequence:  1d\n",
      "units:  80\n",
      "dropout1:  0.11814836227952394\n",
      "optimizer: adam\n",
      "activationDense: sigmoid\n",
      "epochs: 90\n",
      "batchsize: 25\n",
      "validation_split: 0.1\n",
      "Model: \"sequential_151\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_453 (Dense)            (None, 144, 80)           160       \n",
      "_________________________________________________________________\n",
      "dense_454 (Dense)            (None, 144, 16)           1296      \n",
      "_________________________________________________________________\n",
      "dropout_151 (Dropout)        (None, 144, 16)           0         \n",
      "_________________________________________________________________\n",
      "dense_455 (Dense)            (None, 144, 1)            17        \n",
      "=================================================================\n",
      "Total params: 1,473\n",
      "Trainable params: 1,473\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/90\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "139/139 [==============================] - 1s 7ms/step - loss: 0.0389 - val_loss: 0.0255\n",
      "Epoch 2/90\n",
      "139/139 [==============================] - 1s 6ms/step - loss: 0.0362 - val_loss: 0.0218\n",
      "Epoch 3/90\n",
      "139/139 [==============================] - 1s 5ms/step - loss: 0.0353 - val_loss: 0.0210\n",
      "Epoch 4/90\n",
      "139/139 [==============================] - 1s 5ms/step - loss: 0.0344 - val_loss: 0.0207\n",
      "Epoch 5/90\n",
      "139/139 [==============================] - 1s 5ms/step - loss: 0.0336 - val_loss: 0.0203\n",
      "Epoch 6/90\n",
      "139/139 [==============================] - 1s 5ms/step - loss: 0.0331 - val_loss: 0.0186\n",
      "Epoch 7/90\n",
      "139/139 [==============================] - 1s 5ms/step - loss: 0.0329 - val_loss: 0.0184\n",
      "Epoch 8/90\n",
      "139/139 [==============================] - 1s 5ms/step - loss: 0.0322 - val_loss: 0.0182\n",
      "Epoch 9/90\n",
      "139/139 [==============================] - 1s 5ms/step - loss: 0.0318 - val_loss: 0.0180\n",
      "Epoch 10/90\n",
      "139/139 [==============================] - 1s 5ms/step - loss: 0.0314 - val_loss: 0.0176\n",
      "Epoch 11/90\n",
      "139/139 [==============================] - 1s 5ms/step - loss: 0.0311 - val_loss: 0.0174\n",
      "Epoch 12/90\n",
      "139/139 [==============================] - 1s 5ms/step - loss: 0.0307 - val_loss: 0.0174\n",
      "Epoch 13/90\n",
      "139/139 [==============================] - 1s 5ms/step - loss: 0.0305 - val_loss: 0.0164\n",
      "Epoch 14/90\n",
      "139/139 [==============================] - 1s 5ms/step - loss: 0.0302 - val_loss: 0.0167\n",
      "Epoch 15/90\n",
      "139/139 [==============================] - 1s 5ms/step - loss: 0.0299 - val_loss: 0.0165\n",
      "Epoch 16/90\n",
      "139/139 [==============================] - 1s 5ms/step - loss: 0.0297 - val_loss: 0.0156\n",
      "Epoch 17/90\n",
      "139/139 [==============================] - 1s 5ms/step - loss: 0.0295 - val_loss: 0.0157\n",
      "Epoch 18/90\n",
      "139/139 [==============================] - 1s 5ms/step - loss: 0.0293 - val_loss: 0.0158\n",
      "Epoch 19/90\n",
      "139/139 [==============================] - 1s 5ms/step - loss: 0.0291 - val_loss: 0.0158\n",
      "Epoch 20/90\n",
      "139/139 [==============================] - 1s 5ms/step - loss: 0.0290 - val_loss: 0.0151\n",
      "Epoch 21/90\n",
      "139/139 [==============================] - 1s 5ms/step - loss: 0.0289 - val_loss: 0.0168\n",
      "Epoch 22/90\n",
      "139/139 [==============================] - 1s 5ms/step - loss: 0.0293 - val_loss: 0.0150\n",
      "Epoch 23/90\n",
      "139/139 [==============================] - 1s 6ms/step - loss: 0.0288 - val_loss: 0.0150\n",
      "Epoch 24/90\n",
      "139/139 [==============================] - 1s 6ms/step - loss: 0.0287 - val_loss: 0.0144\n",
      "Epoch 25/90\n",
      "139/139 [==============================] - 1s 5ms/step - loss: 0.0286 - val_loss: 0.0144\n",
      "Epoch 26/90\n",
      "139/139 [==============================] - 1s 5ms/step - loss: 0.0285 - val_loss: 0.0146\n",
      "Epoch 27/90\n",
      "139/139 [==============================] - 1s 5ms/step - loss: 0.0284 - val_loss: 0.0140\n",
      "Epoch 28/90\n",
      "139/139 [==============================] - 1s 5ms/step - loss: 0.0284 - val_loss: 0.0139\n",
      "Epoch 29/90\n",
      "139/139 [==============================] - 1s 5ms/step - loss: 0.0283 - val_loss: 0.0141\n",
      "Epoch 30/90\n",
      "139/139 [==============================] - 1s 5ms/step - loss: 0.0282 - val_loss: 0.0142\n",
      "Epoch 31/90\n",
      "139/139 [==============================] - 1s 5ms/step - loss: 0.0282 - val_loss: 0.0136\n",
      "Epoch 32/90\n",
      "139/139 [==============================] - 1s 5ms/step - loss: 0.0282 - val_loss: 0.0136\n",
      "Epoch 33/90\n",
      "139/139 [==============================] - 1s 5ms/step - loss: 0.0281 - val_loss: 0.0137\n",
      "Epoch 34/90\n",
      "139/139 [==============================] - 1s 5ms/step - loss: 0.0281 - val_loss: 0.0138\n",
      "Epoch 35/90\n",
      "139/139 [==============================] - 1s 5ms/step - loss: 0.0280 - val_loss: 0.0138\n",
      "Epoch 36/90\n",
      "139/139 [==============================] - 1s 5ms/step - loss: 0.0280 - val_loss: 0.0139\n",
      "Epoch 37/90\n",
      "139/139 [==============================] - 1s 5ms/step - loss: 0.0279 - val_loss: 0.0139\n",
      "Epoch 38/90\n",
      "139/139 [==============================] - 1s 5ms/step - loss: 0.0279 - val_loss: 0.0139\n",
      "Epoch 39/90\n",
      "139/139 [==============================] - 1s 5ms/step - loss: 0.0278 - val_loss: 0.0140\n",
      "Epoch 40/90\n",
      "139/139 [==============================] - 1s 5ms/step - loss: 0.0278 - val_loss: 0.0140\n",
      "Epoch 41/90\n",
      "139/139 [==============================] - 1s 5ms/step - loss: 0.0278 - val_loss: 0.0141\n",
      "Epoch 42/90\n",
      "139/139 [==============================] - 1s 5ms/step - loss: 0.0278 - val_loss: 0.0140\n",
      "Epoch 43/90\n",
      "139/139 [==============================] - 1s 5ms/step - loss: 0.0277 - val_loss: 0.0141\n",
      "Epoch 44/90\n",
      "139/139 [==============================] - 1s 6ms/step - loss: 0.0277 - val_loss: 0.0140\n",
      "Epoch 45/90\n",
      "139/139 [==============================] - 1s 6ms/step - loss: 0.0276 - val_loss: 0.0140\n",
      "Epoch 46/90\n",
      "139/139 [==============================] - 1s 5ms/step - loss: 0.0276 - val_loss: 0.0138\n",
      "Epoch 47/90\n",
      "139/139 [==============================] - 1s 5ms/step - loss: 0.0276 - val_loss: 0.0140\n",
      "Epoch 48/90\n",
      "139/139 [==============================] - 1s 5ms/step - loss: 0.0276 - val_loss: 0.0138\n",
      "Epoch 49/90\n",
      "139/139 [==============================] - 1s 5ms/step - loss: 0.0276 - val_loss: 0.0140\n",
      "Epoch 50/90\n",
      "139/139 [==============================] - 1s 5ms/step - loss: 0.0276 - val_loss: 0.0138\n",
      "Epoch 51/90\n",
      "139/139 [==============================] - 1s 5ms/step - loss: 0.0275 - val_loss: 0.0138\n",
      "Epoch 52/90\n",
      "139/139 [==============================] - 1s 5ms/step - loss: 0.0282 - val_loss: 0.0136\n",
      "Epoch 53/90\n",
      "139/139 [==============================] - 1s 5ms/step - loss: 0.0274 - val_loss: 0.0136\n",
      "Epoch 54/90\n",
      "139/139 [==============================] - 1s 5ms/step - loss: 0.0274 - val_loss: 0.0137\n",
      "Epoch 55/90\n",
      "139/139 [==============================] - 1s 5ms/step - loss: 0.0274 - val_loss: 0.0136\n",
      "Epoch 56/90\n",
      "139/139 [==============================] - 1s 5ms/step - loss: 0.0274 - val_loss: 0.0135\n",
      "Epoch 57/90\n",
      "139/139 [==============================] - 1s 5ms/step - loss: 0.0274 - val_loss: 0.0136\n",
      "Epoch 58/90\n",
      "139/139 [==============================] - 1s 5ms/step - loss: 0.0274 - val_loss: 0.0139\n",
      "Epoch 59/90\n",
      "139/139 [==============================] - 1s 5ms/step - loss: 0.0276 - val_loss: 0.0133\n",
      "Epoch 60/90\n",
      "139/139 [==============================] - 1s 5ms/step - loss: 0.0273 - val_loss: 0.0138\n",
      "Epoch 61/90\n",
      "139/139 [==============================] - 1s 5ms/step - loss: 0.0273 - val_loss: 0.0138\n",
      "Epoch 62/90\n",
      "139/139 [==============================] - 1s 5ms/step - loss: 0.0272 - val_loss: 0.0140\n",
      "Epoch 63/90\n",
      "139/139 [==============================] - 1s 5ms/step - loss: 0.0272 - val_loss: 0.0138\n",
      "Epoch 64/90\n",
      "139/139 [==============================] - 1s 5ms/step - loss: 0.0272 - val_loss: 0.0139\n",
      "Epoch 65/90\n",
      "139/139 [==============================] - 1s 6ms/step - loss: 0.0272 - val_loss: 0.0140\n",
      "Epoch 66/90\n",
      "139/139 [==============================] - 1s 6ms/step - loss: 0.0271 - val_loss: 0.0140\n",
      "Epoch 67/90\n",
      "139/139 [==============================] - 1s 6ms/step - loss: 0.0271 - val_loss: 0.0140\n",
      "Epoch 68/90\n",
      "139/139 [==============================] - 1s 5ms/step - loss: 0.0271 - val_loss: 0.0141\n",
      "Epoch 69/90\n",
      "139/139 [==============================] - 1s 5ms/step - loss: 0.0271 - val_loss: 0.0141\n",
      "Epoch 70/90\n",
      "139/139 [==============================] - 1s 5ms/step - loss: 0.0270 - val_loss: 0.0141\n",
      "Epoch 71/90\n",
      "139/139 [==============================] - 1s 5ms/step - loss: 0.0270 - val_loss: 0.0143\n",
      "Epoch 72/90\n",
      "139/139 [==============================] - 1s 5ms/step - loss: 0.0270 - val_loss: 0.0142\n",
      "Epoch 73/90\n",
      "139/139 [==============================] - 1s 5ms/step - loss: 0.0270 - val_loss: 0.0144\n",
      "Epoch 74/90\n",
      "139/139 [==============================] - 1s 5ms/step - loss: 0.0269 - val_loss: 0.0144\n",
      "Epoch 75/90\n",
      "139/139 [==============================] - 1s 5ms/step - loss: 0.0269 - val_loss: 0.0145\n",
      "Epoch 76/90\n",
      "139/139 [==============================] - 1s 5ms/step - loss: 0.0269 - val_loss: 0.0145\n",
      "Epoch 77/90\n",
      "139/139 [==============================] - 1s 5ms/step - loss: 0.0268 - val_loss: 0.0146\n",
      "Epoch 78/90\n",
      "139/139 [==============================] - 1s 5ms/step - loss: 0.0268 - val_loss: 0.0146\n",
      "Epoch 79/90\n",
      "139/139 [==============================] - 1s 5ms/step - loss: 0.0268 - val_loss: 0.0147\n",
      "Epoch 80/90\n",
      "139/139 [==============================] - 1s 5ms/step - loss: 0.0267 - val_loss: 0.0146\n",
      "Epoch 81/90\n",
      "139/139 [==============================] - 1s 5ms/step - loss: 0.0267 - val_loss: 0.0144\n",
      "Epoch 82/90\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "139/139 [==============================] - 1s 5ms/step - loss: 0.0267 - val_loss: 0.0147\n",
      "Epoch 83/90\n",
      "139/139 [==============================] - 1s 5ms/step - loss: 0.0267 - val_loss: 0.0144\n",
      "Epoch 84/90\n",
      "139/139 [==============================] - 1s 5ms/step - loss: 0.0267 - val_loss: 0.0148\n",
      "Epoch 85/90\n",
      "139/139 [==============================] - 1s 5ms/step - loss: 0.0267 - val_loss: 0.0147\n",
      "Epoch 86/90\n",
      "139/139 [==============================] - 1s 5ms/step - loss: 0.0266 - val_loss: 0.0147\n",
      "Epoch 87/90\n",
      "139/139 [==============================] - 1s 6ms/step - loss: 0.0266 - val_loss: 0.0147\n",
      "Epoch 88/90\n",
      "139/139 [==============================] - 1s 6ms/step - loss: 0.0266 - val_loss: 0.0147\n",
      "Epoch 89/90\n",
      "139/139 [==============================] - 1s 5ms/step - loss: 0.0266 - val_loss: 0.0147\n",
      "Epoch 90/90\n",
      "139/139 [==============================] - 1s 5ms/step - loss: 0.0266 - val_loss: 0.0146\n",
      "Execution time:  68.42319536209106\n",
      "DNN:\n",
      "Mean Absolute Error: 0.0254\n",
      "Root Mean Square Error: 0.0437\n",
      "Mean Square Error: 0.0019\n",
      "\n",
      "Train RMSE: 0.044\n",
      "Train MSE: 0.002\n",
      "Train MAE: 0.025\n",
      "###########################\n",
      "\n",
      "MODEL:  DNN\n",
      "sequence:  1d\n",
      "units:  12\n",
      "dropout1:  0.48476373451509647\n",
      "optimizer: adam\n",
      "activationDense: sigmoid\n",
      "epochs: 52\n",
      "batchsize: 57\n",
      "validation_split: 0.1\n",
      "Model: \"sequential_152\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_456 (Dense)            (None, 144, 12)           24        \n",
      "_________________________________________________________________\n",
      "dense_457 (Dense)            (None, 144, 16)           208       \n",
      "_________________________________________________________________\n",
      "dropout_152 (Dropout)        (None, 144, 16)           0         \n",
      "_________________________________________________________________\n",
      "dense_458 (Dense)            (None, 144, 1)            17        \n",
      "=================================================================\n",
      "Total params: 249\n",
      "Trainable params: 249\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/52\n",
      "61/61 [==============================] - 0s 8ms/step - loss: 0.0794 - val_loss: 0.0870\n",
      "Epoch 2/52\n",
      "61/61 [==============================] - 0s 5ms/step - loss: 0.0472 - val_loss: 0.0492\n",
      "Epoch 3/52\n",
      "61/61 [==============================] - 0s 5ms/step - loss: 0.0424 - val_loss: 0.0424\n",
      "Epoch 4/52\n",
      "61/61 [==============================] - 0s 5ms/step - loss: 0.0412 - val_loss: 0.0413\n",
      "Epoch 5/52\n",
      "61/61 [==============================] - 0s 5ms/step - loss: 0.0398 - val_loss: 0.0400\n",
      "Epoch 6/52\n",
      "61/61 [==============================] - 0s 5ms/step - loss: 0.0384 - val_loss: 0.0360\n",
      "Epoch 7/52\n",
      "61/61 [==============================] - 0s 5ms/step - loss: 0.0366 - val_loss: 0.0334\n",
      "Epoch 8/52\n",
      "61/61 [==============================] - 0s 5ms/step - loss: 0.0352 - val_loss: 0.0324\n",
      "Epoch 9/52\n",
      "61/61 [==============================] - 0s 5ms/step - loss: 0.0343 - val_loss: 0.0311\n",
      "Epoch 10/52\n",
      "61/61 [==============================] - 0s 5ms/step - loss: 0.0334 - val_loss: 0.0273\n",
      "Epoch 11/52\n",
      "61/61 [==============================] - 0s 5ms/step - loss: 0.0328 - val_loss: 0.0261\n",
      "Epoch 12/52\n",
      "61/61 [==============================] - 0s 5ms/step - loss: 0.0320 - val_loss: 0.0256\n",
      "Epoch 13/52\n",
      "61/61 [==============================] - 0s 5ms/step - loss: 0.0313 - val_loss: 0.0226\n",
      "Epoch 14/52\n",
      "61/61 [==============================] - 0s 5ms/step - loss: 0.0308 - val_loss: 0.0246\n",
      "Epoch 15/52\n",
      "61/61 [==============================] - 0s 5ms/step - loss: 0.0303 - val_loss: 0.0239\n",
      "Epoch 16/52\n",
      "61/61 [==============================] - 0s 5ms/step - loss: 0.0300 - val_loss: 0.0233\n",
      "Epoch 17/52\n",
      "61/61 [==============================] - 0s 5ms/step - loss: 0.0296 - val_loss: 0.0230\n",
      "Epoch 18/52\n",
      "61/61 [==============================] - 0s 5ms/step - loss: 0.0293 - val_loss: 0.0224\n",
      "Epoch 19/52\n",
      "61/61 [==============================] - 0s 5ms/step - loss: 0.0290 - val_loss: 0.0221\n",
      "Epoch 20/52\n",
      "61/61 [==============================] - 0s 5ms/step - loss: 0.0287 - val_loss: 0.0219\n",
      "Epoch 21/52\n",
      "61/61 [==============================] - 0s 5ms/step - loss: 0.0284 - val_loss: 0.0214\n",
      "Epoch 22/52\n",
      "61/61 [==============================] - 0s 5ms/step - loss: 0.0282 - val_loss: 0.0209\n",
      "Epoch 23/52\n",
      "61/61 [==============================] - 0s 5ms/step - loss: 0.0280 - val_loss: 0.0206\n",
      "Epoch 24/52\n",
      "61/61 [==============================] - 0s 5ms/step - loss: 0.0278 - val_loss: 0.0201\n",
      "Epoch 25/52\n",
      "61/61 [==============================] - 0s 5ms/step - loss: 0.0277 - val_loss: 0.0198\n",
      "Epoch 26/52\n",
      "61/61 [==============================] - 0s 5ms/step - loss: 0.0275 - val_loss: 0.0195\n",
      "Epoch 27/52\n",
      "61/61 [==============================] - 0s 5ms/step - loss: 0.0274 - val_loss: 0.0193\n",
      "Epoch 28/52\n",
      "61/61 [==============================] - 0s 5ms/step - loss: 0.0273 - val_loss: 0.0192\n",
      "Epoch 29/52\n",
      "61/61 [==============================] - 0s 5ms/step - loss: 0.0272 - val_loss: 0.0191\n",
      "Epoch 30/52\n",
      "61/61 [==============================] - 0s 5ms/step - loss: 0.0271 - val_loss: 0.0190\n",
      "Epoch 31/52\n",
      "61/61 [==============================] - 0s 5ms/step - loss: 0.0271 - val_loss: 0.0189\n",
      "Epoch 32/52\n",
      "61/61 [==============================] - 0s 5ms/step - loss: 0.0270 - val_loss: 0.0189\n",
      "Epoch 33/52\n",
      "61/61 [==============================] - 0s 5ms/step - loss: 0.0269 - val_loss: 0.0187\n",
      "Epoch 34/52\n",
      "61/61 [==============================] - 0s 5ms/step - loss: 0.0268 - val_loss: 0.0187\n",
      "Epoch 35/52\n",
      "61/61 [==============================] - 0s 5ms/step - loss: 0.0268 - val_loss: 0.0186\n",
      "Epoch 36/52\n",
      "61/61 [==============================] - 0s 6ms/step - loss: 0.0267 - val_loss: 0.0184\n",
      "Epoch 37/52\n",
      "61/61 [==============================] - 0s 5ms/step - loss: 0.0267 - val_loss: 0.0183\n",
      "Epoch 38/52\n",
      "61/61 [==============================] - 0s 6ms/step - loss: 0.0266 - val_loss: 0.0182\n",
      "Epoch 39/52\n",
      "61/61 [==============================] - 0s 5ms/step - loss: 0.0266 - val_loss: 0.0181\n",
      "Epoch 40/52\n",
      "61/61 [==============================] - 0s 5ms/step - loss: 0.0266 - val_loss: 0.0180\n",
      "Epoch 41/52\n",
      "61/61 [==============================] - 0s 6ms/step - loss: 0.0265 - val_loss: 0.0179\n",
      "Epoch 42/52\n",
      "61/61 [==============================] - 0s 5ms/step - loss: 0.0265 - val_loss: 0.0178\n",
      "Epoch 43/52\n",
      "61/61 [==============================] - 0s 5ms/step - loss: 0.0264 - val_loss: 0.0176\n",
      "Epoch 44/52\n",
      "61/61 [==============================] - 0s 5ms/step - loss: 0.0264 - val_loss: 0.0176\n",
      "Epoch 45/52\n",
      "61/61 [==============================] - 0s 6ms/step - loss: 0.0264 - val_loss: 0.0175\n",
      "Epoch 46/52\n",
      "61/61 [==============================] - 0s 5ms/step - loss: 0.0264 - val_loss: 0.0174\n",
      "Epoch 47/52\n",
      "61/61 [==============================] - 0s 5ms/step - loss: 0.0264 - val_loss: 0.0173\n",
      "Epoch 48/52\n",
      "61/61 [==============================] - 0s 5ms/step - loss: 0.0263 - val_loss: 0.0175\n",
      "Epoch 49/52\n",
      "61/61 [==============================] - 0s 5ms/step - loss: 0.0263 - val_loss: 0.0175\n",
      "Epoch 50/52\n",
      "61/61 [==============================] - 0s 5ms/step - loss: 0.0263 - val_loss: 0.0178\n",
      "Epoch 51/52\n",
      "61/61 [==============================] - 0s 5ms/step - loss: 0.0262 - val_loss: 0.0178\n",
      "Epoch 52/52\n",
      "61/61 [==============================] - 0s 5ms/step - loss: 0.0262 - val_loss: 0.0179\n",
      "Execution time:  17.819113731384277\n",
      "DNN:\n",
      "Mean Absolute Error: 0.0255\n",
      "Root Mean Square Error: 0.0429\n",
      "Mean Square Error: 0.0018\n",
      "\n",
      "Train RMSE: 0.043\n",
      "Train MSE: 0.002\n",
      "Train MAE: 0.025\n",
      "###########################\n",
      "\n",
      "MODEL:  DNN\n",
      "sequence:  1d\n",
      "units:  87\n",
      "dropout1:  0.40519643149940265\n",
      "optimizer: adam\n",
      "activationDense: sigmoid\n",
      "epochs: 80\n",
      "batchsize: 31\n",
      "validation_split: 0.2\n",
      "Model: \"sequential_153\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_459 (Dense)            (None, 144, 87)           174       \n",
      "_________________________________________________________________\n",
      "dense_460 (Dense)            (None, 144, 16)           1408      \n",
      "_________________________________________________________________\n",
      "dropout_153 (Dropout)        (None, 144, 16)           0         \n",
      "_________________________________________________________________\n",
      "dense_461 (Dense)            (None, 144, 1)            17        \n",
      "=================================================================\n",
      "Total params: 1,599\n",
      "Trainable params: 1,599\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/80\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100/100 [==============================] - 1s 9ms/step - loss: 0.0467 - val_loss: 0.0198\n",
      "Epoch 2/80\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 0.0449 - val_loss: 0.0211\n",
      "Epoch 3/80\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 0.0426 - val_loss: 0.0211\n",
      "Epoch 4/80\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 0.0408 - val_loss: 0.0215\n",
      "Epoch 5/80\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 0.0392 - val_loss: 0.0216\n",
      "Epoch 6/80\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 0.0378 - val_loss: 0.0216\n",
      "Epoch 7/80\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 0.0367 - val_loss: 0.0216\n",
      "Epoch 8/80\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 0.0354 - val_loss: 0.0210\n",
      "Epoch 9/80\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 0.0346 - val_loss: 0.0207\n",
      "Epoch 10/80\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 0.0337 - val_loss: 0.0206\n",
      "Epoch 11/80\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 0.0328 - val_loss: 0.0168\n",
      "Epoch 12/80\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 0.0325 - val_loss: 0.0201\n",
      "Epoch 13/80\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 0.0315 - val_loss: 0.0198\n",
      "Epoch 14/80\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 0.0311 - val_loss: 0.0198\n",
      "Epoch 15/80\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 0.0306 - val_loss: 0.0196\n",
      "Epoch 16/80\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 0.0302 - val_loss: 0.0196\n",
      "Epoch 17/80\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 0.0299 - val_loss: 0.0194\n",
      "Epoch 18/80\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 0.0296 - val_loss: 0.0193\n",
      "Epoch 19/80\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 0.0293 - val_loss: 0.0193\n",
      "Epoch 20/80\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 0.0291 - val_loss: 0.0191\n",
      "Epoch 21/80\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 0.0288 - val_loss: 0.0191\n",
      "Epoch 22/80\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 0.0286 - val_loss: 0.0189\n",
      "Epoch 23/80\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 0.0285 - val_loss: 0.0189\n",
      "Epoch 24/80\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 0.0279 - val_loss: 0.0181\n",
      "Epoch 25/80\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 0.0282 - val_loss: 0.0191\n",
      "Epoch 26/80\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 0.0282 - val_loss: 0.0187\n",
      "Epoch 27/80\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 0.0282 - val_loss: 0.0189\n",
      "Epoch 28/80\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 0.0281 - val_loss: 0.0189\n",
      "Epoch 29/80\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 0.0280 - val_loss: 0.0189\n",
      "Epoch 30/80\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 0.0280 - val_loss: 0.0192\n",
      "Epoch 31/80\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 0.0278 - val_loss: 0.0187\n",
      "Epoch 32/80\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 0.0279 - val_loss: 0.0186\n",
      "Epoch 33/80\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 0.0278 - val_loss: 0.0186\n",
      "Epoch 34/80\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 0.0278 - val_loss: 0.0187\n",
      "Epoch 35/80\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 0.0276 - val_loss: 0.0184\n",
      "Epoch 36/80\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 0.0277 - val_loss: 0.0186\n",
      "Epoch 37/80\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 0.0276 - val_loss: 0.0186\n",
      "Epoch 38/80\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 0.0276 - val_loss: 0.0187\n",
      "Epoch 39/80\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 0.0275 - val_loss: 0.0186\n",
      "Epoch 40/80\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 0.0275 - val_loss: 0.0185\n",
      "Epoch 41/80\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 0.0275 - val_loss: 0.0184\n",
      "Epoch 42/80\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 0.0275 - val_loss: 0.0184\n",
      "Epoch 43/80\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 0.0275 - val_loss: 0.0187\n",
      "Epoch 44/80\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 0.0276 - val_loss: 0.0191\n",
      "Epoch 45/80\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 0.0272 - val_loss: 0.0186\n",
      "Epoch 46/80\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 0.0274 - val_loss: 0.0185\n",
      "Epoch 47/80\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 0.0273 - val_loss: 0.0184\n",
      "Epoch 48/80\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 0.0274 - val_loss: 0.0188\n",
      "Epoch 49/80\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 0.0273 - val_loss: 0.0188\n",
      "Epoch 50/80\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 0.0273 - val_loss: 0.0188\n",
      "Epoch 51/80\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 0.0272 - val_loss: 0.0189\n",
      "Epoch 52/80\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 0.0272 - val_loss: 0.0187\n",
      "Epoch 53/80\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 0.0272 - val_loss: 0.0187\n",
      "Epoch 54/80\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 0.0272 - val_loss: 0.0186\n",
      "Epoch 55/80\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 0.0272 - val_loss: 0.0187\n",
      "Epoch 56/80\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 0.0272 - val_loss: 0.0188\n",
      "Epoch 57/80\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 0.0272 - val_loss: 0.0187\n",
      "Epoch 58/80\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 0.0272 - val_loss: 0.0188\n",
      "Epoch 59/80\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 0.0272 - val_loss: 0.0187\n",
      "Epoch 60/80\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 0.0272 - val_loss: 0.0187\n",
      "Epoch 61/80\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 0.0272 - val_loss: 0.0187\n",
      "Epoch 62/80\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 0.0272 - val_loss: 0.0187\n",
      "Epoch 63/80\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 0.0272 - val_loss: 0.0187\n",
      "Epoch 64/80\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 0.0272 - val_loss: 0.0186\n",
      "Epoch 65/80\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 0.0272 - val_loss: 0.0186\n",
      "Epoch 66/80\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 0.0272 - val_loss: 0.0186\n",
      "Epoch 67/80\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 0.0272 - val_loss: 0.0185\n",
      "Epoch 68/80\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 0.0272 - val_loss: 0.0185\n",
      "Epoch 69/80\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 0.0272 - val_loss: 0.0185\n",
      "Epoch 70/80\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 0.0272 - val_loss: 0.0185\n",
      "Epoch 71/80\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 0.0272 - val_loss: 0.0185\n",
      "Epoch 72/80\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 0.0272 - val_loss: 0.0184\n",
      "Epoch 73/80\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 0.0272 - val_loss: 0.0185\n",
      "Epoch 74/80\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 0.0272 - val_loss: 0.0184\n",
      "Epoch 75/80\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 0.0272 - val_loss: 0.0184\n",
      "Epoch 76/80\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 0.0272 - val_loss: 0.0184\n",
      "Epoch 77/80\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 0.0271 - val_loss: 0.0183\n",
      "Epoch 78/80\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 0.0272 - val_loss: 0.0183\n",
      "Epoch 79/80\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 0.0272 - val_loss: 0.0182\n",
      "Epoch 80/80\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 0.0272 - val_loss: 0.0182\n",
      "Execution time:  57.21766257286072\n",
      "DNN:\n",
      "Mean Absolute Error: 0.0250\n",
      "Root Mean Square Error: 0.0427\n",
      "Mean Square Error: 0.0018\n",
      "\n",
      "Train RMSE: 0.043\n",
      "Train MSE: 0.002\n",
      "Train MAE: 0.025\n",
      "###########################\n",
      "\n",
      "MODEL:  DNN\n",
      "sequence:  1d\n",
      "units:  80\n",
      "dropout1:  0.11814836227952394\n",
      "optimizer: adam\n",
      "activationDense: sigmoid\n",
      "epochs: 90\n",
      "batchsize: 25\n",
      "validation_split: 0.2\n",
      "Model: \"sequential_154\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_462 (Dense)            (None, 144, 80)           160       \n",
      "_________________________________________________________________\n",
      "dense_463 (Dense)            (None, 144, 16)           1296      \n",
      "_________________________________________________________________\n",
      "dropout_154 (Dropout)        (None, 144, 16)           0         \n",
      "_________________________________________________________________\n",
      "dense_464 (Dense)            (None, 144, 1)            17        \n",
      "=================================================================\n",
      "Total params: 1,473\n",
      "Trainable params: 1,473\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/90\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0438 - val_loss: 0.0181\n",
      "Epoch 2/90\n",
      "124/124 [==============================] - 1s 5ms/step - loss: 0.0363 - val_loss: 0.0180\n",
      "Epoch 3/90\n",
      "124/124 [==============================] - 1s 5ms/step - loss: 0.0359 - val_loss: 0.0179\n",
      "Epoch 4/90\n",
      "124/124 [==============================] - 1s 5ms/step - loss: 0.0352 - val_loss: 0.0178\n",
      "Epoch 5/90\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.0346 - val_loss: 0.0179\n",
      "Epoch 6/90\n",
      "124/124 [==============================] - 1s 5ms/step - loss: 0.0341 - val_loss: 0.0177\n",
      "Epoch 7/90\n",
      "124/124 [==============================] - 1s 5ms/step - loss: 0.0338 - val_loss: 0.0176\n",
      "Epoch 8/90\n",
      "124/124 [==============================] - 1s 5ms/step - loss: 0.0332 - val_loss: 0.0177\n",
      "Epoch 9/90\n",
      "124/124 [==============================] - 1s 5ms/step - loss: 0.0329 - val_loss: 0.0174\n",
      "Epoch 10/90\n",
      "124/124 [==============================] - 1s 5ms/step - loss: 0.0325 - val_loss: 0.0178\n",
      "Epoch 11/90\n",
      "124/124 [==============================] - 1s 5ms/step - loss: 0.0321 - val_loss: 0.0175\n",
      "Epoch 12/90\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.0319 - val_loss: 0.0176\n",
      "Epoch 13/90\n",
      "124/124 [==============================] - 1s 5ms/step - loss: 0.0316 - val_loss: 0.0176\n",
      "Epoch 14/90\n",
      "124/124 [==============================] - 1s 5ms/step - loss: 0.0313 - val_loss: 0.0177\n",
      "Epoch 15/90\n",
      "124/124 [==============================] - 1s 5ms/step - loss: 0.0310 - val_loss: 0.0175\n",
      "Epoch 16/90\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.0309 - val_loss: 0.0176\n",
      "Epoch 17/90\n",
      "124/124 [==============================] - 1s 5ms/step - loss: 0.0322 - val_loss: 0.0170\n",
      "Epoch 18/90\n",
      "124/124 [==============================] - 1s 5ms/step - loss: 0.0308 - val_loss: 0.0173\n",
      "Epoch 19/90\n",
      "124/124 [==============================] - 1s 5ms/step - loss: 0.0304 - val_loss: 0.0177\n",
      "Epoch 20/90\n",
      "124/124 [==============================] - 1s 5ms/step - loss: 0.0301 - val_loss: 0.0177\n",
      "Epoch 21/90\n",
      "124/124 [==============================] - 1s 5ms/step - loss: 0.0299 - val_loss: 0.0177\n",
      "Epoch 22/90\n",
      "124/124 [==============================] - 1s 5ms/step - loss: 0.0298 - val_loss: 0.0177\n",
      "Epoch 23/90\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.0298 - val_loss: 0.0178\n",
      "Epoch 24/90\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.0296 - val_loss: 0.0179\n",
      "Epoch 25/90\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.0295 - val_loss: 0.0179\n",
      "Epoch 26/90\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.0294 - val_loss: 0.0179\n",
      "Epoch 27/90\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.0293 - val_loss: 0.0179\n",
      "Epoch 28/90\n",
      "124/124 [==============================] - 1s 5ms/step - loss: 0.0292 - val_loss: 0.0180\n",
      "Epoch 29/90\n",
      "124/124 [==============================] - 1s 5ms/step - loss: 0.0291 - val_loss: 0.0180\n",
      "Epoch 30/90\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.0291 - val_loss: 0.0180\n",
      "Epoch 31/90\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.0290 - val_loss: 0.0181\n",
      "Epoch 32/90\n",
      "124/124 [==============================] - 1s 5ms/step - loss: 0.0289 - val_loss: 0.0182\n",
      "Epoch 33/90\n",
      "124/124 [==============================] - 1s 5ms/step - loss: 0.0288 - val_loss: 0.0181\n",
      "Epoch 34/90\n",
      "124/124 [==============================] - 1s 5ms/step - loss: 0.0288 - val_loss: 0.0182\n",
      "Epoch 35/90\n",
      "124/124 [==============================] - 1s 5ms/step - loss: 0.0287 - val_loss: 0.0182\n",
      "Epoch 36/90\n",
      "124/124 [==============================] - 1s 5ms/step - loss: 0.0286 - val_loss: 0.0183\n",
      "Epoch 37/90\n",
      "124/124 [==============================] - 1s 5ms/step - loss: 0.0286 - val_loss: 0.0183\n",
      "Epoch 38/90\n",
      "124/124 [==============================] - 1s 5ms/step - loss: 0.0286 - val_loss: 0.0183\n",
      "Epoch 39/90\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.0285 - val_loss: 0.0184\n",
      "Epoch 40/90\n",
      "124/124 [==============================] - 1s 5ms/step - loss: 0.0285 - val_loss: 0.0183\n",
      "Epoch 41/90\n",
      "124/124 [==============================] - 1s 5ms/step - loss: 0.0285 - val_loss: 0.0183\n",
      "Epoch 42/90\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.0284 - val_loss: 0.0184\n",
      "Epoch 43/90\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.0284 - val_loss: 0.0184\n",
      "Epoch 44/90\n",
      "124/124 [==============================] - 1s 5ms/step - loss: 0.0284 - val_loss: 0.0184\n",
      "Epoch 45/90\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.0284 - val_loss: 0.0184\n",
      "Epoch 46/90\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.0283 - val_loss: 0.0184\n",
      "Epoch 47/90\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.0283 - val_loss: 0.0184\n",
      "Epoch 48/90\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.0283 - val_loss: 0.0184\n",
      "Epoch 49/90\n",
      "124/124 [==============================] - 1s 5ms/step - loss: 0.0283 - val_loss: 0.0184\n",
      "Epoch 50/90\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.0283 - val_loss: 0.0184\n",
      "Epoch 51/90\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.0283 - val_loss: 0.0184\n",
      "Epoch 52/90\n",
      "124/124 [==============================] - 1s 5ms/step - loss: 0.0282 - val_loss: 0.0184\n",
      "Epoch 53/90\n",
      "124/124 [==============================] - 1s 5ms/step - loss: 0.0282 - val_loss: 0.0184\n",
      "Epoch 54/90\n",
      "124/124 [==============================] - 1s 5ms/step - loss: 0.0282 - val_loss: 0.0184\n",
      "Epoch 55/90\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.0282 - val_loss: 0.0184\n",
      "Epoch 56/90\n",
      "124/124 [==============================] - 1s 5ms/step - loss: 0.0281 - val_loss: 0.0184\n",
      "Epoch 57/90\n",
      "124/124 [==============================] - 1s 5ms/step - loss: 0.0281 - val_loss: 0.0184\n",
      "Epoch 58/90\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.0281 - val_loss: 0.0184\n",
      "Epoch 59/90\n",
      "124/124 [==============================] - 1s 5ms/step - loss: 0.0281 - val_loss: 0.0185\n",
      "Epoch 60/90\n",
      "124/124 [==============================] - 1s 5ms/step - loss: 0.0280 - val_loss: 0.0184\n",
      "Epoch 61/90\n",
      "124/124 [==============================] - 1s 5ms/step - loss: 0.0280 - val_loss: 0.0185\n",
      "Epoch 62/90\n",
      "124/124 [==============================] - 1s 5ms/step - loss: 0.0280 - val_loss: 0.0185\n",
      "Epoch 63/90\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.0279 - val_loss: 0.0184\n",
      "Epoch 64/90\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.0279 - val_loss: 0.0185\n",
      "Epoch 65/90\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.0279 - val_loss: 0.0184\n",
      "Epoch 66/90\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.0279 - val_loss: 0.0185\n",
      "Epoch 67/90\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.0279 - val_loss: 0.0185\n",
      "Epoch 68/90\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.0278 - val_loss: 0.0185\n",
      "Epoch 69/90\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.0278 - val_loss: 0.0185\n",
      "Epoch 70/90\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.0278 - val_loss: 0.0185\n",
      "Epoch 71/90\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.0278 - val_loss: 0.0185\n",
      "Epoch 72/90\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.0277 - val_loss: 0.0185\n",
      "Epoch 73/90\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.0277 - val_loss: 0.0186\n",
      "Epoch 74/90\n",
      "124/124 [==============================] - 1s 5ms/step - loss: 0.0277 - val_loss: 0.0186\n",
      "Epoch 75/90\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.0276 - val_loss: 0.0185\n",
      "Epoch 76/90\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.0276 - val_loss: 0.0185\n",
      "Epoch 77/90\n",
      "124/124 [==============================] - 1s 5ms/step - loss: 0.0276 - val_loss: 0.0185\n",
      "Epoch 78/90\n",
      "124/124 [==============================] - 1s 5ms/step - loss: 0.0276 - val_loss: 0.0185\n",
      "Epoch 79/90\n",
      "124/124 [==============================] - 1s 5ms/step - loss: 0.0276 - val_loss: 0.0185\n",
      "Epoch 80/90\n",
      "124/124 [==============================] - 1s 5ms/step - loss: 0.0275 - val_loss: 0.0185\n",
      "Epoch 81/90\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.0275 - val_loss: 0.0184\n",
      "Epoch 82/90\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "124/124 [==============================] - 1s 6ms/step - loss: 0.0275 - val_loss: 0.0184\n",
      "Epoch 83/90\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.0275 - val_loss: 0.0185\n",
      "Epoch 84/90\n",
      "124/124 [==============================] - 1s 5ms/step - loss: 0.0274 - val_loss: 0.0184\n",
      "Epoch 85/90\n",
      "124/124 [==============================] - 1s 5ms/step - loss: 0.0275 - val_loss: 0.0184\n",
      "Epoch 86/90\n",
      "124/124 [==============================] - 1s 5ms/step - loss: 0.0274 - val_loss: 0.0184\n",
      "Epoch 87/90\n",
      "124/124 [==============================] - 1s 5ms/step - loss: 0.0274 - val_loss: 0.0184\n",
      "Epoch 88/90\n",
      "124/124 [==============================] - 1s 5ms/step - loss: 0.0274 - val_loss: 0.0184\n",
      "Epoch 89/90\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.0274 - val_loss: 0.0184\n",
      "Epoch 90/90\n",
      "124/124 [==============================] - 1s 5ms/step - loss: 0.0273 - val_loss: 0.0184\n",
      "Execution time:  64.38503503799438\n",
      "DNN:\n",
      "Mean Absolute Error: 0.0252\n",
      "Root Mean Square Error: 0.0431\n",
      "Mean Square Error: 0.0019\n",
      "\n",
      "Train RMSE: 0.043\n",
      "Train MSE: 0.002\n",
      "Train MAE: 0.025\n",
      "###########################\n",
      "\n",
      "MODEL:  DNN\n",
      "sequence:  1d\n",
      "units:  12\n",
      "dropout1:  0.48476373451509647\n",
      "optimizer: adam\n",
      "activationDense: sigmoid\n",
      "epochs: 52\n",
      "batchsize: 57\n",
      "validation_split: 0.2\n",
      "Model: \"sequential_155\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_465 (Dense)            (None, 144, 12)           24        \n",
      "_________________________________________________________________\n",
      "dense_466 (Dense)            (None, 144, 16)           208       \n",
      "_________________________________________________________________\n",
      "dropout_155 (Dropout)        (None, 144, 16)           0         \n",
      "_________________________________________________________________\n",
      "dense_467 (Dense)            (None, 144, 1)            17        \n",
      "=================================================================\n",
      "Total params: 249\n",
      "Trainable params: 249\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/52\n",
      "54/54 [==============================] - 0s 8ms/step - loss: 0.0471 - val_loss: 0.0361\n",
      "Epoch 2/52\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 0.0441 - val_loss: 0.0371\n",
      "Epoch 3/52\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 0.0426 - val_loss: 0.0347\n",
      "Epoch 4/52\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 0.0414 - val_loss: 0.0343\n",
      "Epoch 5/52\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 0.0401 - val_loss: 0.0331\n",
      "Epoch 6/52\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 0.0392 - val_loss: 0.0319\n",
      "Epoch 7/52\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 0.0385 - val_loss: 0.0311\n",
      "Epoch 8/52\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 0.0378 - val_loss: 0.0305\n",
      "Epoch 9/52\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 0.0373 - val_loss: 0.0301\n",
      "Epoch 10/52\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 0.0363 - val_loss: 0.0242\n",
      "Epoch 11/52\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 0.0358 - val_loss: 0.0262\n",
      "Epoch 12/52\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 0.0346 - val_loss: 0.0260\n",
      "Epoch 13/52\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 0.0341 - val_loss: 0.0257\n",
      "Epoch 14/52\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 0.0336 - val_loss: 0.0254\n",
      "Epoch 15/52\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 0.0332 - val_loss: 0.0248\n",
      "Epoch 16/52\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 0.0328 - val_loss: 0.0244\n",
      "Epoch 17/52\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 0.0324 - val_loss: 0.0240\n",
      "Epoch 18/52\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 0.0320 - val_loss: 0.0237\n",
      "Epoch 19/52\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 0.0317 - val_loss: 0.0233\n",
      "Epoch 20/52\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 0.0314 - val_loss: 0.0230\n",
      "Epoch 21/52\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 0.0310 - val_loss: 0.0226\n",
      "Epoch 22/52\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 0.0308 - val_loss: 0.0225\n",
      "Epoch 23/52\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 0.0305 - val_loss: 0.0221\n",
      "Epoch 24/52\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 0.0303 - val_loss: 0.0217\n",
      "Epoch 25/52\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 0.0301 - val_loss: 0.0217\n",
      "Epoch 26/52\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 0.0298 - val_loss: 0.0213\n",
      "Epoch 27/52\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 0.0296 - val_loss: 0.0209\n",
      "Epoch 28/52\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 0.0294 - val_loss: 0.0208\n",
      "Epoch 29/52\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 0.0292 - val_loss: 0.0205\n",
      "Epoch 30/52\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 0.0291 - val_loss: 0.0201\n",
      "Epoch 31/52\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 0.0289 - val_loss: 0.0201\n",
      "Epoch 32/52\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 0.0287 - val_loss: 0.0199\n",
      "Epoch 33/52\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 0.0286 - val_loss: 0.0195\n",
      "Epoch 34/52\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 0.0285 - val_loss: 0.0193\n",
      "Epoch 35/52\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 0.0283 - val_loss: 0.0192\n",
      "Epoch 36/52\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 0.0282 - val_loss: 0.0190\n",
      "Epoch 37/52\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 0.0281 - val_loss: 0.0189\n",
      "Epoch 38/52\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 0.0280 - val_loss: 0.0188\n",
      "Epoch 39/52\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 0.0280 - val_loss: 0.0187\n",
      "Epoch 40/52\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 0.0279 - val_loss: 0.0186\n",
      "Epoch 41/52\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 0.0278 - val_loss: 0.0186\n",
      "Epoch 42/52\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 0.0277 - val_loss: 0.0185\n",
      "Epoch 43/52\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 0.0276 - val_loss: 0.0183\n",
      "Epoch 44/52\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 0.0276 - val_loss: 0.0182\n",
      "Epoch 45/52\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 0.0275 - val_loss: 0.0182\n",
      "Epoch 46/52\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 0.0274 - val_loss: 0.0181\n",
      "Epoch 47/52\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 0.0274 - val_loss: 0.0181\n",
      "Epoch 48/52\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 0.0273 - val_loss: 0.0180\n",
      "Epoch 49/52\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 0.0273 - val_loss: 0.0179\n",
      "Epoch 50/52\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 0.0273 - val_loss: 0.0179\n",
      "Epoch 51/52\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 0.0272 - val_loss: 0.0179\n",
      "Epoch 52/52\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 0.0271 - val_loss: 0.0178\n",
      "Execution time:  17.002779245376587\n",
      "DNN:\n",
      "Mean Absolute Error: 0.0226\n",
      "Root Mean Square Error: 0.0394\n",
      "Mean Square Error: 0.0016\n",
      "\n",
      "Train RMSE: 0.039\n",
      "Train MSE: 0.002\n",
      "Train MAE: 0.023\n",
      "###########################\n",
      "\n",
      "MODEL:  DNN\n",
      "sequence:  1d\n",
      "units:  87\n",
      "dropout1:  0.40519643149940265\n",
      "optimizer: adadelta\n",
      "activationDense: tanh\n",
      "epochs: 80\n",
      "batchsize: 31\n",
      "validation_split: 0.1\n",
      "Model: \"sequential_156\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_468 (Dense)            (None, 144, 87)           174       \n",
      "_________________________________________________________________\n",
      "dense_469 (Dense)            (None, 144, 16)           1408      \n",
      "_________________________________________________________________\n",
      "dropout_156 (Dropout)        (None, 144, 16)           0         \n",
      "_________________________________________________________________\n",
      "dense_470 (Dense)            (None, 144, 1)            17        \n",
      "=================================================================\n",
      "Total params: 1,599\n",
      "Trainable params: 1,599\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/80\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "112/112 [==============================] - 1s 8ms/step - loss: 0.2757 - val_loss: 0.2496\n",
      "Epoch 2/80\n",
      "112/112 [==============================] - 1s 6ms/step - loss: 0.2725 - val_loss: 0.2463\n",
      "Epoch 3/80\n",
      "112/112 [==============================] - 1s 6ms/step - loss: 0.2688 - val_loss: 0.2426\n",
      "Epoch 4/80\n",
      "112/112 [==============================] - 1s 6ms/step - loss: 0.2649 - val_loss: 0.2386\n",
      "Epoch 5/80\n",
      "112/112 [==============================] - 1s 6ms/step - loss: 0.2604 - val_loss: 0.2343\n",
      "Epoch 6/80\n",
      "112/112 [==============================] - 1s 6ms/step - loss: 0.2561 - val_loss: 0.2298\n",
      "Epoch 7/80\n",
      "112/112 [==============================] - 1s 6ms/step - loss: 0.2514 - val_loss: 0.2251\n",
      "Epoch 8/80\n",
      "112/112 [==============================] - 1s 6ms/step - loss: 0.2464 - val_loss: 0.2201\n",
      "Epoch 9/80\n",
      "112/112 [==============================] - 1s 6ms/step - loss: 0.2414 - val_loss: 0.2149\n",
      "Epoch 10/80\n",
      "112/112 [==============================] - 1s 6ms/step - loss: 0.2360 - val_loss: 0.2095\n",
      "Epoch 11/80\n",
      "112/112 [==============================] - 1s 6ms/step - loss: 0.2299 - val_loss: 0.2039\n",
      "Epoch 12/80\n",
      "112/112 [==============================] - 1s 6ms/step - loss: 0.2243 - val_loss: 0.1980\n",
      "Epoch 13/80\n",
      "112/112 [==============================] - 1s 6ms/step - loss: 0.2181 - val_loss: 0.1920\n",
      "Epoch 14/80\n",
      "112/112 [==============================] - 1s 6ms/step - loss: 0.2119 - val_loss: 0.1858\n",
      "Epoch 15/80\n",
      "112/112 [==============================] - 1s 6ms/step - loss: 0.2056 - val_loss: 0.1795\n",
      "Epoch 16/80\n",
      "112/112 [==============================] - 1s 6ms/step - loss: 0.1990 - val_loss: 0.1730\n",
      "Epoch 17/80\n",
      "112/112 [==============================] - 1s 6ms/step - loss: 0.1924 - val_loss: 0.1664\n",
      "Epoch 18/80\n",
      "112/112 [==============================] - 1s 6ms/step - loss: 0.1860 - val_loss: 0.1598\n",
      "Epoch 19/80\n",
      "112/112 [==============================] - 1s 7ms/step - loss: 0.1794 - val_loss: 0.1534\n",
      "Epoch 20/80\n",
      "112/112 [==============================] - 1s 7ms/step - loss: 0.1730 - val_loss: 0.1472\n",
      "Epoch 21/80\n",
      "112/112 [==============================] - 1s 7ms/step - loss: 0.1668 - val_loss: 0.1410\n",
      "Epoch 22/80\n",
      "112/112 [==============================] - 1s 7ms/step - loss: 0.1609 - val_loss: 0.1349\n",
      "Epoch 23/80\n",
      "112/112 [==============================] - 1s 6ms/step - loss: 0.1555 - val_loss: 0.1291\n",
      "Epoch 24/80\n",
      "112/112 [==============================] - 1s 6ms/step - loss: 0.1505 - val_loss: 0.1234\n",
      "Epoch 25/80\n",
      "112/112 [==============================] - 1s 6ms/step - loss: 0.1457 - val_loss: 0.1180\n",
      "Epoch 26/80\n",
      "112/112 [==============================] - 1s 6ms/step - loss: 0.1415 - val_loss: 0.1128\n",
      "Epoch 27/80\n",
      "112/112 [==============================] - 1s 6ms/step - loss: 0.1377 - val_loss: 0.1078\n",
      "Epoch 28/80\n",
      "112/112 [==============================] - 1s 6ms/step - loss: 0.1342 - val_loss: 0.1032\n",
      "Epoch 29/80\n",
      "112/112 [==============================] - 1s 6ms/step - loss: 0.1316 - val_loss: 0.0990\n",
      "Epoch 30/80\n",
      "112/112 [==============================] - 1s 6ms/step - loss: 0.1290 - val_loss: 0.0952\n",
      "Epoch 31/80\n",
      "112/112 [==============================] - 1s 6ms/step - loss: 0.1269 - val_loss: 0.0915\n",
      "Epoch 32/80\n",
      "112/112 [==============================] - 1s 6ms/step - loss: 0.1249 - val_loss: 0.0881\n",
      "Epoch 33/80\n",
      "112/112 [==============================] - 1s 6ms/step - loss: 0.1232 - val_loss: 0.0850\n",
      "Epoch 34/80\n",
      "112/112 [==============================] - 1s 6ms/step - loss: 0.1218 - val_loss: 0.0820\n",
      "Epoch 35/80\n",
      "112/112 [==============================] - 1s 6ms/step - loss: 0.1204 - val_loss: 0.0792\n",
      "Epoch 36/80\n",
      "112/112 [==============================] - 1s 6ms/step - loss: 0.1192 - val_loss: 0.0765\n",
      "Epoch 37/80\n",
      "112/112 [==============================] - 1s 6ms/step - loss: 0.1181 - val_loss: 0.0741\n",
      "Epoch 38/80\n",
      "112/112 [==============================] - 1s 6ms/step - loss: 0.1170 - val_loss: 0.0717\n",
      "Epoch 39/80\n",
      "112/112 [==============================] - 1s 6ms/step - loss: 0.1161 - val_loss: 0.0695\n",
      "Epoch 40/80\n",
      "112/112 [==============================] - 1s 6ms/step - loss: 0.1152 - val_loss: 0.0675\n",
      "Epoch 41/80\n",
      "112/112 [==============================] - 1s 7ms/step - loss: 0.1145 - val_loss: 0.0655\n",
      "Epoch 42/80\n",
      "112/112 [==============================] - 1s 7ms/step - loss: 0.1138 - val_loss: 0.0636\n",
      "Epoch 43/80\n",
      "112/112 [==============================] - 1s 7ms/step - loss: 0.1132 - val_loss: 0.0619\n",
      "Epoch 44/80\n",
      "112/112 [==============================] - 1s 6ms/step - loss: 0.1123 - val_loss: 0.0602\n",
      "Epoch 45/80\n",
      "112/112 [==============================] - 1s 6ms/step - loss: 0.1118 - val_loss: 0.0585\n",
      "Epoch 46/80\n",
      "112/112 [==============================] - 1s 6ms/step - loss: 0.1113 - val_loss: 0.0570\n",
      "Epoch 47/80\n",
      "112/112 [==============================] - 1s 6ms/step - loss: 0.1107 - val_loss: 0.0555\n",
      "Epoch 48/80\n",
      "112/112 [==============================] - 1s 6ms/step - loss: 0.1101 - val_loss: 0.0540\n",
      "Epoch 49/80\n",
      "112/112 [==============================] - 1s 6ms/step - loss: 0.1099 - val_loss: 0.0526\n",
      "Epoch 50/80\n",
      "112/112 [==============================] - 1s 7ms/step - loss: 0.1092 - val_loss: 0.0513\n",
      "Epoch 51/80\n",
      "112/112 [==============================] - 1s 6ms/step - loss: 0.1090 - val_loss: 0.0500\n",
      "Epoch 52/80\n",
      "112/112 [==============================] - 1s 6ms/step - loss: 0.1085 - val_loss: 0.0488\n",
      "Epoch 53/80\n",
      "112/112 [==============================] - 1s 6ms/step - loss: 0.1080 - val_loss: 0.0476\n",
      "Epoch 54/80\n",
      "112/112 [==============================] - 1s 6ms/step - loss: 0.1078 - val_loss: 0.0465\n",
      "Epoch 55/80\n",
      "112/112 [==============================] - 1s 6ms/step - loss: 0.1073 - val_loss: 0.0454\n",
      "Epoch 56/80\n",
      "112/112 [==============================] - 1s 6ms/step - loss: 0.1069 - val_loss: 0.0444\n",
      "Epoch 57/80\n",
      "112/112 [==============================] - 1s 6ms/step - loss: 0.1068 - val_loss: 0.0434\n",
      "Epoch 58/80\n",
      "112/112 [==============================] - ETA: 0s - loss: 0.106 - 1s 7ms/step - loss: 0.1062 - val_loss: 0.0424\n",
      "Epoch 59/80\n",
      "112/112 [==============================] - 1s 6ms/step - loss: 0.1060 - val_loss: 0.0414\n",
      "Epoch 60/80\n",
      "112/112 [==============================] - 1s 6ms/step - loss: 0.1054 - val_loss: 0.0405\n",
      "Epoch 61/80\n",
      "112/112 [==============================] - 1s 6ms/step - loss: 0.1053 - val_loss: 0.0396\n",
      "Epoch 62/80\n",
      "112/112 [==============================] - 1s 7ms/step - loss: 0.1049 - val_loss: 0.0387\n",
      "Epoch 63/80\n",
      "112/112 [==============================] - 1s 7ms/step - loss: 0.1045 - val_loss: 0.0379\n",
      "Epoch 64/80\n",
      "112/112 [==============================] - 1s 7ms/step - loss: 0.1040 - val_loss: 0.0370\n",
      "Epoch 65/80\n",
      "112/112 [==============================] - 1s 7ms/step - loss: 0.1040 - val_loss: 0.0362\n",
      "Epoch 66/80\n",
      "112/112 [==============================] - 1s 6ms/step - loss: 0.1039 - val_loss: 0.0354\n",
      "Epoch 67/80\n",
      "112/112 [==============================] - 1s 6ms/step - loss: 0.1031 - val_loss: 0.0347\n",
      "Epoch 68/80\n",
      "112/112 [==============================] - 1s 6ms/step - loss: 0.1030 - val_loss: 0.0339\n",
      "Epoch 69/80\n",
      "112/112 [==============================] - 1s 6ms/step - loss: 0.1028 - val_loss: 0.0332\n",
      "Epoch 70/80\n",
      "112/112 [==============================] - 1s 6ms/step - loss: 0.1024 - val_loss: 0.0326\n",
      "Epoch 71/80\n",
      "112/112 [==============================] - 1s 6ms/step - loss: 0.1021 - val_loss: 0.0320\n",
      "Epoch 72/80\n",
      "112/112 [==============================] - 1s 6ms/step - loss: 0.1019 - val_loss: 0.0313\n",
      "Epoch 73/80\n",
      "112/112 [==============================] - 1s 6ms/step - loss: 0.1017 - val_loss: 0.0308\n",
      "Epoch 74/80\n",
      "112/112 [==============================] - 1s 6ms/step - loss: 0.1014 - val_loss: 0.0302\n",
      "Epoch 75/80\n",
      "112/112 [==============================] - 1s 6ms/step - loss: 0.1011 - val_loss: 0.0296\n",
      "Epoch 76/80\n",
      "112/112 [==============================] - 1s 6ms/step - loss: 0.1010 - val_loss: 0.0291\n",
      "Epoch 77/80\n",
      "112/112 [==============================] - 1s 6ms/step - loss: 0.1007 - val_loss: 0.0286\n",
      "Epoch 78/80\n",
      "112/112 [==============================] - 1s 6ms/step - loss: 0.1003 - val_loss: 0.0282\n",
      "Epoch 79/80\n",
      "112/112 [==============================] - 1s 6ms/step - loss: 0.1004 - val_loss: 0.0277\n",
      "Epoch 80/80\n",
      "112/112 [==============================] - 1s 6ms/step - loss: 0.1001 - val_loss: 0.0273\n",
      "Execution time:  59.93169403076172\n",
      "DNN:\n",
      "Mean Absolute Error: 0.0426\n",
      "Root Mean Square Error: 0.0469\n",
      "Mean Square Error: 0.0022\n",
      "\n",
      "Train RMSE: 0.047\n",
      "Train MSE: 0.002\n",
      "Train MAE: 0.043\n",
      "###########################\n",
      "\n",
      "MODEL:  DNN\n",
      "sequence:  1d\n",
      "units:  80\n",
      "dropout1:  0.11814836227952394\n",
      "optimizer: adadelta\n",
      "activationDense: tanh\n",
      "epochs: 90\n",
      "batchsize: 25\n",
      "validation_split: 0.1\n",
      "Model: \"sequential_157\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_471 (Dense)            (None, 144, 80)           160       \n",
      "_________________________________________________________________\n",
      "dense_472 (Dense)            (None, 144, 16)           1296      \n",
      "_________________________________________________________________\n",
      "dropout_157 (Dropout)        (None, 144, 16)           0         \n",
      "_________________________________________________________________\n",
      "dense_473 (Dense)            (None, 144, 1)            17        \n",
      "=================================================================\n",
      "Total params: 1,473\n",
      "Trainable params: 1,473\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/90\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "139/139 [==============================] - 1s 6ms/step - loss: 0.4103 - val_loss: 0.3733\n",
      "Epoch 2/90\n",
      "139/139 [==============================] - 1s 6ms/step - loss: 0.4069 - val_loss: 0.3698\n",
      "Epoch 3/90\n",
      "139/139 [==============================] - 1s 6ms/step - loss: 0.4031 - val_loss: 0.3663\n",
      "Epoch 4/90\n",
      "139/139 [==============================] - 1s 5ms/step - loss: 0.3996 - val_loss: 0.3630\n",
      "Epoch 5/90\n",
      "139/139 [==============================] - 1s 5ms/step - loss: 0.3960 - val_loss: 0.3594\n",
      "Epoch 6/90\n",
      "139/139 [==============================] - 1s 5ms/step - loss: 0.3922 - val_loss: 0.3556\n",
      "Epoch 7/90\n",
      "139/139 [==============================] - 1s 5ms/step - loss: 0.3881 - val_loss: 0.3515\n",
      "Epoch 8/90\n",
      "139/139 [==============================] - 1s 5ms/step - loss: 0.3838 - val_loss: 0.3472\n",
      "Epoch 9/90\n",
      "139/139 [==============================] - 1s 5ms/step - loss: 0.3792 - val_loss: 0.3427\n",
      "Epoch 10/90\n",
      "139/139 [==============================] - 1s 5ms/step - loss: 0.3745 - val_loss: 0.3387\n",
      "Epoch 11/90\n",
      "139/139 [==============================] - 1s 5ms/step - loss: 0.3708 - val_loss: 0.3361\n",
      "Epoch 12/90\n",
      "139/139 [==============================] - 1s 5ms/step - loss: 0.3678 - val_loss: 0.3334\n",
      "Epoch 13/90\n",
      "139/139 [==============================] - 1s 5ms/step - loss: 0.3649 - val_loss: 0.3306\n",
      "Epoch 14/90\n",
      "139/139 [==============================] - 1s 5ms/step - loss: 0.3619 - val_loss: 0.3277\n",
      "Epoch 15/90\n",
      "139/139 [==============================] - 1s 5ms/step - loss: 0.3588 - val_loss: 0.3247\n",
      "Epoch 16/90\n",
      "139/139 [==============================] - 1s 5ms/step - loss: 0.3557 - val_loss: 0.3216\n",
      "Epoch 17/90\n",
      "139/139 [==============================] - 1s 5ms/step - loss: 0.3523 - val_loss: 0.3183\n",
      "Epoch 18/90\n",
      "139/139 [==============================] - 1s 5ms/step - loss: 0.3488 - val_loss: 0.3149\n",
      "Epoch 19/90\n",
      "139/139 [==============================] - 1s 5ms/step - loss: 0.3453 - val_loss: 0.3114\n",
      "Epoch 20/90\n",
      "139/139 [==============================] - 1s 5ms/step - loss: 0.3416 - val_loss: 0.3078\n",
      "Epoch 21/90\n",
      "139/139 [==============================] - 1s 5ms/step - loss: 0.3378 - val_loss: 0.3043\n",
      "Epoch 22/90\n",
      "139/139 [==============================] - 1s 5ms/step - loss: 0.3314 - val_loss: 0.2951\n",
      "Epoch 23/90\n",
      "139/139 [==============================] - 1s 5ms/step - loss: 0.3215 - val_loss: 0.2854\n",
      "Epoch 24/90\n",
      "139/139 [==============================] - 1s 6ms/step - loss: 0.3114 - val_loss: 0.2756\n",
      "Epoch 25/90\n",
      "139/139 [==============================] - 1s 5ms/step - loss: 0.3011 - val_loss: 0.2655\n",
      "Epoch 26/90\n",
      "139/139 [==============================] - 1s 5ms/step - loss: 0.2906 - val_loss: 0.2551\n",
      "Epoch 27/90\n",
      "139/139 [==============================] - 1s 5ms/step - loss: 0.2798 - val_loss: 0.2444\n",
      "Epoch 28/90\n",
      "139/139 [==============================] - 1s 5ms/step - loss: 0.2687 - val_loss: 0.2334\n",
      "Epoch 29/90\n",
      "139/139 [==============================] - 1s 5ms/step - loss: 0.2572 - val_loss: 0.2220\n",
      "Epoch 30/90\n",
      "139/139 [==============================] - 1s 5ms/step - loss: 0.2445 - val_loss: 0.2073\n",
      "Epoch 31/90\n",
      "139/139 [==============================] - 1s 5ms/step - loss: 0.2280 - val_loss: 0.1905\n",
      "Epoch 32/90\n",
      "139/139 [==============================] - 1s 5ms/step - loss: 0.2107 - val_loss: 0.1736\n",
      "Epoch 33/90\n",
      "139/139 [==============================] - 1s 5ms/step - loss: 0.1932 - val_loss: 0.1568\n",
      "Epoch 34/90\n",
      "139/139 [==============================] - 1s 5ms/step - loss: 0.1758 - val_loss: 0.1401\n",
      "Epoch 35/90\n",
      "139/139 [==============================] - 1s 5ms/step - loss: 0.1587 - val_loss: 0.1234\n",
      "Epoch 36/90\n",
      "139/139 [==============================] - 1s 5ms/step - loss: 0.1413 - val_loss: 0.1062\n",
      "Epoch 37/90\n",
      "139/139 [==============================] - 1s 5ms/step - loss: 0.1237 - val_loss: 0.0887\n",
      "Epoch 38/90\n",
      "139/139 [==============================] - 1s 5ms/step - loss: 0.1056 - val_loss: 0.0707\n",
      "Epoch 39/90\n",
      "139/139 [==============================] - 1s 5ms/step - loss: 0.0877 - val_loss: 0.0530\n",
      "Epoch 40/90\n",
      "139/139 [==============================] - 1s 5ms/step - loss: 0.0723 - val_loss: 0.0374\n",
      "Epoch 41/90\n",
      "139/139 [==============================] - 1s 5ms/step - loss: 0.0629 - val_loss: 0.0297\n",
      "Epoch 42/90\n",
      "139/139 [==============================] - 1s 5ms/step - loss: 0.0607 - val_loss: 0.0252\n",
      "Epoch 43/90\n",
      "139/139 [==============================] - 1s 5ms/step - loss: 0.0599 - val_loss: 0.0225\n",
      "Epoch 44/90\n",
      "139/139 [==============================] - 1s 5ms/step - loss: 0.0593 - val_loss: 0.0210\n",
      "Epoch 45/90\n",
      "139/139 [==============================] - 1s 6ms/step - loss: 0.0592 - val_loss: 0.0199\n",
      "Epoch 46/90\n",
      "139/139 [==============================] - 1s 6ms/step - loss: 0.0591 - val_loss: 0.0191\n",
      "Epoch 47/90\n",
      "139/139 [==============================] - 1s 5ms/step - loss: 0.0590 - val_loss: 0.0186\n",
      "Epoch 48/90\n",
      "139/139 [==============================] - 1s 6ms/step - loss: 0.0589 - val_loss: 0.0183\n",
      "Epoch 49/90\n",
      "139/139 [==============================] - 1s 5ms/step - loss: 0.0590 - val_loss: 0.0180\n",
      "Epoch 50/90\n",
      "139/139 [==============================] - 1s 5ms/step - loss: 0.0589 - val_loss: 0.0178\n",
      "Epoch 51/90\n",
      "139/139 [==============================] - 1s 5ms/step - loss: 0.0589 - val_loss: 0.0176\n",
      "Epoch 52/90\n",
      "139/139 [==============================] - 1s 5ms/step - loss: 0.0589 - val_loss: 0.0175\n",
      "Epoch 53/90\n",
      "139/139 [==============================] - 1s 5ms/step - loss: 0.0587 - val_loss: 0.0173\n",
      "Epoch 54/90\n",
      "139/139 [==============================] - 1s 5ms/step - loss: 0.0590 - val_loss: 0.0173\n",
      "Epoch 55/90\n",
      "139/139 [==============================] - 1s 5ms/step - loss: 0.0590 - val_loss: 0.0172\n",
      "Epoch 56/90\n",
      "139/139 [==============================] - 1s 5ms/step - loss: 0.0587 - val_loss: 0.0172\n",
      "Epoch 57/90\n",
      "139/139 [==============================] - 1s 5ms/step - loss: 0.0588 - val_loss: 0.0172\n",
      "Epoch 58/90\n",
      "139/139 [==============================] - 1s 5ms/step - loss: 0.0588 - val_loss: 0.0172\n",
      "Epoch 59/90\n",
      "139/139 [==============================] - 1s 5ms/step - loss: 0.0587 - val_loss: 0.0172\n",
      "Epoch 60/90\n",
      "139/139 [==============================] - 1s 5ms/step - loss: 0.0588 - val_loss: 0.0171\n",
      "Epoch 61/90\n",
      "139/139 [==============================] - 1s 5ms/step - loss: 0.0589 - val_loss: 0.0171\n",
      "Epoch 62/90\n",
      "139/139 [==============================] - 1s 5ms/step - loss: 0.0587 - val_loss: 0.0171\n",
      "Epoch 63/90\n",
      "139/139 [==============================] - 1s 5ms/step - loss: 0.0587 - val_loss: 0.0171\n",
      "Epoch 64/90\n",
      "139/139 [==============================] - 1s 5ms/step - loss: 0.0586 - val_loss: 0.0171\n",
      "Epoch 65/90\n",
      "139/139 [==============================] - 1s 5ms/step - loss: 0.0589 - val_loss: 0.0171\n",
      "Epoch 66/90\n",
      "139/139 [==============================] - 1s 5ms/step - loss: 0.0587 - val_loss: 0.0171\n",
      "Epoch 67/90\n",
      "139/139 [==============================] - 1s 6ms/step - loss: 0.0588 - val_loss: 0.0171\n",
      "Epoch 68/90\n",
      "139/139 [==============================] - 1s 6ms/step - loss: 0.0587 - val_loss: 0.0171\n",
      "Epoch 69/90\n",
      "139/139 [==============================] - 1s 5ms/step - loss: 0.0587 - val_loss: 0.0171\n",
      "Epoch 70/90\n",
      "139/139 [==============================] - 1s 5ms/step - loss: 0.0587 - val_loss: 0.0170\n",
      "Epoch 71/90\n",
      "139/139 [==============================] - 1s 5ms/step - loss: 0.0588 - val_loss: 0.0170\n",
      "Epoch 72/90\n",
      "139/139 [==============================] - 1s 5ms/step - loss: 0.0586 - val_loss: 0.0170\n",
      "Epoch 73/90\n",
      "139/139 [==============================] - 1s 5ms/step - loss: 0.0585 - val_loss: 0.0170\n",
      "Epoch 74/90\n",
      "139/139 [==============================] - 1s 5ms/step - loss: 0.0587 - val_loss: 0.0170\n",
      "Epoch 75/90\n",
      "139/139 [==============================] - 1s 5ms/step - loss: 0.0587 - val_loss: 0.0170\n",
      "Epoch 76/90\n",
      "139/139 [==============================] - 1s 5ms/step - loss: 0.0587 - val_loss: 0.0170\n",
      "Epoch 77/90\n",
      "139/139 [==============================] - 1s 5ms/step - loss: 0.0587 - val_loss: 0.0170\n",
      "Epoch 78/90\n",
      "139/139 [==============================] - 1s 5ms/step - loss: 0.0588 - val_loss: 0.0170\n",
      "Epoch 79/90\n",
      "139/139 [==============================] - 1s 5ms/step - loss: 0.0587 - val_loss: 0.0170\n",
      "Epoch 80/90\n",
      "139/139 [==============================] - 1s 5ms/step - loss: 0.0587 - val_loss: 0.0170\n",
      "Epoch 81/90\n",
      "139/139 [==============================] - 1s 5ms/step - loss: 0.0586 - val_loss: 0.0170\n",
      "Epoch 82/90\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "139/139 [==============================] - 1s 5ms/step - loss: 0.0587 - val_loss: 0.0170\n",
      "Epoch 83/90\n",
      "139/139 [==============================] - 1s 5ms/step - loss: 0.0586 - val_loss: 0.0169\n",
      "Epoch 84/90\n",
      "139/139 [==============================] - 1s 5ms/step - loss: 0.0587 - val_loss: 0.0169\n",
      "Epoch 85/90\n",
      "139/139 [==============================] - 1s 5ms/step - loss: 0.0584 - val_loss: 0.0169\n",
      "Epoch 86/90\n",
      "139/139 [==============================] - 1s 5ms/step - loss: 0.0588 - val_loss: 0.0169\n",
      "Epoch 87/90\n",
      "139/139 [==============================] - 1s 5ms/step - loss: 0.0586 - val_loss: 0.0169\n",
      "Epoch 88/90\n",
      "139/139 [==============================] - 1s 5ms/step - loss: 0.0585 - val_loss: 0.0169\n",
      "Epoch 89/90\n",
      "139/139 [==============================] - 1s 6ms/step - loss: 0.0586 - val_loss: 0.0169\n",
      "Epoch 90/90\n",
      "139/139 [==============================] - 1s 5ms/step - loss: 0.0585 - val_loss: 0.0169\n",
      "Execution time:  67.70560669898987\n",
      "DNN:\n",
      "Mean Absolute Error: 0.0383\n",
      "Root Mean Square Error: 0.0472\n",
      "Mean Square Error: 0.0022\n",
      "\n",
      "Train RMSE: 0.047\n",
      "Train MSE: 0.002\n",
      "Train MAE: 0.038\n",
      "###########################\n",
      "\n",
      "MODEL:  DNN\n",
      "sequence:  1d\n",
      "units:  12\n",
      "dropout1:  0.48476373451509647\n",
      "optimizer: adadelta\n",
      "activationDense: tanh\n",
      "epochs: 52\n",
      "batchsize: 57\n",
      "validation_split: 0.1\n",
      "Model: \"sequential_158\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_474 (Dense)            (None, 144, 12)           24        \n",
      "_________________________________________________________________\n",
      "dense_475 (Dense)            (None, 144, 16)           208       \n",
      "_________________________________________________________________\n",
      "dropout_158 (Dropout)        (None, 144, 16)           0         \n",
      "_________________________________________________________________\n",
      "dense_476 (Dense)            (None, 144, 1)            17        \n",
      "=================================================================\n",
      "Total params: 249\n",
      "Trainable params: 249\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/52\n",
      "61/61 [==============================] - 0s 8ms/step - loss: 0.5223 - val_loss: 0.4778\n",
      "Epoch 2/52\n",
      "61/61 [==============================] - 0s 5ms/step - loss: 0.5214 - val_loss: 0.4770\n",
      "Epoch 3/52\n",
      "61/61 [==============================] - 0s 5ms/step - loss: 0.5208 - val_loss: 0.4761\n",
      "Epoch 4/52\n",
      "61/61 [==============================] - 0s 5ms/step - loss: 0.5198 - val_loss: 0.4752\n",
      "Epoch 5/52\n",
      "61/61 [==============================] - 0s 5ms/step - loss: 0.5189 - val_loss: 0.4743\n",
      "Epoch 6/52\n",
      "61/61 [==============================] - 0s 5ms/step - loss: 0.5178 - val_loss: 0.4733\n",
      "Epoch 7/52\n",
      "61/61 [==============================] - 0s 5ms/step - loss: 0.5167 - val_loss: 0.4723\n",
      "Epoch 8/52\n",
      "61/61 [==============================] - 0s 5ms/step - loss: 0.5158 - val_loss: 0.4713\n",
      "Epoch 9/52\n",
      "61/61 [==============================] - 0s 5ms/step - loss: 0.5146 - val_loss: 0.4702\n",
      "Epoch 10/52\n",
      "61/61 [==============================] - 0s 5ms/step - loss: 0.5137 - val_loss: 0.4691\n",
      "Epoch 11/52\n",
      "61/61 [==============================] - 0s 5ms/step - loss: 0.5124 - val_loss: 0.4680\n",
      "Epoch 12/52\n",
      "61/61 [==============================] - 0s 5ms/step - loss: 0.5116 - val_loss: 0.4669\n",
      "Epoch 13/52\n",
      "61/61 [==============================] - 0s 5ms/step - loss: 0.5102 - val_loss: 0.4657\n",
      "Epoch 14/52\n",
      "61/61 [==============================] - 0s 5ms/step - loss: 0.5090 - val_loss: 0.4645\n",
      "Epoch 15/52\n",
      "61/61 [==============================] - 0s 5ms/step - loss: 0.5078 - val_loss: 0.4632\n",
      "Epoch 16/52\n",
      "61/61 [==============================] - 0s 5ms/step - loss: 0.5064 - val_loss: 0.4620\n",
      "Epoch 17/52\n",
      "61/61 [==============================] - 0s 5ms/step - loss: 0.5049 - val_loss: 0.4607\n",
      "Epoch 18/52\n",
      "61/61 [==============================] - 0s 5ms/step - loss: 0.5036 - val_loss: 0.4594\n",
      "Epoch 19/52\n",
      "61/61 [==============================] - 0s 5ms/step - loss: 0.5023 - val_loss: 0.4580\n",
      "Epoch 20/52\n",
      "61/61 [==============================] - 0s 5ms/step - loss: 0.5009 - val_loss: 0.4567\n",
      "Epoch 21/52\n",
      "61/61 [==============================] - 0s 5ms/step - loss: 0.4997 - val_loss: 0.4553\n",
      "Epoch 22/52\n",
      "61/61 [==============================] - 0s 5ms/step - loss: 0.4982 - val_loss: 0.4539\n",
      "Epoch 23/52\n",
      "61/61 [==============================] - 0s 5ms/step - loss: 0.4965 - val_loss: 0.4524\n",
      "Epoch 24/52\n",
      "61/61 [==============================] - 0s 5ms/step - loss: 0.4951 - val_loss: 0.4510\n",
      "Epoch 25/52\n",
      "61/61 [==============================] - 0s 5ms/step - loss: 0.4936 - val_loss: 0.4495\n",
      "Epoch 26/52\n",
      "61/61 [==============================] - 0s 5ms/step - loss: 0.4920 - val_loss: 0.4480\n",
      "Epoch 27/52\n",
      "61/61 [==============================] - 0s 5ms/step - loss: 0.4905 - val_loss: 0.4464\n",
      "Epoch 28/52\n",
      "61/61 [==============================] - 0s 5ms/step - loss: 0.4891 - val_loss: 0.4449\n",
      "Epoch 29/52\n",
      "61/61 [==============================] - 0s 5ms/step - loss: 0.4873 - val_loss: 0.4433\n",
      "Epoch 30/52\n",
      "61/61 [==============================] - 0s 5ms/step - loss: 0.4856 - val_loss: 0.4417\n",
      "Epoch 31/52\n",
      "61/61 [==============================] - 0s 5ms/step - loss: 0.4841 - val_loss: 0.4401\n",
      "Epoch 32/52\n",
      "61/61 [==============================] - 0s 5ms/step - loss: 0.4823 - val_loss: 0.4385\n",
      "Epoch 33/52\n",
      "61/61 [==============================] - 0s 5ms/step - loss: 0.4807 - val_loss: 0.4368\n",
      "Epoch 34/52\n",
      "61/61 [==============================] - 0s 5ms/step - loss: 0.4790 - val_loss: 0.4351\n",
      "Epoch 35/52\n",
      "61/61 [==============================] - 0s 5ms/step - loss: 0.4771 - val_loss: 0.4334\n",
      "Epoch 36/52\n",
      "61/61 [==============================] - 0s 5ms/step - loss: 0.4756 - val_loss: 0.4317\n",
      "Epoch 37/52\n",
      "61/61 [==============================] - 0s 5ms/step - loss: 0.4736 - val_loss: 0.4299\n",
      "Epoch 38/52\n",
      "61/61 [==============================] - 0s 5ms/step - loss: 0.4717 - val_loss: 0.4282\n",
      "Epoch 39/52\n",
      "61/61 [==============================] - 0s 5ms/step - loss: 0.4699 - val_loss: 0.4264\n",
      "Epoch 40/52\n",
      "61/61 [==============================] - 0s 6ms/step - loss: 0.4684 - val_loss: 0.4246\n",
      "Epoch 41/52\n",
      "61/61 [==============================] - 0s 6ms/step - loss: 0.4662 - val_loss: 0.4228\n",
      "Epoch 42/52\n",
      "61/61 [==============================] - 0s 6ms/step - loss: 0.4645 - val_loss: 0.4209\n",
      "Epoch 43/52\n",
      "61/61 [==============================] - 0s 5ms/step - loss: 0.4626 - val_loss: 0.4191\n",
      "Epoch 44/52\n",
      "61/61 [==============================] - 0s 6ms/step - loss: 0.4606 - val_loss: 0.4172\n",
      "Epoch 45/52\n",
      "61/61 [==============================] - 0s 6ms/step - loss: 0.4588 - val_loss: 0.4153\n",
      "Epoch 46/52\n",
      "61/61 [==============================] - 0s 5ms/step - loss: 0.4567 - val_loss: 0.4134\n",
      "Epoch 47/52\n",
      "61/61 [==============================] - 0s 5ms/step - loss: 0.4549 - val_loss: 0.4115\n",
      "Epoch 48/52\n",
      "61/61 [==============================] - 0s 5ms/step - loss: 0.4526 - val_loss: 0.4095\n",
      "Epoch 49/52\n",
      "61/61 [==============================] - 0s 5ms/step - loss: 0.4507 - val_loss: 0.4075\n",
      "Epoch 50/52\n",
      "61/61 [==============================] - 0s 5ms/step - loss: 0.4488 - val_loss: 0.4055\n",
      "Epoch 51/52\n",
      "61/61 [==============================] - 0s 5ms/step - loss: 0.4467 - val_loss: 0.4035\n",
      "Epoch 52/52\n",
      "61/61 [==============================] - 0s 5ms/step - loss: 0.4445 - val_loss: 0.4015\n",
      "Execution time:  17.95234441757202\n",
      "DNN:\n",
      "Mean Absolute Error: 0.4408\n",
      "Root Mean Square Error: 0.4437\n",
      "Mean Square Error: 0.1968\n",
      "\n",
      "Train RMSE: 0.444\n",
      "Train MSE: 0.197\n",
      "Train MAE: 0.441\n",
      "###########################\n",
      "\n",
      "MODEL:  DNN\n",
      "sequence:  1d\n",
      "units:  87\n",
      "dropout1:  0.40519643149940265\n",
      "optimizer: adadelta\n",
      "activationDense: tanh\n",
      "epochs: 80\n",
      "batchsize: 31\n",
      "validation_split: 0.2\n",
      "Model: \"sequential_159\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_477 (Dense)            (None, 144, 87)           174       \n",
      "_________________________________________________________________\n",
      "dense_478 (Dense)            (None, 144, 16)           1408      \n",
      "_________________________________________________________________\n",
      "dropout_159 (Dropout)        (None, 144, 16)           0         \n",
      "_________________________________________________________________\n",
      "dense_479 (Dense)            (None, 144, 1)            17        \n",
      "=================================================================\n",
      "Total params: 1,599\n",
      "Trainable params: 1,599\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/80\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100/100 [==============================] - 1s 8ms/step - loss: 0.3960 - val_loss: 0.3748\n",
      "Epoch 2/80\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 0.3937 - val_loss: 0.3725\n",
      "Epoch 3/80\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 0.3913 - val_loss: 0.3699\n",
      "Epoch 4/80\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 0.3886 - val_loss: 0.3672\n",
      "Epoch 5/80\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 0.3858 - val_loss: 0.3644\n",
      "Epoch 6/80\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 0.3827 - val_loss: 0.3613\n",
      "Epoch 7/80\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 0.3796 - val_loss: 0.3581\n",
      "Epoch 8/80\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 0.3762 - val_loss: 0.3548\n",
      "Epoch 9/80\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 0.3729 - val_loss: 0.3514\n",
      "Epoch 10/80\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 0.3692 - val_loss: 0.3479\n",
      "Epoch 11/80\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 0.3655 - val_loss: 0.3442\n",
      "Epoch 12/80\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 0.3617 - val_loss: 0.3405\n",
      "Epoch 13/80\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 0.3578 - val_loss: 0.3366\n",
      "Epoch 14/80\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 0.3539 - val_loss: 0.3327\n",
      "Epoch 15/80\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 0.3498 - val_loss: 0.3287\n",
      "Epoch 16/80\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 0.3457 - val_loss: 0.3246\n",
      "Epoch 17/80\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 0.3414 - val_loss: 0.3204\n",
      "Epoch 18/80\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 0.3371 - val_loss: 0.3160\n",
      "Epoch 19/80\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 0.3326 - val_loss: 0.3116\n",
      "Epoch 20/80\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 0.3280 - val_loss: 0.3071\n",
      "Epoch 21/80\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 0.3233 - val_loss: 0.3024\n",
      "Epoch 22/80\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 0.3187 - val_loss: 0.2980\n",
      "Epoch 23/80\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 0.3140 - val_loss: 0.2936\n",
      "Epoch 24/80\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 0.3096 - val_loss: 0.2891\n",
      "Epoch 25/80\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 0.3050 - val_loss: 0.2846\n",
      "Epoch 26/80\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 0.3003 - val_loss: 0.2800\n",
      "Epoch 27/80\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 0.2956 - val_loss: 0.2755\n",
      "Epoch 28/80\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 0.2910 - val_loss: 0.2711\n",
      "Epoch 29/80\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 0.2865 - val_loss: 0.2667\n",
      "Epoch 30/80\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 0.2821 - val_loss: 0.2623\n",
      "Epoch 31/80\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 0.2775 - val_loss: 0.2579\n",
      "Epoch 32/80\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 0.2731 - val_loss: 0.2535\n",
      "Epoch 33/80\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 0.2688 - val_loss: 0.2491\n",
      "Epoch 34/80\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 0.2641 - val_loss: 0.2446\n",
      "Epoch 35/80\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 0.2597 - val_loss: 0.2401\n",
      "Epoch 36/80\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 0.2550 - val_loss: 0.2355\n",
      "Epoch 37/80\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 0.2504 - val_loss: 0.2309\n",
      "Epoch 38/80\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 0.2458 - val_loss: 0.2263\n",
      "Epoch 39/80\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 0.2411 - val_loss: 0.2216\n",
      "Epoch 40/80\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 0.2362 - val_loss: 0.2168\n",
      "Epoch 41/80\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 0.2314 - val_loss: 0.2120\n",
      "Epoch 42/80\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 0.2267 - val_loss: 0.2072\n",
      "Epoch 43/80\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 0.2217 - val_loss: 0.2023\n",
      "Epoch 44/80\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 0.2168 - val_loss: 0.1973\n",
      "Epoch 45/80\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 0.2115 - val_loss: 0.1918\n",
      "Epoch 46/80\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 0.2064 - val_loss: 0.1862\n",
      "Epoch 47/80\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 0.2004 - val_loss: 0.1803\n",
      "Epoch 48/80\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 0.1947 - val_loss: 0.1743\n",
      "Epoch 49/80\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 0.1884 - val_loss: 0.1683\n",
      "Epoch 50/80\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 0.1829 - val_loss: 0.1622\n",
      "Epoch 51/80\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 0.1768 - val_loss: 0.1562\n",
      "Epoch 52/80\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 0.1709 - val_loss: 0.1501\n",
      "Epoch 53/80\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 0.1655 - val_loss: 0.1442\n",
      "Epoch 54/80\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 0.1603 - val_loss: 0.1388\n",
      "Epoch 55/80\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 0.1563 - val_loss: 0.1337\n",
      "Epoch 56/80\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 0.1526 - val_loss: 0.1292\n",
      "Epoch 57/80\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 0.1495 - val_loss: 0.1250\n",
      "Epoch 58/80\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 0.1472 - val_loss: 0.1212\n",
      "Epoch 59/80\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 0.1448 - val_loss: 0.1177\n",
      "Epoch 60/80\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 0.1428 - val_loss: 0.1145\n",
      "Epoch 61/80\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 0.1414 - val_loss: 0.1114\n",
      "Epoch 62/80\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 0.1398 - val_loss: 0.1086\n",
      "Epoch 63/80\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 0.1382 - val_loss: 0.1058\n",
      "Epoch 64/80\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 0.1368 - val_loss: 0.1033\n",
      "Epoch 65/80\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 0.1357 - val_loss: 0.1008\n",
      "Epoch 66/80\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 0.1344 - val_loss: 0.0985\n",
      "Epoch 67/80\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 0.1333 - val_loss: 0.0963\n",
      "Epoch 68/80\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 0.1324 - val_loss: 0.0943\n",
      "Epoch 69/80\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 0.1312 - val_loss: 0.0922\n",
      "Epoch 70/80\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 0.1307 - val_loss: 0.0903\n",
      "Epoch 71/80\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 0.1294 - val_loss: 0.0883\n",
      "Epoch 72/80\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 0.1290 - val_loss: 0.0865\n",
      "Epoch 73/80\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 0.1280 - val_loss: 0.0847\n",
      "Epoch 74/80\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 0.1275 - val_loss: 0.0829\n",
      "Epoch 75/80\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 0.1263 - val_loss: 0.0812\n",
      "Epoch 76/80\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 0.1259 - val_loss: 0.0795\n",
      "Epoch 77/80\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 0.1252 - val_loss: 0.0778\n",
      "Epoch 78/80\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 0.1245 - val_loss: 0.0762\n",
      "Epoch 79/80\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 0.1241 - val_loss: 0.0746\n",
      "Epoch 80/80\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 0.1232 - val_loss: 0.0731\n",
      "Execution time:  56.73365259170532\n",
      "DNN:\n",
      "Mean Absolute Error: 0.0849\n",
      "Root Mean Square Error: 0.0892\n",
      "Mean Square Error: 0.0080\n",
      "\n",
      "Train RMSE: 0.089\n",
      "Train MSE: 0.008\n",
      "Train MAE: 0.085\n",
      "###########################\n",
      "\n",
      "MODEL:  DNN\n",
      "sequence:  1d\n",
      "units:  80\n",
      "dropout1:  0.11814836227952394\n",
      "optimizer: adadelta\n",
      "activationDense: tanh\n",
      "epochs: 90\n",
      "batchsize: 25\n",
      "validation_split: 0.2\n",
      "Model: \"sequential_160\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_480 (Dense)            (None, 144, 80)           160       \n",
      "_________________________________________________________________\n",
      "dense_481 (Dense)            (None, 144, 16)           1296      \n",
      "_________________________________________________________________\n",
      "dropout_160 (Dropout)        (None, 144, 16)           0         \n",
      "_________________________________________________________________\n",
      "dense_482 (Dense)            (None, 144, 1)            17        \n",
      "=================================================================\n",
      "Total params: 1,473\n",
      "Trainable params: 1,473\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/90\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "124/124 [==============================] - 1s 7ms/step - loss: 0.3835 - val_loss: 0.3623\n",
      "Epoch 2/90\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.3798 - val_loss: 0.3585\n",
      "Epoch 3/90\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.3758 - val_loss: 0.3544\n",
      "Epoch 4/90\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.3714 - val_loss: 0.3500\n",
      "Epoch 5/90\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.3670 - val_loss: 0.3455\n",
      "Epoch 6/90\n",
      "124/124 [==============================] - 1s 5ms/step - loss: 0.3621 - val_loss: 0.3407\n",
      "Epoch 7/90\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.3570 - val_loss: 0.3356\n",
      "Epoch 8/90\n",
      "124/124 [==============================] - 1s 5ms/step - loss: 0.3518 - val_loss: 0.3303\n",
      "Epoch 9/90\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.3462 - val_loss: 0.3248\n",
      "Epoch 10/90\n",
      "124/124 [==============================] - 1s 5ms/step - loss: 0.3403 - val_loss: 0.3190\n",
      "Epoch 11/90\n",
      "124/124 [==============================] - 1s 5ms/step - loss: 0.3344 - val_loss: 0.3130\n",
      "Epoch 12/90\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.3281 - val_loss: 0.3068\n",
      "Epoch 13/90\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.3216 - val_loss: 0.3004\n",
      "Epoch 14/90\n",
      "124/124 [==============================] - 1s 5ms/step - loss: 0.3150 - val_loss: 0.2938\n",
      "Epoch 15/90\n",
      "124/124 [==============================] - 1s 5ms/step - loss: 0.3081 - val_loss: 0.2870\n",
      "Epoch 16/90\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.3010 - val_loss: 0.2799\n",
      "Epoch 17/90\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.2937 - val_loss: 0.2731\n",
      "Epoch 18/90\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.2870 - val_loss: 0.2665\n",
      "Epoch 19/90\n",
      "124/124 [==============================] - 1s 5ms/step - loss: 0.2799 - val_loss: 0.2599\n",
      "Epoch 20/90\n",
      "124/124 [==============================] - 1s 5ms/step - loss: 0.2730 - val_loss: 0.2531\n",
      "Epoch 21/90\n",
      "124/124 [==============================] - 1s 5ms/step - loss: 0.2660 - val_loss: 0.2461\n",
      "Epoch 22/90\n",
      "124/124 [==============================] - 1s 5ms/step - loss: 0.2587 - val_loss: 0.2389\n",
      "Epoch 23/90\n",
      "124/124 [==============================] - 1s 5ms/step - loss: 0.2512 - val_loss: 0.2315\n",
      "Epoch 24/90\n",
      "124/124 [==============================] - 1s 5ms/step - loss: 0.2436 - val_loss: 0.2240\n",
      "Epoch 25/90\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.2358 - val_loss: 0.2162\n",
      "Epoch 26/90\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.2278 - val_loss: 0.2083\n",
      "Epoch 27/90\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.2196 - val_loss: 0.2001\n",
      "Epoch 28/90\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.2111 - val_loss: 0.1918\n",
      "Epoch 29/90\n",
      "124/124 [==============================] - 1s 5ms/step - loss: 0.2025 - val_loss: 0.1832\n",
      "Epoch 30/90\n",
      "124/124 [==============================] - 1s 5ms/step - loss: 0.1939 - val_loss: 0.1752\n",
      "Epoch 31/90\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.1858 - val_loss: 0.1673\n",
      "Epoch 32/90\n",
      "124/124 [==============================] - 1s 5ms/step - loss: 0.1776 - val_loss: 0.1598\n",
      "Epoch 33/90\n",
      "124/124 [==============================] - 1s 5ms/step - loss: 0.1700 - val_loss: 0.1525\n",
      "Epoch 34/90\n",
      "124/124 [==============================] - 1s 5ms/step - loss: 0.1626 - val_loss: 0.1452\n",
      "Epoch 35/90\n",
      "124/124 [==============================] - 1s 5ms/step - loss: 0.1549 - val_loss: 0.1377\n",
      "Epoch 36/90\n",
      "124/124 [==============================] - 1s 5ms/step - loss: 0.1473 - val_loss: 0.1301\n",
      "Epoch 37/90\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.1397 - val_loss: 0.1224\n",
      "Epoch 38/90\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.1318 - val_loss: 0.1146\n",
      "Epoch 39/90\n",
      "124/124 [==============================] - 1s 5ms/step - loss: 0.1239 - val_loss: 0.1067\n",
      "Epoch 40/90\n",
      "124/124 [==============================] - 1s 5ms/step - loss: 0.1160 - val_loss: 0.0987\n",
      "Epoch 41/90\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.1078 - val_loss: 0.0906\n",
      "Epoch 42/90\n",
      "124/124 [==============================] - 1s 5ms/step - loss: 0.0998 - val_loss: 0.0824\n",
      "Epoch 43/90\n",
      "124/124 [==============================] - 1s 5ms/step - loss: 0.0917 - val_loss: 0.0743\n",
      "Epoch 44/90\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.0842 - val_loss: 0.0664\n",
      "Epoch 45/90\n",
      "124/124 [==============================] - 1s 5ms/step - loss: 0.0771 - val_loss: 0.0587\n",
      "Epoch 46/90\n",
      "124/124 [==============================] - 1s 5ms/step - loss: 0.0704 - val_loss: 0.0515\n",
      "Epoch 47/90\n",
      "124/124 [==============================] - 1s 5ms/step - loss: 0.0648 - val_loss: 0.0451\n",
      "Epoch 48/90\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.0604 - val_loss: 0.0414\n",
      "Epoch 49/90\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.0588 - val_loss: 0.0386\n",
      "Epoch 50/90\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.0578 - val_loss: 0.0365\n",
      "Epoch 51/90\n",
      "124/124 [==============================] - 1s 5ms/step - loss: 0.0570 - val_loss: 0.0349\n",
      "Epoch 52/90\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.0564 - val_loss: 0.0336\n",
      "Epoch 53/90\n",
      "124/124 [==============================] - 1s 5ms/step - loss: 0.0560 - val_loss: 0.0325\n",
      "Epoch 54/90\n",
      "124/124 [==============================] - 1s 5ms/step - loss: 0.0558 - val_loss: 0.0317\n",
      "Epoch 55/90\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.0553 - val_loss: 0.0310\n",
      "Epoch 56/90\n",
      "124/124 [==============================] - 1s 5ms/step - loss: 0.0552 - val_loss: 0.0303\n",
      "Epoch 57/90\n",
      "124/124 [==============================] - 1s 5ms/step - loss: 0.0550 - val_loss: 0.0297\n",
      "Epoch 58/90\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.0548 - val_loss: 0.0291\n",
      "Epoch 59/90\n",
      "124/124 [==============================] - 1s 5ms/step - loss: 0.0547 - val_loss: 0.0286\n",
      "Epoch 60/90\n",
      "124/124 [==============================] - 1s 5ms/step - loss: 0.0546 - val_loss: 0.0281\n",
      "Epoch 61/90\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.0544 - val_loss: 0.0276\n",
      "Epoch 62/90\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.0541 - val_loss: 0.0271\n",
      "Epoch 63/90\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.0543 - val_loss: 0.0266\n",
      "Epoch 64/90\n",
      "124/124 [==============================] - 1s 5ms/step - loss: 0.0541 - val_loss: 0.0262\n",
      "Epoch 65/90\n",
      "124/124 [==============================] - 1s 5ms/step - loss: 0.0540 - val_loss: 0.0257\n",
      "Epoch 66/90\n",
      "124/124 [==============================] - 1s 5ms/step - loss: 0.0539 - val_loss: 0.0253\n",
      "Epoch 67/90\n",
      "124/124 [==============================] - 1s 5ms/step - loss: 0.0539 - val_loss: 0.0250\n",
      "Epoch 68/90\n",
      "124/124 [==============================] - 1s 5ms/step - loss: 0.0538 - val_loss: 0.0246\n",
      "Epoch 69/90\n",
      "124/124 [==============================] - 1s 5ms/step - loss: 0.0537 - val_loss: 0.0243\n",
      "Epoch 70/90\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.0536 - val_loss: 0.0240\n",
      "Epoch 71/90\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.0536 - val_loss: 0.0237\n",
      "Epoch 72/90\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.0536 - val_loss: 0.0234\n",
      "Epoch 73/90\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.0535 - val_loss: 0.0231\n",
      "Epoch 74/90\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.0535 - val_loss: 0.0228\n",
      "Epoch 75/90\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.0534 - val_loss: 0.0225\n",
      "Epoch 76/90\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.0535 - val_loss: 0.0222\n",
      "Epoch 77/90\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.0532 - val_loss: 0.0220\n",
      "Epoch 78/90\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.0533 - val_loss: 0.0217\n",
      "Epoch 79/90\n",
      "124/124 [==============================] - 1s 5ms/step - loss: 0.0533 - val_loss: 0.0215\n",
      "Epoch 80/90\n",
      "124/124 [==============================] - 1s 5ms/step - loss: 0.0532 - val_loss: 0.0212\n",
      "Epoch 81/90\n",
      "124/124 [==============================] - 1s 5ms/step - loss: 0.0532 - val_loss: 0.0210\n",
      "Epoch 82/90\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "124/124 [==============================] - 1s 5ms/step - loss: 0.0532 - val_loss: 0.0208\n",
      "Epoch 83/90\n",
      "124/124 [==============================] - 1s 5ms/step - loss: 0.0532 - val_loss: 0.0207\n",
      "Epoch 84/90\n",
      "124/124 [==============================] - 1s 5ms/step - loss: 0.0531 - val_loss: 0.0205\n",
      "Epoch 85/90\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.0532 - val_loss: 0.0204\n",
      "Epoch 86/90\n",
      "124/124 [==============================] - 1s 5ms/step - loss: 0.0531 - val_loss: 0.0202\n",
      "Epoch 87/90\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.0530 - val_loss: 0.0201\n",
      "Epoch 88/90\n",
      "124/124 [==============================] - 1s 5ms/step - loss: 0.0531 - val_loss: 0.0199\n",
      "Epoch 89/90\n",
      "124/124 [==============================] - 1s 5ms/step - loss: 0.0529 - val_loss: 0.0198\n",
      "Epoch 90/90\n",
      "124/124 [==============================] - 1s 5ms/step - loss: 0.0529 - val_loss: 0.0196\n",
      "Execution time:  64.18820762634277\n",
      "DNN:\n",
      "Mean Absolute Error: 0.0250\n",
      "Root Mean Square Error: 0.0333\n",
      "Mean Square Error: 0.0011\n",
      "\n",
      "Train RMSE: 0.033\n",
      "Train MSE: 0.001\n",
      "Train MAE: 0.025\n",
      "###########################\n",
      "\n",
      "MODEL:  DNN\n",
      "sequence:  1d\n",
      "units:  12\n",
      "dropout1:  0.48476373451509647\n",
      "optimizer: adadelta\n",
      "activationDense: tanh\n",
      "epochs: 52\n",
      "batchsize: 57\n",
      "validation_split: 0.2\n",
      "Model: \"sequential_161\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_483 (Dense)            (None, 144, 12)           24        \n",
      "_________________________________________________________________\n",
      "dense_484 (Dense)            (None, 144, 16)           208       \n",
      "_________________________________________________________________\n",
      "dropout_161 (Dropout)        (None, 144, 16)           0         \n",
      "_________________________________________________________________\n",
      "dense_485 (Dense)            (None, 144, 1)            17        \n",
      "=================================================================\n",
      "Total params: 249\n",
      "Trainable params: 249\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/52\n",
      "54/54 [==============================] - 0s 9ms/step - loss: 0.3045 - val_loss: 0.2873\n",
      "Epoch 2/52\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 0.3040 - val_loss: 0.2864\n",
      "Epoch 3/52\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 0.3031 - val_loss: 0.2855\n",
      "Epoch 4/52\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 0.3020 - val_loss: 0.2845\n",
      "Epoch 5/52\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 0.3011 - val_loss: 0.2835\n",
      "Epoch 6/52\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 0.3003 - val_loss: 0.2825\n",
      "Epoch 7/52\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 0.2990 - val_loss: 0.2814\n",
      "Epoch 8/52\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 0.2980 - val_loss: 0.2803\n",
      "Epoch 9/52\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 0.2969 - val_loss: 0.2791\n",
      "Epoch 10/52\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 0.2954 - val_loss: 0.2780\n",
      "Epoch 11/52\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 0.2944 - val_loss: 0.2767\n",
      "Epoch 12/52\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 0.2934 - val_loss: 0.2755\n",
      "Epoch 13/52\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 0.2918 - val_loss: 0.2742\n",
      "Epoch 14/52\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 0.2909 - val_loss: 0.2729\n",
      "Epoch 15/52\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 0.2893 - val_loss: 0.2715\n",
      "Epoch 16/52\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 0.2877 - val_loss: 0.2702\n",
      "Epoch 17/52\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 0.2865 - val_loss: 0.2687\n",
      "Epoch 18/52\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 0.2853 - val_loss: 0.2673\n",
      "Epoch 19/52\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 0.2841 - val_loss: 0.2658\n",
      "Epoch 20/52\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 0.2826 - val_loss: 0.2644\n",
      "Epoch 21/52\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 0.2809 - val_loss: 0.2628\n",
      "Epoch 22/52\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 0.2793 - val_loss: 0.2613\n",
      "Epoch 23/52\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 0.2777 - val_loss: 0.2597\n",
      "Epoch 24/52\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 0.2761 - val_loss: 0.2581\n",
      "Epoch 25/52\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 0.2742 - val_loss: 0.2565\n",
      "Epoch 26/52\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 0.2731 - val_loss: 0.2549\n",
      "Epoch 27/52\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 0.2715 - val_loss: 0.2532\n",
      "Epoch 28/52\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 0.2699 - val_loss: 0.2515\n",
      "Epoch 29/52\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 0.2681 - val_loss: 0.2498\n",
      "Epoch 30/52\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 0.2662 - val_loss: 0.2481\n",
      "Epoch 31/52\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 0.2649 - val_loss: 0.2463\n",
      "Epoch 32/52\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 0.2632 - val_loss: 0.2445\n",
      "Epoch 33/52\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 0.2615 - val_loss: 0.2427\n",
      "Epoch 34/52\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 0.2596 - val_loss: 0.2409\n",
      "Epoch 35/52\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 0.2576 - val_loss: 0.2391\n",
      "Epoch 36/52\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 0.2557 - val_loss: 0.2372\n",
      "Epoch 37/52\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 0.2544 - val_loss: 0.2353\n",
      "Epoch 38/52\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 0.2522 - val_loss: 0.2334\n",
      "Epoch 39/52\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 0.2508 - val_loss: 0.2315\n",
      "Epoch 40/52\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 0.2488 - val_loss: 0.2295\n",
      "Epoch 41/52\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 0.2474 - val_loss: 0.2276\n",
      "Epoch 42/52\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 0.2448 - val_loss: 0.2256\n",
      "Epoch 43/52\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 0.2430 - val_loss: 0.2236\n",
      "Epoch 44/52\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 0.2413 - val_loss: 0.2216\n",
      "Epoch 45/52\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 0.2394 - val_loss: 0.2196\n",
      "Epoch 46/52\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 0.2377 - val_loss: 0.2176\n",
      "Epoch 47/52\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 0.2355 - val_loss: 0.2156\n",
      "Epoch 48/52\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 0.2341 - val_loss: 0.2135\n",
      "Epoch 49/52\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 0.2322 - val_loss: 0.2114\n",
      "Epoch 50/52\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 0.2297 - val_loss: 0.2094\n",
      "Epoch 51/52\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 0.2281 - val_loss: 0.2073\n",
      "Epoch 52/52\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 0.2262 - val_loss: 0.2052\n",
      "Execution time:  16.786931037902832\n",
      "DNN:\n",
      "Mean Absolute Error: 0.2174\n",
      "Root Mean Square Error: 0.2192\n",
      "Mean Square Error: 0.0481\n",
      "\n",
      "Train RMSE: 0.219\n",
      "Train MSE: 0.048\n",
      "Train MAE: 0.217\n",
      "###########################\n",
      "\n",
      "MODEL:  DNN\n",
      "sequence:  1d\n",
      "units:  87\n",
      "dropout1:  0.40519643149940265\n",
      "optimizer: adadelta\n",
      "activationDense: sigmoid\n",
      "epochs: 80\n",
      "batchsize: 31\n",
      "validation_split: 0.1\n",
      "Model: \"sequential_162\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_486 (Dense)            (None, 144, 87)           174       \n",
      "_________________________________________________________________\n",
      "dense_487 (Dense)            (None, 144, 16)           1408      \n",
      "_________________________________________________________________\n",
      "dropout_162 (Dropout)        (None, 144, 16)           0         \n",
      "_________________________________________________________________\n",
      "dense_488 (Dense)            (None, 144, 1)            17        \n",
      "=================================================================\n",
      "Total params: 1,599\n",
      "Trainable params: 1,599\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/80\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "112/112 [==============================] - 1s 8ms/step - loss: 0.0962 - val_loss: 0.1283\n",
      "Epoch 2/80\n",
      "112/112 [==============================] - 1s 6ms/step - loss: 0.0957 - val_loss: 0.1278\n",
      "Epoch 3/80\n",
      "112/112 [==============================] - 1s 6ms/step - loss: 0.0951 - val_loss: 0.1272\n",
      "Epoch 4/80\n",
      "112/112 [==============================] - 1s 6ms/step - loss: 0.0945 - val_loss: 0.1266\n",
      "Epoch 5/80\n",
      "112/112 [==============================] - 1s 6ms/step - loss: 0.0939 - val_loss: 0.1260\n",
      "Epoch 6/80\n",
      "112/112 [==============================] - 1s 6ms/step - loss: 0.0933 - val_loss: 0.1253\n",
      "Epoch 7/80\n",
      "112/112 [==============================] - 1s 7ms/step - loss: 0.0927 - val_loss: 0.1247\n",
      "Epoch 8/80\n",
      "112/112 [==============================] - 1s 6ms/step - loss: 0.0920 - val_loss: 0.1240\n",
      "Epoch 9/80\n",
      "112/112 [==============================] - 1s 6ms/step - loss: 0.0913 - val_loss: 0.1233\n",
      "Epoch 10/80\n",
      "112/112 [==============================] - 1s 6ms/step - loss: 0.0906 - val_loss: 0.1225\n",
      "Epoch 11/80\n",
      "112/112 [==============================] - 1s 6ms/step - loss: 0.0899 - val_loss: 0.1217\n",
      "Epoch 12/80\n",
      "112/112 [==============================] - 1s 7ms/step - loss: 0.0891 - val_loss: 0.1210\n",
      "Epoch 13/80\n",
      "112/112 [==============================] - 1s 7ms/step - loss: 0.0884 - val_loss: 0.1201\n",
      "Epoch 14/80\n",
      "112/112 [==============================] - 1s 6ms/step - loss: 0.0876 - val_loss: 0.1193\n",
      "Epoch 15/80\n",
      "112/112 [==============================] - 1s 6ms/step - loss: 0.0868 - val_loss: 0.1185\n",
      "Epoch 16/80\n",
      "112/112 [==============================] - 1s 6ms/step - loss: 0.0860 - val_loss: 0.1176\n",
      "Epoch 17/80\n",
      "112/112 [==============================] - 1s 6ms/step - loss: 0.0851 - val_loss: 0.1167\n",
      "Epoch 18/80\n",
      "112/112 [==============================] - 1s 6ms/step - loss: 0.0843 - val_loss: 0.1158\n",
      "Epoch 19/80\n",
      "112/112 [==============================] - 1s 6ms/step - loss: 0.0834 - val_loss: 0.1149\n",
      "Epoch 20/80\n",
      "112/112 [==============================] - 1s 6ms/step - loss: 0.0825 - val_loss: 0.1140\n",
      "Epoch 21/80\n",
      "112/112 [==============================] - 1s 7ms/step - loss: 0.0817 - val_loss: 0.1130\n",
      "Epoch 22/80\n",
      "112/112 [==============================] - 1s 7ms/step - loss: 0.0808 - val_loss: 0.1121\n",
      "Epoch 23/80\n",
      "112/112 [==============================] - 1s 7ms/step - loss: 0.0799 - val_loss: 0.1111\n",
      "Epoch 24/80\n",
      "112/112 [==============================] - 1s 7ms/step - loss: 0.0790 - val_loss: 0.1102\n",
      "Epoch 25/80\n",
      "112/112 [==============================] - 1s 6ms/step - loss: 0.0781 - val_loss: 0.1092\n",
      "Epoch 26/80\n",
      "112/112 [==============================] - 1s 6ms/step - loss: 0.0772 - val_loss: 0.1082\n",
      "Epoch 27/80\n",
      "112/112 [==============================] - 1s 6ms/step - loss: 0.0764 - val_loss: 0.1072\n",
      "Epoch 28/80\n",
      "112/112 [==============================] - 1s 6ms/step - loss: 0.0754 - val_loss: 0.1062\n",
      "Epoch 29/80\n",
      "112/112 [==============================] - 1s 6ms/step - loss: 0.0745 - val_loss: 0.1052\n",
      "Epoch 30/80\n",
      "112/112 [==============================] - 1s 6ms/step - loss: 0.0736 - val_loss: 0.1042\n",
      "Epoch 31/80\n",
      "112/112 [==============================] - 1s 6ms/step - loss: 0.0727 - val_loss: 0.1032\n",
      "Epoch 32/80\n",
      "112/112 [==============================] - 1s 6ms/step - loss: 0.0718 - val_loss: 0.1021\n",
      "Epoch 33/80\n",
      "112/112 [==============================] - 1s 6ms/step - loss: 0.0709 - val_loss: 0.1011\n",
      "Epoch 34/80\n",
      "112/112 [==============================] - 1s 7ms/step - loss: 0.0701 - val_loss: 0.1002\n",
      "Epoch 35/80\n",
      "112/112 [==============================] - 1s 6ms/step - loss: 0.0692 - val_loss: 0.0993\n",
      "Epoch 36/80\n",
      "112/112 [==============================] - 1s 6ms/step - loss: 0.0685 - val_loss: 0.0984\n",
      "Epoch 37/80\n",
      "112/112 [==============================] - 1s 6ms/step - loss: 0.0678 - val_loss: 0.0976\n",
      "Epoch 38/80\n",
      "112/112 [==============================] - 1s 6ms/step - loss: 0.0670 - val_loss: 0.0966\n",
      "Epoch 39/80\n",
      "112/112 [==============================] - 1s 6ms/step - loss: 0.0662 - val_loss: 0.0956\n",
      "Epoch 40/80\n",
      "112/112 [==============================] - 1s 6ms/step - loss: 0.0654 - val_loss: 0.0947\n",
      "Epoch 41/80\n",
      "112/112 [==============================] - 1s 6ms/step - loss: 0.0646 - val_loss: 0.0937\n",
      "Epoch 42/80\n",
      "112/112 [==============================] - 1s 7ms/step - loss: 0.0638 - val_loss: 0.0928\n",
      "Epoch 43/80\n",
      "112/112 [==============================] - 1s 7ms/step - loss: 0.0631 - val_loss: 0.0919\n",
      "Epoch 44/80\n",
      "112/112 [==============================] - 1s 7ms/step - loss: 0.0623 - val_loss: 0.0909\n",
      "Epoch 45/80\n",
      "112/112 [==============================] - 1s 7ms/step - loss: 0.0616 - val_loss: 0.0900\n",
      "Epoch 46/80\n",
      "112/112 [==============================] - 1s 7ms/step - loss: 0.0609 - val_loss: 0.0891\n",
      "Epoch 47/80\n",
      "112/112 [==============================] - 1s 6ms/step - loss: 0.0603 - val_loss: 0.0883\n",
      "Epoch 48/80\n",
      "112/112 [==============================] - 1s 7ms/step - loss: 0.0597 - val_loss: 0.0874\n",
      "Epoch 49/80\n",
      "112/112 [==============================] - 1s 6ms/step - loss: 0.0590 - val_loss: 0.0865\n",
      "Epoch 50/80\n",
      "112/112 [==============================] - 1s 7ms/step - loss: 0.0584 - val_loss: 0.0857\n",
      "Epoch 51/80\n",
      "112/112 [==============================] - 1s 6ms/step - loss: 0.0578 - val_loss: 0.0849\n",
      "Epoch 52/80\n",
      "112/112 [==============================] - 1s 7ms/step - loss: 0.0572 - val_loss: 0.0841\n",
      "Epoch 53/80\n",
      "112/112 [==============================] - 1s 6ms/step - loss: 0.0566 - val_loss: 0.0833\n",
      "Epoch 54/80\n",
      "112/112 [==============================] - 1s 6ms/step - loss: 0.0561 - val_loss: 0.0825\n",
      "Epoch 55/80\n",
      "112/112 [==============================] - 1s 6ms/step - loss: 0.0556 - val_loss: 0.0817\n",
      "Epoch 56/80\n",
      "112/112 [==============================] - 1s 6ms/step - loss: 0.0550 - val_loss: 0.0810\n",
      "Epoch 57/80\n",
      "112/112 [==============================] - 1s 6ms/step - loss: 0.0545 - val_loss: 0.0802\n",
      "Epoch 58/80\n",
      "112/112 [==============================] - 1s 7ms/step - loss: 0.0540 - val_loss: 0.0795\n",
      "Epoch 59/80\n",
      "112/112 [==============================] - 1s 6ms/step - loss: 0.0536 - val_loss: 0.0788\n",
      "Epoch 60/80\n",
      "112/112 [==============================] - 1s 6ms/step - loss: 0.0530 - val_loss: 0.0781\n",
      "Epoch 61/80\n",
      "112/112 [==============================] - 1s 6ms/step - loss: 0.0526 - val_loss: 0.0774\n",
      "Epoch 62/80\n",
      "112/112 [==============================] - 1s 6ms/step - loss: 0.0522 - val_loss: 0.0767\n",
      "Epoch 63/80\n",
      "112/112 [==============================] - 1s 6ms/step - loss: 0.0517 - val_loss: 0.0760\n",
      "Epoch 64/80\n",
      "112/112 [==============================] - 1s 7ms/step - loss: 0.0513 - val_loss: 0.0753\n",
      "Epoch 65/80\n",
      "112/112 [==============================] - 1s 7ms/step - loss: 0.0509 - val_loss: 0.0747\n",
      "Epoch 66/80\n",
      "112/112 [==============================] - 1s 7ms/step - loss: 0.0504 - val_loss: 0.0740\n",
      "Epoch 67/80\n",
      "112/112 [==============================] - 1s 7ms/step - loss: 0.0501 - val_loss: 0.0734\n",
      "Epoch 68/80\n",
      "112/112 [==============================] - 1s 7ms/step - loss: 0.0497 - val_loss: 0.0727\n",
      "Epoch 69/80\n",
      "112/112 [==============================] - 1s 6ms/step - loss: 0.0493 - val_loss: 0.0721\n",
      "Epoch 70/80\n",
      "112/112 [==============================] - 1s 6ms/step - loss: 0.0489 - val_loss: 0.0715\n",
      "Epoch 71/80\n",
      "112/112 [==============================] - 1s 6ms/step - loss: 0.0486 - val_loss: 0.0709\n",
      "Epoch 72/80\n",
      "112/112 [==============================] - 1s 6ms/step - loss: 0.0483 - val_loss: 0.0703\n",
      "Epoch 73/80\n",
      "112/112 [==============================] - 1s 6ms/step - loss: 0.0479 - val_loss: 0.0697\n",
      "Epoch 74/80\n",
      "112/112 [==============================] - 1s 6ms/step - loss: 0.0476 - val_loss: 0.0691\n",
      "Epoch 75/80\n",
      "112/112 [==============================] - 1s 6ms/step - loss: 0.0472 - val_loss: 0.0685\n",
      "Epoch 76/80\n",
      "112/112 [==============================] - 1s 6ms/step - loss: 0.0470 - val_loss: 0.0679\n",
      "Epoch 77/80\n",
      "112/112 [==============================] - 1s 6ms/step - loss: 0.0466 - val_loss: 0.0673\n",
      "Epoch 78/80\n",
      "112/112 [==============================] - 1s 7ms/step - loss: 0.0462 - val_loss: 0.0668\n",
      "Epoch 79/80\n",
      "112/112 [==============================] - 1s 7ms/step - loss: 0.0460 - val_loss: 0.0662\n",
      "Epoch 80/80\n",
      "112/112 [==============================] - 1s 6ms/step - loss: 0.0457 - val_loss: 0.0657\n",
      "Execution time:  60.93491840362549\n",
      "DNN:\n",
      "Mean Absolute Error: 0.0458\n",
      "Root Mean Square Error: 0.0542\n",
      "Mean Square Error: 0.0029\n",
      "\n",
      "Train RMSE: 0.054\n",
      "Train MSE: 0.003\n",
      "Train MAE: 0.046\n",
      "###########################\n",
      "\n",
      "MODEL:  DNN\n",
      "sequence:  1d\n",
      "units:  80\n",
      "dropout1:  0.11814836227952394\n",
      "optimizer: adadelta\n",
      "activationDense: sigmoid\n",
      "epochs: 90\n",
      "batchsize: 25\n",
      "validation_split: 0.1\n",
      "Model: \"sequential_163\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_489 (Dense)            (None, 144, 80)           160       \n",
      "_________________________________________________________________\n",
      "dense_490 (Dense)            (None, 144, 16)           1296      \n",
      "_________________________________________________________________\n",
      "dropout_163 (Dropout)        (None, 144, 16)           0         \n",
      "_________________________________________________________________\n",
      "dense_491 (Dense)            (None, 144, 1)            17        \n",
      "=================================================================\n",
      "Total params: 1,473\n",
      "Trainable params: 1,473\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/90\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "139/139 [==============================] - 1s 7ms/step - loss: 0.0945 - val_loss: 0.1267\n",
      "Epoch 2/90\n",
      "139/139 [==============================] - 1s 5ms/step - loss: 0.0940 - val_loss: 0.1263\n",
      "Epoch 3/90\n",
      "139/139 [==============================] - 1s 5ms/step - loss: 0.0935 - val_loss: 0.1257\n",
      "Epoch 4/90\n",
      "139/139 [==============================] - 1s 6ms/step - loss: 0.0930 - val_loss: 0.1252\n",
      "Epoch 5/90\n",
      "139/139 [==============================] - 1s 6ms/step - loss: 0.0924 - val_loss: 0.1246\n",
      "Epoch 6/90\n",
      "139/139 [==============================] - 1s 5ms/step - loss: 0.0919 - val_loss: 0.1240\n",
      "Epoch 7/90\n",
      "139/139 [==============================] - 1s 5ms/step - loss: 0.0913 - val_loss: 0.1234\n",
      "Epoch 8/90\n",
      "139/139 [==============================] - 1s 5ms/step - loss: 0.0907 - val_loss: 0.1228\n",
      "Epoch 9/90\n",
      "139/139 [==============================] - 1s 5ms/step - loss: 0.0901 - val_loss: 0.1222\n",
      "Epoch 10/90\n",
      "139/139 [==============================] - 1s 5ms/step - loss: 0.0895 - val_loss: 0.1215\n",
      "Epoch 11/90\n",
      "139/139 [==============================] - 1s 5ms/step - loss: 0.0888 - val_loss: 0.1208\n",
      "Epoch 12/90\n",
      "139/139 [==============================] - 1s 5ms/step - loss: 0.0882 - val_loss: 0.1201\n",
      "Epoch 13/90\n",
      "139/139 [==============================] - 1s 5ms/step - loss: 0.0875 - val_loss: 0.1194\n",
      "Epoch 14/90\n",
      "139/139 [==============================] - 1s 5ms/step - loss: 0.0868 - val_loss: 0.1186\n",
      "Epoch 15/90\n",
      "139/139 [==============================] - 1s 5ms/step - loss: 0.0861 - val_loss: 0.1179\n",
      "Epoch 16/90\n",
      "139/139 [==============================] - 1s 5ms/step - loss: 0.0853 - val_loss: 0.1171\n",
      "Epoch 17/90\n",
      "139/139 [==============================] - 1s 5ms/step - loss: 0.0846 - val_loss: 0.1163\n",
      "Epoch 18/90\n",
      "139/139 [==============================] - 1s 5ms/step - loss: 0.0838 - val_loss: 0.1155\n",
      "Epoch 19/90\n",
      "139/139 [==============================] - 1s 5ms/step - loss: 0.0831 - val_loss: 0.1147\n",
      "Epoch 20/90\n",
      "139/139 [==============================] - 1s 5ms/step - loss: 0.0823 - val_loss: 0.1139\n",
      "Epoch 21/90\n",
      "139/139 [==============================] - 1s 5ms/step - loss: 0.0816 - val_loss: 0.1131\n",
      "Epoch 22/90\n",
      "139/139 [==============================] - 1s 5ms/step - loss: 0.0808 - val_loss: 0.1123\n",
      "Epoch 23/90\n",
      "139/139 [==============================] - 1s 5ms/step - loss: 0.0800 - val_loss: 0.1114\n",
      "Epoch 24/90\n",
      "139/139 [==============================] - 1s 5ms/step - loss: 0.0792 - val_loss: 0.1106\n",
      "Epoch 25/90\n",
      "139/139 [==============================] - 1s 6ms/step - loss: 0.0784 - val_loss: 0.1097\n",
      "Epoch 26/90\n",
      "139/139 [==============================] - 1s 6ms/step - loss: 0.0776 - val_loss: 0.1088\n",
      "Epoch 27/90\n",
      "139/139 [==============================] - 1s 5ms/step - loss: 0.0768 - val_loss: 0.1080\n",
      "Epoch 28/90\n",
      "139/139 [==============================] - 1s 5ms/step - loss: 0.0760 - val_loss: 0.1071\n",
      "Epoch 29/90\n",
      "139/139 [==============================] - 1s 5ms/step - loss: 0.0752 - val_loss: 0.1062\n",
      "Epoch 30/90\n",
      "139/139 [==============================] - 1s 5ms/step - loss: 0.0744 - val_loss: 0.1053\n",
      "Epoch 31/90\n",
      "139/139 [==============================] - 1s 5ms/step - loss: 0.0736 - val_loss: 0.1044\n",
      "Epoch 32/90\n",
      "139/139 [==============================] - 1s 5ms/step - loss: 0.0728 - val_loss: 0.1034\n",
      "Epoch 33/90\n",
      "139/139 [==============================] - 1s 5ms/step - loss: 0.0719 - val_loss: 0.1025\n",
      "Epoch 34/90\n",
      "139/139 [==============================] - 1s 5ms/step - loss: 0.0711 - val_loss: 0.1016\n",
      "Epoch 35/90\n",
      "139/139 [==============================] - 1s 5ms/step - loss: 0.0703 - val_loss: 0.1006\n",
      "Epoch 36/90\n",
      "139/139 [==============================] - 1s 5ms/step - loss: 0.0695 - val_loss: 0.0996\n",
      "Epoch 37/90\n",
      "139/139 [==============================] - 1s 5ms/step - loss: 0.0686 - val_loss: 0.0987\n",
      "Epoch 38/90\n",
      "139/139 [==============================] - 1s 5ms/step - loss: 0.0678 - val_loss: 0.0977\n",
      "Epoch 39/90\n",
      "139/139 [==============================] - 1s 5ms/step - loss: 0.0670 - val_loss: 0.0968\n",
      "Epoch 40/90\n",
      "139/139 [==============================] - 1s 5ms/step - loss: 0.0661 - val_loss: 0.0958\n",
      "Epoch 41/90\n",
      "139/139 [==============================] - 1s 5ms/step - loss: 0.0653 - val_loss: 0.0948\n",
      "Epoch 42/90\n",
      "139/139 [==============================] - 1s 5ms/step - loss: 0.0645 - val_loss: 0.0939\n",
      "Epoch 43/90\n",
      "139/139 [==============================] - 1s 5ms/step - loss: 0.0637 - val_loss: 0.0929\n",
      "Epoch 44/90\n",
      "139/139 [==============================] - 1s 5ms/step - loss: 0.0629 - val_loss: 0.0920\n",
      "Epoch 45/90\n",
      "139/139 [==============================] - 1s 5ms/step - loss: 0.0622 - val_loss: 0.0910\n",
      "Epoch 46/90\n",
      "139/139 [==============================] - 1s 6ms/step - loss: 0.0614 - val_loss: 0.0901\n",
      "Epoch 47/90\n",
      "139/139 [==============================] - 1s 6ms/step - loss: 0.0606 - val_loss: 0.0891\n",
      "Epoch 48/90\n",
      "139/139 [==============================] - 1s 6ms/step - loss: 0.0599 - val_loss: 0.0882\n",
      "Epoch 49/90\n",
      "139/139 [==============================] - 1s 5ms/step - loss: 0.0591 - val_loss: 0.0872\n",
      "Epoch 50/90\n",
      "139/139 [==============================] - 1s 5ms/step - loss: 0.0583 - val_loss: 0.0863\n",
      "Epoch 51/90\n",
      "139/139 [==============================] - 1s 5ms/step - loss: 0.0576 - val_loss: 0.0854\n",
      "Epoch 52/90\n",
      "139/139 [==============================] - 1s 5ms/step - loss: 0.0569 - val_loss: 0.0844\n",
      "Epoch 53/90\n",
      "139/139 [==============================] - 1s 5ms/step - loss: 0.0562 - val_loss: 0.0835\n",
      "Epoch 54/90\n",
      "139/139 [==============================] - 1s 5ms/step - loss: 0.0555 - val_loss: 0.0826\n",
      "Epoch 55/90\n",
      "139/139 [==============================] - 1s 5ms/step - loss: 0.0549 - val_loss: 0.0818\n",
      "Epoch 56/90\n",
      "139/139 [==============================] - 1s 5ms/step - loss: 0.0543 - val_loss: 0.0810\n",
      "Epoch 57/90\n",
      "139/139 [==============================] - 1s 5ms/step - loss: 0.0537 - val_loss: 0.0801\n",
      "Epoch 58/90\n",
      "139/139 [==============================] - 1s 5ms/step - loss: 0.0531 - val_loss: 0.0793\n",
      "Epoch 59/90\n",
      "139/139 [==============================] - 1s 5ms/step - loss: 0.0525 - val_loss: 0.0786\n",
      "Epoch 60/90\n",
      "139/139 [==============================] - 1s 5ms/step - loss: 0.0520 - val_loss: 0.0778\n",
      "Epoch 61/90\n",
      "139/139 [==============================] - 1s 5ms/step - loss: 0.0515 - val_loss: 0.0770\n",
      "Epoch 62/90\n",
      "139/139 [==============================] - 1s 5ms/step - loss: 0.0510 - val_loss: 0.0763\n",
      "Epoch 63/90\n",
      "139/139 [==============================] - 1s 5ms/step - loss: 0.0505 - val_loss: 0.0755\n",
      "Epoch 64/90\n",
      "139/139 [==============================] - 1s 5ms/step - loss: 0.0500 - val_loss: 0.0748\n",
      "Epoch 65/90\n",
      "139/139 [==============================] - 1s 5ms/step - loss: 0.0495 - val_loss: 0.0741\n",
      "Epoch 66/90\n",
      "139/139 [==============================] - 1s 5ms/step - loss: 0.0490 - val_loss: 0.0734\n",
      "Epoch 67/90\n",
      "139/139 [==============================] - 1s 5ms/step - loss: 0.0486 - val_loss: 0.0726\n",
      "Epoch 68/90\n",
      "139/139 [==============================] - 1s 6ms/step - loss: 0.0482 - val_loss: 0.0720\n",
      "Epoch 69/90\n",
      "139/139 [==============================] - 1s 6ms/step - loss: 0.0478 - val_loss: 0.0713\n",
      "Epoch 70/90\n",
      "139/139 [==============================] - 1s 5ms/step - loss: 0.0473 - val_loss: 0.0706\n",
      "Epoch 71/90\n",
      "139/139 [==============================] - 1s 5ms/step - loss: 0.0469 - val_loss: 0.0699\n",
      "Epoch 72/90\n",
      "139/139 [==============================] - 1s 5ms/step - loss: 0.0465 - val_loss: 0.0693\n",
      "Epoch 73/90\n",
      "139/139 [==============================] - 1s 5ms/step - loss: 0.0462 - val_loss: 0.0687\n",
      "Epoch 74/90\n",
      "139/139 [==============================] - 1s 5ms/step - loss: 0.0458 - val_loss: 0.0680\n",
      "Epoch 75/90\n",
      "139/139 [==============================] - 1s 5ms/step - loss: 0.0454 - val_loss: 0.0674\n",
      "Epoch 76/90\n",
      "139/139 [==============================] - 1s 5ms/step - loss: 0.0451 - val_loss: 0.0667\n",
      "Epoch 77/90\n",
      "139/139 [==============================] - 1s 5ms/step - loss: 0.0447 - val_loss: 0.0661\n",
      "Epoch 78/90\n",
      "139/139 [==============================] - 1s 5ms/step - loss: 0.0444 - val_loss: 0.0655\n",
      "Epoch 79/90\n",
      "139/139 [==============================] - 1s 5ms/step - loss: 0.0440 - val_loss: 0.0649\n",
      "Epoch 80/90\n",
      "139/139 [==============================] - 1s 5ms/step - loss: 0.0437 - val_loss: 0.0643\n",
      "Epoch 81/90\n",
      "139/139 [==============================] - 1s 5ms/step - loss: 0.0434 - val_loss: 0.0636\n",
      "Epoch 82/90\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "139/139 [==============================] - 1s 5ms/step - loss: 0.0430 - val_loss: 0.0630\n",
      "Epoch 83/90\n",
      "139/139 [==============================] - 1s 5ms/step - loss: 0.0427 - val_loss: 0.0624\n",
      "Epoch 84/90\n",
      "139/139 [==============================] - 1s 5ms/step - loss: 0.0424 - val_loss: 0.0618\n",
      "Epoch 85/90\n",
      "139/139 [==============================] - 1s 5ms/step - loss: 0.0421 - val_loss: 0.0612\n",
      "Epoch 86/90\n",
      "139/139 [==============================] - 1s 5ms/step - loss: 0.0417 - val_loss: 0.0606\n",
      "Epoch 87/90\n",
      "139/139 [==============================] - 1s 5ms/step - loss: 0.0414 - val_loss: 0.0600\n",
      "Epoch 88/90\n",
      "139/139 [==============================] - 1s 5ms/step - loss: 0.0411 - val_loss: 0.0594\n",
      "Epoch 89/90\n",
      "139/139 [==============================] - 1s 6ms/step - loss: 0.0408 - val_loss: 0.0588\n",
      "Epoch 90/90\n",
      "139/139 [==============================] - 1s 6ms/step - loss: 0.0406 - val_loss: 0.0582\n",
      "Execution time:  68.71140575408936\n",
      "DNN:\n",
      "Mean Absolute Error: 0.0418\n",
      "Root Mean Square Error: 0.0504\n",
      "Mean Square Error: 0.0025\n",
      "\n",
      "Train RMSE: 0.050\n",
      "Train MSE: 0.003\n",
      "Train MAE: 0.042\n",
      "###########################\n",
      "\n",
      "MODEL:  DNN\n",
      "sequence:  1d\n",
      "units:  12\n",
      "dropout1:  0.48476373451509647\n",
      "optimizer: adadelta\n",
      "activationDense: sigmoid\n",
      "epochs: 52\n",
      "batchsize: 57\n",
      "validation_split: 0.1\n",
      "Model: \"sequential_164\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_492 (Dense)            (None, 144, 12)           24        \n",
      "_________________________________________________________________\n",
      "dense_493 (Dense)            (None, 144, 16)           208       \n",
      "_________________________________________________________________\n",
      "dropout_164 (Dropout)        (None, 144, 16)           0         \n",
      "_________________________________________________________________\n",
      "dense_494 (Dense)            (None, 144, 1)            17        \n",
      "=================================================================\n",
      "Total params: 249\n",
      "Trainable params: 249\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/52\n",
      "61/61 [==============================] - 0s 8ms/step - loss: 0.1072 - val_loss: 0.1381\n",
      "Epoch 2/52\n",
      "61/61 [==============================] - 0s 5ms/step - loss: 0.1071 - val_loss: 0.1379\n",
      "Epoch 3/52\n",
      "61/61 [==============================] - 0s 5ms/step - loss: 0.1067 - val_loss: 0.1377\n",
      "Epoch 4/52\n",
      "61/61 [==============================] - 0s 5ms/step - loss: 0.1065 - val_loss: 0.1374\n",
      "Epoch 5/52\n",
      "61/61 [==============================] - 0s 5ms/step - loss: 0.1064 - val_loss: 0.1372\n",
      "Epoch 6/52\n",
      "61/61 [==============================] - 0s 5ms/step - loss: 0.1062 - val_loss: 0.1369\n",
      "Epoch 7/52\n",
      "61/61 [==============================] - 0s 5ms/step - loss: 0.1058 - val_loss: 0.1367\n",
      "Epoch 8/52\n",
      "61/61 [==============================] - 0s 5ms/step - loss: 0.1055 - val_loss: 0.1364\n",
      "Epoch 9/52\n",
      "61/61 [==============================] - 0s 5ms/step - loss: 0.1052 - val_loss: 0.1361\n",
      "Epoch 10/52\n",
      "61/61 [==============================] - 0s 5ms/step - loss: 0.1050 - val_loss: 0.1358\n",
      "Epoch 11/52\n",
      "61/61 [==============================] - 0s 5ms/step - loss: 0.1047 - val_loss: 0.1355\n",
      "Epoch 12/52\n",
      "61/61 [==============================] - 0s 5ms/step - loss: 0.1045 - val_loss: 0.1352\n",
      "Epoch 13/52\n",
      "61/61 [==============================] - 0s 5ms/step - loss: 0.1042 - val_loss: 0.1349\n",
      "Epoch 14/52\n",
      "61/61 [==============================] - 0s 5ms/step - loss: 0.1039 - val_loss: 0.1346\n",
      "Epoch 15/52\n",
      "61/61 [==============================] - 0s 6ms/step - loss: 0.1036 - val_loss: 0.1343\n",
      "Epoch 16/52\n",
      "61/61 [==============================] - 0s 5ms/step - loss: 0.1033 - val_loss: 0.1339\n",
      "Epoch 17/52\n",
      "61/61 [==============================] - 0s 5ms/step - loss: 0.1030 - val_loss: 0.1336\n",
      "Epoch 18/52\n",
      "61/61 [==============================] - 0s 5ms/step - loss: 0.1027 - val_loss: 0.1333\n",
      "Epoch 19/52\n",
      "61/61 [==============================] - 0s 5ms/step - loss: 0.1023 - val_loss: 0.1329\n",
      "Epoch 20/52\n",
      "61/61 [==============================] - 0s 5ms/step - loss: 0.1020 - val_loss: 0.1326\n",
      "Epoch 21/52\n",
      "61/61 [==============================] - 0s 5ms/step - loss: 0.1017 - val_loss: 0.1323\n",
      "Epoch 22/52\n",
      "61/61 [==============================] - 0s 5ms/step - loss: 0.1014 - val_loss: 0.1319\n",
      "Epoch 23/52\n",
      "61/61 [==============================] - 0s 5ms/step - loss: 0.1010 - val_loss: 0.1315\n",
      "Epoch 24/52\n",
      "61/61 [==============================] - 0s 5ms/step - loss: 0.1007 - val_loss: 0.1312\n",
      "Epoch 25/52\n",
      "61/61 [==============================] - 0s 5ms/step - loss: 0.1004 - val_loss: 0.1308\n",
      "Epoch 26/52\n",
      "61/61 [==============================] - 0s 5ms/step - loss: 0.1000 - val_loss: 0.1305\n",
      "Epoch 27/52\n",
      "61/61 [==============================] - 0s 5ms/step - loss: 0.0997 - val_loss: 0.1301\n",
      "Epoch 28/52\n",
      "61/61 [==============================] - 0s 5ms/step - loss: 0.0993 - val_loss: 0.1297\n",
      "Epoch 29/52\n",
      "61/61 [==============================] - 0s 5ms/step - loss: 0.0989 - val_loss: 0.1293\n",
      "Epoch 30/52\n",
      "61/61 [==============================] - 0s 5ms/step - loss: 0.0986 - val_loss: 0.1290\n",
      "Epoch 31/52\n",
      "61/61 [==============================] - 0s 5ms/step - loss: 0.0983 - val_loss: 0.1286\n",
      "Epoch 32/52\n",
      "61/61 [==============================] - 0s 5ms/step - loss: 0.0979 - val_loss: 0.1282\n",
      "Epoch 33/52\n",
      "61/61 [==============================] - 0s 5ms/step - loss: 0.0975 - val_loss: 0.1278\n",
      "Epoch 34/52\n",
      "61/61 [==============================] - 0s 5ms/step - loss: 0.0971 - val_loss: 0.1274\n",
      "Epoch 35/52\n",
      "61/61 [==============================] - 0s 5ms/step - loss: 0.0968 - val_loss: 0.1270\n",
      "Epoch 36/52\n",
      "61/61 [==============================] - 0s 5ms/step - loss: 0.0964 - val_loss: 0.1266\n",
      "Epoch 37/52\n",
      "61/61 [==============================] - 0s 5ms/step - loss: 0.0960 - val_loss: 0.1262\n",
      "Epoch 38/52\n",
      "61/61 [==============================] - 0s 5ms/step - loss: 0.0956 - val_loss: 0.1258\n",
      "Epoch 39/52\n",
      "61/61 [==============================] - 0s 5ms/step - loss: 0.0953 - val_loss: 0.1254\n",
      "Epoch 40/52\n",
      "61/61 [==============================] - 0s 5ms/step - loss: 0.0950 - val_loss: 0.1250\n",
      "Epoch 41/52\n",
      "61/61 [==============================] - 0s 6ms/step - loss: 0.0946 - val_loss: 0.1246\n",
      "Epoch 42/52\n",
      "61/61 [==============================] - 0s 6ms/step - loss: 0.0941 - val_loss: 0.1242\n",
      "Epoch 43/52\n",
      "61/61 [==============================] - 0s 5ms/step - loss: 0.0938 - val_loss: 0.1238\n",
      "Epoch 44/52\n",
      "61/61 [==============================] - 0s 6ms/step - loss: 0.0935 - val_loss: 0.1234\n",
      "Epoch 45/52\n",
      "61/61 [==============================] - 0s 6ms/step - loss: 0.0931 - val_loss: 0.1230\n",
      "Epoch 46/52\n",
      "61/61 [==============================] - 0s 5ms/step - loss: 0.0927 - val_loss: 0.1226\n",
      "Epoch 47/52\n",
      "61/61 [==============================] - 0s 5ms/step - loss: 0.0924 - val_loss: 0.1222\n",
      "Epoch 48/52\n",
      "61/61 [==============================] - 0s 5ms/step - loss: 0.0920 - val_loss: 0.1218\n",
      "Epoch 49/52\n",
      "61/61 [==============================] - 0s 5ms/step - loss: 0.0916 - val_loss: 0.1213\n",
      "Epoch 50/52\n",
      "61/61 [==============================] - 0s 5ms/step - loss: 0.0913 - val_loss: 0.1209\n",
      "Epoch 51/52\n",
      "61/61 [==============================] - 0s 5ms/step - loss: 0.0908 - val_loss: 0.1205\n",
      "Epoch 52/52\n",
      "61/61 [==============================] - 0s 5ms/step - loss: 0.0904 - val_loss: 0.1201\n",
      "Execution time:  17.919365882873535\n",
      "DNN:\n",
      "Mean Absolute Error: 0.0903\n",
      "Root Mean Square Error: 0.0970\n",
      "Mean Square Error: 0.0094\n",
      "\n",
      "Train RMSE: 0.097\n",
      "Train MSE: 0.009\n",
      "Train MAE: 0.090\n",
      "###########################\n",
      "\n",
      "MODEL:  DNN\n",
      "sequence:  1d\n",
      "units:  87\n",
      "dropout1:  0.40519643149940265\n",
      "optimizer: adadelta\n",
      "activationDense: sigmoid\n",
      "epochs: 80\n",
      "batchsize: 31\n",
      "validation_split: 0.2\n",
      "Model: \"sequential_165\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_495 (Dense)            (None, 144, 87)           174       \n",
      "_________________________________________________________________\n",
      "dense_496 (Dense)            (None, 144, 16)           1408      \n",
      "_________________________________________________________________\n",
      "dropout_165 (Dropout)        (None, 144, 16)           0         \n",
      "_________________________________________________________________\n",
      "dense_497 (Dense)            (None, 144, 1)            17        \n",
      "=================================================================\n",
      "Total params: 1,599\n",
      "Trainable params: 1,599\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/80\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100/100 [==============================] - 1s 8ms/step - loss: 0.0977 - val_loss: 0.1167\n",
      "Epoch 2/80\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 0.0970 - val_loss: 0.1160\n",
      "Epoch 3/80\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 0.0962 - val_loss: 0.1152\n",
      "Epoch 4/80\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 0.0954 - val_loss: 0.1144\n",
      "Epoch 5/80\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 0.0946 - val_loss: 0.1136\n",
      "Epoch 6/80\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 0.0937 - val_loss: 0.1127\n",
      "Epoch 7/80\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 0.0928 - val_loss: 0.1118\n",
      "Epoch 8/80\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 0.0919 - val_loss: 0.1109\n",
      "Epoch 9/80\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 0.0909 - val_loss: 0.1100\n",
      "Epoch 10/80\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 0.0899 - val_loss: 0.1090\n",
      "Epoch 11/80\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 0.0889 - val_loss: 0.1080\n",
      "Epoch 12/80\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 0.0879 - val_loss: 0.1070\n",
      "Epoch 13/80\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 0.0870 - val_loss: 0.1062\n",
      "Epoch 14/80\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 0.0861 - val_loss: 0.1053\n",
      "Epoch 15/80\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 0.0852 - val_loss: 0.1045\n",
      "Epoch 16/80\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 0.0844 - val_loss: 0.1036\n",
      "Epoch 17/80\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 0.0834 - val_loss: 0.1027\n",
      "Epoch 18/80\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 0.0826 - val_loss: 0.1018\n",
      "Epoch 19/80\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 0.0816 - val_loss: 0.1009\n",
      "Epoch 20/80\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 0.0807 - val_loss: 0.1000\n",
      "Epoch 21/80\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 0.0798 - val_loss: 0.0990\n",
      "Epoch 22/80\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 0.0789 - val_loss: 0.0981\n",
      "Epoch 23/80\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 0.0780 - val_loss: 0.0972\n",
      "Epoch 24/80\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 0.0771 - val_loss: 0.0965\n",
      "Epoch 25/80\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 0.0764 - val_loss: 0.0957\n",
      "Epoch 26/80\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 0.0756 - val_loss: 0.0949\n",
      "Epoch 27/80\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 0.0749 - val_loss: 0.0942\n",
      "Epoch 28/80\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 0.0742 - val_loss: 0.0934\n",
      "Epoch 29/80\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 0.0735 - val_loss: 0.0927\n",
      "Epoch 30/80\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 0.0727 - val_loss: 0.0919\n",
      "Epoch 31/80\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 0.0720 - val_loss: 0.0912\n",
      "Epoch 32/80\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 0.0713 - val_loss: 0.0904\n",
      "Epoch 33/80\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 0.0706 - val_loss: 0.0896\n",
      "Epoch 34/80\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 0.0698 - val_loss: 0.0889\n",
      "Epoch 35/80\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 0.0691 - val_loss: 0.0882\n",
      "Epoch 36/80\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 0.0685 - val_loss: 0.0874\n",
      "Epoch 37/80\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 0.0678 - val_loss: 0.0867\n",
      "Epoch 38/80\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 0.0671 - val_loss: 0.0860\n",
      "Epoch 39/80\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 0.0665 - val_loss: 0.0853\n",
      "Epoch 40/80\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 0.0659 - val_loss: 0.0845\n",
      "Epoch 41/80\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 0.0652 - val_loss: 0.0837\n",
      "Epoch 42/80\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 0.0645 - val_loss: 0.0829\n",
      "Epoch 43/80\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 0.0638 - val_loss: 0.0821\n",
      "Epoch 44/80\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 0.0631 - val_loss: 0.0813\n",
      "Epoch 45/80\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 0.0624 - val_loss: 0.0805\n",
      "Epoch 46/80\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 0.0618 - val_loss: 0.0798\n",
      "Epoch 47/80\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 0.0611 - val_loss: 0.0790\n",
      "Epoch 48/80\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 0.0605 - val_loss: 0.0784\n",
      "Epoch 49/80\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 0.0600 - val_loss: 0.0777\n",
      "Epoch 50/80\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 0.0594 - val_loss: 0.0770\n",
      "Epoch 51/80\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 0.0589 - val_loss: 0.0764\n",
      "Epoch 52/80\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 0.0585 - val_loss: 0.0758\n",
      "Epoch 53/80\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 0.0580 - val_loss: 0.0751\n",
      "Epoch 54/80\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 0.0575 - val_loss: 0.0745\n",
      "Epoch 55/80\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 0.0570 - val_loss: 0.0739\n",
      "Epoch 56/80\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 0.0566 - val_loss: 0.0733\n",
      "Epoch 57/80\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 0.0561 - val_loss: 0.0728\n",
      "Epoch 58/80\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 0.0558 - val_loss: 0.0722\n",
      "Epoch 59/80\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 0.0553 - val_loss: 0.0716\n",
      "Epoch 60/80\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 0.0549 - val_loss: 0.0711\n",
      "Epoch 61/80\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 0.0545 - val_loss: 0.0706\n",
      "Epoch 62/80\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 0.0542 - val_loss: 0.0700\n",
      "Epoch 63/80\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 0.0538 - val_loss: 0.0695\n",
      "Epoch 64/80\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 0.0534 - val_loss: 0.0690\n",
      "Epoch 65/80\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 0.0531 - val_loss: 0.0685\n",
      "Epoch 66/80\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 0.0527 - val_loss: 0.0680\n",
      "Epoch 67/80\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 0.0524 - val_loss: 0.0675\n",
      "Epoch 68/80\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 0.0521 - val_loss: 0.0670\n",
      "Epoch 69/80\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 0.0518 - val_loss: 0.0665\n",
      "Epoch 70/80\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 0.0514 - val_loss: 0.0660\n",
      "Epoch 71/80\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 0.0511 - val_loss: 0.0656\n",
      "Epoch 72/80\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 0.0508 - val_loss: 0.0651\n",
      "Epoch 73/80\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 0.0504 - val_loss: 0.0646\n",
      "Epoch 74/80\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 0.0503 - val_loss: 0.0642\n",
      "Epoch 75/80\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 0.0499 - val_loss: 0.0637\n",
      "Epoch 76/80\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 0.0496 - val_loss: 0.0633\n",
      "Epoch 77/80\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 0.0494 - val_loss: 0.0628\n",
      "Epoch 78/80\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 0.0491 - val_loss: 0.0624\n",
      "Epoch 79/80\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 0.0488 - val_loss: 0.0620\n",
      "Epoch 80/80\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 0.0486 - val_loss: 0.0615\n",
      "Execution time:  56.42977023124695\n",
      "DNN:\n",
      "Mean Absolute Error: 0.0493\n",
      "Root Mean Square Error: 0.0574\n",
      "Mean Square Error: 0.0033\n",
      "\n",
      "Train RMSE: 0.057\n",
      "Train MSE: 0.003\n",
      "Train MAE: 0.049\n",
      "###########################\n",
      "\n",
      "MODEL:  DNN\n",
      "sequence:  1d\n",
      "units:  80\n",
      "dropout1:  0.11814836227952394\n",
      "optimizer: adadelta\n",
      "activationDense: sigmoid\n",
      "epochs: 90\n",
      "batchsize: 25\n",
      "validation_split: 0.2\n",
      "Model: \"sequential_166\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_498 (Dense)            (None, 144, 80)           160       \n",
      "_________________________________________________________________\n",
      "dense_499 (Dense)            (None, 144, 16)           1296      \n",
      "_________________________________________________________________\n",
      "dropout_166 (Dropout)        (None, 144, 16)           0         \n",
      "_________________________________________________________________\n",
      "dense_500 (Dense)            (None, 144, 1)            17        \n",
      "=================================================================\n",
      "Total params: 1,473\n",
      "Trainable params: 1,473\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/90\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "124/124 [==============================] - 1s 7ms/step - loss: 0.0986 - val_loss: 0.1176\n",
      "Epoch 2/90\n",
      "124/124 [==============================] - 1s 5ms/step - loss: 0.0979 - val_loss: 0.1169\n",
      "Epoch 3/90\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.0972 - val_loss: 0.1162\n",
      "Epoch 4/90\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.0964 - val_loss: 0.1155\n",
      "Epoch 5/90\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.0957 - val_loss: 0.1148\n",
      "Epoch 6/90\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.0949 - val_loss: 0.1140\n",
      "Epoch 7/90\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.0941 - val_loss: 0.1132\n",
      "Epoch 8/90\n",
      "124/124 [==============================] - 1s 5ms/step - loss: 0.0933 - val_loss: 0.1125\n",
      "Epoch 9/90\n",
      "124/124 [==============================] - 1s 5ms/step - loss: 0.0925 - val_loss: 0.1116\n",
      "Epoch 10/90\n",
      "124/124 [==============================] - 1s 5ms/step - loss: 0.0916 - val_loss: 0.1108\n",
      "Epoch 11/90\n",
      "124/124 [==============================] - 1s 5ms/step - loss: 0.0908 - val_loss: 0.1099\n",
      "Epoch 12/90\n",
      "124/124 [==============================] - 1s 5ms/step - loss: 0.0899 - val_loss: 0.1090\n",
      "Epoch 13/90\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.0890 - val_loss: 0.1081\n",
      "Epoch 14/90\n",
      "124/124 [==============================] - 1s 5ms/step - loss: 0.0880 - val_loss: 0.1072\n",
      "Epoch 15/90\n",
      "124/124 [==============================] - 1s 5ms/step - loss: 0.0870 - val_loss: 0.1062\n",
      "Epoch 16/90\n",
      "124/124 [==============================] - 1s 5ms/step - loss: 0.0861 - val_loss: 0.1054\n",
      "Epoch 17/90\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.0852 - val_loss: 0.1045\n",
      "Epoch 18/90\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.0843 - val_loss: 0.1037\n",
      "Epoch 19/90\n",
      "124/124 [==============================] - 1s 5ms/step - loss: 0.0834 - val_loss: 0.1028\n",
      "Epoch 20/90\n",
      "124/124 [==============================] - 1s 5ms/step - loss: 0.0826 - val_loss: 0.1019\n",
      "Epoch 21/90\n",
      "124/124 [==============================] - 1s 5ms/step - loss: 0.0816 - val_loss: 0.1010\n",
      "Epoch 22/90\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.0807 - val_loss: 0.1001\n",
      "Epoch 23/90\n",
      "124/124 [==============================] - 1s 5ms/step - loss: 0.0798 - val_loss: 0.0992\n",
      "Epoch 24/90\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.0789 - val_loss: 0.0983\n",
      "Epoch 25/90\n",
      "124/124 [==============================] - 1s 5ms/step - loss: 0.0780 - val_loss: 0.0973\n",
      "Epoch 26/90\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.0770 - val_loss: 0.0964\n",
      "Epoch 27/90\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.0761 - val_loss: 0.0955\n",
      "Epoch 28/90\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.0752 - val_loss: 0.0945\n",
      "Epoch 29/90\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.0743 - val_loss: 0.0936\n",
      "Epoch 30/90\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.0733 - val_loss: 0.0926\n",
      "Epoch 31/90\n",
      "124/124 [==============================] - 1s 5ms/step - loss: 0.0724 - val_loss: 0.0916\n",
      "Epoch 32/90\n",
      "124/124 [==============================] - 1s 5ms/step - loss: 0.0714 - val_loss: 0.0907\n",
      "Epoch 33/90\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.0705 - val_loss: 0.0897\n",
      "Epoch 34/90\n",
      "124/124 [==============================] - 1s 5ms/step - loss: 0.0695 - val_loss: 0.0887\n",
      "Epoch 35/90\n",
      "124/124 [==============================] - 1s 5ms/step - loss: 0.0686 - val_loss: 0.0877\n",
      "Epoch 36/90\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.0676 - val_loss: 0.0867\n",
      "Epoch 37/90\n",
      "124/124 [==============================] - 1s 5ms/step - loss: 0.0666 - val_loss: 0.0857\n",
      "Epoch 38/90\n",
      "124/124 [==============================] - 1s 5ms/step - loss: 0.0657 - val_loss: 0.0847\n",
      "Epoch 39/90\n",
      "124/124 [==============================] - 1s 5ms/step - loss: 0.0648 - val_loss: 0.0837\n",
      "Epoch 40/90\n",
      "124/124 [==============================] - 1s 5ms/step - loss: 0.0639 - val_loss: 0.0827\n",
      "Epoch 41/90\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.0630 - val_loss: 0.0817\n",
      "Epoch 42/90\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.0621 - val_loss: 0.0808\n",
      "Epoch 43/90\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.0613 - val_loss: 0.0798\n",
      "Epoch 44/90\n",
      "124/124 [==============================] - 1s 5ms/step - loss: 0.0604 - val_loss: 0.0788\n",
      "Epoch 45/90\n",
      "124/124 [==============================] - 1s 5ms/step - loss: 0.0595 - val_loss: 0.0779\n",
      "Epoch 46/90\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.0587 - val_loss: 0.0769\n",
      "Epoch 47/90\n",
      "124/124 [==============================] - 1s 5ms/step - loss: 0.0579 - val_loss: 0.0759\n",
      "Epoch 48/90\n",
      "124/124 [==============================] - 1s 5ms/step - loss: 0.0571 - val_loss: 0.0750\n",
      "Epoch 49/90\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.0562 - val_loss: 0.0741\n",
      "Epoch 50/90\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.0555 - val_loss: 0.0732\n",
      "Epoch 51/90\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.0548 - val_loss: 0.0723\n",
      "Epoch 52/90\n",
      "124/124 [==============================] - 1s 5ms/step - loss: 0.0541 - val_loss: 0.0714\n",
      "Epoch 53/90\n",
      "124/124 [==============================] - 1s 5ms/step - loss: 0.0534 - val_loss: 0.0706\n",
      "Epoch 54/90\n",
      "124/124 [==============================] - 1s 5ms/step - loss: 0.0528 - val_loss: 0.0697\n",
      "Epoch 55/90\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.0522 - val_loss: 0.0689\n",
      "Epoch 56/90\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.0517 - val_loss: 0.0682\n",
      "Epoch 57/90\n",
      "124/124 [==============================] - 1s 5ms/step - loss: 0.0511 - val_loss: 0.0674\n",
      "Epoch 58/90\n",
      "124/124 [==============================] - 1s 5ms/step - loss: 0.0506 - val_loss: 0.0666\n",
      "Epoch 59/90\n",
      "124/124 [==============================] - 1s 5ms/step - loss: 0.0500 - val_loss: 0.0659\n",
      "Epoch 60/90\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.0495 - val_loss: 0.0652\n",
      "Epoch 61/90\n",
      "124/124 [==============================] - 1s 5ms/step - loss: 0.0490 - val_loss: 0.0644\n",
      "Epoch 62/90\n",
      "124/124 [==============================] - 1s 5ms/step - loss: 0.0485 - val_loss: 0.0637\n",
      "Epoch 63/90\n",
      "124/124 [==============================] - 1s 5ms/step - loss: 0.0480 - val_loss: 0.0630\n",
      "Epoch 64/90\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.0476 - val_loss: 0.0624\n",
      "Epoch 65/90\n",
      "124/124 [==============================] - 1s 5ms/step - loss: 0.0471 - val_loss: 0.0617\n",
      "Epoch 66/90\n",
      "124/124 [==============================] - 1s 5ms/step - loss: 0.0467 - val_loss: 0.0611\n",
      "Epoch 67/90\n",
      "124/124 [==============================] - 1s 5ms/step - loss: 0.0463 - val_loss: 0.0604\n",
      "Epoch 68/90\n",
      "124/124 [==============================] - 1s 5ms/step - loss: 0.0459 - val_loss: 0.0598\n",
      "Epoch 69/90\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.0455 - val_loss: 0.0592\n",
      "Epoch 70/90\n",
      "124/124 [==============================] - 1s 5ms/step - loss: 0.0451 - val_loss: 0.0586\n",
      "Epoch 71/90\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.0448 - val_loss: 0.0580\n",
      "Epoch 72/90\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.0444 - val_loss: 0.0574\n",
      "Epoch 73/90\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.0441 - val_loss: 0.0568\n",
      "Epoch 74/90\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.0437 - val_loss: 0.0562\n",
      "Epoch 75/90\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.0434 - val_loss: 0.0556\n",
      "Epoch 76/90\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.0431 - val_loss: 0.0550\n",
      "Epoch 77/90\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.0428 - val_loss: 0.0545\n",
      "Epoch 78/90\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.0424 - val_loss: 0.0539\n",
      "Epoch 79/90\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.0422 - val_loss: 0.0533\n",
      "Epoch 80/90\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.0418 - val_loss: 0.0528\n",
      "Epoch 81/90\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.0416 - val_loss: 0.0522\n",
      "Epoch 82/90\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "124/124 [==============================] - 1s 6ms/step - loss: 0.0413 - val_loss: 0.0517\n",
      "Epoch 83/90\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.0410 - val_loss: 0.0512\n",
      "Epoch 84/90\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.0407 - val_loss: 0.0506\n",
      "Epoch 85/90\n",
      "124/124 [==============================] - 1s 5ms/step - loss: 0.0404 - val_loss: 0.0501\n",
      "Epoch 86/90\n",
      "124/124 [==============================] - 1s 5ms/step - loss: 0.0401 - val_loss: 0.0496\n",
      "Epoch 87/90\n",
      "124/124 [==============================] - 1s 5ms/step - loss: 0.0399 - val_loss: 0.0491\n",
      "Epoch 88/90\n",
      "124/124 [==============================] - 1s 5ms/step - loss: 0.0397 - val_loss: 0.0486\n",
      "Epoch 89/90\n",
      "124/124 [==============================] - 1s 5ms/step - loss: 0.0394 - val_loss: 0.0481\n",
      "Epoch 90/90\n",
      "124/124 [==============================] - 1s 5ms/step - loss: 0.0392 - val_loss: 0.0476\n",
      "Execution time:  64.22369146347046\n",
      "DNN:\n",
      "Mean Absolute Error: 0.0404\n",
      "Root Mean Square Error: 0.0494\n",
      "Mean Square Error: 0.0024\n",
      "\n",
      "Train RMSE: 0.049\n",
      "Train MSE: 0.002\n",
      "Train MAE: 0.040\n",
      "###########################\n",
      "\n",
      "MODEL:  DNN\n",
      "sequence:  1d\n",
      "units:  12\n",
      "dropout1:  0.48476373451509647\n",
      "optimizer: adadelta\n",
      "activationDense: sigmoid\n",
      "epochs: 52\n",
      "batchsize: 57\n",
      "validation_split: 0.2\n",
      "Model: \"sequential_167\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_501 (Dense)            (None, 144, 12)           24        \n",
      "_________________________________________________________________\n",
      "dense_502 (Dense)            (None, 144, 16)           208       \n",
      "_________________________________________________________________\n",
      "dropout_167 (Dropout)        (None, 144, 16)           0         \n",
      "_________________________________________________________________\n",
      "dense_503 (Dense)            (None, 144, 1)            17        \n",
      "=================================================================\n",
      "Total params: 249\n",
      "Trainable params: 249\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/52\n",
      "54/54 [==============================] - 0s 9ms/step - loss: 0.0789 - val_loss: 0.0986\n",
      "Epoch 2/52\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 0.0788 - val_loss: 0.0985\n",
      "Epoch 3/52\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 0.0787 - val_loss: 0.0983\n",
      "Epoch 4/52\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 0.0786 - val_loss: 0.0982\n",
      "Epoch 5/52\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 0.0785 - val_loss: 0.0981\n",
      "Epoch 6/52\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 0.0784 - val_loss: 0.0980\n",
      "Epoch 7/52\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 0.0783 - val_loss: 0.0978\n",
      "Epoch 8/52\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 0.0781 - val_loss: 0.0977\n",
      "Epoch 9/52\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 0.0780 - val_loss: 0.0976\n",
      "Epoch 10/52\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 0.0779 - val_loss: 0.0974\n",
      "Epoch 11/52\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 0.0777 - val_loss: 0.0973\n",
      "Epoch 12/52\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 0.0776 - val_loss: 0.0971\n",
      "Epoch 13/52\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 0.0774 - val_loss: 0.0970\n",
      "Epoch 14/52\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 0.0773 - val_loss: 0.0968\n",
      "Epoch 15/52\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 0.0772 - val_loss: 0.0967\n",
      "Epoch 16/52\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 0.0770 - val_loss: 0.0965\n",
      "Epoch 17/52\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 0.0769 - val_loss: 0.0964\n",
      "Epoch 18/52\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 0.0768 - val_loss: 0.0962\n",
      "Epoch 19/52\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 0.0766 - val_loss: 0.0961\n",
      "Epoch 20/52\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 0.0765 - val_loss: 0.0959\n",
      "Epoch 21/52\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 0.0763 - val_loss: 0.0958\n",
      "Epoch 22/52\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 0.0762 - val_loss: 0.0956\n",
      "Epoch 23/52\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 0.0760 - val_loss: 0.0954\n",
      "Epoch 24/52\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 0.0759 - val_loss: 0.0953\n",
      "Epoch 25/52\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 0.0756 - val_loss: 0.0951\n",
      "Epoch 26/52\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 0.0756 - val_loss: 0.0949\n",
      "Epoch 27/52\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 0.0754 - val_loss: 0.0948\n",
      "Epoch 28/52\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 0.0752 - val_loss: 0.0946\n",
      "Epoch 29/52\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 0.0751 - val_loss: 0.0944\n",
      "Epoch 30/52\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 0.0749 - val_loss: 0.0942\n",
      "Epoch 31/52\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 0.0747 - val_loss: 0.0941\n",
      "Epoch 32/52\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 0.0746 - val_loss: 0.0939\n",
      "Epoch 33/52\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 0.0744 - val_loss: 0.0937\n",
      "Epoch 34/52\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 0.0743 - val_loss: 0.0935\n",
      "Epoch 35/52\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 0.0741 - val_loss: 0.0934\n",
      "Epoch 36/52\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 0.0739 - val_loss: 0.0932\n",
      "Epoch 37/52\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 0.0737 - val_loss: 0.0930\n",
      "Epoch 38/52\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 0.0736 - val_loss: 0.0928\n",
      "Epoch 39/52\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 0.0734 - val_loss: 0.0927\n",
      "Epoch 40/52\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 0.0733 - val_loss: 0.0925\n",
      "Epoch 41/52\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 0.0731 - val_loss: 0.0923\n",
      "Epoch 42/52\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 0.0729 - val_loss: 0.0921\n",
      "Epoch 43/52\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 0.0727 - val_loss: 0.0919\n",
      "Epoch 44/52\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 0.0726 - val_loss: 0.0917\n",
      "Epoch 45/52\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 0.0724 - val_loss: 0.0916\n",
      "Epoch 46/52\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 0.0722 - val_loss: 0.0914\n",
      "Epoch 47/52\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 0.0721 - val_loss: 0.0912\n",
      "Epoch 48/52\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 0.0719 - val_loss: 0.0910\n",
      "Epoch 49/52\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 0.0718 - val_loss: 0.0908\n",
      "Epoch 50/52\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 0.0716 - val_loss: 0.0906\n",
      "Epoch 51/52\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 0.0714 - val_loss: 0.0905\n",
      "Epoch 52/52\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 0.0712 - val_loss: 0.0903\n",
      "Execution time:  17.163371324539185\n",
      "DNN:\n",
      "Mean Absolute Error: 0.0735\n",
      "Root Mean Square Error: 0.0812\n",
      "Mean Square Error: 0.0066\n",
      "\n",
      "Train RMSE: 0.081\n",
      "Train MSE: 0.007\n",
      "Train MAE: 0.074\n",
      "###########################\n",
      "\n",
      "MODEL:  DNN\n",
      "sequence:  1d\n",
      "units:  87\n",
      "dropout1:  0.40519643149940265\n",
      "optimizer: adamax\n",
      "activationDense: tanh\n",
      "epochs: 80\n",
      "batchsize: 31\n",
      "validation_split: 0.1\n",
      "Model: \"sequential_168\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_504 (Dense)            (None, 144, 87)           174       \n",
      "_________________________________________________________________\n",
      "dense_505 (Dense)            (None, 144, 16)           1408      \n",
      "_________________________________________________________________\n",
      "dropout_168 (Dropout)        (None, 144, 16)           0         \n",
      "_________________________________________________________________\n",
      "dense_506 (Dense)            (None, 144, 1)            17        \n",
      "=================================================================\n",
      "Total params: 1,599\n",
      "Trainable params: 1,599\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/80\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "112/112 [==============================] - 1s 9ms/step - loss: 0.1612 - val_loss: 0.0158\n",
      "Epoch 2/80\n",
      "112/112 [==============================] - 1s 7ms/step - loss: 0.0997 - val_loss: 0.0225\n",
      "Epoch 3/80\n",
      "112/112 [==============================] - 1s 6ms/step - loss: 0.0848 - val_loss: 0.0130\n",
      "Epoch 4/80\n",
      "112/112 [==============================] - 1s 7ms/step - loss: 0.0716 - val_loss: 0.0087\n",
      "Epoch 5/80\n",
      "112/112 [==============================] - 1s 7ms/step - loss: 0.0636 - val_loss: 0.0097\n",
      "Epoch 6/80\n",
      "112/112 [==============================] - 1s 7ms/step - loss: 0.0579 - val_loss: 0.0071\n",
      "Epoch 7/80\n",
      "112/112 [==============================] - 1s 6ms/step - loss: 0.0517 - val_loss: 0.0060\n",
      "Epoch 8/80\n",
      "112/112 [==============================] - 1s 6ms/step - loss: 0.0472 - val_loss: 0.0065\n",
      "Epoch 9/80\n",
      "112/112 [==============================] - 1s 6ms/step - loss: 0.0437 - val_loss: 0.0072\n",
      "Epoch 10/80\n",
      "112/112 [==============================] - 1s 6ms/step - loss: 0.0407 - val_loss: 0.0080\n",
      "Epoch 11/80\n",
      "112/112 [==============================] - 1s 7ms/step - loss: 0.0381 - val_loss: 0.0090\n",
      "Epoch 12/80\n",
      "112/112 [==============================] - 1s 6ms/step - loss: 0.0358 - val_loss: 0.0118\n",
      "Epoch 13/80\n",
      "112/112 [==============================] - 1s 6ms/step - loss: 0.0342 - val_loss: 0.0136\n",
      "Epoch 14/80\n",
      "112/112 [==============================] - 1s 6ms/step - loss: 0.0329 - val_loss: 0.0139\n",
      "Epoch 15/80\n",
      "112/112 [==============================] - 1s 6ms/step - loss: 0.0320 - val_loss: 0.0113\n",
      "Epoch 16/80\n",
      "112/112 [==============================] - 1s 6ms/step - loss: 0.0306 - val_loss: 0.0098\n",
      "Epoch 17/80\n",
      "112/112 [==============================] - 1s 7ms/step - loss: 0.0299 - val_loss: 0.0103\n",
      "Epoch 18/80\n",
      "112/112 [==============================] - 1s 6ms/step - loss: 0.0291 - val_loss: 0.0099\n",
      "Epoch 19/80\n",
      "112/112 [==============================] - 1s 6ms/step - loss: 0.0284 - val_loss: 0.0097\n",
      "Epoch 20/80\n",
      "112/112 [==============================] - 1s 6ms/step - loss: 0.0282 - val_loss: 0.0097\n",
      "Epoch 21/80\n",
      "112/112 [==============================] - 1s 7ms/step - loss: 0.0280 - val_loss: 0.0101\n",
      "Epoch 22/80\n",
      "112/112 [==============================] - 1s 7ms/step - loss: 0.0278 - val_loss: 0.0109\n",
      "Epoch 23/80\n",
      "112/112 [==============================] - 1s 7ms/step - loss: 0.0277 - val_loss: 0.0112\n",
      "Epoch 24/80\n",
      "112/112 [==============================] - 1s 7ms/step - loss: 0.0276 - val_loss: 0.0119\n",
      "Epoch 25/80\n",
      "112/112 [==============================] - 1s 6ms/step - loss: 0.0276 - val_loss: 0.0122\n",
      "Epoch 26/80\n",
      "112/112 [==============================] - 1s 6ms/step - loss: 0.0275 - val_loss: 0.0129\n",
      "Epoch 27/80\n",
      "112/112 [==============================] - 1s 6ms/step - loss: 0.0275 - val_loss: 0.0133\n",
      "Epoch 28/80\n",
      "112/112 [==============================] - 1s 7ms/step - loss: 0.0274 - val_loss: 0.0139\n",
      "Epoch 29/80\n",
      "112/112 [==============================] - 1s 6ms/step - loss: 0.0274 - val_loss: 0.0137\n",
      "Epoch 30/80\n",
      "112/112 [==============================] - 1s 6ms/step - loss: 0.0275 - val_loss: 0.0124\n",
      "Epoch 31/80\n",
      "112/112 [==============================] - 1s 6ms/step - loss: 0.0276 - val_loss: 0.0133\n",
      "Epoch 32/80\n",
      "112/112 [==============================] - 1s 6ms/step - loss: 0.0271 - val_loss: 0.0139\n",
      "Epoch 33/80\n",
      "112/112 [==============================] - 1s 6ms/step - loss: 0.0273 - val_loss: 0.0140\n",
      "Epoch 34/80\n",
      "112/112 [==============================] - 1s 6ms/step - loss: 0.0273 - val_loss: 0.0141\n",
      "Epoch 35/80\n",
      "112/112 [==============================] - 1s 6ms/step - loss: 0.0272 - val_loss: 0.0127\n",
      "Epoch 36/80\n",
      "112/112 [==============================] - 1s 6ms/step - loss: 0.0273 - val_loss: 0.0141\n",
      "Epoch 37/80\n",
      "112/112 [==============================] - 1s 6ms/step - loss: 0.0272 - val_loss: 0.0128\n",
      "Epoch 38/80\n",
      "112/112 [==============================] - 1s 6ms/step - loss: 0.0273 - val_loss: 0.0132\n",
      "Epoch 39/80\n",
      "112/112 [==============================] - 1s 7ms/step - loss: 0.0273 - val_loss: 0.0123\n",
      "Epoch 40/80\n",
      "112/112 [==============================] - 1s 7ms/step - loss: 0.0273 - val_loss: 0.0139\n",
      "Epoch 41/80\n",
      "112/112 [==============================] - 1s 6ms/step - loss: 0.0272 - val_loss: 0.0127\n",
      "Epoch 42/80\n",
      "112/112 [==============================] - 1s 7ms/step - loss: 0.0273 - val_loss: 0.0129\n",
      "Epoch 43/80\n",
      "112/112 [==============================] - 1s 7ms/step - loss: 0.0273 - val_loss: 0.0130\n",
      "Epoch 44/80\n",
      "112/112 [==============================] - 1s 7ms/step - loss: 0.0273 - val_loss: 0.0136\n",
      "Epoch 45/80\n",
      "112/112 [==============================] - 1s 7ms/step - loss: 0.0272 - val_loss: 0.0126\n",
      "Epoch 46/80\n",
      "112/112 [==============================] - 1s 7ms/step - loss: 0.0274 - val_loss: 0.0133\n",
      "Epoch 47/80\n",
      "112/112 [==============================] - 1s 6ms/step - loss: 0.0271 - val_loss: 0.0136\n",
      "Epoch 48/80\n",
      "112/112 [==============================] - 1s 7ms/step - loss: 0.0271 - val_loss: 0.0118\n",
      "Epoch 49/80\n",
      "112/112 [==============================] - 1s 6ms/step - loss: 0.0272 - val_loss: 0.0130\n",
      "Epoch 50/80\n",
      "112/112 [==============================] - 1s 6ms/step - loss: 0.0271 - val_loss: 0.0131\n",
      "Epoch 51/80\n",
      "112/112 [==============================] - 1s 7ms/step - loss: 0.0271 - val_loss: 0.0121\n",
      "Epoch 52/80\n",
      "112/112 [==============================] - 1s 7ms/step - loss: 0.0272 - val_loss: 0.0125\n",
      "Epoch 53/80\n",
      "112/112 [==============================] - 1s 6ms/step - loss: 0.0272 - val_loss: 0.0128\n",
      "Epoch 54/80\n",
      "112/112 [==============================] - 1s 6ms/step - loss: 0.0271 - val_loss: 0.0122\n",
      "Epoch 55/80\n",
      "112/112 [==============================] - 1s 7ms/step - loss: 0.0272 - val_loss: 0.0121\n",
      "Epoch 56/80\n",
      "112/112 [==============================] - 1s 6ms/step - loss: 0.0272 - val_loss: 0.0126\n",
      "Epoch 57/80\n",
      "112/112 [==============================] - 1s 6ms/step - loss: 0.0272 - val_loss: 0.0122\n",
      "Epoch 58/80\n",
      "112/112 [==============================] - 1s 7ms/step - loss: 0.0272 - val_loss: 0.0123\n",
      "Epoch 59/80\n",
      "112/112 [==============================] - 1s 6ms/step - loss: 0.0272 - val_loss: 0.0121\n",
      "Epoch 60/80\n",
      "112/112 [==============================] - 1s 7ms/step - loss: 0.0271 - val_loss: 0.0125\n",
      "Epoch 61/80\n",
      "112/112 [==============================] - 1s 6ms/step - loss: 0.0270 - val_loss: 0.0125\n",
      "Epoch 62/80\n",
      "112/112 [==============================] - 1s 7ms/step - loss: 0.0271 - val_loss: 0.0108\n",
      "Epoch 63/80\n",
      "112/112 [==============================] - 1s 7ms/step - loss: 0.0272 - val_loss: 0.0124\n",
      "Epoch 64/80\n",
      "112/112 [==============================] - 1s 7ms/step - loss: 0.0270 - val_loss: 0.0118\n",
      "Epoch 65/80\n",
      "112/112 [==============================] - 1s 7ms/step - loss: 0.0271 - val_loss: 0.0113\n",
      "Epoch 66/80\n",
      "112/112 [==============================] - 1s 7ms/step - loss: 0.0271 - val_loss: 0.0119\n",
      "Epoch 67/80\n",
      "112/112 [==============================] - 1s 7ms/step - loss: 0.0270 - val_loss: 0.0116\n",
      "Epoch 68/80\n",
      "112/112 [==============================] - 1s 7ms/step - loss: 0.0271 - val_loss: 0.0106\n",
      "Epoch 69/80\n",
      "112/112 [==============================] - 1s 7ms/step - loss: 0.0271 - val_loss: 0.0118\n",
      "Epoch 70/80\n",
      "112/112 [==============================] - 1s 7ms/step - loss: 0.0269 - val_loss: 0.0112\n",
      "Epoch 71/80\n",
      "112/112 [==============================] - 1s 6ms/step - loss: 0.0271 - val_loss: 0.0103\n",
      "Epoch 72/80\n",
      "112/112 [==============================] - 1s 6ms/step - loss: 0.0271 - val_loss: 0.0114\n",
      "Epoch 73/80\n",
      "112/112 [==============================] - 1s 7ms/step - loss: 0.0269 - val_loss: 0.0112\n",
      "Epoch 74/80\n",
      "112/112 [==============================] - 1s 7ms/step - loss: 0.0270 - val_loss: 0.0104\n",
      "Epoch 75/80\n",
      "112/112 [==============================] - 1s 6ms/step - loss: 0.0270 - val_loss: 0.0112\n",
      "Epoch 76/80\n",
      "112/112 [==============================] - 1s 6ms/step - loss: 0.0269 - val_loss: 0.0108\n",
      "Epoch 77/80\n",
      "112/112 [==============================] - 1s 6ms/step - loss: 0.0270 - val_loss: 0.0106\n",
      "Epoch 78/80\n",
      "112/112 [==============================] - 1s 6ms/step - loss: 0.0269 - val_loss: 0.0115\n",
      "Epoch 79/80\n",
      "112/112 [==============================] - 1s 7ms/step - loss: 0.0268 - val_loss: 0.0101\n",
      "Epoch 80/80\n",
      "112/112 [==============================] - 1s 6ms/step - loss: 0.0270 - val_loss: 0.0115\n",
      "Execution time:  60.94595503807068\n",
      "DNN:\n",
      "Mean Absolute Error: 0.0242\n",
      "Root Mean Square Error: 0.0416\n",
      "Mean Square Error: 0.0017\n",
      "\n",
      "Train RMSE: 0.042\n",
      "Train MSE: 0.002\n",
      "Train MAE: 0.024\n",
      "###########################\n",
      "\n",
      "MODEL:  DNN\n",
      "sequence:  1d\n",
      "units:  80\n",
      "dropout1:  0.11814836227952394\n",
      "optimizer: adamax\n",
      "activationDense: tanh\n",
      "epochs: 90\n",
      "batchsize: 25\n",
      "validation_split: 0.1\n",
      "Model: \"sequential_169\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_507 (Dense)            (None, 144, 80)           160       \n",
      "_________________________________________________________________\n",
      "dense_508 (Dense)            (None, 144, 16)           1296      \n",
      "_________________________________________________________________\n",
      "dropout_169 (Dropout)        (None, 144, 16)           0         \n",
      "_________________________________________________________________\n",
      "dense_509 (Dense)            (None, 144, 1)            17        \n",
      "=================================================================\n",
      "Total params: 1,473\n",
      "Trainable params: 1,473\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/90\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "139/139 [==============================] - 1s 7ms/step - loss: 0.0973 - val_loss: 0.0099\n",
      "Epoch 2/90\n",
      "139/139 [==============================] - 1s 5ms/step - loss: 0.0532 - val_loss: 0.0084\n",
      "Epoch 3/90\n",
      "139/139 [==============================] - 1s 5ms/step - loss: 0.0511 - val_loss: 0.0066\n",
      "Epoch 4/90\n",
      "139/139 [==============================] - 1s 6ms/step - loss: 0.0489 - val_loss: 0.0058\n",
      "Epoch 5/90\n",
      "139/139 [==============================] - 1s 6ms/step - loss: 0.0470 - val_loss: 0.0065\n",
      "Epoch 6/90\n",
      "139/139 [==============================] - 1s 5ms/step - loss: 0.0453 - val_loss: 0.0069\n",
      "Epoch 7/90\n",
      "139/139 [==============================] - 1s 5ms/step - loss: 0.0437 - val_loss: 0.0078\n",
      "Epoch 8/90\n",
      "139/139 [==============================] - 1s 5ms/step - loss: 0.0421 - val_loss: 0.0083\n",
      "Epoch 9/90\n",
      "139/139 [==============================] - 1s 5ms/step - loss: 0.0410 - val_loss: 0.0096\n",
      "Epoch 10/90\n",
      "139/139 [==============================] - 1s 5ms/step - loss: 0.0397 - val_loss: 0.0098\n",
      "Epoch 11/90\n",
      "139/139 [==============================] - 1s 5ms/step - loss: 0.0387 - val_loss: 0.0097\n",
      "Epoch 12/90\n",
      "139/139 [==============================] - 1s 5ms/step - loss: 0.0377 - val_loss: 0.0099\n",
      "Epoch 13/90\n",
      "139/139 [==============================] - 1s 5ms/step - loss: 0.0369 - val_loss: 0.0120\n",
      "Epoch 14/90\n",
      "139/139 [==============================] - 1s 5ms/step - loss: 0.0363 - val_loss: 0.0133\n",
      "Epoch 15/90\n",
      "139/139 [==============================] - 1s 5ms/step - loss: 0.0356 - val_loss: 0.0130\n",
      "Epoch 16/90\n",
      "139/139 [==============================] - 1s 5ms/step - loss: 0.0349 - val_loss: 0.0143\n",
      "Epoch 17/90\n",
      "139/139 [==============================] - 1s 5ms/step - loss: 0.0343 - val_loss: 0.0154\n",
      "Epoch 18/90\n",
      "139/139 [==============================] - 1s 5ms/step - loss: 0.0339 - val_loss: 0.0166\n",
      "Epoch 19/90\n",
      "139/139 [==============================] - 1s 5ms/step - loss: 0.0334 - val_loss: 0.0170\n",
      "Epoch 20/90\n",
      "139/139 [==============================] - 1s 5ms/step - loss: 0.0330 - val_loss: 0.0174\n",
      "Epoch 21/90\n",
      "139/139 [==============================] - 1s 5ms/step - loss: 0.0326 - val_loss: 0.0172\n",
      "Epoch 22/90\n",
      "139/139 [==============================] - 1s 5ms/step - loss: 0.0321 - val_loss: 0.0172\n",
      "Epoch 23/90\n",
      "139/139 [==============================] - 1s 6ms/step - loss: 0.0317 - val_loss: 0.0167\n",
      "Epoch 24/90\n",
      "139/139 [==============================] - 1s 5ms/step - loss: 0.0313 - val_loss: 0.0157\n",
      "Epoch 25/90\n",
      "139/139 [==============================] - 1s 6ms/step - loss: 0.0310 - val_loss: 0.0164\n",
      "Epoch 26/90\n",
      "139/139 [==============================] - 1s 6ms/step - loss: 0.0306 - val_loss: 0.0160\n",
      "Epoch 27/90\n",
      "139/139 [==============================] - 1s 6ms/step - loss: 0.0304 - val_loss: 0.0162\n",
      "Epoch 28/90\n",
      "139/139 [==============================] - 1s 6ms/step - loss: 0.0301 - val_loss: 0.0159\n",
      "Epoch 29/90\n",
      "139/139 [==============================] - 1s 6ms/step - loss: 0.0299 - val_loss: 0.0156\n",
      "Epoch 30/90\n",
      "139/139 [==============================] - 1s 5ms/step - loss: 0.0297 - val_loss: 0.0154\n",
      "Epoch 31/90\n",
      "139/139 [==============================] - 1s 5ms/step - loss: 0.0293 - val_loss: 0.0158\n",
      "Epoch 32/90\n",
      "139/139 [==============================] - 1s 5ms/step - loss: 0.0291 - val_loss: 0.0154\n",
      "Epoch 33/90\n",
      "139/139 [==============================] - 1s 5ms/step - loss: 0.0289 - val_loss: 0.0150\n",
      "Epoch 34/90\n",
      "139/139 [==============================] - 1s 5ms/step - loss: 0.0288 - val_loss: 0.0149\n",
      "Epoch 35/90\n",
      "139/139 [==============================] - 1s 5ms/step - loss: 0.0287 - val_loss: 0.0147\n",
      "Epoch 36/90\n",
      "139/139 [==============================] - 1s 5ms/step - loss: 0.0286 - val_loss: 0.0134\n",
      "Epoch 37/90\n",
      "139/139 [==============================] - 1s 5ms/step - loss: 0.0286 - val_loss: 0.0133\n",
      "Epoch 38/90\n",
      "139/139 [==============================] - 1s 5ms/step - loss: 0.0284 - val_loss: 0.0128\n",
      "Epoch 39/90\n",
      "139/139 [==============================] - 1s 5ms/step - loss: 0.0285 - val_loss: 0.0130\n",
      "Epoch 40/90\n",
      "139/139 [==============================] - 1s 5ms/step - loss: 0.0285 - val_loss: 0.0128\n",
      "Epoch 41/90\n",
      "139/139 [==============================] - 1s 5ms/step - loss: 0.0284 - val_loss: 0.0124\n",
      "Epoch 42/90\n",
      "139/139 [==============================] - 1s 5ms/step - loss: 0.0282 - val_loss: 0.0123\n",
      "Epoch 43/90\n",
      "139/139 [==============================] - 1s 5ms/step - loss: 0.0282 - val_loss: 0.0122\n",
      "Epoch 44/90\n",
      "139/139 [==============================] - 1s 5ms/step - loss: 0.0282 - val_loss: 0.0113\n",
      "Epoch 45/90\n",
      "139/139 [==============================] - 1s 5ms/step - loss: 0.0282 - val_loss: 0.0109\n",
      "Epoch 46/90\n",
      "139/139 [==============================] - 1s 6ms/step - loss: 0.0282 - val_loss: 0.0110\n",
      "Epoch 47/90\n",
      "139/139 [==============================] - 1s 6ms/step - loss: 0.0280 - val_loss: 0.0105\n",
      "Epoch 48/90\n",
      "139/139 [==============================] - 1s 6ms/step - loss: 0.0280 - val_loss: 0.0102\n",
      "Epoch 49/90\n",
      "139/139 [==============================] - 1s 5ms/step - loss: 0.0279 - val_loss: 0.0105\n",
      "Epoch 50/90\n",
      "139/139 [==============================] - 1s 5ms/step - loss: 0.0278 - val_loss: 0.0108\n",
      "Epoch 51/90\n",
      "139/139 [==============================] - 1s 5ms/step - loss: 0.0278 - val_loss: 0.0112\n",
      "Epoch 52/90\n",
      "139/139 [==============================] - 1s 5ms/step - loss: 0.0278 - val_loss: 0.0116\n",
      "Epoch 53/90\n",
      "139/139 [==============================] - 1s 5ms/step - loss: 0.0280 - val_loss: 0.0107\n",
      "Epoch 54/90\n",
      "139/139 [==============================] - 1s 5ms/step - loss: 0.0278 - val_loss: 0.0108\n",
      "Epoch 55/90\n",
      "139/139 [==============================] - 1s 5ms/step - loss: 0.0278 - val_loss: 0.0108\n",
      "Epoch 56/90\n",
      "139/139 [==============================] - 1s 5ms/step - loss: 0.0277 - val_loss: 0.0118\n",
      "Epoch 57/90\n",
      "139/139 [==============================] - 1s 5ms/step - loss: 0.0277 - val_loss: 0.0113\n",
      "Epoch 58/90\n",
      "139/139 [==============================] - 1s 5ms/step - loss: 0.0277 - val_loss: 0.0109\n",
      "Epoch 59/90\n",
      "139/139 [==============================] - 1s 5ms/step - loss: 0.0277 - val_loss: 0.0120\n",
      "Epoch 60/90\n",
      "139/139 [==============================] - 1s 5ms/step - loss: 0.0276 - val_loss: 0.0126\n",
      "Epoch 61/90\n",
      "139/139 [==============================] - 1s 5ms/step - loss: 0.0276 - val_loss: 0.0112\n",
      "Epoch 62/90\n",
      "139/139 [==============================] - 1s 5ms/step - loss: 0.0277 - val_loss: 0.0121\n",
      "Epoch 63/90\n",
      "139/139 [==============================] - 1s 5ms/step - loss: 0.0276 - val_loss: 0.0125\n",
      "Epoch 64/90\n",
      "139/139 [==============================] - 1s 5ms/step - loss: 0.0276 - val_loss: 0.0118\n",
      "Epoch 65/90\n",
      "139/139 [==============================] - 1s 5ms/step - loss: 0.0276 - val_loss: 0.0123\n",
      "Epoch 66/90\n",
      "139/139 [==============================] - 1s 5ms/step - loss: 0.0276 - val_loss: 0.0119\n",
      "Epoch 67/90\n",
      "139/139 [==============================] - 1s 6ms/step - loss: 0.0276 - val_loss: 0.0121\n",
      "Epoch 68/90\n",
      "139/139 [==============================] - 1s 6ms/step - loss: 0.0276 - val_loss: 0.0118\n",
      "Epoch 69/90\n",
      "139/139 [==============================] - 1s 5ms/step - loss: 0.0276 - val_loss: 0.0120\n",
      "Epoch 70/90\n",
      "139/139 [==============================] - 1s 5ms/step - loss: 0.0276 - val_loss: 0.0118\n",
      "Epoch 71/90\n",
      "139/139 [==============================] - 1s 5ms/step - loss: 0.0276 - val_loss: 0.0119\n",
      "Epoch 72/90\n",
      "139/139 [==============================] - 1s 5ms/step - loss: 0.0276 - val_loss: 0.0117\n",
      "Epoch 73/90\n",
      "139/139 [==============================] - 1s 5ms/step - loss: 0.0276 - val_loss: 0.0118\n",
      "Epoch 74/90\n",
      "139/139 [==============================] - 1s 5ms/step - loss: 0.0276 - val_loss: 0.0119\n",
      "Epoch 75/90\n",
      "139/139 [==============================] - 1s 5ms/step - loss: 0.0275 - val_loss: 0.0118\n",
      "Epoch 76/90\n",
      "139/139 [==============================] - 1s 5ms/step - loss: 0.0275 - val_loss: 0.0115\n",
      "Epoch 77/90\n",
      "139/139 [==============================] - 1s 5ms/step - loss: 0.0276 - val_loss: 0.0114\n",
      "Epoch 78/90\n",
      "139/139 [==============================] - 1s 5ms/step - loss: 0.0276 - val_loss: 0.0116\n",
      "Epoch 79/90\n",
      "139/139 [==============================] - 1s 5ms/step - loss: 0.0275 - val_loss: 0.0117\n",
      "Epoch 80/90\n",
      "139/139 [==============================] - 1s 6ms/step - loss: 0.0275 - val_loss: 0.0114\n",
      "Epoch 81/90\n",
      "139/139 [==============================] - 1s 6ms/step - loss: 0.0275 - val_loss: 0.0112\n",
      "Epoch 82/90\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "139/139 [==============================] - 1s 5ms/step - loss: 0.0275 - val_loss: 0.0113\n",
      "Epoch 83/90\n",
      "139/139 [==============================] - 1s 5ms/step - loss: 0.0275 - val_loss: 0.0114\n",
      "Epoch 84/90\n",
      "139/139 [==============================] - 1s 5ms/step - loss: 0.0275 - val_loss: 0.0113\n",
      "Epoch 85/90\n",
      "139/139 [==============================] - 1s 5ms/step - loss: 0.0275 - val_loss: 0.0113\n",
      "Epoch 86/90\n",
      "139/139 [==============================] - 1s 5ms/step - loss: 0.0275 - val_loss: 0.0108\n",
      "Epoch 87/90\n",
      "139/139 [==============================] - 1s 5ms/step - loss: 0.0275 - val_loss: 0.0107\n",
      "Epoch 88/90\n",
      "139/139 [==============================] - 1s 6ms/step - loss: 0.0275 - val_loss: 0.0108\n",
      "Epoch 89/90\n",
      "139/139 [==============================] - 1s 6ms/step - loss: 0.0275 - val_loss: 0.0107\n",
      "Epoch 90/90\n",
      "139/139 [==============================] - 1s 5ms/step - loss: 0.0275 - val_loss: 0.0106\n",
      "Execution time:  69.50578308105469\n",
      "DNN:\n",
      "Mean Absolute Error: 0.0258\n",
      "Root Mean Square Error: 0.0455\n",
      "Mean Square Error: 0.0021\n",
      "\n",
      "Train RMSE: 0.045\n",
      "Train MSE: 0.002\n",
      "Train MAE: 0.026\n",
      "###########################\n",
      "\n",
      "MODEL:  DNN\n",
      "sequence:  1d\n",
      "units:  12\n",
      "dropout1:  0.48476373451509647\n",
      "optimizer: adamax\n",
      "activationDense: tanh\n",
      "epochs: 52\n",
      "batchsize: 57\n",
      "validation_split: 0.1\n",
      "Model: \"sequential_170\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_510 (Dense)            (None, 144, 12)           24        \n",
      "_________________________________________________________________\n",
      "dense_511 (Dense)            (None, 144, 16)           208       \n",
      "_________________________________________________________________\n",
      "dropout_170 (Dropout)        (None, 144, 16)           0         \n",
      "_________________________________________________________________\n",
      "dense_512 (Dense)            (None, 144, 1)            17        \n",
      "=================================================================\n",
      "Total params: 249\n",
      "Trainable params: 249\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/52\n",
      "61/61 [==============================] - 1s 8ms/step - loss: 0.2658 - val_loss: 0.0907\n",
      "Epoch 2/52\n",
      "61/61 [==============================] - 0s 5ms/step - loss: 0.1204 - val_loss: 0.0144\n",
      "Epoch 3/52\n",
      "61/61 [==============================] - 0s 5ms/step - loss: 0.1073 - val_loss: 0.0065\n",
      "Epoch 4/52\n",
      "61/61 [==============================] - 0s 5ms/step - loss: 0.0978 - val_loss: 0.0064\n",
      "Epoch 5/52\n",
      "61/61 [==============================] - 0s 5ms/step - loss: 0.0893 - val_loss: 0.0068\n",
      "Epoch 6/52\n",
      "61/61 [==============================] - 0s 5ms/step - loss: 0.0824 - val_loss: 0.0093\n",
      "Epoch 7/52\n",
      "61/61 [==============================] - 0s 5ms/step - loss: 0.0761 - val_loss: 0.0084\n",
      "Epoch 8/52\n",
      "61/61 [==============================] - 0s 5ms/step - loss: 0.0704 - val_loss: 0.0070\n",
      "Epoch 9/52\n",
      "61/61 [==============================] - 0s 5ms/step - loss: 0.0648 - val_loss: 0.0057\n",
      "Epoch 10/52\n",
      "61/61 [==============================] - 0s 5ms/step - loss: 0.0586 - val_loss: 0.0071\n",
      "Epoch 11/52\n",
      "61/61 [==============================] - 0s 5ms/step - loss: 0.0523 - val_loss: 0.0084\n",
      "Epoch 12/52\n",
      "61/61 [==============================] - 0s 5ms/step - loss: 0.0477 - val_loss: 0.0079\n",
      "Epoch 13/52\n",
      "61/61 [==============================] - 0s 5ms/step - loss: 0.0444 - val_loss: 0.0077\n",
      "Epoch 14/52\n",
      "61/61 [==============================] - 0s 5ms/step - loss: 0.0417 - val_loss: 0.0079\n",
      "Epoch 15/52\n",
      "61/61 [==============================] - 0s 5ms/step - loss: 0.0392 - val_loss: 0.0087\n",
      "Epoch 16/52\n",
      "61/61 [==============================] - 0s 5ms/step - loss: 0.0368 - val_loss: 0.0093\n",
      "Epoch 17/52\n",
      "61/61 [==============================] - 0s 5ms/step - loss: 0.0347 - val_loss: 0.0101\n",
      "Epoch 18/52\n",
      "61/61 [==============================] - 0s 5ms/step - loss: 0.0329 - val_loss: 0.0107\n",
      "Epoch 19/52\n",
      "61/61 [==============================] - 0s 5ms/step - loss: 0.0313 - val_loss: 0.0106\n",
      "Epoch 20/52\n",
      "61/61 [==============================] - 0s 5ms/step - loss: 0.0302 - val_loss: 0.0102\n",
      "Epoch 21/52\n",
      "61/61 [==============================] - 0s 5ms/step - loss: 0.0294 - val_loss: 0.0102\n",
      "Epoch 22/52\n",
      "61/61 [==============================] - 0s 5ms/step - loss: 0.0287 - val_loss: 0.0099\n",
      "Epoch 23/52\n",
      "61/61 [==============================] - 0s 5ms/step - loss: 0.0282 - val_loss: 0.0097\n",
      "Epoch 24/52\n",
      "61/61 [==============================] - 0s 5ms/step - loss: 0.0279 - val_loss: 0.0096\n",
      "Epoch 25/52\n",
      "61/61 [==============================] - 0s 5ms/step - loss: 0.0276 - val_loss: 0.0095\n",
      "Epoch 26/52\n",
      "61/61 [==============================] - 0s 5ms/step - loss: 0.0275 - val_loss: 0.0096\n",
      "Epoch 27/52\n",
      "61/61 [==============================] - 0s 5ms/step - loss: 0.0273 - val_loss: 0.0100\n",
      "Epoch 28/52\n",
      "61/61 [==============================] - 0s 5ms/step - loss: 0.0274 - val_loss: 0.0108\n",
      "Epoch 29/52\n",
      "61/61 [==============================] - 0s 5ms/step - loss: 0.0271 - val_loss: 0.0107\n",
      "Epoch 30/52\n",
      "61/61 [==============================] - 0s 5ms/step - loss: 0.0272 - val_loss: 0.0120\n",
      "Epoch 31/52\n",
      "61/61 [==============================] - 0s 5ms/step - loss: 0.0271 - val_loss: 0.0132\n",
      "Epoch 32/52\n",
      "61/61 [==============================] - 0s 5ms/step - loss: 0.0268 - val_loss: 0.0126\n",
      "Epoch 33/52\n",
      "61/61 [==============================] - 0s 5ms/step - loss: 0.0268 - val_loss: 0.0145\n",
      "Epoch 34/52\n",
      "61/61 [==============================] - 0s 5ms/step - loss: 0.0268 - val_loss: 0.0153\n",
      "Epoch 35/52\n",
      "61/61 [==============================] - 0s 5ms/step - loss: 0.0266 - val_loss: 0.0151\n",
      "Epoch 36/52\n",
      "61/61 [==============================] - 0s 5ms/step - loss: 0.0267 - val_loss: 0.0156\n",
      "Epoch 37/52\n",
      "61/61 [==============================] - 0s 5ms/step - loss: 0.0266 - val_loss: 0.0157\n",
      "Epoch 38/52\n",
      "61/61 [==============================] - 0s 5ms/step - loss: 0.0266 - val_loss: 0.0161\n",
      "Epoch 39/52\n",
      "61/61 [==============================] - 0s 6ms/step - loss: 0.0265 - val_loss: 0.0158\n",
      "Epoch 40/52\n",
      "61/61 [==============================] - 0s 6ms/step - loss: 0.0265 - val_loss: 0.0150\n",
      "Epoch 41/52\n",
      "61/61 [==============================] - 0s 6ms/step - loss: 0.0266 - val_loss: 0.0158\n",
      "Epoch 42/52\n",
      "61/61 [==============================] - 0s 5ms/step - loss: 0.0264 - val_loss: 0.0153\n",
      "Epoch 43/52\n",
      "61/61 [==============================] - 0s 6ms/step - loss: 0.0267 - val_loss: 0.0162\n",
      "Epoch 44/52\n",
      "61/61 [==============================] - 0s 5ms/step - loss: 0.0265 - val_loss: 0.0164\n",
      "Epoch 45/52\n",
      "61/61 [==============================] - 0s 5ms/step - loss: 0.0265 - val_loss: 0.0155\n",
      "Epoch 46/52\n",
      "61/61 [==============================] - 0s 5ms/step - loss: 0.0267 - val_loss: 0.0174\n",
      "Epoch 47/52\n",
      "61/61 [==============================] - 0s 5ms/step - loss: 0.0262 - val_loss: 0.0158\n",
      "Epoch 48/52\n",
      "61/61 [==============================] - 0s 5ms/step - loss: 0.0266 - val_loss: 0.0169\n",
      "Epoch 49/52\n",
      "61/61 [==============================] - 0s 5ms/step - loss: 0.0263 - val_loss: 0.0161\n",
      "Epoch 50/52\n",
      "61/61 [==============================] - 0s 5ms/step - loss: 0.0265 - val_loss: 0.0171\n",
      "Epoch 51/52\n",
      "61/61 [==============================] - 0s 5ms/step - loss: 0.0263 - val_loss: 0.0166\n",
      "Epoch 52/52\n",
      "61/61 [==============================] - 0s 5ms/step - loss: 0.0264 - val_loss: 0.0164\n",
      "Execution time:  17.956063508987427\n",
      "DNN:\n",
      "Mean Absolute Error: 0.0251\n",
      "Root Mean Square Error: 0.0420\n",
      "Mean Square Error: 0.0018\n",
      "\n",
      "Train RMSE: 0.042\n",
      "Train MSE: 0.002\n",
      "Train MAE: 0.025\n",
      "###########################\n",
      "\n",
      "MODEL:  DNN\n",
      "sequence:  1d\n",
      "units:  87\n",
      "dropout1:  0.40519643149940265\n",
      "optimizer: adamax\n",
      "activationDense: tanh\n",
      "epochs: 80\n",
      "batchsize: 31\n",
      "validation_split: 0.2\n",
      "Model: \"sequential_171\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_513 (Dense)            (None, 144, 87)           174       \n",
      "_________________________________________________________________\n",
      "dense_514 (Dense)            (None, 144, 16)           1408      \n",
      "_________________________________________________________________\n",
      "dropout_171 (Dropout)        (None, 144, 16)           0         \n",
      "_________________________________________________________________\n",
      "dense_515 (Dense)            (None, 144, 1)            17        \n",
      "=================================================================\n",
      "Total params: 1,599\n",
      "Trainable params: 1,599\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/80\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100/100 [==============================] - 1s 12ms/step - loss: 0.1146 - val_loss: 0.0327\n",
      "Epoch 2/80\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 0.0890 - val_loss: 0.0416\n",
      "Epoch 3/80\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 0.0827 - val_loss: 0.0386\n",
      "Epoch 4/80\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 0.0773 - val_loss: 0.0370\n",
      "Epoch 5/80\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 0.0713 - val_loss: 0.0342\n",
      "Epoch 6/80\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 0.0658 - val_loss: 0.0324\n",
      "Epoch 7/80\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 0.0604 - val_loss: 0.0298\n",
      "Epoch 8/80\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 0.0551 - val_loss: 0.0278\n",
      "Epoch 9/80\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 0.0499 - val_loss: 0.0266\n",
      "Epoch 10/80\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 0.0460 - val_loss: 0.0246\n",
      "Epoch 11/80\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 0.0428 - val_loss: 0.0238\n",
      "Epoch 12/80\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 0.0401 - val_loss: 0.0224\n",
      "Epoch 13/80\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 0.0380 - val_loss: 0.0210\n",
      "Epoch 14/80\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 0.0361 - val_loss: 0.0195\n",
      "Epoch 15/80\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 0.0346 - val_loss: 0.0185\n",
      "Epoch 16/80\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 0.0334 - val_loss: 0.0180\n",
      "Epoch 17/80\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 0.0326 - val_loss: 0.0181\n",
      "Epoch 18/80\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 0.0324 - val_loss: 0.0171\n",
      "Epoch 19/80\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 0.0318 - val_loss: 0.0169\n",
      "Epoch 20/80\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 0.0313 - val_loss: 0.0166\n",
      "Epoch 21/80\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 0.0302 - val_loss: 0.0164\n",
      "Epoch 22/80\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 0.0300 - val_loss: 0.0162\n",
      "Epoch 23/80\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 0.0295 - val_loss: 0.0163\n",
      "Epoch 24/80\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 0.0289 - val_loss: 0.0164\n",
      "Epoch 25/80\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 0.0286 - val_loss: 0.0182\n",
      "Epoch 26/80\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 0.0285 - val_loss: 0.0187\n",
      "Epoch 27/80\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 0.0283 - val_loss: 0.0186\n",
      "Epoch 28/80\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 0.0283 - val_loss: 0.0189\n",
      "Epoch 29/80\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 0.0282 - val_loss: 0.0189\n",
      "Epoch 30/80\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 0.0282 - val_loss: 0.0190\n",
      "Epoch 31/80\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 0.0282 - val_loss: 0.0192\n",
      "Epoch 32/80\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 0.0281 - val_loss: 0.0189\n",
      "Epoch 33/80\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 0.0282 - val_loss: 0.0191\n",
      "Epoch 34/80\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 0.0282 - val_loss: 0.0192\n",
      "Epoch 35/80\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 0.0281 - val_loss: 0.0190\n",
      "Epoch 36/80\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 0.0282 - val_loss: 0.0192\n",
      "Epoch 37/80\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 0.0281 - val_loss: 0.0190\n",
      "Epoch 38/80\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 0.0282 - val_loss: 0.0192\n",
      "Epoch 39/80\n",
      "100/100 [==============================] - 1s 8ms/step - loss: 0.0281 - val_loss: 0.0189\n",
      "Epoch 40/80\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 0.0282 - val_loss: 0.0192\n",
      "Epoch 41/80\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 0.0281 - val_loss: 0.0189\n",
      "Epoch 42/80\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 0.0282 - val_loss: 0.0192\n",
      "Epoch 43/80\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 0.0281 - val_loss: 0.0189\n",
      "Epoch 44/80\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 0.0282 - val_loss: 0.0192\n",
      "Epoch 45/80\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 0.0281 - val_loss: 0.0189\n",
      "Epoch 46/80\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 0.0282 - val_loss: 0.0191\n",
      "Epoch 47/80\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 0.0281 - val_loss: 0.0191\n",
      "Epoch 48/80\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 0.0281 - val_loss: 0.0191\n",
      "Epoch 49/80\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 0.0281 - val_loss: 0.0190\n",
      "Epoch 50/80\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 0.0281 - val_loss: 0.0191\n",
      "Epoch 51/80\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 0.0281 - val_loss: 0.0189\n",
      "Epoch 52/80\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 0.0282 - val_loss: 0.0191\n",
      "Epoch 53/80\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 0.0281 - val_loss: 0.0191\n",
      "Epoch 54/80\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 0.0281 - val_loss: 0.0188\n",
      "Epoch 55/80\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 0.0279 - val_loss: 0.0162\n",
      "Epoch 56/80\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 0.0279 - val_loss: 0.0186\n",
      "Epoch 57/80\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 0.0282 - val_loss: 0.0190\n",
      "Epoch 58/80\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 0.0280 - val_loss: 0.0189\n",
      "Epoch 59/80\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 0.0281 - val_loss: 0.0188\n",
      "Epoch 60/80\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 0.0280 - val_loss: 0.0188\n",
      "Epoch 61/80\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 0.0280 - val_loss: 0.0188\n",
      "Epoch 62/80\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 0.0280 - val_loss: 0.0188\n",
      "Epoch 63/80\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 0.0280 - val_loss: 0.0187\n",
      "Epoch 64/80\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 0.0280 - val_loss: 0.0187\n",
      "Epoch 65/80\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 0.0280 - val_loss: 0.0186\n",
      "Epoch 66/80\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 0.0280 - val_loss: 0.0186\n",
      "Epoch 67/80\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 0.0281 - val_loss: 0.0185\n",
      "Epoch 68/80\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 0.0281 - val_loss: 0.0187\n",
      "Epoch 69/80\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 0.0280 - val_loss: 0.0185\n",
      "Epoch 70/80\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 0.0281 - val_loss: 0.0186\n",
      "Epoch 71/80\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 0.0281 - val_loss: 0.0186\n",
      "Epoch 72/80\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 0.0281 - val_loss: 0.0187\n",
      "Epoch 73/80\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 0.0280 - val_loss: 0.0182\n",
      "Epoch 74/80\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 0.0282 - val_loss: 0.0187\n",
      "Epoch 75/80\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 0.0280 - val_loss: 0.0187\n",
      "Epoch 76/80\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 0.0280 - val_loss: 0.0183\n",
      "Epoch 77/80\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 0.0282 - val_loss: 0.0186\n",
      "Epoch 78/80\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 0.0281 - val_loss: 0.0186\n",
      "Epoch 79/80\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 0.0281 - val_loss: 0.0182\n",
      "Epoch 80/80\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 0.0282 - val_loss: 0.0188\n",
      "Execution time:  57.25297522544861\n",
      "DNN:\n",
      "Mean Absolute Error: 0.0257\n",
      "Root Mean Square Error: 0.0429\n",
      "Mean Square Error: 0.0018\n",
      "\n",
      "Train RMSE: 0.043\n",
      "Train MSE: 0.002\n",
      "Train MAE: 0.026\n",
      "###########################\n",
      "\n",
      "MODEL:  DNN\n",
      "sequence:  1d\n",
      "units:  80\n",
      "dropout1:  0.11814836227952394\n",
      "optimizer: adamax\n",
      "activationDense: tanh\n",
      "epochs: 90\n",
      "batchsize: 25\n",
      "validation_split: 0.2\n",
      "Model: \"sequential_172\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_516 (Dense)            (None, 144, 80)           160       \n",
      "_________________________________________________________________\n",
      "dense_517 (Dense)            (None, 144, 16)           1296      \n",
      "_________________________________________________________________\n",
      "dropout_172 (Dropout)        (None, 144, 16)           0         \n",
      "_________________________________________________________________\n",
      "dense_518 (Dense)            (None, 144, 1)            17        \n",
      "=================================================================\n",
      "Total params: 1,473\n",
      "Trainable params: 1,473\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/90\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "124/124 [==============================] - 1s 8ms/step - loss: 0.1098 - val_loss: 0.0359\n",
      "Epoch 2/90\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.0523 - val_loss: 0.0351\n",
      "Epoch 3/90\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.0505 - val_loss: 0.0387\n",
      "Epoch 4/90\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.0491 - val_loss: 0.0374\n",
      "Epoch 5/90\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.0479 - val_loss: 0.0354\n",
      "Epoch 6/90\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.0467 - val_loss: 0.0327\n",
      "Epoch 7/90\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.0454 - val_loss: 0.0321\n",
      "Epoch 8/90\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.0442 - val_loss: 0.0298\n",
      "Epoch 9/90\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.0430 - val_loss: 0.0298\n",
      "Epoch 10/90\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.0417 - val_loss: 0.0283\n",
      "Epoch 11/90\n",
      "124/124 [==============================] - 1s 5ms/step - loss: 0.0406 - val_loss: 0.0273\n",
      "Epoch 12/90\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.0399 - val_loss: 0.0269\n",
      "Epoch 13/90\n",
      "124/124 [==============================] - 1s 5ms/step - loss: 0.0390 - val_loss: 0.0254\n",
      "Epoch 14/90\n",
      "124/124 [==============================] - 1s 5ms/step - loss: 0.0381 - val_loss: 0.0243\n",
      "Epoch 15/90\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.0373 - val_loss: 0.0235\n",
      "Epoch 16/90\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.0368 - val_loss: 0.0218\n",
      "Epoch 17/90\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.0360 - val_loss: 0.0213\n",
      "Epoch 18/90\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.0354 - val_loss: 0.0201\n",
      "Epoch 19/90\n",
      "124/124 [==============================] - 1s 5ms/step - loss: 0.0350 - val_loss: 0.0197\n",
      "Epoch 20/90\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.0345 - val_loss: 0.0203\n",
      "Epoch 21/90\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.0343 - val_loss: 0.0194\n",
      "Epoch 22/90\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.0339 - val_loss: 0.0180\n",
      "Epoch 23/90\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.0333 - val_loss: 0.0177\n",
      "Epoch 24/90\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.0329 - val_loss: 0.0179\n",
      "Epoch 25/90\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.0327 - val_loss: 0.0174\n",
      "Epoch 26/90\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.0317 - val_loss: 0.0170\n",
      "Epoch 27/90\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.0315 - val_loss: 0.0170\n",
      "Epoch 28/90\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.0314 - val_loss: 0.0172\n",
      "Epoch 29/90\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.0312 - val_loss: 0.0170\n",
      "Epoch 30/90\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.0310 - val_loss: 0.0170\n",
      "Epoch 31/90\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.0307 - val_loss: 0.0169\n",
      "Epoch 32/90\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.0316 - val_loss: 0.0172\n",
      "Epoch 33/90\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.0312 - val_loss: 0.0171\n",
      "Epoch 34/90\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.0309 - val_loss: 0.0169\n",
      "Epoch 35/90\n",
      "124/124 [==============================] - 1s 5ms/step - loss: 0.0307 - val_loss: 0.0168\n",
      "Epoch 36/90\n",
      "124/124 [==============================] - 1s 5ms/step - loss: 0.0305 - val_loss: 0.0168\n",
      "Epoch 37/90\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.0304 - val_loss: 0.0169\n",
      "Epoch 38/90\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.0303 - val_loss: 0.0166\n",
      "Epoch 39/90\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.0302 - val_loss: 0.0166\n",
      "Epoch 40/90\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.0303 - val_loss: 0.0169\n",
      "Epoch 41/90\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.0303 - val_loss: 0.0168\n",
      "Epoch 42/90\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.0306 - val_loss: 0.0169\n",
      "Epoch 43/90\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.0302 - val_loss: 0.0169\n",
      "Epoch 44/90\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.0303 - val_loss: 0.0168\n",
      "Epoch 45/90\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.0303 - val_loss: 0.0170\n",
      "Epoch 46/90\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.0299 - val_loss: 0.0167\n",
      "Epoch 47/90\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.0300 - val_loss: 0.0167\n",
      "Epoch 48/90\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.0300 - val_loss: 0.0165\n",
      "Epoch 49/90\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.0299 - val_loss: 0.0165\n",
      "Epoch 50/90\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.0298 - val_loss: 0.0165\n",
      "Epoch 51/90\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.0298 - val_loss: 0.0165\n",
      "Epoch 52/90\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.0297 - val_loss: 0.0165\n",
      "Epoch 53/90\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.0297 - val_loss: 0.0165\n",
      "Epoch 54/90\n",
      "124/124 [==============================] - 1s 5ms/step - loss: 0.0296 - val_loss: 0.0165\n",
      "Epoch 55/90\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.0295 - val_loss: 0.0165\n",
      "Epoch 56/90\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.0294 - val_loss: 0.0164\n",
      "Epoch 57/90\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.0295 - val_loss: 0.0163\n",
      "Epoch 58/90\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.0293 - val_loss: 0.0163\n",
      "Epoch 59/90\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.0290 - val_loss: 0.0163\n",
      "Epoch 60/90\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.0290 - val_loss: 0.0169\n",
      "Epoch 61/90\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.0286 - val_loss: 0.0181\n",
      "Epoch 62/90\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.0286 - val_loss: 0.0164\n",
      "Epoch 63/90\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.0288 - val_loss: 0.0179\n",
      "Epoch 64/90\n",
      "124/124 [==============================] - 1s 5ms/step - loss: 0.0286 - val_loss: 0.0165\n",
      "Epoch 65/90\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.0288 - val_loss: 0.0179\n",
      "Epoch 66/90\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.0285 - val_loss: 0.0164\n",
      "Epoch 67/90\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.0288 - val_loss: 0.0179\n",
      "Epoch 68/90\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.0285 - val_loss: 0.0164\n",
      "Epoch 69/90\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.0287 - val_loss: 0.0178\n",
      "Epoch 70/90\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.0286 - val_loss: 0.0174\n",
      "Epoch 71/90\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.0286 - val_loss: 0.0181\n",
      "Epoch 72/90\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.0285 - val_loss: 0.0170\n",
      "Epoch 73/90\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.0286 - val_loss: 0.0178\n",
      "Epoch 74/90\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.0286 - val_loss: 0.0172\n",
      "Epoch 75/90\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.0287 - val_loss: 0.0177\n",
      "Epoch 76/90\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.0286 - val_loss: 0.0177\n",
      "Epoch 77/90\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.0286 - val_loss: 0.0180\n",
      "Epoch 78/90\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.0285 - val_loss: 0.0179\n",
      "Epoch 79/90\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.0285 - val_loss: 0.0176\n",
      "Epoch 80/90\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.0286 - val_loss: 0.0177\n",
      "Epoch 81/90\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.0286 - val_loss: 0.0177\n",
      "Epoch 82/90\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "124/124 [==============================] - 1s 6ms/step - loss: 0.0286 - val_loss: 0.0178\n",
      "Epoch 83/90\n",
      "124/124 [==============================] - 1s 5ms/step - loss: 0.0285 - val_loss: 0.0177\n",
      "Epoch 84/90\n",
      "124/124 [==============================] - 1s 5ms/step - loss: 0.0285 - val_loss: 0.0178\n",
      "Epoch 85/90\n",
      "124/124 [==============================] - 1s 5ms/step - loss: 0.0285 - val_loss: 0.0178\n",
      "Epoch 86/90\n",
      "124/124 [==============================] - 1s 5ms/step - loss: 0.0285 - val_loss: 0.0178\n",
      "Epoch 87/90\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.0285 - val_loss: 0.0178\n",
      "Epoch 88/90\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.0285 - val_loss: 0.0177\n",
      "Epoch 89/90\n",
      "124/124 [==============================] - 1s 5ms/step - loss: 0.0285 - val_loss: 0.0177\n",
      "Epoch 90/90\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.0285 - val_loss: 0.0177\n",
      "Execution time:  65.03902173042297\n",
      "DNN:\n",
      "Mean Absolute Error: 0.0259\n",
      "Root Mean Square Error: 0.0446\n",
      "Mean Square Error: 0.0020\n",
      "\n",
      "Train RMSE: 0.045\n",
      "Train MSE: 0.002\n",
      "Train MAE: 0.026\n",
      "###########################\n",
      "\n",
      "MODEL:  DNN\n",
      "sequence:  1d\n",
      "units:  12\n",
      "dropout1:  0.48476373451509647\n",
      "optimizer: adamax\n",
      "activationDense: tanh\n",
      "epochs: 52\n",
      "batchsize: 57\n",
      "validation_split: 0.2\n",
      "Model: \"sequential_173\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_519 (Dense)            (None, 144, 12)           24        \n",
      "_________________________________________________________________\n",
      "dense_520 (Dense)            (None, 144, 16)           208       \n",
      "_________________________________________________________________\n",
      "dropout_173 (Dropout)        (None, 144, 16)           0         \n",
      "_________________________________________________________________\n",
      "dense_521 (Dense)            (None, 144, 1)            17        \n",
      "=================================================================\n",
      "Total params: 249\n",
      "Trainable params: 249\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/52\n",
      "54/54 [==============================] - 0s 9ms/step - loss: 0.1762 - val_loss: 0.0299\n",
      "Epoch 2/52\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 0.1153 - val_loss: 0.0256\n",
      "Epoch 3/52\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 0.1065 - val_loss: 0.0297\n",
      "Epoch 4/52\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 0.1004 - val_loss: 0.0350\n",
      "Epoch 5/52\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 0.0958 - val_loss: 0.0326\n",
      "Epoch 6/52\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 0.0908 - val_loss: 0.0312\n",
      "Epoch 7/52\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 0.0862 - val_loss: 0.0284\n",
      "Epoch 8/52\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 0.0811 - val_loss: 0.0256\n",
      "Epoch 9/52\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 0.0759 - val_loss: 0.0221\n",
      "Epoch 10/52\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 0.0704 - val_loss: 0.0200\n",
      "Epoch 11/52\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 0.0656 - val_loss: 0.0181\n",
      "Epoch 12/52\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 0.0609 - val_loss: 0.0165\n",
      "Epoch 13/52\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 0.0565 - val_loss: 0.0160\n",
      "Epoch 14/52\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 0.0523 - val_loss: 0.0156\n",
      "Epoch 15/52\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 0.0484 - val_loss: 0.0155\n",
      "Epoch 16/52\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 0.0447 - val_loss: 0.0156\n",
      "Epoch 17/52\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 0.0415 - val_loss: 0.0160\n",
      "Epoch 18/52\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 0.0385 - val_loss: 0.0166\n",
      "Epoch 19/52\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 0.0357 - val_loss: 0.0160\n",
      "Epoch 20/52\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 0.0337 - val_loss: 0.0158\n",
      "Epoch 21/52\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 0.0324 - val_loss: 0.0160\n",
      "Epoch 22/52\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 0.0312 - val_loss: 0.0157\n",
      "Epoch 23/52\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 0.0304 - val_loss: 0.0155\n",
      "Epoch 24/52\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 0.0299 - val_loss: 0.0156\n",
      "Epoch 25/52\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 0.0295 - val_loss: 0.0158\n",
      "Epoch 26/52\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 0.0288 - val_loss: 0.0158\n",
      "Epoch 27/52\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 0.0283 - val_loss: 0.0159\n",
      "Epoch 28/52\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 0.0279 - val_loss: 0.0169\n",
      "Epoch 29/52\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 0.0275 - val_loss: 0.0181\n",
      "Epoch 30/52\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 0.0271 - val_loss: 0.0185\n",
      "Epoch 31/52\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 0.0270 - val_loss: 0.0188\n",
      "Epoch 32/52\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 0.0269 - val_loss: 0.0188\n",
      "Epoch 33/52\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 0.0270 - val_loss: 0.0192\n",
      "Epoch 34/52\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 0.0269 - val_loss: 0.0192\n",
      "Epoch 35/52\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 0.0270 - val_loss: 0.0193\n",
      "Epoch 36/52\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 0.0270 - val_loss: 0.0193\n",
      "Epoch 37/52\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 0.0269 - val_loss: 0.0194\n",
      "Epoch 38/52\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 0.0269 - val_loss: 0.0194\n",
      "Epoch 39/52\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 0.0269 - val_loss: 0.0194\n",
      "Epoch 40/52\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 0.0269 - val_loss: 0.0193\n",
      "Epoch 41/52\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 0.0269 - val_loss: 0.0193\n",
      "Epoch 42/52\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 0.0270 - val_loss: 0.0194\n",
      "Epoch 43/52\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 0.0269 - val_loss: 0.0194\n",
      "Epoch 44/52\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 0.0269 - val_loss: 0.0193\n",
      "Epoch 45/52\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 0.0269 - val_loss: 0.0194\n",
      "Epoch 46/52\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 0.0269 - val_loss: 0.0192\n",
      "Epoch 47/52\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 0.0270 - val_loss: 0.0193\n",
      "Epoch 48/52\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 0.0269 - val_loss: 0.0195\n",
      "Epoch 49/52\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 0.0268 - val_loss: 0.0192\n",
      "Epoch 50/52\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 0.0269 - val_loss: 0.0191\n",
      "Epoch 51/52\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 0.0270 - val_loss: 0.0193\n",
      "Epoch 52/52\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 0.0270 - val_loss: 0.0193\n",
      "Execution time:  17.174506664276123\n",
      "DNN:\n",
      "Mean Absolute Error: 0.0231\n",
      "Root Mean Square Error: 0.0375\n",
      "Mean Square Error: 0.0014\n",
      "\n",
      "Train RMSE: 0.038\n",
      "Train MSE: 0.001\n",
      "Train MAE: 0.023\n",
      "###########################\n",
      "\n",
      "MODEL:  DNN\n",
      "sequence:  1d\n",
      "units:  87\n",
      "dropout1:  0.40519643149940265\n",
      "optimizer: adamax\n",
      "activationDense: sigmoid\n",
      "epochs: 80\n",
      "batchsize: 31\n",
      "validation_split: 0.1\n",
      "Model: \"sequential_174\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_522 (Dense)            (None, 144, 87)           174       \n",
      "_________________________________________________________________\n",
      "dense_523 (Dense)            (None, 144, 16)           1408      \n",
      "_________________________________________________________________\n",
      "dropout_174 (Dropout)        (None, 144, 16)           0         \n",
      "_________________________________________________________________\n",
      "dense_524 (Dense)            (None, 144, 1)            17        \n",
      "=================================================================\n",
      "Total params: 1,599\n",
      "Trainable params: 1,599\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/80\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "112/112 [==============================] - 1s 8ms/step - loss: 0.0608 - val_loss: 0.0495\n",
      "Epoch 2/80\n",
      "112/112 [==============================] - 1s 6ms/step - loss: 0.0477 - val_loss: 0.0439\n",
      "Epoch 3/80\n",
      "112/112 [==============================] - 1s 6ms/step - loss: 0.0430 - val_loss: 0.0401\n",
      "Epoch 4/80\n",
      "112/112 [==============================] - 1s 6ms/step - loss: 0.0404 - val_loss: 0.0368\n",
      "Epoch 5/80\n",
      "112/112 [==============================] - 1s 6ms/step - loss: 0.0384 - val_loss: 0.0338\n",
      "Epoch 6/80\n",
      "112/112 [==============================] - 1s 6ms/step - loss: 0.0368 - val_loss: 0.0318\n",
      "Epoch 7/80\n",
      "112/112 [==============================] - 1s 6ms/step - loss: 0.0352 - val_loss: 0.0296\n",
      "Epoch 8/80\n",
      "112/112 [==============================] - 1s 6ms/step - loss: 0.0339 - val_loss: 0.0277\n",
      "Epoch 9/80\n",
      "112/112 [==============================] - 1s 6ms/step - loss: 0.0328 - val_loss: 0.0261\n",
      "Epoch 10/80\n",
      "112/112 [==============================] - 1s 6ms/step - loss: 0.0318 - val_loss: 0.0237\n",
      "Epoch 11/80\n",
      "112/112 [==============================] - 1s 6ms/step - loss: 0.0310 - val_loss: 0.0226\n",
      "Epoch 12/80\n",
      "112/112 [==============================] - 1s 6ms/step - loss: 0.0302 - val_loss: 0.0215\n",
      "Epoch 13/80\n",
      "112/112 [==============================] - 1s 6ms/step - loss: 0.0296 - val_loss: 0.0194\n",
      "Epoch 14/80\n",
      "112/112 [==============================] - 1s 6ms/step - loss: 0.0292 - val_loss: 0.0183\n",
      "Epoch 15/80\n",
      "112/112 [==============================] - 1s 6ms/step - loss: 0.0288 - val_loss: 0.0178\n",
      "Epoch 16/80\n",
      "112/112 [==============================] - 1s 6ms/step - loss: 0.0283 - val_loss: 0.0165\n",
      "Epoch 17/80\n",
      "112/112 [==============================] - 1s 6ms/step - loss: 0.0279 - val_loss: 0.0168\n",
      "Epoch 18/80\n",
      "112/112 [==============================] - 1s 6ms/step - loss: 0.0277 - val_loss: 0.0169\n",
      "Epoch 19/80\n",
      "112/112 [==============================] - 1s 7ms/step - loss: 0.0275 - val_loss: 0.0164\n",
      "Epoch 20/80\n",
      "112/112 [==============================] - 1s 7ms/step - loss: 0.0274 - val_loss: 0.0189\n",
      "Epoch 21/80\n",
      "112/112 [==============================] - 1s 7ms/step - loss: 0.0270 - val_loss: 0.0186\n",
      "Epoch 22/80\n",
      "112/112 [==============================] - 1s 7ms/step - loss: 0.0269 - val_loss: 0.0183\n",
      "Epoch 23/80\n",
      "112/112 [==============================] - 1s 6ms/step - loss: 0.0268 - val_loss: 0.0181\n",
      "Epoch 24/80\n",
      "112/112 [==============================] - 1s 6ms/step - loss: 0.0265 - val_loss: 0.0190\n",
      "Epoch 25/80\n",
      "112/112 [==============================] - 1s 6ms/step - loss: 0.0264 - val_loss: 0.0195\n",
      "Epoch 26/80\n",
      "112/112 [==============================] - 1s 6ms/step - loss: 0.0263 - val_loss: 0.0185\n",
      "Epoch 27/80\n",
      "112/112 [==============================] - 1s 6ms/step - loss: 0.0264 - val_loss: 0.0188\n",
      "Epoch 28/80\n",
      "112/112 [==============================] - 1s 6ms/step - loss: 0.0263 - val_loss: 0.0186\n",
      "Epoch 29/80\n",
      "112/112 [==============================] - 1s 6ms/step - loss: 0.0263 - val_loss: 0.0186\n",
      "Epoch 30/80\n",
      "112/112 [==============================] - 1s 6ms/step - loss: 0.0263 - val_loss: 0.0188\n",
      "Epoch 31/80\n",
      "112/112 [==============================] - 1s 6ms/step - loss: 0.0263 - val_loss: 0.0186\n",
      "Epoch 32/80\n",
      "112/112 [==============================] - 1s 6ms/step - loss: 0.0263 - val_loss: 0.0186\n",
      "Epoch 33/80\n",
      "112/112 [==============================] - 1s 6ms/step - loss: 0.0263 - val_loss: 0.0185\n",
      "Epoch 34/80\n",
      "112/112 [==============================] - 1s 7ms/step - loss: 0.0263 - val_loss: 0.0188\n",
      "Epoch 35/80\n",
      "112/112 [==============================] - 1s 7ms/step - loss: 0.0263 - val_loss: 0.0186\n",
      "Epoch 36/80\n",
      "112/112 [==============================] - 1s 6ms/step - loss: 0.0263 - val_loss: 0.0185\n",
      "Epoch 37/80\n",
      "112/112 [==============================] - 1s 7ms/step - loss: 0.0263 - val_loss: 0.0188\n",
      "Epoch 38/80\n",
      "112/112 [==============================] - 1s 6ms/step - loss: 0.0263 - val_loss: 0.0186\n",
      "Epoch 39/80\n",
      "112/112 [==============================] - 1s 6ms/step - loss: 0.0263 - val_loss: 0.0186\n",
      "Epoch 40/80\n",
      "112/112 [==============================] - 1s 7ms/step - loss: 0.0263 - val_loss: 0.0188\n",
      "Epoch 41/80\n",
      "112/112 [==============================] - 1s 7ms/step - loss: 0.0263 - val_loss: 0.0186\n",
      "Epoch 42/80\n",
      "112/112 [==============================] - 1s 7ms/step - loss: 0.0263 - val_loss: 0.0186\n",
      "Epoch 43/80\n",
      "112/112 [==============================] - 1s 7ms/step - loss: 0.0263 - val_loss: 0.0185\n",
      "Epoch 44/80\n",
      "112/112 [==============================] - 1s 6ms/step - loss: 0.0263 - val_loss: 0.0188\n",
      "Epoch 45/80\n",
      "112/112 [==============================] - 1s 6ms/step - loss: 0.0263 - val_loss: 0.0186\n",
      "Epoch 46/80\n",
      "112/112 [==============================] - 1s 6ms/step - loss: 0.0263 - val_loss: 0.0185\n",
      "Epoch 47/80\n",
      "112/112 [==============================] - 1s 6ms/step - loss: 0.0263 - val_loss: 0.0188\n",
      "Epoch 48/80\n",
      "112/112 [==============================] - 1s 6ms/step - loss: 0.0263 - val_loss: 0.0186\n",
      "Epoch 49/80\n",
      "112/112 [==============================] - 1s 6ms/step - loss: 0.0263 - val_loss: 0.0186\n",
      "Epoch 50/80\n",
      "112/112 [==============================] - 1s 6ms/step - loss: 0.0263 - val_loss: 0.0188\n",
      "Epoch 51/80\n",
      "112/112 [==============================] - 1s 6ms/step - loss: 0.0263 - val_loss: 0.0186\n",
      "Epoch 52/80\n",
      "112/112 [==============================] - 1s 6ms/step - loss: 0.0263 - val_loss: 0.0186\n",
      "Epoch 53/80\n",
      "112/112 [==============================] - 1s 6ms/step - loss: 0.0263 - val_loss: 0.0185\n",
      "Epoch 54/80\n",
      "112/112 [==============================] - 1s 6ms/step - loss: 0.0263 - val_loss: 0.0188\n",
      "Epoch 55/80\n",
      "112/112 [==============================] - 1s 6ms/step - loss: 0.0263 - val_loss: 0.0186\n",
      "Epoch 56/80\n",
      "112/112 [==============================] - 1s 6ms/step - loss: 0.0263 - val_loss: 0.0185\n",
      "Epoch 57/80\n",
      "112/112 [==============================] - 1s 6ms/step - loss: 0.0263 - val_loss: 0.0188\n",
      "Epoch 58/80\n",
      "112/112 [==============================] - 1s 6ms/step - loss: 0.0263 - val_loss: 0.0186\n",
      "Epoch 59/80\n",
      "112/112 [==============================] - 1s 6ms/step - loss: 0.0263 - val_loss: 0.0186\n",
      "Epoch 60/80\n",
      "112/112 [==============================] - 1s 6ms/step - loss: 0.0263 - val_loss: 0.0188\n",
      "Epoch 61/80\n",
      "112/112 [==============================] - 1s 6ms/step - loss: 0.0263 - val_loss: 0.0186\n",
      "Epoch 62/80\n",
      "112/112 [==============================] - 1s 7ms/step - loss: 0.0263 - val_loss: 0.0186\n",
      "Epoch 63/80\n",
      "112/112 [==============================] - 1s 7ms/step - loss: 0.0263 - val_loss: 0.0185\n",
      "Epoch 64/80\n",
      "112/112 [==============================] - 1s 7ms/step - loss: 0.0263 - val_loss: 0.0188\n",
      "Epoch 65/80\n",
      "112/112 [==============================] - 1s 6ms/step - loss: 0.0263 - val_loss: 0.0186\n",
      "Epoch 66/80\n",
      "112/112 [==============================] - 1s 6ms/step - loss: 0.0263 - val_loss: 0.0185\n",
      "Epoch 67/80\n",
      "112/112 [==============================] - 1s 6ms/step - loss: 0.0263 - val_loss: 0.0188\n",
      "Epoch 68/80\n",
      "112/112 [==============================] - 1s 6ms/step - loss: 0.0263 - val_loss: 0.0186\n",
      "Epoch 69/80\n",
      "112/112 [==============================] - 1s 6ms/step - loss: 0.0263 - val_loss: 0.0186\n",
      "Epoch 70/80\n",
      "112/112 [==============================] - 1s 7ms/step - loss: 0.0263 - val_loss: 0.0188\n",
      "Epoch 71/80\n",
      "112/112 [==============================] - 1s 6ms/step - loss: 0.0263 - val_loss: 0.0186\n",
      "Epoch 72/80\n",
      "112/112 [==============================] - 1s 6ms/step - loss: 0.0263 - val_loss: 0.0186\n",
      "Epoch 73/80\n",
      "112/112 [==============================] - 1s 6ms/step - loss: 0.0263 - val_loss: 0.0185\n",
      "Epoch 74/80\n",
      "112/112 [==============================] - 1s 6ms/step - loss: 0.0264 - val_loss: 0.0188\n",
      "Epoch 75/80\n",
      "112/112 [==============================] - 1s 6ms/step - loss: 0.0263 - val_loss: 0.0186\n",
      "Epoch 76/80\n",
      "112/112 [==============================] - 1s 6ms/step - loss: 0.0263 - val_loss: 0.0186\n",
      "Epoch 77/80\n",
      "112/112 [==============================] - 1s 7ms/step - loss: 0.0263 - val_loss: 0.0188\n",
      "Epoch 78/80\n",
      "112/112 [==============================] - 1s 6ms/step - loss: 0.0263 - val_loss: 0.0186\n",
      "Epoch 79/80\n",
      "112/112 [==============================] - 1s 6ms/step - loss: 0.0263 - val_loss: 0.0186\n",
      "Epoch 80/80\n",
      "112/112 [==============================] - 1s 6ms/step - loss: 0.0263 - val_loss: 0.0185\n",
      "Execution time:  60.222731590270996\n",
      "DNN:\n",
      "Mean Absolute Error: 0.0260\n",
      "Root Mean Square Error: 0.0435\n",
      "Mean Square Error: 0.0019\n",
      "\n",
      "Train RMSE: 0.043\n",
      "Train MSE: 0.002\n",
      "Train MAE: 0.026\n",
      "###########################\n",
      "\n",
      "MODEL:  DNN\n",
      "sequence:  1d\n",
      "units:  80\n",
      "dropout1:  0.11814836227952394\n",
      "optimizer: adamax\n",
      "activationDense: sigmoid\n",
      "epochs: 90\n",
      "batchsize: 25\n",
      "validation_split: 0.1\n",
      "Model: \"sequential_175\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_525 (Dense)            (None, 144, 80)           160       \n",
      "_________________________________________________________________\n",
      "dense_526 (Dense)            (None, 144, 16)           1296      \n",
      "_________________________________________________________________\n",
      "dropout_175 (Dropout)        (None, 144, 16)           0         \n",
      "_________________________________________________________________\n",
      "dense_527 (Dense)            (None, 144, 1)            17        \n",
      "=================================================================\n",
      "Total params: 1,473\n",
      "Trainable params: 1,473\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/90\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "139/139 [==============================] - 1s 6ms/step - loss: 0.0475 - val_loss: 0.0222\n",
      "Epoch 2/90\n",
      "139/139 [==============================] - 1s 6ms/step - loss: 0.0339 - val_loss: 0.0206\n",
      "Epoch 3/90\n",
      "139/139 [==============================] - 1s 6ms/step - loss: 0.0337 - val_loss: 0.0203\n",
      "Epoch 4/90\n",
      "139/139 [==============================] - 1s 5ms/step - loss: 0.0333 - val_loss: 0.0202\n",
      "Epoch 5/90\n",
      "139/139 [==============================] - 1s 5ms/step - loss: 0.0330 - val_loss: 0.0199\n",
      "Epoch 6/90\n",
      "139/139 [==============================] - 1s 5ms/step - loss: 0.0327 - val_loss: 0.0195\n",
      "Epoch 7/90\n",
      "139/139 [==============================] - 1s 5ms/step - loss: 0.0324 - val_loss: 0.0191\n",
      "Epoch 8/90\n",
      "139/139 [==============================] - 1s 5ms/step - loss: 0.0320 - val_loss: 0.0193\n",
      "Epoch 9/90\n",
      "139/139 [==============================] - 1s 5ms/step - loss: 0.0317 - val_loss: 0.0192\n",
      "Epoch 10/90\n",
      "139/139 [==============================] - 1s 5ms/step - loss: 0.0315 - val_loss: 0.0193\n",
      "Epoch 11/90\n",
      "139/139 [==============================] - 1s 5ms/step - loss: 0.0313 - val_loss: 0.0178\n",
      "Epoch 12/90\n",
      "139/139 [==============================] - 1s 5ms/step - loss: 0.0311 - val_loss: 0.0176\n",
      "Epoch 13/90\n",
      "139/139 [==============================] - 1s 5ms/step - loss: 0.0307 - val_loss: 0.0179\n",
      "Epoch 14/90\n",
      "139/139 [==============================] - 1s 5ms/step - loss: 0.0305 - val_loss: 0.0176\n",
      "Epoch 15/90\n",
      "139/139 [==============================] - 1s 5ms/step - loss: 0.0304 - val_loss: 0.0175\n",
      "Epoch 16/90\n",
      "139/139 [==============================] - 1s 6ms/step - loss: 0.0302 - val_loss: 0.0175\n",
      "Epoch 17/90\n",
      "139/139 [==============================] - 1s 5ms/step - loss: 0.0300 - val_loss: 0.0176\n",
      "Epoch 18/90\n",
      "139/139 [==============================] - 1s 5ms/step - loss: 0.0297 - val_loss: 0.0174\n",
      "Epoch 19/90\n",
      "139/139 [==============================] - 1s 5ms/step - loss: 0.0297 - val_loss: 0.0162\n",
      "Epoch 20/90\n",
      "139/139 [==============================] - 1s 5ms/step - loss: 0.0296 - val_loss: 0.0168\n",
      "Epoch 21/90\n",
      "139/139 [==============================] - 1s 5ms/step - loss: 0.0298 - val_loss: 0.0170\n",
      "Epoch 22/90\n",
      "139/139 [==============================] - 1s 5ms/step - loss: 0.0292 - val_loss: 0.0161\n",
      "Epoch 23/90\n",
      "139/139 [==============================] - 1s 6ms/step - loss: 0.0291 - val_loss: 0.0161\n",
      "Epoch 24/90\n",
      "139/139 [==============================] - 1s 6ms/step - loss: 0.0290 - val_loss: 0.0150\n",
      "Epoch 25/90\n",
      "139/139 [==============================] - 1s 6ms/step - loss: 0.0290 - val_loss: 0.0149\n",
      "Epoch 26/90\n",
      "139/139 [==============================] - 1s 5ms/step - loss: 0.0288 - val_loss: 0.0153\n",
      "Epoch 27/90\n",
      "139/139 [==============================] - 1s 5ms/step - loss: 0.0287 - val_loss: 0.0153\n",
      "Epoch 28/90\n",
      "139/139 [==============================] - 1s 5ms/step - loss: 0.0286 - val_loss: 0.0152\n",
      "Epoch 29/90\n",
      "139/139 [==============================] - 1s 5ms/step - loss: 0.0285 - val_loss: 0.0142\n",
      "Epoch 30/90\n",
      "139/139 [==============================] - 1s 5ms/step - loss: 0.0284 - val_loss: 0.0141\n",
      "Epoch 31/90\n",
      "139/139 [==============================] - 1s 5ms/step - loss: 0.0283 - val_loss: 0.0142\n",
      "Epoch 32/90\n",
      "139/139 [==============================] - 1s 5ms/step - loss: 0.0282 - val_loss: 0.0138\n",
      "Epoch 33/90\n",
      "139/139 [==============================] - 1s 5ms/step - loss: 0.0282 - val_loss: 0.0144\n",
      "Epoch 34/90\n",
      "139/139 [==============================] - 1s 5ms/step - loss: 0.0283 - val_loss: 0.0136\n",
      "Epoch 35/90\n",
      "139/139 [==============================] - 1s 5ms/step - loss: 0.0279 - val_loss: 0.0140\n",
      "Epoch 36/90\n",
      "139/139 [==============================] - 1s 5ms/step - loss: 0.0278 - val_loss: 0.0138\n",
      "Epoch 37/90\n",
      "139/139 [==============================] - 1s 5ms/step - loss: 0.0277 - val_loss: 0.0142\n",
      "Epoch 38/90\n",
      "139/139 [==============================] - 1s 5ms/step - loss: 0.0277 - val_loss: 0.0142\n",
      "Epoch 39/90\n",
      "139/139 [==============================] - 1s 5ms/step - loss: 0.0276 - val_loss: 0.0142\n",
      "Epoch 40/90\n",
      "139/139 [==============================] - 1s 5ms/step - loss: 0.0276 - val_loss: 0.0138\n",
      "Epoch 41/90\n",
      "139/139 [==============================] - 1s 5ms/step - loss: 0.0278 - val_loss: 0.0132\n",
      "Epoch 42/90\n",
      "139/139 [==============================] - 1s 5ms/step - loss: 0.0275 - val_loss: 0.0129\n",
      "Epoch 43/90\n",
      "139/139 [==============================] - 1s 5ms/step - loss: 0.0273 - val_loss: 0.0134\n",
      "Epoch 44/90\n",
      "139/139 [==============================] - 1s 5ms/step - loss: 0.0273 - val_loss: 0.0135\n",
      "Epoch 45/90\n",
      "139/139 [==============================] - 1s 6ms/step - loss: 0.0272 - val_loss: 0.0135\n",
      "Epoch 46/90\n",
      "139/139 [==============================] - 1s 6ms/step - loss: 0.0272 - val_loss: 0.0135\n",
      "Epoch 47/90\n",
      "139/139 [==============================] - 1s 5ms/step - loss: 0.0271 - val_loss: 0.0134\n",
      "Epoch 48/90\n",
      "139/139 [==============================] - 1s 5ms/step - loss: 0.0271 - val_loss: 0.0133\n",
      "Epoch 49/90\n",
      "139/139 [==============================] - 1s 5ms/step - loss: 0.0271 - val_loss: 0.0132\n",
      "Epoch 50/90\n",
      "139/139 [==============================] - 1s 5ms/step - loss: 0.0270 - val_loss: 0.0132\n",
      "Epoch 51/90\n",
      "139/139 [==============================] - 1s 5ms/step - loss: 0.0270 - val_loss: 0.0132\n",
      "Epoch 52/90\n",
      "139/139 [==============================] - 1s 5ms/step - loss: 0.0270 - val_loss: 0.0130\n",
      "Epoch 53/90\n",
      "139/139 [==============================] - 1s 5ms/step - loss: 0.0269 - val_loss: 0.0129\n",
      "Epoch 54/90\n",
      "139/139 [==============================] - 1s 5ms/step - loss: 0.0269 - val_loss: 0.0130\n",
      "Epoch 55/90\n",
      "139/139 [==============================] - 1s 5ms/step - loss: 0.0269 - val_loss: 0.0129\n",
      "Epoch 56/90\n",
      "139/139 [==============================] - 1s 5ms/step - loss: 0.0269 - val_loss: 0.0128\n",
      "Epoch 57/90\n",
      "139/139 [==============================] - 1s 5ms/step - loss: 0.0269 - val_loss: 0.0128\n",
      "Epoch 58/90\n",
      "139/139 [==============================] - 1s 5ms/step - loss: 0.0268 - val_loss: 0.0128\n",
      "Epoch 59/90\n",
      "139/139 [==============================] - 1s 5ms/step - loss: 0.0268 - val_loss: 0.0127\n",
      "Epoch 60/90\n",
      "139/139 [==============================] - 1s 5ms/step - loss: 0.0268 - val_loss: 0.0127\n",
      "Epoch 61/90\n",
      "139/139 [==============================] - 1s 5ms/step - loss: 0.0268 - val_loss: 0.0127\n",
      "Epoch 62/90\n",
      "139/139 [==============================] - 1s 5ms/step - loss: 0.0268 - val_loss: 0.0126\n",
      "Epoch 63/90\n",
      "139/139 [==============================] - 1s 5ms/step - loss: 0.0268 - val_loss: 0.0127\n",
      "Epoch 64/90\n",
      "139/139 [==============================] - 1s 5ms/step - loss: 0.0267 - val_loss: 0.0126\n",
      "Epoch 65/90\n",
      "139/139 [==============================] - 1s 5ms/step - loss: 0.0267 - val_loss: 0.0125\n",
      "Epoch 66/90\n",
      "139/139 [==============================] - 1s 6ms/step - loss: 0.0267 - val_loss: 0.0126\n",
      "Epoch 67/90\n",
      "139/139 [==============================] - 1s 6ms/step - loss: 0.0267 - val_loss: 0.0125\n",
      "Epoch 68/90\n",
      "139/139 [==============================] - 1s 6ms/step - loss: 0.0267 - val_loss: 0.0126\n",
      "Epoch 69/90\n",
      "139/139 [==============================] - 1s 5ms/step - loss: 0.0267 - val_loss: 0.0125\n",
      "Epoch 70/90\n",
      "139/139 [==============================] - 1s 5ms/step - loss: 0.0267 - val_loss: 0.0127\n",
      "Epoch 71/90\n",
      "139/139 [==============================] - 1s 5ms/step - loss: 0.0266 - val_loss: 0.0127\n",
      "Epoch 72/90\n",
      "139/139 [==============================] - 1s 5ms/step - loss: 0.0266 - val_loss: 0.0126\n",
      "Epoch 73/90\n",
      "139/139 [==============================] - 1s 5ms/step - loss: 0.0266 - val_loss: 0.0126\n",
      "Epoch 74/90\n",
      "139/139 [==============================] - 1s 5ms/step - loss: 0.0266 - val_loss: 0.0126\n",
      "Epoch 75/90\n",
      "139/139 [==============================] - 1s 5ms/step - loss: 0.0266 - val_loss: 0.0126\n",
      "Epoch 76/90\n",
      "139/139 [==============================] - 1s 5ms/step - loss: 0.0265 - val_loss: 0.0126\n",
      "Epoch 77/90\n",
      "139/139 [==============================] - 1s 5ms/step - loss: 0.0266 - val_loss: 0.0127\n",
      "Epoch 78/90\n",
      "139/139 [==============================] - 1s 5ms/step - loss: 0.0265 - val_loss: 0.0126\n",
      "Epoch 79/90\n",
      "139/139 [==============================] - 1s 5ms/step - loss: 0.0265 - val_loss: 0.0123\n",
      "Epoch 80/90\n",
      "139/139 [==============================] - 1s 5ms/step - loss: 0.0265 - val_loss: 0.0123\n",
      "Epoch 81/90\n",
      "139/139 [==============================] - 1s 5ms/step - loss: 0.0265 - val_loss: 0.0123\n",
      "Epoch 82/90\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "139/139 [==============================] - 1s 5ms/step - loss: 0.0264 - val_loss: 0.0122\n",
      "Epoch 83/90\n",
      "139/139 [==============================] - 1s 5ms/step - loss: 0.0265 - val_loss: 0.0123\n",
      "Epoch 84/90\n",
      "139/139 [==============================] - 1s 5ms/step - loss: 0.0264 - val_loss: 0.0122\n",
      "Epoch 85/90\n",
      "139/139 [==============================] - 1s 5ms/step - loss: 0.0264 - val_loss: 0.0122\n",
      "Epoch 86/90\n",
      "139/139 [==============================] - 1s 5ms/step - loss: 0.0264 - val_loss: 0.0121\n",
      "Epoch 87/90\n",
      "139/139 [==============================] - 1s 5ms/step - loss: 0.0264 - val_loss: 0.0121\n",
      "Epoch 88/90\n",
      "139/139 [==============================] - 1s 6ms/step - loss: 0.0264 - val_loss: 0.0120\n",
      "Epoch 89/90\n",
      "139/139 [==============================] - 1s 5ms/step - loss: 0.0263 - val_loss: 0.0119\n",
      "Epoch 90/90\n",
      "139/139 [==============================] - 1s 5ms/step - loss: 0.0263 - val_loss: 0.0119\n",
      "Execution time:  68.08814096450806\n",
      "DNN:\n",
      "Mean Absolute Error: 0.0246\n",
      "Root Mean Square Error: 0.0427\n",
      "Mean Square Error: 0.0018\n",
      "\n",
      "Train RMSE: 0.043\n",
      "Train MSE: 0.002\n",
      "Train MAE: 0.025\n",
      "###########################\n",
      "\n",
      "MODEL:  DNN\n",
      "sequence:  1d\n",
      "units:  12\n",
      "dropout1:  0.48476373451509647\n",
      "optimizer: adamax\n",
      "activationDense: sigmoid\n",
      "epochs: 52\n",
      "batchsize: 57\n",
      "validation_split: 0.1\n",
      "Model: \"sequential_176\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_528 (Dense)            (None, 144, 12)           24        \n",
      "_________________________________________________________________\n",
      "dense_529 (Dense)            (None, 144, 16)           208       \n",
      "_________________________________________________________________\n",
      "dropout_176 (Dropout)        (None, 144, 16)           0         \n",
      "_________________________________________________________________\n",
      "dense_530 (Dense)            (None, 144, 1)            17        \n",
      "=================================================================\n",
      "Total params: 249\n",
      "Trainable params: 249\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/52\n",
      "61/61 [==============================] - 0s 8ms/step - loss: 0.0631 - val_loss: 0.0585\n",
      "Epoch 2/52\n",
      "61/61 [==============================] - 0s 5ms/step - loss: 0.0455 - val_loss: 0.0478\n",
      "Epoch 3/52\n",
      "61/61 [==============================] - 0s 5ms/step - loss: 0.0432 - val_loss: 0.0440\n",
      "Epoch 4/52\n",
      "61/61 [==============================] - 0s 5ms/step - loss: 0.0412 - val_loss: 0.0414\n",
      "Epoch 5/52\n",
      "61/61 [==============================] - 0s 5ms/step - loss: 0.0396 - val_loss: 0.0392\n",
      "Epoch 6/52\n",
      "61/61 [==============================] - 0s 5ms/step - loss: 0.0384 - val_loss: 0.0375\n",
      "Epoch 7/52\n",
      "61/61 [==============================] - 0s 5ms/step - loss: 0.0374 - val_loss: 0.0362\n",
      "Epoch 8/52\n",
      "61/61 [==============================] - 0s 5ms/step - loss: 0.0365 - val_loss: 0.0356\n",
      "Epoch 9/52\n",
      "61/61 [==============================] - 0s 5ms/step - loss: 0.0358 - val_loss: 0.0345\n",
      "Epoch 10/52\n",
      "61/61 [==============================] - 0s 5ms/step - loss: 0.0352 - val_loss: 0.0338\n",
      "Epoch 11/52\n",
      "61/61 [==============================] - 0s 5ms/step - loss: 0.0346 - val_loss: 0.0330\n",
      "Epoch 12/52\n",
      "61/61 [==============================] - 0s 5ms/step - loss: 0.0340 - val_loss: 0.0323\n",
      "Epoch 13/52\n",
      "61/61 [==============================] - 0s 5ms/step - loss: 0.0335 - val_loss: 0.0315\n",
      "Epoch 14/52\n",
      "61/61 [==============================] - 0s 5ms/step - loss: 0.0331 - val_loss: 0.0306\n",
      "Epoch 15/52\n",
      "61/61 [==============================] - 0s 5ms/step - loss: 0.0327 - val_loss: 0.0299\n",
      "Epoch 16/52\n",
      "61/61 [==============================] - 0s 5ms/step - loss: 0.0323 - val_loss: 0.0292\n",
      "Epoch 17/52\n",
      "61/61 [==============================] - 0s 5ms/step - loss: 0.0320 - val_loss: 0.0287\n",
      "Epoch 18/52\n",
      "61/61 [==============================] - 0s 5ms/step - loss: 0.0317 - val_loss: 0.0281\n",
      "Epoch 19/52\n",
      "61/61 [==============================] - 0s 5ms/step - loss: 0.0314 - val_loss: 0.0276\n",
      "Epoch 20/52\n",
      "61/61 [==============================] - 0s 5ms/step - loss: 0.0312 - val_loss: 0.0271\n",
      "Epoch 21/52\n",
      "61/61 [==============================] - 0s 5ms/step - loss: 0.0309 - val_loss: 0.0267\n",
      "Epoch 22/52\n",
      "61/61 [==============================] - 0s 5ms/step - loss: 0.0306 - val_loss: 0.0264\n",
      "Epoch 23/52\n",
      "61/61 [==============================] - 0s 5ms/step - loss: 0.0304 - val_loss: 0.0259\n",
      "Epoch 24/52\n",
      "61/61 [==============================] - 0s 5ms/step - loss: 0.0302 - val_loss: 0.0256\n",
      "Epoch 25/52\n",
      "61/61 [==============================] - 0s 5ms/step - loss: 0.0300 - val_loss: 0.0251\n",
      "Epoch 26/52\n",
      "61/61 [==============================] - 0s 5ms/step - loss: 0.0297 - val_loss: 0.0247\n",
      "Epoch 27/52\n",
      "61/61 [==============================] - 0s 5ms/step - loss: 0.0295 - val_loss: 0.0244\n",
      "Epoch 28/52\n",
      "61/61 [==============================] - 0s 5ms/step - loss: 0.0294 - val_loss: 0.0241\n",
      "Epoch 29/52\n",
      "61/61 [==============================] - 0s 5ms/step - loss: 0.0292 - val_loss: 0.0238\n",
      "Epoch 30/52\n",
      "61/61 [==============================] - 0s 5ms/step - loss: 0.0290 - val_loss: 0.0232\n",
      "Epoch 31/52\n",
      "61/61 [==============================] - 0s 5ms/step - loss: 0.0287 - val_loss: 0.0224\n",
      "Epoch 32/52\n",
      "61/61 [==============================] - 0s 5ms/step - loss: 0.0285 - val_loss: 0.0222\n",
      "Epoch 33/52\n",
      "61/61 [==============================] - 0s 5ms/step - loss: 0.0284 - val_loss: 0.0219\n",
      "Epoch 34/52\n",
      "61/61 [==============================] - 0s 5ms/step - loss: 0.0283 - val_loss: 0.0217\n",
      "Epoch 35/52\n",
      "61/61 [==============================] - 0s 5ms/step - loss: 0.0282 - val_loss: 0.0215\n",
      "Epoch 36/52\n",
      "61/61 [==============================] - 0s 5ms/step - loss: 0.0280 - val_loss: 0.0213\n",
      "Epoch 37/52\n",
      "61/61 [==============================] - 0s 6ms/step - loss: 0.0280 - val_loss: 0.0212\n",
      "Epoch 38/52\n",
      "61/61 [==============================] - 0s 6ms/step - loss: 0.0279 - val_loss: 0.0210\n",
      "Epoch 39/52\n",
      "61/61 [==============================] - 0s 6ms/step - loss: 0.0278 - val_loss: 0.0209\n",
      "Epoch 40/52\n",
      "61/61 [==============================] - 0s 6ms/step - loss: 0.0277 - val_loss: 0.0206\n",
      "Epoch 41/52\n",
      "61/61 [==============================] - 0s 6ms/step - loss: 0.0276 - val_loss: 0.0204\n",
      "Epoch 42/52\n",
      "61/61 [==============================] - 0s 6ms/step - loss: 0.0275 - val_loss: 0.0202\n",
      "Epoch 43/52\n",
      "61/61 [==============================] - 0s 5ms/step - loss: 0.0274 - val_loss: 0.0201\n",
      "Epoch 44/52\n",
      "61/61 [==============================] - 0s 5ms/step - loss: 0.0274 - val_loss: 0.0200\n",
      "Epoch 45/52\n",
      "61/61 [==============================] - 0s 5ms/step - loss: 0.0273 - val_loss: 0.0198\n",
      "Epoch 46/52\n",
      "61/61 [==============================] - 0s 5ms/step - loss: 0.0273 - val_loss: 0.0197\n",
      "Epoch 47/52\n",
      "61/61 [==============================] - 0s 5ms/step - loss: 0.0272 - val_loss: 0.0196\n",
      "Epoch 48/52\n",
      "61/61 [==============================] - 0s 5ms/step - loss: 0.0272 - val_loss: 0.0196\n",
      "Epoch 49/52\n",
      "61/61 [==============================] - 0s 6ms/step - loss: 0.0271 - val_loss: 0.0195\n",
      "Epoch 50/52\n",
      "61/61 [==============================] - 0s 5ms/step - loss: 0.0271 - val_loss: 0.0194\n",
      "Epoch 51/52\n",
      "61/61 [==============================] - 0s 5ms/step - loss: 0.0270 - val_loss: 0.0193\n",
      "Epoch 52/52\n",
      "61/61 [==============================] - 0s 5ms/step - loss: 0.0270 - val_loss: 0.0192\n",
      "Execution time:  18.359009265899658\n",
      "DNN:\n",
      "Mean Absolute Error: 0.0259\n",
      "Root Mean Square Error: 0.0430\n",
      "Mean Square Error: 0.0018\n",
      "\n",
      "Train RMSE: 0.043\n",
      "Train MSE: 0.002\n",
      "Train MAE: 0.026\n",
      "###########################\n",
      "\n",
      "MODEL:  DNN\n",
      "sequence:  1d\n",
      "units:  87\n",
      "dropout1:  0.40519643149940265\n",
      "optimizer: adamax\n",
      "activationDense: sigmoid\n",
      "epochs: 80\n",
      "batchsize: 31\n",
      "validation_split: 0.2\n",
      "Model: \"sequential_177\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_531 (Dense)            (None, 144, 87)           174       \n",
      "_________________________________________________________________\n",
      "dense_532 (Dense)            (None, 144, 16)           1408      \n",
      "_________________________________________________________________\n",
      "dropout_177 (Dropout)        (None, 144, 16)           0         \n",
      "_________________________________________________________________\n",
      "dense_533 (Dense)            (None, 144, 1)            17        \n",
      "=================================================================\n",
      "Total params: 1,599\n",
      "Trainable params: 1,599\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/80\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100/100 [==============================] - 1s 8ms/step - loss: 0.0473 - val_loss: 0.0298\n",
      "Epoch 2/80\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 0.0429 - val_loss: 0.0270\n",
      "Epoch 3/80\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 0.0418 - val_loss: 0.0260\n",
      "Epoch 4/80\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 0.0407 - val_loss: 0.0252\n",
      "Epoch 5/80\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 0.0398 - val_loss: 0.0244\n",
      "Epoch 6/80\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 0.0389 - val_loss: 0.0236\n",
      "Epoch 7/80\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 0.0381 - val_loss: 0.0230\n",
      "Epoch 8/80\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 0.0374 - val_loss: 0.0222\n",
      "Epoch 9/80\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 0.0368 - val_loss: 0.0219\n",
      "Epoch 10/80\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 0.0361 - val_loss: 0.0214\n",
      "Epoch 11/80\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 0.0355 - val_loss: 0.0211\n",
      "Epoch 12/80\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 0.0349 - val_loss: 0.0209\n",
      "Epoch 13/80\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 0.0341 - val_loss: 0.0203\n",
      "Epoch 14/80\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 0.0338 - val_loss: 0.0201\n",
      "Epoch 15/80\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 0.0333 - val_loss: 0.0200\n",
      "Epoch 16/80\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 0.0328 - val_loss: 0.0197\n",
      "Epoch 17/80\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 0.0324 - val_loss: 0.0197\n",
      "Epoch 18/80\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 0.0320 - val_loss: 0.0195\n",
      "Epoch 19/80\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 0.0314 - val_loss: 0.0194\n",
      "Epoch 20/80\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 0.0311 - val_loss: 0.0192\n",
      "Epoch 21/80\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 0.0307 - val_loss: 0.0191\n",
      "Epoch 22/80\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 0.0304 - val_loss: 0.0190\n",
      "Epoch 23/80\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 0.0301 - val_loss: 0.0188\n",
      "Epoch 24/80\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 0.0299 - val_loss: 0.0187\n",
      "Epoch 25/80\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 0.0296 - val_loss: 0.0187\n",
      "Epoch 26/80\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 0.0294 - val_loss: 0.0188\n",
      "Epoch 27/80\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 0.0292 - val_loss: 0.0186\n",
      "Epoch 28/80\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 0.0290 - val_loss: 0.0186\n",
      "Epoch 29/80\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 0.0288 - val_loss: 0.0185\n",
      "Epoch 30/80\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 0.0287 - val_loss: 0.0184\n",
      "Epoch 31/80\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 0.0285 - val_loss: 0.0183\n",
      "Epoch 32/80\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 0.0284 - val_loss: 0.0183\n",
      "Epoch 33/80\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 0.0283 - val_loss: 0.0184\n",
      "Epoch 34/80\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 0.0281 - val_loss: 0.0182\n",
      "Epoch 35/80\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 0.0279 - val_loss: 0.0182\n",
      "Epoch 36/80\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 0.0278 - val_loss: 0.0181\n",
      "Epoch 37/80\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 0.0278 - val_loss: 0.0181\n",
      "Epoch 38/80\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 0.0276 - val_loss: 0.0179\n",
      "Epoch 39/80\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 0.0276 - val_loss: 0.0179\n",
      "Epoch 40/80\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 0.0276 - val_loss: 0.0179\n",
      "Epoch 41/80\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 0.0273 - val_loss: 0.0176\n",
      "Epoch 42/80\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 0.0274 - val_loss: 0.0177\n",
      "Epoch 43/80\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 0.0274 - val_loss: 0.0178\n",
      "Epoch 44/80\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 0.0273 - val_loss: 0.0176\n",
      "Epoch 45/80\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 0.0274 - val_loss: 0.0174\n",
      "Epoch 46/80\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 0.0272 - val_loss: 0.0175\n",
      "Epoch 47/80\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 0.0272 - val_loss: 0.0175\n",
      "Epoch 48/80\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 0.0272 - val_loss: 0.0175\n",
      "Epoch 49/80\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 0.0272 - val_loss: 0.0175\n",
      "Epoch 50/80\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 0.0272 - val_loss: 0.0175\n",
      "Epoch 51/80\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 0.0271 - val_loss: 0.0174\n",
      "Epoch 52/80\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 0.0271 - val_loss: 0.0175\n",
      "Epoch 53/80\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 0.0271 - val_loss: 0.0175\n",
      "Epoch 54/80\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 0.0271 - val_loss: 0.0174\n",
      "Epoch 55/80\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 0.0270 - val_loss: 0.0173\n",
      "Epoch 56/80\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 0.0270 - val_loss: 0.0173\n",
      "Epoch 57/80\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 0.0270 - val_loss: 0.0174\n",
      "Epoch 58/80\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 0.0271 - val_loss: 0.0176\n",
      "Epoch 59/80\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 0.0269 - val_loss: 0.0173\n",
      "Epoch 60/80\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 0.0269 - val_loss: 0.0173\n",
      "Epoch 61/80\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 0.0269 - val_loss: 0.0173\n",
      "Epoch 62/80\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 0.0269 - val_loss: 0.0173\n",
      "Epoch 63/80\n",
      "100/100 [==============================] - 1s 8ms/step - loss: 0.0269 - val_loss: 0.0173\n",
      "Epoch 64/80\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 0.0268 - val_loss: 0.0172\n",
      "Epoch 65/80\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 0.0268 - val_loss: 0.0171\n",
      "Epoch 66/80\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 0.0268 - val_loss: 0.0171\n",
      "Epoch 67/80\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 0.0267 - val_loss: 0.0170\n",
      "Epoch 68/80\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 0.0268 - val_loss: 0.0170\n",
      "Epoch 69/80\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 0.0268 - val_loss: 0.0170\n",
      "Epoch 70/80\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 0.0267 - val_loss: 0.0171\n",
      "Epoch 71/80\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 0.0267 - val_loss: 0.0172\n",
      "Epoch 72/80\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 0.0267 - val_loss: 0.0172\n",
      "Epoch 73/80\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 0.0266 - val_loss: 0.0171\n",
      "Epoch 74/80\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 0.0267 - val_loss: 0.0171\n",
      "Epoch 75/80\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 0.0267 - val_loss: 0.0170\n",
      "Epoch 76/80\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 0.0266 - val_loss: 0.0170\n",
      "Epoch 77/80\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 0.0266 - val_loss: 0.0171\n",
      "Epoch 78/80\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 0.0266 - val_loss: 0.0172\n",
      "Epoch 79/80\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 0.0266 - val_loss: 0.0172\n",
      "Epoch 80/80\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 0.0265 - val_loss: 0.0172\n",
      "Execution time:  56.93525433540344\n",
      "DNN:\n",
      "Mean Absolute Error: 0.0233\n",
      "Root Mean Square Error: 0.0407\n",
      "Mean Square Error: 0.0017\n",
      "\n",
      "Train RMSE: 0.041\n",
      "Train MSE: 0.002\n",
      "Train MAE: 0.023\n",
      "###########################\n",
      "\n",
      "MODEL:  DNN\n",
      "sequence:  1d\n",
      "units:  80\n",
      "dropout1:  0.11814836227952394\n",
      "optimizer: adamax\n",
      "activationDense: sigmoid\n",
      "epochs: 90\n",
      "batchsize: 25\n",
      "validation_split: 0.2\n",
      "Model: \"sequential_178\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_534 (Dense)            (None, 144, 80)           160       \n",
      "_________________________________________________________________\n",
      "dense_535 (Dense)            (None, 144, 16)           1296      \n",
      "_________________________________________________________________\n",
      "dropout_178 (Dropout)        (None, 144, 16)           0         \n",
      "_________________________________________________________________\n",
      "dense_536 (Dense)            (None, 144, 1)            17        \n",
      "=================================================================\n",
      "Total params: 1,473\n",
      "Trainable params: 1,473\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/90\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "124/124 [==============================] - 1s 8ms/step - loss: 0.0557 - val_loss: 0.0199\n",
      "Epoch 2/90\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.0343 - val_loss: 0.0187\n",
      "Epoch 3/90\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.0341 - val_loss: 0.0197\n",
      "Epoch 4/90\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.0336 - val_loss: 0.0193\n",
      "Epoch 5/90\n",
      "124/124 [==============================] - 1s 5ms/step - loss: 0.0335 - val_loss: 0.0195\n",
      "Epoch 6/90\n",
      "124/124 [==============================] - 1s 5ms/step - loss: 0.0332 - val_loss: 0.0193\n",
      "Epoch 7/90\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.0330 - val_loss: 0.0192\n",
      "Epoch 8/90\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.0328 - val_loss: 0.0189\n",
      "Epoch 9/90\n",
      "124/124 [==============================] - 1s 5ms/step - loss: 0.0327 - val_loss: 0.0188\n",
      "Epoch 10/90\n",
      "124/124 [==============================] - 1s 5ms/step - loss: 0.0325 - val_loss: 0.0188\n",
      "Epoch 11/90\n",
      "124/124 [==============================] - 1s 5ms/step - loss: 0.0322 - val_loss: 0.0188\n",
      "Epoch 12/90\n",
      "124/124 [==============================] - 1s 5ms/step - loss: 0.0320 - val_loss: 0.0189\n",
      "Epoch 13/90\n",
      "124/124 [==============================] - 1s 5ms/step - loss: 0.0318 - val_loss: 0.0188\n",
      "Epoch 14/90\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.0316 - val_loss: 0.0186\n",
      "Epoch 15/90\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.0315 - val_loss: 0.0187\n",
      "Epoch 16/90\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.0313 - val_loss: 0.0187\n",
      "Epoch 17/90\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.0311 - val_loss: 0.0186\n",
      "Epoch 18/90\n",
      "124/124 [==============================] - 1s 5ms/step - loss: 0.0309 - val_loss: 0.0186\n",
      "Epoch 19/90\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.0307 - val_loss: 0.0186\n",
      "Epoch 20/90\n",
      "124/124 [==============================] - 1s 5ms/step - loss: 0.0307 - val_loss: 0.0187\n",
      "Epoch 21/90\n",
      "124/124 [==============================] - 1s 5ms/step - loss: 0.0305 - val_loss: 0.0186\n",
      "Epoch 22/90\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.0303 - val_loss: 0.0187\n",
      "Epoch 23/90\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.0303 - val_loss: 0.0188\n",
      "Epoch 24/90\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.0301 - val_loss: 0.0188\n",
      "Epoch 25/90\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.0300 - val_loss: 0.0187\n",
      "Epoch 26/90\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.0298 - val_loss: 0.0187\n",
      "Epoch 27/90\n",
      "124/124 [==============================] - 1s 5ms/step - loss: 0.0297 - val_loss: 0.0188\n",
      "Epoch 28/90\n",
      "124/124 [==============================] - 1s 5ms/step - loss: 0.0296 - val_loss: 0.0188\n",
      "Epoch 29/90\n",
      "124/124 [==============================] - 1s 5ms/step - loss: 0.0295 - val_loss: 0.0188\n",
      "Epoch 30/90\n",
      "124/124 [==============================] - 1s 5ms/step - loss: 0.0293 - val_loss: 0.0188\n",
      "Epoch 31/90\n",
      "124/124 [==============================] - 1s 5ms/step - loss: 0.0293 - val_loss: 0.0189\n",
      "Epoch 32/90\n",
      "124/124 [==============================] - 1s 5ms/step - loss: 0.0292 - val_loss: 0.0190\n",
      "Epoch 33/90\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.0291 - val_loss: 0.0190\n",
      "Epoch 34/90\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.0290 - val_loss: 0.0189\n",
      "Epoch 35/90\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.0289 - val_loss: 0.0189\n",
      "Epoch 36/90\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.0288 - val_loss: 0.0189\n",
      "Epoch 37/90\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.0288 - val_loss: 0.0183\n",
      "Epoch 38/90\n",
      "124/124 [==============================] - 1s 5ms/step - loss: 0.0287 - val_loss: 0.0190\n",
      "Epoch 39/90\n",
      "124/124 [==============================] - 1s 5ms/step - loss: 0.0286 - val_loss: 0.0190\n",
      "Epoch 40/90\n",
      "124/124 [==============================] - 1s 5ms/step - loss: 0.0286 - val_loss: 0.0190\n",
      "Epoch 41/90\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.0285 - val_loss: 0.0190\n",
      "Epoch 42/90\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.0285 - val_loss: 0.0191\n",
      "Epoch 43/90\n",
      "124/124 [==============================] - 1s 5ms/step - loss: 0.0284 - val_loss: 0.0191\n",
      "Epoch 44/90\n",
      "124/124 [==============================] - 1s 5ms/step - loss: 0.0284 - val_loss: 0.0190\n",
      "Epoch 45/90\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.0283 - val_loss: 0.0190\n",
      "Epoch 46/90\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.0283 - val_loss: 0.0190\n",
      "Epoch 47/90\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.0282 - val_loss: 0.0191\n",
      "Epoch 48/90\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.0282 - val_loss: 0.0192\n",
      "Epoch 49/90\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.0281 - val_loss: 0.0190\n",
      "Epoch 50/90\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.0281 - val_loss: 0.0191\n",
      "Epoch 51/90\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.0278 - val_loss: 0.0177\n",
      "Epoch 52/90\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.0284 - val_loss: 0.0192\n",
      "Epoch 53/90\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.0279 - val_loss: 0.0191\n",
      "Epoch 54/90\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.0278 - val_loss: 0.0190\n",
      "Epoch 55/90\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.0278 - val_loss: 0.0191\n",
      "Epoch 56/90\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.0278 - val_loss: 0.0190\n",
      "Epoch 57/90\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.0278 - val_loss: 0.0190\n",
      "Epoch 58/90\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.0277 - val_loss: 0.0190\n",
      "Epoch 59/90\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.0277 - val_loss: 0.0190\n",
      "Epoch 60/90\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.0277 - val_loss: 0.0190\n",
      "Epoch 61/90\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.0276 - val_loss: 0.0190\n",
      "Epoch 62/90\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.0276 - val_loss: 0.0190\n",
      "Epoch 63/90\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.0276 - val_loss: 0.0190\n",
      "Epoch 64/90\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.0279 - val_loss: 0.0198\n",
      "Epoch 65/90\n",
      "124/124 [==============================] - 1s 5ms/step - loss: 0.0273 - val_loss: 0.0189\n",
      "Epoch 66/90\n",
      "124/124 [==============================] - 1s 5ms/step - loss: 0.0275 - val_loss: 0.0189\n",
      "Epoch 67/90\n",
      "124/124 [==============================] - 1s 5ms/step - loss: 0.0272 - val_loss: 0.0173\n",
      "Epoch 68/90\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.0282 - val_loss: 0.0191\n",
      "Epoch 69/90\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.0274 - val_loss: 0.0189\n",
      "Epoch 70/90\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.0274 - val_loss: 0.0189\n",
      "Epoch 71/90\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.0274 - val_loss: 0.0189\n",
      "Epoch 72/90\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.0274 - val_loss: 0.0188\n",
      "Epoch 73/90\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.0274 - val_loss: 0.0188\n",
      "Epoch 74/90\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.0274 - val_loss: 0.0188\n",
      "Epoch 75/90\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.0274 - val_loss: 0.0188\n",
      "Epoch 76/90\n",
      "124/124 [==============================] - 1s 5ms/step - loss: 0.0274 - val_loss: 0.0188\n",
      "Epoch 77/90\n",
      "124/124 [==============================] - 1s 5ms/step - loss: 0.0274 - val_loss: 0.0188\n",
      "Epoch 78/90\n",
      "124/124 [==============================] - 1s 5ms/step - loss: 0.0274 - val_loss: 0.0188\n",
      "Epoch 79/90\n",
      "124/124 [==============================] - 1s 5ms/step - loss: 0.0274 - val_loss: 0.0188\n",
      "Epoch 80/90\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.0274 - val_loss: 0.0188\n",
      "Epoch 81/90\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.0273 - val_loss: 0.0189\n",
      "Epoch 82/90\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "124/124 [==============================] - 1s 6ms/step - loss: 0.0273 - val_loss: 0.0188\n",
      "Epoch 83/90\n",
      "124/124 [==============================] - 1s 5ms/step - loss: 0.0273 - val_loss: 0.0188\n",
      "Epoch 84/90\n",
      "124/124 [==============================] - 1s 5ms/step - loss: 0.0273 - val_loss: 0.0189\n",
      "Epoch 85/90\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.0273 - val_loss: 0.0189\n",
      "Epoch 86/90\n",
      "124/124 [==============================] - 1s 5ms/step - loss: 0.0273 - val_loss: 0.0189\n",
      "Epoch 87/90\n",
      "124/124 [==============================] - 1s 5ms/step - loss: 0.0273 - val_loss: 0.0188\n",
      "Epoch 88/90\n",
      "124/124 [==============================] - 1s 5ms/step - loss: 0.0273 - val_loss: 0.0189\n",
      "Epoch 89/90\n",
      "124/124 [==============================] - 1s 5ms/step - loss: 0.0272 - val_loss: 0.0188\n",
      "Epoch 90/90\n",
      "124/124 [==============================] - 1s 5ms/step - loss: 0.0272 - val_loss: 0.0188\n",
      "Execution time:  64.6579475402832\n",
      "DNN:\n",
      "Mean Absolute Error: 0.0255\n",
      "Root Mean Square Error: 0.0430\n",
      "Mean Square Error: 0.0018\n",
      "\n",
      "Train RMSE: 0.043\n",
      "Train MSE: 0.002\n",
      "Train MAE: 0.025\n",
      "###########################\n",
      "\n",
      "MODEL:  DNN\n",
      "sequence:  1d\n",
      "units:  12\n",
      "dropout1:  0.48476373451509647\n",
      "optimizer: adamax\n",
      "activationDense: sigmoid\n",
      "epochs: 52\n",
      "batchsize: 57\n",
      "validation_split: 0.2\n",
      "Model: \"sequential_179\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_537 (Dense)            (None, 144, 12)           24        \n",
      "_________________________________________________________________\n",
      "dense_538 (Dense)            (None, 144, 16)           208       \n",
      "_________________________________________________________________\n",
      "dropout_179 (Dropout)        (None, 144, 16)           0         \n",
      "_________________________________________________________________\n",
      "dense_539 (Dense)            (None, 144, 1)            17        \n",
      "=================================================================\n",
      "Total params: 249\n",
      "Trainable params: 249\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/52\n",
      "54/54 [==============================] - 0s 9ms/step - loss: 0.0776 - val_loss: 0.0737\n",
      "Epoch 2/52\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 0.0468 - val_loss: 0.0455\n",
      "Epoch 3/52\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 0.0413 - val_loss: 0.0383\n",
      "Epoch 4/52\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 0.0404 - val_loss: 0.0366\n",
      "Epoch 5/52\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 0.0395 - val_loss: 0.0352\n",
      "Epoch 6/52\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 0.0386 - val_loss: 0.0343\n",
      "Epoch 7/52\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 0.0379 - val_loss: 0.0334\n",
      "Epoch 8/52\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 0.0372 - val_loss: 0.0327\n",
      "Epoch 9/52\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 0.0366 - val_loss: 0.0319\n",
      "Epoch 10/52\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 0.0361 - val_loss: 0.0315\n",
      "Epoch 11/52\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 0.0355 - val_loss: 0.0308\n",
      "Epoch 12/52\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 0.0350 - val_loss: 0.0304\n",
      "Epoch 13/52\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 0.0344 - val_loss: 0.0299\n",
      "Epoch 14/52\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 0.0341 - val_loss: 0.0295\n",
      "Epoch 15/52\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 0.0336 - val_loss: 0.0290\n",
      "Epoch 16/52\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 0.0333 - val_loss: 0.0285\n",
      "Epoch 17/52\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 0.0328 - val_loss: 0.0279\n",
      "Epoch 18/52\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 0.0325 - val_loss: 0.0274\n",
      "Epoch 19/52\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 0.0322 - val_loss: 0.0270\n",
      "Epoch 20/52\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 0.0319 - val_loss: 0.0268\n",
      "Epoch 21/52\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 0.0316 - val_loss: 0.0265\n",
      "Epoch 22/52\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 0.0312 - val_loss: 0.0262\n",
      "Epoch 23/52\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 0.0310 - val_loss: 0.0262\n",
      "Epoch 24/52\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 0.0308 - val_loss: 0.0261\n",
      "Epoch 25/52\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 0.0305 - val_loss: 0.0259\n",
      "Epoch 26/52\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 0.0303 - val_loss: 0.0258\n",
      "Epoch 27/52\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 0.0300 - val_loss: 0.0256\n",
      "Epoch 28/52\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 0.0298 - val_loss: 0.0255\n",
      "Epoch 29/52\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 0.0296 - val_loss: 0.0251\n",
      "Epoch 30/52\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 0.0294 - val_loss: 0.0247\n",
      "Epoch 31/52\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 0.0293 - val_loss: 0.0244\n",
      "Epoch 32/52\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 0.0291 - val_loss: 0.0240\n",
      "Epoch 33/52\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 0.0290 - val_loss: 0.0236\n",
      "Epoch 34/52\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 0.0289 - val_loss: 0.0233\n",
      "Epoch 35/52\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 0.0287 - val_loss: 0.0230\n",
      "Epoch 36/52\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 0.0286 - val_loss: 0.0228\n",
      "Epoch 37/52\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 0.0285 - val_loss: 0.0226\n",
      "Epoch 38/52\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 0.0284 - val_loss: 0.0224\n",
      "Epoch 39/52\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 0.0283 - val_loss: 0.0221\n",
      "Epoch 40/52\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 0.0282 - val_loss: 0.0219\n",
      "Epoch 41/52\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 0.0282 - val_loss: 0.0218\n",
      "Epoch 42/52\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 0.0281 - val_loss: 0.0215\n",
      "Epoch 43/52\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 0.0280 - val_loss: 0.0214\n",
      "Epoch 44/52\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 0.0279 - val_loss: 0.0212\n",
      "Epoch 45/52\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 0.0279 - val_loss: 0.0210\n",
      "Epoch 46/52\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 0.0278 - val_loss: 0.0209\n",
      "Epoch 47/52\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 0.0278 - val_loss: 0.0208\n",
      "Epoch 48/52\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 0.0277 - val_loss: 0.0207\n",
      "Epoch 49/52\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 0.0277 - val_loss: 0.0206\n",
      "Epoch 50/52\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 0.0276 - val_loss: 0.0205\n",
      "Epoch 51/52\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 0.0276 - val_loss: 0.0205\n",
      "Epoch 52/52\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 0.0276 - val_loss: 0.0204\n",
      "Execution time:  17.237717866897583\n",
      "DNN:\n",
      "Mean Absolute Error: 0.0260\n",
      "Root Mean Square Error: 0.0427\n",
      "Mean Square Error: 0.0018\n",
      "\n",
      "Train RMSE: 0.043\n",
      "Train MSE: 0.002\n",
      "Train MAE: 0.026\n",
      "###########################\n",
      "\n",
      "MODEL:  DNN\n",
      "sequence:  3d\n",
      "units:  87\n",
      "dropout1:  0.40519643149940265\n",
      "optimizer: adam\n",
      "activationDense: tanh\n",
      "epochs: 80\n",
      "batchsize: 31\n",
      "validation_split: 0.1\n",
      "Model: \"sequential_180\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_540 (Dense)            (None, 432, 87)           174       \n",
      "_________________________________________________________________\n",
      "dense_541 (Dense)            (None, 432, 16)           1408      \n",
      "_________________________________________________________________\n",
      "dropout_180 (Dropout)        (None, 432, 16)           0         \n",
      "_________________________________________________________________\n",
      "dense_542 (Dense)            (None, 432, 1)            17        \n",
      "=================================================================\n",
      "Total params: 1,599\n",
      "Trainable params: 1,599\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/80\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "104/104 [==============================] - 2s 17ms/step - loss: 0.1940 - val_loss: 0.0587\n",
      "Epoch 2/80\n",
      "104/104 [==============================] - 2s 15ms/step - loss: 0.1232 - val_loss: 0.0281\n",
      "Epoch 3/80\n",
      "104/104 [==============================] - 2s 15ms/step - loss: 0.0963 - val_loss: 0.0069\n",
      "Epoch 4/80\n",
      "104/104 [==============================] - 2s 15ms/step - loss: 0.0682 - val_loss: 0.0060\n",
      "Epoch 5/80\n",
      "104/104 [==============================] - 2s 15ms/step - loss: 0.0467 - val_loss: 0.0113\n",
      "Epoch 6/80\n",
      "104/104 [==============================] - 2s 15ms/step - loss: 0.0345 - val_loss: 0.0114\n",
      "Epoch 7/80\n",
      "104/104 [==============================] - 2s 15ms/step - loss: 0.0285 - val_loss: 0.0098\n",
      "Epoch 8/80\n",
      "104/104 [==============================] - 2s 15ms/step - loss: 0.0267 - val_loss: 0.0111\n",
      "Epoch 9/80\n",
      "104/104 [==============================] - 2s 15ms/step - loss: 0.0266 - val_loss: 0.0136\n",
      "Epoch 10/80\n",
      "104/104 [==============================] - 2s 16ms/step - loss: 0.0263 - val_loss: 0.0134\n",
      "Epoch 11/80\n",
      "104/104 [==============================] - 2s 15ms/step - loss: 0.0263 - val_loss: 0.0136\n",
      "Epoch 12/80\n",
      "104/104 [==============================] - 2s 15ms/step - loss: 0.0259 - val_loss: 0.0193\n",
      "Epoch 13/80\n",
      "104/104 [==============================] - 2s 15ms/step - loss: 0.0259 - val_loss: 0.0127\n",
      "Epoch 14/80\n",
      "104/104 [==============================] - 2s 15ms/step - loss: 0.0263 - val_loss: 0.0139\n",
      "Epoch 15/80\n",
      "104/104 [==============================] - 2s 15ms/step - loss: 0.0262 - val_loss: 0.0139\n",
      "Epoch 16/80\n",
      "104/104 [==============================] - 2s 15ms/step - loss: 0.0261 - val_loss: 0.0139\n",
      "Epoch 17/80\n",
      "104/104 [==============================] - 2s 15ms/step - loss: 0.0261 - val_loss: 0.0140\n",
      "Epoch 18/80\n",
      "104/104 [==============================] - 2s 15ms/step - loss: 0.0261 - val_loss: 0.0140\n",
      "Epoch 19/80\n",
      "104/104 [==============================] - 2s 15ms/step - loss: 0.0261 - val_loss: 0.0141\n",
      "Epoch 20/80\n",
      "104/104 [==============================] - 2s 16ms/step - loss: 0.0261 - val_loss: 0.0141\n",
      "Epoch 21/80\n",
      "104/104 [==============================] - 2s 15ms/step - loss: 0.0261 - val_loss: 0.0141\n",
      "Epoch 22/80\n",
      "104/104 [==============================] - 2s 15ms/step - loss: 0.0261 - val_loss: 0.0141\n",
      "Epoch 23/80\n",
      "104/104 [==============================] - 2s 15ms/step - loss: 0.0261 - val_loss: 0.0139\n",
      "Epoch 24/80\n",
      "104/104 [==============================] - 2s 15ms/step - loss: 0.0261 - val_loss: 0.0142\n",
      "Epoch 25/80\n",
      "104/104 [==============================] - 2s 15ms/step - loss: 0.0261 - val_loss: 0.0142\n",
      "Epoch 26/80\n",
      "104/104 [==============================] - 2s 15ms/step - loss: 0.0261 - val_loss: 0.0142\n",
      "Epoch 27/80\n",
      "104/104 [==============================] - 2s 15ms/step - loss: 0.0261 - val_loss: 0.0142\n",
      "Epoch 28/80\n",
      "104/104 [==============================] - 2s 15ms/step - loss: 0.0261 - val_loss: 0.0141\n",
      "Epoch 29/80\n",
      "104/104 [==============================] - 2s 16ms/step - loss: 0.0261 - val_loss: 0.0142\n",
      "Epoch 30/80\n",
      "104/104 [==============================] - 2s 16ms/step - loss: 0.0261 - val_loss: 0.0141\n",
      "Epoch 31/80\n",
      "104/104 [==============================] - 2s 15ms/step - loss: 0.0261 - val_loss: 0.0142\n",
      "Epoch 32/80\n",
      "104/104 [==============================] - 2s 15ms/step - loss: 0.0261 - val_loss: 0.0142\n",
      "Epoch 33/80\n",
      "104/104 [==============================] - 2s 15ms/step - loss: 0.0261 - val_loss: 0.0142\n",
      "Epoch 34/80\n",
      "104/104 [==============================] - 2s 15ms/step - loss: 0.0261 - val_loss: 0.0142\n",
      "Epoch 35/80\n",
      "104/104 [==============================] - 2s 15ms/step - loss: 0.0261 - val_loss: 0.0142\n",
      "Epoch 36/80\n",
      "104/104 [==============================] - 2s 15ms/step - loss: 0.0261 - val_loss: 0.0142\n",
      "Epoch 37/80\n",
      "104/104 [==============================] - 2s 15ms/step - loss: 0.0261 - val_loss: 0.0142\n",
      "Epoch 38/80\n",
      "104/104 [==============================] - 2s 15ms/step - loss: 0.0261 - val_loss: 0.0142\n",
      "Epoch 39/80\n",
      "104/104 [==============================] - 2s 16ms/step - loss: 0.0261 - val_loss: 0.0142\n",
      "Epoch 40/80\n",
      "104/104 [==============================] - 2s 16ms/step - loss: 0.0261 - val_loss: 0.0142\n",
      "Epoch 41/80\n",
      "104/104 [==============================] - 2s 15ms/step - loss: 0.0261 - val_loss: 0.0142\n",
      "Epoch 42/80\n",
      "104/104 [==============================] - 2s 15ms/step - loss: 0.0261 - val_loss: 0.0142\n",
      "Epoch 43/80\n",
      "104/104 [==============================] - 2s 15ms/step - loss: 0.0261 - val_loss: 0.0142\n",
      "Epoch 44/80\n",
      "104/104 [==============================] - 2s 15ms/step - loss: 0.0261 - val_loss: 0.0142\n",
      "Epoch 45/80\n",
      "104/104 [==============================] - 2s 15ms/step - loss: 0.0261 - val_loss: 0.0142\n",
      "Epoch 46/80\n",
      "104/104 [==============================] - 2s 15ms/step - loss: 0.0261 - val_loss: 0.0142\n",
      "Epoch 47/80\n",
      "104/104 [==============================] - 2s 15ms/step - loss: 0.0261 - val_loss: 0.0142\n",
      "Epoch 48/80\n",
      "104/104 [==============================] - 2s 15ms/step - loss: 0.0261 - val_loss: 0.0142\n",
      "Epoch 49/80\n",
      "104/104 [==============================] - 2s 16ms/step - loss: 0.0261 - val_loss: 0.0142\n",
      "Epoch 50/80\n",
      "104/104 [==============================] - 2s 16ms/step - loss: 0.0261 - val_loss: 0.0142\n",
      "Epoch 51/80\n",
      "104/104 [==============================] - 2s 15ms/step - loss: 0.0261 - val_loss: 0.0142\n",
      "Epoch 52/80\n",
      "104/104 [==============================] - 2s 15ms/step - loss: 0.0261 - val_loss: 0.0142\n",
      "Epoch 53/80\n",
      "104/104 [==============================] - 2s 15ms/step - loss: 0.0261 - val_loss: 0.0142\n",
      "Epoch 54/80\n",
      "104/104 [==============================] - 2s 15ms/step - loss: 0.0261 - val_loss: 0.0142\n",
      "Epoch 55/80\n",
      "104/104 [==============================] - 2s 15ms/step - loss: 0.0261 - val_loss: 0.0142\n",
      "Epoch 56/80\n",
      "104/104 [==============================] - 2s 15ms/step - loss: 0.0261 - val_loss: 0.0142\n",
      "Epoch 57/80\n",
      "104/104 [==============================] - 2s 15ms/step - loss: 0.0261 - val_loss: 0.0142\n",
      "Epoch 58/80\n",
      "104/104 [==============================] - 2s 15ms/step - loss: 0.0261 - val_loss: 0.0142\n",
      "Epoch 59/80\n",
      "104/104 [==============================] - 2s 16ms/step - loss: 0.0261 - val_loss: 0.0142\n",
      "Epoch 60/80\n",
      "104/104 [==============================] - 2s 16ms/step - loss: 0.0261 - val_loss: 0.0142\n",
      "Epoch 61/80\n",
      "104/104 [==============================] - 2s 16ms/step - loss: 0.0261 - val_loss: 0.0142\n",
      "Epoch 62/80\n",
      "104/104 [==============================] - 2s 15ms/step - loss: 0.0261 - val_loss: 0.0142\n",
      "Epoch 63/80\n",
      "104/104 [==============================] - 2s 15ms/step - loss: 0.0261 - val_loss: 0.0142\n",
      "Epoch 64/80\n",
      "104/104 [==============================] - 2s 15ms/step - loss: 0.0261 - val_loss: 0.0142\n",
      "Epoch 65/80\n",
      "104/104 [==============================] - 2s 15ms/step - loss: 0.0261 - val_loss: 0.0142\n",
      "Epoch 66/80\n",
      "104/104 [==============================] - 2s 15ms/step - loss: 0.0261 - val_loss: 0.0142\n",
      "Epoch 67/80\n",
      "104/104 [==============================] - 2s 15ms/step - loss: 0.0261 - val_loss: 0.0142\n",
      "Epoch 68/80\n",
      "104/104 [==============================] - 2s 15ms/step - loss: 0.0261 - val_loss: 0.0142\n",
      "Epoch 69/80\n",
      "104/104 [==============================] - 2s 16ms/step - loss: 0.0261 - val_loss: 0.0142\n",
      "Epoch 70/80\n",
      "104/104 [==============================] - 2s 16ms/step - loss: 0.0261 - val_loss: 0.0142\n",
      "Epoch 71/80\n",
      "104/104 [==============================] - 2s 15ms/step - loss: 0.0261 - val_loss: 0.0142\n",
      "Epoch 72/80\n",
      "104/104 [==============================] - 2s 15ms/step - loss: 0.0261 - val_loss: 0.0142\n",
      "Epoch 73/80\n",
      "104/104 [==============================] - 2s 15ms/step - loss: 0.0261 - val_loss: 0.0142\n",
      "Epoch 74/80\n",
      "104/104 [==============================] - 2s 15ms/step - loss: 0.0261 - val_loss: 0.0142\n",
      "Epoch 75/80\n",
      "104/104 [==============================] - 2s 15ms/step - loss: 0.0261 - val_loss: 0.0142\n",
      "Epoch 76/80\n",
      "104/104 [==============================] - 2s 15ms/step - loss: 0.0261 - val_loss: 0.0142\n",
      "Epoch 77/80\n",
      "104/104 [==============================] - 2s 15ms/step - loss: 0.0261 - val_loss: 0.0142\n",
      "Epoch 78/80\n",
      "104/104 [==============================] - 2s 15ms/step - loss: 0.0261 - val_loss: 0.0142\n",
      "Epoch 79/80\n",
      "104/104 [==============================] - 2s 16ms/step - loss: 0.0261 - val_loss: 0.0142\n",
      "Epoch 80/80\n",
      "104/104 [==============================] - 2s 16ms/step - loss: 0.0261 - val_loss: 0.0142\n",
      "Execution time:  129.49278450012207\n",
      "DNN:\n",
      "Mean Absolute Error: 0.0253\n",
      "Root Mean Square Error: 0.0445\n",
      "Mean Square Error: 0.0020\n",
      "\n",
      "Train RMSE: 0.045\n",
      "Train MSE: 0.002\n",
      "Train MAE: 0.025\n",
      "###########################\n",
      "\n",
      "MODEL:  DNN\n",
      "sequence:  3d\n",
      "units:  80\n",
      "dropout1:  0.11814836227952394\n",
      "optimizer: adam\n",
      "activationDense: tanh\n",
      "epochs: 90\n",
      "batchsize: 25\n",
      "validation_split: 0.1\n",
      "Model: \"sequential_181\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_543 (Dense)            (None, 432, 80)           160       \n",
      "_________________________________________________________________\n",
      "dense_544 (Dense)            (None, 432, 16)           1296      \n",
      "_________________________________________________________________\n",
      "dropout_181 (Dropout)        (None, 432, 16)           0         \n",
      "_________________________________________________________________\n",
      "dense_545 (Dense)            (None, 432, 1)            17        \n",
      "=================================================================\n",
      "Total params: 1,473\n",
      "Trainable params: 1,473\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/90\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "129/129 [==============================] - 2s 13ms/step - loss: 0.1104 - val_loss: 0.0205\n",
      "Epoch 2/90\n",
      "129/129 [==============================] - 1s 12ms/step - loss: 0.0562 - val_loss: 0.0148\n",
      "Epoch 3/90\n",
      "129/129 [==============================] - 2s 12ms/step - loss: 0.0530 - val_loss: 0.0099\n",
      "Epoch 4/90\n",
      "129/129 [==============================] - 2s 12ms/step - loss: 0.0502 - val_loss: 0.0070\n",
      "Epoch 5/90\n",
      "129/129 [==============================] - 2s 12ms/step - loss: 0.0473 - val_loss: 0.0073\n",
      "Epoch 6/90\n",
      "129/129 [==============================] - 1s 12ms/step - loss: 0.0444 - val_loss: 0.0067\n",
      "Epoch 7/90\n",
      "129/129 [==============================] - 2s 12ms/step - loss: 0.0400 - val_loss: 0.0072\n",
      "Epoch 8/90\n",
      "129/129 [==============================] - 2s 12ms/step - loss: 0.0386 - val_loss: 0.0118\n",
      "Epoch 9/90\n",
      "129/129 [==============================] - 2s 12ms/step - loss: 0.0375 - val_loss: 0.0141\n",
      "Epoch 10/90\n",
      "129/129 [==============================] - 2s 12ms/step - loss: 0.0362 - val_loss: 0.0162\n",
      "Epoch 11/90\n",
      "129/129 [==============================] - 2s 12ms/step - loss: 0.0352 - val_loss: 0.0175\n",
      "Epoch 12/90\n",
      "129/129 [==============================] - 2s 12ms/step - loss: 0.0348 - val_loss: 0.0199\n",
      "Epoch 13/90\n",
      "129/129 [==============================] - 1s 12ms/step - loss: 0.0336 - val_loss: 0.0183\n",
      "Epoch 14/90\n",
      "129/129 [==============================] - 2s 12ms/step - loss: 0.0328 - val_loss: 0.0177\n",
      "Epoch 15/90\n",
      "129/129 [==============================] - 1s 12ms/step - loss: 0.0320 - val_loss: 0.0176\n",
      "Epoch 16/90\n",
      "129/129 [==============================] - 2s 12ms/step - loss: 0.0314 - val_loss: 0.0158\n",
      "Epoch 17/90\n",
      "129/129 [==============================] - 1s 12ms/step - loss: 0.0307 - val_loss: 0.0157\n",
      "Epoch 18/90\n",
      "129/129 [==============================] - 2s 12ms/step - loss: 0.0300 - val_loss: 0.0153\n",
      "Epoch 19/90\n",
      "129/129 [==============================] - 2s 13ms/step - loss: 0.0295 - val_loss: 0.0154\n",
      "Epoch 20/90\n",
      "129/129 [==============================] - 2s 12ms/step - loss: 0.0292 - val_loss: 0.0150\n",
      "Epoch 21/90\n",
      "129/129 [==============================] - 2s 12ms/step - loss: 0.0288 - val_loss: 0.0162\n",
      "Epoch 22/90\n",
      "129/129 [==============================] - 2s 12ms/step - loss: 0.0286 - val_loss: 0.0128\n",
      "Epoch 23/90\n",
      "129/129 [==============================] - 1s 12ms/step - loss: 0.0284 - val_loss: 0.0122\n",
      "Epoch 24/90\n",
      "129/129 [==============================] - 2s 12ms/step - loss: 0.0282 - val_loss: 0.0124\n",
      "Epoch 25/90\n",
      "129/129 [==============================] - 2s 12ms/step - loss: 0.0280 - val_loss: 0.0110\n",
      "Epoch 26/90\n",
      "129/129 [==============================] - 2s 12ms/step - loss: 0.0279 - val_loss: 0.0108\n",
      "Epoch 27/90\n",
      "129/129 [==============================] - 1s 12ms/step - loss: 0.0277 - val_loss: 0.0109\n",
      "Epoch 28/90\n",
      "129/129 [==============================] - 2s 12ms/step - loss: 0.0275 - val_loss: 0.0108\n",
      "Epoch 29/90\n",
      "129/129 [==============================] - 2s 12ms/step - loss: 0.0274 - val_loss: 0.0105\n",
      "Epoch 30/90\n",
      "129/129 [==============================] - 2s 12ms/step - loss: 0.0273 - val_loss: 0.0105\n",
      "Epoch 31/90\n",
      "129/129 [==============================] - 2s 12ms/step - loss: 0.0272 - val_loss: 0.0107\n",
      "Epoch 32/90\n",
      "129/129 [==============================] - 2s 12ms/step - loss: 0.0271 - val_loss: 0.0107\n",
      "Epoch 33/90\n",
      "129/129 [==============================] - 2s 12ms/step - loss: 0.0270 - val_loss: 0.0109\n",
      "Epoch 34/90\n",
      "129/129 [==============================] - 1s 12ms/step - loss: 0.0269 - val_loss: 0.0107\n",
      "Epoch 35/90\n",
      "129/129 [==============================] - 2s 12ms/step - loss: 0.0269 - val_loss: 0.0106\n",
      "Epoch 36/90\n",
      "129/129 [==============================] - 2s 12ms/step - loss: 0.0269 - val_loss: 0.0104\n",
      "Epoch 37/90\n",
      "129/129 [==============================] - 2s 12ms/step - loss: 0.0268 - val_loss: 0.0103\n",
      "Epoch 38/90\n",
      "129/129 [==============================] - 1s 12ms/step - loss: 0.0268 - val_loss: 0.0103\n",
      "Epoch 39/90\n",
      "129/129 [==============================] - 2s 12ms/step - loss: 0.0267 - val_loss: 0.0106\n",
      "Epoch 40/90\n",
      "129/129 [==============================] - 2s 12ms/step - loss: 0.0266 - val_loss: 0.0118\n",
      "Epoch 41/90\n",
      "129/129 [==============================] - 2s 12ms/step - loss: 0.0266 - val_loss: 0.0119\n",
      "Epoch 42/90\n",
      "129/129 [==============================] - 2s 12ms/step - loss: 0.0265 - val_loss: 0.0122\n",
      "Epoch 43/90\n",
      "129/129 [==============================] - 2s 12ms/step - loss: 0.0260 - val_loss: 0.0194\n",
      "Epoch 44/90\n",
      "129/129 [==============================] - 2s 12ms/step - loss: 0.0261 - val_loss: 0.0110\n",
      "Epoch 45/90\n",
      "129/129 [==============================] - 2s 12ms/step - loss: 0.0265 - val_loss: 0.0124\n",
      "Epoch 46/90\n",
      "129/129 [==============================] - 2s 12ms/step - loss: 0.0264 - val_loss: 0.0124\n",
      "Epoch 47/90\n",
      "129/129 [==============================] - 2s 12ms/step - loss: 0.0264 - val_loss: 0.0124\n",
      "Epoch 48/90\n",
      "129/129 [==============================] - 2s 12ms/step - loss: 0.0264 - val_loss: 0.0125\n",
      "Epoch 49/90\n",
      "129/129 [==============================] - 2s 12ms/step - loss: 0.0264 - val_loss: 0.0125\n",
      "Epoch 50/90\n",
      "129/129 [==============================] - 2s 13ms/step - loss: 0.0264 - val_loss: 0.0125\n",
      "Epoch 51/90\n",
      "129/129 [==============================] - 2s 12ms/step - loss: 0.0263 - val_loss: 0.0122\n",
      "Epoch 52/90\n",
      "129/129 [==============================] - 2s 12ms/step - loss: 0.0264 - val_loss: 0.0126\n",
      "Epoch 53/90\n",
      "129/129 [==============================] - 2s 12ms/step - loss: 0.0263 - val_loss: 0.0123\n",
      "Epoch 54/90\n",
      "129/129 [==============================] - 2s 12ms/step - loss: 0.0264 - val_loss: 0.0126\n",
      "Epoch 55/90\n",
      "129/129 [==============================] - 2s 12ms/step - loss: 0.0263 - val_loss: 0.0123\n",
      "Epoch 56/90\n",
      "129/129 [==============================] - 2s 12ms/step - loss: 0.0264 - val_loss: 0.0126\n",
      "Epoch 57/90\n",
      "129/129 [==============================] - 2s 12ms/step - loss: 0.0263 - val_loss: 0.0123\n",
      "Epoch 58/90\n",
      "129/129 [==============================] - 2s 12ms/step - loss: 0.0264 - val_loss: 0.0127\n",
      "Epoch 59/90\n",
      "129/129 [==============================] - 2s 12ms/step - loss: 0.0263 - val_loss: 0.0123\n",
      "Epoch 60/90\n",
      "129/129 [==============================] - 2s 13ms/step - loss: 0.0264 - val_loss: 0.0127\n",
      "Epoch 61/90\n",
      "129/129 [==============================] - 2s 12ms/step - loss: 0.0263 - val_loss: 0.0124\n",
      "Epoch 62/90\n",
      "129/129 [==============================] - 2s 12ms/step - loss: 0.0264 - val_loss: 0.0124\n",
      "Epoch 63/90\n",
      "129/129 [==============================] - 2s 12ms/step - loss: 0.0264 - val_loss: 0.0125\n",
      "Epoch 64/90\n",
      "129/129 [==============================] - 2s 12ms/step - loss: 0.0264 - val_loss: 0.0125\n",
      "Epoch 65/90\n",
      "129/129 [==============================] - 2s 12ms/step - loss: 0.0263 - val_loss: 0.0122\n",
      "Epoch 66/90\n",
      "129/129 [==============================] - 2s 12ms/step - loss: 0.0264 - val_loss: 0.0126\n",
      "Epoch 67/90\n",
      "129/129 [==============================] - 2s 12ms/step - loss: 0.0263 - val_loss: 0.0122\n",
      "Epoch 68/90\n",
      "129/129 [==============================] - 2s 12ms/step - loss: 0.0264 - val_loss: 0.0126\n",
      "Epoch 69/90\n",
      "129/129 [==============================] - 2s 12ms/step - loss: 0.0263 - val_loss: 0.0123\n",
      "Epoch 70/90\n",
      "129/129 [==============================] - 2s 13ms/step - loss: 0.0264 - val_loss: 0.0126\n",
      "Epoch 71/90\n",
      "129/129 [==============================] - 2s 13ms/step - loss: 0.0263 - val_loss: 0.0123\n",
      "Epoch 72/90\n",
      "129/129 [==============================] - 2s 12ms/step - loss: 0.0264 - val_loss: 0.0127\n",
      "Epoch 73/90\n",
      "129/129 [==============================] - 2s 12ms/step - loss: 0.0263 - val_loss: 0.0123\n",
      "Epoch 74/90\n",
      "129/129 [==============================] - 2s 12ms/step - loss: 0.0264 - val_loss: 0.0127\n",
      "Epoch 75/90\n",
      "129/129 [==============================] - 2s 12ms/step - loss: 0.0263 - val_loss: 0.0123\n",
      "Epoch 76/90\n",
      "129/129 [==============================] - 2s 12ms/step - loss: 0.0264 - val_loss: 0.0127\n",
      "Epoch 77/90\n",
      "129/129 [==============================] - 2s 12ms/step - loss: 0.0263 - val_loss: 0.0122\n",
      "Epoch 78/90\n",
      "129/129 [==============================] - 2s 12ms/step - loss: 0.0264 - val_loss: 0.0126\n",
      "Epoch 79/90\n",
      "129/129 [==============================] - 2s 12ms/step - loss: 0.0263 - val_loss: 0.0122\n",
      "Epoch 80/90\n",
      "129/129 [==============================] - 2s 12ms/step - loss: 0.0264 - val_loss: 0.0126\n",
      "Epoch 81/90\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "129/129 [==============================] - 2s 12ms/step - loss: 0.0263 - val_loss: 0.0123\n",
      "Epoch 82/90\n",
      "129/129 [==============================] - 2s 12ms/step - loss: 0.0264 - val_loss: 0.0126\n",
      "Epoch 83/90\n",
      "129/129 [==============================] - 1s 12ms/step - loss: 0.0263 - val_loss: 0.0123\n",
      "Epoch 84/90\n",
      "129/129 [==============================] - 2s 12ms/step - loss: 0.0264 - val_loss: 0.0126\n",
      "Epoch 85/90\n",
      "129/129 [==============================] - 2s 12ms/step - loss: 0.0263 - val_loss: 0.0123\n",
      "Epoch 86/90\n",
      "129/129 [==============================] - 2s 12ms/step - loss: 0.0264 - val_loss: 0.0127\n",
      "Epoch 87/90\n",
      "129/129 [==============================] - 2s 12ms/step - loss: 0.0263 - val_loss: 0.0123\n",
      "Epoch 88/90\n",
      "129/129 [==============================] - 1s 12ms/step - loss: 0.0264 - val_loss: 0.0127\n",
      "Epoch 89/90\n",
      "129/129 [==============================] - 2s 12ms/step - loss: 0.0263 - val_loss: 0.0123\n",
      "Epoch 90/90\n",
      "129/129 [==============================] - 2s 12ms/step - loss: 0.0264 - val_loss: 0.0127\n",
      "Execution time:  140.69767260551453\n",
      "DNN:\n",
      "Mean Absolute Error: 0.0255\n",
      "Root Mean Square Error: 0.0454\n",
      "Mean Square Error: 0.0021\n",
      "\n",
      "Train RMSE: 0.045\n",
      "Train MSE: 0.002\n",
      "Train MAE: 0.026\n",
      "###########################\n",
      "\n",
      "MODEL:  DNN\n",
      "sequence:  3d\n",
      "units:  12\n",
      "dropout1:  0.48476373451509647\n",
      "optimizer: adam\n",
      "activationDense: tanh\n",
      "epochs: 52\n",
      "batchsize: 57\n",
      "validation_split: 0.1\n",
      "Model: \"sequential_182\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_546 (Dense)            (None, 432, 12)           24        \n",
      "_________________________________________________________________\n",
      "dense_547 (Dense)            (None, 432, 16)           208       \n",
      "_________________________________________________________________\n",
      "dropout_182 (Dropout)        (None, 432, 16)           0         \n",
      "_________________________________________________________________\n",
      "dense_548 (Dense)            (None, 432, 1)            17        \n",
      "=================================================================\n",
      "Total params: 249\n",
      "Trainable params: 249\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/52\n",
      "57/57 [==============================] - 1s 17ms/step - loss: 0.1662 - val_loss: 0.0131\n",
      "Epoch 2/52\n",
      "57/57 [==============================] - 1s 14ms/step - loss: 0.1020 - val_loss: 0.0078\n",
      "Epoch 3/52\n",
      "57/57 [==============================] - 1s 14ms/step - loss: 0.0833 - val_loss: 0.0090\n",
      "Epoch 4/52\n",
      "57/57 [==============================] - 1s 14ms/step - loss: 0.0729 - val_loss: 0.0082\n",
      "Epoch 5/52\n",
      "57/57 [==============================] - 1s 14ms/step - loss: 0.0668 - val_loss: 0.0081\n",
      "Epoch 6/52\n",
      "57/57 [==============================] - 1s 14ms/step - loss: 0.0621 - val_loss: 0.0074\n",
      "Epoch 7/52\n",
      "57/57 [==============================] - 1s 14ms/step - loss: 0.0577 - val_loss: 0.0068\n",
      "Epoch 8/52\n",
      "57/57 [==============================] - 1s 14ms/step - loss: 0.0535 - val_loss: 0.0069\n",
      "Epoch 9/52\n",
      "57/57 [==============================] - 1s 14ms/step - loss: 0.0495 - val_loss: 0.0070\n",
      "Epoch 10/52\n",
      "57/57 [==============================] - 1s 14ms/step - loss: 0.0459 - val_loss: 0.0071\n",
      "Epoch 11/52\n",
      "57/57 [==============================] - 1s 14ms/step - loss: 0.0426 - val_loss: 0.0071\n",
      "Epoch 12/52\n",
      "57/57 [==============================] - 1s 14ms/step - loss: 0.0398 - val_loss: 0.0073\n",
      "Epoch 13/52\n",
      "57/57 [==============================] - 1s 14ms/step - loss: 0.0374 - val_loss: 0.0075\n",
      "Epoch 14/52\n",
      "57/57 [==============================] - 1s 14ms/step - loss: 0.0352 - val_loss: 0.0077\n",
      "Epoch 15/52\n",
      "57/57 [==============================] - 1s 14ms/step - loss: 0.0333 - val_loss: 0.0079\n",
      "Epoch 16/52\n",
      "57/57 [==============================] - 1s 14ms/step - loss: 0.0319 - val_loss: 0.0081\n",
      "Epoch 17/52\n",
      "57/57 [==============================] - 1s 14ms/step - loss: 0.0307 - val_loss: 0.0082\n",
      "Epoch 18/52\n",
      "57/57 [==============================] - 1s 15ms/step - loss: 0.0295 - val_loss: 0.0085\n",
      "Epoch 19/52\n",
      "57/57 [==============================] - 1s 16ms/step - loss: 0.0288 - val_loss: 0.0085\n",
      "Epoch 20/52\n",
      "57/57 [==============================] - 1s 15ms/step - loss: 0.0283 - val_loss: 0.0091\n",
      "Epoch 21/52\n",
      "57/57 [==============================] - 1s 14ms/step - loss: 0.0276 - val_loss: 0.0097\n",
      "Epoch 22/52\n",
      "57/57 [==============================] - 1s 14ms/step - loss: 0.0273 - val_loss: 0.0105\n",
      "Epoch 23/52\n",
      "57/57 [==============================] - 1s 14ms/step - loss: 0.0271 - val_loss: 0.0116\n",
      "Epoch 24/52\n",
      "57/57 [==============================] - 1s 14ms/step - loss: 0.0269 - val_loss: 0.0120\n",
      "Epoch 25/52\n",
      "57/57 [==============================] - 1s 14ms/step - loss: 0.0267 - val_loss: 0.0127\n",
      "Epoch 26/52\n",
      "57/57 [==============================] - 1s 14ms/step - loss: 0.0265 - val_loss: 0.0133\n",
      "Epoch 27/52\n",
      "57/57 [==============================] - 1s 14ms/step - loss: 0.0264 - val_loss: 0.0137\n",
      "Epoch 28/52\n",
      "57/57 [==============================] - 1s 14ms/step - loss: 0.0263 - val_loss: 0.0144\n",
      "Epoch 29/52\n",
      "57/57 [==============================] - 1s 14ms/step - loss: 0.0262 - val_loss: 0.0149\n",
      "Epoch 30/52\n",
      "57/57 [==============================] - 1s 15ms/step - loss: 0.0261 - val_loss: 0.0151\n",
      "Epoch 31/52\n",
      "57/57 [==============================] - 1s 14ms/step - loss: 0.0260 - val_loss: 0.0153\n",
      "Epoch 32/52\n",
      "57/57 [==============================] - 1s 16ms/step - loss: 0.0259 - val_loss: 0.0156\n",
      "Epoch 33/52\n",
      "57/57 [==============================] - 1s 14ms/step - loss: 0.0259 - val_loss: 0.0159\n",
      "Epoch 34/52\n",
      "57/57 [==============================] - 1s 14ms/step - loss: 0.0258 - val_loss: 0.0161\n",
      "Epoch 35/52\n",
      "57/57 [==============================] - 1s 14ms/step - loss: 0.0258 - val_loss: 0.0163\n",
      "Epoch 36/52\n",
      "57/57 [==============================] - 1s 15ms/step - loss: 0.0258 - val_loss: 0.0166\n",
      "Epoch 37/52\n",
      "57/57 [==============================] - 1s 15ms/step - loss: 0.0257 - val_loss: 0.0171\n",
      "Epoch 38/52\n",
      "57/57 [==============================] - 1s 16ms/step - loss: 0.0256 - val_loss: 0.0172\n",
      "Epoch 39/52\n",
      "57/57 [==============================] - 1s 15ms/step - loss: 0.0256 - val_loss: 0.0172\n",
      "Epoch 40/52\n",
      "57/57 [==============================] - 1s 14ms/step - loss: 0.0255 - val_loss: 0.0173\n",
      "Epoch 41/52\n",
      "57/57 [==============================] - 1s 14ms/step - loss: 0.0255 - val_loss: 0.0174\n",
      "Epoch 42/52\n",
      "57/57 [==============================] - 1s 14ms/step - loss: 0.0255 - val_loss: 0.0174\n",
      "Epoch 43/52\n",
      "57/57 [==============================] - 1s 14ms/step - loss: 0.0255 - val_loss: 0.0174\n",
      "Epoch 44/52\n",
      "57/57 [==============================] - 1s 14ms/step - loss: 0.0254 - val_loss: 0.0175\n",
      "Epoch 45/52\n",
      "57/57 [==============================] - 1s 14ms/step - loss: 0.0254 - val_loss: 0.0174\n",
      "Epoch 46/52\n",
      "57/57 [==============================] - 1s 14ms/step - loss: 0.0254 - val_loss: 0.0174\n",
      "Epoch 47/52\n",
      "57/57 [==============================] - 1s 14ms/step - loss: 0.0254 - val_loss: 0.0175\n",
      "Epoch 48/52\n",
      "57/57 [==============================] - 1s 15ms/step - loss: 0.0254 - val_loss: 0.0174\n",
      "Epoch 49/52\n",
      "57/57 [==============================] - 1s 14ms/step - loss: 0.0254 - val_loss: 0.0176\n",
      "Epoch 50/52\n",
      "57/57 [==============================] - 1s 14ms/step - loss: 0.0253 - val_loss: 0.0173\n",
      "Epoch 51/52\n",
      "57/57 [==============================] - 1s 14ms/step - loss: 0.0254 - val_loss: 0.0176\n",
      "Epoch 52/52\n",
      "57/57 [==============================] - 1s 14ms/step - loss: 0.0254 - val_loss: 0.0176\n",
      "Execution time:  44.26756954193115\n",
      "DNN:\n",
      "Mean Absolute Error: 0.0250\n",
      "Root Mean Square Error: 0.0427\n",
      "Mean Square Error: 0.0018\n",
      "\n",
      "Train RMSE: 0.043\n",
      "Train MSE: 0.002\n",
      "Train MAE: 0.025\n",
      "###########################\n",
      "\n",
      "MODEL:  DNN\n",
      "sequence:  3d\n",
      "units:  87\n",
      "dropout1:  0.40519643149940265\n",
      "optimizer: adam\n",
      "activationDense: tanh\n",
      "epochs: 80\n",
      "batchsize: 31\n",
      "validation_split: 0.2\n",
      "Model: \"sequential_183\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_549 (Dense)            (None, 432, 87)           174       \n",
      "_________________________________________________________________\n",
      "dense_550 (Dense)            (None, 432, 16)           1408      \n",
      "_________________________________________________________________\n",
      "dropout_183 (Dropout)        (None, 432, 16)           0         \n",
      "_________________________________________________________________\n",
      "dense_551 (Dense)            (None, 432, 1)            17        \n",
      "=================================================================\n",
      "Total params: 1,599\n",
      "Trainable params: 1,599\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/80\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "92/92 [==============================] - 2s 19ms/step - loss: 0.1448 - val_loss: 0.0446\n",
      "Epoch 2/80\n",
      "92/92 [==============================] - 2s 17ms/step - loss: 0.0882 - val_loss: 0.0149\n",
      "Epoch 3/80\n",
      "92/92 [==============================] - 1s 16ms/step - loss: 0.0745 - val_loss: 0.0124\n",
      "Epoch 4/80\n",
      "92/92 [==============================] - 1s 16ms/step - loss: 0.0649 - val_loss: 0.0119\n",
      "Epoch 5/80\n",
      "92/92 [==============================] - 1s 16ms/step - loss: 0.0556 - val_loss: 0.0119\n",
      "Epoch 6/80\n",
      "92/92 [==============================] - 1s 16ms/step - loss: 0.0478 - val_loss: 0.0122\n",
      "Epoch 7/80\n",
      "92/92 [==============================] - 1s 16ms/step - loss: 0.0415 - val_loss: 0.0116\n",
      "Epoch 8/80\n",
      "92/92 [==============================] - 1s 16ms/step - loss: 0.0371 - val_loss: 0.0122\n",
      "Epoch 9/80\n",
      "92/92 [==============================] - 1s 16ms/step - loss: 0.0354 - val_loss: 0.0131\n",
      "Epoch 10/80\n",
      "92/92 [==============================] - 1s 16ms/step - loss: 0.0353 - val_loss: 0.0127\n",
      "Epoch 11/80\n",
      "92/92 [==============================] - 1s 16ms/step - loss: 0.0342 - val_loss: 0.0116\n",
      "Epoch 12/80\n",
      "92/92 [==============================] - 2s 16ms/step - loss: 0.0322 - val_loss: 0.0109\n",
      "Epoch 13/80\n",
      "92/92 [==============================] - 2s 17ms/step - loss: 0.0301 - val_loss: 0.0109\n",
      "Epoch 14/80\n",
      "92/92 [==============================] - 1s 16ms/step - loss: 0.0294 - val_loss: 0.0112\n",
      "Epoch 15/80\n",
      "92/92 [==============================] - 1s 16ms/step - loss: 0.0291 - val_loss: 0.0118\n",
      "Epoch 16/80\n",
      "92/92 [==============================] - 1s 16ms/step - loss: 0.0288 - val_loss: 0.0126\n",
      "Epoch 17/80\n",
      "92/92 [==============================] - 1s 16ms/step - loss: 0.0286 - val_loss: 0.0128\n",
      "Epoch 18/80\n",
      "92/92 [==============================] - 1s 16ms/step - loss: 0.0284 - val_loss: 0.0130\n",
      "Epoch 19/80\n",
      "92/92 [==============================] - 1s 16ms/step - loss: 0.0284 - val_loss: 0.0132\n",
      "Epoch 20/80\n",
      "92/92 [==============================] - 1s 16ms/step - loss: 0.0283 - val_loss: 0.0133\n",
      "Epoch 21/80\n",
      "92/92 [==============================] - 1s 16ms/step - loss: 0.0282 - val_loss: 0.0134\n",
      "Epoch 22/80\n",
      "92/92 [==============================] - 1s 16ms/step - loss: 0.0282 - val_loss: 0.0134\n",
      "Epoch 23/80\n",
      "92/92 [==============================] - 2s 17ms/step - loss: 0.0281 - val_loss: 0.0136\n",
      "Epoch 24/80\n",
      "92/92 [==============================] - 2s 17ms/step - loss: 0.0281 - val_loss: 0.0135\n",
      "Epoch 25/80\n",
      "92/92 [==============================] - 1s 16ms/step - loss: 0.0280 - val_loss: 0.0136\n",
      "Epoch 26/80\n",
      "92/92 [==============================] - 1s 16ms/step - loss: 0.0280 - val_loss: 0.0136\n",
      "Epoch 27/80\n",
      "92/92 [==============================] - 1s 16ms/step - loss: 0.0280 - val_loss: 0.0136\n",
      "Epoch 28/80\n",
      "92/92 [==============================] - 1s 16ms/step - loss: 0.0280 - val_loss: 0.0136\n",
      "Epoch 29/80\n",
      "92/92 [==============================] - 1s 16ms/step - loss: 0.0280 - val_loss: 0.0136\n",
      "Epoch 30/80\n",
      "92/92 [==============================] - 1s 16ms/step - loss: 0.0280 - val_loss: 0.0136\n",
      "Epoch 31/80\n",
      "92/92 [==============================] - 1s 16ms/step - loss: 0.0280 - val_loss: 0.0136\n",
      "Epoch 32/80\n",
      "92/92 [==============================] - 1s 16ms/step - loss: 0.0280 - val_loss: 0.0136\n",
      "Epoch 33/80\n",
      "92/92 [==============================] - 1s 16ms/step - loss: 0.0280 - val_loss: 0.0136\n",
      "Epoch 34/80\n",
      "92/92 [==============================] - 2s 17ms/step - loss: 0.0280 - val_loss: 0.0137\n",
      "Epoch 35/80\n",
      "92/92 [==============================] - 2s 17ms/step - loss: 0.0280 - val_loss: 0.0137\n",
      "Epoch 36/80\n",
      "92/92 [==============================] - 1s 16ms/step - loss: 0.0280 - val_loss: 0.0137\n",
      "Epoch 37/80\n",
      "92/92 [==============================] - 1s 16ms/step - loss: 0.0280 - val_loss: 0.0137\n",
      "Epoch 38/80\n",
      "92/92 [==============================] - 1s 16ms/step - loss: 0.0279 - val_loss: 0.0136\n",
      "Epoch 39/80\n",
      "92/92 [==============================] - 1s 16ms/step - loss: 0.0280 - val_loss: 0.0136\n",
      "Epoch 40/80\n",
      "92/92 [==============================] - 1s 16ms/step - loss: 0.0279 - val_loss: 0.0137\n",
      "Epoch 41/80\n",
      "92/92 [==============================] - 1s 16ms/step - loss: 0.0279 - val_loss: 0.0137\n",
      "Epoch 42/80\n",
      "92/92 [==============================] - 1s 16ms/step - loss: 0.0279 - val_loss: 0.0137\n",
      "Epoch 43/80\n",
      "92/92 [==============================] - 1s 16ms/step - loss: 0.0279 - val_loss: 0.0137\n",
      "Epoch 44/80\n",
      "92/92 [==============================] - 2s 16ms/step - loss: 0.0280 - val_loss: 0.0137\n",
      "Epoch 45/80\n",
      "92/92 [==============================] - 2s 17ms/step - loss: 0.0279 - val_loss: 0.0137\n",
      "Epoch 46/80\n",
      "92/92 [==============================] - 2s 17ms/step - loss: 0.0279 - val_loss: 0.0137\n",
      "Epoch 47/80\n",
      "92/92 [==============================] - 1s 16ms/step - loss: 0.0279 - val_loss: 0.0137\n",
      "Epoch 48/80\n",
      "92/92 [==============================] - 1s 16ms/step - loss: 0.0279 - val_loss: 0.0137\n",
      "Epoch 49/80\n",
      "92/92 [==============================] - 1s 16ms/step - loss: 0.0279 - val_loss: 0.0137\n",
      "Epoch 50/80\n",
      "92/92 [==============================] - 1s 16ms/step - loss: 0.0279 - val_loss: 0.0137\n",
      "Epoch 51/80\n",
      "92/92 [==============================] - 1s 16ms/step - loss: 0.0279 - val_loss: 0.0137\n",
      "Epoch 52/80\n",
      "92/92 [==============================] - 1s 16ms/step - loss: 0.0279 - val_loss: 0.0137\n",
      "Epoch 53/80\n",
      "92/92 [==============================] - 1s 16ms/step - loss: 0.0279 - val_loss: 0.0137\n",
      "Epoch 54/80\n",
      "92/92 [==============================] - 1s 16ms/step - loss: 0.0279 - val_loss: 0.0137\n",
      "Epoch 55/80\n",
      "92/92 [==============================] - 2s 17ms/step - loss: 0.0279 - val_loss: 0.0137\n",
      "Epoch 56/80\n",
      "92/92 [==============================] - 2s 17ms/step - loss: 0.0279 - val_loss: 0.0137\n",
      "Epoch 57/80\n",
      "92/92 [==============================] - 1s 16ms/step - loss: 0.0279 - val_loss: 0.0137\n",
      "Epoch 58/80\n",
      "92/92 [==============================] - 1s 16ms/step - loss: 0.0279 - val_loss: 0.0137\n",
      "Epoch 59/80\n",
      "92/92 [==============================] - 1s 16ms/step - loss: 0.0279 - val_loss: 0.0137\n",
      "Epoch 60/80\n",
      "92/92 [==============================] - 1s 16ms/step - loss: 0.0279 - val_loss: 0.0137\n",
      "Epoch 61/80\n",
      "92/92 [==============================] - 1s 16ms/step - loss: 0.0279 - val_loss: 0.0137\n",
      "Epoch 62/80\n",
      "92/92 [==============================] - 1s 16ms/step - loss: 0.0279 - val_loss: 0.0137\n",
      "Epoch 63/80\n",
      "92/92 [==============================] - 1s 16ms/step - loss: 0.0279 - val_loss: 0.0137\n",
      "Epoch 64/80\n",
      "92/92 [==============================] - 1s 16ms/step - loss: 0.0279 - val_loss: 0.0137\n",
      "Epoch 65/80\n",
      "92/92 [==============================] - 2s 16ms/step - loss: 0.0279 - val_loss: 0.0137\n",
      "Epoch 66/80\n",
      "92/92 [==============================] - 2s 17ms/step - loss: 0.0279 - val_loss: 0.0137\n",
      "Epoch 67/80\n",
      "92/92 [==============================] - 2s 16ms/step - loss: 0.0279 - val_loss: 0.0137\n",
      "Epoch 68/80\n",
      "92/92 [==============================] - 1s 16ms/step - loss: 0.0279 - val_loss: 0.0137\n",
      "Epoch 69/80\n",
      "92/92 [==============================] - 1s 16ms/step - loss: 0.0279 - val_loss: 0.0137\n",
      "Epoch 70/80\n",
      "92/92 [==============================] - 1s 16ms/step - loss: 0.0279 - val_loss: 0.0137\n",
      "Epoch 71/80\n",
      "92/92 [==============================] - 1s 16ms/step - loss: 0.0279 - val_loss: 0.0137\n",
      "Epoch 72/80\n",
      "92/92 [==============================] - 1s 16ms/step - loss: 0.0279 - val_loss: 0.0137\n",
      "Epoch 73/80\n",
      "92/92 [==============================] - 1s 16ms/step - loss: 0.0279 - val_loss: 0.0137\n",
      "Epoch 74/80\n",
      "92/92 [==============================] - 1s 16ms/step - loss: 0.0279 - val_loss: 0.0137\n",
      "Epoch 75/80\n",
      "92/92 [==============================] - 1s 16ms/step - loss: 0.0279 - val_loss: 0.0137\n",
      "Epoch 76/80\n",
      "92/92 [==============================] - 2s 17ms/step - loss: 0.0279 - val_loss: 0.0137\n",
      "Epoch 77/80\n",
      "92/92 [==============================] - 2s 17ms/step - loss: 0.0279 - val_loss: 0.0137\n",
      "Epoch 78/80\n",
      "92/92 [==============================] - 1s 16ms/step - loss: 0.0279 - val_loss: 0.0137\n",
      "Epoch 79/80\n",
      "92/92 [==============================] - 1s 16ms/step - loss: 0.0279 - val_loss: 0.0137\n",
      "Epoch 80/80\n",
      "92/92 [==============================] - 1s 16ms/step - loss: 0.0279 - val_loss: 0.0137\n",
      "Execution time:  121.11843204498291\n",
      "DNN:\n",
      "Mean Absolute Error: 0.0252\n",
      "Root Mean Square Error: 0.0436\n",
      "Mean Square Error: 0.0019\n",
      "\n",
      "Train RMSE: 0.044\n",
      "Train MSE: 0.002\n",
      "Train MAE: 0.025\n",
      "###########################\n",
      "\n",
      "MODEL:  DNN\n",
      "sequence:  3d\n",
      "units:  80\n",
      "dropout1:  0.11814836227952394\n",
      "optimizer: adam\n",
      "activationDense: tanh\n",
      "epochs: 90\n",
      "batchsize: 25\n",
      "validation_split: 0.2\n",
      "Model: \"sequential_184\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_552 (Dense)            (None, 432, 80)           160       \n",
      "_________________________________________________________________\n",
      "dense_553 (Dense)            (None, 432, 16)           1296      \n",
      "_________________________________________________________________\n",
      "dropout_184 (Dropout)        (None, 432, 16)           0         \n",
      "_________________________________________________________________\n",
      "dense_554 (Dense)            (None, 432, 1)            17        \n",
      "=================================================================\n",
      "Total params: 1,473\n",
      "Trainable params: 1,473\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/90\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "114/114 [==============================] - 2s 14ms/step - loss: 0.1489 - val_loss: 0.0193\n",
      "Epoch 2/90\n",
      "114/114 [==============================] - 1s 12ms/step - loss: 0.0543 - val_loss: 0.0196\n",
      "Epoch 3/90\n",
      "114/114 [==============================] - 1s 12ms/step - loss: 0.0520 - val_loss: 0.0160\n",
      "Epoch 4/90\n",
      "114/114 [==============================] - 1s 12ms/step - loss: 0.0498 - val_loss: 0.0168\n",
      "Epoch 5/90\n",
      "114/114 [==============================] - 1s 12ms/step - loss: 0.0475 - val_loss: 0.0148\n",
      "Epoch 6/90\n",
      "114/114 [==============================] - 1s 13ms/step - loss: 0.0453 - val_loss: 0.0137\n",
      "Epoch 7/90\n",
      "114/114 [==============================] - 1s 13ms/step - loss: 0.0435 - val_loss: 0.0127\n",
      "Epoch 8/90\n",
      "114/114 [==============================] - 1s 12ms/step - loss: 0.0417 - val_loss: 0.0119\n",
      "Epoch 9/90\n",
      "114/114 [==============================] - 1s 12ms/step - loss: 0.0404 - val_loss: 0.0124\n",
      "Epoch 10/90\n",
      "114/114 [==============================] - 1s 12ms/step - loss: 0.0393 - val_loss: 0.0134\n",
      "Epoch 11/90\n",
      "114/114 [==============================] - 1s 12ms/step - loss: 0.0386 - val_loss: 0.0142\n",
      "Epoch 12/90\n",
      "114/114 [==============================] - 1s 12ms/step - loss: 0.0378 - val_loss: 0.0144\n",
      "Epoch 13/90\n",
      "114/114 [==============================] - 1s 12ms/step - loss: 0.0370 - val_loss: 0.0113\n",
      "Epoch 14/90\n",
      "114/114 [==============================] - 1s 12ms/step - loss: 0.0351 - val_loss: 0.0126\n",
      "Epoch 15/90\n",
      "114/114 [==============================] - 1s 12ms/step - loss: 0.0355 - val_loss: 0.0112\n",
      "Epoch 16/90\n",
      "114/114 [==============================] - 1s 12ms/step - loss: 0.0343 - val_loss: 0.0119\n",
      "Epoch 17/90\n",
      "114/114 [==============================] - 1s 13ms/step - loss: 0.0338 - val_loss: 0.0119\n",
      "Epoch 18/90\n",
      "114/114 [==============================] - 1s 13ms/step - loss: 0.0333 - val_loss: 0.0115\n",
      "Epoch 19/90\n",
      "114/114 [==============================] - 1s 12ms/step - loss: 0.0325 - val_loss: 0.0114\n",
      "Epoch 20/90\n",
      "114/114 [==============================] - 1s 12ms/step - loss: 0.0319 - val_loss: 0.0112\n",
      "Epoch 21/90\n",
      "114/114 [==============================] - 1s 12ms/step - loss: 0.0314 - val_loss: 0.0111\n",
      "Epoch 22/90\n",
      "114/114 [==============================] - 1s 12ms/step - loss: 0.0309 - val_loss: 0.0111\n",
      "Epoch 23/90\n",
      "114/114 [==============================] - 1s 12ms/step - loss: 0.0306 - val_loss: 0.0109\n",
      "Epoch 24/90\n",
      "114/114 [==============================] - 1s 12ms/step - loss: 0.0302 - val_loss: 0.0109\n",
      "Epoch 25/90\n",
      "114/114 [==============================] - 1s 12ms/step - loss: 0.0300 - val_loss: 0.0109\n",
      "Epoch 26/90\n",
      "114/114 [==============================] - 1s 12ms/step - loss: 0.0298 - val_loss: 0.0110\n",
      "Epoch 27/90\n",
      "114/114 [==============================] - 1s 12ms/step - loss: 0.0295 - val_loss: 0.0109\n",
      "Epoch 28/90\n",
      "114/114 [==============================] - 1s 13ms/step - loss: 0.0294 - val_loss: 0.0109\n",
      "Epoch 29/90\n",
      "114/114 [==============================] - 1s 13ms/step - loss: 0.0293 - val_loss: 0.0109\n",
      "Epoch 30/90\n",
      "114/114 [==============================] - 1s 12ms/step - loss: 0.0292 - val_loss: 0.0108\n",
      "Epoch 31/90\n",
      "114/114 [==============================] - 1s 12ms/step - loss: 0.0288 - val_loss: 0.0109\n",
      "Epoch 32/90\n",
      "114/114 [==============================] - 1s 12ms/step - loss: 0.0291 - val_loss: 0.0109\n",
      "Epoch 33/90\n",
      "114/114 [==============================] - 1s 12ms/step - loss: 0.0290 - val_loss: 0.0109\n",
      "Epoch 34/90\n",
      "114/114 [==============================] - 1s 12ms/step - loss: 0.0289 - val_loss: 0.0110\n",
      "Epoch 35/90\n",
      "114/114 [==============================] - 1s 12ms/step - loss: 0.0288 - val_loss: 0.0112\n",
      "Epoch 36/90\n",
      "114/114 [==============================] - 1s 12ms/step - loss: 0.0288 - val_loss: 0.0114\n",
      "Epoch 37/90\n",
      "114/114 [==============================] - 1s 12ms/step - loss: 0.0287 - val_loss: 0.0116\n",
      "Epoch 38/90\n",
      "114/114 [==============================] - 1s 12ms/step - loss: 0.0287 - val_loss: 0.0117\n",
      "Epoch 39/90\n",
      "114/114 [==============================] - 1s 12ms/step - loss: 0.0287 - val_loss: 0.0119\n",
      "Epoch 40/90\n",
      "114/114 [==============================] - 2s 13ms/step - loss: 0.0286 - val_loss: 0.0120\n",
      "Epoch 41/90\n",
      "114/114 [==============================] - 1s 13ms/step - loss: 0.0286 - val_loss: 0.0121\n",
      "Epoch 42/90\n",
      "114/114 [==============================] - 1s 12ms/step - loss: 0.0286 - val_loss: 0.0122\n",
      "Epoch 43/90\n",
      "114/114 [==============================] - 1s 12ms/step - loss: 0.0285 - val_loss: 0.0122\n",
      "Epoch 44/90\n",
      "114/114 [==============================] - 1s 12ms/step - loss: 0.0282 - val_loss: 0.0175\n",
      "Epoch 45/90\n",
      "114/114 [==============================] - 1s 12ms/step - loss: 0.0299 - val_loss: 0.0122\n",
      "Epoch 46/90\n",
      "114/114 [==============================] - 1s 12ms/step - loss: 0.0286 - val_loss: 0.0111\n",
      "Epoch 47/90\n",
      "114/114 [==============================] - 1s 13ms/step - loss: 0.0282 - val_loss: 0.0118\n",
      "Epoch 48/90\n",
      "114/114 [==============================] - 1s 12ms/step - loss: 0.0286 - val_loss: 0.0125\n",
      "Epoch 49/90\n",
      "114/114 [==============================] - 1s 12ms/step - loss: 0.0283 - val_loss: 0.0124\n",
      "Epoch 50/90\n",
      "114/114 [==============================] - 1s 13ms/step - loss: 0.0283 - val_loss: 0.0125\n",
      "Epoch 51/90\n",
      "114/114 [==============================] - 2s 13ms/step - loss: 0.0283 - val_loss: 0.0125\n",
      "Epoch 52/90\n",
      "114/114 [==============================] - 1s 13ms/step - loss: 0.0283 - val_loss: 0.0126\n",
      "Epoch 53/90\n",
      "114/114 [==============================] - 1s 12ms/step - loss: 0.0283 - val_loss: 0.0125\n",
      "Epoch 54/90\n",
      "114/114 [==============================] - 1s 12ms/step - loss: 0.0282 - val_loss: 0.0125\n",
      "Epoch 55/90\n",
      "114/114 [==============================] - 1s 12ms/step - loss: 0.0283 - val_loss: 0.0126\n",
      "Epoch 56/90\n",
      "114/114 [==============================] - 1s 12ms/step - loss: 0.0282 - val_loss: 0.0125\n",
      "Epoch 57/90\n",
      "114/114 [==============================] - 1s 12ms/step - loss: 0.0282 - val_loss: 0.0125\n",
      "Epoch 58/90\n",
      "114/114 [==============================] - 1s 12ms/step - loss: 0.0283 - val_loss: 0.0126\n",
      "Epoch 59/90\n",
      "114/114 [==============================] - 1s 12ms/step - loss: 0.0282 - val_loss: 0.0125\n",
      "Epoch 60/90\n",
      "114/114 [==============================] - 1s 12ms/step - loss: 0.0283 - val_loss: 0.0126\n",
      "Epoch 61/90\n",
      "114/114 [==============================] - 1s 12ms/step - loss: 0.0282 - val_loss: 0.0125\n",
      "Epoch 62/90\n",
      "114/114 [==============================] - 2s 13ms/step - loss: 0.0283 - val_loss: 0.0126\n",
      "Epoch 63/90\n",
      "114/114 [==============================] - 1s 13ms/step - loss: 0.0282 - val_loss: 0.0125\n",
      "Epoch 64/90\n",
      "114/114 [==============================] - 1s 12ms/step - loss: 0.0282 - val_loss: 0.0125\n",
      "Epoch 65/90\n",
      "114/114 [==============================] - 1s 12ms/step - loss: 0.0283 - val_loss: 0.0126\n",
      "Epoch 66/90\n",
      "114/114 [==============================] - 1s 12ms/step - loss: 0.0282 - val_loss: 0.0125\n",
      "Epoch 67/90\n",
      "114/114 [==============================] - 1s 12ms/step - loss: 0.0283 - val_loss: 0.0126\n",
      "Epoch 68/90\n",
      "114/114 [==============================] - 1s 12ms/step - loss: 0.0282 - val_loss: 0.0125\n",
      "Epoch 69/90\n",
      "114/114 [==============================] - 1s 12ms/step - loss: 0.0283 - val_loss: 0.0126\n",
      "Epoch 70/90\n",
      "114/114 [==============================] - 1s 12ms/step - loss: 0.0282 - val_loss: 0.0125\n",
      "Epoch 71/90\n",
      "114/114 [==============================] - 1s 12ms/step - loss: 0.0283 - val_loss: 0.0126\n",
      "Epoch 72/90\n",
      "114/114 [==============================] - 1s 12ms/step - loss: 0.0282 - val_loss: 0.0125\n",
      "Epoch 73/90\n",
      "114/114 [==============================] - 2s 13ms/step - loss: 0.0283 - val_loss: 0.0126\n",
      "Epoch 74/90\n",
      "114/114 [==============================] - 1s 13ms/step - loss: 0.0282 - val_loss: 0.0125\n",
      "Epoch 75/90\n",
      "114/114 [==============================] - 1s 12ms/step - loss: 0.0283 - val_loss: 0.0126\n",
      "Epoch 76/90\n",
      "114/114 [==============================] - 1s 12ms/step - loss: 0.0282 - val_loss: 0.0125\n",
      "Epoch 77/90\n",
      "114/114 [==============================] - 1s 12ms/step - loss: 0.0283 - val_loss: 0.0126\n",
      "Epoch 78/90\n",
      "114/114 [==============================] - 1s 12ms/step - loss: 0.0282 - val_loss: 0.0125\n",
      "Epoch 79/90\n",
      "114/114 [==============================] - 1s 12ms/step - loss: 0.0283 - val_loss: 0.0126\n",
      "Epoch 80/90\n",
      "114/114 [==============================] - 1s 12ms/step - loss: 0.0282 - val_loss: 0.0125\n",
      "Epoch 81/90\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "114/114 [==============================] - 1s 12ms/step - loss: 0.0283 - val_loss: 0.0126\n",
      "Epoch 82/90\n",
      "114/114 [==============================] - 1s 12ms/step - loss: 0.0284 - val_loss: 0.0127\n",
      "Epoch 83/90\n",
      "114/114 [==============================] - 1s 12ms/step - loss: 0.0283 - val_loss: 0.0127\n",
      "Epoch 84/90\n",
      "114/114 [==============================] - 1s 13ms/step - loss: 0.0284 - val_loss: 0.0128\n",
      "Epoch 85/90\n",
      "114/114 [==============================] - 1s 13ms/step - loss: 0.0283 - val_loss: 0.0127\n",
      "Epoch 86/90\n",
      "114/114 [==============================] - 1s 12ms/step - loss: 0.0283 - val_loss: 0.0126\n",
      "Epoch 87/90\n",
      "114/114 [==============================] - 1s 12ms/step - loss: 0.0284 - val_loss: 0.0127\n",
      "Epoch 88/90\n",
      "114/114 [==============================] - 1s 12ms/step - loss: 0.0283 - val_loss: 0.0127\n",
      "Epoch 89/90\n",
      "114/114 [==============================] - 1s 12ms/step - loss: 0.0284 - val_loss: 0.0128\n",
      "Epoch 90/90\n",
      "114/114 [==============================] - 1s 12ms/step - loss: 0.0283 - val_loss: 0.0127\n",
      "Execution time:  129.84763097763062\n",
      "DNN:\n",
      "Mean Absolute Error: 0.0253\n",
      "Root Mean Square Error: 0.0445\n",
      "Mean Square Error: 0.0020\n",
      "\n",
      "Train RMSE: 0.044\n",
      "Train MSE: 0.002\n",
      "Train MAE: 0.025\n",
      "###########################\n",
      "\n",
      "MODEL:  DNN\n",
      "sequence:  3d\n",
      "units:  12\n",
      "dropout1:  0.48476373451509647\n",
      "optimizer: adam\n",
      "activationDense: tanh\n",
      "epochs: 52\n",
      "batchsize: 57\n",
      "validation_split: 0.2\n",
      "Model: \"sequential_185\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_555 (Dense)            (None, 432, 12)           24        \n",
      "_________________________________________________________________\n",
      "dense_556 (Dense)            (None, 432, 16)           208       \n",
      "_________________________________________________________________\n",
      "dropout_185 (Dropout)        (None, 432, 16)           0         \n",
      "_________________________________________________________________\n",
      "dense_557 (Dense)            (None, 432, 1)            17        \n",
      "=================================================================\n",
      "Total params: 249\n",
      "Trainable params: 249\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/52\n",
      "50/50 [==============================] - 1s 24ms/step - loss: 0.2455 - val_loss: 0.1232\n",
      "Epoch 2/52\n",
      "50/50 [==============================] - 1s 15ms/step - loss: 0.1460 - val_loss: 0.0556\n",
      "Epoch 3/52\n",
      "50/50 [==============================] - 1s 15ms/step - loss: 0.1189 - val_loss: 0.0169\n",
      "Epoch 4/52\n",
      "50/50 [==============================] - 1s 14ms/step - loss: 0.0968 - val_loss: 0.0226\n",
      "Epoch 5/52\n",
      "50/50 [==============================] - 1s 15ms/step - loss: 0.0876 - val_loss: 0.0177\n",
      "Epoch 6/52\n",
      "50/50 [==============================] - 1s 15ms/step - loss: 0.0776 - val_loss: 0.0114\n",
      "Epoch 7/52\n",
      "50/50 [==============================] - 1s 16ms/step - loss: 0.0699 - val_loss: 0.0113\n",
      "Epoch 8/52\n",
      "50/50 [==============================] - 1s 16ms/step - loss: 0.0643 - val_loss: 0.0113\n",
      "Epoch 9/52\n",
      "50/50 [==============================] - 1s 16ms/step - loss: 0.0590 - val_loss: 0.0112\n",
      "Epoch 10/52\n",
      "50/50 [==============================] - 1s 15ms/step - loss: 0.0540 - val_loss: 0.0111\n",
      "Epoch 11/52\n",
      "50/50 [==============================] - 1s 15ms/step - loss: 0.0505 - val_loss: 0.0109\n",
      "Epoch 12/52\n",
      "50/50 [==============================] - 1s 14ms/step - loss: 0.0457 - val_loss: 0.0112\n",
      "Epoch 13/52\n",
      "50/50 [==============================] - 1s 15ms/step - loss: 0.0422 - val_loss: 0.0109\n",
      "Epoch 14/52\n",
      "50/50 [==============================] - 1s 15ms/step - loss: 0.0395 - val_loss: 0.0109\n",
      "Epoch 15/52\n",
      "50/50 [==============================] - 1s 15ms/step - loss: 0.0372 - val_loss: 0.0112\n",
      "Epoch 16/52\n",
      "50/50 [==============================] - 1s 15ms/step - loss: 0.0352 - val_loss: 0.0116\n",
      "Epoch 17/52\n",
      "50/50 [==============================] - 1s 15ms/step - loss: 0.0336 - val_loss: 0.0119\n",
      "Epoch 18/52\n",
      "50/50 [==============================] - 1s 15ms/step - loss: 0.0322 - val_loss: 0.0121\n",
      "Epoch 19/52\n",
      "50/50 [==============================] - 1s 15ms/step - loss: 0.0310 - val_loss: 0.0135\n",
      "Epoch 20/52\n",
      "50/50 [==============================] - 1s 14ms/step - loss: 0.0297 - val_loss: 0.0136\n",
      "Epoch 21/52\n",
      "50/50 [==============================] - 1s 15ms/step - loss: 0.0290 - val_loss: 0.0137\n",
      "Epoch 22/52\n",
      "50/50 [==============================] - 1s 15ms/step - loss: 0.0283 - val_loss: 0.0136\n",
      "Epoch 23/52\n",
      "50/50 [==============================] - 1s 15ms/step - loss: 0.0281 - val_loss: 0.0137\n",
      "Epoch 24/52\n",
      "50/50 [==============================] - 1s 15ms/step - loss: 0.0280 - val_loss: 0.0138\n",
      "Epoch 25/52\n",
      "50/50 [==============================] - 1s 15ms/step - loss: 0.0280 - val_loss: 0.0140\n",
      "Epoch 26/52\n",
      "50/50 [==============================] - 1s 15ms/step - loss: 0.0279 - val_loss: 0.0141\n",
      "Epoch 27/52\n",
      "50/50 [==============================] - 1s 16ms/step - loss: 0.0278 - val_loss: 0.0142\n",
      "Epoch 28/52\n",
      "50/50 [==============================] - 1s 16ms/step - loss: 0.0277 - val_loss: 0.0143\n",
      "Epoch 29/52\n",
      "50/50 [==============================] - 1s 16ms/step - loss: 0.0277 - val_loss: 0.0144\n",
      "Epoch 30/52\n",
      "50/50 [==============================] - 1s 16ms/step - loss: 0.0276 - val_loss: 0.0146\n",
      "Epoch 31/52\n",
      "50/50 [==============================] - 1s 15ms/step - loss: 0.0275 - val_loss: 0.0147\n",
      "Epoch 32/52\n",
      "50/50 [==============================] - 1s 15ms/step - loss: 0.0275 - val_loss: 0.0147\n",
      "Epoch 33/52\n",
      "50/50 [==============================] - 1s 15ms/step - loss: 0.0274 - val_loss: 0.0147\n",
      "Epoch 34/52\n",
      "50/50 [==============================] - 1s 14ms/step - loss: 0.0274 - val_loss: 0.0148\n",
      "Epoch 35/52\n",
      "50/50 [==============================] - 1s 15ms/step - loss: 0.0273 - val_loss: 0.0150\n",
      "Epoch 36/52\n",
      "50/50 [==============================] - 1s 15ms/step - loss: 0.0273 - val_loss: 0.0150\n",
      "Epoch 37/52\n",
      "50/50 [==============================] - 1s 15ms/step - loss: 0.0273 - val_loss: 0.0150\n",
      "Epoch 38/52\n",
      "50/50 [==============================] - 1s 16ms/step - loss: 0.0273 - val_loss: 0.0151\n",
      "Epoch 39/52\n",
      "50/50 [==============================] - 1s 16ms/step - loss: 0.0273 - val_loss: 0.0142\n",
      "Epoch 40/52\n",
      "50/50 [==============================] - 1s 17ms/step - loss: 0.0274 - val_loss: 0.0149\n",
      "Epoch 41/52\n",
      "50/50 [==============================] - 1s 16ms/step - loss: 0.0272 - val_loss: 0.0151\n",
      "Epoch 42/52\n",
      "50/50 [==============================] - 1s 17ms/step - loss: 0.0272 - val_loss: 0.0151\n",
      "Epoch 43/52\n",
      "50/50 [==============================] - 1s 15ms/step - loss: 0.0272 - val_loss: 0.0151\n",
      "Epoch 44/52\n",
      "50/50 [==============================] - 1s 16ms/step - loss: 0.0272 - val_loss: 0.0152\n",
      "Epoch 45/52\n",
      "50/50 [==============================] - 1s 15ms/step - loss: 0.0272 - val_loss: 0.0151\n",
      "Epoch 46/52\n",
      "50/50 [==============================] - 1s 15ms/step - loss: 0.0272 - val_loss: 0.0151\n",
      "Epoch 47/52\n",
      "50/50 [==============================] - 1s 15ms/step - loss: 0.0272 - val_loss: 0.0150\n",
      "Epoch 48/52\n",
      "50/50 [==============================] - 1s 16ms/step - loss: 0.0272 - val_loss: 0.0152\n",
      "Epoch 49/52\n",
      "50/50 [==============================] - 1s 16ms/step - loss: 0.0272 - val_loss: 0.0151\n",
      "Epoch 50/52\n",
      "50/50 [==============================] - 1s 16ms/step - loss: 0.0272 - val_loss: 0.0151\n",
      "Epoch 51/52\n",
      "50/50 [==============================] - 1s 16ms/step - loss: 0.0272 - val_loss: 0.0152\n",
      "Epoch 52/52\n",
      "50/50 [==============================] - 1s 15ms/step - loss: 0.0271 - val_loss: 0.0150\n",
      "Execution time:  41.80355381965637\n",
      "DNN:\n",
      "Mean Absolute Error: 0.0248\n",
      "Root Mean Square Error: 0.0420\n",
      "Mean Square Error: 0.0018\n",
      "\n",
      "Train RMSE: 0.042\n",
      "Train MSE: 0.002\n",
      "Train MAE: 0.025\n",
      "###########################\n",
      "\n",
      "MODEL:  DNN\n",
      "sequence:  3d\n",
      "units:  87\n",
      "dropout1:  0.40519643149940265\n",
      "optimizer: adam\n",
      "activationDense: sigmoid\n",
      "epochs: 80\n",
      "batchsize: 31\n",
      "validation_split: 0.1\n",
      "Model: \"sequential_186\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_558 (Dense)            (None, 432, 87)           174       \n",
      "_________________________________________________________________\n",
      "dense_559 (Dense)            (None, 432, 16)           1408      \n",
      "_________________________________________________________________\n",
      "dropout_186 (Dropout)        (None, 432, 16)           0         \n",
      "_________________________________________________________________\n",
      "dense_560 (Dense)            (None, 432, 1)            17        \n",
      "=================================================================\n",
      "Total params: 1,599\n",
      "Trainable params: 1,599\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/80\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "104/104 [==============================] - 2s 17ms/step - loss: 0.0571 - val_loss: 0.0343\n",
      "Epoch 2/80\n",
      "104/104 [==============================] - 2s 15ms/step - loss: 0.0414 - val_loss: 0.0257\n",
      "Epoch 3/80\n",
      "104/104 [==============================] - 2s 15ms/step - loss: 0.0391 - val_loss: 0.0246\n",
      "Epoch 4/80\n",
      "104/104 [==============================] - 2s 15ms/step - loss: 0.0379 - val_loss: 0.0231\n",
      "Epoch 5/80\n",
      "104/104 [==============================] - 2s 15ms/step - loss: 0.0362 - val_loss: 0.0218\n",
      "Epoch 6/80\n",
      "104/104 [==============================] - 2s 15ms/step - loss: 0.0347 - val_loss: 0.0211\n",
      "Epoch 7/80\n",
      "104/104 [==============================] - 2s 16ms/step - loss: 0.0334 - val_loss: 0.0209\n",
      "Epoch 8/80\n",
      "104/104 [==============================] - 2s 17ms/step - loss: 0.0323 - val_loss: 0.0201\n",
      "Epoch 9/80\n",
      "104/104 [==============================] - 2s 16ms/step - loss: 0.0313 - val_loss: 0.0195\n",
      "Epoch 10/80\n",
      "104/104 [==============================] - 2s 15ms/step - loss: 0.0304 - val_loss: 0.0190\n",
      "Epoch 11/80\n",
      "104/104 [==============================] - 2s 15ms/step - loss: 0.0296 - val_loss: 0.0183\n",
      "Epoch 12/80\n",
      "104/104 [==============================] - 2s 15ms/step - loss: 0.0289 - val_loss: 0.0179\n",
      "Epoch 13/80\n",
      "104/104 [==============================] - 2s 15ms/step - loss: 0.0284 - val_loss: 0.0175\n",
      "Epoch 14/80\n",
      "104/104 [==============================] - 2s 15ms/step - loss: 0.0279 - val_loss: 0.0172\n",
      "Epoch 15/80\n",
      "104/104 [==============================] - 2s 15ms/step - loss: 0.0273 - val_loss: 0.0229\n",
      "Epoch 16/80\n",
      "104/104 [==============================] - 2s 15ms/step - loss: 0.0268 - val_loss: 0.0182\n",
      "Epoch 17/80\n",
      "104/104 [==============================] - 2s 16ms/step - loss: 0.0268 - val_loss: 0.0166\n",
      "Epoch 18/80\n",
      "104/104 [==============================] - 2s 16ms/step - loss: 0.0267 - val_loss: 0.0163\n",
      "Epoch 19/80\n",
      "104/104 [==============================] - 2s 16ms/step - loss: 0.0265 - val_loss: 0.0164\n",
      "Epoch 20/80\n",
      "104/104 [==============================] - 2s 15ms/step - loss: 0.0263 - val_loss: 0.0165\n",
      "Epoch 21/80\n",
      "104/104 [==============================] - 2s 15ms/step - loss: 0.0261 - val_loss: 0.0166\n",
      "Epoch 22/80\n",
      "104/104 [==============================] - 2s 15ms/step - loss: 0.0260 - val_loss: 0.0166\n",
      "Epoch 23/80\n",
      "104/104 [==============================] - 2s 15ms/step - loss: 0.0259 - val_loss: 0.0165\n",
      "Epoch 24/80\n",
      "104/104 [==============================] - 2s 15ms/step - loss: 0.0258 - val_loss: 0.0165\n",
      "Epoch 25/80\n",
      "104/104 [==============================] - 2s 15ms/step - loss: 0.0257 - val_loss: 0.0164\n",
      "Epoch 26/80\n",
      "104/104 [==============================] - 2s 15ms/step - loss: 0.0256 - val_loss: 0.0163\n",
      "Epoch 27/80\n",
      "104/104 [==============================] - 2s 16ms/step - loss: 0.0256 - val_loss: 0.0163\n",
      "Epoch 28/80\n",
      "104/104 [==============================] - 2s 16ms/step - loss: 0.0255 - val_loss: 0.0165\n",
      "Epoch 29/80\n",
      "104/104 [==============================] - 2s 15ms/step - loss: 0.0255 - val_loss: 0.0173\n",
      "Epoch 30/80\n",
      "104/104 [==============================] - 2s 15ms/step - loss: 0.0256 - val_loss: 0.0182\n",
      "Epoch 31/80\n",
      "104/104 [==============================] - 2s 15ms/step - loss: 0.0252 - val_loss: 0.0173\n",
      "Epoch 32/80\n",
      "104/104 [==============================] - 2s 15ms/step - loss: 0.0252 - val_loss: 0.0172\n",
      "Epoch 33/80\n",
      "104/104 [==============================] - 2s 15ms/step - loss: 0.0252 - val_loss: 0.0172- l\n",
      "Epoch 34/80\n",
      "104/104 [==============================] - 2s 15ms/step - loss: 0.0252 - val_loss: 0.0173\n",
      "Epoch 35/80\n",
      "104/104 [==============================] - 2s 15ms/step - loss: 0.0252 - val_loss: 0.0177\n",
      "Epoch 36/80\n",
      "104/104 [==============================] - 2s 15ms/step - loss: 0.0251 - val_loss: 0.0177\n",
      "Epoch 37/80\n",
      "104/104 [==============================] - 2s 16ms/step - loss: 0.0250 - val_loss: 0.0171\n",
      "Epoch 38/80\n",
      "104/104 [==============================] - 2s 16ms/step - loss: 0.0251 - val_loss: 0.0181\n",
      "Epoch 39/80\n",
      "104/104 [==============================] - 2s 15ms/step - loss: 0.0250 - val_loss: 0.0168\n",
      "Epoch 40/80\n",
      "104/104 [==============================] - 2s 15ms/step - loss: 0.0252 - val_loss: 0.0180\n",
      "Epoch 41/80\n",
      "104/104 [==============================] - 2s 15ms/step - loss: 0.0250 - val_loss: 0.0179\n",
      "Epoch 42/80\n",
      "104/104 [==============================] - 2s 15ms/step - loss: 0.0250 - val_loss: 0.0184\n",
      "Epoch 43/80\n",
      "104/104 [==============================] - 2s 15ms/step - loss: 0.0250 - val_loss: 0.0183\n",
      "Epoch 44/80\n",
      "104/104 [==============================] - 2s 15ms/step - loss: 0.0250 - val_loss: 0.0183\n",
      "Epoch 45/80\n",
      "104/104 [==============================] - 2s 15ms/step - loss: 0.0250 - val_loss: 0.0184\n",
      "Epoch 46/80\n",
      "104/104 [==============================] - 2s 15ms/step - loss: 0.0250 - val_loss: 0.0183\n",
      "Epoch 47/80\n",
      "104/104 [==============================] - 2s 16ms/step - loss: 0.0250 - val_loss: 0.0184\n",
      "Epoch 48/80\n",
      "104/104 [==============================] - 2s 16ms/step - loss: 0.0250 - val_loss: 0.0183\n",
      "Epoch 49/80\n",
      "104/104 [==============================] - 2s 15ms/step - loss: 0.0250 - val_loss: 0.0184\n",
      "Epoch 50/80\n",
      "104/104 [==============================] - 2s 15ms/step - loss: 0.0250 - val_loss: 0.0183\n",
      "Epoch 51/80\n",
      "104/104 [==============================] - 2s 15ms/step - loss: 0.0250 - val_loss: 0.0183\n",
      "Epoch 52/80\n",
      "104/104 [==============================] - 2s 15ms/step - loss: 0.0250 - val_loss: 0.0184\n",
      "Epoch 53/80\n",
      "104/104 [==============================] - 2s 15ms/step - loss: 0.0250 - val_loss: 0.0183\n",
      "Epoch 54/80\n",
      "104/104 [==============================] - 2s 15ms/step - loss: 0.0250 - val_loss: 0.0184\n",
      "Epoch 55/80\n",
      "104/104 [==============================] - 2s 15ms/step - loss: 0.0250 - val_loss: 0.0184\n",
      "Epoch 56/80\n",
      "104/104 [==============================] - 2s 15ms/step - loss: 0.0250 - val_loss: 0.0183\n",
      "Epoch 57/80\n",
      "104/104 [==============================] - 2s 16ms/step - loss: 0.0250 - val_loss: 0.0183\n",
      "Epoch 58/80\n",
      "104/104 [==============================] - 2s 16ms/step - loss: 0.0250 - val_loss: 0.0184\n",
      "Epoch 59/80\n",
      "104/104 [==============================] - 2s 15ms/step - loss: 0.0250 - val_loss: 0.0183\n",
      "Epoch 60/80\n",
      "104/104 [==============================] - 2s 15ms/step - loss: 0.0250 - val_loss: 0.0184\n",
      "Epoch 61/80\n",
      "104/104 [==============================] - 2s 15ms/step - loss: 0.0250 - val_loss: 0.0184\n",
      "Epoch 62/80\n",
      "104/104 [==============================] - 2s 15ms/step - loss: 0.0250 - val_loss: 0.0184\n",
      "Epoch 63/80\n",
      "104/104 [==============================] - 2s 15ms/step - loss: 0.0250 - val_loss: 0.0184\n",
      "Epoch 64/80\n",
      "104/104 [==============================] - 2s 15ms/step - loss: 0.0250 - val_loss: 0.0183\n",
      "Epoch 65/80\n",
      "104/104 [==============================] - 2s 15ms/step - loss: 0.0250 - val_loss: 0.0184\n",
      "Epoch 66/80\n",
      "104/104 [==============================] - 2s 15ms/step - loss: 0.0250 - val_loss: 0.0184\n",
      "Epoch 67/80\n",
      "104/104 [==============================] - 2s 16ms/step - loss: 0.0250 - val_loss: 0.0184\n",
      "Epoch 68/80\n",
      "104/104 [==============================] - 2s 16ms/step - loss: 0.0250 - val_loss: 0.0184\n",
      "Epoch 69/80\n",
      "104/104 [==============================] - 2s 15ms/step - loss: 0.0250 - val_loss: 0.0183\n",
      "Epoch 70/80\n",
      "104/104 [==============================] - 2s 15ms/step - loss: 0.0250 - val_loss: 0.0184\n",
      "Epoch 71/80\n",
      "104/104 [==============================] - 2s 15ms/step - loss: 0.0250 - val_loss: 0.0184\n",
      "Epoch 72/80\n",
      "104/104 [==============================] - 2s 15ms/step - loss: 0.0250 - val_loss: 0.0183\n",
      "Epoch 73/80\n",
      "104/104 [==============================] - 2s 15ms/step - loss: 0.0250 - val_loss: 0.0184\n",
      "Epoch 74/80\n",
      "104/104 [==============================] - 2s 15ms/step - loss: 0.0250 - val_loss: 0.0184\n",
      "Epoch 75/80\n",
      "104/104 [==============================] - 2s 15ms/step - loss: 0.0250 - val_loss: 0.0184\n",
      "Epoch 76/80\n",
      "104/104 [==============================] - 2s 15ms/step - loss: 0.0250 - val_loss: 0.0184\n",
      "Epoch 77/80\n",
      "104/104 [==============================] - 2s 16ms/step - loss: 0.0250 - val_loss: 0.0184\n",
      "Epoch 78/80\n",
      "104/104 [==============================] - 2s 16ms/step - loss: 0.0250 - val_loss: 0.0184\n",
      "Epoch 79/80\n",
      "104/104 [==============================] - 2s 15ms/step - loss: 0.0250 - val_loss: 0.0184\n",
      "Epoch 80/80\n",
      "104/104 [==============================] - 2s 15ms/step - loss: 0.0250 - val_loss: 0.0183\n",
      "Execution time:  130.35565376281738\n",
      "DNN:\n",
      "Mean Absolute Error: 0.0251\n",
      "Root Mean Square Error: 0.0431\n",
      "Mean Square Error: 0.0019\n",
      "\n",
      "Train RMSE: 0.043\n",
      "Train MSE: 0.002\n",
      "Train MAE: 0.025\n",
      "###########################\n",
      "\n",
      "MODEL:  DNN\n",
      "sequence:  3d\n",
      "units:  80\n",
      "dropout1:  0.11814836227952394\n",
      "optimizer: adam\n",
      "activationDense: sigmoid\n",
      "epochs: 90\n",
      "batchsize: 25\n",
      "validation_split: 0.1\n",
      "Model: \"sequential_187\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_561 (Dense)            (None, 432, 80)           160       \n",
      "_________________________________________________________________\n",
      "dense_562 (Dense)            (None, 432, 16)           1296      \n",
      "_________________________________________________________________\n",
      "dropout_187 (Dropout)        (None, 432, 16)           0         \n",
      "_________________________________________________________________\n",
      "dense_563 (Dense)            (None, 432, 1)            17        \n",
      "=================================================================\n",
      "Total params: 1,473\n",
      "Trainable params: 1,473\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/90\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "129/129 [==============================] - 2s 13ms/step - loss: 0.0476 - val_loss: 0.0262\n",
      "Epoch 2/90\n",
      "129/129 [==============================] - 2s 12ms/step - loss: 0.0330 - val_loss: 0.0303\n",
      "Epoch 3/90\n",
      "129/129 [==============================] - 2s 12ms/step - loss: 0.0338 - val_loss: 0.0239\n",
      "Epoch 4/90\n",
      "129/129 [==============================] - 1s 12ms/step - loss: 0.0323 - val_loss: 0.0284\n",
      "Epoch 5/90\n",
      "129/129 [==============================] - 2s 12ms/step - loss: 0.0325 - val_loss: 0.0218\n",
      "Epoch 6/90\n",
      "129/129 [==============================] - 2s 13ms/step - loss: 0.0316 - val_loss: 0.0195\n",
      "Epoch 7/90\n",
      "129/129 [==============================] - 2s 12ms/step - loss: 0.0312 - val_loss: 0.0196\n",
      "Epoch 8/90\n",
      "129/129 [==============================] - 1s 12ms/step - loss: 0.0307 - val_loss: 0.0193\n",
      "Epoch 9/90\n",
      "129/129 [==============================] - 1s 12ms/step - loss: 0.0304 - val_loss: 0.0172\n",
      "Epoch 10/90\n",
      "129/129 [==============================] - 1s 12ms/step - loss: 0.0300 - val_loss: 0.0173\n",
      "Epoch 11/90\n",
      "129/129 [==============================] - 1s 12ms/step - loss: 0.0296 - val_loss: 0.0272\n",
      "Epoch 12/90\n",
      "129/129 [==============================] - 1s 12ms/step - loss: 0.0305 - val_loss: 0.0173\n",
      "Epoch 13/90\n",
      "129/129 [==============================] - 1s 12ms/step - loss: 0.0291 - val_loss: 0.0163\n",
      "Epoch 14/90\n",
      "129/129 [==============================] - 2s 12ms/step - loss: 0.0289 - val_loss: 0.0163\n",
      "Epoch 15/90\n",
      "129/129 [==============================] - 2s 12ms/step - loss: 0.0286 - val_loss: 0.0152\n",
      "Epoch 16/90\n",
      "129/129 [==============================] - 2s 12ms/step - loss: 0.0284 - val_loss: 0.0152\n",
      "Epoch 17/90\n",
      "129/129 [==============================] - 2s 12ms/step - loss: 0.0282 - val_loss: 0.0141\n",
      "Epoch 18/90\n",
      "129/129 [==============================] - 2s 12ms/step - loss: 0.0283 - val_loss: 0.0143\n",
      "Epoch 19/90\n",
      "129/129 [==============================] - 2s 12ms/step - loss: 0.0281 - val_loss: 0.0143\n",
      "Epoch 20/90\n",
      "129/129 [==============================] - 2s 12ms/step - loss: 0.0277 - val_loss: 0.0138\n",
      "Epoch 21/90\n",
      "129/129 [==============================] - 1s 12ms/step - loss: 0.0275 - val_loss: 0.0131\n",
      "Epoch 22/90\n",
      "129/129 [==============================] - 2s 12ms/step - loss: 0.0274 - val_loss: 0.0137\n",
      "Epoch 23/90\n",
      "129/129 [==============================] - 1s 12ms/step - loss: 0.0272 - val_loss: 0.0138\n",
      "Epoch 24/90\n",
      "129/129 [==============================] - 2s 12ms/step - loss: 0.0270 - val_loss: 0.0141\n",
      "Epoch 25/90\n",
      "129/129 [==============================] - 1s 12ms/step - loss: 0.0269 - val_loss: 0.0143\n",
      "Epoch 26/90\n",
      "129/129 [==============================] - 2s 12ms/step - loss: 0.0268 - val_loss: 0.0145\n",
      "Epoch 27/90\n",
      "129/129 [==============================] - 2s 12ms/step - loss: 0.0267 - val_loss: 0.0143\n",
      "Epoch 28/90\n",
      "129/129 [==============================] - 2s 12ms/step - loss: 0.0266 - val_loss: 0.0143\n",
      "Epoch 29/90\n",
      "129/129 [==============================] - 1s 12ms/step - loss: 0.0265 - val_loss: 0.0141\n",
      "Epoch 30/90\n",
      "129/129 [==============================] - 2s 12ms/step - loss: 0.0265 - val_loss: 0.0140\n",
      "Epoch 31/90\n",
      "129/129 [==============================] - 1s 12ms/step - loss: 0.0261 - val_loss: 0.0167\n",
      "Epoch 32/90\n",
      "129/129 [==============================] - 2s 12ms/step - loss: 0.0265 - val_loss: 0.0143\n",
      "Epoch 33/90\n",
      "129/129 [==============================] - 2s 12ms/step - loss: 0.0264 - val_loss: 0.0138\n",
      "Epoch 34/90\n",
      "129/129 [==============================] - 2s 12ms/step - loss: 0.0263 - val_loss: 0.0140\n",
      "Epoch 35/90\n",
      "129/129 [==============================] - 2s 12ms/step - loss: 0.0263 - val_loss: 0.0141\n",
      "Epoch 36/90\n",
      "129/129 [==============================] - 1s 12ms/step - loss: 0.0262 - val_loss: 0.0145\n",
      "Epoch 37/90\n",
      "129/129 [==============================] - 2s 13ms/step - loss: 0.0262 - val_loss: 0.0146\n",
      "Epoch 38/90\n",
      "129/129 [==============================] - 2s 12ms/step - loss: 0.0262 - val_loss: 0.0147\n",
      "Epoch 39/90\n",
      "129/129 [==============================] - 2s 12ms/step - loss: 0.0261 - val_loss: 0.0148\n",
      "Epoch 40/90\n",
      "129/129 [==============================] - 2s 12ms/step - loss: 0.0261 - val_loss: 0.0148\n",
      "Epoch 41/90\n",
      "129/129 [==============================] - 2s 12ms/step - loss: 0.0260 - val_loss: 0.0148\n",
      "Epoch 42/90\n",
      "129/129 [==============================] - 2s 12ms/step - loss: 0.0260 - val_loss: 0.0149\n",
      "Epoch 43/90\n",
      "129/129 [==============================] - 2s 12ms/step - loss: 0.0260 - val_loss: 0.0151\n",
      "Epoch 44/90\n",
      "129/129 [==============================] - 1s 12ms/step - loss: 0.0259 - val_loss: 0.0151\n",
      "Epoch 45/90\n",
      "129/129 [==============================] - 2s 12ms/step - loss: 0.0259 - val_loss: 0.0152\n",
      "Epoch 46/90\n",
      "129/129 [==============================] - 2s 12ms/step - loss: 0.0259 - val_loss: 0.0153\n",
      "Epoch 47/90\n",
      "129/129 [==============================] - 2s 12ms/step - loss: 0.0258 - val_loss: 0.0154\n",
      "Epoch 48/90\n",
      "129/129 [==============================] - 2s 12ms/step - loss: 0.0258 - val_loss: 0.0154\n",
      "Epoch 49/90\n",
      "129/129 [==============================] - 2s 12ms/step - loss: 0.0258 - val_loss: 0.0155\n",
      "Epoch 50/90\n",
      "129/129 [==============================] - 2s 12ms/step - loss: 0.0258 - val_loss: 0.0156\n",
      "Epoch 51/90\n",
      "129/129 [==============================] - 2s 12ms/step - loss: 0.0257 - val_loss: 0.0156\n",
      "Epoch 52/90\n",
      "129/129 [==============================] - 1s 12ms/step - loss: 0.0257 - val_loss: 0.0157\n",
      "Epoch 53/90\n",
      "129/129 [==============================] - 2s 12ms/step - loss: 0.0257 - val_loss: 0.0158\n",
      "Epoch 54/90\n",
      "129/129 [==============================] - 2s 12ms/step - loss: 0.0257 - val_loss: 0.0158\n",
      "Epoch 55/90\n",
      "129/129 [==============================] - 2s 12ms/step - loss: 0.0257 - val_loss: 0.0159\n",
      "Epoch 56/90\n",
      "129/129 [==============================] - 2s 12ms/step - loss: 0.0256 - val_loss: 0.0158\n",
      "Epoch 57/90\n",
      "129/129 [==============================] - 2s 12ms/step - loss: 0.0256 - val_loss: 0.0160\n",
      "Epoch 58/90\n",
      "129/129 [==============================] - 2s 13ms/step - loss: 0.0256 - val_loss: 0.0159\n",
      "Epoch 59/90\n",
      "129/129 [==============================] - 2s 12ms/step - loss: 0.0256 - val_loss: 0.0160\n",
      "Epoch 60/90\n",
      "129/129 [==============================] - 2s 12ms/step - loss: 0.0256 - val_loss: 0.0161\n",
      "Epoch 61/90\n",
      "129/129 [==============================] - 2s 12ms/step - loss: 0.0255 - val_loss: 0.0160\n",
      "Epoch 62/90\n",
      "129/129 [==============================] - 2s 12ms/step - loss: 0.0255 - val_loss: 0.0162\n",
      "Epoch 63/90\n",
      "129/129 [==============================] - 2s 12ms/step - loss: 0.0255 - val_loss: 0.0162\n",
      "Epoch 64/90\n",
      "129/129 [==============================] - 2s 12ms/step - loss: 0.0255 - val_loss: 0.0163\n",
      "Epoch 65/90\n",
      "129/129 [==============================] - 2s 12ms/step - loss: 0.0255 - val_loss: 0.0163\n",
      "Epoch 66/90\n",
      "129/129 [==============================] - 2s 12ms/step - loss: 0.0254 - val_loss: 0.0163\n",
      "Epoch 67/90\n",
      "129/129 [==============================] - 2s 12ms/step - loss: 0.0254 - val_loss: 0.0163\n",
      "Epoch 68/90\n",
      "129/129 [==============================] - 2s 13ms/step - loss: 0.0254 - val_loss: 0.0166A: 0s - loss:\n",
      "Epoch 69/90\n",
      "129/129 [==============================] - 2s 12ms/step - loss: 0.0254 - val_loss: 0.0163\n",
      "Epoch 70/90\n",
      "129/129 [==============================] - 2s 12ms/step - loss: 0.0254 - val_loss: 0.0166\n",
      "Epoch 71/90\n",
      "129/129 [==============================] - 2s 12ms/step - loss: 0.0253 - val_loss: 0.0164\n",
      "Epoch 72/90\n",
      "129/129 [==============================] - 2s 12ms/step - loss: 0.0254 - val_loss: 0.0167\n",
      "Epoch 73/90\n",
      "129/129 [==============================] - 2s 12ms/step - loss: 0.0253 - val_loss: 0.0166\n",
      "Epoch 74/90\n",
      "129/129 [==============================] - 2s 12ms/step - loss: 0.0253 - val_loss: 0.0168\n",
      "Epoch 75/90\n",
      "129/129 [==============================] - 2s 12ms/step - loss: 0.0253 - val_loss: 0.0169\n",
      "Epoch 76/90\n",
      "129/129 [==============================] - 2s 12ms/step - loss: 0.0253 - val_loss: 0.0170\n",
      "Epoch 77/90\n",
      "129/129 [==============================] - 2s 12ms/step - loss: 0.0253 - val_loss: 0.0171\n",
      "Epoch 78/90\n",
      "129/129 [==============================] - 2s 12ms/step - loss: 0.0253 - val_loss: 0.0172\n",
      "Epoch 79/90\n",
      "129/129 [==============================] - 2s 12ms/step - loss: 0.0252 - val_loss: 0.0172\n",
      "Epoch 80/90\n",
      "129/129 [==============================] - 2s 12ms/step - loss: 0.0252 - val_loss: 0.0172\n",
      "Epoch 81/90\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "129/129 [==============================] - 2s 12ms/step - loss: 0.0252 - val_loss: 0.0173\n",
      "Epoch 82/90\n",
      "129/129 [==============================] - 1s 12ms/step - loss: 0.0252 - val_loss: 0.0175\n",
      "Epoch 83/90\n",
      "129/129 [==============================] - 1s 12ms/step - loss: 0.0252 - val_loss: 0.0174\n",
      "Epoch 84/90\n",
      "129/129 [==============================] - 1s 12ms/step - loss: 0.0252 - val_loss: 0.0176\n",
      "Epoch 85/90\n",
      "129/129 [==============================] - 1s 12ms/step - loss: 0.0251 - val_loss: 0.0176\n",
      "Epoch 86/90\n",
      "129/129 [==============================] - 1s 12ms/step - loss: 0.0251 - val_loss: 0.0177\n",
      "Epoch 87/90\n",
      "129/129 [==============================] - 2s 12ms/step - loss: 0.0251 - val_loss: 0.0177\n",
      "Epoch 88/90\n",
      "129/129 [==============================] - 2s 12ms/step - loss: 0.0251 - val_loss: 0.0177\n",
      "Epoch 89/90\n",
      "129/129 [==============================] - 2s 12ms/step - loss: 0.0251 - val_loss: 0.0178\n",
      "Epoch 90/90\n",
      "129/129 [==============================] - 2s 12ms/step - loss: 0.0251 - val_loss: 0.0177\n",
      "Execution time:  140.09447407722473\n",
      "DNN:\n",
      "Mean Absolute Error: 0.0251\n",
      "Root Mean Square Error: 0.0434\n",
      "Mean Square Error: 0.0019\n",
      "\n",
      "Train RMSE: 0.043\n",
      "Train MSE: 0.002\n",
      "Train MAE: 0.025\n",
      "###########################\n",
      "\n",
      "MODEL:  DNN\n",
      "sequence:  3d\n",
      "units:  12\n",
      "dropout1:  0.48476373451509647\n",
      "optimizer: adam\n",
      "activationDense: sigmoid\n",
      "epochs: 52\n",
      "batchsize: 57\n",
      "validation_split: 0.1\n",
      "Model: \"sequential_188\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_564 (Dense)            (None, 432, 12)           24        \n",
      "_________________________________________________________________\n",
      "dense_565 (Dense)            (None, 432, 16)           208       \n",
      "_________________________________________________________________\n",
      "dropout_188 (Dropout)        (None, 432, 16)           0         \n",
      "_________________________________________________________________\n",
      "dense_566 (Dense)            (None, 432, 1)            17        \n",
      "=================================================================\n",
      "Total params: 249\n",
      "Trainable params: 249\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/52\n",
      "57/57 [==============================] - 1s 17ms/step - loss: 0.1008 - val_loss: 0.0754\n",
      "Epoch 2/52\n",
      "57/57 [==============================] - 1s 14ms/step - loss: 0.0518 - val_loss: 0.0480\n",
      "Epoch 3/52\n",
      "57/57 [==============================] - 1s 14ms/step - loss: 0.0445 - val_loss: 0.0395\n",
      "Epoch 4/52\n",
      "57/57 [==============================] - 1s 14ms/step - loss: 0.0409 - val_loss: 0.0379\n",
      "Epoch 5/52\n",
      "57/57 [==============================] - 1s 14ms/step - loss: 0.0386 - val_loss: 0.0356\n",
      "Epoch 6/52\n",
      "57/57 [==============================] - 1s 14ms/step - loss: 0.0369 - val_loss: 0.0327\n",
      "Epoch 7/52\n",
      "57/57 [==============================] - 1s 14ms/step - loss: 0.0356 - val_loss: 0.0311\n",
      "Epoch 8/52\n",
      "57/57 [==============================] - 1s 14ms/step - loss: 0.0345 - val_loss: 0.0298\n",
      "Epoch 9/52\n",
      "57/57 [==============================] - 1s 14ms/step - loss: 0.0335 - val_loss: 0.0290\n",
      "Epoch 10/52\n",
      "57/57 [==============================] - 1s 14ms/step - loss: 0.0327 - val_loss: 0.0278\n",
      "Epoch 11/52\n",
      "57/57 [==============================] - 1s 14ms/step - loss: 0.0320 - val_loss: 0.0267\n",
      "Epoch 12/52\n",
      "57/57 [==============================] - 1s 14ms/step - loss: 0.0314 - val_loss: 0.0258\n",
      "Epoch 13/52\n",
      "57/57 [==============================] - 1s 14ms/step - loss: 0.0308 - val_loss: 0.0249\n",
      "Epoch 14/52\n",
      "57/57 [==============================] - 1s 15ms/step - loss: 0.0303 - val_loss: 0.0242\n",
      "Epoch 15/52\n",
      "57/57 [==============================] - 1s 16ms/step - loss: 0.0298 - val_loss: 0.0235\n",
      "Epoch 16/52\n",
      "57/57 [==============================] - 1s 15ms/step - loss: 0.0293 - val_loss: 0.0228\n",
      "Epoch 17/52\n",
      "57/57 [==============================] - 1s 15ms/step - loss: 0.0289 - val_loss: 0.0222\n",
      "Epoch 18/52\n",
      "57/57 [==============================] - 1s 14ms/step - loss: 0.0285 - val_loss: 0.0218\n",
      "Epoch 19/52\n",
      "57/57 [==============================] - 1s 14ms/step - loss: 0.0282 - val_loss: 0.0216\n",
      "Epoch 20/52\n",
      "57/57 [==============================] - 1s 14ms/step - loss: 0.0279 - val_loss: 0.0213\n",
      "Epoch 21/52\n",
      "57/57 [==============================] - 1s 14ms/step - loss: 0.0276 - val_loss: 0.0207\n",
      "Epoch 22/52\n",
      "57/57 [==============================] - 1s 14ms/step - loss: 0.0274 - val_loss: 0.0201\n",
      "Epoch 23/52\n",
      "57/57 [==============================] - 1s 14ms/step - loss: 0.0272 - val_loss: 0.0197\n",
      "Epoch 24/52\n",
      "57/57 [==============================] - 1s 14ms/step - loss: 0.0270 - val_loss: 0.0193\n",
      "Epoch 25/52\n",
      "57/57 [==============================] - 1s 14ms/step - loss: 0.0268 - val_loss: 0.0191\n",
      "Epoch 26/52\n",
      "57/57 [==============================] - 1s 14ms/step - loss: 0.0267 - val_loss: 0.0189\n",
      "Epoch 27/52\n",
      "57/57 [==============================] - 1s 14ms/step - loss: 0.0265 - val_loss: 0.0187\n",
      "Epoch 28/52\n",
      "57/57 [==============================] - 1s 14ms/step - loss: 0.0264 - val_loss: 0.0187\n",
      "Epoch 29/52\n",
      "57/57 [==============================] - 1s 14ms/step - loss: 0.0263 - val_loss: 0.0186\n",
      "Epoch 30/52\n",
      "57/57 [==============================] - 1s 14ms/step - loss: 0.0262 - val_loss: 0.0184\n",
      "Epoch 31/52\n",
      "57/57 [==============================] - 1s 14ms/step - loss: 0.0261 - val_loss: 0.0182\n",
      "Epoch 32/52\n",
      "57/57 [==============================] - 1s 14ms/step - loss: 0.0260 - val_loss: 0.0180\n",
      "Epoch 33/52\n",
      "57/57 [==============================] - 1s 15ms/step - loss: 0.0259 - val_loss: 0.0181\n",
      "Epoch 34/52\n",
      "57/57 [==============================] - 1s 16ms/step - loss: 0.0258 - val_loss: 0.0190\n",
      "Epoch 35/52\n",
      "57/57 [==============================] - 1s 16ms/step - loss: 0.0255 - val_loss: 0.0184\n",
      "Epoch 36/52\n",
      "57/57 [==============================] - 1s 15ms/step - loss: 0.0255 - val_loss: 0.0183\n",
      "Epoch 37/52\n",
      "57/57 [==============================] - 1s 14ms/step - loss: 0.0255 - val_loss: 0.0182\n",
      "Epoch 38/52\n",
      "57/57 [==============================] - 1s 14ms/step - loss: 0.0254 - val_loss: 0.0182\n",
      "Epoch 39/52\n",
      "57/57 [==============================] - 1s 14ms/step - loss: 0.0254 - val_loss: 0.0182\n",
      "Epoch 40/52\n",
      "57/57 [==============================] - 1s 14ms/step - loss: 0.0254 - val_loss: 0.0182\n",
      "Epoch 41/52\n",
      "57/57 [==============================] - 1s 14ms/step - loss: 0.0253 - val_loss: 0.0189\n",
      "Epoch 42/52\n",
      "57/57 [==============================] - 1s 14ms/step - loss: 0.0251 - val_loss: 0.0182\n",
      "Epoch 43/52\n",
      "57/57 [==============================] - 1s 14ms/step - loss: 0.0251 - val_loss: 0.0180\n",
      "Epoch 44/52\n",
      "57/57 [==============================] - 1s 14ms/step - loss: 0.0251 - val_loss: 0.0181\n",
      "Epoch 45/52\n",
      "57/57 [==============================] - 1s 14ms/step - loss: 0.0251 - val_loss: 0.0183\n",
      "Epoch 46/52\n",
      "57/57 [==============================] - 1s 14ms/step - loss: 0.0250 - val_loss: 0.0184\n",
      "Epoch 47/52\n",
      "57/57 [==============================] - 1s 14ms/step - loss: 0.0250 - val_loss: 0.0185\n",
      "Epoch 48/52\n",
      "57/57 [==============================] - 1s 14ms/step - loss: 0.0250 - val_loss: 0.0185\n",
      "Epoch 49/52\n",
      "57/57 [==============================] - 1s 14ms/step - loss: 0.0250 - val_loss: 0.0186\n",
      "Epoch 50/52\n",
      "57/57 [==============================] - 1s 14ms/step - loss: 0.0250 - val_loss: 0.0187\n",
      "Epoch 51/52\n",
      "57/57 [==============================] - 1s 14ms/step - loss: 0.0250 - val_loss: 0.0187\n",
      "Epoch 52/52\n",
      "57/57 [==============================] - 1s 15ms/step - loss: 0.0249 - val_loss: 0.0188\n",
      "Execution time:  44.15416979789734\n",
      "DNN:\n",
      "Mean Absolute Error: 0.0249\n",
      "Root Mean Square Error: 0.0423\n",
      "Mean Square Error: 0.0018\n",
      "\n",
      "Train RMSE: 0.042\n",
      "Train MSE: 0.002\n",
      "Train MAE: 0.025\n",
      "###########################\n",
      "\n",
      "MODEL:  DNN\n",
      "sequence:  3d\n",
      "units:  87\n",
      "dropout1:  0.40519643149940265\n",
      "optimizer: adam\n",
      "activationDense: sigmoid\n",
      "epochs: 80\n",
      "batchsize: 31\n",
      "validation_split: 0.2\n",
      "Model: \"sequential_189\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_567 (Dense)            (None, 432, 87)           174       \n",
      "_________________________________________________________________\n",
      "dense_568 (Dense)            (None, 432, 16)           1408      \n",
      "_________________________________________________________________\n",
      "dropout_189 (Dropout)        (None, 432, 16)           0         \n",
      "_________________________________________________________________\n",
      "dense_569 (Dense)            (None, 432, 1)            17        \n",
      "=================================================================\n",
      "Total params: 1,599\n",
      "Trainable params: 1,599\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/80\n",
      "92/92 [==============================] - 2s 18ms/step - loss: 0.0630 - val_loss: 0.0376\n",
      "Epoch 2/80\n",
      "92/92 [==============================] - 1s 16ms/step - loss: 0.0460 - val_loss: 0.0336\n",
      "Epoch 3/80\n",
      "92/92 [==============================] - 1s 16ms/step - loss: 0.0432 - val_loss: 0.0309\n",
      "Epoch 4/80\n",
      "92/92 [==============================] - 1s 16ms/step - loss: 0.0403 - val_loss: 0.0131\n",
      "Epoch 5/80\n",
      "92/92 [==============================] - 1s 16ms/step - loss: 0.0402 - val_loss: 0.0264\n",
      "Epoch 6/80\n",
      "92/92 [==============================] - 1s 16ms/step - loss: 0.0367 - val_loss: 0.0240\n",
      "Epoch 7/80\n",
      "92/92 [==============================] - 1s 16ms/step - loss: 0.0351 - val_loss: 0.0221\n",
      "Epoch 8/80\n",
      "92/92 [==============================] - 1s 16ms/step - loss: 0.0337 - val_loss: 0.0206\n",
      "Epoch 9/80\n",
      "92/92 [==============================] - 1s 16ms/step - loss: 0.0326 - val_loss: 0.0192\n",
      "Epoch 10/80\n",
      "92/92 [==============================] - 2s 16ms/step - loss: 0.0316 - val_loss: 0.0182\n",
      "Epoch 11/80\n",
      "92/92 [==============================] - 2s 17ms/step - loss: 0.0309 - val_loss: 0.0173\n",
      "Epoch 12/80\n",
      "92/92 [==============================] - 1s 16ms/step - loss: 0.0302 - val_loss: 0.0166\n",
      "Epoch 13/80\n",
      "92/92 [==============================] - 1s 16ms/step - loss: 0.0297 - val_loss: 0.0161\n",
      "Epoch 14/80\n",
      "92/92 [==============================] - 1s 16ms/step - loss: 0.0292 - val_loss: 0.0158\n",
      "Epoch 15/80\n",
      "92/92 [==============================] - 1s 16ms/step - loss: 0.0288 - val_loss: 0.0155\n",
      "Epoch 16/80\n",
      "92/92 [==============================] - 1s 16ms/step - loss: 0.0285 - val_loss: 0.0153\n",
      "Epoch 17/80\n",
      "92/92 [==============================] - 1s 16ms/step - loss: 0.0280 - val_loss: 0.0119\n",
      "Epoch 18/80\n",
      "92/92 [==============================] - 1s 16ms/step - loss: 0.0286 - val_loss: 0.0151\n",
      "Epoch 19/80\n",
      "92/92 [==============================] - 1s 16ms/step - loss: 0.0278 - val_loss: 0.0148\n",
      "Epoch 20/80\n",
      "92/92 [==============================] - 1s 16ms/step - loss: 0.0277 - val_loss: 0.0146\n",
      "Epoch 21/80\n",
      "92/92 [==============================] - 2s 17ms/step - loss: 0.0276 - val_loss: 0.0144\n",
      "Epoch 22/80\n",
      "92/92 [==============================] - 2s 17ms/step - loss: 0.0275 - val_loss: 0.0143\n",
      "Epoch 23/80\n",
      "92/92 [==============================] - 1s 16ms/step - loss: 0.0274 - val_loss: 0.0143\n",
      "Epoch 24/80\n",
      "92/92 [==============================] - 1s 16ms/step - loss: 0.0274 - val_loss: 0.0144\n",
      "Epoch 25/80\n",
      "92/92 [==============================] - 1s 16ms/step - loss: 0.0272 - val_loss: 0.0144\n",
      "Epoch 26/80\n",
      "92/92 [==============================] - 1s 16ms/step - loss: 0.0272 - val_loss: 0.0144\n",
      "Epoch 27/80\n",
      "92/92 [==============================] - 1s 16ms/step - loss: 0.0273 - val_loss: 0.0150\n",
      "Epoch 28/80\n",
      "92/92 [==============================] - 1s 16ms/step - loss: 0.0269 - val_loss: 0.0147\n",
      "Epoch 29/80\n",
      "92/92 [==============================] - 1s 16ms/step - loss: 0.0269 - val_loss: 0.0146\n",
      "Epoch 30/80\n",
      "92/92 [==============================] - 1s 16ms/step - loss: 0.0269 - val_loss: 0.0147\n",
      "Epoch 31/80\n",
      "92/92 [==============================] - 1s 16ms/step - loss: 0.0268 - val_loss: 0.0146\n",
      "Epoch 32/80\n",
      "92/92 [==============================] - 2s 17ms/step - loss: 0.0269 - val_loss: 0.0149\n",
      "Epoch 33/80\n",
      "92/92 [==============================] - 2s 17ms/step - loss: 0.0267 - val_loss: 0.0148\n",
      "Epoch 34/80\n",
      "92/92 [==============================] - 1s 16ms/step - loss: 0.0267 - val_loss: 0.0148\n",
      "Epoch 35/80\n",
      "92/92 [==============================] - 1s 16ms/step - loss: 0.0267 - val_loss: 0.0148\n",
      "Epoch 36/80\n",
      "92/92 [==============================] - 1s 16ms/step - loss: 0.0267 - val_loss: 0.0148\n",
      "Epoch 37/80\n",
      "92/92 [==============================] - 1s 16ms/step - loss: 0.0267 - val_loss: 0.0148\n",
      "Epoch 38/80\n",
      "92/92 [==============================] - 1s 16ms/step - loss: 0.0267 - val_loss: 0.0148\n",
      "Epoch 39/80\n",
      "92/92 [==============================] - 2s 16ms/step - loss: 0.0267 - val_loss: 0.0148\n",
      "Epoch 40/80\n",
      "92/92 [==============================] - 1s 16ms/step - loss: 0.0267 - val_loss: 0.0148\n",
      "Epoch 41/80\n",
      "92/92 [==============================] - 1s 16ms/step - loss: 0.0267 - val_loss: 0.0148\n",
      "Epoch 42/80\n",
      "92/92 [==============================] - 2s 17ms/step - loss: 0.0267 - val_loss: 0.0148\n",
      "Epoch 43/80\n",
      "92/92 [==============================] - 2s 17ms/step - loss: 0.0267 - val_loss: 0.0148\n",
      "Epoch 44/80\n",
      "92/92 [==============================] - 1s 16ms/step - loss: 0.0267 - val_loss: 0.0148\n",
      "Epoch 45/80\n",
      "92/92 [==============================] - 1s 16ms/step - loss: 0.0267 - val_loss: 0.0147\n",
      "Epoch 46/80\n",
      "92/92 [==============================] - 1s 16ms/step - loss: 0.0269 - val_loss: 0.0148\n",
      "Epoch 47/80\n",
      "92/92 [==============================] - 1s 16ms/step - loss: 0.0267 - val_loss: 0.0148\n",
      "Epoch 48/80\n",
      "92/92 [==============================] - 1s 16ms/step - loss: 0.0267 - val_loss: 0.0148\n",
      "Epoch 49/80\n",
      "92/92 [==============================] - 1s 16ms/step - loss: 0.0267 - val_loss: 0.0148\n",
      "Epoch 50/80\n",
      "92/92 [==============================] - 1s 16ms/step - loss: 0.0267 - val_loss: 0.0148\n",
      "Epoch 51/80\n",
      "92/92 [==============================] - 1s 16ms/step - loss: 0.0267 - val_loss: 0.0148\n",
      "Epoch 52/80\n",
      "92/92 [==============================] - 1s 16ms/step - loss: 0.0267 - val_loss: 0.0148\n",
      "Epoch 53/80\n",
      "92/92 [==============================] - 2s 17ms/step - loss: 0.0267 - val_loss: 0.0148\n",
      "Epoch 54/80\n",
      "92/92 [==============================] - 2s 16ms/step - loss: 0.0267 - val_loss: 0.0148\n",
      "Epoch 55/80\n",
      "92/92 [==============================] - 1s 16ms/step - loss: 0.0267 - val_loss: 0.0148\n",
      "Epoch 56/80\n",
      "92/92 [==============================] - 1s 16ms/step - loss: 0.0267 - val_loss: 0.0148\n",
      "Epoch 57/80\n",
      "92/92 [==============================] - 1s 16ms/step - loss: 0.0267 - val_loss: 0.0148\n",
      "Epoch 58/80\n",
      "92/92 [==============================] - 1s 16ms/step - loss: 0.0267 - val_loss: 0.0148\n",
      "Epoch 59/80\n",
      "92/92 [==============================] - 1s 16ms/step - loss: 0.0267 - val_loss: 0.0148\n",
      "Epoch 60/80\n",
      "92/92 [==============================] - 1s 16ms/step - loss: 0.0267 - val_loss: 0.0148\n",
      "Epoch 61/80\n",
      "92/92 [==============================] - 1s 16ms/step - loss: 0.0267 - val_loss: 0.0148\n",
      "Epoch 62/80\n",
      "92/92 [==============================] - 1s 16ms/step - loss: 0.0267 - val_loss: 0.0148\n",
      "Epoch 63/80\n",
      "92/92 [==============================] - 2s 17ms/step - loss: 0.0267 - val_loss: 0.0148\n",
      "Epoch 64/80\n",
      "92/92 [==============================] - 2s 17ms/step - loss: 0.0267 - val_loss: 0.0148\n",
      "Epoch 65/80\n",
      "92/92 [==============================] - 2s 17ms/step - loss: 0.0267 - val_loss: 0.0144\n",
      "Epoch 66/80\n",
      "92/92 [==============================] - 1s 16ms/step - loss: 0.0272 - val_loss: 0.0148\n",
      "Epoch 67/80\n",
      "92/92 [==============================] - 1s 16ms/step - loss: 0.0267 - val_loss: 0.0138\n",
      "Epoch 68/80\n",
      "92/92 [==============================] - 1s 16ms/step - loss: 0.0271 - val_loss: 0.0148\n",
      "Epoch 69/80\n",
      "92/92 [==============================] - 1s 16ms/step - loss: 0.0267 - val_loss: 0.0148\n",
      "Epoch 70/80\n",
      "92/92 [==============================] - 2s 16ms/step - loss: 0.0267 - val_loss: 0.0148\n",
      "Epoch 71/80\n",
      "92/92 [==============================] - 1s 16ms/step - loss: 0.0267 - val_loss: 0.0148\n",
      "Epoch 72/80\n",
      "92/92 [==============================] - 1s 16ms/step - loss: 0.0267 - val_loss: 0.0148\n",
      "Epoch 73/80\n",
      "92/92 [==============================] - 1s 16ms/step - loss: 0.0267 - val_loss: 0.0148\n",
      "Epoch 74/80\n",
      "92/92 [==============================] - 2s 17ms/step - loss: 0.0267 - val_loss: 0.0148\n",
      "Epoch 75/80\n",
      "92/92 [==============================] - 2s 17ms/step - loss: 0.0267 - val_loss: 0.0148\n",
      "Epoch 76/80\n",
      "92/92 [==============================] - 1s 16ms/step - loss: 0.0267 - val_loss: 0.0148\n",
      "Epoch 77/80\n",
      "92/92 [==============================] - 1s 16ms/step - loss: 0.0267 - val_loss: 0.0148\n",
      "Epoch 78/80\n",
      "92/92 [==============================] - 1s 16ms/step - loss: 0.0267 - val_loss: 0.0148\n",
      "Epoch 79/80\n",
      "92/92 [==============================] - 1s 16ms/step - loss: 0.0267 - val_loss: 0.0148\n",
      "Epoch 80/80\n",
      "92/92 [==============================] - 1s 16ms/step - loss: 0.0267 - val_loss: 0.0148\n",
      "Execution time:  121.10552501678467\n",
      "DNN:\n",
      "Mean Absolute Error: 0.0251\n",
      "Root Mean Square Error: 0.0429\n",
      "Mean Square Error: 0.0018\n",
      "\n",
      "Train RMSE: 0.043\n",
      "Train MSE: 0.002\n",
      "Train MAE: 0.025\n",
      "###########################\n",
      "\n",
      "MODEL:  DNN\n",
      "sequence:  3d\n",
      "units:  80\n",
      "dropout1:  0.11814836227952394\n",
      "optimizer: adam\n",
      "activationDense: sigmoid\n",
      "epochs: 90\n",
      "batchsize: 25\n",
      "validation_split: 0.2\n",
      "Model: \"sequential_190\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_570 (Dense)            (None, 432, 80)           160       \n",
      "_________________________________________________________________\n",
      "dense_571 (Dense)            (None, 432, 16)           1296      \n",
      "_________________________________________________________________\n",
      "dropout_190 (Dropout)        (None, 432, 16)           0         \n",
      "_________________________________________________________________\n",
      "dense_572 (Dense)            (None, 432, 1)            17        \n",
      "=================================================================\n",
      "Total params: 1,473\n",
      "Trainable params: 1,473\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/90\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "114/114 [==============================] - 2s 17ms/step - loss: 0.0681 - val_loss: 0.0141\n",
      "Epoch 2/90\n",
      "114/114 [==============================] - 1s 12ms/step - loss: 0.0378 - val_loss: 0.0133\n",
      "Epoch 3/90\n",
      "114/114 [==============================] - 1s 13ms/step - loss: 0.0349 - val_loss: 0.0132\n",
      "Epoch 4/90\n",
      "114/114 [==============================] - 1s 13ms/step - loss: 0.0365 - val_loss: 0.0133\n",
      "Epoch 5/90\n",
      "114/114 [==============================] - 1s 13ms/step - loss: 0.0337 - val_loss: 0.0133\n",
      "Epoch 6/90\n",
      "114/114 [==============================] - 1s 12ms/step - loss: 0.0333 - val_loss: 0.0135\n",
      "Epoch 7/90\n",
      "114/114 [==============================] - 1s 12ms/step - loss: 0.0328 - val_loss: 0.0136\n",
      "Epoch 8/90\n",
      "114/114 [==============================] - 1s 12ms/step - loss: 0.0325 - val_loss: 0.0133\n",
      "Epoch 9/90\n",
      "114/114 [==============================] - 1s 12ms/step - loss: 0.0322 - val_loss: 0.0135\n",
      "Epoch 10/90\n",
      "114/114 [==============================] - 1s 12ms/step - loss: 0.0319 - val_loss: 0.0135\n",
      "Epoch 11/90\n",
      "114/114 [==============================] - 1s 12ms/step - loss: 0.0316 - val_loss: 0.0135\n",
      "Epoch 12/90\n",
      "114/114 [==============================] - 1s 12ms/step - loss: 0.0313 - val_loss: 0.0136\n",
      "Epoch 13/90\n",
      "114/114 [==============================] - 1s 12ms/step - loss: 0.0311 - val_loss: 0.0137\n",
      "Epoch 14/90\n",
      "114/114 [==============================] - 1s 13ms/step - loss: 0.0308 - val_loss: 0.0137\n",
      "Epoch 15/90\n",
      "114/114 [==============================] - 2s 13ms/step - loss: 0.0305 - val_loss: 0.0138\n",
      "Epoch 16/90\n",
      "114/114 [==============================] - 1s 13ms/step - loss: 0.0303 - val_loss: 0.0139\n",
      "Epoch 17/90\n",
      "114/114 [==============================] - 1s 12ms/step - loss: 0.0301 - val_loss: 0.0139\n",
      "Epoch 18/90\n",
      "114/114 [==============================] - 1s 12ms/step - loss: 0.0299 - val_loss: 0.0140\n",
      "Epoch 19/90\n",
      "114/114 [==============================] - 1s 12ms/step - loss: 0.0297 - val_loss: 0.0140\n",
      "Epoch 20/90\n",
      "114/114 [==============================] - 1s 12ms/step - loss: 0.0296 - val_loss: 0.0140\n",
      "Epoch 21/90\n",
      "114/114 [==============================] - 1s 12ms/step - loss: 0.0294 - val_loss: 0.0141\n",
      "Epoch 22/90\n",
      "114/114 [==============================] - 1s 12ms/step - loss: 0.0293 - val_loss: 0.0141\n",
      "Epoch 23/90\n",
      "114/114 [==============================] - 1s 12ms/step - loss: 0.0292 - val_loss: 0.0141\n",
      "Epoch 24/90\n",
      "114/114 [==============================] - 1s 12ms/step - loss: 0.0290 - val_loss: 0.0142\n",
      "Epoch 25/90\n",
      "114/114 [==============================] - 1s 12ms/step - loss: 0.0289 - val_loss: 0.0142\n",
      "Epoch 26/90\n",
      "114/114 [==============================] - 2s 13ms/step - loss: 0.0288 - val_loss: 0.0142\n",
      "Epoch 27/90\n",
      "114/114 [==============================] - 1s 13ms/step - loss: 0.0287 - val_loss: 0.0143\n",
      "Epoch 28/90\n",
      "114/114 [==============================] - 1s 12ms/step - loss: 0.0286 - val_loss: 0.0144\n",
      "Epoch 29/90\n",
      "114/114 [==============================] - 1s 12ms/step - loss: 0.0285 - val_loss: 0.0144\n",
      "Epoch 30/90\n",
      "114/114 [==============================] - 1s 12ms/step - loss: 0.0284 - val_loss: 0.0143\n",
      "Epoch 31/90\n",
      "114/114 [==============================] - 1s 12ms/step - loss: 0.0283 - val_loss: 0.0144\n",
      "Epoch 32/90\n",
      "114/114 [==============================] - 1s 12ms/step - loss: 0.0282 - val_loss: 0.0143\n",
      "Epoch 33/90\n",
      "114/114 [==============================] - 1s 12ms/step - loss: 0.0281 - val_loss: 0.0144\n",
      "Epoch 34/90\n",
      "114/114 [==============================] - 1s 12ms/step - loss: 0.0281 - val_loss: 0.0144\n",
      "Epoch 35/90\n",
      "114/114 [==============================] - 1s 12ms/step - loss: 0.0280 - val_loss: 0.0144\n",
      "Epoch 36/90\n",
      "114/114 [==============================] - 1s 12ms/step - loss: 0.0279 - val_loss: 0.0145\n",
      "Epoch 37/90\n",
      "114/114 [==============================] - 1s 13ms/step - loss: 0.0279 - val_loss: 0.0145\n",
      "Epoch 38/90\n",
      "114/114 [==============================] - 2s 13ms/step - loss: 0.0278 - val_loss: 0.0144\n",
      "Epoch 39/90\n",
      "114/114 [==============================] - 1s 13ms/step - loss: 0.0278 - val_loss: 0.0144\n",
      "Epoch 40/90\n",
      "114/114 [==============================] - 1s 12ms/step - loss: 0.0277 - val_loss: 0.0144\n",
      "Epoch 41/90\n",
      "114/114 [==============================] - 1s 12ms/step - loss: 0.0277 - val_loss: 0.0144\n",
      "Epoch 42/90\n",
      "114/114 [==============================] - 1s 12ms/step - loss: 0.0276 - val_loss: 0.0144\n",
      "Epoch 43/90\n",
      "114/114 [==============================] - 1s 12ms/step - loss: 0.0276 - val_loss: 0.0144\n",
      "Epoch 44/90\n",
      "114/114 [==============================] - 1s 12ms/step - loss: 0.0275 - val_loss: 0.0144\n",
      "Epoch 45/90\n",
      "114/114 [==============================] - 1s 12ms/step - loss: 0.0275 - val_loss: 0.0144\n",
      "Epoch 46/90\n",
      "114/114 [==============================] - 1s 12ms/step - loss: 0.0275 - val_loss: 0.0144\n",
      "Epoch 47/90\n",
      "114/114 [==============================] - 1s 12ms/step - loss: 0.0274 - val_loss: 0.0144\n",
      "Epoch 48/90\n",
      "114/114 [==============================] - 1s 13ms/step - loss: 0.0274 - val_loss: 0.0144\n",
      "Epoch 49/90\n",
      "114/114 [==============================] - 1s 13ms/step - loss: 0.0274 - val_loss: 0.0144\n",
      "Epoch 50/90\n",
      "114/114 [==============================] - 1s 12ms/step - loss: 0.0273 - val_loss: 0.0144\n",
      "Epoch 51/90\n",
      "114/114 [==============================] - 1s 12ms/step - loss: 0.0273 - val_loss: 0.0144\n",
      "Epoch 52/90\n",
      "114/114 [==============================] - 1s 12ms/step - loss: 0.0273 - val_loss: 0.0144\n",
      "Epoch 53/90\n",
      "114/114 [==============================] - 1s 12ms/step - loss: 0.0272 - val_loss: 0.0144\n",
      "Epoch 54/90\n",
      "114/114 [==============================] - 1s 12ms/step - loss: 0.0272 - val_loss: 0.0144\n",
      "Epoch 55/90\n",
      "114/114 [==============================] - 1s 12ms/step - loss: 0.0272 - val_loss: 0.0144\n",
      "Epoch 56/90\n",
      "114/114 [==============================] - 1s 12ms/step - loss: 0.0272 - val_loss: 0.0144\n",
      "Epoch 57/90\n",
      "114/114 [==============================] - 1s 12ms/step - loss: 0.0271 - val_loss: 0.0144\n",
      "Epoch 58/90\n",
      "114/114 [==============================] - 1s 12ms/step - loss: 0.0271 - val_loss: 0.0144\n",
      "Epoch 59/90\n",
      "114/114 [==============================] - 1s 13ms/step - loss: 0.0271 - val_loss: 0.0144\n",
      "Epoch 60/90\n",
      "114/114 [==============================] - 1s 13ms/step - loss: 0.0271 - val_loss: 0.0144\n",
      "Epoch 61/90\n",
      "114/114 [==============================] - 1s 12ms/step - loss: 0.0271 - val_loss: 0.0144\n",
      "Epoch 62/90\n",
      "114/114 [==============================] - 1s 12ms/step - loss: 0.0271 - val_loss: 0.0144\n",
      "Epoch 63/90\n",
      "114/114 [==============================] - 1s 12ms/step - loss: 0.0270 - val_loss: 0.0144\n",
      "Epoch 64/90\n",
      "114/114 [==============================] - 1s 13ms/step - loss: 0.0270 - val_loss: 0.0144\n",
      "Epoch 65/90\n",
      "114/114 [==============================] - 1s 13ms/step - loss: 0.0270 - val_loss: 0.0144\n",
      "Epoch 66/90\n",
      "114/114 [==============================] - 1s 12ms/step - loss: 0.0270 - val_loss: 0.0144\n",
      "Epoch 67/90\n",
      "114/114 [==============================] - 1s 12ms/step - loss: 0.0270 - val_loss: 0.0144\n",
      "Epoch 68/90\n",
      "114/114 [==============================] - 1s 12ms/step - loss: 0.0270 - val_loss: 0.0144\n",
      "Epoch 69/90\n",
      "114/114 [==============================] - 1s 12ms/step - loss: 0.0270 - val_loss: 0.0144\n",
      "Epoch 70/90\n",
      "114/114 [==============================] - 1s 13ms/step - loss: 0.0270 - val_loss: 0.0144\n",
      "Epoch 71/90\n",
      "114/114 [==============================] - 2s 13ms/step - loss: 0.0270 - val_loss: 0.0144\n",
      "Epoch 72/90\n",
      "114/114 [==============================] - 1s 13ms/step - loss: 0.0270 - val_loss: 0.0144\n",
      "Epoch 73/90\n",
      "114/114 [==============================] - 1s 12ms/step - loss: 0.0269 - val_loss: 0.0145\n",
      "Epoch 74/90\n",
      "114/114 [==============================] - 1s 12ms/step - loss: 0.0269 - val_loss: 0.0145\n",
      "Epoch 75/90\n",
      "114/114 [==============================] - 1s 12ms/step - loss: 0.0269 - val_loss: 0.0145\n",
      "Epoch 76/90\n",
      "114/114 [==============================] - 1s 12ms/step - loss: 0.0269 - val_loss: 0.0145\n",
      "Epoch 77/90\n",
      "114/114 [==============================] - 1s 12ms/step - loss: 0.0269 - val_loss: 0.0145\n",
      "Epoch 78/90\n",
      "114/114 [==============================] - 1s 13ms/step - loss: 0.0269 - val_loss: 0.0145\n",
      "Epoch 79/90\n",
      "114/114 [==============================] - 1s 12ms/step - loss: 0.0269 - val_loss: 0.0145\n",
      "Epoch 80/90\n",
      "114/114 [==============================] - 1s 12ms/step - loss: 0.0269 - val_loss: 0.0145\n",
      "Epoch 81/90\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "114/114 [==============================] - 1s 13ms/step - loss: 0.0269 - val_loss: 0.0145\n",
      "Epoch 82/90\n",
      "114/114 [==============================] - 1s 13ms/step - loss: 0.0269 - val_loss: 0.0146\n",
      "Epoch 83/90\n",
      "114/114 [==============================] - 1s 12ms/step - loss: 0.0269 - val_loss: 0.0146\n",
      "Epoch 84/90\n",
      "114/114 [==============================] - 1s 12ms/step - loss: 0.0269 - val_loss: 0.0145\n",
      "Epoch 85/90\n",
      "114/114 [==============================] - 1s 12ms/step - loss: 0.0269 - val_loss: 0.0146\n",
      "Epoch 86/90\n",
      "114/114 [==============================] - 1s 12ms/step - loss: 0.0269 - val_loss: 0.0145\n",
      "Epoch 87/90\n",
      "114/114 [==============================] - 1s 12ms/step - loss: 0.0269 - val_loss: 0.0145\n",
      "Epoch 88/90\n",
      "114/114 [==============================] - 1s 12ms/step - loss: 0.0269 - val_loss: 0.0146\n",
      "Epoch 89/90\n",
      "114/114 [==============================] - 1s 12ms/step - loss: 0.0260 - val_loss: 0.0111\n",
      "Epoch 90/90\n",
      "114/114 [==============================] - 1s 12ms/step - loss: 0.0275 - val_loss: 0.0154\n",
      "Execution time:  130.6944079399109\n",
      "DNN:\n",
      "Mean Absolute Error: 0.0251\n",
      "Root Mean Square Error: 0.0425\n",
      "Mean Square Error: 0.0018\n",
      "\n",
      "Train RMSE: 0.043\n",
      "Train MSE: 0.002\n",
      "Train MAE: 0.025\n",
      "###########################\n",
      "\n",
      "MODEL:  DNN\n",
      "sequence:  3d\n",
      "units:  12\n",
      "dropout1:  0.48476373451509647\n",
      "optimizer: adam\n",
      "activationDense: sigmoid\n",
      "epochs: 52\n",
      "batchsize: 57\n",
      "validation_split: 0.2\n",
      "Model: \"sequential_191\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_573 (Dense)            (None, 432, 12)           24        \n",
      "_________________________________________________________________\n",
      "dense_574 (Dense)            (None, 432, 16)           208       \n",
      "_________________________________________________________________\n",
      "dropout_191 (Dropout)        (None, 432, 16)           0         \n",
      "_________________________________________________________________\n",
      "dense_575 (Dense)            (None, 432, 1)            17        \n",
      "=================================================================\n",
      "Total params: 249\n",
      "Trainable params: 249\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/52\n",
      "50/50 [==============================] - 1s 18ms/step - loss: 0.0968 - val_loss: 0.0642\n",
      "Epoch 2/52\n",
      "50/50 [==============================] - 1s 17ms/step - loss: 0.0512 - val_loss: 0.0350\n",
      "Epoch 3/52\n",
      "50/50 [==============================] - 1s 16ms/step - loss: 0.0449 - val_loss: 0.0332\n",
      "Epoch 4/52\n",
      "50/50 [==============================] - 1s 16ms/step - loss: 0.0412 - val_loss: 0.0317\n",
      "Epoch 5/52\n",
      "50/50 [==============================] - 1s 15ms/step - loss: 0.0396 - val_loss: 0.0308\n",
      "Epoch 6/52\n",
      "50/50 [==============================] - 1s 15ms/step - loss: 0.0385 - val_loss: 0.0301\n",
      "Epoch 7/52\n",
      "50/50 [==============================] - 1s 15ms/step - loss: 0.0375 - val_loss: 0.0290\n",
      "Epoch 8/52\n",
      "50/50 [==============================] - 1s 15ms/step - loss: 0.0367 - val_loss: 0.0280\n",
      "Epoch 9/52\n",
      "50/50 [==============================] - 1s 14ms/step - loss: 0.0360 - val_loss: 0.0272\n",
      "Epoch 10/52\n",
      "50/50 [==============================] - 1s 15ms/step - loss: 0.0353 - val_loss: 0.0261\n",
      "Epoch 11/52\n",
      "50/50 [==============================] - 1s 15ms/step - loss: 0.0346 - val_loss: 0.0252\n",
      "Epoch 12/52\n",
      "50/50 [==============================] - 1s 15ms/step - loss: 0.0340 - val_loss: 0.0245\n",
      "Epoch 13/52\n",
      "50/50 [==============================] - 1s 15ms/step - loss: 0.0335 - val_loss: 0.0236\n",
      "Epoch 14/52\n",
      "50/50 [==============================] - 1s 15ms/step - loss: 0.0330 - val_loss: 0.0230\n",
      "Epoch 15/52\n",
      "50/50 [==============================] - 1s 15ms/step - loss: 0.0326 - val_loss: 0.0224\n",
      "Epoch 16/52\n",
      "50/50 [==============================] - 1s 15ms/step - loss: 0.0321 - val_loss: 0.0218\n",
      "Epoch 17/52\n",
      "50/50 [==============================] - 1s 15ms/step - loss: 0.0317 - val_loss: 0.0213\n",
      "Epoch 18/52\n",
      "50/50 [==============================] - 1s 15ms/step - loss: 0.0314 - val_loss: 0.0207\n",
      "Epoch 19/52\n",
      "50/50 [==============================] - 1s 15ms/step - loss: 0.0310 - val_loss: 0.0202\n",
      "Epoch 20/52\n",
      "50/50 [==============================] - 1s 15ms/step - loss: 0.0307 - val_loss: 0.0197\n",
      "Epoch 21/52\n",
      "50/50 [==============================] - 1s 16ms/step - loss: 0.0304 - val_loss: 0.0193\n",
      "Epoch 22/52\n",
      "50/50 [==============================] - 1s 15ms/step - loss: 0.0301 - val_loss: 0.0188\n",
      "Epoch 23/52\n",
      "50/50 [==============================] - 1s 16ms/step - loss: 0.0299 - val_loss: 0.0185\n",
      "Epoch 24/52\n",
      "50/50 [==============================] - 1s 16ms/step - loss: 0.0296 - val_loss: 0.0182\n",
      "Epoch 25/52\n",
      "50/50 [==============================] - 1s 16ms/step - loss: 0.0295 - val_loss: 0.0181\n",
      "Epoch 26/52\n",
      "50/50 [==============================] - 1s 15ms/step - loss: 0.0292 - val_loss: 0.0179\n",
      "Epoch 27/52\n",
      "50/50 [==============================] - 1s 15ms/step - loss: 0.0291 - val_loss: 0.0177\n",
      "Epoch 28/52\n",
      "50/50 [==============================] - 1s 15ms/step - loss: 0.0289 - val_loss: 0.0174\n",
      "Epoch 29/52\n",
      "50/50 [==============================] - 1s 15ms/step - loss: 0.0287 - val_loss: 0.0171\n",
      "Epoch 30/52\n",
      "50/50 [==============================] - 1s 15ms/step - loss: 0.0284 - val_loss: 0.0140\n",
      "Epoch 31/52\n",
      "50/50 [==============================] - 1s 15ms/step - loss: 0.0291 - val_loss: 0.0165\n",
      "Epoch 32/52\n",
      "50/50 [==============================] - 1s 15ms/step - loss: 0.0284 - val_loss: 0.0160\n",
      "Epoch 33/52\n",
      "50/50 [==============================] - 1s 15ms/step - loss: 0.0283 - val_loss: 0.0158\n",
      "Epoch 34/52\n",
      "50/50 [==============================] - 1s 15ms/step - loss: 0.0282 - val_loss: 0.0156\n",
      "Epoch 35/52\n",
      "50/50 [==============================] - 1s 15ms/step - loss: 0.0281 - val_loss: 0.0155\n",
      "Epoch 36/52\n",
      "50/50 [==============================] - 1s 15ms/step - loss: 0.0280 - val_loss: 0.0153\n",
      "Epoch 37/52\n",
      "50/50 [==============================] - 1s 15ms/step - loss: 0.0279 - val_loss: 0.0152\n",
      "Epoch 38/52\n",
      "50/50 [==============================] - 1s 15ms/step - loss: 0.0278 - val_loss: 0.0152\n",
      "Epoch 39/52\n",
      "50/50 [==============================] - 1s 14ms/step - loss: 0.0278 - val_loss: 0.0152\n",
      "Epoch 40/52\n",
      "50/50 [==============================] - 1s 15ms/step - loss: 0.0277 - val_loss: 0.0151\n",
      "Epoch 41/52\n",
      "50/50 [==============================] - 1s 15ms/step - loss: 0.0277 - val_loss: 0.0151\n",
      "Epoch 42/52\n",
      "50/50 [==============================] - 1s 15ms/step - loss: 0.0276 - val_loss: 0.0151\n",
      "Epoch 43/52\n",
      "50/50 [==============================] - 1s 15ms/step - loss: 0.0276 - val_loss: 0.0151\n",
      "Epoch 44/52\n",
      "50/50 [==============================] - 1s 16ms/step - loss: 0.0276 - val_loss: 0.0151\n",
      "Epoch 45/52\n",
      "50/50 [==============================] - 1s 16ms/step - loss: 0.0275 - val_loss: 0.0151\n",
      "Epoch 46/52\n",
      "50/50 [==============================] - 1s 16ms/step - loss: 0.0275 - val_loss: 0.0151\n",
      "Epoch 47/52\n",
      "50/50 [==============================] - 1s 15ms/step - loss: 0.0274 - val_loss: 0.0150\n",
      "Epoch 48/52\n",
      "50/50 [==============================] - 1s 15ms/step - loss: 0.0274 - val_loss: 0.0151\n",
      "Epoch 49/52\n",
      "50/50 [==============================] - 1s 15ms/step - loss: 0.0274 - val_loss: 0.0151\n",
      "Epoch 50/52\n",
      "50/50 [==============================] - 1s 15ms/step - loss: 0.0273 - val_loss: 0.0150\n",
      "Epoch 51/52\n",
      "50/50 [==============================] - 1s 15ms/step - loss: 0.0273 - val_loss: 0.0151\n",
      "Epoch 52/52\n",
      "50/50 [==============================] - 1s 15ms/step - loss: 0.0272 - val_loss: 0.0150\n",
      "Execution time:  41.05609941482544\n",
      "DNN:\n",
      "Mean Absolute Error: 0.0246\n",
      "Root Mean Square Error: 0.0416\n",
      "Mean Square Error: 0.0017\n",
      "\n",
      "Train RMSE: 0.042\n",
      "Train MSE: 0.002\n",
      "Train MAE: 0.025\n",
      "###########################\n",
      "\n",
      "MODEL:  DNN\n",
      "sequence:  3d\n",
      "units:  87\n",
      "dropout1:  0.40519643149940265\n",
      "optimizer: adadelta\n",
      "activationDense: tanh\n",
      "epochs: 80\n",
      "batchsize: 31\n",
      "validation_split: 0.1\n",
      "Model: \"sequential_192\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_576 (Dense)            (None, 432, 87)           174       \n",
      "_________________________________________________________________\n",
      "dense_577 (Dense)            (None, 432, 16)           1408      \n",
      "_________________________________________________________________\n",
      "dropout_192 (Dropout)        (None, 432, 16)           0         \n",
      "_________________________________________________________________\n",
      "dense_578 (Dense)            (None, 432, 1)            17        \n",
      "=================================================================\n",
      "Total params: 1,599\n",
      "Trainable params: 1,599\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/80\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "104/104 [==============================] - 2s 17ms/step - loss: 0.3433 - val_loss: 0.3136\n",
      "Epoch 2/80\n",
      "104/104 [==============================] - 2s 15ms/step - loss: 0.3415 - val_loss: 0.3117\n",
      "Epoch 3/80\n",
      "104/104 [==============================] - 2s 15ms/step - loss: 0.3394 - val_loss: 0.3097\n",
      "Epoch 4/80\n",
      "104/104 [==============================] - 2s 15ms/step - loss: 0.3374 - val_loss: 0.3075\n",
      "Epoch 5/80\n",
      "104/104 [==============================] - 2s 16ms/step - loss: 0.3351 - val_loss: 0.3052\n",
      "Epoch 6/80\n",
      "104/104 [==============================] - 2s 16ms/step - loss: 0.3325 - val_loss: 0.3027\n",
      "Epoch 7/80\n",
      "104/104 [==============================] - 2s 15ms/step - loss: 0.3300 - val_loss: 0.3002\n",
      "Epoch 8/80\n",
      "104/104 [==============================] - 2s 15ms/step - loss: 0.3273 - val_loss: 0.2975\n",
      "Epoch 9/80\n",
      "104/104 [==============================] - 2s 15ms/step - loss: 0.3246 - val_loss: 0.2947\n",
      "Epoch 10/80\n",
      "104/104 [==============================] - 2s 15ms/step - loss: 0.3216 - val_loss: 0.2918\n",
      "Epoch 11/80\n",
      "104/104 [==============================] - 2s 15ms/step - loss: 0.3186 - val_loss: 0.2887\n",
      "Epoch 12/80\n",
      "104/104 [==============================] - 2s 15ms/step - loss: 0.3154 - val_loss: 0.2856\n",
      "Epoch 13/80\n",
      "104/104 [==============================] - 2s 15ms/step - loss: 0.3122 - val_loss: 0.2824\n",
      "Epoch 14/80\n",
      "104/104 [==============================] - 2s 15ms/step - loss: 0.3088 - val_loss: 0.2790\n",
      "Epoch 15/80\n",
      "104/104 [==============================] - 2s 15ms/step - loss: 0.3054 - val_loss: 0.2756\n",
      "Epoch 16/80\n",
      "104/104 [==============================] - 2s 16ms/step - loss: 0.3019 - val_loss: 0.2720\n",
      "Epoch 17/80\n",
      "104/104 [==============================] - 2s 16ms/step - loss: 0.2981 - val_loss: 0.2684\n",
      "Epoch 18/80\n",
      "104/104 [==============================] - 2s 15ms/step - loss: 0.2944 - val_loss: 0.2647\n",
      "Epoch 19/80\n",
      "104/104 [==============================] - 2s 15ms/step - loss: 0.2905 - val_loss: 0.2599\n",
      "Epoch 20/80\n",
      "104/104 [==============================] - 2s 15ms/step - loss: 0.2839 - val_loss: 0.2523\n",
      "Epoch 21/80\n",
      "104/104 [==============================] - 2s 15ms/step - loss: 0.2761 - val_loss: 0.2447\n",
      "Epoch 22/80\n",
      "104/104 [==============================] - 2s 15ms/step - loss: 0.2683 - val_loss: 0.2369\n",
      "Epoch 23/80\n",
      "104/104 [==============================] - 2s 15ms/step - loss: 0.2604 - val_loss: 0.2291\n",
      "Epoch 24/80\n",
      "104/104 [==============================] - 2s 15ms/step - loss: 0.2523 - val_loss: 0.2210\n",
      "Epoch 25/80\n",
      "104/104 [==============================] - 2s 16ms/step - loss: 0.2441 - val_loss: 0.2129\n",
      "Epoch 26/80\n",
      "104/104 [==============================] - 2s 16ms/step - loss: 0.2360 - val_loss: 0.2048\n",
      "Epoch 27/80\n",
      "104/104 [==============================] - 2s 15ms/step - loss: 0.2277 - val_loss: 0.1964\n",
      "Epoch 28/80\n",
      "104/104 [==============================] - 2s 15ms/step - loss: 0.2192 - val_loss: 0.1878\n",
      "Epoch 29/80\n",
      "104/104 [==============================] - 2s 15ms/step - loss: 0.2105 - val_loss: 0.1791\n",
      "Epoch 30/80\n",
      "104/104 [==============================] - 2s 15ms/step - loss: 0.2016 - val_loss: 0.1701\n",
      "Epoch 31/80\n",
      "104/104 [==============================] - 2s 15ms/step - loss: 0.1926 - val_loss: 0.1609\n",
      "Epoch 32/80\n",
      "104/104 [==============================] - 2s 15ms/step - loss: 0.1835 - val_loss: 0.1516\n",
      "Epoch 33/80\n",
      "104/104 [==============================] - 2s 15ms/step - loss: 0.1746 - val_loss: 0.1423\n",
      "Epoch 34/80\n",
      "104/104 [==============================] - 2s 15ms/step - loss: 0.1664 - val_loss: 0.1334\n",
      "Epoch 35/80\n",
      "104/104 [==============================] - 2s 16ms/step - loss: 0.1595 - val_loss: 0.1255\n",
      "Epoch 36/80\n",
      "104/104 [==============================] - 2s 16ms/step - loss: 0.1541 - val_loss: 0.1184\n",
      "Epoch 37/80\n",
      "104/104 [==============================] - 2s 15ms/step - loss: 0.1497 - val_loss: 0.1124\n",
      "Epoch 38/80\n",
      "104/104 [==============================] - 2s 15ms/step - loss: 0.1466 - val_loss: 0.1069\n",
      "Epoch 39/80\n",
      "104/104 [==============================] - 2s 15ms/step - loss: 0.1432 - val_loss: 0.1004\n",
      "Epoch 40/80\n",
      "104/104 [==============================] - 2s 15ms/step - loss: 0.1397 - val_loss: 0.0932\n",
      "Epoch 41/80\n",
      "104/104 [==============================] - 2s 15ms/step - loss: 0.1360 - val_loss: 0.0866\n",
      "Epoch 42/80\n",
      "104/104 [==============================] - 2s 15ms/step - loss: 0.1326 - val_loss: 0.0803\n",
      "Epoch 43/80\n",
      "104/104 [==============================] - 2s 15ms/step - loss: 0.1293 - val_loss: 0.0742\n",
      "Epoch 44/80\n",
      "104/104 [==============================] - 2s 15ms/step - loss: 0.1262 - val_loss: 0.0685\n",
      "Epoch 45/80\n",
      "104/104 [==============================] - 2s 16ms/step - loss: 0.1235 - val_loss: 0.0629\n",
      "Epoch 46/80\n",
      "104/104 [==============================] - 2s 16ms/step - loss: 0.1210 - val_loss: 0.0577\n",
      "Epoch 47/80\n",
      "104/104 [==============================] - 2s 15ms/step - loss: 0.1189 - val_loss: 0.0529\n",
      "Epoch 48/80\n",
      "104/104 [==============================] - 2s 16ms/step - loss: 0.1170 - val_loss: 0.0486\n",
      "Epoch 49/80\n",
      "104/104 [==============================] - 2s 15ms/step - loss: 0.1156 - val_loss: 0.0452\n",
      "Epoch 50/80\n",
      "104/104 [==============================] - 2s 15ms/step - loss: 0.1147 - val_loss: 0.0423\n",
      "Epoch 51/80\n",
      "104/104 [==============================] - 2s 15ms/step - loss: 0.1139 - val_loss: 0.0399\n",
      "Epoch 52/80\n",
      "104/104 [==============================] - 2s 15ms/step - loss: 0.1134 - val_loss: 0.0380\n",
      "Epoch 53/80\n",
      "104/104 [==============================] - 2s 15ms/step - loss: 0.1129 - val_loss: 0.0364\n",
      "Epoch 54/80\n",
      "104/104 [==============================] - 2s 15ms/step - loss: 0.1126 - val_loss: 0.0350\n",
      "Epoch 55/80\n",
      "104/104 [==============================] - 2s 16ms/step - loss: 0.1122 - val_loss: 0.0338\n",
      "Epoch 56/80\n",
      "104/104 [==============================] - 2s 16ms/step - loss: 0.1119 - val_loss: 0.0328\n",
      "Epoch 57/80\n",
      "104/104 [==============================] - 2s 15ms/step - loss: 0.1117 - val_loss: 0.0319\n",
      "Epoch 58/80\n",
      "104/104 [==============================] - 2s 15ms/step - loss: 0.1115 - val_loss: 0.0311\n",
      "Epoch 59/80\n",
      "104/104 [==============================] - 2s 15ms/step - loss: 0.1115 - val_loss: 0.0303\n",
      "Epoch 60/80\n",
      "104/104 [==============================] - 2s 15ms/step - loss: 0.1112 - val_loss: 0.0296\n",
      "Epoch 61/80\n",
      "104/104 [==============================] - 2s 15ms/step - loss: 0.1111 - val_loss: 0.0290\n",
      "Epoch 62/80\n",
      "104/104 [==============================] - 2s 15ms/step - loss: 0.1111 - val_loss: 0.0285\n",
      "Epoch 63/80\n",
      "104/104 [==============================] - 2s 15ms/step - loss: 0.1109 - val_loss: 0.0279\n",
      "Epoch 64/80\n",
      "104/104 [==============================] - 2s 15ms/step - loss: 0.1107 - val_loss: 0.0274\n",
      "Epoch 65/80\n",
      "104/104 [==============================] - 2s 16ms/step - loss: 0.1106 - val_loss: 0.0270\n",
      "Epoch 66/80\n",
      "104/104 [==============================] - 2s 16ms/step - loss: 0.1104 - val_loss: 0.0266\n",
      "Epoch 67/80\n",
      "104/104 [==============================] - 2s 15ms/step - loss: 0.1104 - val_loss: 0.0263\n",
      "Epoch 68/80\n",
      "104/104 [==============================] - 2s 15ms/step - loss: 0.1105 - val_loss: 0.0260\n",
      "Epoch 69/80\n",
      "104/104 [==============================] - 2s 15ms/step - loss: 0.1102 - val_loss: 0.0257\n",
      "Epoch 70/80\n",
      "104/104 [==============================] - 2s 15ms/step - loss: 0.1102 - val_loss: 0.0254\n",
      "Epoch 71/80\n",
      "104/104 [==============================] - 2s 15ms/step - loss: 0.1100 - val_loss: 0.0251\n",
      "Epoch 72/80\n",
      "104/104 [==============================] - 2s 15ms/step - loss: 0.1100 - val_loss: 0.0249\n",
      "Epoch 73/80\n",
      "104/104 [==============================] - 2s 15ms/step - loss: 0.1099 - val_loss: 0.0246\n",
      "Epoch 74/80\n",
      "104/104 [==============================] - 2s 15ms/step - loss: 0.1099 - val_loss: 0.0244\n",
      "Epoch 75/80\n",
      "104/104 [==============================] - 2s 16ms/step - loss: 0.1098 - val_loss: 0.0241\n",
      "Epoch 76/80\n",
      "104/104 [==============================] - 2s 16ms/step - loss: 0.1096 - val_loss: 0.0239\n",
      "Epoch 77/80\n",
      "104/104 [==============================] - 2s 15ms/step - loss: 0.1095 - val_loss: 0.0237\n",
      "Epoch 78/80\n",
      "104/104 [==============================] - 2s 15ms/step - loss: 0.1095 - val_loss: 0.0236\n",
      "Epoch 79/80\n",
      "104/104 [==============================] - 2s 15ms/step - loss: 0.1092 - val_loss: 0.0234\n",
      "Epoch 80/80\n",
      "104/104 [==============================] - 2s 15ms/step - loss: 0.1093 - val_loss: 0.0232\n",
      "Execution time:  130.25696182250977\n",
      "DNN:\n",
      "Mean Absolute Error: 0.0462\n",
      "Root Mean Square Error: 0.0528\n",
      "Mean Square Error: 0.0028\n",
      "\n",
      "Train RMSE: 0.053\n",
      "Train MSE: 0.003\n",
      "Train MAE: 0.046\n",
      "###########################\n",
      "\n",
      "MODEL:  DNN\n",
      "sequence:  3d\n",
      "units:  80\n",
      "dropout1:  0.11814836227952394\n",
      "optimizer: adadelta\n",
      "activationDense: tanh\n",
      "epochs: 90\n",
      "batchsize: 25\n",
      "validation_split: 0.1\n",
      "Model: \"sequential_193\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_579 (Dense)            (None, 432, 80)           160       \n",
      "_________________________________________________________________\n",
      "dense_580 (Dense)            (None, 432, 16)           1296      \n",
      "_________________________________________________________________\n",
      "dropout_193 (Dropout)        (None, 432, 16)           0         \n",
      "_________________________________________________________________\n",
      "dense_581 (Dense)            (None, 432, 1)            17        \n",
      "=================================================================\n",
      "Total params: 1,473\n",
      "Trainable params: 1,473\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/90\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "129/129 [==============================] - 2s 13ms/step - loss: 0.4363 - val_loss: 0.4001\n",
      "Epoch 2/90\n",
      "129/129 [==============================] - 1s 12ms/step - loss: 0.4325 - val_loss: 0.3961\n",
      "Epoch 3/90\n",
      "129/129 [==============================] - 1s 12ms/step - loss: 0.4283 - val_loss: 0.3918\n",
      "Epoch 4/90\n",
      "129/129 [==============================] - 2s 12ms/step - loss: 0.4237 - val_loss: 0.3872\n",
      "Epoch 5/90\n",
      "129/129 [==============================] - 2s 12ms/step - loss: 0.4187 - val_loss: 0.3822\n",
      "Epoch 6/90\n",
      "129/129 [==============================] - 1s 12ms/step - loss: 0.4134 - val_loss: 0.3769\n",
      "Epoch 7/90\n",
      "129/129 [==============================] - 2s 12ms/step - loss: 0.4078 - val_loss: 0.3713\n",
      "Epoch 8/90\n",
      "129/129 [==============================] - 1s 12ms/step - loss: 0.4019 - val_loss: 0.3654\n",
      "Epoch 9/90\n",
      "129/129 [==============================] - 1s 12ms/step - loss: 0.3957 - val_loss: 0.3593\n",
      "Epoch 10/90\n",
      "129/129 [==============================] - 1s 12ms/step - loss: 0.3893 - val_loss: 0.3529\n",
      "Epoch 11/90\n",
      "129/129 [==============================] - 1s 12ms/step - loss: 0.3826 - val_loss: 0.3463\n",
      "Epoch 12/90\n",
      "129/129 [==============================] - 1s 12ms/step - loss: 0.3757 - val_loss: 0.3395\n",
      "Epoch 13/90\n",
      "129/129 [==============================] - 1s 12ms/step - loss: 0.3685 - val_loss: 0.3324\n",
      "Epoch 14/90\n",
      "129/129 [==============================] - 2s 12ms/step - loss: 0.3611 - val_loss: 0.3250\n",
      "Epoch 15/90\n",
      "129/129 [==============================] - 2s 12ms/step - loss: 0.3534 - val_loss: 0.3175\n",
      "Epoch 16/90\n",
      "129/129 [==============================] - 1s 12ms/step - loss: 0.3455 - val_loss: 0.3096\n",
      "Epoch 17/90\n",
      "129/129 [==============================] - 1s 12ms/step - loss: 0.3373 - val_loss: 0.3015\n",
      "Epoch 18/90\n",
      "129/129 [==============================] - 1s 12ms/step - loss: 0.3289 - val_loss: 0.2932\n",
      "Epoch 19/90\n",
      "129/129 [==============================] - 1s 12ms/step - loss: 0.3202 - val_loss: 0.2846\n",
      "Epoch 20/90\n",
      "129/129 [==============================] - 1s 12ms/step - loss: 0.3112 - val_loss: 0.2761\n",
      "Epoch 21/90\n",
      "129/129 [==============================] - 1s 12ms/step - loss: 0.3022 - val_loss: 0.2656\n",
      "Epoch 22/90\n",
      "129/129 [==============================] - 1s 12ms/step - loss: 0.2884 - val_loss: 0.2494\n",
      "Epoch 23/90\n",
      "129/129 [==============================] - 2s 12ms/step - loss: 0.2716 - val_loss: 0.2327\n",
      "Epoch 24/90\n",
      "129/129 [==============================] - 2s 12ms/step - loss: 0.2541 - val_loss: 0.2145\n",
      "Epoch 25/90\n",
      "129/129 [==============================] - 2s 13ms/step - loss: 0.2327 - val_loss: 0.1894\n",
      "Epoch 26/90\n",
      "129/129 [==============================] - 2s 12ms/step - loss: 0.2063 - val_loss: 0.1629\n",
      "Epoch 27/90\n",
      "129/129 [==============================] - 1s 12ms/step - loss: 0.1788 - val_loss: 0.1361\n",
      "Epoch 28/90\n",
      "129/129 [==============================] - 2s 12ms/step - loss: 0.1513 - val_loss: 0.1093\n",
      "Epoch 29/90\n",
      "129/129 [==============================] - 1s 12ms/step - loss: 0.1236 - val_loss: 0.0815\n",
      "Epoch 30/90\n",
      "129/129 [==============================] - 1s 12ms/step - loss: 0.0953 - val_loss: 0.0539\n",
      "Epoch 31/90\n",
      "129/129 [==============================] - 1s 12ms/step - loss: 0.0709 - val_loss: 0.0312\n",
      "Epoch 32/90\n",
      "129/129 [==============================] - 2s 12ms/step - loss: 0.0591 - val_loss: 0.0199\n",
      "Epoch 33/90\n",
      "129/129 [==============================] - 1s 12ms/step - loss: 0.0557 - val_loss: 0.0138\n",
      "Epoch 34/90\n",
      "129/129 [==============================] - 1s 12ms/step - loss: 0.0545 - val_loss: 0.0106\n",
      "Epoch 35/90\n",
      "129/129 [==============================] - 2s 12ms/step - loss: 0.0537 - val_loss: 0.0090\n",
      "Epoch 36/90\n",
      "129/129 [==============================] - 2s 12ms/step - loss: 0.0534 - val_loss: 0.0080\n",
      "Epoch 37/90\n",
      "129/129 [==============================] - 1s 12ms/step - loss: 0.0532 - val_loss: 0.0075\n",
      "Epoch 38/90\n",
      "129/129 [==============================] - 2s 12ms/step - loss: 0.0530 - val_loss: 0.0072\n",
      "Epoch 39/90\n",
      "129/129 [==============================] - 2s 12ms/step - loss: 0.0528 - val_loss: 0.0071\n",
      "Epoch 40/90\n",
      "129/129 [==============================] - 1s 12ms/step - loss: 0.0526 - val_loss: 0.0069\n",
      "Epoch 41/90\n",
      "129/129 [==============================] - 1s 12ms/step - loss: 0.0526 - val_loss: 0.0068\n",
      "Epoch 42/90\n",
      "129/129 [==============================] - 2s 12ms/step - loss: 0.0525 - val_loss: 0.0067\n",
      "Epoch 43/90\n",
      "129/129 [==============================] - 1s 12ms/step - loss: 0.0525 - val_loss: 0.0067\n",
      "Epoch 44/90\n",
      "129/129 [==============================] - 1s 12ms/step - loss: 0.0524 - val_loss: 0.0067\n",
      "Epoch 45/90\n",
      "129/129 [==============================] - 2s 12ms/step - loss: 0.0523 - val_loss: 0.0068\n",
      "Epoch 46/90\n",
      "129/129 [==============================] - 2s 12ms/step - loss: 0.0522 - val_loss: 0.0069\n",
      "Epoch 47/90\n",
      "129/129 [==============================] - 2s 12ms/step - loss: 0.0522 - val_loss: 0.0070\n",
      "Epoch 48/90\n",
      "129/129 [==============================] - 1s 12ms/step - loss: 0.0521 - val_loss: 0.0071\n",
      "Epoch 49/90\n",
      "129/129 [==============================] - 2s 12ms/step - loss: 0.0521 - val_loss: 0.0072\n",
      "Epoch 50/90\n",
      "129/129 [==============================] - 1s 12ms/step - loss: 0.0520 - val_loss: 0.0073\n",
      "Epoch 51/90\n",
      "129/129 [==============================] - 2s 12ms/step - loss: 0.0520 - val_loss: 0.0074\n",
      "Epoch 52/90\n",
      "129/129 [==============================] - 1s 12ms/step - loss: 0.0519 - val_loss: 0.0075\n",
      "Epoch 53/90\n",
      "129/129 [==============================] - 2s 12ms/step - loss: 0.0519 - val_loss: 0.0076\n",
      "Epoch 54/90\n",
      "129/129 [==============================] - 1s 12ms/step - loss: 0.0519 - val_loss: 0.0077\n",
      "Epoch 55/90\n",
      "129/129 [==============================] - 2s 12ms/step - loss: 0.0519 - val_loss: 0.0078\n",
      "Epoch 56/90\n",
      "129/129 [==============================] - 2s 13ms/step - loss: 0.0519 - val_loss: 0.0078\n",
      "Epoch 57/90\n",
      "129/129 [==============================] - 2s 12ms/step - loss: 0.0518 - val_loss: 0.0079\n",
      "Epoch 58/90\n",
      "129/129 [==============================] - 2s 12ms/step - loss: 0.0518 - val_loss: 0.0080\n",
      "Epoch 59/90\n",
      "129/129 [==============================] - 2s 12ms/step - loss: 0.0518 - val_loss: 0.0080\n",
      "Epoch 60/90\n",
      "129/129 [==============================] - 1s 12ms/step - loss: 0.0518 - val_loss: 0.0081\n",
      "Epoch 61/90\n",
      "129/129 [==============================] - 2s 12ms/step - loss: 0.0517 - val_loss: 0.0082\n",
      "Epoch 62/90\n",
      "129/129 [==============================] - 2s 12ms/step - loss: 0.0517 - val_loss: 0.0082\n",
      "Epoch 63/90\n",
      "129/129 [==============================] - 1s 12ms/step - loss: 0.0517 - val_loss: 0.0083\n",
      "Epoch 64/90\n",
      "129/129 [==============================] - 2s 12ms/step - loss: 0.0517 - val_loss: 0.0084\n",
      "Epoch 65/90\n",
      "129/129 [==============================] - 2s 12ms/step - loss: 0.0517 - val_loss: 0.0084\n",
      "Epoch 66/90\n",
      "129/129 [==============================] - 2s 12ms/step - loss: 0.0517 - val_loss: 0.0085\n",
      "Epoch 67/90\n",
      "129/129 [==============================] - 2s 12ms/step - loss: 0.0516 - val_loss: 0.0085\n",
      "Epoch 68/90\n",
      "129/129 [==============================] - 2s 12ms/step - loss: 0.0517 - val_loss: 0.0086\n",
      "Epoch 69/90\n",
      "129/129 [==============================] - 1s 12ms/step - loss: 0.0517 - val_loss: 0.0087\n",
      "Epoch 70/90\n",
      "129/129 [==============================] - 2s 12ms/step - loss: 0.0517 - val_loss: 0.0087\n",
      "Epoch 71/90\n",
      "129/129 [==============================] - 2s 12ms/step - loss: 0.0516 - val_loss: 0.0088\n",
      "Epoch 72/90\n",
      "129/129 [==============================] - 2s 12ms/step - loss: 0.0516 - val_loss: 0.0088\n",
      "Epoch 73/90\n",
      "129/129 [==============================] - 2s 12ms/step - loss: 0.0516 - val_loss: 0.0088\n",
      "Epoch 74/90\n",
      "129/129 [==============================] - 2s 12ms/step - loss: 0.0516 - val_loss: 0.0089\n",
      "Epoch 75/90\n",
      "129/129 [==============================] - 2s 12ms/step - loss: 0.0516 - val_loss: 0.0089\n",
      "Epoch 76/90\n",
      "129/129 [==============================] - 2s 12ms/step - loss: 0.0516 - val_loss: 0.0090\n",
      "Epoch 77/90\n",
      "129/129 [==============================] - 2s 13ms/step - loss: 0.0516 - val_loss: 0.0090\n",
      "Epoch 78/90\n",
      "129/129 [==============================] - 2s 12ms/step - loss: 0.0516 - val_loss: 0.0091\n",
      "Epoch 79/90\n",
      "129/129 [==============================] - 2s 12ms/step - loss: 0.0515 - val_loss: 0.0091\n",
      "Epoch 80/90\n",
      "129/129 [==============================] - 2s 12ms/step - loss: 0.0516 - val_loss: 0.0092\n",
      "Epoch 81/90\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "129/129 [==============================] - 2s 12ms/step - loss: 0.0516 - val_loss: 0.0092\n",
      "Epoch 82/90\n",
      "129/129 [==============================] - 1s 12ms/step - loss: 0.0515 - val_loss: 0.0093\n",
      "Epoch 83/90\n",
      "129/129 [==============================] - 1s 12ms/step - loss: 0.0515 - val_loss: 0.0093\n",
      "Epoch 84/90\n",
      "129/129 [==============================] - 1s 12ms/step - loss: 0.0515 - val_loss: 0.0093\n",
      "Epoch 85/90\n",
      "129/129 [==============================] - 1s 12ms/step - loss: 0.0515 - val_loss: 0.0094\n",
      "Epoch 86/90\n",
      "129/129 [==============================] - 1s 12ms/step - loss: 0.0515 - val_loss: 0.0094\n",
      "Epoch 87/90\n",
      "129/129 [==============================] - 2s 13ms/step - loss: 0.0515 - val_loss: 0.0094\n",
      "Epoch 88/90\n",
      "129/129 [==============================] - 2s 12ms/step - loss: 0.0515 - val_loss: 0.0095\n",
      "Epoch 89/90\n",
      "129/129 [==============================] - 1s 12ms/step - loss: 0.0515 - val_loss: 0.0095\n",
      "Epoch 90/90\n",
      "129/129 [==============================] - 1s 12ms/step - loss: 0.0515 - val_loss: 0.0095\n",
      "Execution time:  139.52779269218445\n",
      "DNN:\n",
      "Mean Absolute Error: 0.0196\n",
      "Root Mean Square Error: 0.0345\n",
      "Mean Square Error: 0.0012\n",
      "\n",
      "Train RMSE: 0.034\n",
      "Train MSE: 0.001\n",
      "Train MAE: 0.020\n",
      "###########################\n",
      "\n",
      "MODEL:  DNN\n",
      "sequence:  3d\n",
      "units:  12\n",
      "dropout1:  0.48476373451509647\n",
      "optimizer: adadelta\n",
      "activationDense: tanh\n",
      "epochs: 52\n",
      "batchsize: 57\n",
      "validation_split: 0.1\n",
      "Model: \"sequential_194\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_582 (Dense)            (None, 432, 12)           24        \n",
      "_________________________________________________________________\n",
      "dense_583 (Dense)            (None, 432, 16)           208       \n",
      "_________________________________________________________________\n",
      "dropout_194 (Dropout)        (None, 432, 16)           0         \n",
      "_________________________________________________________________\n",
      "dense_584 (Dense)            (None, 432, 1)            17        \n",
      "=================================================================\n",
      "Total params: 249\n",
      "Trainable params: 249\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/52\n",
      "57/57 [==============================] - 1s 17ms/step - loss: 0.5384 - val_loss: 0.4988\n",
      "Epoch 2/52\n",
      "57/57 [==============================] - 1s 14ms/step - loss: 0.5376 - val_loss: 0.4981\n",
      "Epoch 3/52\n",
      "57/57 [==============================] - 1s 14ms/step - loss: 0.5368 - val_loss: 0.4974\n",
      "Epoch 4/52\n",
      "57/57 [==============================] - 1s 14ms/step - loss: 0.5361 - val_loss: 0.4966\n",
      "Epoch 5/52\n",
      "57/57 [==============================] - 1s 14ms/step - loss: 0.5354 - val_loss: 0.4958\n",
      "Epoch 6/52\n",
      "57/57 [==============================] - 1s 14ms/step - loss: 0.5346 - val_loss: 0.4949\n",
      "Epoch 7/52\n",
      "57/57 [==============================] - 1s 14ms/step - loss: 0.5337 - val_loss: 0.4941\n",
      "Epoch 8/52\n",
      "57/57 [==============================] - 1s 14ms/step - loss: 0.5327 - val_loss: 0.4932\n",
      "Epoch 9/52\n",
      "57/57 [==============================] - 1s 14ms/step - loss: 0.5318 - val_loss: 0.4923\n",
      "Epoch 10/52\n",
      "57/57 [==============================] - 1s 14ms/step - loss: 0.5309 - val_loss: 0.4913\n",
      "Epoch 11/52\n",
      "57/57 [==============================] - 1s 15ms/step - loss: 0.5299 - val_loss: 0.4903\n",
      "Epoch 12/52\n",
      "57/57 [==============================] - 1s 16ms/step - loss: 0.5289 - val_loss: 0.4893\n",
      "Epoch 13/52\n",
      "57/57 [==============================] - 1s 15ms/step - loss: 0.5278 - val_loss: 0.4883\n",
      "Epoch 14/52\n",
      "57/57 [==============================] - 1s 14ms/step - loss: 0.5268 - val_loss: 0.4872\n",
      "Epoch 15/52\n",
      "57/57 [==============================] - 1s 14ms/step - loss: 0.5259 - val_loss: 0.4862\n",
      "Epoch 16/52\n",
      "57/57 [==============================] - 1s 14ms/step - loss: 0.5247 - val_loss: 0.4851\n",
      "Epoch 17/52\n",
      "57/57 [==============================] - 1s 14ms/step - loss: 0.5235 - val_loss: 0.4839\n",
      "Epoch 18/52\n",
      "57/57 [==============================] - 1s 14ms/step - loss: 0.5226 - val_loss: 0.4828\n",
      "Epoch 19/52\n",
      "57/57 [==============================] - 1s 14ms/step - loss: 0.5215 - val_loss: 0.4816\n",
      "Epoch 20/52\n",
      "57/57 [==============================] - 1s 14ms/step - loss: 0.5202 - val_loss: 0.4804\n",
      "Epoch 21/52\n",
      "57/57 [==============================] - 1s 14ms/step - loss: 0.5188 - val_loss: 0.4792\n",
      "Epoch 22/52\n",
      "57/57 [==============================] - 1s 14ms/step - loss: 0.5177 - val_loss: 0.4780\n",
      "Epoch 23/52\n",
      "57/57 [==============================] - 1s 15ms/step - loss: 0.5163 - val_loss: 0.4767\n",
      "Epoch 24/52\n",
      "57/57 [==============================] - 1s 14ms/step - loss: 0.5153 - val_loss: 0.4755\n",
      "Epoch 25/52\n",
      "57/57 [==============================] - 1s 14ms/step - loss: 0.5139 - val_loss: 0.4742\n",
      "Epoch 26/52\n",
      "57/57 [==============================] - 1s 14ms/step - loss: 0.5127 - val_loss: 0.4729\n",
      "Epoch 27/52\n",
      "57/57 [==============================] - 1s 14ms/step - loss: 0.5112 - val_loss: 0.4715\n",
      "Epoch 28/52\n",
      "57/57 [==============================] - 1s 14ms/step - loss: 0.5099 - val_loss: 0.4702\n",
      "Epoch 29/52\n",
      "57/57 [==============================] - 1s 14ms/step - loss: 0.5085 - val_loss: 0.4688\n",
      "Epoch 30/52\n",
      "57/57 [==============================] - 1s 15ms/step - loss: 0.5070 - val_loss: 0.4674\n",
      "Epoch 31/52\n",
      "57/57 [==============================] - 1s 15ms/step - loss: 0.5058 - val_loss: 0.4660\n",
      "Epoch 32/52\n",
      "57/57 [==============================] - 1s 16ms/step - loss: 0.5042 - val_loss: 0.4646\n",
      "Epoch 33/52\n",
      "57/57 [==============================] - 1s 15ms/step - loss: 0.5027 - val_loss: 0.4632\n",
      "Epoch 34/52\n",
      "57/57 [==============================] - 1s 14ms/step - loss: 0.5011 - val_loss: 0.4617\n",
      "Epoch 35/52\n",
      "57/57 [==============================] - 1s 14ms/step - loss: 0.4998 - val_loss: 0.4602\n",
      "Epoch 36/52\n",
      "57/57 [==============================] - 1s 14ms/step - loss: 0.4984 - val_loss: 0.4588\n",
      "Epoch 37/52\n",
      "57/57 [==============================] - 1s 14ms/step - loss: 0.4968 - val_loss: 0.4572\n",
      "Epoch 38/52\n",
      "57/57 [==============================] - 1s 14ms/step - loss: 0.4954 - val_loss: 0.4557\n",
      "Epoch 39/52\n",
      "57/57 [==============================] - 1s 14ms/step - loss: 0.4939 - val_loss: 0.4542\n",
      "Epoch 40/52\n",
      "57/57 [==============================] - 1s 14ms/step - loss: 0.4923 - val_loss: 0.4526\n",
      "Epoch 41/52\n",
      "57/57 [==============================] - 1s 14ms/step - loss: 0.4906 - val_loss: 0.4510\n",
      "Epoch 42/52\n",
      "57/57 [==============================] - 1s 14ms/step - loss: 0.4889 - val_loss: 0.4495\n",
      "Epoch 43/52\n",
      "57/57 [==============================] - 1s 14ms/step - loss: 0.4874 - val_loss: 0.4478\n",
      "Epoch 44/52\n",
      "57/57 [==============================] - 1s 14ms/step - loss: 0.4857 - val_loss: 0.4462\n",
      "Epoch 45/52\n",
      "57/57 [==============================] - 1s 14ms/step - loss: 0.4841 - val_loss: 0.4446\n",
      "Epoch 46/52\n",
      "57/57 [==============================] - 1s 14ms/step - loss: 0.4826 - val_loss: 0.4429\n",
      "Epoch 47/52\n",
      "57/57 [==============================] - 1s 14ms/step - loss: 0.4806 - val_loss: 0.4413\n",
      "Epoch 48/52\n",
      "57/57 [==============================] - 1s 14ms/step - loss: 0.4791 - val_loss: 0.4396\n",
      "Epoch 49/52\n",
      "57/57 [==============================] - 1s 15ms/step - loss: 0.4772 - val_loss: 0.4379\n",
      "Epoch 50/52\n",
      "57/57 [==============================] - 1s 15ms/step - loss: 0.4756 - val_loss: 0.4361\n",
      "Epoch 51/52\n",
      "57/57 [==============================] - 1s 16ms/step - loss: 0.4739 - val_loss: 0.4345\n",
      "Epoch 52/52\n",
      "57/57 [==============================] - 1s 15ms/step - loss: 0.4723 - val_loss: 0.4329\n",
      "Execution time:  44.01806664466858\n",
      "DNN:\n",
      "Mean Absolute Error: 0.4708\n",
      "Root Mean Square Error: 0.4737\n",
      "Mean Square Error: 0.2244\n",
      "\n",
      "Train RMSE: 0.474\n",
      "Train MSE: 0.224\n",
      "Train MAE: 0.471\n",
      "###########################\n",
      "\n",
      "MODEL:  DNN\n",
      "sequence:  3d\n",
      "units:  87\n",
      "dropout1:  0.40519643149940265\n",
      "optimizer: adadelta\n",
      "activationDense: tanh\n",
      "epochs: 80\n",
      "batchsize: 31\n",
      "validation_split: 0.2\n",
      "Model: \"sequential_195\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_585 (Dense)            (None, 432, 87)           174       \n",
      "_________________________________________________________________\n",
      "dense_586 (Dense)            (None, 432, 16)           1408      \n",
      "_________________________________________________________________\n",
      "dropout_195 (Dropout)        (None, 432, 16)           0         \n",
      "_________________________________________________________________\n",
      "dense_587 (Dense)            (None, 432, 1)            17        \n",
      "=================================================================\n",
      "Total params: 1,599\n",
      "Trainable params: 1,599\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/80\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "92/92 [==============================] - 2s 21ms/step - loss: 0.4453 - val_loss: 0.4163\n",
      "Epoch 2/80\n",
      "92/92 [==============================] - 1s 16ms/step - loss: 0.4433 - val_loss: 0.4141\n",
      "Epoch 3/80\n",
      "92/92 [==============================] - 1s 16ms/step - loss: 0.4411 - val_loss: 0.4118\n",
      "Epoch 4/80\n",
      "92/92 [==============================] - 1s 16ms/step - loss: 0.4386 - val_loss: 0.4095\n",
      "Epoch 5/80\n",
      "92/92 [==============================] - 1s 16ms/step - loss: 0.4363 - val_loss: 0.4071\n",
      "Epoch 6/80\n",
      "92/92 [==============================] - 1s 16ms/step - loss: 0.4338 - val_loss: 0.4046\n",
      "Epoch 7/80\n",
      "92/92 [==============================] - 1s 16ms/step - loss: 0.4312 - val_loss: 0.4021\n",
      "Epoch 8/80\n",
      "92/92 [==============================] - 1s 16ms/step - loss: 0.4285 - val_loss: 0.3994\n",
      "Epoch 9/80\n",
      "92/92 [==============================] - 2s 17ms/step - loss: 0.4258 - val_loss: 0.3967\n",
      "Epoch 10/80\n",
      "92/92 [==============================] - 2s 17ms/step - loss: 0.4230 - val_loss: 0.3939\n",
      "Epoch 11/80\n",
      "92/92 [==============================] - 1s 16ms/step - loss: 0.4202 - val_loss: 0.3912\n",
      "Epoch 12/80\n",
      "92/92 [==============================] - 1s 16ms/step - loss: 0.4173 - val_loss: 0.3884\n",
      "Epoch 13/80\n",
      "92/92 [==============================] - 1s 16ms/step - loss: 0.4145 - val_loss: 0.3855\n",
      "Epoch 14/80\n",
      "92/92 [==============================] - 1s 16ms/step - loss: 0.4115 - val_loss: 0.3825\n",
      "Epoch 15/80\n",
      "92/92 [==============================] - 1s 16ms/step - loss: 0.4085 - val_loss: 0.3796\n",
      "Epoch 16/80\n",
      "92/92 [==============================] - 1s 16ms/step - loss: 0.4054 - val_loss: 0.3765\n",
      "Epoch 17/80\n",
      "92/92 [==============================] - 1s 16ms/step - loss: 0.4023 - val_loss: 0.3734\n",
      "Epoch 18/80\n",
      "92/92 [==============================] - 1s 16ms/step - loss: 0.3991 - val_loss: 0.3703\n",
      "Epoch 19/80\n",
      "92/92 [==============================] - 2s 17ms/step - loss: 0.3959 - val_loss: 0.3671\n",
      "Epoch 20/80\n",
      "92/92 [==============================] - 2s 17ms/step - loss: 0.3926 - val_loss: 0.3638\n",
      "Epoch 21/80\n",
      "92/92 [==============================] - 1s 16ms/step - loss: 0.3893 - val_loss: 0.3605\n",
      "Epoch 22/80\n",
      "92/92 [==============================] - 1s 16ms/step - loss: 0.3859 - val_loss: 0.3572\n",
      "Epoch 23/80\n",
      "92/92 [==============================] - 1s 16ms/step - loss: 0.3825 - val_loss: 0.3540\n",
      "Epoch 24/80\n",
      "92/92 [==============================] - 1s 16ms/step - loss: 0.3793 - val_loss: 0.3510\n",
      "Epoch 25/80\n",
      "92/92 [==============================] - 1s 16ms/step - loss: 0.3761 - val_loss: 0.3478\n",
      "Epoch 26/80\n",
      "92/92 [==============================] - 1s 16ms/step - loss: 0.3729 - val_loss: 0.3447\n",
      "Epoch 27/80\n",
      "92/92 [==============================] - 1s 16ms/step - loss: 0.3697 - val_loss: 0.3415\n",
      "Epoch 28/80\n",
      "92/92 [==============================] - 1s 16ms/step - loss: 0.3664 - val_loss: 0.3383\n",
      "Epoch 29/80\n",
      "92/92 [==============================] - 1s 16ms/step - loss: 0.3631 - val_loss: 0.3350\n",
      "Epoch 30/80\n",
      "92/92 [==============================] - 2s 17ms/step - loss: 0.3598 - val_loss: 0.3316\n",
      "Epoch 31/80\n",
      "92/92 [==============================] - 2s 17ms/step - loss: 0.3562 - val_loss: 0.3282\n",
      "Epoch 32/80\n",
      "92/92 [==============================] - 2s 17ms/step - loss: 0.3529 - val_loss: 0.3248\n",
      "Epoch 33/80\n",
      "92/92 [==============================] - 1s 16ms/step - loss: 0.3494 - val_loss: 0.3214\n",
      "Epoch 34/80\n",
      "92/92 [==============================] - 1s 16ms/step - loss: 0.3458 - val_loss: 0.3180\n",
      "Epoch 35/80\n",
      "92/92 [==============================] - 1s 16ms/step - loss: 0.3424 - val_loss: 0.3145\n",
      "Epoch 36/80\n",
      "92/92 [==============================] - 1s 16ms/step - loss: 0.3388 - val_loss: 0.3110\n",
      "Epoch 37/80\n",
      "92/92 [==============================] - 1s 16ms/step - loss: 0.3351 - val_loss: 0.3074\n",
      "Epoch 38/80\n",
      "92/92 [==============================] - 1s 16ms/step - loss: 0.3316 - val_loss: 0.3038\n",
      "Epoch 39/80\n",
      "92/92 [==============================] - 1s 16ms/step - loss: 0.3279 - val_loss: 0.3001\n",
      "Epoch 40/80\n",
      "92/92 [==============================] - 1s 16ms/step - loss: 0.3242 - val_loss: 0.2965\n",
      "Epoch 41/80\n",
      "92/92 [==============================] - 2s 17ms/step - loss: 0.3205 - val_loss: 0.2929\n",
      "Epoch 42/80\n",
      "92/92 [==============================] - 2s 17ms/step - loss: 0.3169 - val_loss: 0.2895\n",
      "Epoch 43/80\n",
      "92/92 [==============================] - 1s 16ms/step - loss: 0.3135 - val_loss: 0.2866\n",
      "Epoch 44/80\n",
      "92/92 [==============================] - 1s 16ms/step - loss: 0.3105 - val_loss: 0.2838\n",
      "Epoch 45/80\n",
      "92/92 [==============================] - 1s 16ms/step - loss: 0.3075 - val_loss: 0.2810\n",
      "Epoch 46/80\n",
      "92/92 [==============================] - 1s 16ms/step - loss: 0.3047 - val_loss: 0.2782\n",
      "Epoch 47/80\n",
      "92/92 [==============================] - 1s 16ms/step - loss: 0.3017 - val_loss: 0.2754\n",
      "Epoch 48/80\n",
      "92/92 [==============================] - 1s 16ms/step - loss: 0.2988 - val_loss: 0.2726\n",
      "Epoch 49/80\n",
      "92/92 [==============================] - 1s 16ms/step - loss: 0.2958 - val_loss: 0.2697\n",
      "Epoch 50/80\n",
      "92/92 [==============================] - 1s 16ms/step - loss: 0.2929 - val_loss: 0.2668\n",
      "Epoch 51/80\n",
      "92/92 [==============================] - 2s 17ms/step - loss: 0.2899 - val_loss: 0.2638\n",
      "Epoch 52/80\n",
      "92/92 [==============================] - 2s 17ms/step - loss: 0.2869 - val_loss: 0.2608\n",
      "Epoch 53/80\n",
      "92/92 [==============================] - 1s 16ms/step - loss: 0.2838 - val_loss: 0.2578\n",
      "Epoch 54/80\n",
      "92/92 [==============================] - 1s 16ms/step - loss: 0.2807 - val_loss: 0.2547\n",
      "Epoch 55/80\n",
      "92/92 [==============================] - 1s 16ms/step - loss: 0.2775 - val_loss: 0.2515\n",
      "Epoch 56/80\n",
      "92/92 [==============================] - 1s 16ms/step - loss: 0.2743 - val_loss: 0.2483\n",
      "Epoch 57/80\n",
      "92/92 [==============================] - 1s 16ms/step - loss: 0.2709 - val_loss: 0.2450\n",
      "Epoch 58/80\n",
      "92/92 [==============================] - 1s 16ms/step - loss: 0.2677 - val_loss: 0.2417\n",
      "Epoch 59/80\n",
      "92/92 [==============================] - 1s 16ms/step - loss: 0.2644 - val_loss: 0.2383\n",
      "Epoch 60/80\n",
      "92/92 [==============================] - 1s 16ms/step - loss: 0.2608 - val_loss: 0.2349\n",
      "Epoch 61/80\n",
      "92/92 [==============================] - 1s 16ms/step - loss: 0.2574 - val_loss: 0.2314\n",
      "Epoch 62/80\n",
      "92/92 [==============================] - 2s 17ms/step - loss: 0.2540 - val_loss: 0.2278\n",
      "Epoch 63/80\n",
      "92/92 [==============================] - 2s 17ms/step - loss: 0.2504 - val_loss: 0.2242\n",
      "Epoch 64/80\n",
      "92/92 [==============================] - 1s 16ms/step - loss: 0.2467 - val_loss: 0.2205\n",
      "Epoch 65/80\n",
      "92/92 [==============================] - 1s 16ms/step - loss: 0.2430 - val_loss: 0.2168\n",
      "Epoch 66/80\n",
      "92/92 [==============================] - 1s 16ms/step - loss: 0.2393 - val_loss: 0.2130\n",
      "Epoch 67/80\n",
      "92/92 [==============================] - 1s 16ms/step - loss: 0.2353 - val_loss: 0.2091\n",
      "Epoch 68/80\n",
      "92/92 [==============================] - 1s 16ms/step - loss: 0.2317 - val_loss: 0.2051\n",
      "Epoch 69/80\n",
      "92/92 [==============================] - 1s 16ms/step - loss: 0.2277 - val_loss: 0.2011\n",
      "Epoch 70/80\n",
      "92/92 [==============================] - 1s 16ms/step - loss: 0.2236 - val_loss: 0.1970\n",
      "Epoch 71/80\n",
      "92/92 [==============================] - 1s 16ms/step - loss: 0.2197 - val_loss: 0.1929\n",
      "Epoch 72/80\n",
      "92/92 [==============================] - 1s 16ms/step - loss: 0.2155 - val_loss: 0.1886\n",
      "Epoch 73/80\n",
      "92/92 [==============================] - 2s 17ms/step - loss: 0.2115 - val_loss: 0.1843\n",
      "Epoch 74/80\n",
      "92/92 [==============================] - 1s 16ms/step - loss: 0.2071 - val_loss: 0.1800\n",
      "Epoch 75/80\n",
      "92/92 [==============================] - 1s 16ms/step - loss: 0.2028 - val_loss: 0.1755\n",
      "Epoch 76/80\n",
      "92/92 [==============================] - 1s 16ms/step - loss: 0.1984 - val_loss: 0.1710\n",
      "Epoch 77/80\n",
      "92/92 [==============================] - 1s 16ms/step - loss: 0.1940 - val_loss: 0.1665\n",
      "Epoch 78/80\n",
      "92/92 [==============================] - 1s 16ms/step - loss: 0.1899 - val_loss: 0.1618\n",
      "Epoch 79/80\n",
      "92/92 [==============================] - 1s 16ms/step - loss: 0.1853 - val_loss: 0.1572\n",
      "Epoch 80/80\n",
      "92/92 [==============================] - 1s 16ms/step - loss: 0.1807 - val_loss: 0.1525\n",
      "Execution time:  121.32032632827759\n",
      "DNN:\n",
      "Mean Absolute Error: 0.1728\n",
      "Root Mean Square Error: 0.1756\n",
      "Mean Square Error: 0.0308\n",
      "\n",
      "Train RMSE: 0.176\n",
      "Train MSE: 0.031\n",
      "Train MAE: 0.173\n",
      "###########################\n",
      "\n",
      "MODEL:  DNN\n",
      "sequence:  3d\n",
      "units:  80\n",
      "dropout1:  0.11814836227952394\n",
      "optimizer: adadelta\n",
      "activationDense: tanh\n",
      "epochs: 90\n",
      "batchsize: 25\n",
      "validation_split: 0.2\n",
      "Model: \"sequential_196\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_588 (Dense)            (None, 432, 80)           160       \n",
      "_________________________________________________________________\n",
      "dense_589 (Dense)            (None, 432, 16)           1296      \n",
      "_________________________________________________________________\n",
      "dropout_196 (Dropout)        (None, 432, 16)           0         \n",
      "_________________________________________________________________\n",
      "dense_590 (Dense)            (None, 432, 1)            17        \n",
      "=================================================================\n",
      "Total params: 1,473\n",
      "Trainable params: 1,473\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/90\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "114/114 [==============================] - 2s 14ms/step - loss: 0.4171 - val_loss: 0.3887\n",
      "Epoch 2/90\n",
      "114/114 [==============================] - 1s 13ms/step - loss: 0.4139 - val_loss: 0.3854\n",
      "Epoch 3/90\n",
      "114/114 [==============================] - 1s 13ms/step - loss: 0.4104 - val_loss: 0.3818\n",
      "Epoch 4/90\n",
      "114/114 [==============================] - 1s 12ms/step - loss: 0.4066 - val_loss: 0.3780\n",
      "Epoch 5/90\n",
      "114/114 [==============================] - 1s 12ms/step - loss: 0.4026 - val_loss: 0.3739\n",
      "Epoch 6/90\n",
      "114/114 [==============================] - 1s 12ms/step - loss: 0.3983 - val_loss: 0.3696\n",
      "Epoch 7/90\n",
      "114/114 [==============================] - 1s 12ms/step - loss: 0.3938 - val_loss: 0.3651\n",
      "Epoch 8/90\n",
      "114/114 [==============================] - 1s 12ms/step - loss: 0.3891 - val_loss: 0.3603\n",
      "Epoch 9/90\n",
      "114/114 [==============================] - 1s 12ms/step - loss: 0.3841 - val_loss: 0.3554\n",
      "Epoch 10/90\n",
      "114/114 [==============================] - 1s 12ms/step - loss: 0.3790 - val_loss: 0.3503\n",
      "Epoch 11/90\n",
      "114/114 [==============================] - 1s 12ms/step - loss: 0.3737 - val_loss: 0.3450\n",
      "Epoch 12/90\n",
      "114/114 [==============================] - 1s 12ms/step - loss: 0.3682 - val_loss: 0.3395\n",
      "Epoch 13/90\n",
      "114/114 [==============================] - 1s 13ms/step - loss: 0.3624 - val_loss: 0.3337\n",
      "Epoch 14/90\n",
      "114/114 [==============================] - 1s 13ms/step - loss: 0.3565 - val_loss: 0.3278\n",
      "Epoch 15/90\n",
      "114/114 [==============================] - 1s 13ms/step - loss: 0.3503 - val_loss: 0.3217\n",
      "Epoch 16/90\n",
      "114/114 [==============================] - 1s 13ms/step - loss: 0.3441 - val_loss: 0.3155\n",
      "Epoch 17/90\n",
      "114/114 [==============================] - 2s 13ms/step - loss: 0.3376 - val_loss: 0.3093\n",
      "Epoch 18/90\n",
      "114/114 [==============================] - 1s 12ms/step - loss: 0.3314 - val_loss: 0.3032\n",
      "Epoch 19/90\n",
      "114/114 [==============================] - 1s 12ms/step - loss: 0.3251 - val_loss: 0.2970\n",
      "Epoch 20/90\n",
      "114/114 [==============================] - 1s 12ms/step - loss: 0.3186 - val_loss: 0.2905\n",
      "Epoch 21/90\n",
      "114/114 [==============================] - 1s 12ms/step - loss: 0.3119 - val_loss: 0.2839\n",
      "Epoch 22/90\n",
      "114/114 [==============================] - 1s 12ms/step - loss: 0.3050 - val_loss: 0.2771\n",
      "Epoch 23/90\n",
      "114/114 [==============================] - 1s 12ms/step - loss: 0.2980 - val_loss: 0.2700\n",
      "Epoch 24/90\n",
      "114/114 [==============================] - 1s 13ms/step - loss: 0.2907 - val_loss: 0.2628\n",
      "Epoch 25/90\n",
      "114/114 [==============================] - 1s 13ms/step - loss: 0.2832 - val_loss: 0.2554\n",
      "Epoch 26/90\n",
      "114/114 [==============================] - 1s 12ms/step - loss: 0.2756 - val_loss: 0.2478\n",
      "Epoch 27/90\n",
      "114/114 [==============================] - 1s 12ms/step - loss: 0.2677 - val_loss: 0.2402\n",
      "Epoch 28/90\n",
      "114/114 [==============================] - 1s 12ms/step - loss: 0.2602 - val_loss: 0.2333\n",
      "Epoch 29/90\n",
      "114/114 [==============================] - 1s 12ms/step - loss: 0.2531 - val_loss: 0.2263\n",
      "Epoch 30/90\n",
      "114/114 [==============================] - 1s 12ms/step - loss: 0.2458 - val_loss: 0.2191\n",
      "Epoch 31/90\n",
      "114/114 [==============================] - 1s 13ms/step - loss: 0.2383 - val_loss: 0.2117\n",
      "Epoch 32/90\n",
      "114/114 [==============================] - 1s 13ms/step - loss: 0.2306 - val_loss: 0.2040\n",
      "Epoch 33/90\n",
      "114/114 [==============================] - 1s 12ms/step - loss: 0.2227 - val_loss: 0.1961\n",
      "Epoch 34/90\n",
      "114/114 [==============================] - 1s 12ms/step - loss: 0.2147 - val_loss: 0.1881\n",
      "Epoch 35/90\n",
      "114/114 [==============================] - 1s 13ms/step - loss: 0.2063 - val_loss: 0.1797\n",
      "Epoch 36/90\n",
      "114/114 [==============================] - 2s 13ms/step - loss: 0.1978 - val_loss: 0.1712\n",
      "Epoch 37/90\n",
      "114/114 [==============================] - 1s 13ms/step - loss: 0.1890 - val_loss: 0.1624\n",
      "Epoch 38/90\n",
      "114/114 [==============================] - 1s 12ms/step - loss: 0.1800 - val_loss: 0.1533\n",
      "Epoch 39/90\n",
      "114/114 [==============================] - 1s 13ms/step - loss: 0.1707 - val_loss: 0.1440\n",
      "Epoch 40/90\n",
      "114/114 [==============================] - 2s 13ms/step - loss: 0.1612 - val_loss: 0.1344\n",
      "Epoch 41/90\n",
      "114/114 [==============================] - 1s 12ms/step - loss: 0.1514 - val_loss: 0.1246\n",
      "Epoch 42/90\n",
      "114/114 [==============================] - 1s 12ms/step - loss: 0.1413 - val_loss: 0.1144\n",
      "Epoch 43/90\n",
      "114/114 [==============================] - 1s 12ms/step - loss: 0.1310 - val_loss: 0.1040\n",
      "Epoch 44/90\n",
      "114/114 [==============================] - 1s 12ms/step - loss: 0.1204 - val_loss: 0.0933\n",
      "Epoch 45/90\n",
      "114/114 [==============================] - 1s 12ms/step - loss: 0.1089 - val_loss: 0.0800\n",
      "Epoch 46/90\n",
      "114/114 [==============================] - 1s 13ms/step - loss: 0.0948 - val_loss: 0.0648\n",
      "Epoch 47/90\n",
      "114/114 [==============================] - 2s 13ms/step - loss: 0.0810 - val_loss: 0.0507\n",
      "Epoch 48/90\n",
      "114/114 [==============================] - 1s 13ms/step - loss: 0.0707 - val_loss: 0.0397\n",
      "Epoch 49/90\n",
      "114/114 [==============================] - 1s 12ms/step - loss: 0.0648 - val_loss: 0.0343\n",
      "Epoch 50/90\n",
      "114/114 [==============================] - 1s 12ms/step - loss: 0.0631 - val_loss: 0.0305\n",
      "Epoch 51/90\n",
      "114/114 [==============================] - 1s 12ms/step - loss: 0.0621 - val_loss: 0.0280\n",
      "Epoch 52/90\n",
      "114/114 [==============================] - 1s 12ms/step - loss: 0.0616 - val_loss: 0.0261\n",
      "Epoch 53/90\n",
      "114/114 [==============================] - 1s 12ms/step - loss: 0.0612 - val_loss: 0.0247\n",
      "Epoch 54/90\n",
      "114/114 [==============================] - 1s 12ms/step - loss: 0.0611 - val_loss: 0.0237\n",
      "Epoch 55/90\n",
      "114/114 [==============================] - 1s 12ms/step - loss: 0.0609 - val_loss: 0.0228\n",
      "Epoch 56/90\n",
      "114/114 [==============================] - 1s 12ms/step - loss: 0.0608 - val_loss: 0.0221\n",
      "Epoch 57/90\n",
      "114/114 [==============================] - 1s 13ms/step - loss: 0.0607 - val_loss: 0.0215\n",
      "Epoch 58/90\n",
      "114/114 [==============================] - 2s 13ms/step - loss: 0.0606 - val_loss: 0.0211\n",
      "Epoch 59/90\n",
      "114/114 [==============================] - 1s 13ms/step - loss: 0.0606 - val_loss: 0.0207\n",
      "Epoch 60/90\n",
      "114/114 [==============================] - 1s 12ms/step - loss: 0.0605 - val_loss: 0.0204\n",
      "Epoch 61/90\n",
      "114/114 [==============================] - 1s 12ms/step - loss: 0.0605 - val_loss: 0.0202\n",
      "Epoch 62/90\n",
      "114/114 [==============================] - 1s 12ms/step - loss: 0.0605 - val_loss: 0.0200\n",
      "Epoch 63/90\n",
      "114/114 [==============================] - 1s 12ms/step - loss: 0.0605 - val_loss: 0.0198\n",
      "Epoch 64/90\n",
      "114/114 [==============================] - 1s 13ms/step - loss: 0.0604 - val_loss: 0.0196\n",
      "Epoch 65/90\n",
      "114/114 [==============================] - 1s 12ms/step - loss: 0.0604 - val_loss: 0.0194\n",
      "Epoch 66/90\n",
      "114/114 [==============================] - 1s 12ms/step - loss: 0.0603 - val_loss: 0.0193\n",
      "Epoch 67/90\n",
      "114/114 [==============================] - 1s 12ms/step - loss: 0.0604 - val_loss: 0.0191\n",
      "Epoch 68/90\n",
      "114/114 [==============================] - 1s 13ms/step - loss: 0.0603 - val_loss: 0.0190\n",
      "Epoch 69/90\n",
      "114/114 [==============================] - 2s 13ms/step - loss: 0.0603 - val_loss: 0.0188\n",
      "Epoch 70/90\n",
      "114/114 [==============================] - 1s 13ms/step - loss: 0.0604 - val_loss: 0.0187\n",
      "Epoch 71/90\n",
      "114/114 [==============================] - 1s 12ms/step - loss: 0.0602 - val_loss: 0.0185\n",
      "Epoch 72/90\n",
      "114/114 [==============================] - 1s 12ms/step - loss: 0.0602 - val_loss: 0.0184\n",
      "Epoch 73/90\n",
      "114/114 [==============================] - 1s 12ms/step - loss: 0.0602 - val_loss: 0.0183\n",
      "Epoch 74/90\n",
      "114/114 [==============================] - 1s 12ms/step - loss: 0.0602 - val_loss: 0.0182\n",
      "Epoch 75/90\n",
      "114/114 [==============================] - 1s 12ms/step - loss: 0.0601 - val_loss: 0.0181\n",
      "Epoch 76/90\n",
      "114/114 [==============================] - 1s 12ms/step - loss: 0.0603 - val_loss: 0.0180\n",
      "Epoch 77/90\n",
      "114/114 [==============================] - 1s 12ms/step - loss: 0.0602 - val_loss: 0.0179\n",
      "Epoch 78/90\n",
      "114/114 [==============================] - 1s 12ms/step - loss: 0.0602 - val_loss: 0.0178\n",
      "Epoch 79/90\n",
      "114/114 [==============================] - 1s 12ms/step - loss: 0.0601 - val_loss: 0.0178\n",
      "Epoch 80/90\n",
      "114/114 [==============================] - 1s 13ms/step - loss: 0.0601 - val_loss: 0.0177\n",
      "Epoch 81/90\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "114/114 [==============================] - 1s 13ms/step - loss: 0.0601 - val_loss: 0.0177\n",
      "Epoch 82/90\n",
      "114/114 [==============================] - 1s 12ms/step - loss: 0.0601 - val_loss: 0.0176\n",
      "Epoch 83/90\n",
      "114/114 [==============================] - 1s 12ms/step - loss: 0.0601 - val_loss: 0.0176\n",
      "Epoch 84/90\n",
      "114/114 [==============================] - 1s 12ms/step - loss: 0.0601 - val_loss: 0.0175\n",
      "Epoch 85/90\n",
      "114/114 [==============================] - 1s 12ms/step - loss: 0.0601 - val_loss: 0.0175\n",
      "Epoch 86/90\n",
      "114/114 [==============================] - 1s 12ms/step - loss: 0.0601 - val_loss: 0.0174\n",
      "Epoch 87/90\n",
      "114/114 [==============================] - 1s 12ms/step - loss: 0.0600 - val_loss: 0.0174\n",
      "Epoch 88/90\n",
      "114/114 [==============================] - 1s 12ms/step - loss: 0.0600 - val_loss: 0.0173\n",
      "Epoch 89/90\n",
      "114/114 [==============================] - 1s 12ms/step - loss: 0.0601 - val_loss: 0.0173\n",
      "Epoch 90/90\n",
      "114/114 [==============================] - 1s 12ms/step - loss: 0.0601 - val_loss: 0.0173\n",
      "Execution time:  130.6467320919037\n",
      "DNN:\n",
      "Mean Absolute Error: 0.0330\n",
      "Root Mean Square Error: 0.0420\n",
      "Mean Square Error: 0.0018\n",
      "\n",
      "Train RMSE: 0.042\n",
      "Train MSE: 0.002\n",
      "Train MAE: 0.033\n",
      "###########################\n",
      "\n",
      "MODEL:  DNN\n",
      "sequence:  3d\n",
      "units:  12\n",
      "dropout1:  0.48476373451509647\n",
      "optimizer: adadelta\n",
      "activationDense: tanh\n",
      "epochs: 52\n",
      "batchsize: 57\n",
      "validation_split: 0.2\n",
      "Model: \"sequential_197\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_591 (Dense)            (None, 432, 12)           24        \n",
      "_________________________________________________________________\n",
      "dense_592 (Dense)            (None, 432, 16)           208       \n",
      "_________________________________________________________________\n",
      "dropout_197 (Dropout)        (None, 432, 16)           0         \n",
      "_________________________________________________________________\n",
      "dense_593 (Dense)            (None, 432, 1)            17        \n",
      "=================================================================\n",
      "Total params: 249\n",
      "Trainable params: 249\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/52\n",
      "50/50 [==============================] - 1s 18ms/step - loss: 0.3168 - val_loss: 0.2933\n",
      "Epoch 2/52\n",
      "50/50 [==============================] - 1s 15ms/step - loss: 0.3161 - val_loss: 0.2926\n",
      "Epoch 3/52\n",
      "50/50 [==============================] - 1s 15ms/step - loss: 0.3152 - val_loss: 0.2919\n",
      "Epoch 4/52\n",
      "50/50 [==============================] - 1s 15ms/step - loss: 0.3145 - val_loss: 0.2911\n",
      "Epoch 5/52\n",
      "50/50 [==============================] - 1s 15ms/step - loss: 0.3136 - val_loss: 0.2903\n",
      "Epoch 6/52\n",
      "50/50 [==============================] - 1s 15ms/step - loss: 0.3129 - val_loss: 0.2894\n",
      "Epoch 7/52\n",
      "50/50 [==============================] - 1s 15ms/step - loss: 0.3121 - val_loss: 0.2886\n",
      "Epoch 8/52\n",
      "50/50 [==============================] - 1s 15ms/step - loss: 0.3112 - val_loss: 0.2877\n",
      "Epoch 9/52\n",
      "50/50 [==============================] - 1s 15ms/step - loss: 0.3103 - val_loss: 0.2868\n",
      "Epoch 10/52\n",
      "50/50 [==============================] - 1s 15ms/step - loss: 0.3092 - val_loss: 0.2858\n",
      "Epoch 11/52\n",
      "50/50 [==============================] - 1s 15ms/step - loss: 0.3083 - val_loss: 0.2848\n",
      "Epoch 12/52\n",
      "50/50 [==============================] - 1s 15ms/step - loss: 0.3073 - val_loss: 0.2838\n",
      "Epoch 13/52\n",
      "50/50 [==============================] - 1s 15ms/step - loss: 0.3063 - val_loss: 0.2828\n",
      "Epoch 14/52\n",
      "50/50 [==============================] - 1s 15ms/step - loss: 0.3053 - val_loss: 0.2818\n",
      "Epoch 15/52\n",
      "50/50 [==============================] - 1s 15ms/step - loss: 0.3042 - val_loss: 0.2807\n",
      "Epoch 16/52\n",
      "50/50 [==============================] - 1s 14ms/step - loss: 0.3031 - val_loss: 0.2796\n",
      "Epoch 17/52\n",
      "50/50 [==============================] - 1s 15ms/step - loss: 0.3020 - val_loss: 0.2785\n",
      "Epoch 18/52\n",
      "50/50 [==============================] - 1s 15ms/step - loss: 0.3009 - val_loss: 0.2773\n",
      "Epoch 19/52\n",
      "50/50 [==============================] - 1s 16ms/step - loss: 0.2997 - val_loss: 0.2762\n",
      "Epoch 20/52\n",
      "50/50 [==============================] - 1s 17ms/step - loss: 0.2987 - val_loss: 0.2750\n",
      "Epoch 21/52\n",
      "50/50 [==============================] - 1s 16ms/step - loss: 0.2973 - val_loss: 0.2738\n",
      "Epoch 22/52\n",
      "50/50 [==============================] - 1s 16ms/step - loss: 0.2961 - val_loss: 0.2725\n",
      "Epoch 23/52\n",
      "50/50 [==============================] - 1s 15ms/step - loss: 0.2949 - val_loss: 0.2713\n",
      "Epoch 24/52\n",
      "50/50 [==============================] - 1s 15ms/step - loss: 0.2935 - val_loss: 0.2700\n",
      "Epoch 25/52\n",
      "50/50 [==============================] - 1s 15ms/step - loss: 0.2923 - val_loss: 0.2687\n",
      "Epoch 26/52\n",
      "50/50 [==============================] - 1s 15ms/step - loss: 0.2910 - val_loss: 0.2674\n",
      "Epoch 27/52\n",
      "50/50 [==============================] - 1s 15ms/step - loss: 0.2897 - val_loss: 0.2661\n",
      "Epoch 28/52\n",
      "50/50 [==============================] - 1s 15ms/step - loss: 0.2883 - val_loss: 0.2648\n",
      "Epoch 29/52\n",
      "50/50 [==============================] - 1s 15ms/step - loss: 0.2870 - val_loss: 0.2634\n",
      "Epoch 30/52\n",
      "50/50 [==============================] - 1s 15ms/step - loss: 0.2855 - val_loss: 0.2620\n",
      "Epoch 31/52\n",
      "50/50 [==============================] - 1s 15ms/step - loss: 0.2842 - val_loss: 0.2606\n",
      "Epoch 32/52\n",
      "50/50 [==============================] - 1s 15ms/step - loss: 0.2829 - val_loss: 0.2592\n",
      "Epoch 33/52\n",
      "50/50 [==============================] - 1s 15ms/step - loss: 0.2814 - val_loss: 0.2577\n",
      "Epoch 34/52\n",
      "50/50 [==============================] - 1s 15ms/step - loss: 0.2800 - val_loss: 0.2563\n",
      "Epoch 35/52\n",
      "50/50 [==============================] - 1s 15ms/step - loss: 0.2784 - val_loss: 0.2548\n",
      "Epoch 36/52\n",
      "50/50 [==============================] - 1s 15ms/step - loss: 0.2769 - val_loss: 0.2533\n",
      "Epoch 37/52\n",
      "50/50 [==============================] - 1s 15ms/step - loss: 0.2754 - val_loss: 0.2518\n",
      "Epoch 38/52\n",
      "50/50 [==============================] - 1s 15ms/step - loss: 0.2739 - val_loss: 0.2503\n",
      "Epoch 39/52\n",
      "50/50 [==============================] - 1s 15ms/step - loss: 0.2723 - val_loss: 0.2487\n",
      "Epoch 40/52\n",
      "50/50 [==============================] - 1s 16ms/step - loss: 0.2709 - val_loss: 0.2472\n",
      "Epoch 41/52\n",
      "50/50 [==============================] - 1s 17ms/step - loss: 0.2692 - val_loss: 0.2457\n",
      "Epoch 42/52\n",
      "50/50 [==============================] - 1s 17ms/step - loss: 0.2680 - val_loss: 0.2442\n",
      "Epoch 43/52\n",
      "50/50 [==============================] - 1s 16ms/step - loss: 0.2662 - val_loss: 0.2427\n",
      "Epoch 44/52\n",
      "50/50 [==============================] - 1s 15ms/step - loss: 0.2649 - val_loss: 0.2412\n",
      "Epoch 45/52\n",
      "50/50 [==============================] - 1s 15ms/step - loss: 0.2632 - val_loss: 0.2396\n",
      "Epoch 46/52\n",
      "50/50 [==============================] - 1s 15ms/step - loss: 0.2617 - val_loss: 0.2380\n",
      "Epoch 47/52\n",
      "50/50 [==============================] - 1s 15ms/step - loss: 0.2601 - val_loss: 0.2364\n",
      "Epoch 48/52\n",
      "50/50 [==============================] - 1s 15ms/step - loss: 0.2585 - val_loss: 0.2348\n",
      "Epoch 49/52\n",
      "50/50 [==============================] - 1s 15ms/step - loss: 0.2568 - val_loss: 0.2332\n",
      "Epoch 50/52\n",
      "50/50 [==============================] - 1s 15ms/step - loss: 0.2554 - val_loss: 0.2316\n",
      "Epoch 51/52\n",
      "50/50 [==============================] - 1s 15ms/step - loss: 0.2535 - val_loss: 0.2300\n",
      "Epoch 52/52\n",
      "50/50 [==============================] - 1s 15ms/step - loss: 0.2522 - val_loss: 0.2284\n",
      "Execution time:  41.411032915115356\n",
      "DNN:\n",
      "Mean Absolute Error: 0.2482\n",
      "Root Mean Square Error: 0.2499\n",
      "Mean Square Error: 0.0624\n",
      "\n",
      "Train RMSE: 0.250\n",
      "Train MSE: 0.062\n",
      "Train MAE: 0.248\n",
      "###########################\n",
      "\n",
      "MODEL:  DNN\n",
      "sequence:  3d\n",
      "units:  87\n",
      "dropout1:  0.40519643149940265\n",
      "optimizer: adadelta\n",
      "activationDense: sigmoid\n",
      "epochs: 80\n",
      "batchsize: 31\n",
      "validation_split: 0.1\n",
      "Model: \"sequential_198\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_594 (Dense)            (None, 432, 87)           174       \n",
      "_________________________________________________________________\n",
      "dense_595 (Dense)            (None, 432, 16)           1408      \n",
      "_________________________________________________________________\n",
      "dropout_198 (Dropout)        (None, 432, 16)           0         \n",
      "_________________________________________________________________\n",
      "dense_596 (Dense)            (None, 432, 1)            17        \n",
      "=================================================================\n",
      "Total params: 1,599\n",
      "Trainable params: 1,599\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/80\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "104/104 [==============================] - 2s 17ms/step - loss: 0.1050 - val_loss: 0.1345\n",
      "Epoch 2/80\n",
      "104/104 [==============================] - 2s 15ms/step - loss: 0.1043 - val_loss: 0.1337\n",
      "Epoch 3/80\n",
      "104/104 [==============================] - 2s 15ms/step - loss: 0.1036 - val_loss: 0.1329\n",
      "Epoch 4/80\n",
      "104/104 [==============================] - 2s 16ms/step - loss: 0.1027 - val_loss: 0.1320\n",
      "Epoch 5/80\n",
      "104/104 [==============================] - 2s 16ms/step - loss: 0.1019 - val_loss: 0.1311\n",
      "Epoch 6/80\n",
      "104/104 [==============================] - 2s 15ms/step - loss: 0.1009 - val_loss: 0.1302\n",
      "Epoch 7/80\n",
      "104/104 [==============================] - 2s 15ms/step - loss: 0.1000 - val_loss: 0.1291\n",
      "Epoch 8/80\n",
      "104/104 [==============================] - 2s 15ms/step - loss: 0.0990 - val_loss: 0.1281\n",
      "Epoch 9/80\n",
      "104/104 [==============================] - 2s 15ms/step - loss: 0.0979 - val_loss: 0.1270\n",
      "Epoch 10/80\n",
      "104/104 [==============================] - 2s 15ms/step - loss: 0.0968 - val_loss: 0.1259\n",
      "Epoch 11/80\n",
      "104/104 [==============================] - 2s 15ms/step - loss: 0.0957 - val_loss: 0.1247\n",
      "Epoch 12/80\n",
      "104/104 [==============================] - 2s 15ms/step - loss: 0.0946 - val_loss: 0.1235\n",
      "Epoch 13/80\n",
      "104/104 [==============================] - 2s 15ms/step - loss: 0.0935 - val_loss: 0.1223\n",
      "Epoch 14/80\n",
      "104/104 [==============================] - 2s 16ms/step - loss: 0.0923 - val_loss: 0.1211\n",
      "Epoch 15/80\n",
      "104/104 [==============================] - 2s 16ms/step - loss: 0.0911 - val_loss: 0.1199\n",
      "Epoch 16/80\n",
      "104/104 [==============================] - 2s 15ms/step - loss: 0.0900 - val_loss: 0.1186\n",
      "Epoch 17/80\n",
      "104/104 [==============================] - 2s 15ms/step - loss: 0.0888 - val_loss: 0.1174\n",
      "Epoch 18/80\n",
      "104/104 [==============================] - 2s 15ms/step - loss: 0.0876 - val_loss: 0.1161\n",
      "Epoch 19/80\n",
      "104/104 [==============================] - 2s 15ms/step - loss: 0.0864 - val_loss: 0.1148\n",
      "Epoch 20/80\n",
      "104/104 [==============================] - 2s 15ms/step - loss: 0.0852 - val_loss: 0.1135\n",
      "Epoch 21/80\n",
      "104/104 [==============================] - 2s 15ms/step - loss: 0.0840 - val_loss: 0.1122\n",
      "Epoch 22/80\n",
      "104/104 [==============================] - 2s 16ms/step - loss: 0.0828 - val_loss: 0.1109\n",
      "Epoch 23/80\n",
      "104/104 [==============================] - 2s 15ms/step - loss: 0.0815 - val_loss: 0.1096\n",
      "Epoch 24/80\n",
      "104/104 [==============================] - 2s 16ms/step - loss: 0.0803 - val_loss: 0.1082\n",
      "Epoch 25/80\n",
      "104/104 [==============================] - 2s 16ms/step - loss: 0.0791 - val_loss: 0.1069\n",
      "Epoch 26/80\n",
      "104/104 [==============================] - 2s 15ms/step - loss: 0.0779 - val_loss: 0.1056\n",
      "Epoch 27/80\n",
      "104/104 [==============================] - 2s 15ms/step - loss: 0.0767 - val_loss: 0.1043\n",
      "Epoch 28/80\n",
      "104/104 [==============================] - 2s 16ms/step - loss: 0.0756 - val_loss: 0.1029\n",
      "Epoch 29/80\n",
      "104/104 [==============================] - 2s 16ms/step - loss: 0.0744 - val_loss: 0.1016\n",
      "Epoch 30/80\n",
      "104/104 [==============================] - 2s 15ms/step - loss: 0.0732 - val_loss: 0.1003\n",
      "Epoch 31/80\n",
      "104/104 [==============================] - 2s 15ms/step - loss: 0.0721 - val_loss: 0.0990\n",
      "Epoch 32/80\n",
      "104/104 [==============================] - 2s 15ms/step - loss: 0.0710 - val_loss: 0.0977\n",
      "Epoch 33/80\n",
      "104/104 [==============================] - 2s 16ms/step - loss: 0.0699 - val_loss: 0.0964\n",
      "Epoch 34/80\n",
      "104/104 [==============================] - 2s 16ms/step - loss: 0.0689 - val_loss: 0.0951\n",
      "Epoch 35/80\n",
      "104/104 [==============================] - 2s 15ms/step - loss: 0.0679 - val_loss: 0.0939\n",
      "Epoch 36/80\n",
      "104/104 [==============================] - 2s 15ms/step - loss: 0.0669 - val_loss: 0.0928\n",
      "Epoch 37/80\n",
      "104/104 [==============================] - 2s 15ms/step - loss: 0.0660 - val_loss: 0.0918\n",
      "Epoch 38/80\n",
      "104/104 [==============================] - 2s 15ms/step - loss: 0.0652 - val_loss: 0.0908\n",
      "Epoch 39/80\n",
      "104/104 [==============================] - 2s 15ms/step - loss: 0.0644 - val_loss: 0.0898\n",
      "Epoch 40/80\n",
      "104/104 [==============================] - 2s 15ms/step - loss: 0.0637 - val_loss: 0.0889\n",
      "Epoch 41/80\n",
      "104/104 [==============================] - 2s 15ms/step - loss: 0.0630 - val_loss: 0.0880\n",
      "Epoch 42/80\n",
      "104/104 [==============================] - 2s 15ms/step - loss: 0.0622 - val_loss: 0.0870\n",
      "Epoch 43/80\n",
      "104/104 [==============================] - 2s 16ms/step - loss: 0.0616 - val_loss: 0.0861\n",
      "Epoch 44/80\n",
      "104/104 [==============================] - 2s 16ms/step - loss: 0.0609 - val_loss: 0.0852\n",
      "Epoch 45/80\n",
      "104/104 [==============================] - 2s 15ms/step - loss: 0.0602 - val_loss: 0.0844\n",
      "Epoch 46/80\n",
      "104/104 [==============================] - 2s 15ms/step - loss: 0.0596 - val_loss: 0.0835\n",
      "Epoch 47/80\n",
      "104/104 [==============================] - 2s 16ms/step - loss: 0.0590 - val_loss: 0.0826\n",
      "Epoch 48/80\n",
      "104/104 [==============================] - 2s 15ms/step - loss: 0.0584 - val_loss: 0.0817\n",
      "Epoch 49/80\n",
      "104/104 [==============================] - 2s 15ms/step - loss: 0.0577 - val_loss: 0.0809\n",
      "Epoch 50/80\n",
      "104/104 [==============================] - 2s 15ms/step - loss: 0.0572 - val_loss: 0.0801\n",
      "Epoch 51/80\n",
      "104/104 [==============================] - 2s 15ms/step - loss: 0.0566 - val_loss: 0.0792\n",
      "Epoch 52/80\n",
      "104/104 [==============================] - 2s 15ms/step - loss: 0.0560 - val_loss: 0.0784\n",
      "Epoch 53/80\n",
      "104/104 [==============================] - 2s 16ms/step - loss: 0.0556 - val_loss: 0.0776\n",
      "Epoch 54/80\n",
      "104/104 [==============================] - 2s 16ms/step - loss: 0.0550 - val_loss: 0.0768\n",
      "Epoch 55/80\n",
      "104/104 [==============================] - 2s 15ms/step - loss: 0.0545 - val_loss: 0.0760\n",
      "Epoch 56/80\n",
      "104/104 [==============================] - 2s 15ms/step - loss: 0.0540 - val_loss: 0.0753\n",
      "Epoch 57/80\n",
      "104/104 [==============================] - 2s 15ms/step - loss: 0.0535 - val_loss: 0.0745\n",
      "Epoch 58/80\n",
      "104/104 [==============================] - 2s 15ms/step - loss: 0.0530 - val_loss: 0.0738\n",
      "Epoch 59/80\n",
      "104/104 [==============================] - 2s 15ms/step - loss: 0.0526 - val_loss: 0.0730- ETA: 0s -\n",
      "Epoch 60/80\n",
      "104/104 [==============================] - 2s 15ms/step - loss: 0.0522 - val_loss: 0.0723\n",
      "Epoch 61/80\n",
      "104/104 [==============================] - 2s 15ms/step - loss: 0.0518 - val_loss: 0.0716\n",
      "Epoch 62/80\n",
      "104/104 [==============================] - 2s 15ms/step - loss: 0.0513 - val_loss: 0.0709\n",
      "Epoch 63/80\n",
      "104/104 [==============================] - 2s 16ms/step - loss: 0.0510 - val_loss: 0.0703\n",
      "Epoch 64/80\n",
      "104/104 [==============================] - 2s 16ms/step - loss: 0.0506 - val_loss: 0.0696\n",
      "Epoch 65/80\n",
      "104/104 [==============================] - 2s 15ms/step - loss: 0.0503 - val_loss: 0.0690\n",
      "Epoch 66/80\n",
      "104/104 [==============================] - 2s 15ms/step - loss: 0.0499 - val_loss: 0.0683\n",
      "Epoch 67/80\n",
      "104/104 [==============================] - 2s 15ms/step - loss: 0.0496 - val_loss: 0.0677\n",
      "Epoch 68/80\n",
      "104/104 [==============================] - 2s 15ms/step - loss: 0.0493 - val_loss: 0.0671\n",
      "Epoch 69/80\n",
      "104/104 [==============================] - 2s 15ms/step - loss: 0.0490 - val_loss: 0.0665\n",
      "Epoch 70/80\n",
      "104/104 [==============================] - 2s 15ms/step - loss: 0.0487 - val_loss: 0.0659\n",
      "Epoch 71/80\n",
      "104/104 [==============================] - 2s 15ms/step - loss: 0.0484 - val_loss: 0.0654\n",
      "Epoch 72/80\n",
      "104/104 [==============================] - 2s 15ms/step - loss: 0.0482 - val_loss: 0.0648\n",
      "Epoch 73/80\n",
      "104/104 [==============================] - 2s 16ms/step - loss: 0.0479 - val_loss: 0.0643\n",
      "Epoch 74/80\n",
      "104/104 [==============================] - 2s 16ms/step - loss: 0.0477 - val_loss: 0.0638\n",
      "Epoch 75/80\n",
      "104/104 [==============================] - 2s 15ms/step - loss: 0.0475 - val_loss: 0.0633\n",
      "Epoch 76/80\n",
      "104/104 [==============================] - 2s 15ms/step - loss: 0.0473 - val_loss: 0.0628\n",
      "Epoch 77/80\n",
      "104/104 [==============================] - 2s 15ms/step - loss: 0.0471 - val_loss: 0.0623\n",
      "Epoch 78/80\n",
      "104/104 [==============================] - 2s 15ms/step - loss: 0.0469 - val_loss: 0.0619\n",
      "Epoch 79/80\n",
      "104/104 [==============================] - 2s 15ms/step - loss: 0.0468 - val_loss: 0.0615\n",
      "Epoch 80/80\n",
      "104/104 [==============================] - 2s 15ms/step - loss: 0.0466 - val_loss: 0.0611\n",
      "Execution time:  130.25465488433838\n",
      "DNN:\n",
      "Mean Absolute Error: 0.0437\n",
      "Root Mean Square Error: 0.0524\n",
      "Mean Square Error: 0.0027\n",
      "\n",
      "Train RMSE: 0.052\n",
      "Train MSE: 0.003\n",
      "Train MAE: 0.044\n",
      "###########################\n",
      "\n",
      "MODEL:  DNN\n",
      "sequence:  3d\n",
      "units:  80\n",
      "dropout1:  0.11814836227952394\n",
      "optimizer: adadelta\n",
      "activationDense: sigmoid\n",
      "epochs: 90\n",
      "batchsize: 25\n",
      "validation_split: 0.1\n",
      "Model: \"sequential_199\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_597 (Dense)            (None, 432, 80)           160       \n",
      "_________________________________________________________________\n",
      "dense_598 (Dense)            (None, 432, 16)           1296      \n",
      "_________________________________________________________________\n",
      "dropout_199 (Dropout)        (None, 432, 16)           0         \n",
      "_________________________________________________________________\n",
      "dense_599 (Dense)            (None, 432, 1)            17        \n",
      "=================================================================\n",
      "Total params: 1,473\n",
      "Trainable params: 1,473\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/90\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "129/129 [==============================] - 2s 13ms/step - loss: 0.1007 - val_loss: 0.1305\n",
      "Epoch 2/90\n",
      "129/129 [==============================] - 2s 12ms/step - loss: 0.1001 - val_loss: 0.1299\n",
      "Epoch 3/90\n",
      "129/129 [==============================] - 2s 12ms/step - loss: 0.0995 - val_loss: 0.1293\n",
      "Epoch 4/90\n",
      "129/129 [==============================] - 1s 12ms/step - loss: 0.0989 - val_loss: 0.1286\n",
      "Epoch 5/90\n",
      "129/129 [==============================] - 1s 11ms/step - loss: 0.0982 - val_loss: 0.1279\n",
      "Epoch 6/90\n",
      "129/129 [==============================] - 1s 12ms/step - loss: 0.0974 - val_loss: 0.1271\n",
      "Epoch 7/90\n",
      "129/129 [==============================] - 2s 12ms/step - loss: 0.0967 - val_loss: 0.1263\n",
      "Epoch 8/90\n",
      "129/129 [==============================] - 2s 12ms/step - loss: 0.0958 - val_loss: 0.1254\n",
      "Epoch 9/90\n",
      "129/129 [==============================] - 2s 12ms/step - loss: 0.0950 - val_loss: 0.1245\n",
      "Epoch 10/90\n",
      "129/129 [==============================] - 1s 12ms/step - loss: 0.0941 - val_loss: 0.1236\n",
      "Epoch 11/90\n",
      "129/129 [==============================] - 1s 12ms/step - loss: 0.0932 - val_loss: 0.1227\n",
      "Epoch 12/90\n",
      "129/129 [==============================] - 2s 12ms/step - loss: 0.0923 - val_loss: 0.1217\n",
      "Epoch 13/90\n",
      "129/129 [==============================] - 2s 13ms/step - loss: 0.0913 - val_loss: 0.1207\n",
      "Epoch 14/90\n",
      "129/129 [==============================] - 2s 12ms/step - loss: 0.0904 - val_loss: 0.1197\n",
      "Epoch 15/90\n",
      "129/129 [==============================] - 1s 12ms/step - loss: 0.0894 - val_loss: 0.1186\n",
      "Epoch 16/90\n",
      "129/129 [==============================] - 1s 12ms/step - loss: 0.0884 - val_loss: 0.1175\n",
      "Epoch 17/90\n",
      "129/129 [==============================] - 1s 11ms/step - loss: 0.0873 - val_loss: 0.1164\n",
      "Epoch 18/90\n",
      "129/129 [==============================] - 1s 12ms/step - loss: 0.0863 - val_loss: 0.1153\n",
      "Epoch 19/90\n",
      "129/129 [==============================] - 2s 13ms/step - loss: 0.0852 - val_loss: 0.1142\n",
      "Epoch 20/90\n",
      "129/129 [==============================] - 1s 12ms/step - loss: 0.0841 - val_loss: 0.1130\n",
      "Epoch 21/90\n",
      "129/129 [==============================] - 1s 12ms/step - loss: 0.0830 - val_loss: 0.1118\n",
      "Epoch 22/90\n",
      "129/129 [==============================] - 2s 12ms/step - loss: 0.0818 - val_loss: 0.1106\n",
      "Epoch 23/90\n",
      "129/129 [==============================] - 2s 13ms/step - loss: 0.0807 - val_loss: 0.1094\n",
      "Epoch 24/90\n",
      "129/129 [==============================] - 2s 12ms/step - loss: 0.0796 - val_loss: 0.1082\n",
      "Epoch 25/90\n",
      "129/129 [==============================] - 2s 12ms/step - loss: 0.0785 - val_loss: 0.1070\n",
      "Epoch 26/90\n",
      "129/129 [==============================] - 1s 12ms/step - loss: 0.0773 - val_loss: 0.1057\n",
      "Epoch 27/90\n",
      "129/129 [==============================] - 2s 12ms/step - loss: 0.0762 - val_loss: 0.1045\n",
      "Epoch 28/90\n",
      "129/129 [==============================] - 1s 12ms/step - loss: 0.0751 - val_loss: 0.1032\n",
      "Epoch 29/90\n",
      "129/129 [==============================] - 2s 12ms/step - loss: 0.0739 - val_loss: 0.1020\n",
      "Epoch 30/90\n",
      "129/129 [==============================] - 1s 12ms/step - loss: 0.0728 - val_loss: 0.1007\n",
      "Epoch 31/90\n",
      "129/129 [==============================] - 1s 12ms/step - loss: 0.0716 - val_loss: 0.0994\n",
      "Epoch 32/90\n",
      "129/129 [==============================] - 1s 12ms/step - loss: 0.0705 - val_loss: 0.0981\n",
      "Epoch 33/90\n",
      "129/129 [==============================] - 2s 12ms/step - loss: 0.0693 - val_loss: 0.0969\n",
      "Epoch 34/90\n",
      "129/129 [==============================] - 2s 12ms/step - loss: 0.0682 - val_loss: 0.0956\n",
      "Epoch 35/90\n",
      "129/129 [==============================] - 2s 12ms/step - loss: 0.0671 - val_loss: 0.0943\n",
      "Epoch 36/90\n",
      "129/129 [==============================] - 1s 12ms/step - loss: 0.0660 - val_loss: 0.0930\n",
      "Epoch 37/90\n",
      "129/129 [==============================] - 2s 12ms/step - loss: 0.0649 - val_loss: 0.0917\n",
      "Epoch 38/90\n",
      "129/129 [==============================] - 1s 12ms/step - loss: 0.0638 - val_loss: 0.0905\n",
      "Epoch 39/90\n",
      "129/129 [==============================] - 1s 12ms/step - loss: 0.0627 - val_loss: 0.0892\n",
      "Epoch 40/90\n",
      "129/129 [==============================] - 1s 12ms/step - loss: 0.0616 - val_loss: 0.0879\n",
      "Epoch 41/90\n",
      "129/129 [==============================] - 1s 12ms/step - loss: 0.0606 - val_loss: 0.0866\n",
      "Epoch 42/90\n",
      "129/129 [==============================] - 2s 12ms/step - loss: 0.0595 - val_loss: 0.0853\n",
      "Epoch 43/90\n",
      "129/129 [==============================] - 2s 12ms/step - loss: 0.0585 - val_loss: 0.0841\n",
      "Epoch 44/90\n",
      "129/129 [==============================] - 2s 13ms/step - loss: 0.0574 - val_loss: 0.0828\n",
      "Epoch 45/90\n",
      "129/129 [==============================] - 2s 12ms/step - loss: 0.0564 - val_loss: 0.0816\n",
      "Epoch 46/90\n",
      "129/129 [==============================] - 2s 12ms/step - loss: 0.0555 - val_loss: 0.0803\n",
      "Epoch 47/90\n",
      "129/129 [==============================] - 1s 12ms/step - loss: 0.0546 - val_loss: 0.0792\n",
      "Epoch 48/90\n",
      "129/129 [==============================] - 2s 12ms/step - loss: 0.0537 - val_loss: 0.0780\n",
      "Epoch 49/90\n",
      "129/129 [==============================] - 1s 12ms/step - loss: 0.0528 - val_loss: 0.0768\n",
      "Epoch 50/90\n",
      "129/129 [==============================] - 2s 12ms/step - loss: 0.0520 - val_loss: 0.0757\n",
      "Epoch 51/90\n",
      "129/129 [==============================] - 1s 12ms/step - loss: 0.0512 - val_loss: 0.0746\n",
      "Epoch 52/90\n",
      "129/129 [==============================] - 2s 12ms/step - loss: 0.0504 - val_loss: 0.0735\n",
      "Epoch 53/90\n",
      "129/129 [==============================] - 2s 12ms/step - loss: 0.0496 - val_loss: 0.0724\n",
      "Epoch 54/90\n",
      "129/129 [==============================] - 2s 13ms/step - loss: 0.0489 - val_loss: 0.0713\n",
      "Epoch 55/90\n",
      "129/129 [==============================] - 2s 13ms/step - loss: 0.0482 - val_loss: 0.0702\n",
      "Epoch 56/90\n",
      "129/129 [==============================] - 2s 12ms/step - loss: 0.0475 - val_loss: 0.0692\n",
      "Epoch 57/90\n",
      "129/129 [==============================] - 2s 12ms/step - loss: 0.0468 - val_loss: 0.0681\n",
      "Epoch 58/90\n",
      "129/129 [==============================] - 2s 12ms/step - loss: 0.0462 - val_loss: 0.0671\n",
      "Epoch 59/90\n",
      "129/129 [==============================] - 2s 12ms/step - loss: 0.0455 - val_loss: 0.0661\n",
      "Epoch 60/90\n",
      "129/129 [==============================] - 2s 12ms/step - loss: 0.0449 - val_loss: 0.0652\n",
      "Epoch 61/90\n",
      "129/129 [==============================] - 2s 12ms/step - loss: 0.0443 - val_loss: 0.0642\n",
      "Epoch 62/90\n",
      "129/129 [==============================] - 2s 12ms/step - loss: 0.0437 - val_loss: 0.0632\n",
      "Epoch 63/90\n",
      "129/129 [==============================] - 2s 12ms/step - loss: 0.0432 - val_loss: 0.0623\n",
      "Epoch 64/90\n",
      "129/129 [==============================] - 2s 13ms/step - loss: 0.0426 - val_loss: 0.0614\n",
      "Epoch 65/90\n",
      "129/129 [==============================] - 2s 12ms/step - loss: 0.0421 - val_loss: 0.0604\n",
      "Epoch 66/90\n",
      "129/129 [==============================] - 2s 12ms/step - loss: 0.0415 - val_loss: 0.0595\n",
      "Epoch 67/90\n",
      "129/129 [==============================] - 1s 12ms/step - loss: 0.0410 - val_loss: 0.0586\n",
      "Epoch 68/90\n",
      "129/129 [==============================] - 2s 12ms/step - loss: 0.0405 - val_loss: 0.0577\n",
      "Epoch 69/90\n",
      "129/129 [==============================] - 2s 12ms/step - loss: 0.0400 - val_loss: 0.0568\n",
      "Epoch 70/90\n",
      "129/129 [==============================] - 2s 12ms/step - loss: 0.0395 - val_loss: 0.0559\n",
      "Epoch 71/90\n",
      "129/129 [==============================] - 1s 12ms/step - loss: 0.0390 - val_loss: 0.0550\n",
      "Epoch 72/90\n",
      "129/129 [==============================] - 2s 12ms/step - loss: 0.0386 - val_loss: 0.0542\n",
      "Epoch 73/90\n",
      "129/129 [==============================] - 2s 12ms/step - loss: 0.0382 - val_loss: 0.0533\n",
      "Epoch 74/90\n",
      "129/129 [==============================] - 2s 12ms/step - loss: 0.0377 - val_loss: 0.0525\n",
      "Epoch 75/90\n",
      "129/129 [==============================] - 2s 12ms/step - loss: 0.0373 - val_loss: 0.0517\n",
      "Epoch 76/90\n",
      "129/129 [==============================] - 2s 12ms/step - loss: 0.0369 - val_loss: 0.0509\n",
      "Epoch 77/90\n",
      "129/129 [==============================] - 2s 12ms/step - loss: 0.0365 - val_loss: 0.0501\n",
      "Epoch 78/90\n",
      "129/129 [==============================] - 2s 12ms/step - loss: 0.0362 - val_loss: 0.0494\n",
      "Epoch 79/90\n",
      "129/129 [==============================] - 2s 12ms/step - loss: 0.0359 - val_loss: 0.0486\n",
      "Epoch 80/90\n",
      "129/129 [==============================] - 2s 12ms/step - loss: 0.0355 - val_loss: 0.0479\n",
      "Epoch 81/90\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "129/129 [==============================] - 1s 12ms/step - loss: 0.0352 - val_loss: 0.0472\n",
      "Epoch 82/90\n",
      "129/129 [==============================] - 1s 11ms/step - loss: 0.0349 - val_loss: 0.0465\n",
      "Epoch 83/90\n",
      "129/129 [==============================] - 1s 12ms/step - loss: 0.0346 - val_loss: 0.0459\n",
      "Epoch 84/90\n",
      "129/129 [==============================] - 2s 12ms/step - loss: 0.0343 - val_loss: 0.0452\n",
      "Epoch 85/90\n",
      "129/129 [==============================] - 2s 13ms/step - loss: 0.0341 - val_loss: 0.0446\n",
      "Epoch 86/90\n",
      "129/129 [==============================] - 2s 12ms/step - loss: 0.0338 - val_loss: 0.0439\n",
      "Epoch 87/90\n",
      "129/129 [==============================] - 2s 12ms/step - loss: 0.0336 - val_loss: 0.0433\n",
      "Epoch 88/90\n",
      "129/129 [==============================] - 1s 12ms/step - loss: 0.0333 - val_loss: 0.0427\n",
      "Epoch 89/90\n",
      "129/129 [==============================] - 2s 12ms/step - loss: 0.0331 - val_loss: 0.0422\n",
      "Epoch 90/90\n",
      "129/129 [==============================] - 1s 12ms/step - loss: 0.0329 - val_loss: 0.0416\n",
      "Execution time:  139.9935998916626\n",
      "DNN:\n",
      "Mean Absolute Error: 0.0340\n",
      "Root Mean Square Error: 0.0459\n",
      "Mean Square Error: 0.0021\n",
      "\n",
      "Train RMSE: 0.046\n",
      "Train MSE: 0.002\n",
      "Train MAE: 0.034\n",
      "###########################\n",
      "\n",
      "MODEL:  DNN\n",
      "sequence:  3d\n",
      "units:  12\n",
      "dropout1:  0.48476373451509647\n",
      "optimizer: adadelta\n",
      "activationDense: sigmoid\n",
      "epochs: 52\n",
      "batchsize: 57\n",
      "validation_split: 0.1\n",
      "Model: \"sequential_200\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_600 (Dense)            (None, 432, 12)           24        \n",
      "_________________________________________________________________\n",
      "dense_601 (Dense)            (None, 432, 16)           208       \n",
      "_________________________________________________________________\n",
      "dropout_200 (Dropout)        (None, 432, 16)           0         \n",
      "_________________________________________________________________\n",
      "dense_602 (Dense)            (None, 432, 1)            17        \n",
      "=================================================================\n",
      "Total params: 249\n",
      "Trainable params: 249\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/52\n",
      "57/57 [==============================] - 1s 23ms/step - loss: 0.1114 - val_loss: 0.1409\n",
      "Epoch 2/52\n",
      "57/57 [==============================] - 1s 14ms/step - loss: 0.1113 - val_loss: 0.1408\n",
      "Epoch 3/52\n",
      "57/57 [==============================] - 1s 14ms/step - loss: 0.1112 - val_loss: 0.1407\n",
      "Epoch 4/52\n",
      "57/57 [==============================] - 1s 14ms/step - loss: 0.1111 - val_loss: 0.1405\n",
      "Epoch 5/52\n",
      "57/57 [==============================] - 1s 14ms/step - loss: 0.1109 - val_loss: 0.1404\n",
      "Epoch 6/52\n",
      "57/57 [==============================] - 1s 15ms/step - loss: 0.1108 - val_loss: 0.1403\n",
      "Epoch 7/52\n",
      "57/57 [==============================] - 1s 16ms/step - loss: 0.1106 - val_loss: 0.1401\n",
      "Epoch 8/52\n",
      "57/57 [==============================] - 1s 16ms/step - loss: 0.1105 - val_loss: 0.1400\n",
      "Epoch 9/52\n",
      "57/57 [==============================] - 1s 15ms/step - loss: 0.1104 - val_loss: 0.1398\n",
      "Epoch 10/52\n",
      "57/57 [==============================] - 1s 14ms/step - loss: 0.1102 - val_loss: 0.1397\n",
      "Epoch 11/52\n",
      "57/57 [==============================] - 1s 14ms/step - loss: 0.1101 - val_loss: 0.1395\n",
      "Epoch 12/52\n",
      "57/57 [==============================] - 1s 14ms/step - loss: 0.1099 - val_loss: 0.1394\n",
      "Epoch 13/52\n",
      "57/57 [==============================] - 1s 14ms/step - loss: 0.1097 - val_loss: 0.1392\n",
      "Epoch 14/52\n",
      "57/57 [==============================] - 1s 14ms/step - loss: 0.1096 - val_loss: 0.1390\n",
      "Epoch 15/52\n",
      "57/57 [==============================] - 1s 14ms/step - loss: 0.1094 - val_loss: 0.1389\n",
      "Epoch 16/52\n",
      "57/57 [==============================] - 1s 14ms/step - loss: 0.1092 - val_loss: 0.1387\n",
      "Epoch 17/52\n",
      "57/57 [==============================] - 1s 14ms/step - loss: 0.1090 - val_loss: 0.1385\n",
      "Epoch 18/52\n",
      "57/57 [==============================] - 1s 14ms/step - loss: 0.1089 - val_loss: 0.1383\n",
      "Epoch 19/52\n",
      "57/57 [==============================] - 1s 14ms/step - loss: 0.1087 - val_loss: 0.1381\n",
      "Epoch 20/52\n",
      "57/57 [==============================] - 1s 14ms/step - loss: 0.1085 - val_loss: 0.1379\n",
      "Epoch 21/52\n",
      "57/57 [==============================] - 1s 14ms/step - loss: 0.1083 - val_loss: 0.1378\n",
      "Epoch 22/52\n",
      "57/57 [==============================] - 1s 14ms/step - loss: 0.1082 - val_loss: 0.1376\n",
      "Epoch 23/52\n",
      "57/57 [==============================] - 1s 14ms/step - loss: 0.1079 - val_loss: 0.1374\n",
      "Epoch 24/52\n",
      "57/57 [==============================] - 1s 14ms/step - loss: 0.1078 - val_loss: 0.1372\n",
      "Epoch 25/52\n",
      "57/57 [==============================] - 1s 15ms/step - loss: 0.1076 - val_loss: 0.1370\n",
      "Epoch 26/52\n",
      "57/57 [==============================] - 1s 15ms/step - loss: 0.1074 - val_loss: 0.1368\n",
      "Epoch 27/52\n",
      "57/57 [==============================] - 1s 15ms/step - loss: 0.1071 - val_loss: 0.1366\n",
      "Epoch 28/52\n",
      "57/57 [==============================] - 1s 15ms/step - loss: 0.1070 - val_loss: 0.1363\n",
      "Epoch 29/52\n",
      "57/57 [==============================] - 1s 14ms/step - loss: 0.1067 - val_loss: 0.1361\n",
      "Epoch 30/52\n",
      "57/57 [==============================] - 1s 14ms/step - loss: 0.1065 - val_loss: 0.1359\n",
      "Epoch 31/52\n",
      "57/57 [==============================] - 1s 14ms/step - loss: 0.1063 - val_loss: 0.1357\n",
      "Epoch 32/52\n",
      "57/57 [==============================] - 1s 14ms/step - loss: 0.1061 - val_loss: 0.1355\n",
      "Epoch 33/52\n",
      "57/57 [==============================] - 1s 14ms/step - loss: 0.1059 - val_loss: 0.1353\n",
      "Epoch 34/52\n",
      "57/57 [==============================] - 1s 14ms/step - loss: 0.1057 - val_loss: 0.1350\n",
      "Epoch 35/52\n",
      "57/57 [==============================] - 1s 14ms/step - loss: 0.1055 - val_loss: 0.1348\n",
      "Epoch 36/52\n",
      "57/57 [==============================] - 1s 14ms/step - loss: 0.1052 - val_loss: 0.1346\n",
      "Epoch 37/52\n",
      "57/57 [==============================] - 1s 14ms/step - loss: 0.1050 - val_loss: 0.1344\n",
      "Epoch 38/52\n",
      "57/57 [==============================] - 1s 14ms/step - loss: 0.1048 - val_loss: 0.1341\n",
      "Epoch 39/52\n",
      "57/57 [==============================] - 1s 14ms/step - loss: 0.1046 - val_loss: 0.1339\n",
      "Epoch 40/52\n",
      "57/57 [==============================] - 1s 14ms/step - loss: 0.1043 - val_loss: 0.1337\n",
      "Epoch 41/52\n",
      "57/57 [==============================] - 1s 14ms/step - loss: 0.1041 - val_loss: 0.1334\n",
      "Epoch 42/52\n",
      "57/57 [==============================] - 1s 14ms/step - loss: 0.1039 - val_loss: 0.1332\n",
      "Epoch 43/52\n",
      "57/57 [==============================] - 1s 14ms/step - loss: 0.1037 - val_loss: 0.1330\n",
      "Epoch 44/52\n",
      "57/57 [==============================] - 1s 15ms/step - loss: 0.1035 - val_loss: 0.1327\n",
      "Epoch 45/52\n",
      "57/57 [==============================] - 1s 15ms/step - loss: 0.1032 - val_loss: 0.1325\n",
      "Epoch 46/52\n",
      "57/57 [==============================] - 1s 16ms/step - loss: 0.1030 - val_loss: 0.1323\n",
      "Epoch 47/52\n",
      "57/57 [==============================] - 1s 15ms/step - loss: 0.1027 - val_loss: 0.1320\n",
      "Epoch 48/52\n",
      "57/57 [==============================] - 1s 14ms/step - loss: 0.1025 - val_loss: 0.1318\n",
      "Epoch 49/52\n",
      "57/57 [==============================] - 1s 14ms/step - loss: 0.1023 - val_loss: 0.1315\n",
      "Epoch 50/52\n",
      "57/57 [==============================] - 1s 14ms/step - loss: 0.1020 - val_loss: 0.1313\n",
      "Epoch 51/52\n",
      "57/57 [==============================] - 1s 14ms/step - loss: 0.1018 - val_loss: 0.1310\n",
      "Epoch 52/52\n",
      "57/57 [==============================] - 1s 14ms/step - loss: 0.1015 - val_loss: 0.1308\n",
      "Execution time:  44.68583822250366\n",
      "DNN:\n",
      "Mean Absolute Error: 0.1013\n",
      "Root Mean Square Error: 0.1072\n",
      "Mean Square Error: 0.0115\n",
      "\n",
      "Train RMSE: 0.107\n",
      "Train MSE: 0.011\n",
      "Train MAE: 0.101\n",
      "###########################\n",
      "\n",
      "MODEL:  DNN\n",
      "sequence:  3d\n",
      "units:  87\n",
      "dropout1:  0.40519643149940265\n",
      "optimizer: adadelta\n",
      "activationDense: sigmoid\n",
      "epochs: 80\n",
      "batchsize: 31\n",
      "validation_split: 0.2\n",
      "Model: \"sequential_201\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_603 (Dense)            (None, 432, 87)           174       \n",
      "_________________________________________________________________\n",
      "dense_604 (Dense)            (None, 432, 16)           1408      \n",
      "_________________________________________________________________\n",
      "dropout_201 (Dropout)        (None, 432, 16)           0         \n",
      "_________________________________________________________________\n",
      "dense_605 (Dense)            (None, 432, 1)            17        \n",
      "=================================================================\n",
      "Total params: 1,599\n",
      "Trainable params: 1,599\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/80\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "92/92 [==============================] - 2s 18ms/step - loss: 0.1097 - val_loss: 0.1333\n",
      "Epoch 2/80\n",
      "92/92 [==============================] - 1s 16ms/step - loss: 0.1094 - val_loss: 0.1329\n",
      "Epoch 3/80\n",
      "92/92 [==============================] - 1s 16ms/step - loss: 0.1089 - val_loss: 0.1324\n",
      "Epoch 4/80\n",
      "92/92 [==============================] - 1s 16ms/step - loss: 0.1085 - val_loss: 0.1319\n",
      "Epoch 5/80\n",
      "92/92 [==============================] - 1s 16ms/step - loss: 0.1080 - val_loss: 0.1315\n",
      "Epoch 6/80\n",
      "92/92 [==============================] - 2s 17ms/step - loss: 0.1075 - val_loss: 0.1309\n",
      "Epoch 7/80\n",
      "92/92 [==============================] - 2s 17ms/step - loss: 0.1070 - val_loss: 0.1304\n",
      "Epoch 8/80\n",
      "92/92 [==============================] - 1s 16ms/step - loss: 0.1065 - val_loss: 0.1299\n",
      "Epoch 9/80\n",
      "92/92 [==============================] - 1s 16ms/step - loss: 0.1059 - val_loss: 0.1293\n",
      "Epoch 10/80\n",
      "92/92 [==============================] - 1s 16ms/step - loss: 0.1054 - val_loss: 0.1287\n",
      "Epoch 11/80\n",
      "92/92 [==============================] - 1s 16ms/step - loss: 0.1048 - val_loss: 0.1282\n",
      "Epoch 12/80\n",
      "92/92 [==============================] - 1s 16ms/step - loss: 0.1043 - val_loss: 0.1276\n",
      "Epoch 13/80\n",
      "92/92 [==============================] - 1s 16ms/step - loss: 0.1036 - val_loss: 0.1270\n",
      "Epoch 14/80\n",
      "92/92 [==============================] - 1s 16ms/step - loss: 0.1031 - val_loss: 0.1263\n",
      "Epoch 15/80\n",
      "92/92 [==============================] - 1s 16ms/step - loss: 0.1024 - val_loss: 0.1257\n",
      "Epoch 16/80\n",
      "92/92 [==============================] - 1s 16ms/step - loss: 0.1018 - val_loss: 0.1251\n",
      "Epoch 17/80\n",
      "92/92 [==============================] - 2s 17ms/step - loss: 0.1012 - val_loss: 0.1244\n",
      "Epoch 18/80\n",
      "92/92 [==============================] - 2s 17ms/step - loss: 0.1006 - val_loss: 0.1238\n",
      "Epoch 19/80\n",
      "92/92 [==============================] - 1s 16ms/step - loss: 0.0999 - val_loss: 0.1231\n",
      "Epoch 20/80\n",
      "92/92 [==============================] - 1s 16ms/step - loss: 0.0993 - val_loss: 0.1224\n",
      "Epoch 21/80\n",
      "92/92 [==============================] - 1s 16ms/step - loss: 0.0986 - val_loss: 0.1217\n",
      "Epoch 22/80\n",
      "92/92 [==============================] - 1s 16ms/step - loss: 0.0979 - val_loss: 0.1210\n",
      "Epoch 23/80\n",
      "92/92 [==============================] - 1s 16ms/step - loss: 0.0972 - val_loss: 0.1203\n",
      "Epoch 24/80\n",
      "92/92 [==============================] - 2s 17ms/step - loss: 0.0966 - val_loss: 0.1196\n",
      "Epoch 25/80\n",
      "92/92 [==============================] - 2s 18ms/step - loss: 0.0959 - val_loss: 0.1189\n",
      "Epoch 26/80\n",
      "92/92 [==============================] - 1s 16ms/step - loss: 0.0952 - val_loss: 0.1182\n",
      "Epoch 27/80\n",
      "92/92 [==============================] - 2s 17ms/step - loss: 0.0946 - val_loss: 0.1176\n",
      "Epoch 28/80\n",
      "92/92 [==============================] - 2s 17ms/step - loss: 0.0940 - val_loss: 0.1171\n",
      "Epoch 29/80\n",
      "92/92 [==============================] - 1s 16ms/step - loss: 0.0935 - val_loss: 0.1166\n",
      "Epoch 30/80\n",
      "92/92 [==============================] - 1s 16ms/step - loss: 0.0930 - val_loss: 0.1161\n",
      "Epoch 31/80\n",
      "92/92 [==============================] - 1s 16ms/step - loss: 0.0925 - val_loss: 0.1156\n",
      "Epoch 32/80\n",
      "92/92 [==============================] - 1s 16ms/step - loss: 0.0921 - val_loss: 0.1151\n",
      "Epoch 33/80\n",
      "92/92 [==============================] - 1s 16ms/step - loss: 0.0916 - val_loss: 0.1147\n",
      "Epoch 34/80\n",
      "92/92 [==============================] - 1s 16ms/step - loss: 0.0911 - val_loss: 0.1142\n",
      "Epoch 35/80\n",
      "92/92 [==============================] - 1s 16ms/step - loss: 0.0907 - val_loss: 0.1137\n",
      "Epoch 36/80\n",
      "92/92 [==============================] - 1s 16ms/step - loss: 0.0902 - val_loss: 0.1132\n",
      "Epoch 37/80\n",
      "92/92 [==============================] - 1s 16ms/step - loss: 0.0897 - val_loss: 0.1127\n",
      "Epoch 38/80\n",
      "92/92 [==============================] - 2s 17ms/step - loss: 0.0893 - val_loss: 0.1122\n",
      "Epoch 39/80\n",
      "92/92 [==============================] - 2s 17ms/step - loss: 0.0888 - val_loss: 0.1117\n",
      "Epoch 40/80\n",
      "92/92 [==============================] - 1s 16ms/step - loss: 0.0883 - val_loss: 0.1112\n",
      "Epoch 41/80\n",
      "92/92 [==============================] - 1s 16ms/step - loss: 0.0878 - val_loss: 0.1106\n",
      "Epoch 42/80\n",
      "92/92 [==============================] - 1s 16ms/step - loss: 0.0874 - val_loss: 0.1101\n",
      "Epoch 43/80\n",
      "92/92 [==============================] - 1s 16ms/step - loss: 0.0869 - val_loss: 0.1096\n",
      "Epoch 44/80\n",
      "92/92 [==============================] - 1s 16ms/step - loss: 0.0864 - val_loss: 0.1091\n",
      "Epoch 45/80\n",
      "92/92 [==============================] - 1s 16ms/step - loss: 0.0859 - val_loss: 0.1086\n",
      "Epoch 46/80\n",
      "92/92 [==============================] - 1s 16ms/step - loss: 0.0855 - val_loss: 0.1080\n",
      "Epoch 47/80\n",
      "92/92 [==============================] - 1s 16ms/step - loss: 0.0850 - val_loss: 0.1075\n",
      "Epoch 48/80\n",
      "92/92 [==============================] - 1s 16ms/step - loss: 0.0845 - val_loss: 0.1070\n",
      "Epoch 49/80\n",
      "92/92 [==============================] - 2s 17ms/step - loss: 0.0840 - val_loss: 0.1065\n",
      "Epoch 50/80\n",
      "92/92 [==============================] - 2s 17ms/step - loss: 0.0836 - val_loss: 0.1060\n",
      "Epoch 51/80\n",
      "92/92 [==============================] - 1s 16ms/step - loss: 0.0831 - val_loss: 0.1055\n",
      "Epoch 52/80\n",
      "92/92 [==============================] - 1s 16ms/step - loss: 0.0827 - val_loss: 0.1050\n",
      "Epoch 53/80\n",
      "92/92 [==============================] - 1s 16ms/step - loss: 0.0822 - val_loss: 0.1045\n",
      "Epoch 54/80\n",
      "92/92 [==============================] - 1s 16ms/step - loss: 0.0818 - val_loss: 0.1040\n",
      "Epoch 55/80\n",
      "92/92 [==============================] - 1s 16ms/step - loss: 0.0813 - val_loss: 0.1035\n",
      "Epoch 56/80\n",
      "92/92 [==============================] - 1s 16ms/step - loss: 0.0808 - val_loss: 0.1029\n",
      "Epoch 57/80\n",
      "92/92 [==============================] - 1s 16ms/step - loss: 0.0804 - val_loss: 0.1024\n",
      "Epoch 58/80\n",
      "92/92 [==============================] - 1s 16ms/step - loss: 0.0800 - val_loss: 0.1020\n",
      "Epoch 59/80\n",
      "92/92 [==============================] - 2s 17ms/step - loss: 0.0795 - val_loss: 0.1015\n",
      "Epoch 60/80\n",
      "92/92 [==============================] - 2s 17ms/step - loss: 0.0791 - val_loss: 0.1011\n",
      "Epoch 61/80\n",
      "92/92 [==============================] - 2s 16ms/step - loss: 0.0788 - val_loss: 0.1007\n",
      "Epoch 62/80\n",
      "92/92 [==============================] - 1s 16ms/step - loss: 0.0784 - val_loss: 0.1003\n",
      "Epoch 63/80\n",
      "92/92 [==============================] - 1s 16ms/step - loss: 0.0780 - val_loss: 0.0999\n",
      "Epoch 64/80\n",
      "92/92 [==============================] - 1s 16ms/step - loss: 0.0777 - val_loss: 0.0995\n",
      "Epoch 65/80\n",
      "92/92 [==============================] - 1s 16ms/step - loss: 0.0773 - val_loss: 0.0991\n",
      "Epoch 66/80\n",
      "92/92 [==============================] - 1s 16ms/step - loss: 0.0770 - val_loss: 0.0986\n",
      "Epoch 67/80\n",
      "92/92 [==============================] - 1s 16ms/step - loss: 0.0766 - val_loss: 0.0982\n",
      "Epoch 68/80\n",
      "92/92 [==============================] - 1s 16ms/step - loss: 0.0762 - val_loss: 0.0978\n",
      "Epoch 69/80\n",
      "92/92 [==============================] - 1s 16ms/step - loss: 0.0759 - val_loss: 0.0974\n",
      "Epoch 70/80\n",
      "92/92 [==============================] - 2s 17ms/step - loss: 0.0755 - val_loss: 0.0970\n",
      "Epoch 71/80\n",
      "92/92 [==============================] - 2s 17ms/step - loss: 0.0752 - val_loss: 0.0966\n",
      "Epoch 72/80\n",
      "92/92 [==============================] - 1s 16ms/step - loss: 0.0749 - val_loss: 0.0962\n",
      "Epoch 73/80\n",
      "92/92 [==============================] - 1s 16ms/step - loss: 0.0745 - val_loss: 0.0958\n",
      "Epoch 74/80\n",
      "92/92 [==============================] - 1s 16ms/step - loss: 0.0742 - val_loss: 0.0954\n",
      "Epoch 75/80\n",
      "92/92 [==============================] - 1s 16ms/step - loss: 0.0738 - val_loss: 0.0950\n",
      "Epoch 76/80\n",
      "92/92 [==============================] - 1s 16ms/step - loss: 0.0735 - val_loss: 0.0946\n",
      "Epoch 77/80\n",
      "92/92 [==============================] - 1s 16ms/step - loss: 0.0732 - val_loss: 0.0942\n",
      "Epoch 78/80\n",
      "92/92 [==============================] - 1s 16ms/step - loss: 0.0729 - val_loss: 0.0938\n",
      "Epoch 79/80\n",
      "92/92 [==============================] - 1s 16ms/step - loss: 0.0726 - val_loss: 0.0934\n",
      "Epoch 80/80\n",
      "92/92 [==============================] - 2s 17ms/step - loss: 0.0722 - val_loss: 0.0930\n",
      "Execution time:  121.4556794166565\n",
      "DNN:\n",
      "Mean Absolute Error: 0.0735\n",
      "Root Mean Square Error: 0.0807\n",
      "Mean Square Error: 0.0065\n",
      "\n",
      "Train RMSE: 0.081\n",
      "Train MSE: 0.007\n",
      "Train MAE: 0.073\n",
      "###########################\n",
      "\n",
      "MODEL:  DNN\n",
      "sequence:  3d\n",
      "units:  80\n",
      "dropout1:  0.11814836227952394\n",
      "optimizer: adadelta\n",
      "activationDense: sigmoid\n",
      "epochs: 90\n",
      "batchsize: 25\n",
      "validation_split: 0.2\n",
      "Model: \"sequential_202\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_606 (Dense)            (None, 432, 80)           160       \n",
      "_________________________________________________________________\n",
      "dense_607 (Dense)            (None, 432, 16)           1296      \n",
      "_________________________________________________________________\n",
      "dropout_202 (Dropout)        (None, 432, 16)           0         \n",
      "_________________________________________________________________\n",
      "dense_608 (Dense)            (None, 432, 1)            17        \n",
      "=================================================================\n",
      "Total params: 1,473\n",
      "Trainable params: 1,473\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/90\n",
      "114/114 [==============================] - 2s 14ms/step - loss: 0.0892 - val_loss: 0.1123\n",
      "Epoch 2/90\n",
      "114/114 [==============================] - 1s 12ms/step - loss: 0.0883 - val_loss: 0.1113\n",
      "Epoch 3/90\n",
      "114/114 [==============================] - 1s 12ms/step - loss: 0.0873 - val_loss: 0.1103\n",
      "Epoch 4/90\n",
      "114/114 [==============================] - 1s 12ms/step - loss: 0.0863 - val_loss: 0.1092\n",
      "Epoch 5/90\n",
      "114/114 [==============================] - 1s 12ms/step - loss: 0.0854 - val_loss: 0.1082\n",
      "Epoch 6/90\n",
      "114/114 [==============================] - 1s 12ms/step - loss: 0.0843 - val_loss: 0.1070\n",
      "Epoch 7/90\n",
      "114/114 [==============================] - 1s 12ms/step - loss: 0.0832 - val_loss: 0.1059\n",
      "Epoch 8/90\n",
      "114/114 [==============================] - 1s 12ms/step - loss: 0.0821 - val_loss: 0.1046\n",
      "Epoch 9/90\n",
      "114/114 [==============================] - 1s 12ms/step - loss: 0.0810 - val_loss: 0.1034\n",
      "Epoch 10/90\n",
      "114/114 [==============================] - 1s 13ms/step - loss: 0.0798 - val_loss: 0.1021\n",
      "Epoch 11/90\n",
      "114/114 [==============================] - 1s 13ms/step - loss: 0.0786 - val_loss: 0.1008\n",
      "Epoch 12/90\n",
      "114/114 [==============================] - 1s 13ms/step - loss: 0.0774 - val_loss: 0.0994\n",
      "Epoch 13/90\n",
      "114/114 [==============================] - 1s 12ms/step - loss: 0.0762 - val_loss: 0.0981\n",
      "Epoch 14/90\n",
      "114/114 [==============================] - 1s 12ms/step - loss: 0.0750 - val_loss: 0.0967\n",
      "Epoch 15/90\n",
      "114/114 [==============================] - 1s 12ms/step - loss: 0.0737 - val_loss: 0.0952\n",
      "Epoch 16/90\n",
      "114/114 [==============================] - 1s 12ms/step - loss: 0.0724 - val_loss: 0.0938\n",
      "Epoch 17/90\n",
      "114/114 [==============================] - 1s 12ms/step - loss: 0.0712 - val_loss: 0.0923\n",
      "Epoch 18/90\n",
      "114/114 [==============================] - 1s 12ms/step - loss: 0.0698 - val_loss: 0.0908\n",
      "Epoch 19/90\n",
      "114/114 [==============================] - 1s 12ms/step - loss: 0.0685 - val_loss: 0.0893\n",
      "Epoch 20/90\n",
      "114/114 [==============================] - 1s 12ms/step - loss: 0.0673 - val_loss: 0.0878\n",
      "Epoch 21/90\n",
      "114/114 [==============================] - 1s 13ms/step - loss: 0.0660 - val_loss: 0.0863\n",
      "Epoch 22/90\n",
      "114/114 [==============================] - 2s 13ms/step - loss: 0.0647 - val_loss: 0.0848\n",
      "Epoch 23/90\n",
      "114/114 [==============================] - 1s 13ms/step - loss: 0.0634 - val_loss: 0.0833\n",
      "Epoch 24/90\n",
      "114/114 [==============================] - 1s 12ms/step - loss: 0.0622 - val_loss: 0.0818\n",
      "Epoch 25/90\n",
      "114/114 [==============================] - 1s 12ms/step - loss: 0.0609 - val_loss: 0.0802\n",
      "Epoch 26/90\n",
      "114/114 [==============================] - 1s 12ms/step - loss: 0.0597 - val_loss: 0.0787\n",
      "Epoch 27/90\n",
      "114/114 [==============================] - 1s 12ms/step - loss: 0.0585 - val_loss: 0.0773\n",
      "Epoch 28/90\n",
      "114/114 [==============================] - 1s 12ms/step - loss: 0.0574 - val_loss: 0.0758\n",
      "Epoch 29/90\n",
      "114/114 [==============================] - 1s 12ms/step - loss: 0.0562 - val_loss: 0.0744\n",
      "Epoch 30/90\n",
      "114/114 [==============================] - 1s 12ms/step - loss: 0.0552 - val_loss: 0.0730\n",
      "Epoch 31/90\n",
      "114/114 [==============================] - 1s 12ms/step - loss: 0.0542 - val_loss: 0.0717\n",
      "Epoch 32/90\n",
      "114/114 [==============================] - 1s 13ms/step - loss: 0.0532 - val_loss: 0.0703\n",
      "Epoch 33/90\n",
      "114/114 [==============================] - 1s 13ms/step - loss: 0.0523 - val_loss: 0.0691\n",
      "Epoch 34/90\n",
      "114/114 [==============================] - 1s 13ms/step - loss: 0.0514 - val_loss: 0.0679\n",
      "Epoch 35/90\n",
      "114/114 [==============================] - 1s 12ms/step - loss: 0.0506 - val_loss: 0.0667\n",
      "Epoch 36/90\n",
      "114/114 [==============================] - 1s 12ms/step - loss: 0.0498 - val_loss: 0.0656\n",
      "Epoch 37/90\n",
      "114/114 [==============================] - 1s 12ms/step - loss: 0.0491 - val_loss: 0.0645\n",
      "Epoch 38/90\n",
      "114/114 [==============================] - 1s 12ms/step - loss: 0.0483 - val_loss: 0.0634\n",
      "Epoch 39/90\n",
      "114/114 [==============================] - 1s 12ms/step - loss: 0.0477 - val_loss: 0.0623\n",
      "Epoch 40/90\n",
      "114/114 [==============================] - 1s 12ms/step - loss: 0.0470 - val_loss: 0.0613\n",
      "Epoch 41/90\n",
      "114/114 [==============================] - 1s 12ms/step - loss: 0.0463 - val_loss: 0.0603\n",
      "Epoch 42/90\n",
      "114/114 [==============================] - 1s 12ms/step - loss: 0.0457 - val_loss: 0.0593\n",
      "Epoch 43/90\n",
      "114/114 [==============================] - 1s 12ms/step - loss: 0.0452 - val_loss: 0.0585\n",
      "Epoch 44/90\n",
      "114/114 [==============================] - 2s 13ms/step - loss: 0.0447 - val_loss: 0.0576\n",
      "Epoch 45/90\n",
      "114/114 [==============================] - 1s 13ms/step - loss: 0.0442 - val_loss: 0.0568\n",
      "Epoch 46/90\n",
      "114/114 [==============================] - 1s 12ms/step - loss: 0.0437 - val_loss: 0.0560\n",
      "Epoch 47/90\n",
      "114/114 [==============================] - 1s 12ms/step - loss: 0.0432 - val_loss: 0.0552\n",
      "Epoch 48/90\n",
      "114/114 [==============================] - 1s 12ms/step - loss: 0.0428 - val_loss: 0.0544\n",
      "Epoch 49/90\n",
      "114/114 [==============================] - 1s 12ms/step - loss: 0.0423 - val_loss: 0.0536\n",
      "Epoch 50/90\n",
      "114/114 [==============================] - 1s 12ms/step - loss: 0.0419 - val_loss: 0.0528\n",
      "Epoch 51/90\n",
      "114/114 [==============================] - 1s 12ms/step - loss: 0.0415 - val_loss: 0.0521\n",
      "Epoch 52/90\n",
      "114/114 [==============================] - 1s 12ms/step - loss: 0.0411 - val_loss: 0.0513\n",
      "Epoch 53/90\n",
      "114/114 [==============================] - 1s 12ms/step - loss: 0.0407 - val_loss: 0.0506\n",
      "Epoch 54/90\n",
      "114/114 [==============================] - 1s 12ms/step - loss: 0.0403 - val_loss: 0.0499\n",
      "Epoch 55/90\n",
      "114/114 [==============================] - 1s 13ms/step - loss: 0.0399 - val_loss: 0.0491\n",
      "Epoch 56/90\n",
      "114/114 [==============================] - 1s 13ms/step - loss: 0.0396 - val_loss: 0.0484\n",
      "Epoch 57/90\n",
      "114/114 [==============================] - 1s 12ms/step - loss: 0.0392 - val_loss: 0.0477\n",
      "Epoch 58/90\n",
      "114/114 [==============================] - 1s 12ms/step - loss: 0.0389 - val_loss: 0.0471\n",
      "Epoch 59/90\n",
      "114/114 [==============================] - 1s 12ms/step - loss: 0.0386 - val_loss: 0.0464\n",
      "Epoch 60/90\n",
      "114/114 [==============================] - 1s 12ms/step - loss: 0.0382 - val_loss: 0.0457\n",
      "Epoch 61/90\n",
      "114/114 [==============================] - 1s 12ms/step - loss: 0.0379 - val_loss: 0.0451\n",
      "Epoch 62/90\n",
      "114/114 [==============================] - 1s 12ms/step - loss: 0.0376 - val_loss: 0.0444\n",
      "Epoch 63/90\n",
      "114/114 [==============================] - 1s 12ms/step - loss: 0.0373 - val_loss: 0.0438\n",
      "Epoch 64/90\n",
      "114/114 [==============================] - 1s 12ms/step - loss: 0.0370 - val_loss: 0.0432\n",
      "Epoch 65/90\n",
      "114/114 [==============================] - 1s 12ms/step - loss: 0.0368 - val_loss: 0.0426\n",
      "Epoch 66/90\n",
      "114/114 [==============================] - 1s 13ms/step - loss: 0.0365 - val_loss: 0.0420\n",
      "Epoch 67/90\n",
      "114/114 [==============================] - 1s 13ms/step - loss: 0.0363 - val_loss: 0.0414\n",
      "Epoch 68/90\n",
      "114/114 [==============================] - 1s 12ms/step - loss: 0.0359 - val_loss: 0.0407\n",
      "Epoch 69/90\n",
      "114/114 [==============================] - 1s 12ms/step - loss: 0.0356 - val_loss: 0.0399\n",
      "Epoch 70/90\n",
      "114/114 [==============================] - 1s 12ms/step - loss: 0.0353 - val_loss: 0.0392\n",
      "Epoch 71/90\n",
      "114/114 [==============================] - 1s 12ms/step - loss: 0.0351 - val_loss: 0.0384\n",
      "Epoch 72/90\n",
      "114/114 [==============================] - 1s 12ms/step - loss: 0.0348 - val_loss: 0.0378\n",
      "Epoch 73/90\n",
      "114/114 [==============================] - 1s 12ms/step - loss: 0.0345 - val_loss: 0.0371\n",
      "Epoch 74/90\n",
      "114/114 [==============================] - 1s 12ms/step - loss: 0.0343 - val_loss: 0.0364\n",
      "Epoch 75/90\n",
      "114/114 [==============================] - 1s 12ms/step - loss: 0.0340 - val_loss: 0.0358\n",
      "Epoch 76/90\n",
      "114/114 [==============================] - 1s 12ms/step - loss: 0.0338 - val_loss: 0.0352\n",
      "Epoch 77/90\n",
      "114/114 [==============================] - 1s 13ms/step - loss: 0.0336 - val_loss: 0.0347\n",
      "Epoch 78/90\n",
      "114/114 [==============================] - 2s 13ms/step - loss: 0.0334 - val_loss: 0.0341\n",
      "Epoch 79/90\n",
      "114/114 [==============================] - 1s 12ms/step - loss: 0.0332 - val_loss: 0.0336\n",
      "Epoch 80/90\n",
      "114/114 [==============================] - 1s 12ms/step - loss: 0.0330 - val_loss: 0.0331\n",
      "Epoch 81/90\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "114/114 [==============================] - 1s 12ms/step - loss: 0.0329 - val_loss: 0.0326\n",
      "Epoch 82/90\n",
      "114/114 [==============================] - 1s 12ms/step - loss: 0.0328 - val_loss: 0.0322\n",
      "Epoch 83/90\n",
      "114/114 [==============================] - 1s 12ms/step - loss: 0.0326 - val_loss: 0.0317\n",
      "Epoch 84/90\n",
      "114/114 [==============================] - 1s 12ms/step - loss: 0.0325 - val_loss: 0.0313\n",
      "Epoch 85/90\n",
      "114/114 [==============================] - 1s 12ms/step - loss: 0.0324 - val_loss: 0.0309\n",
      "Epoch 86/90\n",
      "114/114 [==============================] - 1s 12ms/step - loss: 0.0323 - val_loss: 0.0305\n",
      "Epoch 87/90\n",
      "114/114 [==============================] - 1s 12ms/step - loss: 0.0322 - val_loss: 0.0302\n",
      "Epoch 88/90\n",
      "114/114 [==============================] - 1s 13ms/step - loss: 0.0321 - val_loss: 0.0298\n",
      "Epoch 89/90\n",
      "114/114 [==============================] - 1s 13ms/step - loss: 0.0320 - val_loss: 0.0295\n",
      "Epoch 90/90\n",
      "114/114 [==============================] - 1s 12ms/step - loss: 0.0319 - val_loss: 0.0292\n",
      "Execution time:  130.28317308425903\n",
      "DNN:\n",
      "Mean Absolute Error: 0.0327\n",
      "Root Mean Square Error: 0.0462\n",
      "Mean Square Error: 0.0021\n",
      "\n",
      "Train RMSE: 0.046\n",
      "Train MSE: 0.002\n",
      "Train MAE: 0.033\n",
      "###########################\n",
      "\n",
      "MODEL:  DNN\n",
      "sequence:  3d\n",
      "units:  12\n",
      "dropout1:  0.48476373451509647\n",
      "optimizer: adadelta\n",
      "activationDense: sigmoid\n",
      "epochs: 52\n",
      "batchsize: 57\n",
      "validation_split: 0.2\n",
      "Model: \"sequential_203\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_609 (Dense)            (None, 432, 12)           24        \n",
      "_________________________________________________________________\n",
      "dense_610 (Dense)            (None, 432, 16)           208       \n",
      "_________________________________________________________________\n",
      "dropout_203 (Dropout)        (None, 432, 16)           0         \n",
      "_________________________________________________________________\n",
      "dense_611 (Dense)            (None, 432, 1)            17        \n",
      "=================================================================\n",
      "Total params: 249\n",
      "Trainable params: 249\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/52\n",
      "50/50 [==============================] - 1s 18ms/step - loss: 0.1458 - val_loss: 0.1685\n",
      "Epoch 2/52\n",
      "50/50 [==============================] - 1s 15ms/step - loss: 0.1457 - val_loss: 0.1684\n",
      "Epoch 3/52\n",
      "50/50 [==============================] - 1s 15ms/step - loss: 0.1455 - val_loss: 0.1682\n",
      "Epoch 4/52\n",
      "50/50 [==============================] - 1s 15ms/step - loss: 0.1454 - val_loss: 0.1680\n",
      "Epoch 5/52\n",
      "50/50 [==============================] - 1s 15ms/step - loss: 0.1452 - val_loss: 0.1679\n",
      "Epoch 6/52\n",
      "50/50 [==============================] - 1s 15ms/step - loss: 0.1450 - val_loss: 0.1677\n",
      "Epoch 7/52\n",
      "50/50 [==============================] - 1s 15ms/step - loss: 0.1449 - val_loss: 0.1675\n",
      "Epoch 8/52\n",
      "50/50 [==============================] - 1s 15ms/step - loss: 0.1447 - val_loss: 0.1673\n",
      "Epoch 9/52\n",
      "50/50 [==============================] - 1s 15ms/step - loss: 0.1445 - val_loss: 0.1672\n",
      "Epoch 10/52\n",
      "50/50 [==============================] - 1s 15ms/step - loss: 0.1443 - val_loss: 0.1670\n",
      "Epoch 11/52\n",
      "50/50 [==============================] - 1s 15ms/step - loss: 0.1441 - val_loss: 0.1668\n",
      "Epoch 12/52\n",
      "50/50 [==============================] - 1s 15ms/step - loss: 0.1439 - val_loss: 0.1666\n",
      "Epoch 13/52\n",
      "50/50 [==============================] - 1s 15ms/step - loss: 0.1437 - val_loss: 0.1663\n",
      "Epoch 14/52\n",
      "50/50 [==============================] - 1s 15ms/step - loss: 0.1434 - val_loss: 0.1661\n",
      "Epoch 15/52\n",
      "50/50 [==============================] - 1s 16ms/step - loss: 0.1433 - val_loss: 0.1659\n",
      "Epoch 16/52\n",
      "50/50 [==============================] - 1s 16ms/step - loss: 0.1430 - val_loss: 0.1657\n",
      "Epoch 17/52\n",
      "50/50 [==============================] - 1s 16ms/step - loss: 0.1428 - val_loss: 0.1655\n",
      "Epoch 18/52\n",
      "50/50 [==============================] - 1s 15ms/step - loss: 0.1426 - val_loss: 0.1652\n",
      "Epoch 19/52\n",
      "50/50 [==============================] - 1s 15ms/step - loss: 0.1424 - val_loss: 0.1650\n",
      "Epoch 20/52\n",
      "50/50 [==============================] - 1s 15ms/step - loss: 0.1421 - val_loss: 0.1648\n",
      "Epoch 21/52\n",
      "50/50 [==============================] - 1s 15ms/step - loss: 0.1419 - val_loss: 0.1645\n",
      "Epoch 22/52\n",
      "50/50 [==============================] - 1s 15ms/step - loss: 0.1416 - val_loss: 0.1643\n",
      "Epoch 23/52\n",
      "50/50 [==============================] - 1s 15ms/step - loss: 0.1414 - val_loss: 0.1640\n",
      "Epoch 24/52\n",
      "50/50 [==============================] - 1s 15ms/step - loss: 0.1411 - val_loss: 0.1638\n",
      "Epoch 25/52\n",
      "50/50 [==============================] - 1s 15ms/step - loss: 0.1409 - val_loss: 0.1635\n",
      "Epoch 26/52\n",
      "50/50 [==============================] - 1s 15ms/step - loss: 0.1406 - val_loss: 0.1633\n",
      "Epoch 27/52\n",
      "50/50 [==============================] - 1s 16ms/step - loss: 0.1404 - val_loss: 0.1630\n",
      "Epoch 28/52\n",
      "50/50 [==============================] - 1s 15ms/step - loss: 0.1401 - val_loss: 0.1628\n",
      "Epoch 29/52\n",
      "50/50 [==============================] - 1s 15ms/step - loss: 0.1399 - val_loss: 0.1625\n",
      "Epoch 30/52\n",
      "50/50 [==============================] - 1s 15ms/step - loss: 0.1396 - val_loss: 0.1623\n",
      "Epoch 31/52\n",
      "50/50 [==============================] - 1s 15ms/step - loss: 0.1394 - val_loss: 0.1621\n",
      "Epoch 32/52\n",
      "50/50 [==============================] - 1s 15ms/step - loss: 0.1392 - val_loss: 0.1618\n",
      "Epoch 33/52\n",
      "50/50 [==============================] - 1s 15ms/step - loss: 0.1389 - val_loss: 0.1616\n",
      "Epoch 34/52\n",
      "50/50 [==============================] - 1s 15ms/step - loss: 0.1387 - val_loss: 0.1613\n",
      "Epoch 35/52\n",
      "50/50 [==============================] - 1s 16ms/step - loss: 0.1384 - val_loss: 0.1611\n",
      "Epoch 36/52\n",
      "50/50 [==============================] - 1s 16ms/step - loss: 0.1382 - val_loss: 0.1609\n",
      "Epoch 37/52\n",
      "50/50 [==============================] - 1s 17ms/step - loss: 0.1379 - val_loss: 0.1606\n",
      "Epoch 38/52\n",
      "50/50 [==============================] - 1s 16ms/step - loss: 0.1377 - val_loss: 0.1604\n",
      "Epoch 39/52\n",
      "50/50 [==============================] - 1s 15ms/step - loss: 0.1375 - val_loss: 0.1601\n",
      "Epoch 40/52\n",
      "50/50 [==============================] - 1s 15ms/step - loss: 0.1372 - val_loss: 0.1598\n",
      "Epoch 41/52\n",
      "50/50 [==============================] - 1s 15ms/step - loss: 0.1369 - val_loss: 0.1596\n",
      "Epoch 42/52\n",
      "50/50 [==============================] - 1s 15ms/step - loss: 0.1367 - val_loss: 0.1593\n",
      "Epoch 43/52\n",
      "50/50 [==============================] - 1s 15ms/step - loss: 0.1364 - val_loss: 0.1591\n",
      "Epoch 44/52\n",
      "50/50 [==============================] - 1s 15ms/step - loss: 0.1362 - val_loss: 0.1588\n",
      "Epoch 45/52\n",
      "50/50 [==============================] - 1s 15ms/step - loss: 0.1359 - val_loss: 0.1585\n",
      "Epoch 46/52\n",
      "50/50 [==============================] - 1s 15ms/step - loss: 0.1356 - val_loss: 0.1583\n",
      "Epoch 47/52\n",
      "50/50 [==============================] - 1s 15ms/step - loss: 0.1354 - val_loss: 0.1580\n",
      "Epoch 48/52\n",
      "50/50 [==============================] - 1s 15ms/step - loss: 0.1351 - val_loss: 0.1577\n",
      "Epoch 49/52\n",
      "50/50 [==============================] - 1s 15ms/step - loss: 0.1348 - val_loss: 0.1575\n",
      "Epoch 50/52\n",
      "50/50 [==============================] - 1s 15ms/step - loss: 0.1346 - val_loss: 0.1572\n",
      "Epoch 51/52\n",
      "50/50 [==============================] - 1s 15ms/step - loss: 0.1343 - val_loss: 0.1569\n",
      "Epoch 52/52\n",
      "50/50 [==============================] - 1s 15ms/step - loss: 0.1340 - val_loss: 0.1566\n",
      "Execution time:  41.221580505371094\n",
      "DNN:\n",
      "Mean Absolute Error: 0.1354\n",
      "Root Mean Square Error: 0.1392\n",
      "Mean Square Error: 0.0194\n",
      "\n",
      "Train RMSE: 0.139\n",
      "Train MSE: 0.019\n",
      "Train MAE: 0.135\n",
      "###########################\n",
      "\n",
      "MODEL:  DNN\n",
      "sequence:  3d\n",
      "units:  87\n",
      "dropout1:  0.40519643149940265\n",
      "optimizer: adamax\n",
      "activationDense: tanh\n",
      "epochs: 80\n",
      "batchsize: 31\n",
      "validation_split: 0.1\n",
      "Model: \"sequential_204\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_612 (Dense)            (None, 432, 87)           174       \n",
      "_________________________________________________________________\n",
      "dense_613 (Dense)            (None, 432, 16)           1408      \n",
      "_________________________________________________________________\n",
      "dropout_204 (Dropout)        (None, 432, 16)           0         \n",
      "_________________________________________________________________\n",
      "dense_614 (Dense)            (None, 432, 1)            17        \n",
      "=================================================================\n",
      "Total params: 1,599\n",
      "Trainable params: 1,599\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/80\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "104/104 [==============================] - 2s 18ms/step - loss: 0.1371 - val_loss: 0.0174\n",
      "Epoch 2/80\n",
      "104/104 [==============================] - 2s 16ms/step - loss: 0.0998 - val_loss: 0.0098\n",
      "Epoch 3/80\n",
      "104/104 [==============================] - 2s 15ms/step - loss: 0.0800 - val_loss: 0.0093\n",
      "Epoch 4/80\n",
      "104/104 [==============================] - 2s 15ms/step - loss: 0.0721 - val_loss: 0.0074\n",
      "Epoch 5/80\n",
      "104/104 [==============================] - 2s 15ms/step - loss: 0.0650 - val_loss: 0.0095\n",
      "Epoch 6/80\n",
      "104/104 [==============================] - 2s 15ms/step - loss: 0.0606 - val_loss: 0.0097\n",
      "Epoch 7/80\n",
      "104/104 [==============================] - 2s 15ms/step - loss: 0.0570 - val_loss: 0.0103A:\n",
      "Epoch 8/80\n",
      "104/104 [==============================] - 2s 15ms/step - loss: 0.0536 - val_loss: 0.0119\n",
      "Epoch 9/80\n",
      "104/104 [==============================] - 2s 15ms/step - loss: 0.0504 - val_loss: 0.0138\n",
      "Epoch 10/80\n",
      "104/104 [==============================] - 2s 15ms/step - loss: 0.0473 - val_loss: 0.0153\n",
      "Epoch 11/80\n",
      "104/104 [==============================] - 2s 15ms/step - loss: 0.0448 - val_loss: 0.0177\n",
      "Epoch 12/80\n",
      "104/104 [==============================] - 2s 16ms/step - loss: 0.0425 - val_loss: 0.0188\n",
      "Epoch 13/80\n",
      "104/104 [==============================] - 2s 15ms/step - loss: 0.0403 - val_loss: 0.0202\n",
      "Epoch 14/80\n",
      "104/104 [==============================] - 2s 15ms/step - loss: 0.0386 - val_loss: 0.0215\n",
      "Epoch 15/80\n",
      "104/104 [==============================] - 2s 15ms/step - loss: 0.0369 - val_loss: 0.0212\n",
      "Epoch 16/80\n",
      "104/104 [==============================] - 2s 15ms/step - loss: 0.0360 - val_loss: 0.0197\n",
      "Epoch 17/80\n",
      "104/104 [==============================] - 2s 15ms/step - loss: 0.0349 - val_loss: 0.0190\n",
      "Epoch 18/80\n",
      "104/104 [==============================] - 2s 15ms/step - loss: 0.0340 - val_loss: 0.0177\n",
      "Epoch 19/80\n",
      "104/104 [==============================] - 2s 15ms/step - loss: 0.0331 - val_loss: 0.0169\n",
      "Epoch 20/80\n",
      "104/104 [==============================] - 2s 15ms/step - loss: 0.0323 - val_loss: 0.0189\n",
      "Epoch 21/80\n",
      "104/104 [==============================] - 2s 16ms/step - loss: 0.0318 - val_loss: 0.0153\n",
      "Epoch 22/80\n",
      "104/104 [==============================] - 2s 16ms/step - loss: 0.0302 - val_loss: 0.0121\n",
      "Epoch 23/80\n",
      "104/104 [==============================] - 2s 15ms/step - loss: 0.0298 - val_loss: 0.0119\n",
      "Epoch 24/80\n",
      "104/104 [==============================] - 2s 15ms/step - loss: 0.0289 - val_loss: 0.0109\n",
      "Epoch 25/80\n",
      "104/104 [==============================] - 2s 15ms/step - loss: 0.0281 - val_loss: 0.0095\n",
      "Epoch 26/80\n",
      "104/104 [==============================] - 2s 15ms/step - loss: 0.0266 - val_loss: 0.0112\n",
      "Epoch 27/80\n",
      "104/104 [==============================] - 2s 15ms/step - loss: 0.0265 - val_loss: 0.0123\n",
      "Epoch 28/80\n",
      "104/104 [==============================] - 2s 15ms/step - loss: 0.0262 - val_loss: 0.0146\n",
      "Epoch 29/80\n",
      "104/104 [==============================] - 2s 15ms/step - loss: 0.0260 - val_loss: 0.0143\n",
      "Epoch 30/80\n",
      "104/104 [==============================] - 2s 15ms/step - loss: 0.0259 - val_loss: 0.0146\n",
      "Epoch 31/80\n",
      "104/104 [==============================] - 2s 16ms/step - loss: 0.0259 - val_loss: 0.0148\n",
      "Epoch 32/80\n",
      "104/104 [==============================] - 2s 16ms/step - loss: 0.0259 - val_loss: 0.0150\n",
      "Epoch 33/80\n",
      "104/104 [==============================] - 2s 15ms/step - loss: 0.0259 - val_loss: 0.0151\n",
      "Epoch 34/80\n",
      "104/104 [==============================] - 2s 15ms/step - loss: 0.0259 - val_loss: 0.0151\n",
      "Epoch 35/80\n",
      "104/104 [==============================] - 2s 15ms/step - loss: 0.0259 - val_loss: 0.0151\n",
      "Epoch 36/80\n",
      "104/104 [==============================] - 2s 15ms/step - loss: 0.0259 - val_loss: 0.0150\n",
      "Epoch 37/80\n",
      "104/104 [==============================] - 2s 15ms/step - loss: 0.0259 - val_loss: 0.0152\n",
      "Epoch 38/80\n",
      "104/104 [==============================] - 2s 15ms/step - loss: 0.0259 - val_loss: 0.0152\n",
      "Epoch 39/80\n",
      "104/104 [==============================] - 2s 15ms/step - loss: 0.0259 - val_loss: 0.0152\n",
      "Epoch 40/80\n",
      "104/104 [==============================] - 2s 15ms/step - loss: 0.0259 - val_loss: 0.0152\n",
      "Epoch 41/80\n",
      "104/104 [==============================] - 2s 16ms/step - loss: 0.0259 - val_loss: 0.0152\n",
      "Epoch 42/80\n",
      "104/104 [==============================] - 2s 16ms/step - loss: 0.0259 - val_loss: 0.0152\n",
      "Epoch 43/80\n",
      "104/104 [==============================] - 2s 15ms/step - loss: 0.0259 - val_loss: 0.0151\n",
      "Epoch 44/80\n",
      "104/104 [==============================] - 2s 15ms/step - loss: 0.0259 - val_loss: 0.0153\n",
      "Epoch 45/80\n",
      "104/104 [==============================] - 2s 15ms/step - loss: 0.0259 - val_loss: 0.0152\n",
      "Epoch 46/80\n",
      "104/104 [==============================] - 2s 15ms/step - loss: 0.0259 - val_loss: 0.0152\n",
      "Epoch 47/80\n",
      "104/104 [==============================] - 2s 15ms/step - loss: 0.0259 - val_loss: 0.0152\n",
      "Epoch 48/80\n",
      "104/104 [==============================] - 2s 15ms/step - loss: 0.0259 - val_loss: 0.0152\n",
      "Epoch 49/80\n",
      "104/104 [==============================] - 2s 15ms/step - loss: 0.0259 - val_loss: 0.0152\n",
      "Epoch 50/80\n",
      "104/104 [==============================] - 2s 15ms/step - loss: 0.0259 - val_loss: 0.0152\n",
      "Epoch 51/80\n",
      "104/104 [==============================] - 2s 16ms/step - loss: 0.0259 - val_loss: 0.0152\n",
      "Epoch 52/80\n",
      "104/104 [==============================] - 2s 16ms/step - loss: 0.0259 - val_loss: 0.0152\n",
      "Epoch 53/80\n",
      "104/104 [==============================] - 2s 15ms/step - loss: 0.0258 - val_loss: 0.0150\n",
      "Epoch 54/80\n",
      "104/104 [==============================] - 2s 15ms/step - loss: 0.0259 - val_loss: 0.0152\n",
      "Epoch 55/80\n",
      "104/104 [==============================] - 2s 15ms/step - loss: 0.0259 - val_loss: 0.0152\n",
      "Epoch 56/80\n",
      "104/104 [==============================] - 2s 15ms/step - loss: 0.0259 - val_loss: 0.0152\n",
      "Epoch 57/80\n",
      "104/104 [==============================] - 2s 15ms/step - loss: 0.0259 - val_loss: 0.0152\n",
      "Epoch 58/80\n",
      "104/104 [==============================] - 2s 15ms/step - loss: 0.0259 - val_loss: 0.0152\n",
      "Epoch 59/80\n",
      "104/104 [==============================] - 2s 15ms/step - loss: 0.0259 - val_loss: 0.0152\n",
      "Epoch 60/80\n",
      "104/104 [==============================] - 2s 15ms/step - loss: 0.0258 - val_loss: 0.0150\n",
      "Epoch 61/80\n",
      "104/104 [==============================] - 2s 16ms/step - loss: 0.0259 - val_loss: 0.0152\n",
      "Epoch 62/80\n",
      "104/104 [==============================] - 2s 16ms/step - loss: 0.0259 - val_loss: 0.0152\n",
      "Epoch 63/80\n",
      "104/104 [==============================] - 2s 15ms/step - loss: 0.0259 - val_loss: 0.0152\n",
      "Epoch 64/80\n",
      "104/104 [==============================] - 2s 15ms/step - loss: 0.0259 - val_loss: 0.0152\n",
      "Epoch 65/80\n",
      "104/104 [==============================] - 2s 15ms/step - loss: 0.0259 - val_loss: 0.0152\n",
      "Epoch 66/80\n",
      "104/104 [==============================] - 2s 15ms/step - loss: 0.0259 - val_loss: 0.0152\n",
      "Epoch 67/80\n",
      "104/104 [==============================] - 2s 15ms/step - loss: 0.0258 - val_loss: 0.0150\n",
      "Epoch 68/80\n",
      "104/104 [==============================] - 2s 15ms/step - loss: 0.0259 - val_loss: 0.0152\n",
      "Epoch 69/80\n",
      "104/104 [==============================] - 2s 15ms/step - loss: 0.0259 - val_loss: 0.0152\n",
      "Epoch 70/80\n",
      "104/104 [==============================] - 2s 16ms/step - loss: 0.0259 - val_loss: 0.0152\n",
      "Epoch 71/80\n",
      "104/104 [==============================] - 2s 16ms/step - loss: 0.0259 - val_loss: 0.0152\n",
      "Epoch 72/80\n",
      "104/104 [==============================] - 2s 16ms/step - loss: 0.0259 - val_loss: 0.0152\n",
      "Epoch 73/80\n",
      "104/104 [==============================] - 2s 15ms/step - loss: 0.0259 - val_loss: 0.0152\n",
      "Epoch 74/80\n",
      "104/104 [==============================] - 2s 15ms/step - loss: 0.0258 - val_loss: 0.0150\n",
      "Epoch 75/80\n",
      "104/104 [==============================] - 2s 15ms/step - loss: 0.0259 - val_loss: 0.0152\n",
      "Epoch 76/80\n",
      "104/104 [==============================] - 2s 15ms/step - loss: 0.0259 - val_loss: 0.0152\n",
      "Epoch 77/80\n",
      "104/104 [==============================] - 2s 15ms/step - loss: 0.0259 - val_loss: 0.0152\n",
      "Epoch 78/80\n",
      "104/104 [==============================] - 2s 15ms/step - loss: 0.0259 - val_loss: 0.0152\n",
      "Epoch 79/80\n",
      "104/104 [==============================] - 2s 15ms/step - loss: 0.0259 - val_loss: 0.0152\n",
      "Epoch 80/80\n",
      "104/104 [==============================] - 2s 16ms/step - loss: 0.0259 - val_loss: 0.0152\n",
      "Execution time:  130.40651106834412\n",
      "DNN:\n",
      "Mean Absolute Error: 0.0253\n",
      "Root Mean Square Error: 0.0441\n",
      "Mean Square Error: 0.0019\n",
      "\n",
      "Train RMSE: 0.044\n",
      "Train MSE: 0.002\n",
      "Train MAE: 0.025\n",
      "###########################\n",
      "\n",
      "MODEL:  DNN\n",
      "sequence:  3d\n",
      "units:  80\n",
      "dropout1:  0.11814836227952394\n",
      "optimizer: adamax\n",
      "activationDense: tanh\n",
      "epochs: 90\n",
      "batchsize: 25\n",
      "validation_split: 0.1\n",
      "Model: \"sequential_205\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_615 (Dense)            (None, 432, 80)           160       \n",
      "_________________________________________________________________\n",
      "dense_616 (Dense)            (None, 432, 16)           1296      \n",
      "_________________________________________________________________\n",
      "dropout_205 (Dropout)        (None, 432, 16)           0         \n",
      "_________________________________________________________________\n",
      "dense_617 (Dense)            (None, 432, 1)            17        \n",
      "=================================================================\n",
      "Total params: 1,473\n",
      "Trainable params: 1,473\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/90\n",
      "129/129 [==============================] - 2s 16ms/step - loss: 0.1208 - val_loss: 0.0090\n",
      "Epoch 2/90\n",
      "129/129 [==============================] - 2s 12ms/step - loss: 0.0559 - val_loss: 0.0073\n",
      "Epoch 3/90\n",
      "129/129 [==============================] - 2s 12ms/step - loss: 0.0537 - val_loss: 0.0069\n",
      "Epoch 4/90\n",
      "129/129 [==============================] - 2s 12ms/step - loss: 0.0513 - val_loss: 0.0077\n",
      "Epoch 5/90\n",
      "129/129 [==============================] - 2s 12ms/step - loss: 0.0491 - val_loss: 0.0075\n",
      "Epoch 6/90\n",
      "129/129 [==============================] - 2s 12ms/step - loss: 0.0474 - val_loss: 0.0098\n",
      "Epoch 7/90\n",
      "129/129 [==============================] - 2s 12ms/step - loss: 0.0454 - val_loss: 0.0109\n",
      "Epoch 8/90\n",
      "129/129 [==============================] - 2s 12ms/step - loss: 0.0439 - val_loss: 0.0119\n",
      "Epoch 9/90\n",
      "129/129 [==============================] - 2s 12ms/step - loss: 0.0426 - val_loss: 0.0123\n",
      "Epoch 10/90\n",
      "129/129 [==============================] - 2s 13ms/step - loss: 0.0415 - val_loss: 0.0133\n",
      "Epoch 11/90\n",
      "129/129 [==============================] - 2s 12ms/step - loss: 0.0403 - val_loss: 0.0137\n",
      "Epoch 12/90\n",
      "129/129 [==============================] - 2s 12ms/step - loss: 0.0395 - val_loss: 0.0149\n",
      "Epoch 13/90\n",
      "129/129 [==============================] - 2s 12ms/step - loss: 0.0387 - val_loss: 0.0124\n",
      "Epoch 14/90\n",
      "129/129 [==============================] - 2s 12ms/step - loss: 0.0375 - val_loss: 0.0134\n",
      "Epoch 15/90\n",
      "129/129 [==============================] - 2s 12ms/step - loss: 0.0372 - val_loss: 0.0148\n",
      "Epoch 16/90\n",
      "129/129 [==============================] - 2s 12ms/step - loss: 0.0365 - val_loss: 0.0138\n",
      "Epoch 17/90\n",
      "129/129 [==============================] - 2s 12ms/step - loss: 0.0360 - val_loss: 0.0154\n",
      "Epoch 18/90\n",
      "129/129 [==============================] - 2s 12ms/step - loss: 0.0347 - val_loss: 0.0152\n",
      "Epoch 19/90\n",
      "129/129 [==============================] - 2s 12ms/step - loss: 0.0347 - val_loss: 0.0152\n",
      "Epoch 20/90\n",
      "129/129 [==============================] - 2s 13ms/step - loss: 0.0342 - val_loss: 0.0156\n",
      "Epoch 21/90\n",
      "129/129 [==============================] - 2s 12ms/step - loss: 0.0337 - val_loss: 0.0158\n",
      "Epoch 22/90\n",
      "129/129 [==============================] - 2s 12ms/step - loss: 0.0328 - val_loss: 0.0159\n",
      "Epoch 23/90\n",
      "129/129 [==============================] - 2s 12ms/step - loss: 0.0325 - val_loss: 0.0161\n",
      "Epoch 24/90\n",
      "129/129 [==============================] - 2s 12ms/step - loss: 0.0320 - val_loss: 0.0161\n",
      "Epoch 25/90\n",
      "129/129 [==============================] - 2s 12ms/step - loss: 0.0314 - val_loss: 0.0142\n",
      "Epoch 26/90\n",
      "129/129 [==============================] - 2s 12ms/step - loss: 0.0311 - val_loss: 0.0157\n",
      "Epoch 27/90\n",
      "129/129 [==============================] - 2s 12ms/step - loss: 0.0306 - val_loss: 0.0155\n",
      "Epoch 28/90\n",
      "129/129 [==============================] - 2s 12ms/step - loss: 0.0302 - val_loss: 0.0139\n",
      "Epoch 29/90\n",
      "129/129 [==============================] - 2s 12ms/step - loss: 0.0298 - val_loss: 0.0138\n",
      "Epoch 30/90\n",
      "129/129 [==============================] - 2s 13ms/step - loss: 0.0298 - val_loss: 0.0149\n",
      "Epoch 31/90\n",
      "129/129 [==============================] - 2s 12ms/step - loss: 0.0292 - val_loss: 0.0135\n",
      "Epoch 32/90\n",
      "129/129 [==============================] - 2s 12ms/step - loss: 0.0290 - val_loss: 0.0114\n",
      "Epoch 33/90\n",
      "129/129 [==============================] - 2s 12ms/step - loss: 0.0289 - val_loss: 0.0114\n",
      "Epoch 34/90\n",
      "129/129 [==============================] - 2s 12ms/step - loss: 0.0288 - val_loss: 0.0106\n",
      "Epoch 35/90\n",
      "129/129 [==============================] - 2s 12ms/step - loss: 0.0283 - val_loss: 0.0111\n",
      "Epoch 36/90\n",
      "129/129 [==============================] - 2s 12ms/step - loss: 0.0282 - val_loss: 0.0105\n",
      "Epoch 37/90\n",
      "129/129 [==============================] - 2s 12ms/step - loss: 0.0278 - val_loss: 0.0105\n",
      "Epoch 38/90\n",
      "129/129 [==============================] - 2s 12ms/step - loss: 0.0276 - val_loss: 0.0105\n",
      "Epoch 39/90\n",
      "129/129 [==============================] - 2s 12ms/step - loss: 0.0275 - val_loss: 0.0103\n",
      "Epoch 40/90\n",
      "129/129 [==============================] - 2s 12ms/step - loss: 0.0273 - val_loss: 0.0104\n",
      "Epoch 41/90\n",
      "129/129 [==============================] - 2s 12ms/step - loss: 0.0272 - val_loss: 0.0103\n",
      "Epoch 42/90\n",
      "129/129 [==============================] - 2s 12ms/step - loss: 0.0271 - val_loss: 0.0102\n",
      "Epoch 43/90\n",
      "129/129 [==============================] - 2s 12ms/step - loss: 0.0270 - val_loss: 0.0104\n",
      "Epoch 44/90\n",
      "129/129 [==============================] - 2s 12ms/step - loss: 0.0269 - val_loss: 0.0103\n",
      "Epoch 45/90\n",
      "129/129 [==============================] - 2s 12ms/step - loss: 0.0268 - val_loss: 0.0103\n",
      "Epoch 46/90\n",
      "129/129 [==============================] - 2s 12ms/step - loss: 0.0268 - val_loss: 0.0103\n",
      "Epoch 47/90\n",
      "129/129 [==============================] - 2s 12ms/step - loss: 0.0267 - val_loss: 0.0109\n",
      "Epoch 48/90\n",
      "129/129 [==============================] - 2s 12ms/step - loss: 0.0266 - val_loss: 0.0115\n",
      "Epoch 49/90\n",
      "129/129 [==============================] - 2s 12ms/step - loss: 0.0265 - val_loss: 0.0121\n",
      "Epoch 50/90\n",
      "129/129 [==============================] - 2s 12ms/step - loss: 0.0264 - val_loss: 0.0125\n",
      "Epoch 51/90\n",
      "129/129 [==============================] - 2s 13ms/step - loss: 0.0263 - val_loss: 0.0127\n",
      "Epoch 52/90\n",
      "129/129 [==============================] - 2s 12ms/step - loss: 0.0263 - val_loss: 0.0129\n",
      "Epoch 53/90\n",
      "129/129 [==============================] - 2s 12ms/step - loss: 0.0263 - val_loss: 0.0131\n",
      "Epoch 54/90\n",
      "129/129 [==============================] - 2s 12ms/step - loss: 0.0262 - val_loss: 0.0133\n",
      "Epoch 55/90\n",
      "129/129 [==============================] - 2s 12ms/step - loss: 0.0262 - val_loss: 0.0135\n",
      "Epoch 56/90\n",
      "129/129 [==============================] - 2s 12ms/step - loss: 0.0261 - val_loss: 0.0132\n",
      "Epoch 57/90\n",
      "129/129 [==============================] - 2s 12ms/step - loss: 0.0262 - val_loss: 0.0134\n",
      "Epoch 58/90\n",
      "129/129 [==============================] - 2s 12ms/step - loss: 0.0261 - val_loss: 0.0134\n",
      "Epoch 59/90\n",
      "129/129 [==============================] - 2s 12ms/step - loss: 0.0262 - val_loss: 0.0154\n",
      "Epoch 60/90\n",
      "129/129 [==============================] - 2s 12ms/step - loss: 0.0269 - val_loss: 0.0106\n",
      "Epoch 61/90\n",
      "129/129 [==============================] - 2s 13ms/step - loss: 0.0264 - val_loss: 0.0138\n",
      "Epoch 62/90\n",
      "129/129 [==============================] - 2s 12ms/step - loss: 0.0262 - val_loss: 0.0135\n",
      "Epoch 63/90\n",
      "129/129 [==============================] - 2s 12ms/step - loss: 0.0261 - val_loss: 0.0132\n",
      "Epoch 64/90\n",
      "129/129 [==============================] - 2s 12ms/step - loss: 0.0262 - val_loss: 0.0134\n",
      "Epoch 65/90\n",
      "129/129 [==============================] - 2s 12ms/step - loss: 0.0261 - val_loss: 0.0134\n",
      "Epoch 66/90\n",
      "129/129 [==============================] - 2s 12ms/step - loss: 0.0261 - val_loss: 0.0134\n",
      "Epoch 67/90\n",
      "129/129 [==============================] - 2s 12ms/step - loss: 0.0261 - val_loss: 0.0134\n",
      "Epoch 68/90\n",
      "129/129 [==============================] - 2s 12ms/step - loss: 0.0261 - val_loss: 0.0134\n",
      "Epoch 69/90\n",
      "129/129 [==============================] - 2s 12ms/step - loss: 0.0261 - val_loss: 0.0134\n",
      "Epoch 70/90\n",
      "129/129 [==============================] - 2s 12ms/step - loss: 0.0261 - val_loss: 0.0133\n",
      "Epoch 71/90\n",
      "129/129 [==============================] - 2s 12ms/step - loss: 0.0262 - val_loss: 0.0135\n",
      "Epoch 72/90\n",
      "129/129 [==============================] - 2s 13ms/step - loss: 0.0261 - val_loss: 0.0132\n",
      "Epoch 73/90\n",
      "129/129 [==============================] - 2s 12ms/step - loss: 0.0262 - val_loss: 0.0134\n",
      "Epoch 74/90\n",
      "129/129 [==============================] - 2s 12ms/step - loss: 0.0261 - val_loss: 0.0134\n",
      "Epoch 75/90\n",
      "129/129 [==============================] - 2s 12ms/step - loss: 0.0261 - val_loss: 0.0134\n",
      "Epoch 76/90\n",
      "129/129 [==============================] - 2s 12ms/step - loss: 0.0261 - val_loss: 0.0134\n",
      "Epoch 77/90\n",
      "129/129 [==============================] - 2s 12ms/step - loss: 0.0261 - val_loss: 0.0134\n",
      "Epoch 78/90\n",
      "129/129 [==============================] - 2s 12ms/step - loss: 0.0261 - val_loss: 0.0133\n",
      "Epoch 79/90\n",
      "129/129 [==============================] - 2s 12ms/step - loss: 0.0262 - val_loss: 0.0135\n",
      "Epoch 80/90\n",
      "129/129 [==============================] - 2s 12ms/step - loss: 0.0261 - val_loss: 0.0132\n",
      "Epoch 81/90\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "129/129 [==============================] - 2s 12ms/step - loss: 0.0262 - val_loss: 0.0134\n",
      "Epoch 82/90\n",
      "129/129 [==============================] - 2s 13ms/step - loss: 0.0261 - val_loss: 0.0134\n",
      "Epoch 83/90\n",
      "129/129 [==============================] - 2s 12ms/step - loss: 0.0261 - val_loss: 0.0134\n",
      "Epoch 84/90\n",
      "129/129 [==============================] - 2s 12ms/step - loss: 0.0261 - val_loss: 0.0134\n",
      "Epoch 85/90\n",
      "129/129 [==============================] - 2s 12ms/step - loss: 0.0261 - val_loss: 0.0134\n",
      "Epoch 86/90\n",
      "129/129 [==============================] - 2s 12ms/step - loss: 0.0261 - val_loss: 0.0133\n",
      "Epoch 87/90\n",
      "129/129 [==============================] - 2s 12ms/step - loss: 0.0262 - val_loss: 0.0135\n",
      "Epoch 88/90\n",
      "129/129 [==============================] - 2s 12ms/step - loss: 0.0261 - val_loss: 0.0132\n",
      "Epoch 89/90\n",
      "129/129 [==============================] - 2s 12ms/step - loss: 0.0262 - val_loss: 0.0134\n",
      "Epoch 90/90\n",
      "129/129 [==============================] - 2s 12ms/step - loss: 0.0261 - val_loss: 0.0134\n",
      "Execution time:  141.44747591018677\n",
      "DNN:\n",
      "Mean Absolute Error: 0.0255\n",
      "Root Mean Square Error: 0.0451\n",
      "Mean Square Error: 0.0020\n",
      "\n",
      "Train RMSE: 0.045\n",
      "Train MSE: 0.002\n",
      "Train MAE: 0.025\n",
      "###########################\n",
      "\n",
      "MODEL:  DNN\n",
      "sequence:  3d\n",
      "units:  12\n",
      "dropout1:  0.48476373451509647\n",
      "optimizer: adamax\n",
      "activationDense: tanh\n",
      "epochs: 52\n",
      "batchsize: 57\n",
      "validation_split: 0.1\n",
      "Model: \"sequential_206\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_618 (Dense)            (None, 432, 12)           24        \n",
      "_________________________________________________________________\n",
      "dense_619 (Dense)            (None, 432, 16)           208       \n",
      "_________________________________________________________________\n",
      "dropout_206 (Dropout)        (None, 432, 16)           0         \n",
      "_________________________________________________________________\n",
      "dense_620 (Dense)            (None, 432, 1)            17        \n",
      "=================================================================\n",
      "Total params: 249\n",
      "Trainable params: 249\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/52\n",
      "57/57 [==============================] - 1s 20ms/step - loss: 0.2130 - val_loss: 0.0335\n",
      "Epoch 2/52\n",
      "57/57 [==============================] - 1s 15ms/step - loss: 0.1136 - val_loss: 0.0163\n",
      "Epoch 3/52\n",
      "57/57 [==============================] - 1s 14ms/step - loss: 0.1036 - val_loss: 0.0194\n",
      "Epoch 4/52\n",
      "57/57 [==============================] - 1s 14ms/step - loss: 0.0979 - val_loss: 0.0220\n",
      "Epoch 5/52\n",
      "57/57 [==============================] - 1s 14ms/step - loss: 0.0926 - val_loss: 0.0211\n",
      "Epoch 6/52\n",
      "57/57 [==============================] - 1s 14ms/step - loss: 0.0875 - val_loss: 0.0190\n",
      "Epoch 7/52\n",
      "57/57 [==============================] - 1s 14ms/step - loss: 0.0824 - val_loss: 0.0163\n",
      "Epoch 8/52\n",
      "57/57 [==============================] - 1s 14ms/step - loss: 0.0770 - val_loss: 0.0131\n",
      "Epoch 9/52\n",
      "57/57 [==============================] - 1s 14ms/step - loss: 0.0717 - val_loss: 0.0105\n",
      "Epoch 10/52\n",
      "57/57 [==============================] - 1s 14ms/step - loss: 0.0665 - val_loss: 0.0085\n",
      "Epoch 11/52\n",
      "57/57 [==============================] - 1s 14ms/step - loss: 0.0616 - val_loss: 0.0072\n",
      "Epoch 12/52\n",
      "57/57 [==============================] - 1s 14ms/step - loss: 0.0571 - val_loss: 0.0066\n",
      "Epoch 13/52\n",
      "57/57 [==============================] - 1s 14ms/step - loss: 0.0527 - val_loss: 0.0071\n",
      "Epoch 14/52\n",
      "57/57 [==============================] - 1s 14ms/step - loss: 0.0487 - val_loss: 0.0078\n",
      "Epoch 15/52\n",
      "57/57 [==============================] - 1s 14ms/step - loss: 0.0451 - val_loss: 0.0085\n",
      "Epoch 16/52\n",
      "57/57 [==============================] - 1s 14ms/step - loss: 0.0417 - val_loss: 0.0094\n",
      "Epoch 17/52\n",
      "57/57 [==============================] - 1s 14ms/step - loss: 0.0387 - val_loss: 0.0098\n",
      "Epoch 18/52\n",
      "57/57 [==============================] - 1s 14ms/step - loss: 0.0361 - val_loss: 0.0099\n",
      "Epoch 19/52\n",
      "57/57 [==============================] - 1s 16ms/step - loss: 0.0338 - val_loss: 0.0092\n",
      "Epoch 20/52\n",
      "57/57 [==============================] - 1s 16ms/step - loss: 0.0321 - val_loss: 0.0090\n",
      "Epoch 21/52\n",
      "57/57 [==============================] - 1s 16ms/step - loss: 0.0307 - val_loss: 0.0087\n",
      "Epoch 22/52\n",
      "57/57 [==============================] - 1s 15ms/step - loss: 0.0296 - val_loss: 0.0088\n",
      "Epoch 23/52\n",
      "57/57 [==============================] - 1s 14ms/step - loss: 0.0287 - val_loss: 0.0091\n",
      "Epoch 24/52\n",
      "57/57 [==============================] - 1s 14ms/step - loss: 0.0279 - val_loss: 0.0123\n",
      "Epoch 25/52\n",
      "57/57 [==============================] - 1s 14ms/step - loss: 0.0267 - val_loss: 0.0139\n",
      "Epoch 26/52\n",
      "57/57 [==============================] - 1s 15ms/step - loss: 0.0262 - val_loss: 0.0135\n",
      "Epoch 27/52\n",
      "57/57 [==============================] - 1s 14ms/step - loss: 0.0261 - val_loss: 0.0138\n",
      "Epoch 28/52\n",
      "57/57 [==============================] - 1s 14ms/step - loss: 0.0259 - val_loss: 0.0139\n",
      "Epoch 29/52\n",
      "57/57 [==============================] - 1s 14ms/step - loss: 0.0259 - val_loss: 0.0144\n",
      "Epoch 30/52\n",
      "57/57 [==============================] - 1s 14ms/step - loss: 0.0258 - val_loss: 0.0149\n",
      "Epoch 31/52\n",
      "57/57 [==============================] - 1s 14ms/step - loss: 0.0257 - val_loss: 0.0155\n",
      "Epoch 32/52\n",
      "57/57 [==============================] - 1s 15ms/step - loss: 0.0256 - val_loss: 0.0160\n",
      "Epoch 33/52\n",
      "57/57 [==============================] - 1s 14ms/step - loss: 0.0256 - val_loss: 0.0165\n",
      "Epoch 34/52\n",
      "57/57 [==============================] - 1s 14ms/step - loss: 0.0255 - val_loss: 0.0170\n",
      "Epoch 35/52\n",
      "57/57 [==============================] - 1s 14ms/step - loss: 0.0254 - val_loss: 0.0172\n",
      "Epoch 36/52\n",
      "57/57 [==============================] - 1s 14ms/step - loss: 0.0254 - val_loss: 0.0172\n",
      "Epoch 37/52\n",
      "57/57 [==============================] - 1s 14ms/step - loss: 0.0254 - val_loss: 0.0174\n",
      "Epoch 38/52\n",
      "57/57 [==============================] - 1s 16ms/step - loss: 0.0254 - val_loss: 0.0175\n",
      "Epoch 39/52\n",
      "57/57 [==============================] - 1s 16ms/step - loss: 0.0254 - val_loss: 0.0177\n",
      "Epoch 40/52\n",
      "57/57 [==============================] - 1s 16ms/step - loss: 0.0254 - val_loss: 0.0180\n",
      "Epoch 41/52\n",
      "57/57 [==============================] - 1s 15ms/step - loss: 0.0253 - val_loss: 0.0183\n",
      "Epoch 42/52\n",
      "57/57 [==============================] - 1s 14ms/step - loss: 0.0252 - val_loss: 0.0182\n",
      "Epoch 43/52\n",
      "57/57 [==============================] - 1s 14ms/step - loss: 0.0252 - val_loss: 0.0182\n",
      "Epoch 44/52\n",
      "57/57 [==============================] - 1s 14ms/step - loss: 0.0252 - val_loss: 0.0182\n",
      "Epoch 45/52\n",
      "57/57 [==============================] - 1s 14ms/step - loss: 0.0252 - val_loss: 0.0182\n",
      "Epoch 46/52\n",
      "57/57 [==============================] - 1s 14ms/step - loss: 0.0252 - val_loss: 0.0181\n",
      "Epoch 47/52\n",
      "57/57 [==============================] - 1s 14ms/step - loss: 0.0252 - val_loss: 0.0181\n",
      "Epoch 48/52\n",
      "57/57 [==============================] - 1s 15ms/step - loss: 0.0252 - val_loss: 0.0182\n",
      "Epoch 49/52\n",
      "57/57 [==============================] - 1s 14ms/step - loss: 0.0252 - val_loss: 0.0182\n",
      "Epoch 50/52\n",
      "57/57 [==============================] - 1s 14ms/step - loss: 0.0252 - val_loss: 0.0183\n",
      "Epoch 51/52\n",
      "57/57 [==============================] - 1s 14ms/step - loss: 0.0252 - val_loss: 0.0182\n",
      "Epoch 52/52\n",
      "57/57 [==============================] - 1s 14ms/step - loss: 0.0251 - val_loss: 0.0178\n",
      "Execution time:  45.24117851257324\n",
      "DNN:\n",
      "Mean Absolute Error: 0.0249\n",
      "Root Mean Square Error: 0.0427\n",
      "Mean Square Error: 0.0018\n",
      "\n",
      "Train RMSE: 0.043\n",
      "Train MSE: 0.002\n",
      "Train MAE: 0.025\n",
      "###########################\n",
      "\n",
      "MODEL:  DNN\n",
      "sequence:  3d\n",
      "units:  87\n",
      "dropout1:  0.40519643149940265\n",
      "optimizer: adamax\n",
      "activationDense: tanh\n",
      "epochs: 80\n",
      "batchsize: 31\n",
      "validation_split: 0.2\n",
      "Model: \"sequential_207\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_621 (Dense)            (None, 432, 87)           174       \n",
      "_________________________________________________________________\n",
      "dense_622 (Dense)            (None, 432, 16)           1408      \n",
      "_________________________________________________________________\n",
      "dropout_207 (Dropout)        (None, 432, 16)           0         \n",
      "_________________________________________________________________\n",
      "dense_623 (Dense)            (None, 432, 1)            17        \n",
      "=================================================================\n",
      "Total params: 1,599\n",
      "Trainable params: 1,599\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/80\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "92/92 [==============================] - 2s 18ms/step - loss: 0.1506 - val_loss: 0.0282\n",
      "Epoch 2/80\n",
      "92/92 [==============================] - 2s 17ms/step - loss: 0.0960 - val_loss: 0.0213\n",
      "Epoch 3/80\n",
      "92/92 [==============================] - 2s 17ms/step - loss: 0.0828 - val_loss: 0.0236\n",
      "Epoch 4/80\n",
      "92/92 [==============================] - 1s 16ms/step - loss: 0.0749 - val_loss: 0.0200\n",
      "Epoch 5/80\n",
      "92/92 [==============================] - 1s 16ms/step - loss: 0.0701 - val_loss: 0.0191\n",
      "Epoch 6/80\n",
      "92/92 [==============================] - 1s 16ms/step - loss: 0.0660 - val_loss: 0.0157\n",
      "Epoch 7/80\n",
      "92/92 [==============================] - 1s 16ms/step - loss: 0.0608 - val_loss: 0.0192\n",
      "Epoch 8/80\n",
      "92/92 [==============================] - 1s 16ms/step - loss: 0.0573 - val_loss: 0.0192\n",
      "Epoch 9/80\n",
      "92/92 [==============================] - 1s 16ms/step - loss: 0.0546 - val_loss: 0.0189\n",
      "Epoch 10/80\n",
      "92/92 [==============================] - 1s 16ms/step - loss: 0.0520 - val_loss: 0.0186\n",
      "Epoch 11/80\n",
      "92/92 [==============================] - 1s 16ms/step - loss: 0.0498 - val_loss: 0.0181\n",
      "Epoch 12/80\n",
      "92/92 [==============================] - 1s 16ms/step - loss: 0.0476 - val_loss: 0.0184\n",
      "Epoch 13/80\n",
      "92/92 [==============================] - 2s 17ms/step - loss: 0.0458 - val_loss: 0.0172\n",
      "Epoch 14/80\n",
      "92/92 [==============================] - 2s 17ms/step - loss: 0.0442 - val_loss: 0.0165\n",
      "Epoch 15/80\n",
      "92/92 [==============================] - 1s 16ms/step - loss: 0.0427 - val_loss: 0.0150\n",
      "Epoch 16/80\n",
      "92/92 [==============================] - 1s 16ms/step - loss: 0.0412 - val_loss: 0.0138\n",
      "Epoch 17/80\n",
      "92/92 [==============================] - 1s 16ms/step - loss: 0.0397 - val_loss: 0.0130\n",
      "Epoch 18/80\n",
      "92/92 [==============================] - 1s 16ms/step - loss: 0.0383 - val_loss: 0.0126\n",
      "Epoch 19/80\n",
      "92/92 [==============================] - 1s 16ms/step - loss: 0.0370 - val_loss: 0.0123\n",
      "Epoch 20/80\n",
      "92/92 [==============================] - 1s 16ms/step - loss: 0.0359 - val_loss: 0.0120\n",
      "Epoch 21/80\n",
      "92/92 [==============================] - 1s 16ms/step - loss: 0.0348 - val_loss: 0.0118\n",
      "Epoch 22/80\n",
      "92/92 [==============================] - 1s 16ms/step - loss: 0.0338 - val_loss: 0.0116\n",
      "Epoch 23/80\n",
      "92/92 [==============================] - 2s 17ms/step - loss: 0.0331 - val_loss: 0.0115\n",
      "Epoch 24/80\n",
      "92/92 [==============================] - 2s 17ms/step - loss: 0.0325 - val_loss: 0.0113\n",
      "Epoch 25/80\n",
      "92/92 [==============================] - 2s 16ms/step - loss: 0.0315 - val_loss: 0.0110\n",
      "Epoch 26/80\n",
      "92/92 [==============================] - 1s 16ms/step - loss: 0.0305 - val_loss: 0.0109\n",
      "Epoch 27/80\n",
      "92/92 [==============================] - 1s 16ms/step - loss: 0.0298 - val_loss: 0.0109\n",
      "Epoch 28/80\n",
      "92/92 [==============================] - 1s 16ms/step - loss: 0.0292 - val_loss: 0.0115\n",
      "Epoch 29/80\n",
      "92/92 [==============================] - 1s 16ms/step - loss: 0.0289 - val_loss: 0.0118\n",
      "Epoch 30/80\n",
      "92/92 [==============================] - 1s 16ms/step - loss: 0.0288 - val_loss: 0.0121\n",
      "Epoch 31/80\n",
      "92/92 [==============================] - 1s 16ms/step - loss: 0.0287 - val_loss: 0.0123\n",
      "Epoch 32/80\n",
      "92/92 [==============================] - 1s 16ms/step - loss: 0.0286 - val_loss: 0.0125\n",
      "Epoch 33/80\n",
      "92/92 [==============================] - 1s 16ms/step - loss: 0.0285 - val_loss: 0.0127\n",
      "Epoch 34/80\n",
      "92/92 [==============================] - 2s 17ms/step - loss: 0.0283 - val_loss: 0.0133\n",
      "Epoch 35/80\n",
      "92/92 [==============================] - 2s 17ms/step - loss: 0.0280 - val_loss: 0.0135\n",
      "Epoch 36/80\n",
      "92/92 [==============================] - 1s 16ms/step - loss: 0.0279 - val_loss: 0.0139\n",
      "Epoch 37/80\n",
      "92/92 [==============================] - 1s 16ms/step - loss: 0.0278 - val_loss: 0.0139\n",
      "Epoch 38/80\n",
      "92/92 [==============================] - 1s 16ms/step - loss: 0.0278 - val_loss: 0.0140\n",
      "Epoch 39/80\n",
      "92/92 [==============================] - 1s 16ms/step - loss: 0.0277 - val_loss: 0.0140\n",
      "Epoch 40/80\n",
      "92/92 [==============================] - 1s 16ms/step - loss: 0.0277 - val_loss: 0.0140\n",
      "Epoch 41/80\n",
      "92/92 [==============================] - 1s 16ms/step - loss: 0.0277 - val_loss: 0.0139\n",
      "Epoch 42/80\n",
      "92/92 [==============================] - 1s 16ms/step - loss: 0.0277 - val_loss: 0.0140\n",
      "Epoch 43/80\n",
      "92/92 [==============================] - 1s 16ms/step - loss: 0.0277 - val_loss: 0.0140\n",
      "Epoch 44/80\n",
      "92/92 [==============================] - 2s 16ms/step - loss: 0.0277 - val_loss: 0.0140\n",
      "Epoch 45/80\n",
      "92/92 [==============================] - 2s 17ms/step - loss: 0.0277 - val_loss: 0.0140\n",
      "Epoch 46/80\n",
      "92/92 [==============================] - 2s 17ms/step - loss: 0.0277 - val_loss: 0.0140\n",
      "Epoch 47/80\n",
      "92/92 [==============================] - 1s 16ms/step - loss: 0.0277 - val_loss: 0.0140\n",
      "Epoch 48/80\n",
      "92/92 [==============================] - 1s 16ms/step - loss: 0.0277 - val_loss: 0.0140\n",
      "Epoch 49/80\n",
      "92/92 [==============================] - 1s 16ms/step - loss: 0.0277 - val_loss: 0.0139\n",
      "Epoch 50/80\n",
      "92/92 [==============================] - 1s 16ms/step - loss: 0.0277 - val_loss: 0.0139\n",
      "Epoch 51/80\n",
      "92/92 [==============================] - 1s 16ms/step - loss: 0.0278 - val_loss: 0.0140\n",
      "Epoch 52/80\n",
      "92/92 [==============================] - 1s 16ms/step - loss: 0.0277 - val_loss: 0.0140\n",
      "Epoch 53/80\n",
      "92/92 [==============================] - 1s 16ms/step - loss: 0.0277 - val_loss: 0.0140\n",
      "Epoch 54/80\n",
      "92/92 [==============================] - 1s 16ms/step - loss: 0.0277 - val_loss: 0.0140\n",
      "Epoch 55/80\n",
      "92/92 [==============================] - 2s 17ms/step - loss: 0.0277 - val_loss: 0.0140\n",
      "Epoch 56/80\n",
      "92/92 [==============================] - 2s 17ms/step - loss: 0.0277 - val_loss: 0.0140\n",
      "Epoch 57/80\n",
      "92/92 [==============================] - 1s 16ms/step - loss: 0.0277 - val_loss: 0.0140\n",
      "Epoch 58/80\n",
      "92/92 [==============================] - ETA: 0s - loss: 0.026 - 1s 16ms/step - loss: 0.0277 - val_loss: 0.0140\n",
      "Epoch 59/80\n",
      "92/92 [==============================] - 1s 16ms/step - loss: 0.0277 - val_loss: 0.0140\n",
      "Epoch 60/80\n",
      "92/92 [==============================] - 1s 16ms/step - loss: 0.0277 - val_loss: 0.0139\n",
      "Epoch 61/80\n",
      "92/92 [==============================] - 1s 16ms/step - loss: 0.0277 - val_loss: 0.0139\n",
      "Epoch 62/80\n",
      "92/92 [==============================] - 1s 16ms/step - loss: 0.0278 - val_loss: 0.0140\n",
      "Epoch 63/80\n",
      "92/92 [==============================] - 1s 16ms/step - loss: 0.0277 - val_loss: 0.0140\n",
      "Epoch 64/80\n",
      "92/92 [==============================] - 1s 16ms/step - loss: 0.0277 - val_loss: 0.0140\n",
      "Epoch 65/80\n",
      "92/92 [==============================] - 1s 16ms/step - loss: 0.0277 - val_loss: 0.0140\n",
      "Epoch 66/80\n",
      "92/92 [==============================] - 2s 18ms/step - loss: 0.0277 - val_loss: 0.0140\n",
      "Epoch 67/80\n",
      "92/92 [==============================] - 2s 18ms/step - loss: 0.0277 - val_loss: 0.0140\n",
      "Epoch 68/80\n",
      "92/92 [==============================] - 2s 19ms/step - loss: 0.0277 - val_loss: 0.0140\n",
      "Epoch 69/80\n",
      "92/92 [==============================] - 2s 19ms/step - loss: 0.0277 - val_loss: 0.0140\n",
      "Epoch 70/80\n",
      "92/92 [==============================] - 2s 19ms/step - loss: 0.0277 - val_loss: 0.0139\n",
      "Epoch 71/80\n",
      "92/92 [==============================] - 2s 19ms/step - loss: 0.0278 - val_loss: 0.0140\n",
      "Epoch 72/80\n",
      "92/92 [==============================] - 2s 20ms/step - loss: 0.0277 - val_loss: 0.0140\n",
      "Epoch 73/80\n",
      "92/92 [==============================] - 2s 19ms/step - loss: 0.0277 - val_loss: 0.0140\n",
      "Epoch 74/80\n",
      "92/92 [==============================] - 2s 18ms/step - loss: 0.0280 - val_loss: 0.0134\n",
      "Epoch 75/80\n",
      "92/92 [==============================] - 2s 19ms/step - loss: 0.0278 - val_loss: 0.0140\n",
      "Epoch 76/80\n",
      "92/92 [==============================] - 2s 18ms/step - loss: 0.0277 - val_loss: 0.0140\n",
      "Epoch 77/80\n",
      "92/92 [==============================] - 2s 18ms/step - loss: 0.0277 - val_loss: 0.0140\n",
      "Epoch 78/80\n",
      "92/92 [==============================] - 2s 17ms/step - loss: 0.0277 - val_loss: 0.0140\n",
      "Epoch 79/80\n",
      "92/92 [==============================] - 2s 17ms/step - loss: 0.0277 - val_loss: 0.0140\n",
      "Epoch 80/80\n",
      "92/92 [==============================] - 2s 17ms/step - loss: 0.0277 - val_loss: 0.0140 - loss: 0.02 - ETA: 0s - loss: 0.0\n",
      "Execution time:  124.60525321960449\n",
      "DNN:\n",
      "Mean Absolute Error: 0.0252\n",
      "Root Mean Square Error: 0.0436\n",
      "Mean Square Error: 0.0019\n",
      "\n",
      "Train RMSE: 0.044\n",
      "Train MSE: 0.002\n",
      "Train MAE: 0.025\n",
      "###########################\n",
      "\n",
      "MODEL:  DNN\n",
      "sequence:  3d\n",
      "units:  80\n",
      "dropout1:  0.11814836227952394\n",
      "optimizer: adamax\n",
      "activationDense: tanh\n",
      "epochs: 90\n",
      "batchsize: 25\n",
      "validation_split: 0.2\n",
      "Model: \"sequential_208\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_624 (Dense)            (None, 432, 80)           160       \n",
      "_________________________________________________________________\n",
      "dense_625 (Dense)            (None, 432, 16)           1296      \n",
      "_________________________________________________________________\n",
      "dropout_208 (Dropout)        (None, 432, 16)           0         \n",
      "_________________________________________________________________\n",
      "dense_626 (Dense)            (None, 432, 1)            17        \n",
      "=================================================================\n",
      "Total params: 1,473\n",
      "Trainable params: 1,473\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/90\n",
      "114/114 [==============================] - 2s 17ms/step - loss: 0.1516 - val_loss: 0.0361\n",
      "Epoch 2/90\n",
      "114/114 [==============================] - 2s 13ms/step - loss: 0.0598 - val_loss: 0.0322\n",
      "Epoch 3/90\n",
      "114/114 [==============================] - 1s 13ms/step - loss: 0.0582 - val_loss: 0.0337\n",
      "Epoch 4/90\n",
      "114/114 [==============================] - 2s 13ms/step - loss: 0.0572 - val_loss: 0.0308\n",
      "Epoch 5/90\n",
      "114/114 [==============================] - 1s 13ms/step - loss: 0.0556 - val_loss: 0.0310\n",
      "Epoch 6/90\n",
      "114/114 [==============================] - 1s 12ms/step - loss: 0.0547 - val_loss: 0.0290\n",
      "Epoch 7/90\n",
      "114/114 [==============================] - 1s 12ms/step - loss: 0.0532 - val_loss: 0.0273\n",
      "Epoch 8/90\n",
      "114/114 [==============================] - 1s 12ms/step - loss: 0.0517 - val_loss: 0.0246\n",
      "Epoch 9/90\n",
      "114/114 [==============================] - 1s 13ms/step - loss: 0.0503 - val_loss: 0.0249\n",
      "Epoch 10/90\n",
      "114/114 [==============================] - 1s 12ms/step - loss: 0.0495 - val_loss: 0.0220\n",
      "Epoch 11/90\n",
      "114/114 [==============================] - 1s 13ms/step - loss: 0.0481 - val_loss: 0.0198\n",
      "Epoch 12/90\n",
      "114/114 [==============================] - 1s 13ms/step - loss: 0.0469 - val_loss: 0.0180\n",
      "Epoch 13/90\n",
      "114/114 [==============================] - 1s 12ms/step - loss: 0.0455 - val_loss: 0.0156\n",
      "Epoch 14/90\n",
      "114/114 [==============================] - 1s 13ms/step - loss: 0.0440 - val_loss: 0.0145\n",
      "Epoch 15/90\n",
      "114/114 [==============================] - 2s 13ms/step - loss: 0.0428 - val_loss: 0.0134\n",
      "Epoch 16/90\n",
      "114/114 [==============================] - 1s 13ms/step - loss: 0.0415 - val_loss: 0.0127\n",
      "Epoch 17/90\n",
      "114/114 [==============================] - 1s 13ms/step - loss: 0.0404 - val_loss: 0.0123\n",
      "Epoch 18/90\n",
      "114/114 [==============================] - 1s 12ms/step - loss: 0.0393 - val_loss: 0.0122\n",
      "Epoch 19/90\n",
      "114/114 [==============================] - 1s 12ms/step - loss: 0.0382 - val_loss: 0.0120\n",
      "Epoch 20/90\n",
      "114/114 [==============================] - 1s 12ms/step - loss: 0.0372 - val_loss: 0.0119\n",
      "Epoch 21/90\n",
      "114/114 [==============================] - 1s 13ms/step - loss: 0.0362 - val_loss: 0.0120\n",
      "Epoch 22/90\n",
      "114/114 [==============================] - 1s 12ms/step - loss: 0.0354 - val_loss: 0.0118\n",
      "Epoch 23/90\n",
      "114/114 [==============================] - 1s 12ms/step - loss: 0.0346 - val_loss: 0.0117\n",
      "Epoch 24/90\n",
      "114/114 [==============================] - 1s 13ms/step - loss: 0.0338 - val_loss: 0.0116\n",
      "Epoch 25/90\n",
      "114/114 [==============================] - 1s 13ms/step - loss: 0.0331 - val_loss: 0.0114\n",
      "Epoch 26/90\n",
      "114/114 [==============================] - 2s 14ms/step - loss: 0.0324 - val_loss: 0.0113\n",
      "Epoch 27/90\n",
      "114/114 [==============================] - 1s 13ms/step - loss: 0.0319 - val_loss: 0.0111\n",
      "Epoch 28/90\n",
      "114/114 [==============================] - 1s 12ms/step - loss: 0.0314 - val_loss: 0.0110\n",
      "Epoch 29/90\n",
      "114/114 [==============================] - 1s 12ms/step - loss: 0.0309 - val_loss: 0.0109\n",
      "Epoch 30/90\n",
      "114/114 [==============================] - 1s 13ms/step - loss: 0.0305 - val_loss: 0.0109\n",
      "Epoch 31/90\n",
      "114/114 [==============================] - 1s 13ms/step - loss: 0.0302 - val_loss: 0.0109\n",
      "Epoch 32/90\n",
      "114/114 [==============================] - 1s 13ms/step - loss: 0.0307 - val_loss: 0.0110\n",
      "Epoch 33/90\n",
      "114/114 [==============================] - 1s 13ms/step - loss: 0.0303 - val_loss: 0.0109\n",
      "Epoch 34/90\n",
      "114/114 [==============================] - 1s 12ms/step - loss: 0.0301 - val_loss: 0.0109\n",
      "Epoch 35/90\n",
      "114/114 [==============================] - 1s 12ms/step - loss: 0.0299 - val_loss: 0.0109\n",
      "Epoch 36/90\n",
      "114/114 [==============================] - 2s 13ms/step - loss: 0.0297 - val_loss: 0.0109\n",
      "Epoch 37/90\n",
      "114/114 [==============================] - 2s 13ms/step - loss: 0.0295 - val_loss: 0.0109\n",
      "Epoch 38/90\n",
      "114/114 [==============================] - 1s 13ms/step - loss: 0.0294 - val_loss: 0.0109\n",
      "Epoch 39/90\n",
      "114/114 [==============================] - 1s 12ms/step - loss: 0.0293 - val_loss: 0.0109\n",
      "Epoch 40/90\n",
      "114/114 [==============================] - 1s 13ms/step - loss: 0.0292 - val_loss: 0.0109\n",
      "Epoch 41/90\n",
      "114/114 [==============================] - 1s 12ms/step - loss: 0.0290 - val_loss: 0.0109\n",
      "Epoch 42/90\n",
      "114/114 [==============================] - 1s 13ms/step - loss: 0.0295 - val_loss: 0.0122\n",
      "Epoch 43/90\n",
      "114/114 [==============================] - 1s 13ms/step - loss: 0.0286 - val_loss: 0.0112\n",
      "Epoch 44/90\n",
      "114/114 [==============================] - 1s 13ms/step - loss: 0.0287 - val_loss: 0.0115\n",
      "Epoch 45/90\n",
      "114/114 [==============================] - 1s 13ms/step - loss: 0.0286 - val_loss: 0.0127\n",
      "Epoch 46/90\n",
      "114/114 [==============================] - 1s 13ms/step - loss: 0.0282 - val_loss: 0.0127\n",
      "Epoch 47/90\n",
      "114/114 [==============================] - 2s 13ms/step - loss: 0.0281 - val_loss: 0.0128\n",
      "Epoch 48/90\n",
      "114/114 [==============================] - 2s 13ms/step - loss: 0.0280 - val_loss: 0.0128\n",
      "Epoch 49/90\n",
      "114/114 [==============================] - 1s 13ms/step - loss: 0.0280 - val_loss: 0.0128\n",
      "Epoch 50/90\n",
      "114/114 [==============================] - 1s 13ms/step - loss: 0.0280 - val_loss: 0.0128\n",
      "Epoch 51/90\n",
      "114/114 [==============================] - 1s 13ms/step - loss: 0.0280 - val_loss: 0.0128\n",
      "Epoch 52/90\n",
      "114/114 [==============================] - 1s 12ms/step - loss: 0.0280 - val_loss: 0.0128\n",
      "Epoch 53/90\n",
      "114/114 [==============================] - 1s 13ms/step - loss: 0.0280 - val_loss: 0.0128\n",
      "Epoch 54/90\n",
      "114/114 [==============================] - 1s 12ms/step - loss: 0.0280 - val_loss: 0.0128\n",
      "Epoch 55/90\n",
      "114/114 [==============================] - 1s 13ms/step - loss: 0.0280 - val_loss: 0.0128\n",
      "Epoch 56/90\n",
      "114/114 [==============================] - 1s 12ms/step - loss: 0.0280 - val_loss: 0.0128\n",
      "Epoch 57/90\n",
      "114/114 [==============================] - 1s 12ms/step - loss: 0.0280 - val_loss: 0.0128\n",
      "Epoch 58/90\n",
      "114/114 [==============================] - 2s 13ms/step - loss: 0.0280 - val_loss: 0.0128\n",
      "Epoch 59/90\n",
      "114/114 [==============================] - 2s 13ms/step - loss: 0.0280 - val_loss: 0.0129\n",
      "Epoch 60/90\n",
      "114/114 [==============================] - 1s 13ms/step - loss: 0.0281 - val_loss: 0.0131\n",
      "Epoch 61/90\n",
      "114/114 [==============================] - 1s 12ms/step - loss: 0.0280 - val_loss: 0.0130\n",
      "Epoch 62/90\n",
      "114/114 [==============================] - 1s 12ms/step - loss: 0.0280 - val_loss: 0.0130\n",
      "Epoch 63/90\n",
      "114/114 [==============================] - 1s 13ms/step - loss: 0.0280 - val_loss: 0.0129\n",
      "Epoch 64/90\n",
      "114/114 [==============================] - 1s 13ms/step - loss: 0.0281 - val_loss: 0.0131\n",
      "Epoch 65/90\n",
      "114/114 [==============================] - 1s 13ms/step - loss: 0.0280 - val_loss: 0.0130\n",
      "Epoch 66/90\n",
      "114/114 [==============================] - 1s 13ms/step - loss: 0.0280 - val_loss: 0.0130\n",
      "Epoch 67/90\n",
      "114/114 [==============================] - 1s 12ms/step - loss: 0.0280 - val_loss: 0.0129\n",
      "Epoch 68/90\n",
      "114/114 [==============================] - 1s 13ms/step - loss: 0.0281 - val_loss: 0.0131\n",
      "Epoch 69/90\n",
      "114/114 [==============================] - 2s 13ms/step - loss: 0.0280 - val_loss: 0.0130\n",
      "Epoch 70/90\n",
      "114/114 [==============================] - 2s 13ms/step - loss: 0.0280 - val_loss: 0.0130\n",
      "Epoch 71/90\n",
      "114/114 [==============================] - 1s 13ms/step - loss: 0.0280 - val_loss: 0.0129\n",
      "Epoch 72/90\n",
      "114/114 [==============================] - 1s 12ms/step - loss: 0.0281 - val_loss: 0.0131\n",
      "Epoch 73/90\n",
      "114/114 [==============================] - 1s 13ms/step - loss: 0.0280 - val_loss: 0.0130\n",
      "Epoch 74/90\n",
      "114/114 [==============================] - 1s 13ms/step - loss: 0.0280 - val_loss: 0.0130\n",
      "Epoch 75/90\n",
      "114/114 [==============================] - 1s 13ms/step - loss: 0.0280 - val_loss: 0.0129\n",
      "Epoch 76/90\n",
      "114/114 [==============================] - 1s 13ms/step - loss: 0.0281 - val_loss: 0.0131\n",
      "Epoch 77/90\n",
      "114/114 [==============================] - 1s 13ms/step - loss: 0.0280 - val_loss: 0.0130\n",
      "Epoch 78/90\n",
      "114/114 [==============================] - 1s 13ms/step - loss: 0.0280 - val_loss: 0.0130\n",
      "Epoch 79/90\n",
      "114/114 [==============================] - 1s 13ms/step - loss: 0.0280 - val_loss: 0.0129\n",
      "Epoch 80/90\n",
      "114/114 [==============================] - 2s 13ms/step - loss: 0.0281 - val_loss: 0.0131\n",
      "Epoch 81/90\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "114/114 [==============================] - 1s 13ms/step - loss: 0.0280 - val_loss: 0.0130\n",
      "Epoch 82/90\n",
      "114/114 [==============================] - 1s 12ms/step - loss: 0.0280 - val_loss: 0.0130\n",
      "Epoch 83/90\n",
      "114/114 [==============================] - 1s 12ms/step - loss: 0.0280 - val_loss: 0.0129\n",
      "Epoch 84/90\n",
      "114/114 [==============================] - 1s 12ms/step - loss: 0.0281 - val_loss: 0.0131\n",
      "Epoch 85/90\n",
      "114/114 [==============================] - 1s 12ms/step - loss: 0.0280 - val_loss: 0.0130\n",
      "Epoch 86/90\n",
      "114/114 [==============================] - 1s 12ms/step - loss: 0.0280 - val_loss: 0.0130\n",
      "Epoch 87/90\n",
      "114/114 [==============================] - 1s 12ms/step - loss: 0.0280 - val_loss: 0.0129\n",
      "Epoch 88/90\n",
      "114/114 [==============================] - 1s 12ms/step - loss: 0.0281 - val_loss: 0.0130\n",
      "Epoch 89/90\n",
      "114/114 [==============================] - 1s 12ms/step - loss: 0.0280 - val_loss: 0.0130\n",
      "Epoch 90/90\n",
      "114/114 [==============================] - 1s 12ms/step - loss: 0.0280 - val_loss: 0.0130\n",
      "Execution time:  133.23346638679504\n",
      "DNN:\n",
      "Mean Absolute Error: 0.0253\n",
      "Root Mean Square Error: 0.0445\n",
      "Mean Square Error: 0.0020\n",
      "\n",
      "Train RMSE: 0.045\n",
      "Train MSE: 0.002\n",
      "Train MAE: 0.025\n",
      "###########################\n",
      "\n",
      "MODEL:  DNN\n",
      "sequence:  3d\n",
      "units:  12\n",
      "dropout1:  0.48476373451509647\n",
      "optimizer: adamax\n",
      "activationDense: tanh\n",
      "epochs: 52\n",
      "batchsize: 57\n",
      "validation_split: 0.2\n",
      "Model: \"sequential_209\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_627 (Dense)            (None, 432, 12)           24        \n",
      "_________________________________________________________________\n",
      "dense_628 (Dense)            (None, 432, 16)           208       \n",
      "_________________________________________________________________\n",
      "dropout_209 (Dropout)        (None, 432, 16)           0         \n",
      "_________________________________________________________________\n",
      "dense_629 (Dense)            (None, 432, 1)            17        \n",
      "=================================================================\n",
      "Total params: 249\n",
      "Trainable params: 249\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/52\n",
      "50/50 [==============================] - 1s 20ms/step - loss: 0.1816 - val_loss: 0.0198\n",
      "Epoch 2/52\n",
      "50/50 [==============================] - 1s 15ms/step - loss: 0.1212 - val_loss: 0.0174\n",
      "Epoch 3/52\n",
      "50/50 [==============================] - 1s 15ms/step - loss: 0.1084 - val_loss: 0.0208\n",
      "Epoch 4/52\n",
      "50/50 [==============================] - 1s 15ms/step - loss: 0.1011 - val_loss: 0.0192\n",
      "Epoch 5/52\n",
      "50/50 [==============================] - 1s 15ms/step - loss: 0.0953 - val_loss: 0.0168\n",
      "Epoch 6/52\n",
      "50/50 [==============================] - 1s 15ms/step - loss: 0.0905 - val_loss: 0.0143\n",
      "Epoch 7/52\n",
      "50/50 [==============================] - 1s 15ms/step - loss: 0.0862 - val_loss: 0.0134\n",
      "Epoch 8/52\n",
      "50/50 [==============================] - 1s 15ms/step - loss: 0.0819 - val_loss: 0.0129\n",
      "Epoch 9/52\n",
      "50/50 [==============================] - 1s 15ms/step - loss: 0.0777 - val_loss: 0.0127\n",
      "Epoch 10/52\n",
      "50/50 [==============================] - 1s 15ms/step - loss: 0.0734 - val_loss: 0.0125\n",
      "Epoch 11/52\n",
      "50/50 [==============================] - 1s 15ms/step - loss: 0.0691 - val_loss: 0.0124\n",
      "Epoch 12/52\n",
      "50/50 [==============================] - 1s 15ms/step - loss: 0.0650 - val_loss: 0.0123\n",
      "Epoch 13/52\n",
      "50/50 [==============================] - 1s 15ms/step - loss: 0.0612 - val_loss: 0.0122\n",
      "Epoch 14/52\n",
      "50/50 [==============================] - 1s 15ms/step - loss: 0.0575 - val_loss: 0.0120\n",
      "Epoch 15/52\n",
      "50/50 [==============================] - 1s 15ms/step - loss: 0.0537 - val_loss: 0.0114\n",
      "Epoch 16/52\n",
      "50/50 [==============================] - 1s 15ms/step - loss: 0.0498 - val_loss: 0.0115\n",
      "Epoch 17/52\n",
      "50/50 [==============================] - 1s 15ms/step - loss: 0.0469 - val_loss: 0.0119\n",
      "Epoch 18/52\n",
      "50/50 [==============================] - 1s 15ms/step - loss: 0.0444 - val_loss: 0.0122\n",
      "Epoch 19/52\n",
      "50/50 [==============================] - 1s 15ms/step - loss: 0.0422 - val_loss: 0.0122\n",
      "Epoch 20/52\n",
      "50/50 [==============================] - 1s 16ms/step - loss: 0.0403 - val_loss: 0.0121\n",
      "Epoch 21/52\n",
      "50/50 [==============================] - 1s 16ms/step - loss: 0.0386 - val_loss: 0.0117\n",
      "Epoch 22/52\n",
      "50/50 [==============================] - 1s 16ms/step - loss: 0.0372 - val_loss: 0.0116\n",
      "Epoch 23/52\n",
      "50/50 [==============================] - 1s 15ms/step - loss: 0.0358 - val_loss: 0.0114\n",
      "Epoch 24/52\n",
      "50/50 [==============================] - 1s 15ms/step - loss: 0.0347 - val_loss: 0.0113\n",
      "Epoch 25/52\n",
      "50/50 [==============================] - 1s 15ms/step - loss: 0.0338 - val_loss: 0.0112\n",
      "Epoch 26/52\n",
      "50/50 [==============================] - 1s 15ms/step - loss: 0.0330 - val_loss: 0.0112\n",
      "Epoch 27/52\n",
      "50/50 [==============================] - 1s 15ms/step - loss: 0.0322 - val_loss: 0.0113\n",
      "Epoch 28/52\n",
      "50/50 [==============================] - 1s 15ms/step - loss: 0.0315 - val_loss: 0.0112\n",
      "Epoch 29/52\n",
      "50/50 [==============================] - 1s 15ms/step - loss: 0.0311 - val_loss: 0.0112\n",
      "Epoch 30/52\n",
      "50/50 [==============================] - 1s 15ms/step - loss: 0.0306 - val_loss: 0.0130\n",
      "Epoch 31/52\n",
      "50/50 [==============================] - 1s 15ms/step - loss: 0.0296 - val_loss: 0.0130\n",
      "Epoch 32/52\n",
      "50/50 [==============================] - 1s 15ms/step - loss: 0.0293 - val_loss: 0.0128\n",
      "Epoch 33/52\n",
      "50/50 [==============================] - 1s 15ms/step - loss: 0.0292 - val_loss: 0.0134\n",
      "Epoch 34/52\n",
      "50/50 [==============================] - 1s 15ms/step - loss: 0.0289 - val_loss: 0.0134\n",
      "Epoch 35/52\n",
      "50/50 [==============================] - 1s 15ms/step - loss: 0.0285 - val_loss: 0.0134\n",
      "Epoch 36/52\n",
      "50/50 [==============================] - 1s 15ms/step - loss: 0.0283 - val_loss: 0.0139\n",
      "Epoch 37/52\n",
      "50/50 [==============================] - 1s 15ms/step - loss: 0.0280 - val_loss: 0.0141\n",
      "Epoch 38/52\n",
      "50/50 [==============================] - 1s 15ms/step - loss: 0.0278 - val_loss: 0.0140\n",
      "Epoch 39/52\n",
      "50/50 [==============================] - 1s 15ms/step - loss: 0.0276 - val_loss: 0.0142\n",
      "Epoch 40/52\n",
      "50/50 [==============================] - 1s 16ms/step - loss: 0.0274 - val_loss: 0.0142\n",
      "Epoch 41/52\n",
      "50/50 [==============================] - 1s 16ms/step - loss: 0.0274 - val_loss: 0.0146\n",
      "Epoch 42/52\n",
      "50/50 [==============================] - 1s 16ms/step - loss: 0.0273 - val_loss: 0.0147\n",
      "Epoch 43/52\n",
      "50/50 [==============================] - 1s 16ms/step - loss: 0.0272 - val_loss: 0.0149\n",
      "Epoch 44/52\n",
      "50/50 [==============================] - 1s 15ms/step - loss: 0.0271 - val_loss: 0.0148\n",
      "Epoch 45/52\n",
      "50/50 [==============================] - 1s 15ms/step - loss: 0.0271 - val_loss: 0.0148\n",
      "Epoch 46/52\n",
      "50/50 [==============================] - 1s 15ms/step - loss: 0.0270 - val_loss: 0.0148\n",
      "Epoch 47/52\n",
      "50/50 [==============================] - 1s 15ms/step - loss: 0.0270 - val_loss: 0.0149\n",
      "Epoch 48/52\n",
      "50/50 [==============================] - 1s 15ms/step - loss: 0.0269 - val_loss: 0.0149\n",
      "Epoch 49/52\n",
      "50/50 [==============================] - 1s 15ms/step - loss: 0.0270 - val_loss: 0.0150\n",
      "Epoch 50/52\n",
      "50/50 [==============================] - 1s 15ms/step - loss: 0.0269 - val_loss: 0.0150\n",
      "Epoch 51/52\n",
      "50/50 [==============================] - 1s 15ms/step - loss: 0.0269 - val_loss: 0.0150\n",
      "Epoch 52/52\n",
      "50/50 [==============================] - 1s 15ms/step - loss: 0.0269 - val_loss: 0.0151\n",
      "Execution time:  41.195196866989136\n",
      "DNN:\n",
      "Mean Absolute Error: 0.0250\n",
      "Root Mean Square Error: 0.0426\n",
      "Mean Square Error: 0.0018\n",
      "\n",
      "Train RMSE: 0.043\n",
      "Train MSE: 0.002\n",
      "Train MAE: 0.025\n",
      "###########################\n",
      "\n",
      "MODEL:  DNN\n",
      "sequence:  3d\n",
      "units:  87\n",
      "dropout1:  0.40519643149940265\n",
      "optimizer: adamax\n",
      "activationDense: sigmoid\n",
      "epochs: 80\n",
      "batchsize: 31\n",
      "validation_split: 0.1\n",
      "Model: \"sequential_210\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_630 (Dense)            (None, 432, 87)           174       \n",
      "_________________________________________________________________\n",
      "dense_631 (Dense)            (None, 432, 16)           1408      \n",
      "_________________________________________________________________\n",
      "dropout_210 (Dropout)        (None, 432, 16)           0         \n",
      "_________________________________________________________________\n",
      "dense_632 (Dense)            (None, 432, 1)            17        \n",
      "=================================================================\n",
      "Total params: 1,599\n",
      "Trainable params: 1,599\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/80\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "104/104 [==============================] - 2s 20ms/step - loss: 0.0496 - val_loss: 0.0320\n",
      "Epoch 2/80\n",
      "104/104 [==============================] - 2s 15ms/step - loss: 0.0401 - val_loss: 0.0247\n",
      "Epoch 3/80\n",
      "104/104 [==============================] - 2s 15ms/step - loss: 0.0380 - val_loss: 0.0214\n",
      "Epoch 4/80\n",
      "104/104 [==============================] - 2s 16ms/step - loss: 0.0368 - val_loss: 0.0209\n",
      "Epoch 5/80\n",
      "104/104 [==============================] - 2s 16ms/step - loss: 0.0355 - val_loss: 0.0189\n",
      "Epoch 6/80\n",
      "104/104 [==============================] - 2s 15ms/step - loss: 0.0351 - val_loss: 0.0187\n",
      "Epoch 7/80\n",
      "104/104 [==============================] - 2s 15ms/step - loss: 0.0346 - val_loss: 0.0185\n",
      "Epoch 8/80\n",
      "104/104 [==============================] - 2s 15ms/step - loss: 0.0340 - val_loss: 0.0182\n",
      "Epoch 9/80\n",
      "104/104 [==============================] - 2s 15ms/step - loss: 0.0335 - val_loss: 0.0178\n",
      "Epoch 10/80\n",
      "104/104 [==============================] - 2s 15ms/step - loss: 0.0330 - val_loss: 0.0176\n",
      "Epoch 11/80\n",
      "104/104 [==============================] - 2s 15ms/step - loss: 0.0325 - val_loss: 0.0175\n",
      "Epoch 12/80\n",
      "104/104 [==============================] - 2s 15ms/step - loss: 0.0321 - val_loss: 0.0173\n",
      "Epoch 13/80\n",
      "104/104 [==============================] - 2s 15ms/step - loss: 0.0316 - val_loss: 0.0172\n",
      "Epoch 14/80\n",
      "104/104 [==============================] - 2s 16ms/step - loss: 0.0312 - val_loss: 0.0171\n",
      "Epoch 15/80\n",
      "104/104 [==============================] - 2s 16ms/step - loss: 0.0308 - val_loss: 0.0169\n",
      "Epoch 16/80\n",
      "104/104 [==============================] - 2s 15ms/step - loss: 0.0304 - val_loss: 0.0167\n",
      "Epoch 17/80\n",
      "104/104 [==============================] - 2s 15ms/step - loss: 0.0300 - val_loss: 0.0166\n",
      "Epoch 18/80\n",
      "104/104 [==============================] - 2s 16ms/step - loss: 0.0297 - val_loss: 0.0163\n",
      "Epoch 19/80\n",
      "104/104 [==============================] - 2s 15ms/step - loss: 0.0293 - val_loss: 0.0162\n",
      "Epoch 20/80\n",
      "104/104 [==============================] - 2s 15ms/step - loss: 0.0290 - val_loss: 0.0160\n",
      "Epoch 21/80\n",
      "104/104 [==============================] - 2s 15ms/step - loss: 0.0287 - val_loss: 0.0160\n",
      "Epoch 22/80\n",
      "104/104 [==============================] - 2s 15ms/step - loss: 0.0285 - val_loss: 0.0158\n",
      "Epoch 23/80\n",
      "104/104 [==============================] - 2s 16ms/step - loss: 0.0282 - val_loss: 0.0156\n",
      "Epoch 24/80\n",
      "104/104 [==============================] - 2s 16ms/step - loss: 0.0280 - val_loss: 0.0154\n",
      "Epoch 25/80\n",
      "104/104 [==============================] - 2s 15ms/step - loss: 0.0278 - val_loss: 0.0154\n",
      "Epoch 26/80\n",
      "104/104 [==============================] - 2s 15ms/step - loss: 0.0276 - val_loss: 0.0154\n",
      "Epoch 27/80\n",
      "104/104 [==============================] - 2s 16ms/step - loss: 0.0274 - val_loss: 0.0154\n",
      "Epoch 28/80\n",
      "104/104 [==============================] - 2s 15ms/step - loss: 0.0272 - val_loss: 0.0151\n",
      "Epoch 29/80\n",
      "104/104 [==============================] - 2s 15ms/step - loss: 0.0271 - val_loss: 0.0153\n",
      "Epoch 30/80\n",
      "104/104 [==============================] - 2s 15ms/step - loss: 0.0270 - val_loss: 0.0153\n",
      "Epoch 31/80\n",
      "104/104 [==============================] - 2s 15ms/step - loss: 0.0268 - val_loss: 0.0153\n",
      "Epoch 32/80\n",
      "104/104 [==============================] - 2s 15ms/step - loss: 0.0267 - val_loss: 0.0152\n",
      "Epoch 33/80\n",
      "104/104 [==============================] - 2s 16ms/step - loss: 0.0266 - val_loss: 0.0152\n",
      "Epoch 34/80\n",
      "104/104 [==============================] - 2s 16ms/step - loss: 0.0265 - val_loss: 0.0152\n",
      "Epoch 35/80\n",
      "104/104 [==============================] - 2s 15ms/step - loss: 0.0265 - val_loss: 0.0151\n",
      "Epoch 36/80\n",
      "104/104 [==============================] - 2s 15ms/step - loss: 0.0264 - val_loss: 0.0153\n",
      "Epoch 37/80\n",
      "104/104 [==============================] - 2s 15ms/step - loss: 0.0263 - val_loss: 0.0152\n",
      "Epoch 38/80\n",
      "104/104 [==============================] - ETA: 0s - loss: 0.0263- ETA: 0s - - 2s 15ms/step - loss: 0.0263 - val_loss: 0.0154\n",
      "Epoch 39/80\n",
      "104/104 [==============================] - 2s 15ms/step - loss: 0.0262 - val_loss: 0.0154\n",
      "Epoch 40/80\n",
      "104/104 [==============================] - 2s 15ms/step - loss: 0.0261 - val_loss: 0.0154\n",
      "Epoch 41/80\n",
      "104/104 [==============================] - 2s 15ms/step - loss: 0.0261 - val_loss: 0.0154\n",
      "Epoch 42/80\n",
      "104/104 [==============================] - 2s 16ms/step - loss: 0.0260 - val_loss: 0.0156\n",
      "Epoch 43/80\n",
      "104/104 [==============================] - 2s 17ms/step - loss: 0.0259 - val_loss: 0.0155\n",
      "Epoch 44/80\n",
      "104/104 [==============================] - 2s 16ms/step - loss: 0.0259 - val_loss: 0.0157\n",
      "Epoch 45/80\n",
      "104/104 [==============================] - 2s 16ms/step - loss: 0.0258 - val_loss: 0.0156\n",
      "Epoch 46/80\n",
      "104/104 [==============================] - 2s 15ms/step - loss: 0.0258 - val_loss: 0.0158\n",
      "Epoch 47/80\n",
      "104/104 [==============================] - 2s 15ms/step - loss: 0.0258 - val_loss: 0.0157\n",
      "Epoch 48/80\n",
      "104/104 [==============================] - 2s 15ms/step - loss: 0.0257 - val_loss: 0.0159\n",
      "Epoch 49/80\n",
      "104/104 [==============================] - 2s 15ms/step - loss: 0.0257 - val_loss: 0.0158\n",
      "Epoch 50/80\n",
      "104/104 [==============================] - 2s 16ms/step - loss: 0.0256 - val_loss: 0.0159\n",
      "Epoch 51/80\n",
      "104/104 [==============================] - 2s 15ms/step - loss: 0.0256 - val_loss: 0.0160\n",
      "Epoch 52/80\n",
      "104/104 [==============================] - 2s 16ms/step - loss: 0.0256 - val_loss: 0.0161\n",
      "Epoch 53/80\n",
      "104/104 [==============================] - 2s 17ms/step - loss: 0.0256 - val_loss: 0.0162\n",
      "Epoch 54/80\n",
      "104/104 [==============================] - 2s 15ms/step - loss: 0.0255 - val_loss: 0.0163\n",
      "Epoch 55/80\n",
      "104/104 [==============================] - 2s 15ms/step - loss: 0.0255 - val_loss: 0.0164\n",
      "Epoch 56/80\n",
      "104/104 [==============================] - 2s 15ms/step - loss: 0.0255 - val_loss: 0.0165\n",
      "Epoch 57/80\n",
      "104/104 [==============================] - 2s 15ms/step - loss: 0.0254 - val_loss: 0.0166\n",
      "Epoch 58/80\n",
      "104/104 [==============================] - 2s 15ms/step - loss: 0.0254 - val_loss: 0.0167\n",
      "Epoch 59/80\n",
      "104/104 [==============================] - 2s 15ms/step - loss: 0.0253 - val_loss: 0.0168\n",
      "Epoch 60/80\n",
      "104/104 [==============================] - 2s 15ms/step - loss: 0.0253 - val_loss: 0.0167\n",
      "Epoch 61/80\n",
      "104/104 [==============================] - 2s 15ms/step - loss: 0.0253 - val_loss: 0.0174\n",
      "Epoch 62/80\n",
      "104/104 [==============================] - 2s 16ms/step - loss: 0.0252 - val_loss: 0.0174\n",
      "Epoch 63/80\n",
      "104/104 [==============================] - 2s 17ms/step - loss: 0.0252 - val_loss: 0.0173\n",
      "Epoch 64/80\n",
      "104/104 [==============================] - 2s 15ms/step - loss: 0.0252 - val_loss: 0.0177\n",
      "Epoch 65/80\n",
      "104/104 [==============================] - 2s 15ms/step - loss: 0.0251 - val_loss: 0.0181\n",
      "Epoch 66/80\n",
      "104/104 [==============================] - 2s 15ms/step - loss: 0.0250 - val_loss: 0.0184\n",
      "Epoch 67/80\n",
      "104/104 [==============================] - 2s 15ms/step - loss: 0.0250 - val_loss: 0.0172\n",
      "Epoch 68/80\n",
      "104/104 [==============================] - 2s 15ms/step - loss: 0.0251 - val_loss: 0.0185\n",
      "Epoch 69/80\n",
      "104/104 [==============================] - 2s 15ms/step - loss: 0.0249 - val_loss: 0.0185\n",
      "Epoch 70/80\n",
      "104/104 [==============================] - 2s 15ms/step - loss: 0.0249 - val_loss: 0.0185\n",
      "Epoch 71/80\n",
      "104/104 [==============================] - 2s 15ms/step - loss: 0.0249 - val_loss: 0.0185\n",
      "Epoch 72/80\n",
      "104/104 [==============================] - 2s 16ms/step - loss: 0.0249 - val_loss: 0.0185\n",
      "Epoch 73/80\n",
      "104/104 [==============================] - 2s 16ms/step - loss: 0.0249 - val_loss: 0.0185\n",
      "Epoch 74/80\n",
      "104/104 [==============================] - 2s 15ms/step - loss: 0.0249 - val_loss: 0.0185\n",
      "Epoch 75/80\n",
      "104/104 [==============================] - 2s 15ms/step - loss: 0.0249 - val_loss: 0.0185\n",
      "Epoch 76/80\n",
      "104/104 [==============================] - 2s 16ms/step - loss: 0.0249 - val_loss: 0.0185\n",
      "Epoch 77/80\n",
      "104/104 [==============================] - 2s 15ms/step - loss: 0.0249 - val_loss: 0.0185\n",
      "Epoch 78/80\n",
      "104/104 [==============================] - 2s 16ms/step - loss: 0.0249 - val_loss: 0.0185\n",
      "Epoch 79/80\n",
      "104/104 [==============================] - 2s 15ms/step - loss: 0.0249 - val_loss: 0.0185\n",
      "Epoch 80/80\n",
      "104/104 [==============================] - 2s 15ms/step - loss: 0.0249 - val_loss: 0.0185\n",
      "Execution time:  131.9345142841339\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DNN:\n",
      "Mean Absolute Error: 0.0251\n",
      "Root Mean Square Error: 0.0431\n",
      "Mean Square Error: 0.0019\n",
      "\n",
      "Train RMSE: 0.043\n",
      "Train MSE: 0.002\n",
      "Train MAE: 0.025\n",
      "###########################\n",
      "\n",
      "MODEL:  DNN\n",
      "sequence:  3d\n",
      "units:  80\n",
      "dropout1:  0.11814836227952394\n",
      "optimizer: adamax\n",
      "activationDense: sigmoid\n",
      "epochs: 90\n",
      "batchsize: 25\n",
      "validation_split: 0.1\n",
      "Model: \"sequential_211\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_633 (Dense)            (None, 432, 80)           160       \n",
      "_________________________________________________________________\n",
      "dense_634 (Dense)            (None, 432, 16)           1296      \n",
      "_________________________________________________________________\n",
      "dropout_211 (Dropout)        (None, 432, 16)           0         \n",
      "_________________________________________________________________\n",
      "dense_635 (Dense)            (None, 432, 1)            17        \n",
      "=================================================================\n",
      "Total params: 1,473\n",
      "Trainable params: 1,473\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/90\n",
      "129/129 [==============================] - 2s 14ms/step - loss: 0.0414 - val_loss: 0.0225\n",
      "Epoch 2/90\n",
      "129/129 [==============================] - 2s 12ms/step - loss: 0.0338 - val_loss: 0.0230\n",
      "Epoch 3/90\n",
      "129/129 [==============================] - 2s 12ms/step - loss: 0.0334 - val_loss: 0.0224\n",
      "Epoch 4/90\n",
      "129/129 [==============================] - 2s 12ms/step - loss: 0.0331 - val_loss: 0.0216\n",
      "Epoch 5/90\n",
      "129/129 [==============================] - 2s 12ms/step - loss: 0.0328 - val_loss: 0.0212\n",
      "Epoch 6/90\n",
      "129/129 [==============================] - 2s 12ms/step - loss: 0.0325 - val_loss: 0.0208\n",
      "Epoch 7/90\n",
      "129/129 [==============================] - 2s 12ms/step - loss: 0.0319 - val_loss: 0.0209\n",
      "Epoch 8/90\n",
      "129/129 [==============================] - 2s 12ms/step - loss: 0.0316 - val_loss: 0.0206\n",
      "Epoch 9/90\n",
      "129/129 [==============================] - 2s 12ms/step - loss: 0.0314 - val_loss: 0.0203\n",
      "Epoch 10/90\n",
      "129/129 [==============================] - 2s 12ms/step - loss: 0.0311 - val_loss: 0.0197\n",
      "Epoch 11/90\n",
      "129/129 [==============================] - 2s 13ms/step - loss: 0.0309 - val_loss: 0.0178\n",
      "Epoch 12/90\n",
      "129/129 [==============================] - 2s 12ms/step - loss: 0.0307 - val_loss: 0.0177\n",
      "Epoch 13/90\n",
      "129/129 [==============================] - 2s 12ms/step - loss: 0.0304 - val_loss: 0.0176\n",
      "Epoch 14/90\n",
      "129/129 [==============================] - 2s 12ms/step - loss: 0.0300 - val_loss: 0.0177\n",
      "Epoch 15/90\n",
      "129/129 [==============================] - 2s 12ms/step - loss: 0.0298 - val_loss: 0.0158\n",
      "Epoch 16/90\n",
      "129/129 [==============================] - 2s 12ms/step - loss: 0.0296 - val_loss: 0.0160\n",
      "Epoch 17/90\n",
      "129/129 [==============================] - 2s 12ms/step - loss: 0.0293 - val_loss: 0.0159\n",
      "Epoch 18/90\n",
      "129/129 [==============================] - 2s 12ms/step - loss: 0.0291 - val_loss: 0.0162\n",
      "Epoch 19/90\n",
      "129/129 [==============================] - 2s 12ms/step - loss: 0.0289 - val_loss: 0.0161\n",
      "Epoch 20/90\n",
      "129/129 [==============================] - 2s 12ms/step - loss: 0.0287 - val_loss: 0.0145\n",
      "Epoch 21/90\n",
      "129/129 [==============================] - 2s 12ms/step - loss: 0.0286 - val_loss: 0.0148\n",
      "Epoch 22/90\n",
      "129/129 [==============================] - 2s 13ms/step - loss: 0.0284 - val_loss: 0.0147\n",
      "Epoch 23/90\n",
      "129/129 [==============================] - 2s 12ms/step - loss: 0.0281 - val_loss: 0.0147\n",
      "Epoch 24/90\n",
      "129/129 [==============================] - 2s 12ms/step - loss: 0.0280 - val_loss: 0.0146\n",
      "Epoch 25/90\n",
      "129/129 [==============================] - 2s 12ms/step - loss: 0.0279 - val_loss: 0.0148\n",
      "Epoch 26/90\n",
      "129/129 [==============================] - 2s 12ms/step - loss: 0.0277 - val_loss: 0.0148\n",
      "Epoch 27/90\n",
      "129/129 [==============================] - 2s 12ms/step - loss: 0.0276 - val_loss: 0.0149\n",
      "Epoch 28/90\n",
      "129/129 [==============================] - 2s 12ms/step - loss: 0.0274 - val_loss: 0.0150\n",
      "Epoch 29/90\n",
      "129/129 [==============================] - 2s 12ms/step - loss: 0.0273 - val_loss: 0.0150\n",
      "Epoch 30/90\n",
      "129/129 [==============================] - 2s 12ms/step - loss: 0.0271 - val_loss: 0.0149\n",
      "Epoch 31/90\n",
      "129/129 [==============================] - 2s 12ms/step - loss: 0.0273 - val_loss: 0.0147\n",
      "Epoch 32/90\n",
      "129/129 [==============================] - 2s 13ms/step - loss: 0.0269 - val_loss: 0.0143\n",
      "Epoch 33/90\n",
      "129/129 [==============================] - 2s 12ms/step - loss: 0.0268 - val_loss: 0.0144\n",
      "Epoch 34/90\n",
      "129/129 [==============================] - 2s 12ms/step - loss: 0.0267 - val_loss: 0.0146\n",
      "Epoch 35/90\n",
      "129/129 [==============================] - 2s 12ms/step - loss: 0.0267 - val_loss: 0.0147\n",
      "Epoch 36/90\n",
      "129/129 [==============================] - 2s 12ms/step - loss: 0.0266 - val_loss: 0.0148\n",
      "Epoch 37/90\n",
      "129/129 [==============================] - 2s 13ms/step - loss: 0.0264 - val_loss: 0.0138\n",
      "Epoch 38/90\n",
      "129/129 [==============================] - 2s 15ms/step - loss: 0.0265 - val_loss: 0.0150\n",
      "Epoch 39/90\n",
      "129/129 [==============================] - 2s 14ms/step - loss: 0.0264 - val_loss: 0.0157\n",
      "Epoch 40/90\n",
      "129/129 [==============================] - 2s 12ms/step - loss: 0.0262 - val_loss: 0.0158\n",
      "Epoch 41/90\n",
      "129/129 [==============================] - 2s 12ms/step - loss: 0.0262 - val_loss: 0.0158\n",
      "Epoch 42/90\n",
      "129/129 [==============================] - 2s 13ms/step - loss: 0.0261 - val_loss: 0.0159\n",
      "Epoch 43/90\n",
      "129/129 [==============================] - 2s 12ms/step - loss: 0.0261 - val_loss: 0.0160\n",
      "Epoch 44/90\n",
      "129/129 [==============================] - 2s 12ms/step - loss: 0.0260 - val_loss: 0.0152\n",
      "Epoch 45/90\n",
      "129/129 [==============================] - 2s 12ms/step - loss: 0.0262 - val_loss: 0.0148\n",
      "Epoch 46/90\n",
      "129/129 [==============================] - 2s 12ms/step - loss: 0.0261 - val_loss: 0.0164\n",
      "Epoch 47/90\n",
      "129/129 [==============================] - 2s 12ms/step - loss: 0.0258 - val_loss: 0.0164\n",
      "Epoch 48/90\n",
      "129/129 [==============================] - 2s 12ms/step - loss: 0.0258 - val_loss: 0.0163\n",
      "Epoch 49/90\n",
      "129/129 [==============================] - 2s 12ms/step - loss: 0.0258 - val_loss: 0.0164\n",
      "Epoch 50/90\n",
      "129/129 [==============================] - 2s 12ms/step - loss: 0.0257 - val_loss: 0.0164\n",
      "Epoch 51/90\n",
      "129/129 [==============================] - 2s 12ms/step - loss: 0.0257 - val_loss: 0.0164\n",
      "Epoch 52/90\n",
      "129/129 [==============================] - 2s 13ms/step - loss: 0.0257 - val_loss: 0.0164\n",
      "Epoch 53/90\n",
      "129/129 [==============================] - 2s 12ms/step - loss: 0.0256 - val_loss: 0.0165\n",
      "Epoch 54/90\n",
      "129/129 [==============================] - 2s 12ms/step - loss: 0.0256 - val_loss: 0.0164\n",
      "Epoch 55/90\n",
      "129/129 [==============================] - 2s 12ms/step - loss: 0.0256 - val_loss: 0.0164\n",
      "Epoch 56/90\n",
      "129/129 [==============================] - 2s 12ms/step - loss: 0.0255 - val_loss: 0.0165\n",
      "Epoch 57/90\n",
      "129/129 [==============================] - 2s 12ms/step - loss: 0.0255 - val_loss: 0.0167\n",
      "Epoch 58/90\n",
      "129/129 [==============================] - 2s 12ms/step - loss: 0.0255 - val_loss: 0.0167\n",
      "Epoch 59/90\n",
      "129/129 [==============================] - 2s 12ms/step - loss: 0.0255 - val_loss: 0.0168\n",
      "Epoch 60/90\n",
      "129/129 [==============================] - 2s 12ms/step - loss: 0.0255 - val_loss: 0.0169\n",
      "Epoch 61/90\n",
      "129/129 [==============================] - 2s 12ms/step - loss: 0.0254 - val_loss: 0.0168\n",
      "Epoch 62/90\n",
      "129/129 [==============================] - 2s 14ms/step - loss: 0.0254 - val_loss: 0.0169\n",
      "Epoch 63/90\n",
      "129/129 [==============================] - 2s 13ms/step - loss: 0.0254 - val_loss: 0.0170\n",
      "Epoch 64/90\n",
      "129/129 [==============================] - 2s 12ms/step - loss: 0.0254 - val_loss: 0.0168\n",
      "Epoch 65/90\n",
      "129/129 [==============================] - 2s 12ms/step - loss: 0.0254 - val_loss: 0.01710s - loss:\n",
      "Epoch 66/90\n",
      "129/129 [==============================] - 2s 12ms/step - loss: 0.0254 - val_loss: 0.0169\n",
      "Epoch 67/90\n",
      "129/129 [==============================] - 2s 13ms/step - loss: 0.0253 - val_loss: 0.0140\n",
      "Epoch 68/90\n",
      "129/129 [==============================] - 2s 12ms/step - loss: 0.0257 - val_loss: 0.0171\n",
      "Epoch 69/90\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "129/129 [==============================] - 2s 12ms/step - loss: 0.0254 - val_loss: 0.0170\n",
      "Epoch 70/90\n",
      "129/129 [==============================] - 2s 13ms/step - loss: 0.0253 - val_loss: 0.0169\n",
      "Epoch 71/90\n",
      "129/129 [==============================] - 2s 13ms/step - loss: 0.0253 - val_loss: 0.0172\n",
      "Epoch 72/90\n",
      "129/129 [==============================] - 2s 14ms/step - loss: 0.0253 - val_loss: 0.0169\n",
      "Epoch 73/90\n",
      "129/129 [==============================] - 2s 13ms/step - loss: 0.0253 - val_loss: 0.0171\n",
      "Epoch 74/90\n",
      "129/129 [==============================] - 2s 13ms/step - loss: 0.0253 - val_loss: 0.0169\n",
      "Epoch 75/90\n",
      "129/129 [==============================] - 2s 13ms/step - loss: 0.0253 - val_loss: 0.0170\n",
      "Epoch 76/90\n",
      "129/129 [==============================] - 2s 13ms/step - loss: 0.0252 - val_loss: 0.0169\n",
      "Epoch 77/90\n",
      "129/129 [==============================] - 2s 14ms/step - loss: 0.0252 - val_loss: 0.0170\n",
      "Epoch 78/90\n",
      "129/129 [==============================] - 2s 12ms/step - loss: 0.0252 - val_loss: 0.0170\n",
      "Epoch 79/90\n",
      "129/129 [==============================] - 2s 12ms/step - loss: 0.0252 - val_loss: 0.0170\n",
      "Epoch 80/90\n",
      "129/129 [==============================] - 2s 12ms/step - loss: 0.0252 - val_loss: 0.0171\n",
      "Epoch 81/90\n",
      "129/129 [==============================] - 2s 13ms/step - loss: 0.0252 - val_loss: 0.0172\n",
      "Epoch 82/90\n",
      "129/129 [==============================] - 2s 13ms/step - loss: 0.0252 - val_loss: 0.0173\n",
      "Epoch 83/90\n",
      "129/129 [==============================] - 2s 12ms/step - loss: 0.0252 - val_loss: 0.0174\n",
      "Epoch 84/90\n",
      "129/129 [==============================] - 2s 12ms/step - loss: 0.0252 - val_loss: 0.0174\n",
      "Epoch 85/90\n",
      "129/129 [==============================] - 2s 12ms/step - loss: 0.0251 - val_loss: 0.0175\n",
      "Epoch 86/90\n",
      "129/129 [==============================] - 2s 12ms/step - loss: 0.0251 - val_loss: 0.0176\n",
      "Epoch 87/90\n",
      "129/129 [==============================] - 2s 12ms/step - loss: 0.0251 - val_loss: 0.0177\n",
      "Epoch 88/90\n",
      "129/129 [==============================] - 2s 12ms/step - loss: 0.0251 - val_loss: 0.0177\n",
      "Epoch 89/90\n",
      "129/129 [==============================] - 2s 12ms/step - loss: 0.0251 - val_loss: 0.0177\n",
      "Epoch 90/90\n",
      "129/129 [==============================] - 2s 13ms/step - loss: 0.0251 - val_loss: 0.0178\n",
      "Execution time:  145.31132221221924\n",
      "DNN:\n",
      "Mean Absolute Error: 0.0251\n",
      "Root Mean Square Error: 0.0434\n",
      "Mean Square Error: 0.0019\n",
      "\n",
      "Train RMSE: 0.043\n",
      "Train MSE: 0.002\n",
      "Train MAE: 0.025\n",
      "###########################\n",
      "\n",
      "MODEL:  DNN\n",
      "sequence:  3d\n",
      "units:  12\n",
      "dropout1:  0.48476373451509647\n",
      "optimizer: adamax\n",
      "activationDense: sigmoid\n",
      "epochs: 52\n",
      "batchsize: 57\n",
      "validation_split: 0.1\n",
      "Model: \"sequential_212\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_636 (Dense)            (None, 432, 12)           24        \n",
      "_________________________________________________________________\n",
      "dense_637 (Dense)            (None, 432, 16)           208       \n",
      "_________________________________________________________________\n",
      "dropout_212 (Dropout)        (None, 432, 16)           0         \n",
      "_________________________________________________________________\n",
      "dense_638 (Dense)            (None, 432, 1)            17        \n",
      "=================================================================\n",
      "Total params: 249\n",
      "Trainable params: 249\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/52\n",
      "57/57 [==============================] - 1s 19ms/step - loss: 0.0635 - val_loss: 0.0500\n",
      "Epoch 2/52\n",
      "57/57 [==============================] - 1s 15ms/step - loss: 0.0510 - val_loss: 0.0441\n",
      "Epoch 3/52\n",
      "57/57 [==============================] - 1s 16ms/step - loss: 0.0454 - val_loss: 0.0410\n",
      "Epoch 4/52\n",
      "57/57 [==============================] - 1s 15ms/step - loss: 0.0424 - val_loss: 0.0404\n",
      "Epoch 5/52\n",
      "57/57 [==============================] - 1s 15ms/step - loss: 0.0410 - val_loss: 0.0384\n",
      "Epoch 6/52\n",
      "57/57 [==============================] - 1s 15ms/step - loss: 0.0396 - val_loss: 0.0364\n",
      "Epoch 7/52\n",
      "57/57 [==============================] - 1s 14ms/step - loss: 0.0382 - val_loss: 0.0353\n",
      "Epoch 8/52\n",
      "57/57 [==============================] - 1s 15ms/step - loss: 0.0371 - val_loss: 0.0345\n",
      "Epoch 9/52\n",
      "57/57 [==============================] - 1s 19ms/step - loss: 0.0361 - val_loss: 0.0337\n",
      "Epoch 10/52\n",
      "57/57 [==============================] - 1s 20ms/step - loss: 0.0353 - val_loss: 0.0327\n",
      "Epoch 11/52\n",
      "57/57 [==============================] - 1s 18ms/step - loss: 0.0346 - val_loss: 0.0319\n",
      "Epoch 12/52\n",
      "57/57 [==============================] - 1s 17ms/step - loss: 0.0341 - val_loss: 0.0315\n",
      "Epoch 13/52\n",
      "57/57 [==============================] - 1s 18ms/step - loss: 0.0335 - val_loss: 0.0308\n",
      "Epoch 14/52\n",
      "57/57 [==============================] - 1s 17ms/step - loss: 0.0330 - val_loss: 0.0302\n",
      "Epoch 15/52\n",
      "57/57 [==============================] - 1s 19ms/step - loss: 0.0326 - val_loss: 0.0295\n",
      "Epoch 16/52\n",
      "57/57 [==============================] - 1s 16ms/step - loss: 0.0321 - val_loss: 0.0287\n",
      "Epoch 17/52\n",
      "57/57 [==============================] - 1s 16ms/step - loss: 0.0317 - val_loss: 0.0279\n",
      "Epoch 18/52\n",
      "57/57 [==============================] - 1s 15ms/step - loss: 0.0313 - val_loss: 0.0273\n",
      "Epoch 19/52\n",
      "57/57 [==============================] - 1s 14ms/step - loss: 0.0310 - val_loss: 0.0267\n",
      "Epoch 20/52\n",
      "57/57 [==============================] - 1s 14ms/step - loss: 0.0307 - val_loss: 0.0263\n",
      "Epoch 21/52\n",
      "57/57 [==============================] - 1s 14ms/step - loss: 0.0303 - val_loss: 0.0257\n",
      "Epoch 22/52\n",
      "57/57 [==============================] - 1s 14ms/step - loss: 0.0300 - val_loss: 0.0251\n",
      "Epoch 23/52\n",
      "57/57 [==============================] - 1s 14ms/step - loss: 0.0297 - val_loss: 0.0245\n",
      "Epoch 24/52\n",
      "57/57 [==============================] - 1s 14ms/step - loss: 0.0295 - val_loss: 0.0240\n",
      "Epoch 25/52\n",
      "57/57 [==============================] - 1s 14ms/step - loss: 0.0293 - val_loss: 0.0236\n",
      "Epoch 26/52\n",
      "57/57 [==============================] - 1s 14ms/step - loss: 0.0290 - val_loss: 0.0231\n",
      "Epoch 27/52\n",
      "57/57 [==============================] - 1s 14ms/step - loss: 0.0288 - val_loss: 0.0227\n",
      "Epoch 28/52\n",
      "57/57 [==============================] - 1s 14ms/step - loss: 0.0285 - val_loss: 0.0223\n",
      "Epoch 29/52\n",
      "57/57 [==============================] - 1s 14ms/step - loss: 0.0283 - val_loss: 0.0219\n",
      "Epoch 30/52\n",
      "57/57 [==============================] - 1s 14ms/step - loss: 0.0281 - val_loss: 0.0215\n",
      "Epoch 31/52\n",
      "57/57 [==============================] - 1s 15ms/step - loss: 0.0279 - val_loss: 0.0211\n",
      "Epoch 32/52\n",
      "57/57 [==============================] - 1s 14ms/step - loss: 0.0278 - val_loss: 0.0208\n",
      "Epoch 33/52\n",
      "57/57 [==============================] - 1s 15ms/step - loss: 0.0276 - val_loss: 0.0205\n",
      "Epoch 34/52\n",
      "57/57 [==============================] - 1s 16ms/step - loss: 0.0274 - val_loss: 0.0202\n",
      "Epoch 35/52\n",
      "57/57 [==============================] - 1s 16ms/step - loss: 0.0273 - val_loss: 0.0198\n",
      "Epoch 36/52\n",
      "57/57 [==============================] - 1s 15ms/step - loss: 0.0272 - val_loss: 0.0196\n",
      "Epoch 37/52\n",
      "57/57 [==============================] - 1s 14ms/step - loss: 0.0270 - val_loss: 0.0193\n",
      "Epoch 38/52\n",
      "57/57 [==============================] - 1s 14ms/step - loss: 0.0269 - val_loss: 0.0191\n",
      "Epoch 39/52\n",
      "57/57 [==============================] - 1s 14ms/step - loss: 0.0268 - val_loss: 0.0188\n",
      "Epoch 40/52\n",
      "57/57 [==============================] - 1s 14ms/step - loss: 0.0267 - val_loss: 0.0186\n",
      "Epoch 41/52\n",
      "57/57 [==============================] - 1s 14ms/step - loss: 0.0266 - val_loss: 0.0184\n",
      "Epoch 42/52\n",
      "57/57 [==============================] - 1s 14ms/step - loss: 0.0265 - val_loss: 0.0183\n",
      "Epoch 43/52\n",
      "57/57 [==============================] - 1s 14ms/step - loss: 0.0264 - val_loss: 0.0181\n",
      "Epoch 44/52\n",
      "57/57 [==============================] - 1s 14ms/step - loss: 0.0263 - val_loss: 0.0180\n",
      "Epoch 45/52\n",
      "57/57 [==============================] - 1s 15ms/step - loss: 0.0263 - val_loss: 0.0180\n",
      "Epoch 46/52\n",
      "57/57 [==============================] - 1s 15ms/step - loss: 0.0262 - val_loss: 0.0179\n",
      "Epoch 47/52\n",
      "57/57 [==============================] - 1s 14ms/step - loss: 0.0261 - val_loss: 0.0177\n",
      "Epoch 48/52\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "57/57 [==============================] - 1s 14ms/step - loss: 0.0261 - val_loss: 0.0178\n",
      "Epoch 49/52\n",
      "57/57 [==============================] - 1s 14ms/step - loss: 0.0260 - val_loss: 0.0177\n",
      "Epoch 50/52\n",
      "57/57 [==============================] - 1s 14ms/step - loss: 0.0260 - val_loss: 0.0178\n",
      "Epoch 51/52\n",
      "57/57 [==============================] - 1s 14ms/step - loss: 0.0259 - val_loss: 0.0176\n",
      "Epoch 52/52\n",
      "57/57 [==============================] - 1s 15ms/step - loss: 0.0259 - val_loss: 0.0176\n",
      "Execution time:  47.04491567611694\n",
      "DNN:\n",
      "Mean Absolute Error: 0.0252\n",
      "Root Mean Square Error: 0.0430\n",
      "Mean Square Error: 0.0019\n",
      "\n",
      "Train RMSE: 0.043\n",
      "Train MSE: 0.002\n",
      "Train MAE: 0.025\n",
      "###########################\n",
      "\n",
      "MODEL:  DNN\n",
      "sequence:  3d\n",
      "units:  87\n",
      "dropout1:  0.40519643149940265\n",
      "optimizer: adamax\n",
      "activationDense: sigmoid\n",
      "epochs: 80\n",
      "batchsize: 31\n",
      "validation_split: 0.2\n",
      "Model: \"sequential_213\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_639 (Dense)            (None, 432, 87)           174       \n",
      "_________________________________________________________________\n",
      "dense_640 (Dense)            (None, 432, 16)           1408      \n",
      "_________________________________________________________________\n",
      "dropout_213 (Dropout)        (None, 432, 16)           0         \n",
      "_________________________________________________________________\n",
      "dense_641 (Dense)            (None, 432, 1)            17        \n",
      "=================================================================\n",
      "Total params: 1,599\n",
      "Trainable params: 1,599\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/80\n",
      "92/92 [==============================] - 2s 18ms/step - loss: 0.0538 - val_loss: 0.0396\n",
      "Epoch 2/80\n",
      "92/92 [==============================] - 1s 16ms/step - loss: 0.0440 - val_loss: 0.0348\n",
      "Epoch 3/80\n",
      "92/92 [==============================] - 1s 16ms/step - loss: 0.0422 - val_loss: 0.0328\n",
      "Epoch 4/80\n",
      "92/92 [==============================] - 1s 16ms/step - loss: 0.0407 - val_loss: 0.0310\n",
      "Epoch 5/80\n",
      "92/92 [==============================] - 1s 16ms/step - loss: 0.0394 - val_loss: 0.0287\n",
      "Epoch 6/80\n",
      "92/92 [==============================] - 1s 16ms/step - loss: 0.0384 - val_loss: 0.0265\n",
      "Epoch 7/80\n",
      "92/92 [==============================] - 1s 16ms/step - loss: 0.0374 - val_loss: 0.0251\n",
      "Epoch 8/80\n",
      "92/92 [==============================] - 1s 16ms/step - loss: 0.0365 - val_loss: 0.0234\n",
      "Epoch 9/80\n",
      "92/92 [==============================] - 1s 16ms/step - loss: 0.0357 - val_loss: 0.0225\n",
      "Epoch 10/80\n",
      "92/92 [==============================] - 2s 16ms/step - loss: 0.0349 - val_loss: 0.0216\n",
      "Epoch 11/80\n",
      "92/92 [==============================] - 2s 17ms/step - loss: 0.0342 - val_loss: 0.0190\n",
      "Epoch 12/80\n",
      "92/92 [==============================] - 2s 16ms/step - loss: 0.0335 - val_loss: 0.0201\n",
      "Epoch 13/80\n",
      "92/92 [==============================] - 1s 16ms/step - loss: 0.0327 - val_loss: 0.0192\n",
      "Epoch 14/80\n",
      "92/92 [==============================] - 1s 16ms/step - loss: 0.0322 - val_loss: 0.0181\n",
      "Epoch 15/80\n",
      "92/92 [==============================] - 1s 16ms/step - loss: 0.0317 - val_loss: 0.0177\n",
      "Epoch 16/80\n",
      "92/92 [==============================] - 1s 16ms/step - loss: 0.0312 - val_loss: 0.0171\n",
      "Epoch 17/80\n",
      "92/92 [==============================] - 1s 16ms/step - loss: 0.0308 - val_loss: 0.0165\n",
      "Epoch 18/80\n",
      "92/92 [==============================] - 1s 16ms/step - loss: 0.0304 - val_loss: 0.0161\n",
      "Epoch 19/80\n",
      "92/92 [==============================] - 1s 16ms/step - loss: 0.0301 - val_loss: 0.0157\n",
      "Epoch 20/80\n",
      "92/92 [==============================] - 1s 16ms/step - loss: 0.0300 - val_loss: 0.0166\n",
      "Epoch 21/80\n",
      "92/92 [==============================] - 2s 17ms/step - loss: 0.0293 - val_loss: 0.0153\n",
      "Epoch 22/80\n",
      "92/92 [==============================] - 2s 17ms/step - loss: 0.0291 - val_loss: 0.0151\n",
      "Epoch 23/80\n",
      "92/92 [==============================] - 1s 16ms/step - loss: 0.0289 - val_loss: 0.0149\n",
      "Epoch 24/80\n",
      "92/92 [==============================] - 1s 16ms/step - loss: 0.0287 - val_loss: 0.0148\n",
      "Epoch 25/80\n",
      "92/92 [==============================] - 1s 16ms/step - loss: 0.0285 - val_loss: 0.0148\n",
      "Epoch 26/80\n",
      "92/92 [==============================] - 1s 16ms/step - loss: 0.0283 - val_loss: 0.0148\n",
      "Epoch 27/80\n",
      "92/92 [==============================] - 1s 16ms/step - loss: 0.0282 - val_loss: 0.0148\n",
      "Epoch 28/80\n",
      "92/92 [==============================] - 1s 16ms/step - loss: 0.0280 - val_loss: 0.0147\n",
      "Epoch 29/80\n",
      "92/92 [==============================] - 1s 16ms/step - loss: 0.0279 - val_loss: 0.0148\n",
      "Epoch 30/80\n",
      "92/92 [==============================] - 1s 16ms/step - loss: 0.0278 - val_loss: 0.0148\n",
      "Epoch 31/80\n",
      "92/92 [==============================] - 2s 17ms/step - loss: 0.0276 - val_loss: 0.0148\n",
      "Epoch 32/80\n",
      "92/92 [==============================] - 2s 17ms/step - loss: 0.0275 - val_loss: 0.0147\n",
      "Epoch 33/80\n",
      "92/92 [==============================] - 2s 16ms/step - loss: 0.0274 - val_loss: 0.0147\n",
      "Epoch 34/80\n",
      "92/92 [==============================] - 1s 16ms/step - loss: 0.0274 - val_loss: 0.0147\n",
      "Epoch 35/80\n",
      "92/92 [==============================] - 1s 16ms/step - loss: 0.0273 - val_loss: 0.0146\n",
      "Epoch 36/80\n",
      "92/92 [==============================] - 1s 16ms/step - loss: 0.0272 - val_loss: 0.0146\n",
      "Epoch 37/80\n",
      "92/92 [==============================] - 1s 16ms/step - loss: 0.0272 - val_loss: 0.0146\n",
      "Epoch 38/80\n",
      "92/92 [==============================] - 1s 16ms/step - loss: 0.0271 - val_loss: 0.0146\n",
      "Epoch 39/80\n",
      "92/92 [==============================] - 1s 16ms/step - loss: 0.0271 - val_loss: 0.0146\n",
      "Epoch 40/80\n",
      "92/92 [==============================] - 1s 16ms/step - loss: 0.0270 - val_loss: 0.0146\n",
      "Epoch 41/80\n",
      "92/92 [==============================] - 1s 16ms/step - loss: 0.0270 - val_loss: 0.0146\n",
      "Epoch 42/80\n",
      "92/92 [==============================] - 2s 17ms/step - loss: 0.0270 - val_loss: 0.0146\n",
      "Epoch 43/80\n",
      "92/92 [==============================] - 2s 17ms/step - loss: 0.0269 - val_loss: 0.0146\n",
      "Epoch 44/80\n",
      "92/92 [==============================] - 1s 16ms/step - loss: 0.0269 - val_loss: 0.0145\n",
      "Epoch 45/80\n",
      "92/92 [==============================] - 1s 16ms/step - loss: 0.0269 - val_loss: 0.0147\n",
      "Epoch 46/80\n",
      "92/92 [==============================] - 1s 16ms/step - loss: 0.0268 - val_loss: 0.0146\n",
      "Epoch 47/80\n",
      "92/92 [==============================] - 1s 16ms/step - loss: 0.0268 - val_loss: 0.0147\n",
      "Epoch 48/80\n",
      "92/92 [==============================] - 2s 16ms/step - loss: 0.0267 - val_loss: 0.0146\n",
      "Epoch 49/80\n",
      "92/92 [==============================] - 2s 17ms/step - loss: 0.0268 - val_loss: 0.0149\n",
      "Epoch 50/80\n",
      "92/92 [==============================] - 1s 16ms/step - loss: 0.0267 - val_loss: 0.0148\n",
      "Epoch 51/80\n",
      "92/92 [==============================] - 1s 16ms/step - loss: 0.0267 - val_loss: 0.0148\n",
      "Epoch 52/80\n",
      "92/92 [==============================] - 2s 17ms/step - loss: 0.0267 - val_loss: 0.0149\n",
      "Epoch 53/80\n",
      "92/92 [==============================] - 2s 17ms/step - loss: 0.0267 - val_loss: 0.0149\n",
      "Epoch 54/80\n",
      "92/92 [==============================] - 2s 17ms/step - loss: 0.0267 - val_loss: 0.0149\n",
      "Epoch 55/80\n",
      "92/92 [==============================] - 1s 16ms/step - loss: 0.0267 - val_loss: 0.0149\n",
      "Epoch 56/80\n",
      "92/92 [==============================] - 2s 16ms/step - loss: 0.0267 - val_loss: 0.0149\n",
      "Epoch 57/80\n",
      "92/92 [==============================] - 1s 16ms/step - loss: 0.0267 - val_loss: 0.0149\n",
      "Epoch 58/80\n",
      "92/92 [==============================] - 1s 16ms/step - loss: 0.0267 - val_loss: 0.0149\n",
      "Epoch 59/80\n",
      "92/92 [==============================] - 1s 16ms/step - loss: 0.0267 - val_loss: 0.0148\n",
      "Epoch 60/80\n",
      "92/92 [==============================] - 2s 17ms/step - loss: 0.0267 - val_loss: 0.0149\n",
      "Epoch 61/80\n",
      "92/92 [==============================] - 2s 18ms/step - loss: 0.0267 - val_loss: 0.0149\n",
      "Epoch 62/80\n",
      "92/92 [==============================] - 2s 17ms/step - loss: 0.0267 - val_loss: 0.0148\n",
      "Epoch 63/80\n",
      "92/92 [==============================] - 2s 18ms/step - loss: 0.0267 - val_loss: 0.0149\n",
      "Epoch 64/80\n",
      "92/92 [==============================] - 2s 17ms/step - loss: 0.0267 - val_loss: 0.0148\n",
      "Epoch 65/80\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "92/92 [==============================] - 1s 16ms/step - loss: 0.0267 - val_loss: 0.0149\n",
      "Epoch 66/80\n",
      "92/92 [==============================] - 1s 16ms/step - loss: 0.0267 - val_loss: 0.0148\n",
      "Epoch 67/80\n",
      "92/92 [==============================] - 1s 16ms/step - loss: 0.0267 - val_loss: 0.0149\n",
      "Epoch 68/80\n",
      "92/92 [==============================] - 1s 16ms/step - loss: 0.0267 - val_loss: 0.0149\n",
      "Epoch 69/80\n",
      "92/92 [==============================] - 1s 16ms/step - loss: 0.0267 - val_loss: 0.0148\n",
      "Epoch 70/80\n",
      "92/92 [==============================] - 2s 16ms/step - loss: 0.0267 - val_loss: 0.0148\n",
      "Epoch 71/80\n",
      "92/92 [==============================] - 1s 16ms/step - loss: 0.0267 - val_loss: 0.0149\n",
      "Epoch 72/80\n",
      "92/92 [==============================] - 1s 16ms/step - loss: 0.0267 - val_loss: 0.0149\n",
      "Epoch 73/80\n",
      "92/92 [==============================] - 2s 17ms/step - loss: 0.0267 - val_loss: 0.0148\n",
      "Epoch 74/80\n",
      "92/92 [==============================] - 2s 17ms/step - loss: 0.0267 - val_loss: 0.0149\n",
      "Epoch 75/80\n",
      "92/92 [==============================] - 2s 17ms/step - loss: 0.0267 - val_loss: 0.0149\n",
      "Epoch 76/80\n",
      "92/92 [==============================] - 1s 16ms/step - loss: 0.0266 - val_loss: 0.0148\n",
      "Epoch 77/80\n",
      "92/92 [==============================] - 1s 16ms/step - loss: 0.0267 - val_loss: 0.0148\n",
      "Epoch 78/80\n",
      "92/92 [==============================] - 1s 16ms/step - loss: 0.0267 - val_loss: 0.0149\n",
      "Epoch 79/80\n",
      "92/92 [==============================] - 1s 16ms/step - loss: 0.0267 - val_loss: 0.0149\n",
      "Epoch 80/80\n",
      "92/92 [==============================] - 1s 16ms/step - loss: 0.0266 - val_loss: 0.0148\n",
      "Execution time:  122.94246935844421\n",
      "DNN:\n",
      "Mean Absolute Error: 0.0251\n",
      "Root Mean Square Error: 0.0429\n",
      "Mean Square Error: 0.0018\n",
      "\n",
      "Train RMSE: 0.043\n",
      "Train MSE: 0.002\n",
      "Train MAE: 0.025\n",
      "###########################\n",
      "\n",
      "MODEL:  DNN\n",
      "sequence:  3d\n",
      "units:  80\n",
      "dropout1:  0.11814836227952394\n",
      "optimizer: adamax\n",
      "activationDense: sigmoid\n",
      "epochs: 90\n",
      "batchsize: 25\n",
      "validation_split: 0.2\n",
      "Model: \"sequential_214\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_642 (Dense)            (None, 432, 80)           160       \n",
      "_________________________________________________________________\n",
      "dense_643 (Dense)            (None, 432, 16)           1296      \n",
      "_________________________________________________________________\n",
      "dropout_214 (Dropout)        (None, 432, 16)           0         \n",
      "_________________________________________________________________\n",
      "dense_644 (Dense)            (None, 432, 1)            17        \n",
      "=================================================================\n",
      "Total params: 1,473\n",
      "Trainable params: 1,473\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/90\n",
      "114/114 [==============================] - 2s 14ms/step - loss: 0.0369 - val_loss: 0.0127\n",
      "Epoch 2/90\n",
      "114/114 [==============================] - 1s 13ms/step - loss: 0.0359 - val_loss: 0.0127\n",
      "Epoch 3/90\n",
      "114/114 [==============================] - 2s 13ms/step - loss: 0.0356 - val_loss: 0.0128\n",
      "Epoch 4/90\n",
      "114/114 [==============================] - 1s 13ms/step - loss: 0.0353 - val_loss: 0.0128\n",
      "Epoch 5/90\n",
      "114/114 [==============================] - 1s 12ms/step - loss: 0.0350 - val_loss: 0.0130\n",
      "Epoch 6/90\n",
      "114/114 [==============================] - 1s 12ms/step - loss: 0.0347 - val_loss: 0.0132\n",
      "Epoch 7/90\n",
      "114/114 [==============================] - 1s 12ms/step - loss: 0.0343 - val_loss: 0.0126\n",
      "Epoch 8/90\n",
      "114/114 [==============================] - 1s 12ms/step - loss: 0.0341 - val_loss: 0.0130\n",
      "Epoch 9/90\n",
      "114/114 [==============================] - 1s 12ms/step - loss: 0.0337 - val_loss: 0.0128\n",
      "Epoch 10/90\n",
      "114/114 [==============================] - 1s 13ms/step - loss: 0.0335 - val_loss: 0.0132\n",
      "Epoch 11/90\n",
      "114/114 [==============================] - 1s 12ms/step - loss: 0.0337 - val_loss: 0.0129\n",
      "Epoch 12/90\n",
      "114/114 [==============================] - 1s 12ms/step - loss: 0.0329 - val_loss: 0.0122\n",
      "Epoch 13/90\n",
      "114/114 [==============================] - 1s 13ms/step - loss: 0.0329 - val_loss: 0.0129\n",
      "Epoch 14/90\n",
      "114/114 [==============================] - 2s 13ms/step - loss: 0.0326 - val_loss: 0.0130\n",
      "Epoch 15/90\n",
      "114/114 [==============================] - 1s 13ms/step - loss: 0.0324 - val_loss: 0.0130\n",
      "Epoch 16/90\n",
      "114/114 [==============================] - 1s 12ms/step - loss: 0.0322 - val_loss: 0.0129\n",
      "Epoch 17/90\n",
      "114/114 [==============================] - 1s 12ms/step - loss: 0.0320 - val_loss: 0.0125\n",
      "Epoch 18/90\n",
      "114/114 [==============================] - 1s 12ms/step - loss: 0.0319 - val_loss: 0.0126\n",
      "Epoch 19/90\n",
      "114/114 [==============================] - 1s 12ms/step - loss: 0.0316 - val_loss: 0.0127\n",
      "Epoch 20/90\n",
      "114/114 [==============================] - 1s 12ms/step - loss: 0.0314 - val_loss: 0.0127\n",
      "Epoch 21/90\n",
      "114/114 [==============================] - 1s 12ms/step - loss: 0.0313 - val_loss: 0.0126\n",
      "Epoch 22/90\n",
      "114/114 [==============================] - 1s 12ms/step - loss: 0.0310 - val_loss: 0.0127\n",
      "Epoch 23/90\n",
      "114/114 [==============================] - 1s 12ms/step - loss: 0.0309 - val_loss: 0.0128\n",
      "Epoch 24/90\n",
      "114/114 [==============================] - 1s 13ms/step - loss: 0.0308 - val_loss: 0.0127\n",
      "Epoch 25/90\n",
      "114/114 [==============================] - 2s 13ms/step - loss: 0.0305 - val_loss: 0.0121\n",
      "Epoch 26/90\n",
      "114/114 [==============================] - 2s 13ms/step - loss: 0.0307 - val_loss: 0.0128\n",
      "Epoch 27/90\n",
      "114/114 [==============================] - 1s 12ms/step - loss: 0.0304 - val_loss: 0.0127\n",
      "Epoch 28/90\n",
      "114/114 [==============================] - 1s 13ms/step - loss: 0.0305 - val_loss: 0.0127\n",
      "Epoch 29/90\n",
      "114/114 [==============================] - 1s 12ms/step - loss: 0.0302 - val_loss: 0.0127\n",
      "Epoch 30/90\n",
      "114/114 [==============================] - 1s 12ms/step - loss: 0.0301 - val_loss: 0.0128\n",
      "Epoch 31/90\n",
      "114/114 [==============================] - 1s 12ms/step - loss: 0.0301 - val_loss: 0.0131\n",
      "Epoch 32/90\n",
      "114/114 [==============================] - 1s 12ms/step - loss: 0.0298 - val_loss: 0.0128\n",
      "Epoch 33/90\n",
      "114/114 [==============================] - 1s 13ms/step - loss: 0.0298 - val_loss: 0.0129\n",
      "Epoch 34/90\n",
      "114/114 [==============================] - 1s 13ms/step - loss: 0.0296 - val_loss: 0.0129\n",
      "Epoch 35/90\n",
      "114/114 [==============================] - 1s 13ms/step - loss: 0.0296 - val_loss: 0.0129\n",
      "Epoch 36/90\n",
      "114/114 [==============================] - 2s 13ms/step - loss: 0.0293 - val_loss: 0.0119\n",
      "Epoch 37/90\n",
      "114/114 [==============================] - 1s 13ms/step - loss: 0.0295 - val_loss: 0.0129\n",
      "Epoch 38/90\n",
      "114/114 [==============================] - 1s 13ms/step - loss: 0.0293 - val_loss: 0.0130\n",
      "Epoch 39/90\n",
      "114/114 [==============================] - 1s 12ms/step - loss: 0.0292 - val_loss: 0.0130\n",
      "Epoch 40/90\n",
      "114/114 [==============================] - 1s 12ms/step - loss: 0.0292 - val_loss: 0.0136\n",
      "Epoch 41/90\n",
      "114/114 [==============================] - 1s 12ms/step - loss: 0.0289 - val_loss: 0.0132\n",
      "Epoch 42/90\n",
      "114/114 [==============================] - 1s 12ms/step - loss: 0.0289 - val_loss: 0.0133\n",
      "Epoch 43/90\n",
      "114/114 [==============================] - 1s 12ms/step - loss: 0.0289 - val_loss: 0.0137\n",
      "Epoch 44/90\n",
      "114/114 [==============================] - 1s 12ms/step - loss: 0.0287 - val_loss: 0.0133\n",
      "Epoch 45/90\n",
      "114/114 [==============================] - 1s 12ms/step - loss: 0.0286 - val_loss: 0.0133\n",
      "Epoch 46/90\n",
      "114/114 [==============================] - 1s 13ms/step - loss: 0.0287 - val_loss: 0.0137\n",
      "Epoch 47/90\n",
      "114/114 [==============================] - 1s 13ms/step - loss: 0.0285 - val_loss: 0.0135\n",
      "Epoch 48/90\n",
      "114/114 [==============================] - 1s 13ms/step - loss: 0.0285 - val_loss: 0.0135\n",
      "Epoch 49/90\n",
      "114/114 [==============================] - 1s 12ms/step - loss: 0.0284 - val_loss: 0.0135\n",
      "Epoch 50/90\n",
      "114/114 [==============================] - 1s 12ms/step - loss: 0.0284 - val_loss: 0.0135\n",
      "Epoch 51/90\n",
      "114/114 [==============================] - 1s 12ms/step - loss: 0.0283 - val_loss: 0.0136\n",
      "Epoch 52/90\n",
      "114/114 [==============================] - 1s 12ms/step - loss: 0.0283 - val_loss: 0.0135\n",
      "Epoch 53/90\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "114/114 [==============================] - 1s 12ms/step - loss: 0.0282 - val_loss: 0.0136\n",
      "Epoch 54/90\n",
      "114/114 [==============================] - 1s 13ms/step - loss: 0.0282 - val_loss: 0.0136\n",
      "Epoch 55/90\n",
      "114/114 [==============================] - 1s 12ms/step - loss: 0.0282 - val_loss: 0.0136\n",
      "Epoch 56/90\n",
      "114/114 [==============================] - 1s 12ms/step - loss: 0.0281 - val_loss: 0.0137\n",
      "Epoch 57/90\n",
      "114/114 [==============================] - 1s 12ms/step - loss: 0.0281 - val_loss: 0.0137\n",
      "Epoch 58/90\n",
      "114/114 [==============================] - 2s 13ms/step - loss: 0.0281 - val_loss: 0.0137\n",
      "Epoch 59/90\n",
      "114/114 [==============================] - 1s 13ms/step - loss: 0.0280 - val_loss: 0.0139\n",
      "Epoch 60/90\n",
      "114/114 [==============================] - 1s 12ms/step - loss: 0.0279 - val_loss: 0.0139\n",
      "Epoch 61/90\n",
      "114/114 [==============================] - 1s 12ms/step - loss: 0.0279 - val_loss: 0.0139\n",
      "Epoch 62/90\n",
      "114/114 [==============================] - 1s 12ms/step - loss: 0.0278 - val_loss: 0.0139\n",
      "Epoch 63/90\n",
      "114/114 [==============================] - 1s 12ms/step - loss: 0.0278 - val_loss: 0.0139\n",
      "Epoch 64/90\n",
      "114/114 [==============================] - 1s 12ms/step - loss: 0.0278 - val_loss: 0.0139\n",
      "Epoch 65/90\n",
      "114/114 [==============================] - 1s 12ms/step - loss: 0.0278 - val_loss: 0.0140\n",
      "Epoch 66/90\n",
      "114/114 [==============================] - 1s 12ms/step - loss: 0.0277 - val_loss: 0.0140\n",
      "Epoch 67/90\n",
      "114/114 [==============================] - 1s 13ms/step - loss: 0.0277 - val_loss: 0.0140\n",
      "Epoch 68/90\n",
      "114/114 [==============================] - 1s 12ms/step - loss: 0.0277 - val_loss: 0.0140\n",
      "Epoch 69/90\n",
      "114/114 [==============================] - 2s 13ms/step - loss: 0.0277 - val_loss: 0.0140\n",
      "Epoch 70/90\n",
      "114/114 [==============================] - 1s 13ms/step - loss: 0.0276 - val_loss: 0.0140\n",
      "Epoch 71/90\n",
      "114/114 [==============================] - 1s 12ms/step - loss: 0.0276 - val_loss: 0.0140\n",
      "Epoch 72/90\n",
      "114/114 [==============================] - 1s 12ms/step - loss: 0.0276 - val_loss: 0.0140\n",
      "Epoch 73/90\n",
      "114/114 [==============================] - 1s 12ms/step - loss: 0.0276 - val_loss: 0.0140\n",
      "Epoch 74/90\n",
      "114/114 [==============================] - 1s 12ms/step - loss: 0.0276 - val_loss: 0.0140\n",
      "Epoch 75/90\n",
      "114/114 [==============================] - 1s 13ms/step - loss: 0.0276 - val_loss: 0.0140\n",
      "Epoch 76/90\n",
      "114/114 [==============================] - 1s 12ms/step - loss: 0.0276 - val_loss: 0.0140\n",
      "Epoch 77/90\n",
      "114/114 [==============================] - 1s 12ms/step - loss: 0.0276 - val_loss: 0.0141\n",
      "Epoch 78/90\n",
      "114/114 [==============================] - 1s 12ms/step - loss: 0.0275 - val_loss: 0.0140\n",
      "Epoch 79/90\n",
      "114/114 [==============================] - 1s 12ms/step - loss: 0.0275 - val_loss: 0.0141\n",
      "Epoch 80/90\n",
      "114/114 [==============================] - 2s 13ms/step - loss: 0.0275 - val_loss: 0.0140\n",
      "Epoch 81/90\n",
      "114/114 [==============================] - 1s 13ms/step - loss: 0.0275 - val_loss: 0.0141\n",
      "Epoch 82/90\n",
      "114/114 [==============================] - 1s 12ms/step - loss: 0.0275 - val_loss: 0.0140\n",
      "Epoch 83/90\n",
      "114/114 [==============================] - 1s 12ms/step - loss: 0.0275 - val_loss: 0.0141\n",
      "Epoch 84/90\n",
      "114/114 [==============================] - 1s 12ms/step - loss: 0.0274 - val_loss: 0.0140\n",
      "Epoch 85/90\n",
      "114/114 [==============================] - 1s 12ms/step - loss: 0.0275 - val_loss: 0.0140\n",
      "Epoch 86/90\n",
      "114/114 [==============================] - 1s 12ms/step - loss: 0.0274 - val_loss: 0.0140\n",
      "Epoch 87/90\n",
      "114/114 [==============================] - 1s 12ms/step - loss: 0.0274 - val_loss: 0.0141\n",
      "Epoch 88/90\n",
      "114/114 [==============================] - 1s 12ms/step - loss: 0.0275 - val_loss: 0.0136\n",
      "Epoch 89/90\n",
      "114/114 [==============================] - 1s 12ms/step - loss: 0.0275 - val_loss: 0.0138\n",
      "Epoch 90/90\n",
      "114/114 [==============================] - 1s 12ms/step - loss: 0.0274 - val_loss: 0.0140\n",
      "Execution time:  131.45213794708252\n",
      "DNN:\n",
      "Mean Absolute Error: 0.0252\n",
      "Root Mean Square Error: 0.0437\n",
      "Mean Square Error: 0.0019\n",
      "\n",
      "Train RMSE: 0.044\n",
      "Train MSE: 0.002\n",
      "Train MAE: 0.025\n",
      "###########################\n",
      "\n",
      "MODEL:  DNN\n",
      "sequence:  3d\n",
      "units:  12\n",
      "dropout1:  0.48476373451509647\n",
      "optimizer: adamax\n",
      "activationDense: sigmoid\n",
      "epochs: 52\n",
      "batchsize: 57\n",
      "validation_split: 0.2\n",
      "Model: \"sequential_215\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_645 (Dense)            (None, 432, 12)           24        \n",
      "_________________________________________________________________\n",
      "dense_646 (Dense)            (None, 432, 16)           208       \n",
      "_________________________________________________________________\n",
      "dropout_215 (Dropout)        (None, 432, 16)           0         \n",
      "_________________________________________________________________\n",
      "dense_647 (Dense)            (None, 432, 1)            17        \n",
      "=================================================================\n",
      "Total params: 249\n",
      "Trainable params: 249\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/52\n",
      "50/50 [==============================] - 1s 26ms/step - loss: 0.1071 - val_loss: 0.0870\n",
      "Epoch 2/52\n",
      "50/50 [==============================] - 1s 15ms/step - loss: 0.0537 - val_loss: 0.0442\n",
      "Epoch 3/52\n",
      "50/50 [==============================] - 1s 15ms/step - loss: 0.0446 - val_loss: 0.0356\n",
      "Epoch 4/52\n",
      "50/50 [==============================] - 1s 15ms/step - loss: 0.0424 - val_loss: 0.0344\n",
      "Epoch 5/52\n",
      "50/50 [==============================] - 1s 15ms/step - loss: 0.0409 - val_loss: 0.0332\n",
      "Epoch 6/52\n",
      "50/50 [==============================] - 1s 15ms/step - loss: 0.0397 - val_loss: 0.0322\n",
      "Epoch 7/52\n",
      "50/50 [==============================] - 1s 15ms/step - loss: 0.0386 - val_loss: 0.0314\n",
      "Epoch 8/52\n",
      "50/50 [==============================] - 1s 15ms/step - loss: 0.0377 - val_loss: 0.0301\n",
      "Epoch 9/52\n",
      "50/50 [==============================] - 1s 15ms/step - loss: 0.0370 - val_loss: 0.0290\n",
      "Epoch 10/52\n",
      "50/50 [==============================] - 1s 15ms/step - loss: 0.0363 - val_loss: 0.0282\n",
      "Epoch 11/52\n",
      "50/50 [==============================] - 1s 15ms/step - loss: 0.0358 - val_loss: 0.0275\n",
      "Epoch 12/52\n",
      "50/50 [==============================] - 1s 15ms/step - loss: 0.0353 - val_loss: 0.0270\n",
      "Epoch 13/52\n",
      "50/50 [==============================] - 1s 15ms/step - loss: 0.0348 - val_loss: 0.0264\n",
      "Epoch 14/52\n",
      "50/50 [==============================] - 1s 15ms/step - loss: 0.0343 - val_loss: 0.0258\n",
      "Epoch 15/52\n",
      "50/50 [==============================] - 1s 15ms/step - loss: 0.0339 - val_loss: 0.0253\n",
      "Epoch 16/52\n",
      "50/50 [==============================] - 1s 15ms/step - loss: 0.0334 - val_loss: 0.0247\n",
      "Epoch 17/52\n",
      "50/50 [==============================] - 1s 15ms/step - loss: 0.0330 - val_loss: 0.0242\n",
      "Epoch 18/52\n",
      "50/50 [==============================] - 1s 15ms/step - loss: 0.0326 - val_loss: 0.0236\n",
      "Epoch 19/52\n",
      "50/50 [==============================] - 1s 16ms/step - loss: 0.0323 - val_loss: 0.0231\n",
      "Epoch 20/52\n",
      "50/50 [==============================] - 1s 16ms/step - loss: 0.0319 - val_loss: 0.0226\n",
      "Epoch 21/52\n",
      "50/50 [==============================] - 1s 16ms/step - loss: 0.0316 - val_loss: 0.0222\n",
      "Epoch 22/52\n",
      "50/50 [==============================] - 1s 16ms/step - loss: 0.0313 - val_loss: 0.0219\n",
      "Epoch 23/52\n",
      "50/50 [==============================] - 1s 15ms/step - loss: 0.0311 - val_loss: 0.0216\n",
      "Epoch 24/52\n",
      "50/50 [==============================] - 1s 15ms/step - loss: 0.0308 - val_loss: 0.0215\n",
      "Epoch 25/52\n",
      "50/50 [==============================] - 1s 15ms/step - loss: 0.0305 - val_loss: 0.0212\n",
      "Epoch 26/52\n",
      "50/50 [==============================] - 1s 15ms/step - loss: 0.0303 - val_loss: 0.0209\n",
      "Epoch 27/52\n",
      "50/50 [==============================] - 1s 15ms/step - loss: 0.0300 - val_loss: 0.0208\n",
      "Epoch 28/52\n",
      "50/50 [==============================] - 1s 15ms/step - loss: 0.0298 - val_loss: 0.0206\n",
      "Epoch 29/52\n",
      "50/50 [==============================] - 1s 15ms/step - loss: 0.0296 - val_loss: 0.0201\n",
      "Epoch 30/52\n",
      "50/50 [==============================] - 1s 15ms/step - loss: 0.0294 - val_loss: 0.0197\n",
      "Epoch 31/52\n",
      "50/50 [==============================] - 1s 15ms/step - loss: 0.0292 - val_loss: 0.0192\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 32/52\n",
      "50/50 [==============================] - 1s 15ms/step - loss: 0.0291 - val_loss: 0.0188\n",
      "Epoch 33/52\n",
      "50/50 [==============================] - 1s 15ms/step - loss: 0.0289 - val_loss: 0.0185\n",
      "Epoch 34/52\n",
      "50/50 [==============================] - 1s 15ms/step - loss: 0.0288 - val_loss: 0.0181\n",
      "Epoch 35/52\n",
      "50/50 [==============================] - 1s 15ms/step - loss: 0.0287 - val_loss: 0.0178\n",
      "Epoch 36/52\n",
      "50/50 [==============================] - 1s 15ms/step - loss: 0.0285 - val_loss: 0.0175\n",
      "Epoch 37/52\n",
      "50/50 [==============================] - 1s 15ms/step - loss: 0.0284 - val_loss: 0.0173\n",
      "Epoch 38/52\n",
      "50/50 [==============================] - 1s 15ms/step - loss: 0.0283 - val_loss: 0.0171\n",
      "Epoch 39/52\n",
      "50/50 [==============================] - 1s 16ms/step - loss: 0.0282 - val_loss: 0.0168\n",
      "Epoch 40/52\n",
      "50/50 [==============================] - 1s 17ms/step - loss: 0.0281 - val_loss: 0.0167\n",
      "Epoch 41/52\n",
      "50/50 [==============================] - 1s 16ms/step - loss: 0.0280 - val_loss: 0.0166\n",
      "Epoch 42/52\n",
      "50/50 [==============================] - 1s 16ms/step - loss: 0.0280 - val_loss: 0.0164\n",
      "Epoch 43/52\n",
      "50/50 [==============================] - 1s 15ms/step - loss: 0.0279 - val_loss: 0.0162\n",
      "Epoch 44/52\n",
      "50/50 [==============================] - 1s 15ms/step - loss: 0.0278 - val_loss: 0.0160\n",
      "Epoch 45/52\n",
      "50/50 [==============================] - 1s 15ms/step - loss: 0.0278 - val_loss: 0.0158\n",
      "Epoch 46/52\n",
      "50/50 [==============================] - 1s 15ms/step - loss: 0.0277 - val_loss: 0.0156\n",
      "Epoch 47/52\n",
      "50/50 [==============================] - 1s 15ms/step - loss: 0.0276 - val_loss: 0.0154\n",
      "Epoch 48/52\n",
      "50/50 [==============================] - 1s 15ms/step - loss: 0.0276 - val_loss: 0.0152\n",
      "Epoch 49/52\n",
      "50/50 [==============================] - 1s 15ms/step - loss: 0.0275 - val_loss: 0.0151\n",
      "Epoch 50/52\n",
      "50/50 [==============================] - 1s 15ms/step - loss: 0.0275 - val_loss: 0.0151\n",
      "Epoch 51/52\n",
      "50/50 [==============================] - 1s 15ms/step - loss: 0.0274 - val_loss: 0.0151\n",
      "Epoch 52/52\n",
      "50/50 [==============================] - 1s 15ms/step - loss: 0.0274 - val_loss: 0.0150\n",
      "Execution time:  42.00743246078491\n",
      "DNN:\n",
      "Mean Absolute Error: 0.0250\n",
      "Root Mean Square Error: 0.0426\n",
      "Mean Square Error: 0.0018\n",
      "\n",
      "Train RMSE: 0.043\n",
      "Train MSE: 0.002\n",
      "Train MAE: 0.025\n",
      "###########################\n",
      "\n",
      "MODEL:  DNN\n",
      "sequence:  7d\n",
      "units:  87\n",
      "dropout1:  0.40519643149940265\n",
      "optimizer: adam\n",
      "activationDense: tanh\n",
      "epochs: 80\n",
      "batchsize: 31\n",
      "validation_split: 0.1\n",
      "Model: \"sequential_216\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_648 (Dense)            (None, 1008, 87)          174       \n",
      "_________________________________________________________________\n",
      "dense_649 (Dense)            (None, 1008, 16)          1408      \n",
      "_________________________________________________________________\n",
      "dropout_216 (Dropout)        (None, 1008, 16)          0         \n",
      "_________________________________________________________________\n",
      "dense_650 (Dense)            (None, 1008, 1)           17        \n",
      "=================================================================\n",
      "Total params: 1,599\n",
      "Trainable params: 1,599\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/80\n",
      "87/87 [==============================] - 3s 37ms/step - loss: 0.1542 - val_loss: 0.0325\n",
      "Epoch 2/80\n",
      "87/87 [==============================] - 3s 37ms/step - loss: 0.0914 - val_loss: 0.0081\n",
      "Epoch 3/80\n",
      "87/87 [==============================] - 3s 36ms/step - loss: 0.0808 - val_loss: 0.0068\n",
      "Epoch 4/80\n",
      "87/87 [==============================] - 3s 35ms/step - loss: 0.0708 - val_loss: 0.0069\n",
      "Epoch 5/80\n",
      "87/87 [==============================] - 3s 35ms/step - loss: 0.0606 - val_loss: 0.0103\n",
      "Epoch 6/80\n",
      "87/87 [==============================] - 3s 35ms/step - loss: 0.0509 - val_loss: 0.0132\n",
      "Epoch 7/80\n",
      "87/87 [==============================] - 3s 37ms/step - loss: 0.0421 - val_loss: 0.0181\n",
      "Epoch 8/80\n",
      "87/87 [==============================] - 3s 36ms/step - loss: 0.0354 - val_loss: 0.0190\n",
      "Epoch 9/80\n",
      "87/87 [==============================] - 3s 37ms/step - loss: 0.0302 - val_loss: 0.0238\n",
      "Epoch 10/80\n",
      "87/87 [==============================] - 3s 39ms/step - loss: 0.0282 - val_loss: 0.0203\n",
      "Epoch 11/80\n",
      "87/87 [==============================] - 3s 36ms/step - loss: 0.0269 - val_loss: 0.0138\n",
      "Epoch 12/80\n",
      "87/87 [==============================] - 3s 37ms/step - loss: 0.0255 - val_loss: 0.0111\n",
      "Epoch 13/80\n",
      "87/87 [==============================] - 3s 36ms/step - loss: 0.0245 - val_loss: 0.0111\n",
      "Epoch 14/80\n",
      "87/87 [==============================] - 3s 35ms/step - loss: 0.0240 - val_loss: 0.0120\n",
      "Epoch 15/80\n",
      "87/87 [==============================] - 3s 35ms/step - loss: 0.0239 - val_loss: 0.0129\n",
      "Epoch 16/80\n",
      "87/87 [==============================] - 3s 35ms/step - loss: 0.0238 - val_loss: 0.0127\n",
      "Epoch 17/80\n",
      "87/87 [==============================] - 3s 37ms/step - loss: 0.0237 - val_loss: 0.0128\n",
      "Epoch 18/80\n",
      "87/87 [==============================] - 3s 36ms/step - loss: 0.0237 - val_loss: 0.0131\n",
      "Epoch 19/80\n",
      "87/87 [==============================] - 3s 35ms/step - loss: 0.0237 - val_loss: 0.0130\n",
      "Epoch 20/80\n",
      "87/87 [==============================] - 3s 35ms/step - loss: 0.0236 - val_loss: 0.0132\n",
      "Epoch 21/80\n",
      "87/87 [==============================] - 3s 35ms/step - loss: 0.0236 - val_loss: 0.0137\n",
      "Epoch 22/80\n",
      "87/87 [==============================] - 3s 36ms/step - loss: 0.0236 - val_loss: 0.0133\n",
      "Epoch 23/80\n",
      "87/87 [==============================] - 3s 36ms/step - loss: 0.0236 - val_loss: 0.0134\n",
      "Epoch 24/80\n",
      "87/87 [==============================] - 3s 35ms/step - loss: 0.0236 - val_loss: 0.0135\n",
      "Epoch 25/80\n",
      "87/87 [==============================] - 3s 35ms/step - loss: 0.0236 - val_loss: 0.0136\n",
      "Epoch 26/80\n",
      "87/87 [==============================] - 3s 35ms/step - loss: 0.0236 - val_loss: 0.0133\n",
      "Epoch 27/80\n",
      "87/87 [==============================] - 3s 36ms/step - loss: 0.0236 - val_loss: 0.0133\n",
      "Epoch 28/80\n",
      "87/87 [==============================] - 3s 36ms/step - loss: 0.0236 - val_loss: 0.0134\n",
      "Epoch 29/80\n",
      "87/87 [==============================] - 3s 35ms/step - loss: 0.0236 - val_loss: 0.0135\n",
      "Epoch 30/80\n",
      "87/87 [==============================] - 3s 35ms/step - loss: 0.0235 - val_loss: 0.0136\n",
      "Epoch 31/80\n",
      "87/87 [==============================] - 3s 35ms/step - loss: 0.0235 - val_loss: 0.0132\n",
      "Epoch 32/80\n",
      "87/87 [==============================] - 3s 36ms/step - loss: 0.0235 - val_loss: 0.0133\n",
      "Epoch 33/80\n",
      "87/87 [==============================] - 3s 37ms/step - loss: 0.0235 - val_loss: 0.0134\n",
      "Epoch 34/80\n",
      "87/87 [==============================] - 3s 35ms/step - loss: 0.0235 - val_loss: 0.0134\n",
      "Epoch 35/80\n",
      "87/87 [==============================] - 3s 35ms/step - loss: 0.0235 - val_loss: 0.0135\n",
      "Epoch 36/80\n",
      "87/87 [==============================] - 3s 35ms/step - loss: 0.0235 - val_loss: 0.0133\n",
      "Epoch 37/80\n",
      "87/87 [==============================] - 3s 36ms/step - loss: 0.0235 - val_loss: 0.0134\n",
      "Epoch 38/80\n",
      "87/87 [==============================] - 3s 37ms/step - loss: 0.0235 - val_loss: 0.0135\n",
      "Epoch 39/80\n",
      "87/87 [==============================] - 3s 35ms/step - loss: 0.0235 - val_loss: 0.0135\n",
      "Epoch 40/80\n",
      "87/87 [==============================] - 3s 35ms/step - loss: 0.0235 - val_loss: 0.0134\n",
      "Epoch 41/80\n",
      "87/87 [==============================] - 3s 35ms/step - loss: 0.0235 - val_loss: 0.0134\n",
      "Epoch 42/80\n",
      "87/87 [==============================] - 3s 35ms/step - loss: 0.0235 - val_loss: 0.0135\n",
      "Epoch 43/80\n",
      "87/87 [==============================] - 3s 37ms/step - loss: 0.0235 - val_loss: 0.0133\n",
      "Epoch 44/80\n",
      "87/87 [==============================] - 3s 35ms/step - loss: 0.0235 - val_loss: 0.0134\n",
      "Epoch 45/80\n",
      "87/87 [==============================] - 3s 35ms/step - loss: 0.0235 - val_loss: 0.0135\n",
      "Epoch 46/80\n",
      "87/87 [==============================] - 3s 35ms/step - loss: 0.0235 - val_loss: 0.0135\n",
      "Epoch 47/80\n",
      "87/87 [==============================] - 3s 36ms/step - loss: 0.0235 - val_loss: 0.0134\n",
      "Epoch 48/80\n",
      "87/87 [==============================] - 3s 37ms/step - loss: 0.0235 - val_loss: 0.0134\n",
      "Epoch 49/80\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "87/87 [==============================] - 3s 35ms/step - loss: 0.0235 - val_loss: 0.0135\n",
      "Epoch 50/80\n",
      "87/87 [==============================] - 3s 35ms/step - loss: 0.0235 - val_loss: 0.0133\n",
      "Epoch 51/80\n",
      "87/87 [==============================] - 3s 35ms/step - loss: 0.0235 - val_loss: 0.0134\n",
      "Epoch 52/80\n",
      "87/87 [==============================] - 3s 35ms/step - loss: 0.0235 - val_loss: 0.0134\n",
      "Epoch 53/80\n",
      "87/87 [==============================] - 3s 37ms/step - loss: 0.0235 - val_loss: 0.0135\n",
      "Epoch 54/80\n",
      "87/87 [==============================] - 3s 35ms/step - loss: 0.0235 - val_loss: 0.0133\n",
      "Epoch 55/80\n",
      "87/87 [==============================] - 3s 35ms/step - loss: 0.0235 - val_loss: 0.0134\n",
      "Epoch 56/80\n",
      "87/87 [==============================] - 3s 36ms/step - loss: 0.0235 - val_loss: 0.0134\n",
      "Epoch 57/80\n",
      "87/87 [==============================] - 3s 35ms/step - loss: 0.0235 - val_loss: 0.0135\n",
      "Epoch 58/80\n",
      "87/87 [==============================] - 3s 37ms/step - loss: 0.0235 - val_loss: 0.0133\n",
      "Epoch 59/80\n",
      "87/87 [==============================] - 3s 35ms/step - loss: 0.0235 - val_loss: 0.0134\n",
      "Epoch 60/80\n",
      "87/87 [==============================] - 3s 35ms/step - loss: 0.0235 - val_loss: 0.0134\n",
      "Epoch 61/80\n",
      "87/87 [==============================] - 3s 35ms/step - loss: 0.0235 - val_loss: 0.0135\n",
      "Epoch 62/80\n",
      "87/87 [==============================] - 3s 35ms/step - loss: 0.0235 - val_loss: 0.0133\n",
      "Epoch 63/80\n",
      "87/87 [==============================] - 3s 37ms/step - loss: 0.0235 - val_loss: 0.0134\n",
      "Epoch 64/80\n",
      "87/87 [==============================] - 3s 35ms/step - loss: 0.0235 - val_loss: 0.0134\n",
      "Epoch 65/80\n",
      "87/87 [==============================] - 3s 35ms/step - loss: 0.0235 - val_loss: 0.0135\n",
      "Epoch 66/80\n",
      "87/87 [==============================] - 3s 35ms/step - loss: 0.0235 - val_loss: 0.0133\n",
      "Epoch 67/80\n",
      "87/87 [==============================] - 3s 36ms/step - loss: 0.0235 - val_loss: 0.0134\n",
      "Epoch 68/80\n",
      "87/87 [==============================] - 3s 37ms/step - loss: 0.0235 - val_loss: 0.0134\n",
      "Epoch 69/80\n",
      "87/87 [==============================] - 3s 35ms/step - loss: 0.0235 - val_loss: 0.0135\n",
      "Epoch 70/80\n",
      "87/87 [==============================] - 3s 35ms/step - loss: 0.0235 - val_loss: 0.0133\n",
      "Epoch 71/80\n",
      "87/87 [==============================] - 3s 35ms/step - loss: 0.0235 - val_loss: 0.0134\n",
      "Epoch 72/80\n",
      "87/87 [==============================] - 3s 35ms/step - loss: 0.0235 - val_loss: 0.0134\n",
      "Epoch 73/80\n",
      "87/87 [==============================] - 3s 37ms/step - loss: 0.0235 - val_loss: 0.0135\n",
      "Epoch 74/80\n",
      "87/87 [==============================] - 3s 36ms/step - loss: 0.0235 - val_loss: 0.0133\n",
      "Epoch 75/80\n",
      "87/87 [==============================] - 3s 35ms/step - loss: 0.0235 - val_loss: 0.0134\n",
      "Epoch 76/80\n",
      "87/87 [==============================] - 3s 35ms/step - loss: 0.0235 - val_loss: 0.0134\n",
      "Epoch 77/80\n",
      "87/87 [==============================] - 3s 35ms/step - loss: 0.0235 - val_loss: 0.0135\n",
      "Epoch 78/80\n",
      "87/87 [==============================] - 3s 36ms/step - loss: 0.0235 - val_loss: 0.0133\n",
      "Epoch 79/80\n",
      "87/87 [==============================] - 3s 36ms/step - loss: 0.0235 - val_loss: 0.0136\n",
      "Epoch 80/80\n",
      "87/87 [==============================] - 3s 35ms/step - loss: 0.0235 - val_loss: 0.0133\n",
      "Execution time:  253.01840329170227\n",
      "DNN:\n",
      "Mean Absolute Error: 0.0259\n",
      "Root Mean Square Error: 0.0468\n",
      "Mean Square Error: 0.0022\n",
      "\n",
      "Train RMSE: 0.047\n",
      "Train MSE: 0.002\n",
      "Train MAE: 0.026\n",
      "###########################\n",
      "\n",
      "MODEL:  DNN\n",
      "sequence:  7d\n",
      "units:  80\n",
      "dropout1:  0.11814836227952394\n",
      "optimizer: adam\n",
      "activationDense: tanh\n",
      "epochs: 90\n",
      "batchsize: 25\n",
      "validation_split: 0.1\n",
      "Model: \"sequential_217\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_651 (Dense)            (None, 1008, 80)          160       \n",
      "_________________________________________________________________\n",
      "dense_652 (Dense)            (None, 1008, 16)          1296      \n",
      "_________________________________________________________________\n",
      "dropout_217 (Dropout)        (None, 1008, 16)          0         \n",
      "_________________________________________________________________\n",
      "dense_653 (Dense)            (None, 1008, 1)           17        \n",
      "=================================================================\n",
      "Total params: 1,473\n",
      "Trainable params: 1,473\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/90\n",
      "108/108 [==============================] - 3s 29ms/step - loss: 0.1233 - val_loss: 0.0232\n",
      "Epoch 2/90\n",
      "108/108 [==============================] - 3s 27ms/step - loss: 0.0529 - val_loss: 0.0153\n",
      "Epoch 3/90\n",
      "108/108 [==============================] - 3s 29ms/step - loss: 0.0498 - val_loss: 0.0090\n",
      "Epoch 4/90\n",
      "108/108 [==============================] - 3s 27ms/step - loss: 0.0470 - val_loss: 0.0061\n",
      "Epoch 5/90\n",
      "108/108 [==============================] - 3s 27ms/step - loss: 0.0441 - val_loss: 0.0062\n",
      "Epoch 6/90\n",
      "108/108 [==============================] - 3s 27ms/step - loss: 0.0418 - val_loss: 0.0071\n",
      "Epoch 7/90\n",
      "108/108 [==============================] - 3s 27ms/step - loss: 0.0397 - val_loss: 0.0081\n",
      "Epoch 8/90\n",
      "108/108 [==============================] - 3s 29ms/step - loss: 0.0376 - val_loss: 0.0078\n",
      "Epoch 9/90\n",
      "108/108 [==============================] - 3s 28ms/step - loss: 0.0359 - val_loss: 0.0082\n",
      "Epoch 10/90\n",
      "108/108 [==============================] - 3s 27ms/step - loss: 0.0343 - val_loss: 0.0092\n",
      "Epoch 11/90\n",
      "108/108 [==============================] - 3s 27ms/step - loss: 0.0323 - val_loss: 0.0094\n",
      "Epoch 12/90\n",
      "108/108 [==============================] - 3s 27ms/step - loss: 0.0320 - val_loss: 0.0051\n",
      "Epoch 13/90\n",
      "108/108 [==============================] - 3s 28ms/step - loss: 0.0311 - val_loss: 0.0084\n",
      "Epoch 14/90\n",
      "108/108 [==============================] - 3s 29ms/step - loss: 0.0301 - val_loss: 0.0110\n",
      "Epoch 15/90\n",
      "108/108 [==============================] - 3s 27ms/step - loss: 0.0290 - val_loss: 0.0130\n",
      "Epoch 16/90\n",
      "108/108 [==============================] - 3s 27ms/step - loss: 0.0286 - val_loss: 0.0172\n",
      "Epoch 17/90\n",
      "108/108 [==============================] - 3s 27ms/step - loss: 0.0281 - val_loss: 0.0211\n",
      "Epoch 18/90\n",
      "108/108 [==============================] - 3s 28ms/step - loss: 0.0276 - val_loss: 0.0231\n",
      "Epoch 19/90\n",
      "108/108 [==============================] - 3s 29ms/step - loss: 0.0272 - val_loss: 0.0144\n",
      "Epoch 20/90\n",
      "108/108 [==============================] - 3s 27ms/step - loss: 0.0267 - val_loss: 0.0234\n",
      "Epoch 21/90\n",
      "108/108 [==============================] - 3s 27ms/step - loss: 0.0266 - val_loss: 0.0227\n",
      "Epoch 22/90\n",
      "108/108 [==============================] - 3s 27ms/step - loss: 0.0263 - val_loss: 0.0192\n",
      "Epoch 23/90\n",
      "108/108 [==============================] - 3s 27ms/step - loss: 0.0259 - val_loss: 0.0227\n",
      "Epoch 24/90\n",
      "108/108 [==============================] - 3s 29ms/step - loss: 0.0256 - val_loss: 0.0212\n",
      "Epoch 25/90\n",
      "108/108 [==============================] - 3s 28ms/step - loss: 0.0255 - val_loss: 0.0193\n",
      "Epoch 26/90\n",
      "108/108 [==============================] - 3s 27ms/step - loss: 0.0254 - val_loss: 0.0182\n",
      "Epoch 27/90\n",
      "108/108 [==============================] - 3s 27ms/step - loss: 0.0252 - val_loss: 0.0175\n",
      "Epoch 28/90\n",
      "108/108 [==============================] - 3s 27ms/step - loss: 0.0251 - val_loss: 0.0163\n",
      "Epoch 29/90\n",
      "108/108 [==============================] - 3s 29ms/step - loss: 0.0249 - val_loss: 0.0158\n",
      "Epoch 30/90\n",
      "108/108 [==============================] - 3s 28ms/step - loss: 0.0248 - val_loss: 0.0150\n",
      "Epoch 31/90\n",
      "108/108 [==============================] - 3s 27ms/step - loss: 0.0247 - val_loss: 0.0141\n",
      "Epoch 32/90\n",
      "108/108 [==============================] - 3s 27ms/step - loss: 0.0246 - val_loss: 0.0136\n",
      "Epoch 33/90\n",
      "108/108 [==============================] - 3s 27ms/step - loss: 0.0244 - val_loss: 0.0134\n",
      "Epoch 34/90\n",
      "108/108 [==============================] - 3s 28ms/step - loss: 0.0244 - val_loss: 0.0131\n",
      "Epoch 35/90\n",
      "108/108 [==============================] - 3s 28ms/step - loss: 0.0244 - val_loss: 0.0124\n",
      "Epoch 36/90\n",
      "108/108 [==============================] - 3s 27ms/step - loss: 0.0243 - val_loss: 0.0125\n",
      "Epoch 37/90\n",
      "108/108 [==============================] - 3s 27ms/step - loss: 0.0243 - val_loss: 0.0122\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 38/90\n",
      "108/108 [==============================] - 3s 27ms/step - loss: 0.0242 - val_loss: 0.0120\n",
      "Epoch 39/90\n",
      "108/108 [==============================] - 3s 28ms/step - loss: 0.0241 - val_loss: 0.0123\n",
      "Epoch 40/90\n",
      "108/108 [==============================] - 3s 29ms/step - loss: 0.0241 - val_loss: 0.0121\n",
      "Epoch 41/90\n",
      "108/108 [==============================] - 3s 27ms/step - loss: 0.0239 - val_loss: 0.0117\n",
      "Epoch 42/90\n",
      "108/108 [==============================] - 3s 27ms/step - loss: 0.0238 - val_loss: 0.0118\n",
      "Epoch 43/90\n",
      "108/108 [==============================] - 3s 27ms/step - loss: 0.0237 - val_loss: 0.0115\n",
      "Epoch 44/90\n",
      "108/108 [==============================] - 3s 27ms/step - loss: 0.0237 - val_loss: 0.0115\n",
      "Epoch 45/90\n",
      "108/108 [==============================] - 3s 29ms/step - loss: 0.0237 - val_loss: 0.0113\n",
      "Epoch 46/90\n",
      "108/108 [==============================] - 3s 28ms/step - loss: 0.0239 - val_loss: 0.0171\n",
      "Epoch 47/90\n",
      "108/108 [==============================] - 3s 27ms/step - loss: 0.0238 - val_loss: 0.0112\n",
      "Epoch 48/90\n",
      "108/108 [==============================] - 3s 27ms/step - loss: 0.0236 - val_loss: 0.0113\n",
      "Epoch 49/90\n",
      "108/108 [==============================] - 3s 27ms/step - loss: 0.0236 - val_loss: 0.0120\n",
      "Epoch 50/90\n",
      "108/108 [==============================] - 3s 28ms/step - loss: 0.0237 - val_loss: 0.0119\n",
      "Epoch 51/90\n",
      "108/108 [==============================] - 3s 29ms/step - loss: 0.0237 - val_loss: 0.0124\n",
      "Epoch 52/90\n",
      "108/108 [==============================] - 3s 28ms/step - loss: 0.0236 - val_loss: 0.0118\n",
      "Epoch 53/90\n",
      "108/108 [==============================] - 3s 27ms/step - loss: 0.0236 - val_loss: 0.0123\n",
      "Epoch 54/90\n",
      "108/108 [==============================] - 3s 27ms/step - loss: 0.0236 - val_loss: 0.0118\n",
      "Epoch 55/90\n",
      "108/108 [==============================] - 3s 28ms/step - loss: 0.0236 - val_loss: 0.0122\n",
      "Epoch 56/90\n",
      "108/108 [==============================] - 3s 29ms/step - loss: 0.0235 - val_loss: 0.0118\n",
      "Epoch 57/90\n",
      "108/108 [==============================] - 3s 27ms/step - loss: 0.0235 - val_loss: 0.0119\n",
      "Epoch 58/90\n",
      "108/108 [==============================] - 3s 27ms/step - loss: 0.0235 - val_loss: 0.0118\n",
      "Epoch 59/90\n",
      "108/108 [==============================] - 3s 27ms/step - loss: 0.0235 - val_loss: 0.0120\n",
      "Epoch 60/90\n",
      "108/108 [==============================] - 3s 27ms/step - loss: 0.0235 - val_loss: 0.0119\n",
      "Epoch 61/90\n",
      "108/108 [==============================] - 3s 29ms/step - loss: 0.0235 - val_loss: 0.0119\n",
      "Epoch 62/90\n",
      "108/108 [==============================] - 3s 28ms/step - loss: 0.0236 - val_loss: 0.0121\n",
      "Epoch 63/90\n",
      "108/108 [==============================] - 3s 27ms/step - loss: 0.0235 - val_loss: 0.0119\n",
      "Epoch 64/90\n",
      "108/108 [==============================] - 3s 27ms/step - loss: 0.0236 - val_loss: 0.0121\n",
      "Epoch 65/90\n",
      "108/108 [==============================] - 3s 27ms/step - loss: 0.0235 - val_loss: 0.0121\n",
      "Epoch 66/90\n",
      "108/108 [==============================] - 3s 28ms/step - loss: 0.0235 - val_loss: 0.0119\n",
      "Epoch 67/90\n",
      "108/108 [==============================] - 3s 28ms/step - loss: 0.0236 - val_loss: 0.0121\n",
      "Epoch 68/90\n",
      "108/108 [==============================] - 3s 27ms/step - loss: 0.0235 - val_loss: 0.0121\n",
      "Epoch 69/90\n",
      "108/108 [==============================] - 3s 27ms/step - loss: 0.0235 - val_loss: 0.0119\n",
      "Epoch 70/90\n",
      "108/108 [==============================] - 3s 27ms/step - loss: 0.0236 - val_loss: 0.0121\n",
      "Epoch 71/90\n",
      "108/108 [==============================] - 3s 28ms/step - loss: 0.0235 - val_loss: 0.0121\n",
      "Epoch 72/90\n",
      "108/108 [==============================] - 3s 28ms/step - loss: 0.0235 - val_loss: 0.0119\n",
      "Epoch 73/90\n",
      "108/108 [==============================] - 3s 28ms/step - loss: 0.0236 - val_loss: 0.0121\n",
      "Epoch 74/90\n",
      "108/108 [==============================] - 3s 27ms/step - loss: 0.0235 - val_loss: 0.0120\n",
      "Epoch 75/90\n",
      "108/108 [==============================] - 3s 27ms/step - loss: 0.0236 - val_loss: 0.0121\n",
      "Epoch 76/90\n",
      "108/108 [==============================] - 3s 27ms/step - loss: 0.0235 - val_loss: 0.0121\n",
      "Epoch 77/90\n",
      "108/108 [==============================] - 3s 29ms/step - loss: 0.0235 - val_loss: 0.0120\n",
      "Epoch 78/90\n",
      "108/108 [==============================] - 3s 27ms/step - loss: 0.0236 - val_loss: 0.0121\n",
      "Epoch 79/90\n",
      "108/108 [==============================] - 3s 27ms/step - loss: 0.0235 - val_loss: 0.0121\n",
      "Epoch 80/90\n",
      "108/108 [==============================] - 3s 27ms/step - loss: 0.0235 - val_loss: 0.0119\n",
      "Epoch 81/90\n",
      "108/108 [==============================] - 3s 27ms/step - loss: 0.0236 - val_loss: 0.0121\n",
      "Epoch 82/90\n",
      "108/108 [==============================] - 3s 28ms/step - loss: 0.0235 - val_loss: 0.0121\n",
      "Epoch 83/90\n",
      "108/108 [==============================] - 3s 28ms/step - loss: 0.0236 - val_loss: 0.0122\n",
      "Epoch 84/90\n",
      "108/108 [==============================] - 3s 28ms/step - loss: 0.0235 - val_loss: 0.0122\n",
      "Epoch 85/90\n",
      "108/108 [==============================] - 3s 28ms/step - loss: 0.0235 - val_loss: 0.0121\n",
      "Epoch 86/90\n",
      "108/108 [==============================] - 3s 27ms/step - loss: 0.0235 - val_loss: 0.0121\n",
      "Epoch 87/90\n",
      "108/108 [==============================] - 3s 28ms/step - loss: 0.0236 - val_loss: 0.0122\n",
      "Epoch 88/90\n",
      "108/108 [==============================] - 3s 28ms/step - loss: 0.0235 - val_loss: 0.0122\n",
      "Epoch 89/90\n",
      "108/108 [==============================] - 3s 28ms/step - loss: 0.0235 - val_loss: 0.0121\n",
      "Epoch 90/90\n",
      "108/108 [==============================] - 3s 27ms/step - loss: 0.0235 - val_loss: 0.0121\n",
      "Execution time:  273.2143096923828\n",
      "DNN:\n",
      "Mean Absolute Error: 0.0261\n",
      "Root Mean Square Error: 0.0474\n",
      "Mean Square Error: 0.0022\n",
      "\n",
      "Train RMSE: 0.047\n",
      "Train MSE: 0.002\n",
      "Train MAE: 0.026\n",
      "###########################\n",
      "\n",
      "MODEL:  DNN\n",
      "sequence:  7d\n",
      "units:  12\n",
      "dropout1:  0.48476373451509647\n",
      "optimizer: adam\n",
      "activationDense: tanh\n",
      "epochs: 52\n",
      "batchsize: 57\n",
      "validation_split: 0.1\n",
      "Model: \"sequential_218\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_654 (Dense)            (None, 1008, 12)          24        \n",
      "_________________________________________________________________\n",
      "dense_655 (Dense)            (None, 1008, 16)          208       \n",
      "_________________________________________________________________\n",
      "dropout_218 (Dropout)        (None, 1008, 16)          0         \n",
      "_________________________________________________________________\n",
      "dense_656 (Dense)            (None, 1008, 1)           17        \n",
      "=================================================================\n",
      "Total params: 249\n",
      "Trainable params: 249\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/52\n",
      "48/48 [==============================] - 2s 33ms/step - loss: 0.3213 - val_loss: 0.1849\n",
      "Epoch 2/52\n",
      "48/48 [==============================] - 1s 30ms/step - loss: 0.1496 - val_loss: 0.0079\n",
      "Epoch 3/52\n",
      "48/48 [==============================] - 2s 32ms/step - loss: 0.1076 - val_loss: 0.0182\n",
      "Epoch 4/52\n",
      "48/48 [==============================] - 2s 32ms/step - loss: 0.0948 - val_loss: 0.0062\n",
      "Epoch 5/52\n",
      "48/48 [==============================] - 1s 31ms/step - loss: 0.0835 - val_loss: 0.0177\n",
      "Epoch 6/52\n",
      "48/48 [==============================] - 1s 30ms/step - loss: 0.0776 - val_loss: 0.0159\n",
      "Epoch 7/52\n",
      "48/48 [==============================] - 1s 30ms/step - loss: 0.0722 - val_loss: 0.0145\n",
      "Epoch 8/52\n",
      "48/48 [==============================] - 1s 30ms/step - loss: 0.0668 - val_loss: 0.0131\n",
      "Epoch 9/52\n",
      "48/48 [==============================] - 1s 31ms/step - loss: 0.0613 - val_loss: 0.0118\n",
      "Epoch 10/52\n",
      "48/48 [==============================] - 1s 30ms/step - loss: 0.0560 - val_loss: 0.0096\n",
      "Epoch 11/52\n",
      "48/48 [==============================] - 1s 30ms/step - loss: 0.0509 - val_loss: 0.0072\n",
      "Epoch 12/52\n",
      "48/48 [==============================] - 1s 30ms/step - loss: 0.0460 - val_loss: 0.0053\n",
      "Epoch 13/52\n",
      "48/48 [==============================] - 1s 30ms/step - loss: 0.0413 - val_loss: 0.0049\n",
      "Epoch 14/52\n",
      "48/48 [==============================] - 2s 32ms/step - loss: 0.0370 - val_loss: 0.0061\n",
      "Epoch 15/52\n",
      "48/48 [==============================] - 2s 31ms/step - loss: 0.0334 - val_loss: 0.0071\n",
      "Epoch 16/52\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "48/48 [==============================] - 1s 30ms/step - loss: 0.0307 - val_loss: 0.0074\n",
      "Epoch 17/52\n",
      "48/48 [==============================] - 1s 30ms/step - loss: 0.0285 - val_loss: 0.0079\n",
      "Epoch 18/52\n",
      "48/48 [==============================] - 1s 30ms/step - loss: 0.0265 - val_loss: 0.0092\n",
      "Epoch 19/52\n",
      "48/48 [==============================] - 1s 30ms/step - loss: 0.0253 - val_loss: 0.0123\n",
      "Epoch 20/52\n",
      "48/48 [==============================] - 1s 31ms/step - loss: 0.0253 - val_loss: 0.0140\n",
      "Epoch 21/52\n",
      "48/48 [==============================] - 1s 29ms/step - loss: 0.0242 - val_loss: 0.0158\n",
      "Epoch 22/52\n",
      "48/48 [==============================] - 1s 31ms/step - loss: 0.0237 - val_loss: 0.0152\n",
      "Epoch 23/52\n",
      "48/48 [==============================] - 1s 30ms/step - loss: 0.0234 - val_loss: 0.0147\n",
      "Epoch 24/52\n",
      "48/48 [==============================] - 1s 30ms/step - loss: 0.0233 - val_loss: 0.0146\n",
      "Epoch 25/52\n",
      "48/48 [==============================] - 2s 32ms/step - loss: 0.0233 - val_loss: 0.0145\n",
      "Epoch 26/52\n",
      "48/48 [==============================] - 1s 31ms/step - loss: 0.0233 - val_loss: 0.0145\n",
      "Epoch 27/52\n",
      "48/48 [==============================] - 1s 30ms/step - loss: 0.0233 - val_loss: 0.0144\n",
      "Epoch 28/52\n",
      "48/48 [==============================] - 1s 30ms/step - loss: 0.0233 - val_loss: 0.0144\n",
      "Epoch 29/52\n",
      "48/48 [==============================] - 1s 30ms/step - loss: 0.0233 - val_loss: 0.0143\n",
      "Epoch 30/52\n",
      "48/48 [==============================] - 1s 30ms/step - loss: 0.0232 - val_loss: 0.0144\n",
      "Epoch 31/52\n",
      "48/48 [==============================] - 1s 29ms/step - loss: 0.0232 - val_loss: 0.0140\n",
      "Epoch 32/52\n",
      "48/48 [==============================] - 1s 31ms/step - loss: 0.0232 - val_loss: 0.0142\n",
      "Epoch 33/52\n",
      "48/48 [==============================] - 1s 30ms/step - loss: 0.0232 - val_loss: 0.0142\n",
      "Epoch 34/52\n",
      "48/48 [==============================] - 1s 30ms/step - loss: 0.0232 - val_loss: 0.0142\n",
      "Epoch 35/52\n",
      "48/48 [==============================] - 1s 31ms/step - loss: 0.0232 - val_loss: 0.0142\n",
      "Epoch 36/52\n",
      "48/48 [==============================] - 2s 33ms/step - loss: 0.0232 - val_loss: 0.0142\n",
      "Epoch 37/52\n",
      "48/48 [==============================] - 2s 31ms/step - loss: 0.0232 - val_loss: 0.0141\n",
      "Epoch 38/52\n",
      "48/48 [==============================] - 1s 30ms/step - loss: 0.0232 - val_loss: 0.0142\n",
      "Epoch 39/52\n",
      "48/48 [==============================] - 1s 30ms/step - loss: 0.0232 - val_loss: 0.0141\n",
      "Epoch 40/52\n",
      "48/48 [==============================] - 1s 30ms/step - loss: 0.0232 - val_loss: 0.0142\n",
      "Epoch 41/52\n",
      "48/48 [==============================] - 1s 30ms/step - loss: 0.0232 - val_loss: 0.0142\n",
      "Epoch 42/52\n",
      "48/48 [==============================] - 1s 30ms/step - loss: 0.0231 - val_loss: 0.0140\n",
      "Epoch 43/52\n",
      "48/48 [==============================] - 1s 30ms/step - loss: 0.0232 - val_loss: 0.0142\n",
      "Epoch 44/52\n",
      "48/48 [==============================] - 1s 30ms/step - loss: 0.0231 - val_loss: 0.0140\n",
      "Epoch 45/52\n",
      "48/48 [==============================] - 1s 30ms/step - loss: 0.0232 - val_loss: 0.0141\n",
      "Epoch 46/52\n",
      "48/48 [==============================] - 2s 33ms/step - loss: 0.0231 - val_loss: 0.0139\n",
      "Epoch 47/52\n",
      "48/48 [==============================] - 2s 32ms/step - loss: 0.0232 - val_loss: 0.0141\n",
      "Epoch 48/52\n",
      "48/48 [==============================] - 1s 30ms/step - loss: 0.0231 - val_loss: 0.0141\n",
      "Epoch 49/52\n",
      "48/48 [==============================] - 1s 30ms/step - loss: 0.0231 - val_loss: 0.0139\n",
      "Epoch 50/52\n",
      "48/48 [==============================] - 1s 30ms/step - loss: 0.0231 - val_loss: 0.0141\n",
      "Epoch 51/52\n",
      "48/48 [==============================] - 1s 30ms/step - loss: 0.0231 - val_loss: 0.0139\n",
      "Epoch 52/52\n",
      "48/48 [==============================] - 1s 29ms/step - loss: 0.0231 - val_loss: 0.0140\n",
      "Execution time:  78.57191014289856\n",
      "DNN:\n",
      "Mean Absolute Error: 0.0259\n",
      "Root Mean Square Error: 0.0465\n",
      "Mean Square Error: 0.0022\n",
      "\n",
      "Train RMSE: 0.047\n",
      "Train MSE: 0.002\n",
      "Train MAE: 0.026\n",
      "###########################\n",
      "\n",
      "MODEL:  DNN\n",
      "sequence:  7d\n",
      "units:  87\n",
      "dropout1:  0.40519643149940265\n",
      "optimizer: adam\n",
      "activationDense: tanh\n",
      "epochs: 80\n",
      "batchsize: 31\n",
      "validation_split: 0.2\n",
      "Model: \"sequential_219\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_657 (Dense)            (None, 1008, 87)          174       \n",
      "_________________________________________________________________\n",
      "dense_658 (Dense)            (None, 1008, 16)          1408      \n",
      "_________________________________________________________________\n",
      "dropout_219 (Dropout)        (None, 1008, 16)          0         \n",
      "_________________________________________________________________\n",
      "dense_659 (Dense)            (None, 1008, 1)           17        \n",
      "=================================================================\n",
      "Total params: 1,599\n",
      "Trainable params: 1,599\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/80\n",
      "77/77 [==============================] - 3s 39ms/step - loss: 0.1639 - val_loss: 0.0417\n",
      "Epoch 2/80\n",
      "77/77 [==============================] - 3s 38ms/step - loss: 0.0897 - val_loss: 0.0248\n",
      "Epoch 3/80\n",
      "77/77 [==============================] - 3s 38ms/step - loss: 0.0806 - val_loss: 0.0174\n",
      "Epoch 4/80\n",
      "77/77 [==============================] - 3s 37ms/step - loss: 0.0728 - val_loss: 0.0114\n",
      "Epoch 5/80\n",
      "77/77 [==============================] - 3s 37ms/step - loss: 0.0621 - val_loss: 0.0134\n",
      "Epoch 6/80\n",
      "77/77 [==============================] - 3s 37ms/step - loss: 0.0557 - val_loss: 0.0132\n",
      "Epoch 7/80\n",
      "77/77 [==============================] - 3s 37ms/step - loss: 0.0499 - val_loss: 0.0137\n",
      "Epoch 8/80\n",
      "77/77 [==============================] - 3s 39ms/step - loss: 0.0445 - val_loss: 0.0130\n",
      "Epoch 9/80\n",
      "77/77 [==============================] - 3s 37ms/step - loss: 0.0401 - val_loss: 0.0131\n",
      "Epoch 10/80\n",
      "77/77 [==============================] - 3s 36ms/step - loss: 0.0368 - val_loss: 0.0134\n",
      "Epoch 11/80\n",
      "77/77 [==============================] - 3s 37ms/step - loss: 0.0343 - val_loss: 0.0107\n",
      "Epoch 12/80\n",
      "77/77 [==============================] - 3s 37ms/step - loss: 0.0320 - val_loss: 0.0103\n",
      "Epoch 13/80\n",
      "77/77 [==============================] - 3s 38ms/step - loss: 0.0303 - val_loss: 0.0104\n",
      "Epoch 14/80\n",
      "77/77 [==============================] - 3s 38ms/step - loss: 0.0294 - val_loss: 0.0103\n",
      "Epoch 15/80\n",
      "77/77 [==============================] - 3s 36ms/step - loss: 0.0272 - val_loss: 0.0102\n",
      "Epoch 16/80\n",
      "77/77 [==============================] - 3s 37ms/step - loss: 0.0264 - val_loss: 0.0102\n",
      "Epoch 17/80\n",
      "77/77 [==============================] - 3s 37ms/step - loss: 0.0260 - val_loss: 0.0115\n",
      "Epoch 18/80\n",
      "77/77 [==============================] - 3s 37ms/step - loss: 0.0258 - val_loss: 0.0115\n",
      "Epoch 19/80\n",
      "77/77 [==============================] - 3s 39ms/step - loss: 0.0257 - val_loss: 0.0119\n",
      "Epoch 20/80\n",
      "77/77 [==============================] - 3s 37ms/step - loss: 0.0256 - val_loss: 0.0119\n",
      "Epoch 21/80\n",
      "77/77 [==============================] - 3s 37ms/step - loss: 0.0255 - val_loss: 0.0120\n",
      "Epoch 22/80\n",
      "77/77 [==============================] - 3s 37ms/step - loss: 0.0254 - val_loss: 0.0121\n",
      "Epoch 23/80\n",
      "77/77 [==============================] - 3s 36ms/step - loss: 0.0254 - val_loss: 0.0122\n",
      "Epoch 24/80\n",
      "77/77 [==============================] - 3s 38ms/step - loss: 0.0253 - val_loss: 0.0122\n",
      "Epoch 25/80\n",
      "77/77 [==============================] - 3s 38ms/step - loss: 0.0253 - val_loss: 0.0123\n",
      "Epoch 26/80\n",
      "77/77 [==============================] - 3s 37ms/step - loss: 0.0252 - val_loss: 0.0123\n",
      "Epoch 27/80\n",
      "77/77 [==============================] - 3s 37ms/step - loss: 0.0252 - val_loss: 0.0123\n",
      "Epoch 28/80\n",
      "77/77 [==============================] - 3s 36ms/step - loss: 0.0252 - val_loss: 0.0122\n",
      "Epoch 29/80\n",
      "77/77 [==============================] - 3s 37ms/step - loss: 0.0252 - val_loss: 0.0123\n",
      "Epoch 30/80\n",
      "77/77 [==============================] - 3s 39ms/step - loss: 0.0252 - val_loss: 0.0123\n",
      "Epoch 31/80\n",
      "77/77 [==============================] - 3s 37ms/step - loss: 0.0252 - val_loss: 0.0123\n",
      "Epoch 32/80\n",
      "77/77 [==============================] - 3s 37ms/step - loss: 0.0252 - val_loss: 0.0121\n",
      "Epoch 33/80\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "77/77 [==============================] - 3s 37ms/step - loss: 0.0252 - val_loss: 0.0122\n",
      "Epoch 34/80\n",
      "77/77 [==============================] - 3s 36ms/step - loss: 0.0252 - val_loss: 0.0122\n",
      "Epoch 35/80\n",
      "77/77 [==============================] - 3s 37ms/step - loss: 0.0252 - val_loss: 0.0123\n",
      "Epoch 36/80\n",
      "77/77 [==============================] - 3s 38ms/step - loss: 0.0251 - val_loss: 0.0123\n",
      "Epoch 37/80\n",
      "77/77 [==============================] - 3s 36ms/step - loss: 0.0252 - val_loss: 0.0121\n",
      "Epoch 38/80\n",
      "77/77 [==============================] - 3s 37ms/step - loss: 0.0251 - val_loss: 0.0121\n",
      "Epoch 39/80\n",
      "77/77 [==============================] - 3s 37ms/step - loss: 0.0251 - val_loss: 0.0122\n",
      "Epoch 40/80\n",
      "77/77 [==============================] - 3s 36ms/step - loss: 0.0251 - val_loss: 0.0123\n",
      "Epoch 41/80\n",
      "77/77 [==============================] - 3s 38ms/step - loss: 0.0251 - val_loss: 0.0123\n",
      "Epoch 42/80\n",
      "77/77 [==============================] - 3s 37ms/step - loss: 0.0251 - val_loss: 0.0120\n",
      "Epoch 43/80\n",
      "77/77 [==============================] - 3s 36ms/step - loss: 0.0251 - val_loss: 0.0122\n",
      "Epoch 44/80\n",
      "77/77 [==============================] - 3s 36ms/step - loss: 0.0251 - val_loss: 0.0123\n",
      "Epoch 45/80\n",
      "77/77 [==============================] - 3s 37ms/step - loss: 0.0251 - val_loss: 0.0123\n",
      "Epoch 46/80\n",
      "77/77 [==============================] - 3s 37ms/step - loss: 0.0251 - val_loss: 0.0120\n",
      "Epoch 47/80\n",
      "77/77 [==============================] - 3s 38ms/step - loss: 0.0251 - val_loss: 0.0122\n",
      "Epoch 48/80\n",
      "77/77 [==============================] - 3s 36ms/step - loss: 0.0251 - val_loss: 0.0123\n",
      "Epoch 49/80\n",
      "77/77 [==============================] - 3s 37ms/step - loss: 0.0251 - val_loss: 0.0120\n",
      "Epoch 50/80\n",
      "77/77 [==============================] - 3s 36ms/step - loss: 0.0251 - val_loss: 0.0122\n",
      "Epoch 51/80\n",
      "77/77 [==============================] - 3s 36ms/step - loss: 0.0251 - val_loss: 0.0123\n",
      "Epoch 52/80\n",
      "77/77 [==============================] - 3s 39ms/step - loss: 0.0251 - val_loss: 0.0120\n",
      "Epoch 53/80\n",
      "77/77 [==============================] - 3s 37ms/step - loss: 0.0251 - val_loss: 0.0123\n",
      "Epoch 54/80\n",
      "77/77 [==============================] - 3s 37ms/step - loss: 0.0251 - val_loss: 0.0121\n",
      "Epoch 55/80\n",
      "77/77 [==============================] - 3s 36ms/step - loss: 0.0251 - val_loss: 0.0122\n",
      "Epoch 56/80\n",
      "77/77 [==============================] - 3s 36ms/step - loss: 0.0251 - val_loss: 0.0123\n",
      "Epoch 57/80\n",
      "77/77 [==============================] - 3s 37ms/step - loss: 0.0251 - val_loss: 0.0121\n",
      "Epoch 58/80\n",
      "77/77 [==============================] - 3s 39ms/step - loss: 0.0251 - val_loss: 0.0123\n",
      "Epoch 59/80\n",
      "77/77 [==============================] - 3s 36ms/step - loss: 0.0251 - val_loss: 0.0120\n",
      "Epoch 60/80\n",
      "77/77 [==============================] - 3s 37ms/step - loss: 0.0251 - val_loss: 0.0121\n",
      "Epoch 61/80\n",
      "77/77 [==============================] - 3s 37ms/step - loss: 0.0251 - val_loss: 0.0123\n",
      "Epoch 62/80\n",
      "77/77 [==============================] - 3s 37ms/step - loss: 0.0251 - val_loss: 0.0120\n",
      "Epoch 63/80\n",
      "77/77 [==============================] - 3s 38ms/step - loss: 0.0251 - val_loss: 0.0122\n",
      "Epoch 64/80\n",
      "77/77 [==============================] - 3s 37ms/step - loss: 0.0251 - val_loss: 0.0123\n",
      "Epoch 65/80\n",
      "77/77 [==============================] - 3s 36ms/step - loss: 0.0251 - val_loss: 0.0120\n",
      "Epoch 66/80\n",
      "77/77 [==============================] - 3s 36ms/step - loss: 0.0251 - val_loss: 0.0121\n",
      "Epoch 67/80\n",
      "77/77 [==============================] - 3s 37ms/step - loss: 0.0251 - val_loss: 0.0122\n",
      "Epoch 68/80\n",
      "77/77 [==============================] - 3s 37ms/step - loss: 0.0251 - val_loss: 0.0121\n",
      "Epoch 69/80\n",
      "77/77 [==============================] - 3s 38ms/step - loss: 0.0251 - val_loss: 0.0122\n",
      "Epoch 70/80\n",
      "77/77 [==============================] - 3s 37ms/step - loss: 0.0251 - val_loss: 0.0123\n",
      "Epoch 71/80\n",
      "77/77 [==============================] - 3s 37ms/step - loss: 0.0251 - val_loss: 0.0120\n",
      "Epoch 72/80\n",
      "77/77 [==============================] - 3s 37ms/step - loss: 0.0251 - val_loss: 0.0121\n",
      "Epoch 73/80\n",
      "77/77 [==============================] - 3s 37ms/step - loss: 0.0251 - val_loss: 0.0123\n",
      "Epoch 74/80\n",
      "77/77 [==============================] - 3s 39ms/step - loss: 0.0251 - val_loss: 0.0121\n",
      "Epoch 75/80\n",
      "77/77 [==============================] - 3s 37ms/step - loss: 0.0251 - val_loss: 0.0122\n",
      "Epoch 76/80\n",
      "77/77 [==============================] - 3s 37ms/step - loss: 0.0251 - val_loss: 0.0121\n",
      "Epoch 77/80\n",
      "77/77 [==============================] - 3s 37ms/step - loss: 0.0251 - val_loss: 0.0122\n",
      "Epoch 78/80\n",
      "77/77 [==============================] - 3s 36ms/step - loss: 0.0251 - val_loss: 0.0123\n",
      "Epoch 79/80\n",
      "77/77 [==============================] - 3s 37ms/step - loss: 0.0251 - val_loss: 0.0120\n",
      "Epoch 80/80\n",
      "77/77 [==============================] - 3s 38ms/step - loss: 0.0251 - val_loss: 0.0122\n",
      "Execution time:  232.92282390594482\n",
      "DNN:\n",
      "Mean Absolute Error: 0.0259\n",
      "Root Mean Square Error: 0.0465\n",
      "Mean Square Error: 0.0022\n",
      "\n",
      "Train RMSE: 0.047\n",
      "Train MSE: 0.002\n",
      "Train MAE: 0.026\n",
      "###########################\n",
      "\n",
      "MODEL:  DNN\n",
      "sequence:  7d\n",
      "units:  80\n",
      "dropout1:  0.11814836227952394\n",
      "optimizer: adam\n",
      "activationDense: tanh\n",
      "epochs: 90\n",
      "batchsize: 25\n",
      "validation_split: 0.2\n",
      "Model: \"sequential_220\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_660 (Dense)            (None, 1008, 80)          160       \n",
      "_________________________________________________________________\n",
      "dense_661 (Dense)            (None, 1008, 16)          1296      \n",
      "_________________________________________________________________\n",
      "dropout_220 (Dropout)        (None, 1008, 16)          0         \n",
      "_________________________________________________________________\n",
      "dense_662 (Dense)            (None, 1008, 1)           17        \n",
      "=================================================================\n",
      "Total params: 1,473\n",
      "Trainable params: 1,473\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/90\n",
      "96/96 [==============================] - 3s 30ms/step - loss: 0.0968 - val_loss: 0.0135\n",
      "Epoch 2/90\n",
      "96/96 [==============================] - 3s 28ms/step - loss: 0.0512 - val_loss: 0.0175\n",
      "Epoch 3/90\n",
      "96/96 [==============================] - 3s 28ms/step - loss: 0.0479 - val_loss: 0.0198\n",
      "Epoch 4/90\n",
      "96/96 [==============================] - 3s 29ms/step - loss: 0.0454 - val_loss: 0.0228\n",
      "Epoch 5/90\n",
      "96/96 [==============================] - 3s 30ms/step - loss: 0.0434 - val_loss: 0.0243\n",
      "Epoch 6/90\n",
      "96/96 [==============================] - 3s 28ms/step - loss: 0.0418 - val_loss: 0.0238\n",
      "Epoch 7/90\n",
      "96/96 [==============================] - 3s 28ms/step - loss: 0.0404 - val_loss: 0.0231\n",
      "Epoch 8/90\n",
      "96/96 [==============================] - 3s 28ms/step - loss: 0.0392 - val_loss: 0.0241\n",
      "Epoch 9/90\n",
      "96/96 [==============================] - 3s 28ms/step - loss: 0.0381 - val_loss: 0.0222\n",
      "Epoch 10/90\n",
      "96/96 [==============================] - 3s 29ms/step - loss: 0.0371 - val_loss: 0.0225\n",
      "Epoch 11/90\n",
      "96/96 [==============================] - 3s 29ms/step - loss: 0.0362 - val_loss: 0.0212\n",
      "Epoch 12/90\n",
      "96/96 [==============================] - 3s 28ms/step - loss: 0.0355 - val_loss: 0.0202\n",
      "Epoch 13/90\n",
      "96/96 [==============================] - 3s 28ms/step - loss: 0.0346 - val_loss: 0.0184\n",
      "Epoch 14/90\n",
      "96/96 [==============================] - 3s 28ms/step - loss: 0.0340 - val_loss: 0.0176\n",
      "Epoch 15/90\n",
      "96/96 [==============================] - 3s 29ms/step - loss: 0.0333 - val_loss: 0.0169\n",
      "Epoch 16/90\n",
      "96/96 [==============================] - 3s 30ms/step - loss: 0.0326 - val_loss: 0.0163\n",
      "Epoch 17/90\n",
      "96/96 [==============================] - 3s 29ms/step - loss: 0.0321 - val_loss: 0.0167\n",
      "Epoch 18/90\n",
      "96/96 [==============================] - 3s 28ms/step - loss: 0.0317 - val_loss: 0.0144\n",
      "Epoch 19/90\n",
      "96/96 [==============================] - 3s 28ms/step - loss: 0.0316 - val_loss: 0.0127\n",
      "Epoch 20/90\n",
      "96/96 [==============================] - 3s 29ms/step - loss: 0.0306 - val_loss: 0.0173\n",
      "Epoch 21/90\n",
      "96/96 [==============================] - 3s 29ms/step - loss: 0.0315 - val_loss: 0.0181\n",
      "Epoch 22/90\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "96/96 [==============================] - 3s 30ms/step - loss: 0.0303 - val_loss: 0.0154\n",
      "Epoch 23/90\n",
      "96/96 [==============================] - 3s 28ms/step - loss: 0.0302 - val_loss: 0.0131\n",
      "Epoch 24/90\n",
      "96/96 [==============================] - 3s 28ms/step - loss: 0.0298 - val_loss: 0.0117\n",
      "Epoch 25/90\n",
      "96/96 [==============================] - 3s 28ms/step - loss: 0.0295 - val_loss: 0.0106\n",
      "Epoch 26/90\n",
      "96/96 [==============================] - 3s 28ms/step - loss: 0.0290 - val_loss: 0.0104\n",
      "Epoch 27/90\n",
      "96/96 [==============================] - 3s 29ms/step - loss: 0.0286 - val_loss: 0.0104\n",
      "Epoch 28/90\n",
      "96/96 [==============================] - 3s 29ms/step - loss: 0.0284 - val_loss: 0.0104\n",
      "Epoch 29/90\n",
      "96/96 [==============================] - 3s 28ms/step - loss: 0.0281 - val_loss: 0.0103\n",
      "Epoch 30/90\n",
      "96/96 [==============================] - 3s 28ms/step - loss: 0.0277 - val_loss: 0.0104\n",
      "Epoch 31/90\n",
      "96/96 [==============================] - 3s 28ms/step - loss: 0.0276 - val_loss: 0.0102\n",
      "Epoch 32/90\n",
      "96/96 [==============================] - 3s 28ms/step - loss: 0.0273 - val_loss: 0.0103\n",
      "Epoch 33/90\n",
      "96/96 [==============================] - 3s 29ms/step - loss: 0.0271 - val_loss: 0.0103\n",
      "Epoch 34/90\n",
      "96/96 [==============================] - 3s 29ms/step - loss: 0.0269 - val_loss: 0.0103\n",
      "Epoch 35/90\n",
      "96/96 [==============================] - 3s 28ms/step - loss: 0.0268 - val_loss: 0.0103\n",
      "Epoch 36/90\n",
      "96/96 [==============================] - 3s 28ms/step - loss: 0.0266 - val_loss: 0.0103\n",
      "Epoch 37/90\n",
      "96/96 [==============================] - 3s 28ms/step - loss: 0.0265 - val_loss: 0.0103\n",
      "Epoch 38/90\n",
      "96/96 [==============================] - 3s 28ms/step - loss: 0.0264 - val_loss: 0.0102\n",
      "Epoch 39/90\n",
      "96/96 [==============================] - 3s 30ms/step - loss: 0.0264 - val_loss: 0.0101\n",
      "Epoch 40/90\n",
      "96/96 [==============================] - 3s 29ms/step - loss: 0.0263 - val_loss: 0.0102\n",
      "Epoch 41/90\n",
      "96/96 [==============================] - 3s 28ms/step - loss: 0.0262 - val_loss: 0.0102\n",
      "Epoch 42/90\n",
      "96/96 [==============================] - 3s 28ms/step - loss: 0.0261 - val_loss: 0.0102\n",
      "Epoch 43/90\n",
      "96/96 [==============================] - 3s 28ms/step - loss: 0.0260 - val_loss: 0.0102\n",
      "Epoch 44/90\n",
      "96/96 [==============================] - 3s 28ms/step - loss: 0.0260 - val_loss: 0.0101\n",
      "Epoch 45/90\n",
      "96/96 [==============================] - 3s 30ms/step - loss: 0.0259 - val_loss: 0.0101\n",
      "Epoch 46/90\n",
      "96/96 [==============================] - 3s 28ms/step - loss: 0.0258 - val_loss: 0.0101\n",
      "Epoch 47/90\n",
      "96/96 [==============================] - 3s 28ms/step - loss: 0.0258 - val_loss: 0.0101\n",
      "Epoch 48/90\n",
      "96/96 [==============================] - 3s 28ms/step - loss: 0.0257 - val_loss: 0.0102\n",
      "Epoch 49/90\n",
      "96/96 [==============================] - 3s 28ms/step - loss: 0.0257 - val_loss: 0.0101\n",
      "Epoch 50/90\n",
      "96/96 [==============================] - 3s 29ms/step - loss: 0.0258 - val_loss: 0.0102\n",
      "Epoch 51/90\n",
      "96/96 [==============================] - 3s 30ms/step - loss: 0.0257 - val_loss: 0.0102\n",
      "Epoch 52/90\n",
      "96/96 [==============================] - 3s 28ms/step - loss: 0.0256 - val_loss: 0.0103\n",
      "Epoch 53/90\n",
      "96/96 [==============================] - 3s 29ms/step - loss: 0.0256 - val_loss: 0.0104\n",
      "Epoch 54/90\n",
      "96/96 [==============================] - 3s 28ms/step - loss: 0.0255 - val_loss: 0.0105\n",
      "Epoch 55/90\n",
      "96/96 [==============================] - 3s 28ms/step - loss: 0.0258 - val_loss: 0.0102\n",
      "Epoch 56/90\n",
      "96/96 [==============================] - 3s 29ms/step - loss: 0.0235 - val_loss: 0.0166\n",
      "Epoch 57/90\n",
      "96/96 [==============================] - 3s 29ms/step - loss: 0.0274 - val_loss: 0.0107\n",
      "Epoch 58/90\n",
      "96/96 [==============================] - 3s 29ms/step - loss: 0.0254 - val_loss: 0.0105\n",
      "Epoch 59/90\n",
      "96/96 [==============================] - 3s 28ms/step - loss: 0.0253 - val_loss: 0.0106\n",
      "Epoch 60/90\n",
      "96/96 [==============================] - 3s 28ms/step - loss: 0.0252 - val_loss: 0.0108\n",
      "Epoch 61/90\n",
      "96/96 [==============================] - 3s 28ms/step - loss: 0.0253 - val_loss: 0.0112\n",
      "Epoch 62/90\n",
      "96/96 [==============================] - 3s 30ms/step - loss: 0.0254 - val_loss: 0.0115\n",
      "Epoch 63/90\n",
      "96/96 [==============================] - 3s 29ms/step - loss: 0.0254 - val_loss: 0.0113\n",
      "Epoch 64/90\n",
      "96/96 [==============================] - 3s 28ms/step - loss: 0.0253 - val_loss: 0.0115\n",
      "Epoch 65/90\n",
      "96/96 [==============================] - 3s 28ms/step - loss: 0.0253 - val_loss: 0.0112\n",
      "Epoch 66/90\n",
      "96/96 [==============================] - 3s 28ms/step - loss: 0.0252 - val_loss: 0.0116\n",
      "Epoch 67/90\n",
      "96/96 [==============================] - 3s 29ms/step - loss: 0.0252 - val_loss: 0.0111\n",
      "Epoch 68/90\n",
      "96/96 [==============================] - 3s 30ms/step - loss: 0.0252 - val_loss: 0.0116\n",
      "Epoch 69/90\n",
      "96/96 [==============================] - 3s 28ms/step - loss: 0.0252 - val_loss: 0.0112\n",
      "Epoch 70/90\n",
      "96/96 [==============================] - 3s 28ms/step - loss: 0.0251 - val_loss: 0.0114\n",
      "Epoch 71/90\n",
      "96/96 [==============================] - 3s 28ms/step - loss: 0.0251 - val_loss: 0.0115\n",
      "Epoch 72/90\n",
      "96/96 [==============================] - 3s 28ms/step - loss: 0.0252 - val_loss: 0.0112\n",
      "Epoch 73/90\n",
      "96/96 [==============================] - 3s 29ms/step - loss: 0.0251 - val_loss: 0.0116\n",
      "Epoch 74/90\n",
      "96/96 [==============================] - 3s 29ms/step - loss: 0.0252 - val_loss: 0.0113\n",
      "Epoch 75/90\n",
      "96/96 [==============================] - 3s 28ms/step - loss: 0.0251 - val_loss: 0.0114\n",
      "Epoch 76/90\n",
      "96/96 [==============================] - 3s 28ms/step - loss: 0.0252 - val_loss: 0.0113\n",
      "Epoch 77/90\n",
      "96/96 [==============================] - 3s 28ms/step - loss: 0.0251 - val_loss: 0.0114\n",
      "Epoch 78/90\n",
      "96/96 [==============================] - 3s 28ms/step - loss: 0.0252 - val_loss: 0.0112\n",
      "Epoch 79/90\n",
      "96/96 [==============================] - 3s 30ms/step - loss: 0.0251 - val_loss: 0.0117\n",
      "Epoch 80/90\n",
      "96/96 [==============================] - 3s 29ms/step - loss: 0.0252 - val_loss: 0.0114\n",
      "Epoch 81/90\n",
      "96/96 [==============================] - 3s 28ms/step - loss: 0.0251 - val_loss: 0.0115\n",
      "Epoch 82/90\n",
      "96/96 [==============================] - 3s 28ms/step - loss: 0.0252 - val_loss: 0.0113\n",
      "Epoch 83/90\n",
      "96/96 [==============================] - 3s 28ms/step - loss: 0.0251 - val_loss: 0.0114\n",
      "Epoch 84/90\n",
      "96/96 [==============================] - 3s 28ms/step - loss: 0.0251 - val_loss: 0.0113\n",
      "Epoch 85/90\n",
      "96/96 [==============================] - 3s 30ms/step - loss: 0.0251 - val_loss: 0.0114\n",
      "Epoch 86/90\n",
      "96/96 [==============================] - 3s 29ms/step - loss: 0.0251 - val_loss: 0.0144\n",
      "Epoch 87/90\n",
      "96/96 [==============================] - 3s 29ms/step - loss: 0.0255 - val_loss: 0.0107\n",
      "Epoch 88/90\n",
      "96/96 [==============================] - 3s 28ms/step - loss: 0.0247 - val_loss: 0.0136\n",
      "Epoch 89/90\n",
      "96/96 [==============================] - 3s 28ms/step - loss: 0.0255 - val_loss: 0.0117\n",
      "Epoch 90/90\n",
      "96/96 [==============================] - 3s 29ms/step - loss: 0.0252 - val_loss: 0.0114\n",
      "Execution time:  251.77310180664062\n",
      "DNN:\n",
      "Mean Absolute Error: 0.0260\n",
      "Root Mean Square Error: 0.0471\n",
      "Mean Square Error: 0.0022\n",
      "\n",
      "Train RMSE: 0.047\n",
      "Train MSE: 0.002\n",
      "Train MAE: 0.026\n",
      "###########################\n",
      "\n",
      "MODEL:  DNN\n",
      "sequence:  7d\n",
      "units:  12\n",
      "dropout1:  0.48476373451509647\n",
      "optimizer: adam\n",
      "activationDense: tanh\n",
      "epochs: 52\n",
      "batchsize: 57\n",
      "validation_split: 0.2\n",
      "Model: \"sequential_221\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_663 (Dense)            (None, 1008, 12)          24        \n",
      "_________________________________________________________________\n",
      "dense_664 (Dense)            (None, 1008, 16)          208       \n",
      "_________________________________________________________________\n",
      "dropout_221 (Dropout)        (None, 1008, 16)          0         \n",
      "_________________________________________________________________\n",
      "dense_665 (Dense)            (None, 1008, 1)           17        \n",
      "=================================================================\n",
      "Total params: 249\n",
      "Trainable params: 249\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/52\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42/42 [==============================] - 1s 36ms/step - loss: 0.1956 - val_loss: 0.0539\n",
      "Epoch 2/52\n",
      "42/42 [==============================] - 1s 30ms/step - loss: 0.1290 - val_loss: 0.0327\n",
      "Epoch 3/52\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 0.1178 - val_loss: 0.0256\n",
      "Epoch 4/52\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 0.1073 - val_loss: 0.0132\n",
      "Epoch 5/52\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 0.0984 - val_loss: 0.0118\n",
      "Epoch 6/52\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 0.0906 - val_loss: 0.0115\n",
      "Epoch 7/52\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 0.0828 - val_loss: 0.0113\n",
      "Epoch 8/52\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 0.0751 - val_loss: 0.0112\n",
      "Epoch 9/52\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 0.0675 - val_loss: 0.0111\n",
      "Epoch 10/52\n",
      "42/42 [==============================] - 1s 33ms/step - loss: 0.0604 - val_loss: 0.0110\n",
      "Epoch 11/52\n",
      "42/42 [==============================] - 1s 35ms/step - loss: 0.0537 - val_loss: 0.0109\n",
      "Epoch 12/52\n",
      "42/42 [==============================] - 1s 32ms/step - loss: 0.0480 - val_loss: 0.0108\n",
      "Epoch 13/52\n",
      "42/42 [==============================] - 1s 32ms/step - loss: 0.0429 - val_loss: 0.0112\n",
      "Epoch 14/52\n",
      "42/42 [==============================] - 1s 32ms/step - loss: 0.0383 - val_loss: 0.0124\n",
      "Epoch 15/52\n",
      "42/42 [==============================] - 1s 32ms/step - loss: 0.0344 - val_loss: 0.0117\n",
      "Epoch 16/52\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 0.0317 - val_loss: 0.0114\n",
      "Epoch 17/52\n",
      "42/42 [==============================] - 1s 32ms/step - loss: 0.0305 - val_loss: 0.0130\n",
      "Epoch 18/52\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 0.0281 - val_loss: 0.0105\n",
      "Epoch 19/52\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 0.0269 - val_loss: 0.0155\n",
      "Epoch 20/52\n",
      "42/42 [==============================] - 1s 32ms/step - loss: 0.0260 - val_loss: 0.0131\n",
      "Epoch 21/52\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 0.0252 - val_loss: 0.0136\n",
      "Epoch 22/52\n",
      "42/42 [==============================] - 1s 34ms/step - loss: 0.0249 - val_loss: 0.0132\n",
      "Epoch 23/52\n",
      "42/42 [==============================] - 1s 33ms/step - loss: 0.0249 - val_loss: 0.0129\n",
      "Epoch 24/52\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 0.0249 - val_loss: 0.0126\n",
      "Epoch 25/52\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 0.0249 - val_loss: 0.0124\n",
      "Epoch 26/52\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 0.0248 - val_loss: 0.0123\n",
      "Epoch 27/52\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 0.0249 - val_loss: 0.0127\n",
      "Epoch 28/52\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 0.0248 - val_loss: 0.0126\n",
      "Epoch 29/52\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 0.0248 - val_loss: 0.0124\n",
      "Epoch 30/52\n",
      "42/42 [==============================] - 1s 32ms/step - loss: 0.0248 - val_loss: 0.0123\n",
      "Epoch 31/52\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 0.0248 - val_loss: 0.0122\n",
      "Epoch 32/52\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 0.0248 - val_loss: 0.0127\n",
      "Epoch 33/52\n",
      "42/42 [==============================] - 1s 32ms/step - loss: 0.0247 - val_loss: 0.0125\n",
      "Epoch 34/52\n",
      "42/42 [==============================] - 1s 35ms/step - loss: 0.0247 - val_loss: 0.0124\n",
      "Epoch 35/52\n",
      "42/42 [==============================] - 1s 33ms/step - loss: 0.0247 - val_loss: 0.0123\n",
      "Epoch 36/52\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 0.0247 - val_loss: 0.0121\n",
      "Epoch 37/52\n",
      "42/42 [==============================] - 1s 32ms/step - loss: 0.0248 - val_loss: 0.0126\n",
      "Epoch 38/52\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 0.0247 - val_loss: 0.0125\n",
      "Epoch 39/52\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 0.0247 - val_loss: 0.0124\n",
      "Epoch 40/52\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 0.0247 - val_loss: 0.0123\n",
      "Epoch 41/52\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 0.0247 - val_loss: 0.0122\n",
      "Epoch 42/52\n",
      "42/42 [==============================] - 1s 32ms/step - loss: 0.0247 - val_loss: 0.0121\n",
      "Epoch 43/52\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 0.0247 - val_loss: 0.0125\n",
      "Epoch 44/52\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 0.0247 - val_loss: 0.0124\n",
      "Epoch 45/52\n",
      "42/42 [==============================] - 1s 32ms/step - loss: 0.0247 - val_loss: 0.0122\n",
      "Epoch 46/52\n",
      "42/42 [==============================] - 1s 34ms/step - loss: 0.0247 - val_loss: 0.0122\n",
      "Epoch 47/52\n",
      "42/42 [==============================] - 1s 32ms/step - loss: 0.0247 - val_loss: 0.0121\n",
      "Epoch 48/52\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 0.0247 - val_loss: 0.0120\n",
      "Epoch 49/52\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 0.0247 - val_loss: 0.0125\n",
      "Epoch 50/52\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 0.0247 - val_loss: 0.0124\n",
      "Epoch 51/52\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 0.0247 - val_loss: 0.0123\n",
      "Epoch 52/52\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 0.0246 - val_loss: 0.0123\n",
      "Execution time:  72.3345251083374\n",
      "DNN:\n",
      "Mean Absolute Error: 0.0258\n",
      "Root Mean Square Error: 0.0461\n",
      "Mean Square Error: 0.0021\n",
      "\n",
      "Train RMSE: 0.046\n",
      "Train MSE: 0.002\n",
      "Train MAE: 0.026\n",
      "###########################\n",
      "\n",
      "MODEL:  DNN\n",
      "sequence:  7d\n",
      "units:  87\n",
      "dropout1:  0.40519643149940265\n",
      "optimizer: adam\n",
      "activationDense: sigmoid\n",
      "epochs: 80\n",
      "batchsize: 31\n",
      "validation_split: 0.1\n",
      "Model: \"sequential_222\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_666 (Dense)            (None, 1008, 87)          174       \n",
      "_________________________________________________________________\n",
      "dense_667 (Dense)            (None, 1008, 16)          1408      \n",
      "_________________________________________________________________\n",
      "dropout_222 (Dropout)        (None, 1008, 16)          0         \n",
      "_________________________________________________________________\n",
      "dense_668 (Dense)            (None, 1008, 1)           17        \n",
      "=================================================================\n",
      "Total params: 1,599\n",
      "Trainable params: 1,599\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/80\n",
      "87/87 [==============================] - 3s 37ms/step - loss: 0.0535 - val_loss: 0.0263\n",
      "Epoch 2/80\n",
      "87/87 [==============================] - 3s 37ms/step - loss: 0.0369 - val_loss: 0.0235\n",
      "Epoch 3/80\n",
      "87/87 [==============================] - 3s 36ms/step - loss: 0.0354 - val_loss: 0.0232\n",
      "Epoch 4/80\n",
      "87/87 [==============================] - 3s 35ms/step - loss: 0.0342 - val_loss: 0.0225\n",
      "Epoch 5/80\n",
      "87/87 [==============================] - 3s 35ms/step - loss: 0.0332 - val_loss: 0.0214\n",
      "Epoch 6/80\n",
      "87/87 [==============================] - 3s 35ms/step - loss: 0.0322 - val_loss: 0.0207\n",
      "Epoch 7/80\n",
      "87/87 [==============================] - 3s 37ms/step - loss: 0.0313 - val_loss: 0.0201\n",
      "Epoch 8/80\n",
      "87/87 [==============================] - 3s 36ms/step - loss: 0.0301 - val_loss: 0.0235\n",
      "Epoch 9/80\n",
      "87/87 [==============================] - 3s 35ms/step - loss: 0.0296 - val_loss: 0.0171\n",
      "Epoch 10/80\n",
      "87/87 [==============================] - 3s 35ms/step - loss: 0.0289 - val_loss: 0.0171\n",
      "Epoch 11/80\n",
      "87/87 [==============================] - 3s 35ms/step - loss: 0.0282 - val_loss: 0.0171\n",
      "Epoch 12/80\n",
      "87/87 [==============================] - 3s 36ms/step - loss: 0.0276 - val_loss: 0.0167\n",
      "Epoch 13/80\n",
      "87/87 [==============================] - 3s 36ms/step - loss: 0.0271 - val_loss: 0.0163\n",
      "Epoch 14/80\n",
      "87/87 [==============================] - 3s 35ms/step - loss: 0.0266 - val_loss: 0.0168\n",
      "Epoch 15/80\n",
      "87/87 [==============================] - 3s 35ms/step - loss: 0.0262 - val_loss: 0.0160\n",
      "Epoch 16/80\n",
      "87/87 [==============================] - 3s 35ms/step - loss: 0.0259 - val_loss: 0.0161\n",
      "Epoch 17/80\n",
      "87/87 [==============================] - 3s 36ms/step - loss: 0.0256 - val_loss: 0.0162\n",
      "Epoch 18/80\n",
      "87/87 [==============================] - 3s 37ms/step - loss: 0.0253 - val_loss: 0.0163\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19/80\n",
      "87/87 [==============================] - 3s 35ms/step - loss: 0.0250 - val_loss: 0.0163\n",
      "Epoch 20/80\n",
      "87/87 [==============================] - 3s 35ms/step - loss: 0.0248 - val_loss: 0.0164\n",
      "Epoch 21/80\n",
      "87/87 [==============================] - 3s 35ms/step - loss: 0.0246 - val_loss: 0.0164\n",
      "Epoch 22/80\n",
      "87/87 [==============================] - 3s 36ms/step - loss: 0.0244 - val_loss: 0.0163\n",
      "Epoch 23/80\n",
      "87/87 [==============================] - 3s 37ms/step - loss: 0.0242 - val_loss: 0.0162\n",
      "Epoch 24/80\n",
      "87/87 [==============================] - 3s 35ms/step - loss: 0.0241 - val_loss: 0.0162\n",
      "Epoch 25/80\n",
      "87/87 [==============================] - 3s 35ms/step - loss: 0.0240 - val_loss: 0.0162\n",
      "Epoch 26/80\n",
      "87/87 [==============================] - 3s 35ms/step - loss: 0.0239 - val_loss: 0.0161\n",
      "Epoch 27/80\n",
      "87/87 [==============================] - 3s 35ms/step - loss: 0.0238 - val_loss: 0.0161\n",
      "Epoch 28/80\n",
      "87/87 [==============================] - 3s 37ms/step - loss: 0.0237 - val_loss: 0.0161\n",
      "Epoch 29/80\n",
      "87/87 [==============================] - 3s 35ms/step - loss: 0.0236 - val_loss: 0.0161\n",
      "Epoch 30/80\n",
      "87/87 [==============================] - 3s 35ms/step - loss: 0.0235 - val_loss: 0.0160\n",
      "Epoch 31/80\n",
      "87/87 [==============================] - 3s 35ms/step - loss: 0.0235 - val_loss: 0.0159\n",
      "Epoch 32/80\n",
      "87/87 [==============================] - 3s 35ms/step - loss: 0.0234 - val_loss: 0.0158\n",
      "Epoch 33/80\n",
      "87/87 [==============================] - 3s 37ms/step - loss: 0.0234 - val_loss: 0.0158\n",
      "Epoch 34/80\n",
      "87/87 [==============================] - 3s 35ms/step - loss: 0.0233 - val_loss: 0.0158\n",
      "Epoch 35/80\n",
      "87/87 [==============================] - 3s 35ms/step - loss: 0.0233 - val_loss: 0.0157\n",
      "Epoch 36/80\n",
      "87/87 [==============================] - 3s 35ms/step - loss: 0.0233 - val_loss: 0.0157\n",
      "Epoch 37/80\n",
      "87/87 [==============================] - 3s 35ms/step - loss: 0.0232 - val_loss: 0.0156\n",
      "Epoch 38/80\n",
      "87/87 [==============================] - 3s 37ms/step - loss: 0.0232 - val_loss: 0.0156\n",
      "Epoch 39/80\n",
      "87/87 [==============================] - 3s 35ms/step - loss: 0.0232 - val_loss: 0.0155\n",
      "Epoch 40/80\n",
      "87/87 [==============================] - 3s 35ms/step - loss: 0.0231 - val_loss: 0.0154\n",
      "Epoch 41/80\n",
      "87/87 [==============================] - 3s 35ms/step - loss: 0.0231 - val_loss: 0.0153\n",
      "Epoch 42/80\n",
      "87/87 [==============================] - 3s 35ms/step - loss: 0.0231 - val_loss: 0.0152\n",
      "Epoch 43/80\n",
      "87/87 [==============================] - 3s 37ms/step - loss: 0.0231 - val_loss: 0.0151\n",
      "Epoch 44/80\n",
      "87/87 [==============================] - 3s 35ms/step - loss: 0.0230 - val_loss: 0.0150\n",
      "Epoch 45/80\n",
      "87/87 [==============================] - 3s 35ms/step - loss: 0.0230 - val_loss: 0.0149\n",
      "Epoch 46/80\n",
      "87/87 [==============================] - 3s 35ms/step - loss: 0.0230 - val_loss: 0.0148\n",
      "Epoch 47/80\n",
      "87/87 [==============================] - 3s 36ms/step - loss: 0.0230 - val_loss: 0.0146\n",
      "Epoch 48/80\n",
      "87/87 [==============================] - 3s 37ms/step - loss: 0.0230 - val_loss: 0.0145\n",
      "Epoch 49/80\n",
      "87/87 [==============================] - 3s 36ms/step - loss: 0.0229 - val_loss: 0.0144\n",
      "Epoch 50/80\n",
      "87/87 [==============================] - 3s 35ms/step - loss: 0.0229 - val_loss: 0.0142\n",
      "Epoch 51/80\n",
      "87/87 [==============================] - 3s 35ms/step - loss: 0.0229 - val_loss: 0.0141\n",
      "Epoch 52/80\n",
      "87/87 [==============================] - 3s 35ms/step - loss: 0.0229 - val_loss: 0.0140\n",
      "Epoch 53/80\n",
      "87/87 [==============================] - 3s 37ms/step - loss: 0.0229 - val_loss: 0.0139\n",
      "Epoch 54/80\n",
      "87/87 [==============================] - 3s 36ms/step - loss: 0.0228 - val_loss: 0.0137\n",
      "Epoch 55/80\n",
      "87/87 [==============================] - 3s 35ms/step - loss: 0.0228 - val_loss: 0.0136\n",
      "Epoch 56/80\n",
      "87/87 [==============================] - 3s 35ms/step - loss: 0.0228 - val_loss: 0.0135\n",
      "Epoch 57/80\n",
      "87/87 [==============================] - 3s 35ms/step - loss: 0.0228 - val_loss: 0.0134\n",
      "Epoch 58/80\n",
      "87/87 [==============================] - 3s 37ms/step - loss: 0.0228 - val_loss: 0.0133\n",
      "Epoch 59/80\n",
      "87/87 [==============================] - 3s 36ms/step - loss: 0.0228 - val_loss: 0.0132\n",
      "Epoch 60/80\n",
      "87/87 [==============================] - 3s 35ms/step - loss: 0.0227 - val_loss: 0.0131\n",
      "Epoch 61/80\n",
      "87/87 [==============================] - 3s 35ms/step - loss: 0.0227 - val_loss: 0.0129\n",
      "Epoch 62/80\n",
      "87/87 [==============================] - 3s 36ms/step - loss: 0.0227 - val_loss: 0.0128\n",
      "Epoch 63/80\n",
      "87/87 [==============================] - 3s 37ms/step - loss: 0.0227 - val_loss: 0.0127\n",
      "Epoch 64/80\n",
      "87/87 [==============================] - 3s 36ms/step - loss: 0.0227 - val_loss: 0.0127\n",
      "Epoch 65/80\n",
      "87/87 [==============================] - 3s 35ms/step - loss: 0.0227 - val_loss: 0.0126\n",
      "Epoch 66/80\n",
      "87/87 [==============================] - 3s 35ms/step - loss: 0.0227 - val_loss: 0.0126\n",
      "Epoch 67/80\n",
      "87/87 [==============================] - 3s 36ms/step - loss: 0.0227 - val_loss: 0.0125\n",
      "Epoch 68/80\n",
      "87/87 [==============================] - 3s 36ms/step - loss: 0.0226 - val_loss: 0.0125\n",
      "Epoch 69/80\n",
      "87/87 [==============================] - 3s 36ms/step - loss: 0.0226 - val_loss: 0.0124\n",
      "Epoch 70/80\n",
      "87/87 [==============================] - 3s 35ms/step - loss: 0.0226 - val_loss: 0.0124\n",
      "Epoch 71/80\n",
      "87/87 [==============================] - 3s 35ms/step - loss: 0.0226 - val_loss: 0.0123\n",
      "Epoch 72/80\n",
      "87/87 [==============================] - 3s 35ms/step - loss: 0.0227 - val_loss: 0.0126\n",
      "Epoch 73/80\n",
      "87/87 [==============================] - 3s 36ms/step - loss: 0.0226 - val_loss: 0.0124\n",
      "Epoch 74/80\n",
      "87/87 [==============================] - 3s 37ms/step - loss: 0.0226 - val_loss: 0.0123\n",
      "Epoch 75/80\n",
      "87/87 [==============================] - 3s 35ms/step - loss: 0.0226 - val_loss: 0.0125\n",
      "Epoch 76/80\n",
      "87/87 [==============================] - 3s 35ms/step - loss: 0.0226 - val_loss: 0.0124\n",
      "Epoch 77/80\n",
      "87/87 [==============================] - 3s 35ms/step - loss: 0.0226 - val_loss: 0.0122\n",
      "Epoch 78/80\n",
      "87/87 [==============================] - 3s 36ms/step - loss: 0.0226 - val_loss: 0.0126\n",
      "Epoch 79/80\n",
      "87/87 [==============================] - 3s 37ms/step - loss: 0.0226 - val_loss: 0.0121\n",
      "Epoch 80/80\n",
      "87/87 [==============================] - 3s 35ms/step - loss: 0.0226 - val_loss: 0.0126\n",
      "Execution time:  252.10885977745056\n",
      "DNN:\n",
      "Mean Absolute Error: 0.0260\n",
      "Root Mean Square Error: 0.0472\n",
      "Mean Square Error: 0.0022\n",
      "\n",
      "Train RMSE: 0.047\n",
      "Train MSE: 0.002\n",
      "Train MAE: 0.026\n",
      "###########################\n",
      "\n",
      "MODEL:  DNN\n",
      "sequence:  7d\n",
      "units:  80\n",
      "dropout1:  0.11814836227952394\n",
      "optimizer: adam\n",
      "activationDense: sigmoid\n",
      "epochs: 90\n",
      "batchsize: 25\n",
      "validation_split: 0.1\n",
      "Model: \"sequential_223\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_669 (Dense)            (None, 1008, 80)          160       \n",
      "_________________________________________________________________\n",
      "dense_670 (Dense)            (None, 1008, 16)          1296      \n",
      "_________________________________________________________________\n",
      "dropout_223 (Dropout)        (None, 1008, 16)          0         \n",
      "_________________________________________________________________\n",
      "dense_671 (Dense)            (None, 1008, 1)           17        \n",
      "=================================================================\n",
      "Total params: 1,473\n",
      "Trainable params: 1,473\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/90\n",
      "108/108 [==============================] - 3s 29ms/step - loss: 0.0456 - val_loss: 0.0247\n",
      "Epoch 2/90\n",
      "108/108 [==============================] - 3s 27ms/step - loss: 0.0289 - val_loss: 0.0234\n",
      "Epoch 3/90\n",
      "108/108 [==============================] - 3s 28ms/step - loss: 0.0288 - val_loss: 0.0233\n",
      "Epoch 4/90\n",
      "108/108 [==============================] - 3s 28ms/step - loss: 0.0283 - val_loss: 0.0224\n",
      "Epoch 5/90\n",
      "108/108 [==============================] - 3s 28ms/step - loss: 0.0281 - val_loss: 0.0215\n",
      "Epoch 6/90\n",
      "108/108 [==============================] - 3s 27ms/step - loss: 0.0279 - val_loss: 0.0211\n",
      "Epoch 7/90\n",
      "108/108 [==============================] - 3s 28ms/step - loss: 0.0276 - val_loss: 0.0205\n",
      "Epoch 8/90\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "108/108 [==============================] - 3s 28ms/step - loss: 0.0274 - val_loss: 0.0201\n",
      "Epoch 9/90\n",
      "108/108 [==============================] - 3s 28ms/step - loss: 0.0272 - val_loss: 0.0194\n",
      "Epoch 10/90\n",
      "108/108 [==============================] - 3s 27ms/step - loss: 0.0270 - val_loss: 0.0191\n",
      "Epoch 11/90\n",
      "108/108 [==============================] - 3s 27ms/step - loss: 0.0268 - val_loss: 0.0189\n",
      "Epoch 12/90\n",
      "108/108 [==============================] - 3s 27ms/step - loss: 0.0266 - val_loss: 0.0183\n",
      "Epoch 13/90\n",
      "108/108 [==============================] - 3s 27ms/step - loss: 0.0255 - val_loss: 0.0234\n",
      "Epoch 14/90\n",
      "108/108 [==============================] - 3s 29ms/step - loss: 0.0265 - val_loss: 0.0194\n",
      "Epoch 15/90\n",
      "108/108 [==============================] - 3s 28ms/step - loss: 0.0262 - val_loss: 0.0180\n",
      "Epoch 16/90\n",
      "108/108 [==============================] - 3s 27ms/step - loss: 0.0260 - val_loss: 0.0172\n",
      "Epoch 17/90\n",
      "108/108 [==============================] - 3s 28ms/step - loss: 0.0258 - val_loss: 0.0169\n",
      "Epoch 18/90\n",
      "108/108 [==============================] - 3s 27ms/step - loss: 0.0257 - val_loss: 0.0163\n",
      "Epoch 19/90\n",
      "108/108 [==============================] - 3s 29ms/step - loss: 0.0256 - val_loss: 0.0160\n",
      "Epoch 20/90\n",
      "108/108 [==============================] - 3s 28ms/step - loss: 0.0254 - val_loss: 0.0154\n",
      "Epoch 21/90\n",
      "108/108 [==============================] - 3s 28ms/step - loss: 0.0253 - val_loss: 0.0154\n",
      "Epoch 22/90\n",
      "108/108 [==============================] - 3s 27ms/step - loss: 0.0252 - val_loss: 0.0155\n",
      "Epoch 23/90\n",
      "108/108 [==============================] - 3s 27ms/step - loss: 0.0251 - val_loss: 0.0150\n",
      "Epoch 24/90\n",
      "108/108 [==============================] - 3s 28ms/step - loss: 0.0250 - val_loss: 0.0148\n",
      "Epoch 25/90\n",
      "108/108 [==============================] - 3s 28ms/step - loss: 0.0249 - val_loss: 0.0149\n",
      "Epoch 26/90\n",
      "108/108 [==============================] - 3s 27ms/step - loss: 0.0248 - val_loss: 0.0144\n",
      "Epoch 27/90\n",
      "108/108 [==============================] - 3s 27ms/step - loss: 0.0248 - val_loss: 0.0146\n",
      "Epoch 28/90\n",
      "108/108 [==============================] - 3s 27ms/step - loss: 0.0247 - val_loss: 0.0147\n",
      "Epoch 29/90\n",
      "108/108 [==============================] - 3s 28ms/step - loss: 0.0246 - val_loss: 0.0146\n",
      "Epoch 30/90\n",
      "108/108 [==============================] - 3s 29ms/step - loss: 0.0245 - val_loss: 0.0147\n",
      "Epoch 31/90\n",
      "108/108 [==============================] - 3s 27ms/step - loss: 0.0244 - val_loss: 0.0147\n",
      "Epoch 32/90\n",
      "108/108 [==============================] - 3s 27ms/step - loss: 0.0243 - val_loss: 0.0147\n",
      "Epoch 33/90\n",
      "108/108 [==============================] - 3s 27ms/step - loss: 0.0242 - val_loss: 0.0149\n",
      "Epoch 34/90\n",
      "108/108 [==============================] - 3s 27ms/step - loss: 0.0242 - val_loss: 0.0150\n",
      "Epoch 35/90\n",
      "108/108 [==============================] - 3s 29ms/step - loss: 0.0241 - val_loss: 0.0151\n",
      "Epoch 36/90\n",
      "108/108 [==============================] - 3s 27ms/step - loss: 0.0240 - val_loss: 0.0151\n",
      "Epoch 37/90\n",
      "108/108 [==============================] - 3s 27ms/step - loss: 0.0240 - val_loss: 0.0152\n",
      "Epoch 38/90\n",
      "108/108 [==============================] - 3s 27ms/step - loss: 0.0239 - val_loss: 0.0150\n",
      "Epoch 39/90\n",
      "108/108 [==============================] - 3s 27ms/step - loss: 0.0239 - val_loss: 0.0150\n",
      "Epoch 40/90\n",
      "108/108 [==============================] - 3s 29ms/step - loss: 0.0239 - val_loss: 0.0149\n",
      "Epoch 41/90\n",
      "108/108 [==============================] - 3s 28ms/step - loss: 0.0239 - val_loss: 0.0147\n",
      "Epoch 42/90\n",
      "108/108 [==============================] - 3s 27ms/step - loss: 0.0238 - val_loss: 0.0146\n",
      "Epoch 43/90\n",
      "108/108 [==============================] - 3s 27ms/step - loss: 0.0238 - val_loss: 0.0146\n",
      "Epoch 44/90\n",
      "108/108 [==============================] - 3s 27ms/step - loss: 0.0238 - val_loss: 0.0146\n",
      "Epoch 45/90\n",
      "108/108 [==============================] - 3s 28ms/step - loss: 0.0237 - val_loss: 0.0145\n",
      "Epoch 46/90\n",
      "108/108 [==============================] - 3s 28ms/step - loss: 0.0237 - val_loss: 0.0146\n",
      "Epoch 47/90\n",
      "108/108 [==============================] - 3s 27ms/step - loss: 0.0236 - val_loss: 0.0145\n",
      "Epoch 48/90\n",
      "108/108 [==============================] - 3s 28ms/step - loss: 0.0236 - val_loss: 0.0145\n",
      "Epoch 49/90\n",
      "108/108 [==============================] - 3s 27ms/step - loss: 0.0236 - val_loss: 0.0145\n",
      "Epoch 50/90\n",
      "108/108 [==============================] - 3s 28ms/step - loss: 0.0235 - val_loss: 0.0145\n",
      "Epoch 51/90\n",
      "108/108 [==============================] - 3s 29ms/step - loss: 0.0235 - val_loss: 0.0145\n",
      "Epoch 52/90\n",
      "108/108 [==============================] - 3s 28ms/step - loss: 0.0234 - val_loss: 0.0145\n",
      "Epoch 53/90\n",
      "108/108 [==============================] - 3s 27ms/step - loss: 0.0234 - val_loss: 0.0145\n",
      "Epoch 54/90\n",
      "108/108 [==============================] - 3s 28ms/step - loss: 0.0234 - val_loss: 0.0145\n",
      "Epoch 55/90\n",
      "108/108 [==============================] - 3s 27ms/step - loss: 0.0234 - val_loss: 0.0145\n",
      "Epoch 56/90\n",
      "108/108 [==============================] - 3s 29ms/step - loss: 0.0234 - val_loss: 0.0145\n",
      "Epoch 57/90\n",
      "108/108 [==============================] - 3s 28ms/step - loss: 0.0226 - val_loss: 0.0205\n",
      "Epoch 58/90\n",
      "108/108 [==============================] - 3s 27ms/step - loss: 0.0237 - val_loss: 0.0137\n",
      "Epoch 59/90\n",
      "108/108 [==============================] - 3s 27ms/step - loss: 0.0235 - val_loss: 0.0149\n",
      "Epoch 60/90\n",
      "108/108 [==============================] - 3s 28ms/step - loss: 0.0234 - val_loss: 0.0145\n",
      "Epoch 61/90\n",
      "108/108 [==============================] - 3s 28ms/step - loss: 0.0234 - val_loss: 0.0145\n",
      "Epoch 62/90\n",
      "108/108 [==============================] - 3s 28ms/step - loss: 0.0234 - val_loss: 0.0144\n",
      "Epoch 63/90\n",
      "108/108 [==============================] - 3s 28ms/step - loss: 0.0233 - val_loss: 0.0144\n",
      "Epoch 64/90\n",
      "108/108 [==============================] - 3s 28ms/step - loss: 0.0233 - val_loss: 0.0143\n",
      "Epoch 65/90\n",
      "108/108 [==============================] - 3s 28ms/step - loss: 0.0233 - val_loss: 0.0144\n",
      "Epoch 66/90\n",
      "108/108 [==============================] - 3s 28ms/step - loss: 0.0233 - val_loss: 0.0144\n",
      "Epoch 67/90\n",
      "108/108 [==============================] - 3s 28ms/step - loss: 0.0233 - val_loss: 0.0144\n",
      "Epoch 68/90\n",
      "108/108 [==============================] - 3s 29ms/step - loss: 0.0232 - val_loss: 0.0145\n",
      "Epoch 69/90\n",
      "108/108 [==============================] - 3s 28ms/step - loss: 0.0232 - val_loss: 0.0145\n",
      "Epoch 70/90\n",
      "108/108 [==============================] - 3s 27ms/step - loss: 0.0232 - val_loss: 0.0146\n",
      "Epoch 71/90\n",
      "108/108 [==============================] - 3s 28ms/step - loss: 0.0232 - val_loss: 0.0145\n",
      "Epoch 72/90\n",
      "108/108 [==============================] - 3s 29ms/step - loss: 0.0232 - val_loss: 0.0147\n",
      "Epoch 73/90\n",
      "108/108 [==============================] - 3s 27ms/step - loss: 0.0232 - val_loss: 0.0146\n",
      "Epoch 74/90\n",
      "108/108 [==============================] - 3s 28ms/step - loss: 0.0232 - val_loss: 0.0146\n",
      "Epoch 75/90\n",
      "108/108 [==============================] - 3s 27ms/step - loss: 0.0232 - val_loss: 0.0147\n",
      "Epoch 76/90\n",
      "108/108 [==============================] - 3s 27ms/step - loss: 0.0232 - val_loss: 0.0147\n",
      "Epoch 77/90\n",
      "108/108 [==============================] - 3s 29ms/step - loss: 0.0232 - val_loss: 0.0146\n",
      "Epoch 78/90\n",
      "108/108 [==============================] - 3s 27ms/step - loss: 0.0232 - val_loss: 0.0148\n",
      "Epoch 79/90\n",
      "108/108 [==============================] - 3s 29ms/step - loss: 0.0232 - val_loss: 0.0145\n",
      "Epoch 80/90\n",
      "108/108 [==============================] - 3s 30ms/step - loss: 0.0232 - val_loss: 0.0147\n",
      "Epoch 81/90\n",
      "108/108 [==============================] - 3s 28ms/step - loss: 0.0231 - val_loss: 0.0144\n",
      "Epoch 82/90\n",
      "108/108 [==============================] - 3s 29ms/step - loss: 0.0231 - val_loss: 0.0145\n",
      "Epoch 83/90\n",
      "108/108 [==============================] - 3s 28ms/step - loss: 0.0231 - val_loss: 0.0143\n",
      "Epoch 84/90\n",
      "108/108 [==============================] - 3s 28ms/step - loss: 0.0231 - val_loss: 0.0143\n",
      "Epoch 85/90\n",
      "108/108 [==============================] - 3s 27ms/step - loss: 0.0231 - val_loss: 0.0141\n",
      "Epoch 86/90\n",
      "108/108 [==============================] - 3s 27ms/step - loss: 0.0231 - val_loss: 0.0141\n",
      "Epoch 87/90\n",
      "108/108 [==============================] - 3s 28ms/step - loss: 0.0230 - val_loss: 0.0140\n",
      "Epoch 88/90\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "108/108 [==============================] - 3s 28ms/step - loss: 0.0230 - val_loss: 0.0139\n",
      "Epoch 89/90\n",
      "108/108 [==============================] - 3s 27ms/step - loss: 0.0230 - val_loss: 0.0138\n",
      "Epoch 90/90\n",
      "108/108 [==============================] - 3s 27ms/step - loss: 0.0230 - val_loss: 0.0138\n",
      "Execution time:  274.5630130767822\n",
      "DNN:\n",
      "Mean Absolute Error: 0.0259\n",
      "Root Mean Square Error: 0.0467\n",
      "Mean Square Error: 0.0022\n",
      "\n",
      "Train RMSE: 0.047\n",
      "Train MSE: 0.002\n",
      "Train MAE: 0.026\n",
      "###########################\n",
      "\n",
      "MODEL:  DNN\n",
      "sequence:  7d\n",
      "units:  12\n",
      "dropout1:  0.48476373451509647\n",
      "optimizer: adam\n",
      "activationDense: sigmoid\n",
      "epochs: 52\n",
      "batchsize: 57\n",
      "validation_split: 0.1\n",
      "Model: \"sequential_224\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_672 (Dense)            (None, 1008, 12)          24        \n",
      "_________________________________________________________________\n",
      "dense_673 (Dense)            (None, 1008, 16)          208       \n",
      "_________________________________________________________________\n",
      "dropout_224 (Dropout)        (None, 1008, 16)          0         \n",
      "_________________________________________________________________\n",
      "dense_674 (Dense)            (None, 1008, 1)           17        \n",
      "=================================================================\n",
      "Total params: 249\n",
      "Trainable params: 249\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/52\n",
      "48/48 [==============================] - 2s 33ms/step - loss: 0.0561 - val_loss: 0.0374\n",
      "Epoch 2/52\n",
      "48/48 [==============================] - 1s 31ms/step - loss: 0.0436 - val_loss: 0.0380\n",
      "Epoch 3/52\n",
      "48/48 [==============================] - 2s 32ms/step - loss: 0.0408 - val_loss: 0.0347\n",
      "Epoch 4/52\n",
      "48/48 [==============================] - 2s 32ms/step - loss: 0.0388 - val_loss: 0.0323\n",
      "Epoch 5/52\n",
      "48/48 [==============================] - 1s 31ms/step - loss: 0.0371 - val_loss: 0.0290\n",
      "Epoch 6/52\n",
      "48/48 [==============================] - 1s 30ms/step - loss: 0.0357 - val_loss: 0.0283\n",
      "Epoch 7/52\n",
      "48/48 [==============================] - 1s 30ms/step - loss: 0.0347 - val_loss: 0.0275\n",
      "Epoch 8/52\n",
      "48/48 [==============================] - 1s 29ms/step - loss: 0.0339 - val_loss: 0.0271\n",
      "Epoch 9/52\n",
      "48/48 [==============================] - 1s 30ms/step - loss: 0.0332 - val_loss: 0.0266\n",
      "Epoch 10/52\n",
      "48/48 [==============================] - 1s 30ms/step - loss: 0.0325 - val_loss: 0.0261\n",
      "Epoch 11/52\n",
      "48/48 [==============================] - 1s 30ms/step - loss: 0.0319 - val_loss: 0.0256\n",
      "Epoch 12/52\n",
      "48/48 [==============================] - 1s 30ms/step - loss: 0.0310 - val_loss: 0.0205\n",
      "Epoch 13/52\n",
      "48/48 [==============================] - 1s 31ms/step - loss: 0.0307 - val_loss: 0.0217\n",
      "Epoch 14/52\n",
      "48/48 [==============================] - 2s 33ms/step - loss: 0.0302 - val_loss: 0.0224\n",
      "Epoch 15/52\n",
      "48/48 [==============================] - 1s 31ms/step - loss: 0.0296 - val_loss: 0.0223\n",
      "Epoch 16/52\n",
      "48/48 [==============================] - 1s 31ms/step - loss: 0.0291 - val_loss: 0.0220\n",
      "Epoch 17/52\n",
      "48/48 [==============================] - 1s 31ms/step - loss: 0.0287 - val_loss: 0.0218\n",
      "Epoch 18/52\n",
      "48/48 [==============================] - 1s 30ms/step - loss: 0.0283 - val_loss: 0.0216\n",
      "Epoch 19/52\n",
      "48/48 [==============================] - 1s 30ms/step - loss: 0.0279 - val_loss: 0.0213\n",
      "Epoch 20/52\n",
      "48/48 [==============================] - 1s 30ms/step - loss: 0.0275 - val_loss: 0.0210\n",
      "Epoch 21/52\n",
      "48/48 [==============================] - 1s 30ms/step - loss: 0.0272 - val_loss: 0.0206: 0.027\n",
      "Epoch 22/52\n",
      "48/48 [==============================] - 1s 30ms/step - loss: 0.0269 - val_loss: 0.0204\n",
      "Epoch 23/52\n",
      "48/48 [==============================] - 1s 30ms/step - loss: 0.0266 - val_loss: 0.0201\n",
      "Epoch 24/52\n",
      "48/48 [==============================] - 2s 32ms/step - loss: 0.0263 - val_loss: 0.0199\n",
      "Epoch 25/52\n",
      "48/48 [==============================] - 2s 33ms/step - loss: 0.0261 - val_loss: 0.0196\n",
      "Epoch 26/52\n",
      "48/48 [==============================] - 1s 29ms/step - loss: 0.0258 - val_loss: 0.0194\n",
      "Epoch 27/52\n",
      "48/48 [==============================] - 1s 30ms/step - loss: 0.0261 - val_loss: 0.0187\n",
      "Epoch 28/52\n",
      "48/48 [==============================] - 1s 31ms/step - loss: 0.0254 - val_loss: 0.0189\n",
      "Epoch 29/52\n",
      "48/48 [==============================] - 1s 30ms/step - loss: 0.0252 - val_loss: 0.0188\n",
      "Epoch 30/52\n",
      "48/48 [==============================] - 1s 30ms/step - loss: 0.0251 - val_loss: 0.0186\n",
      "Epoch 31/52\n",
      "48/48 [==============================] - 1s 30ms/step - loss: 0.0249 - val_loss: 0.0184\n",
      "Epoch 32/52\n",
      "48/48 [==============================] - 1s 30ms/step - loss: 0.0247 - val_loss: 0.0182\n",
      "Epoch 33/52\n",
      "48/48 [==============================] - 1s 30ms/step - loss: 0.0246 - val_loss: 0.0180\n",
      "Epoch 34/52\n",
      "48/48 [==============================] - 1s 30ms/step - loss: 0.0244 - val_loss: 0.0178\n",
      "Epoch 35/52\n",
      "48/48 [==============================] - 2s 32ms/step - loss: 0.0243 - val_loss: 0.0177\n",
      "Epoch 36/52\n",
      "48/48 [==============================] - 2s 32ms/step - loss: 0.0242 - val_loss: 0.0176\n",
      "Epoch 37/52\n",
      "48/48 [==============================] - 1s 30ms/step - loss: 0.0241 - val_loss: 0.0175\n",
      "Epoch 38/52\n",
      "48/48 [==============================] - 1s 30ms/step - loss: 0.0240 - val_loss: 0.0174\n",
      "Epoch 39/52\n",
      "48/48 [==============================] - 1s 31ms/step - loss: 0.0239 - val_loss: 0.0173\n",
      "Epoch 40/52\n",
      "48/48 [==============================] - 1s 30ms/step - loss: 0.0238 - val_loss: 0.0172\n",
      "Epoch 41/52\n",
      "48/48 [==============================] - 1s 30ms/step - loss: 0.0237 - val_loss: 0.0171\n",
      "Epoch 42/52\n",
      "48/48 [==============================] - 1s 30ms/step - loss: 0.0237 - val_loss: 0.0171\n",
      "Epoch 43/52\n",
      "48/48 [==============================] - 1s 30ms/step - loss: 0.0236 - val_loss: 0.0170\n",
      "Epoch 44/52\n",
      "48/48 [==============================] - 1s 30ms/step - loss: 0.0235 - val_loss: 0.0169\n",
      "Epoch 45/52\n",
      "48/48 [==============================] - 1s 30ms/step - loss: 0.0235 - val_loss: 0.0168\n",
      "Epoch 46/52\n",
      "48/48 [==============================] - 2s 32ms/step - loss: 0.0234 - val_loss: 0.0167\n",
      "Epoch 47/52\n",
      "48/48 [==============================] - ETA: 0s - loss: 0.023 - 2s 32ms/step - loss: 0.0234 - val_loss: 0.0166\n",
      "Epoch 48/52\n",
      "48/48 [==============================] - 1s 30ms/step - loss: 0.0233 - val_loss: 0.0166\n",
      "Epoch 49/52\n",
      "48/48 [==============================] - 1s 30ms/step - loss: 0.0233 - val_loss: 0.0165\n",
      "Epoch 50/52\n",
      "48/48 [==============================] - 1s 30ms/step - loss: 0.0233 - val_loss: 0.0164\n",
      "Epoch 51/52\n",
      "48/48 [==============================] - 1s 30ms/step - loss: 0.0232 - val_loss: 0.0164\n",
      "Epoch 52/52\n",
      "48/48 [==============================] - 1s 30ms/step - loss: 0.0232 - val_loss: 0.0162\n",
      "Execution time:  78.71421003341675\n",
      "DNN:\n",
      "Mean Absolute Error: 0.0259\n",
      "Root Mean Square Error: 0.0462\n",
      "Mean Square Error: 0.0021\n",
      "\n",
      "Train RMSE: 0.046\n",
      "Train MSE: 0.002\n",
      "Train MAE: 0.026\n",
      "###########################\n",
      "\n",
      "MODEL:  DNN\n",
      "sequence:  7d\n",
      "units:  87\n",
      "dropout1:  0.40519643149940265\n",
      "optimizer: adam\n",
      "activationDense: sigmoid\n",
      "epochs: 80\n",
      "batchsize: 31\n",
      "validation_split: 0.2\n",
      "Model: \"sequential_225\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_675 (Dense)            (None, 1008, 87)          174       \n",
      "_________________________________________________________________\n",
      "dense_676 (Dense)            (None, 1008, 16)          1408      \n",
      "_________________________________________________________________\n",
      "dropout_225 (Dropout)        (None, 1008, 16)          0         \n",
      "_________________________________________________________________\n",
      "dense_677 (Dense)            (None, 1008, 1)           17        \n",
      "=================================================================\n",
      "Total params: 1,599\n",
      "Trainable params: 1,599\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/80\n",
      "77/77 [==============================] - 3s 39ms/step - loss: 0.0649 - val_loss: 0.0238\n",
      "Epoch 2/80\n",
      "77/77 [==============================] - 3s 38ms/step - loss: 0.0416 - val_loss: 0.0182\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/80\n",
      "77/77 [==============================] - 3s 37ms/step - loss: 0.0387 - val_loss: 0.0170\n",
      "Epoch 4/80\n",
      "77/77 [==============================] - 3s 37ms/step - loss: 0.0370 - val_loss: 0.0164\n",
      "Epoch 5/80\n",
      "77/77 [==============================] - 3s 37ms/step - loss: 0.0359 - val_loss: 0.0164\n",
      "Epoch 6/80\n",
      "77/77 [==============================] - 3s 36ms/step - loss: 0.0348 - val_loss: 0.0162\n",
      "Epoch 7/80\n",
      "77/77 [==============================] - 3s 37ms/step - loss: 0.0338 - val_loss: 0.0162\n",
      "Epoch 8/80\n",
      "77/77 [==============================] - 3s 38ms/step - loss: 0.0328 - val_loss: 0.0161\n",
      "Epoch 9/80\n",
      "77/77 [==============================] - 3s 37ms/step - loss: 0.0319 - val_loss: 0.0161\n",
      "Epoch 10/80\n",
      "77/77 [==============================] - 3s 36ms/step - loss: 0.0312 - val_loss: 0.0159\n",
      "Epoch 11/80\n",
      "77/77 [==============================] - 3s 36ms/step - loss: 0.0304 - val_loss: 0.0159\n",
      "Epoch 12/80\n",
      "77/77 [==============================] - 3s 36ms/step - loss: 0.0298 - val_loss: 0.0159\n",
      "Epoch 13/80\n",
      "77/77 [==============================] - 3s 38ms/step - loss: 0.0292 - val_loss: 0.0158\n",
      "Epoch 14/80\n",
      "77/77 [==============================] - 3s 37ms/step - loss: 0.0286 - val_loss: 0.0158\n",
      "Epoch 15/80\n",
      "77/77 [==============================] - 3s 37ms/step - loss: 0.0281 - val_loss: 0.0157\n",
      "Epoch 16/80\n",
      "77/77 [==============================] - 3s 36ms/step - loss: 0.0277 - val_loss: 0.0156\n",
      "Epoch 17/80\n",
      "77/77 [==============================] - 3s 37ms/step - loss: 0.0275 - val_loss: 0.0150\n",
      "Epoch 18/80\n",
      "77/77 [==============================] - 3s 37ms/step - loss: 0.0269 - val_loss: 0.0153\n",
      "Epoch 19/80\n",
      "77/77 [==============================] - 3s 39ms/step - loss: 0.0266 - val_loss: 0.0151\n",
      "Epoch 20/80\n",
      "77/77 [==============================] - 3s 37ms/step - loss: 0.0263 - val_loss: 0.0149\n",
      "Epoch 21/80\n",
      "77/77 [==============================] - 3s 37ms/step - loss: 0.0260 - val_loss: 0.0148\n",
      "Epoch 22/80\n",
      "77/77 [==============================] - 3s 36ms/step - loss: 0.0258 - val_loss: 0.0147\n",
      "Epoch 23/80\n",
      "77/77 [==============================] - 3s 37ms/step - loss: 0.0256 - val_loss: 0.0146\n",
      "Epoch 24/80\n",
      "77/77 [==============================] - 3s 38ms/step - loss: 0.0250 - val_loss: 0.0150\n",
      "Epoch 25/80\n",
      "77/77 [==============================] - 3s 37ms/step - loss: 0.0254 - val_loss: 0.0144\n",
      "Epoch 26/80\n",
      "77/77 [==============================] - 3s 37ms/step - loss: 0.0252 - val_loss: 0.0143\n",
      "Epoch 27/80\n",
      "77/77 [==============================] - 3s 37ms/step - loss: 0.0251 - val_loss: 0.0142\n",
      "Epoch 28/80\n",
      "77/77 [==============================] - 3s 36ms/step - loss: 0.0250 - val_loss: 0.0141\n",
      "Epoch 29/80\n",
      "77/77 [==============================] - 3s 37ms/step - loss: 0.0249 - val_loss: 0.0140\n",
      "Epoch 30/80\n",
      "77/77 [==============================] - 3s 39ms/step - loss: 0.0249 - val_loss: 0.0139\n",
      "Epoch 31/80\n",
      "77/77 [==============================] - 3s 37ms/step - loss: 0.0248 - val_loss: 0.0138\n",
      "Epoch 32/80\n",
      "77/77 [==============================] - 3s 37ms/step - loss: 0.0248 - val_loss: 0.0137\n",
      "Epoch 33/80\n",
      "77/77 [==============================] - 3s 36ms/step - loss: 0.0247 - val_loss: 0.0137\n",
      "Epoch 34/80\n",
      "77/77 [==============================] - 3s 36ms/step - loss: 0.0247 - val_loss: 0.0136\n",
      "Epoch 35/80\n",
      "77/77 [==============================] - 3s 38ms/step - loss: 0.0247 - val_loss: 0.0136\n",
      "Epoch 36/80\n",
      "77/77 [==============================] - 3s 38ms/step - loss: 0.0246 - val_loss: 0.0135\n",
      "Epoch 37/80\n",
      "77/77 [==============================] - 3s 37ms/step - loss: 0.0246 - val_loss: 0.0135\n",
      "Epoch 38/80\n",
      "77/77 [==============================] - 3s 36ms/step - loss: 0.0246 - val_loss: 0.0134\n",
      "Epoch 39/80\n",
      "77/77 [==============================] - 3s 37ms/step - loss: 0.0246 - val_loss: 0.0134\n",
      "Epoch 40/80\n",
      "77/77 [==============================] - 3s 37ms/step - loss: 0.0245 - val_loss: 0.0133\n",
      "Epoch 41/80\n",
      "77/77 [==============================] - 3s 39ms/step - loss: 0.0245 - val_loss: 0.0132\n",
      "Epoch 42/80\n",
      "77/77 [==============================] - 3s 37ms/step - loss: 0.0245 - val_loss: 0.0132\n",
      "Epoch 43/80\n",
      "77/77 [==============================] - 3s 36ms/step - loss: 0.0245 - val_loss: 0.0131\n",
      "Epoch 44/80\n",
      "77/77 [==============================] - 3s 37ms/step - loss: 0.0245 - val_loss: 0.0130\n",
      "Epoch 45/80\n",
      "77/77 [==============================] - 3s 37ms/step - loss: 0.0245 - val_loss: 0.0129\n",
      "Epoch 46/80\n",
      "77/77 [==============================] - 3s 38ms/step - loss: 0.0243 - val_loss: 0.0121\n",
      "Epoch 47/80\n",
      "77/77 [==============================] - 3s 38ms/step - loss: 0.0245 - val_loss: 0.0144\n",
      "Epoch 48/80\n",
      "77/77 [==============================] - 3s 37ms/step - loss: 0.0244 - val_loss: 0.0141\n",
      "Epoch 49/80\n",
      "77/77 [==============================] - 3s 37ms/step - loss: 0.0243 - val_loss: 0.0137\n",
      "Epoch 50/80\n",
      "77/77 [==============================] - 3s 37ms/step - loss: 0.0243 - val_loss: 0.0134\n",
      "Epoch 51/80\n",
      "77/77 [==============================] - 3s 37ms/step - loss: 0.0243 - val_loss: 0.0131\n",
      "Epoch 52/80\n",
      "77/77 [==============================] - 3s 39ms/step - loss: 0.0243 - val_loss: 0.0130\n",
      "Epoch 53/80\n",
      "77/77 [==============================] - 3s 37ms/step - loss: 0.0243 - val_loss: 0.0128\n",
      "Epoch 54/80\n",
      "77/77 [==============================] - 3s 37ms/step - loss: 0.0243 - val_loss: 0.0127\n",
      "Epoch 55/80\n",
      "77/77 [==============================] - 3s 37ms/step - loss: 0.0243 - val_loss: 0.0126\n",
      "Epoch 56/80\n",
      "77/77 [==============================] - 3s 37ms/step - loss: 0.0243 - val_loss: 0.0125\n",
      "Epoch 57/80\n",
      "77/77 [==============================] - 3s 37ms/step - loss: 0.0243 - val_loss: 0.0124\n",
      "Epoch 58/80\n",
      "77/77 [==============================] - 3s 38ms/step - loss: 0.0242 - val_loss: 0.0123\n",
      "Epoch 59/80\n",
      "77/77 [==============================] - 3s 36ms/step - loss: 0.0242 - val_loss: 0.0123\n",
      "Epoch 60/80\n",
      "77/77 [==============================] - 3s 37ms/step - loss: 0.0242 - val_loss: 0.0122\n",
      "Epoch 61/80\n",
      "77/77 [==============================] - 3s 37ms/step - loss: 0.0242 - val_loss: 0.0121\n",
      "Epoch 62/80\n",
      "77/77 [==============================] - 3s 37ms/step - loss: 0.0242 - val_loss: 0.0121\n",
      "Epoch 63/80\n",
      "77/77 [==============================] - 3s 39ms/step - loss: 0.0242 - val_loss: 0.0120\n",
      "Epoch 64/80\n",
      "77/77 [==============================] - 3s 37ms/step - loss: 0.0242 - val_loss: 0.0120\n",
      "Epoch 65/80\n",
      "77/77 [==============================] - 3s 39ms/step - loss: 0.0242 - val_loss: 0.0119\n",
      "Epoch 66/80\n",
      "77/77 [==============================] - 3s 37ms/step - loss: 0.0242 - val_loss: 0.0113\n",
      "Epoch 67/80\n",
      "77/77 [==============================] - 3s 37ms/step - loss: 0.0243 - val_loss: 0.0124\n",
      "Epoch 68/80\n",
      "77/77 [==============================] - 3s 38ms/step - loss: 0.0242 - val_loss: 0.0123\n",
      "Epoch 69/80\n",
      "77/77 [==============================] - 3s 39ms/step - loss: 0.0242 - val_loss: 0.0122\n",
      "Epoch 70/80\n",
      "77/77 [==============================] - 3s 37ms/step - loss: 0.0242 - val_loss: 0.0122\n",
      "Epoch 71/80\n",
      "77/77 [==============================] - 3s 37ms/step - loss: 0.0242 - val_loss: 0.0121\n",
      "Epoch 72/80\n",
      "77/77 [==============================] - 3s 37ms/step - loss: 0.0242 - val_loss: 0.0120\n",
      "Epoch 73/80\n",
      "77/77 [==============================] - 3s 37ms/step - loss: 0.0242 - val_loss: 0.0119\n",
      "Epoch 74/80\n",
      "77/77 [==============================] - 3s 39ms/step - loss: 0.0242 - val_loss: 0.0118\n",
      "Epoch 75/80\n",
      "77/77 [==============================] - 3s 37ms/step - loss: 0.0242 - val_loss: 0.0118\n",
      "Epoch 76/80\n",
      "77/77 [==============================] - 3s 37ms/step - loss: 0.0242 - val_loss: 0.0117\n",
      "Epoch 77/80\n",
      "77/77 [==============================] - 3s 37ms/step - loss: 0.0242 - val_loss: 0.0116\n",
      "Epoch 78/80\n",
      "77/77 [==============================] - 3s 36ms/step - loss: 0.0242 - val_loss: 0.0115\n",
      "Epoch 79/80\n",
      "77/77 [==============================] - 3s 38ms/step - loss: 0.0242 - val_loss: 0.0115\n",
      "Epoch 80/80\n",
      "77/77 [==============================] - 3s 39ms/step - loss: 0.0242 - val_loss: 0.0114\n",
      "Execution time:  233.09254002571106\n",
      "DNN:\n",
      "Mean Absolute Error: 0.0260\n",
      "Root Mean Square Error: 0.0472\n",
      "Mean Square Error: 0.0022\n",
      "\n",
      "Train RMSE: 0.047\n",
      "Train MSE: 0.002\n",
      "Train MAE: 0.026\n",
      "###########################\n",
      "\n",
      "MODEL:  DNN\n",
      "sequence:  7d\n",
      "units:  80\n",
      "dropout1:  0.11814836227952394\n",
      "optimizer: adam\n",
      "activationDense: sigmoid\n",
      "epochs: 90\n",
      "batchsize: 25\n",
      "validation_split: 0.2\n",
      "Model: \"sequential_226\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_678 (Dense)            (None, 1008, 80)          160       \n",
      "_________________________________________________________________\n",
      "dense_679 (Dense)            (None, 1008, 16)          1296      \n",
      "_________________________________________________________________\n",
      "dropout_226 (Dropout)        (None, 1008, 16)          0         \n",
      "_________________________________________________________________\n",
      "dense_680 (Dense)            (None, 1008, 1)           17        \n",
      "=================================================================\n",
      "Total params: 1,473\n",
      "Trainable params: 1,473\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/90\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "96/96 [==============================] - 3s 30ms/step - loss: 0.0616 - val_loss: 0.0161\n",
      "Epoch 2/90\n",
      "96/96 [==============================] - 3s 28ms/step - loss: 0.0317 - val_loss: 0.0178\n",
      "Epoch 3/90\n",
      "96/96 [==============================] - 3s 28ms/step - loss: 0.0315 - val_loss: 0.0164\n",
      "Epoch 4/90\n",
      "96/96 [==============================] - 3s 30ms/step - loss: 0.0311 - val_loss: 0.0155\n",
      "Epoch 5/90\n",
      "96/96 [==============================] - 3s 32ms/step - loss: 0.0308 - val_loss: 0.0154\n",
      "Epoch 6/90\n",
      "96/96 [==============================] - 3s 31ms/step - loss: 0.0305 - val_loss: 0.0154\n",
      "Epoch 7/90\n",
      "96/96 [==============================] - 3s 29ms/step - loss: 0.0303 - val_loss: 0.0145\n",
      "Epoch 8/90\n",
      "96/96 [==============================] - 3s 28ms/step - loss: 0.0300 - val_loss: 0.0145\n",
      "Epoch 9/90\n",
      "96/96 [==============================] - 3s 29ms/step - loss: 0.0297 - val_loss: 0.0144\n",
      "Epoch 10/90\n",
      "96/96 [==============================] - 3s 30ms/step - loss: 0.0295 - val_loss: 0.0138\n",
      "Epoch 11/90\n",
      "96/96 [==============================] - 3s 28ms/step - loss: 0.0292 - val_loss: 0.0138\n",
      "Epoch 12/90\n",
      "96/96 [==============================] - 3s 28ms/step - loss: 0.0290 - val_loss: 0.0138\n",
      "Epoch 13/90\n",
      "96/96 [==============================] - 3s 28ms/step - loss: 0.0287 - val_loss: 0.0132\n",
      "Epoch 14/90\n",
      "96/96 [==============================] - 3s 28ms/step - loss: 0.0285 - val_loss: 0.0133\n",
      "Epoch 15/90\n",
      "96/96 [==============================] - 3s 29ms/step - loss: 0.0283 - val_loss: 0.0133\n",
      "Epoch 16/90\n",
      "96/96 [==============================] - 3s 30ms/step - loss: 0.0281 - val_loss: 0.0144\n",
      "Epoch 17/90\n",
      "96/96 [==============================] - 3s 29ms/step - loss: 0.0280 - val_loss: 0.0131\n",
      "Epoch 18/90\n",
      "96/96 [==============================] - 3s 28ms/step - loss: 0.0277 - val_loss: 0.0133\n",
      "Epoch 19/90\n",
      "96/96 [==============================] - 3s 28ms/step - loss: 0.0275 - val_loss: 0.0134\n",
      "Epoch 20/90\n",
      "96/96 [==============================] - 3s 29ms/step - loss: 0.0273 - val_loss: 0.0134\n",
      "Epoch 21/90\n",
      "96/96 [==============================] - 3s 30ms/step - loss: 0.0271 - val_loss: 0.0132\n",
      "Epoch 22/90\n",
      "96/96 [==============================] - 3s 29ms/step - loss: 0.0271 - val_loss: 0.0131\n",
      "Epoch 23/90\n",
      "96/96 [==============================] - 3s 29ms/step - loss: 0.0268 - val_loss: 0.0133\n",
      "Epoch 24/90\n",
      "96/96 [==============================] - 3s 28ms/step - loss: 0.0267 - val_loss: 0.0133\n",
      "Epoch 25/90\n",
      "96/96 [==============================] - 3s 28ms/step - loss: 0.0265 - val_loss: 0.0132\n",
      "Epoch 26/90\n",
      "96/96 [==============================] - 3s 29ms/step - loss: 0.0263 - val_loss: 0.0132\n",
      "Epoch 27/90\n",
      "96/96 [==============================] - 3s 30ms/step - loss: 0.0262 - val_loss: 0.0132\n",
      "Epoch 28/90\n",
      "96/96 [==============================] - 3s 29ms/step - loss: 0.0261 - val_loss: 0.0132\n",
      "Epoch 29/90\n",
      "96/96 [==============================] - 3s 29ms/step - loss: 0.0260 - val_loss: 0.0132\n",
      "Epoch 30/90\n",
      "96/96 [==============================] - 3s 29ms/step - loss: 0.0258 - val_loss: 0.0132\n",
      "Epoch 31/90\n",
      "96/96 [==============================] - 3s 29ms/step - loss: 0.0258 - val_loss: 0.0132\n",
      "Epoch 32/90\n",
      "96/96 [==============================] - 3s 29ms/step - loss: 0.0257 - val_loss: 0.0132\n",
      "Epoch 33/90\n",
      "96/96 [==============================] - 3s 30ms/step - loss: 0.0256 - val_loss: 0.0132\n",
      "Epoch 34/90\n",
      "96/96 [==============================] - 3s 29ms/step - loss: 0.0255 - val_loss: 0.0132\n",
      "Epoch 35/90\n",
      "96/96 [==============================] - 3s 28ms/step - loss: 0.0254 - val_loss: 0.0131\n",
      "Epoch 36/90\n",
      "96/96 [==============================] - 3s 28ms/step - loss: 0.0253 - val_loss: 0.0130\n",
      "Epoch 37/90\n",
      "96/96 [==============================] - 3s 28ms/step - loss: 0.0252 - val_loss: 0.0130\n",
      "Epoch 38/90\n",
      "96/96 [==============================] - 3s 30ms/step - loss: 0.0252 - val_loss: 0.0130\n",
      "Epoch 39/90\n",
      "96/96 [==============================] - 3s 29ms/step - loss: 0.0251 - val_loss: 0.0130\n",
      "Epoch 40/90\n",
      "96/96 [==============================] - 3s 29ms/step - loss: 0.0250 - val_loss: 0.0129\n",
      "Epoch 41/90\n",
      "96/96 [==============================] - 3s 28ms/step - loss: 0.0250 - val_loss: 0.0129\n",
      "Epoch 42/90\n",
      "96/96 [==============================] - 3s 28ms/step - loss: 0.0249 - val_loss: 0.0129\n",
      "Epoch 43/90\n",
      "96/96 [==============================] - 3s 28ms/step - loss: 0.0249 - val_loss: 0.0130\n",
      "Epoch 44/90\n",
      "96/96 [==============================] - 3s 30ms/step - loss: 0.0249 - val_loss: 0.0130\n",
      "Epoch 45/90\n",
      "96/96 [==============================] - 3s 29ms/step - loss: 0.0248 - val_loss: 0.0130\n",
      "Epoch 46/90\n",
      "96/96 [==============================] - 3s 29ms/step - loss: 0.0248 - val_loss: 0.0130\n",
      "Epoch 47/90\n",
      "96/96 [==============================] - 3s 29ms/step - loss: 0.0248 - val_loss: 0.0130\n",
      "Epoch 48/90\n",
      "96/96 [==============================] - 3s 29ms/step - loss: 0.0248 - val_loss: 0.0130\n",
      "Epoch 49/90\n",
      "96/96 [==============================] - 3s 29ms/step - loss: 0.0248 - val_loss: 0.0130\n",
      "Epoch 50/90\n",
      "96/96 [==============================] - 3s 30ms/step - loss: 0.0248 - val_loss: 0.0130\n",
      "Epoch 51/90\n",
      "96/96 [==============================] - 3s 28ms/step - loss: 0.0248 - val_loss: 0.0129\n",
      "Epoch 52/90\n",
      "96/96 [==============================] - 3s 29ms/step - loss: 0.0248 - val_loss: 0.0128\n",
      "Epoch 53/90\n",
      "96/96 [==============================] - 3s 28ms/step - loss: 0.0247 - val_loss: 0.0128\n",
      "Epoch 54/90\n",
      "96/96 [==============================] - 3s 29ms/step - loss: 0.0247 - val_loss: 0.0127\n",
      "Epoch 55/90\n",
      "96/96 [==============================] - 3s 29ms/step - loss: 0.0247 - val_loss: 0.0127\n",
      "Epoch 56/90\n",
      "96/96 [==============================] - 3s 30ms/step - loss: 0.0241 - val_loss: 0.0144\n",
      "Epoch 57/90\n",
      "96/96 [==============================] - 3s 28ms/step - loss: 0.0256 - val_loss: 0.0127\n",
      "Epoch 58/90\n",
      "96/96 [==============================] - 3s 29ms/step - loss: 0.0248 - val_loss: 0.0135\n",
      "Epoch 59/90\n",
      "96/96 [==============================] - 3s 29ms/step - loss: 0.0249 - val_loss: 0.0127\n",
      "Epoch 60/90\n",
      "96/96 [==============================] - 3s 28ms/step - loss: 0.0247 - val_loss: 0.0126\n",
      "Epoch 61/90\n",
      "96/96 [==============================] - 3s 30ms/step - loss: 0.0247 - val_loss: 0.0125\n",
      "Epoch 62/90\n",
      "96/96 [==============================] - 3s 29ms/step - loss: 0.0246 - val_loss: 0.0124\n",
      "Epoch 63/90\n",
      "96/96 [==============================] - 3s 28ms/step - loss: 0.0246 - val_loss: 0.0124\n",
      "Epoch 64/90\n",
      "96/96 [==============================] - 3s 29ms/step - loss: 0.0246 - val_loss: 0.0124\n",
      "Epoch 65/90\n",
      "96/96 [==============================] - 3s 28ms/step - loss: 0.0246 - val_loss: 0.0123\n",
      "Epoch 66/90\n",
      "96/96 [==============================] - 3s 29ms/step - loss: 0.0246 - val_loss: 0.0123\n",
      "Epoch 67/90\n",
      "96/96 [==============================] - 3s 30ms/step - loss: 0.0246 - val_loss: 0.0123\n",
      "Epoch 68/90\n",
      "96/96 [==============================] - 3s 28ms/step - loss: 0.0246 - val_loss: 0.0123\n",
      "Epoch 69/90\n",
      "96/96 [==============================] - 3s 29ms/step - loss: 0.0246 - val_loss: 0.0122\n",
      "Epoch 70/90\n",
      "96/96 [==============================] - 3s 29ms/step - loss: 0.0246 - val_loss: 0.0122\n",
      "Epoch 71/90\n",
      "96/96 [==============================] - 3s 28ms/step - loss: 0.0245 - val_loss: 0.0122\n",
      "Epoch 72/90\n",
      "96/96 [==============================] - 3s 29ms/step - loss: 0.0245 - val_loss: 0.0121\n",
      "Epoch 73/90\n",
      "96/96 [==============================] - 3s 30ms/step - loss: 0.0245 - val_loss: 0.0121\n",
      "Epoch 74/90\n",
      "96/96 [==============================] - 3s 30ms/step - loss: 0.0245 - val_loss: 0.0121\n",
      "Epoch 75/90\n",
      "96/96 [==============================] - 3s 29ms/step - loss: 0.0245 - val_loss: 0.0121\n",
      "Epoch 76/90\n",
      "96/96 [==============================] - 3s 29ms/step - loss: 0.0245 - val_loss: 0.0120\n",
      "Epoch 77/90\n",
      "96/96 [==============================] - 3s 29ms/step - loss: 0.0245 - val_loss: 0.0120\n",
      "Epoch 78/90\n",
      "96/96 [==============================] - 3s 30ms/step - loss: 0.0245 - val_loss: 0.0120\n",
      "Epoch 79/90\n",
      "96/96 [==============================] - 3s 29ms/step - loss: 0.0245 - val_loss: 0.0119\n",
      "Epoch 80/90\n",
      "96/96 [==============================] - 3s 28ms/step - loss: 0.0245 - val_loss: 0.0119\n",
      "Epoch 81/90\n",
      "96/96 [==============================] - 3s 29ms/step - loss: 0.0245 - val_loss: 0.0119\n",
      "Epoch 82/90\n",
      "96/96 [==============================] - 3s 29ms/step - loss: 0.0244 - val_loss: 0.0119\n",
      "Epoch 83/90\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "96/96 [==============================] - 3s 29ms/step - loss: 0.0244 - val_loss: 0.0118\n",
      "Epoch 84/90\n",
      "96/96 [==============================] - 3s 30ms/step - loss: 0.0244 - val_loss: 0.0118\n",
      "Epoch 85/90\n",
      "96/96 [==============================] - 3s 28ms/step - loss: 0.0244 - val_loss: 0.0118\n",
      "Epoch 86/90\n",
      "96/96 [==============================] - 3s 28ms/step - loss: 0.0244 - val_loss: 0.0118\n",
      "Epoch 87/90\n",
      "96/96 [==============================] - 3s 28ms/step - loss: 0.0244 - val_loss: 0.0117\n",
      "Epoch 88/90\n",
      "96/96 [==============================] - 3s 28ms/step - loss: 0.0244 - val_loss: 0.0117\n",
      "Epoch 89/90\n",
      "96/96 [==============================] - 3s 29ms/step - loss: 0.0244 - val_loss: 0.0117\n",
      "Epoch 90/90\n",
      "96/96 [==============================] - 3s 30ms/step - loss: 0.0244 - val_loss: 0.0117\n",
      "Execution time:  254.30602169036865\n",
      "DNN:\n",
      "Mean Absolute Error: 0.0260\n",
      "Root Mean Square Error: 0.0470\n",
      "Mean Square Error: 0.0022\n",
      "\n",
      "Train RMSE: 0.047\n",
      "Train MSE: 0.002\n",
      "Train MAE: 0.026\n",
      "###########################\n",
      "\n",
      "MODEL:  DNN\n",
      "sequence:  7d\n",
      "units:  12\n",
      "dropout1:  0.48476373451509647\n",
      "optimizer: adam\n",
      "activationDense: sigmoid\n",
      "epochs: 52\n",
      "batchsize: 57\n",
      "validation_split: 0.2\n",
      "Model: \"sequential_227\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_681 (Dense)            (None, 1008, 12)          24        \n",
      "_________________________________________________________________\n",
      "dense_682 (Dense)            (None, 1008, 16)          208       \n",
      "_________________________________________________________________\n",
      "dropout_227 (Dropout)        (None, 1008, 16)          0         \n",
      "_________________________________________________________________\n",
      "dense_683 (Dense)            (None, 1008, 1)           17        \n",
      "=================================================================\n",
      "Total params: 249\n",
      "Trainable params: 249\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/52\n",
      "42/42 [==============================] - 1s 36ms/step - loss: 0.0528 - val_loss: 0.0425\n",
      "Epoch 2/52\n",
      "42/42 [==============================] - 1s 30ms/step - loss: 0.0461 - val_loss: 0.0375\n",
      "Epoch 3/52\n",
      "42/42 [==============================] - 1s 32ms/step - loss: 0.0429 - val_loss: 0.0346\n",
      "Epoch 4/52\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 0.0405 - val_loss: 0.0323\n",
      "Epoch 5/52\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 0.0388 - val_loss: 0.0307\n",
      "Epoch 6/52\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 0.0375 - val_loss: 0.0295\n",
      "Epoch 7/52\n",
      "42/42 [==============================] - 2s 36ms/step - loss: 0.0366 - val_loss: 0.0286\n",
      "Epoch 8/52\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.0358 - val_loss: 0.0278\n",
      "Epoch 9/52\n",
      "42/42 [==============================] - 2s 40ms/step - loss: 0.0351 - val_loss: 0.0272\n",
      "Epoch 10/52\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.0345 - val_loss: 0.0266\n",
      "Epoch 11/52\n",
      "42/42 [==============================] - 2s 39ms/step - loss: 0.0339 - val_loss: 0.0261\n",
      "Epoch 12/52\n",
      "42/42 [==============================] - 2s 36ms/step - loss: 0.0333 - val_loss: 0.0255\n",
      "Epoch 13/52\n",
      "42/42 [==============================] - 1s 35ms/step - loss: 0.0328 - val_loss: 0.0250\n",
      "Epoch 14/52\n",
      "42/42 [==============================] - 1s 32ms/step - loss: 0.0323 - val_loss: 0.0243\n",
      "Epoch 15/52\n",
      "42/42 [==============================] - 1s 34ms/step - loss: 0.0318 - val_loss: 0.0237\n",
      "Epoch 16/52\n",
      "42/42 [==============================] - 2s 36ms/step - loss: 0.0313 - val_loss: 0.0232\n",
      "Epoch 17/52\n",
      "42/42 [==============================] - 1s 33ms/step - loss: 0.0309 - val_loss: 0.0227\n",
      "Epoch 18/52\n",
      "42/42 [==============================] - 1s 34ms/step - loss: 0.0304 - val_loss: 0.0222\n",
      "Epoch 19/52\n",
      "42/42 [==============================] - 1s 35ms/step - loss: 0.0300 - val_loss: 0.0217\n",
      "Epoch 20/52\n",
      "42/42 [==============================] - 1s 33ms/step - loss: 0.0296 - val_loss: 0.0213\n",
      "Epoch 21/52\n",
      "42/42 [==============================] - 1s 33ms/step - loss: 0.0293 - val_loss: 0.0208\n",
      "Epoch 22/52\n",
      "42/42 [==============================] - 1s 32ms/step - loss: 0.0289 - val_loss: 0.0203\n",
      "Epoch 23/52\n",
      "42/42 [==============================] - 1s 32ms/step - loss: 0.0286 - val_loss: 0.0199\n",
      "Epoch 24/52\n",
      "42/42 [==============================] - 1s 33ms/step - loss: 0.0283 - val_loss: 0.0195\n",
      "Epoch 25/52\n",
      "42/42 [==============================] - 1s 32ms/step - loss: 0.0280 - val_loss: 0.0192\n",
      "Epoch 26/52\n",
      "42/42 [==============================] - 1s 32ms/step - loss: 0.0277 - val_loss: 0.0188\n",
      "Epoch 27/52\n",
      "42/42 [==============================] - 1s 32ms/step - loss: 0.0276 - val_loss: 0.0184\n",
      "Epoch 28/52\n",
      "42/42 [==============================] - 1s 32ms/step - loss: 0.0273 - val_loss: 0.0182\n",
      "Epoch 29/52\n",
      "42/42 [==============================] - 1s 32ms/step - loss: 0.0270 - val_loss: 0.0179\n",
      "Epoch 30/52\n",
      "42/42 [==============================] - 1s 34ms/step - loss: 0.0269 - val_loss: 0.0177\n",
      "Epoch 31/52\n",
      "42/42 [==============================] - 1s 35ms/step - loss: 0.0267 - val_loss: 0.0174\n",
      "Epoch 32/52\n",
      "42/42 [==============================] - 1s 32ms/step - loss: 0.0265 - val_loss: 0.0172\n",
      "Epoch 33/52\n",
      "42/42 [==============================] - 1s 33ms/step - loss: 0.0263 - val_loss: 0.0169\n",
      "Epoch 34/52\n",
      "42/42 [==============================] - 1s 33ms/step - loss: 0.0262 - val_loss: 0.0167\n",
      "Epoch 35/52\n",
      "42/42 [==============================] - 1s 32ms/step - loss: 0.0260 - val_loss: 0.0166\n",
      "Epoch 36/52\n",
      "42/42 [==============================] - 1s 32ms/step - loss: 0.0259 - val_loss: 0.0164\n",
      "Epoch 37/52\n",
      "42/42 [==============================] - 1s 32ms/step - loss: 0.0258 - val_loss: 0.0163\n",
      "Epoch 38/52\n",
      "42/42 [==============================] - 1s 32ms/step - loss: 0.0257 - val_loss: 0.0161\n",
      "Epoch 39/52\n",
      "42/42 [==============================] - 1s 33ms/step - loss: 0.0256 - val_loss: 0.0161\n",
      "Epoch 40/52\n",
      "42/42 [==============================] - 1s 32ms/step - loss: 0.0254 - val_loss: 0.0159\n",
      "Epoch 41/52\n",
      "42/42 [==============================] - 1s 34ms/step - loss: 0.0252 - val_loss: 0.0155\n",
      "Epoch 42/52\n",
      "42/42 [==============================] - 1s 34ms/step - loss: 0.0251 - val_loss: 0.0153\n",
      "Epoch 43/52\n",
      "42/42 [==============================] - 1s 33ms/step - loss: 0.0251 - val_loss: 0.0153\n",
      "Epoch 44/52\n",
      "42/42 [==============================] - 1s 33ms/step - loss: 0.0250 - val_loss: 0.0152\n",
      "Epoch 45/52\n",
      "42/42 [==============================] - 1s 32ms/step - loss: 0.0249 - val_loss: 0.0151\n",
      "Epoch 46/52\n",
      "42/42 [==============================] - 1s 33ms/step - loss: 0.0249 - val_loss: 0.0151\n",
      "Epoch 47/52\n",
      "42/42 [==============================] - 1s 33ms/step - loss: 0.0248 - val_loss: 0.0150\n",
      "Epoch 48/52\n",
      "42/42 [==============================] - 1s 32ms/step - loss: 0.0248 - val_loss: 0.0151\n",
      "Epoch 49/52\n",
      "42/42 [==============================] - 1s 34ms/step - loss: 0.0247 - val_loss: 0.0148\n",
      "Epoch 50/52\n",
      "42/42 [==============================] - 1s 33ms/step - loss: 0.0247 - val_loss: 0.0148\n",
      "Epoch 51/52\n",
      "42/42 [==============================] - 1s 33ms/step - loss: 0.0246 - val_loss: 0.0146- ETA: 0s\n",
      "Epoch 52/52\n",
      "42/42 [==============================] - 1s 33ms/step - loss: 0.0245 - val_loss: 0.0145\n",
      "Execution time:  75.68637752532959\n",
      "DNN:\n",
      "Mean Absolute Error: 0.0262\n",
      "Root Mean Square Error: 0.0464\n",
      "Mean Square Error: 0.0022\n",
      "\n",
      "Train RMSE: 0.046\n",
      "Train MSE: 0.002\n",
      "Train MAE: 0.026\n",
      "###########################\n",
      "\n",
      "MODEL:  DNN\n",
      "sequence:  7d\n",
      "units:  87\n",
      "dropout1:  0.40519643149940265\n",
      "optimizer: adadelta\n",
      "activationDense: tanh\n",
      "epochs: 80\n",
      "batchsize: 31\n",
      "validation_split: 0.1\n",
      "Model: \"sequential_228\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_684 (Dense)            (None, 1008, 87)          174       \n",
      "_________________________________________________________________\n",
      "dense_685 (Dense)            (None, 1008, 16)          1408      \n",
      "_________________________________________________________________\n",
      "dropout_228 (Dropout)        (None, 1008, 16)          0         \n",
      "_________________________________________________________________\n",
      "dense_686 (Dense)            (None, 1008, 1)           17        \n",
      "=================================================================\n",
      "Total params: 1,599\n",
      "Trainable params: 1,599\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/80\n",
      "87/87 [==============================] - 3s 37ms/step - loss: 0.4494 - val_loss: 0.4161\n",
      "Epoch 2/80\n",
      "87/87 [==============================] - 3s 35ms/step - loss: 0.4475 - val_loss: 0.4142\n",
      "Epoch 3/80\n",
      "87/87 [==============================] - 3s 35ms/step - loss: 0.4455 - val_loss: 0.4121\n",
      "Epoch 4/80\n",
      "87/87 [==============================] - 3s 35ms/step - loss: 0.4433 - val_loss: 0.4099\n",
      "Epoch 5/80\n",
      "87/87 [==============================] - 3s 36ms/step - loss: 0.4410 - val_loss: 0.4076\n",
      "Epoch 6/80\n",
      "87/87 [==============================] - 3s 36ms/step - loss: 0.4385 - val_loss: 0.4052\n",
      "Epoch 7/80\n",
      "87/87 [==============================] - 3s 35ms/step - loss: 0.4360 - val_loss: 0.4026\n",
      "Epoch 8/80\n",
      "87/87 [==============================] - 3s 35ms/step - loss: 0.4334 - val_loss: 0.4000\n",
      "Epoch 9/80\n",
      "87/87 [==============================] - 3s 35ms/step - loss: 0.4306 - val_loss: 0.3972\n",
      "Epoch 10/80\n",
      "87/87 [==============================] - 3s 36ms/step - loss: 0.4277 - val_loss: 0.3944\n",
      "Epoch 11/80\n",
      "87/87 [==============================] - 3s 36ms/step - loss: 0.4248 - val_loss: 0.3914\n",
      "Epoch 12/80\n",
      "87/87 [==============================] - 3s 35ms/step - loss: 0.4218 - val_loss: 0.3884\n",
      "Epoch 13/80\n",
      "87/87 [==============================] - 3s 35ms/step - loss: 0.4186 - val_loss: 0.3853\n",
      "Epoch 14/80\n",
      "87/87 [==============================] - 3s 35ms/step - loss: 0.4154 - val_loss: 0.3821\n",
      "Epoch 15/80\n",
      "87/87 [==============================] - 3s 36ms/step - loss: 0.4121 - val_loss: 0.3788\n",
      "Epoch 16/80\n",
      "87/87 [==============================] - 3s 36ms/step - loss: 0.4087 - val_loss: 0.3754\n",
      "Epoch 17/80\n",
      "87/87 [==============================] - 3s 35ms/step - loss: 0.4052 - val_loss: 0.3720\n",
      "Epoch 18/80\n",
      "87/87 [==============================] - 3s 35ms/step - loss: 0.4016 - val_loss: 0.3685\n",
      "Epoch 19/80\n",
      "87/87 [==============================] - 3s 35ms/step - loss: 0.3980 - val_loss: 0.3649\n",
      "Epoch 20/80\n",
      "87/87 [==============================] - 3s 35ms/step - loss: 0.3943 - val_loss: 0.3612\n",
      "Epoch 21/80\n",
      "87/87 [==============================] - 3s 37ms/step - loss: 0.3905 - val_loss: 0.3574\n",
      "Epoch 22/80\n",
      "87/87 [==============================] - 3s 35ms/step - loss: 0.3866 - val_loss: 0.3538\n",
      "Epoch 23/80\n",
      "87/87 [==============================] - 3s 35ms/step - loss: 0.3831 - val_loss: 0.3506\n",
      "Epoch 24/80\n",
      "87/87 [==============================] - 3s 35ms/step - loss: 0.3797 - val_loss: 0.3473\n",
      "Epoch 25/80\n",
      "87/87 [==============================] - 3s 35ms/step - loss: 0.3764 - val_loss: 0.3440\n",
      "Epoch 26/80\n",
      "87/87 [==============================] - 3s 37ms/step - loss: 0.3730 - val_loss: 0.3406\n",
      "Epoch 27/80\n",
      "87/87 [==============================] - 3s 35ms/step - loss: 0.3695 - val_loss: 0.3372\n",
      "Epoch 28/80\n",
      "87/87 [==============================] - 3s 35ms/step - loss: 0.3659 - val_loss: 0.3338\n",
      "Epoch 29/80\n",
      "87/87 [==============================] - 3s 35ms/step - loss: 0.3624 - val_loss: 0.3303\n",
      "Epoch 30/80\n",
      "87/87 [==============================] - 3s 35ms/step - loss: 0.3589 - val_loss: 0.3268\n",
      "Epoch 31/80\n",
      "87/87 [==============================] - 3s 37ms/step - loss: 0.3553 - val_loss: 0.3233\n",
      "Epoch 32/80\n",
      "87/87 [==============================] - 3s 35ms/step - loss: 0.3516 - val_loss: 0.3197\n",
      "Epoch 33/80\n",
      "87/87 [==============================] - 3s 35ms/step - loss: 0.3479 - val_loss: 0.3160\n",
      "Epoch 34/80\n",
      "87/87 [==============================] - 3s 35ms/step - loss: 0.3441 - val_loss: 0.3123\n",
      "Epoch 35/80\n",
      "87/87 [==============================] - 3s 35ms/step - loss: 0.3403 - val_loss: 0.3085\n",
      "Epoch 36/80\n",
      "87/87 [==============================] - 3s 37ms/step - loss: 0.3364 - val_loss: 0.3047\n",
      "Epoch 37/80\n",
      "87/87 [==============================] - 3s 36ms/step - loss: 0.3325 - val_loss: 0.3009\n",
      "Epoch 38/80\n",
      "87/87 [==============================] - 3s 35ms/step - loss: 0.3285 - val_loss: 0.2971\n",
      "Epoch 39/80\n",
      "87/87 [==============================] - 3s 35ms/step - loss: 0.3249 - val_loss: 0.2942\n",
      "Epoch 40/80\n",
      "87/87 [==============================] - 3s 35ms/step - loss: 0.3219 - val_loss: 0.2915\n",
      "Epoch 41/80\n",
      "87/87 [==============================] - 3s 37ms/step - loss: 0.3189 - val_loss: 0.2887\n",
      "Epoch 42/80\n",
      "87/87 [==============================] - 3s 35ms/step - loss: 0.3160 - val_loss: 0.2859\n",
      "Epoch 43/80\n",
      "87/87 [==============================] - 3s 35ms/step - loss: 0.3129 - val_loss: 0.2830\n",
      "Epoch 44/80\n",
      "87/87 [==============================] - 3s 35ms/step - loss: 0.3099 - val_loss: 0.2800\n",
      "Epoch 45/80\n",
      "87/87 [==============================] - 3s 35ms/step - loss: 0.3068 - val_loss: 0.2770\n",
      "Epoch 46/80\n",
      "87/87 [==============================] - 3s 36ms/step - loss: 0.3037 - val_loss: 0.2739\n",
      "Epoch 47/80\n",
      "87/87 [==============================] - 3s 36ms/step - loss: 0.3004 - val_loss: 0.2708\n",
      "Epoch 48/80\n",
      "87/87 [==============================] - 3s 35ms/step - loss: 0.2972 - val_loss: 0.2676\n",
      "Epoch 49/80\n",
      "87/87 [==============================] - 3s 35ms/step - loss: 0.2939 - val_loss: 0.2644\n",
      "Epoch 50/80\n",
      "87/87 [==============================] - 3s 35ms/step - loss: 0.2905 - val_loss: 0.2610\n",
      "Epoch 51/80\n",
      "87/87 [==============================] - 3s 36ms/step - loss: 0.2872 - val_loss: 0.2577\n",
      "Epoch 52/80\n",
      "87/87 [==============================] - 3s 36ms/step - loss: 0.2837 - val_loss: 0.2542\n",
      "Epoch 53/80\n",
      "87/87 [==============================] - 3s 35ms/step - loss: 0.2801 - val_loss: 0.2506\n",
      "Epoch 54/80\n",
      "87/87 [==============================] - 3s 35ms/step - loss: 0.2765 - val_loss: 0.2470\n",
      "Epoch 55/80\n",
      "87/87 [==============================] - 3s 35ms/step - loss: 0.2727 - val_loss: 0.2433\n",
      "Epoch 56/80\n",
      "87/87 [==============================] - 3s 36ms/step - loss: 0.2689 - val_loss: 0.2395\n",
      "Epoch 57/80\n",
      "87/87 [==============================] - 3s 36ms/step - loss: 0.2651 - val_loss: 0.2356\n",
      "Epoch 58/80\n",
      "87/87 [==============================] - 3s 35ms/step - loss: 0.2611 - val_loss: 0.2316\n",
      "Epoch 59/80\n",
      "87/87 [==============================] - 3s 35ms/step - loss: 0.2570 - val_loss: 0.2275\n",
      "Epoch 60/80\n",
      "87/87 [==============================] - 3s 35ms/step - loss: 0.2528 - val_loss: 0.2233\n",
      "Epoch 61/80\n",
      "87/87 [==============================] - 3s 36ms/step - loss: 0.2485 - val_loss: 0.2191\n",
      "Epoch 62/80\n",
      "87/87 [==============================] - 3s 37ms/step - loss: 0.2442 - val_loss: 0.2147\n",
      "Epoch 63/80\n",
      "87/87 [==============================] - 3s 35ms/step - loss: 0.2398 - val_loss: 0.2102\n",
      "Epoch 64/80\n",
      "87/87 [==============================] - 3s 35ms/step - loss: 0.2354 - val_loss: 0.2057\n",
      "Epoch 65/80\n",
      "87/87 [==============================] - 3s 35ms/step - loss: 0.2307 - val_loss: 0.2010\n",
      "Epoch 66/80\n",
      "87/87 [==============================] - 3s 36ms/step - loss: 0.2253 - val_loss: 0.1940\n",
      "Epoch 67/80\n",
      "87/87 [==============================] - ETA: 0s - loss: 0.217 - 3s 37ms/step - loss: 0.2172 - val_loss: 0.1852\n",
      "Epoch 68/80\n",
      "87/87 [==============================] - 3s 35ms/step - loss: 0.2084 - val_loss: 0.1762\n",
      "Epoch 69/80\n",
      "87/87 [==============================] - 3s 35ms/step - loss: 0.1994 - val_loss: 0.1672\n",
      "Epoch 70/80\n",
      "87/87 [==============================] - 3s 35ms/step - loss: 0.1905 - val_loss: 0.1581\n",
      "Epoch 71/80\n",
      "87/87 [==============================] - 3s 35ms/step - loss: 0.1814 - val_loss: 0.1489\n",
      "Epoch 72/80\n",
      "87/87 [==============================] - 3s 37ms/step - loss: 0.1724 - val_loss: 0.1397\n",
      "Epoch 73/80\n",
      "87/87 [==============================] - 3s 35ms/step - loss: 0.1639 - val_loss: 0.1307\n",
      "Epoch 74/80\n",
      "87/87 [==============================] - 3s 35ms/step - loss: 0.1563 - val_loss: 0.1225\n",
      "Epoch 75/80\n",
      "87/87 [==============================] - 3s 36ms/step - loss: 0.1503 - val_loss: 0.1154\n",
      "Epoch 76/80\n",
      "87/87 [==============================] - 3s 35ms/step - loss: 0.1462 - val_loss: 0.1093\n",
      "Epoch 77/80\n",
      "87/87 [==============================] - 3s 37ms/step - loss: 0.1428 - val_loss: 0.1042\n",
      "Epoch 78/80\n",
      "87/87 [==============================] - 3s 35ms/step - loss: 0.1403 - val_loss: 0.0996\n",
      "Epoch 79/80\n",
      "87/87 [==============================] - 3s 35ms/step - loss: 0.1382 - val_loss: 0.0956\n",
      "Epoch 80/80\n",
      "87/87 [==============================] - 3s 35ms/step - loss: 0.1363 - val_loss: 0.0920\n",
      "Execution time:  250.89760971069336\n",
      "DNN:\n",
      "Mean Absolute Error: 0.1213\n",
      "Root Mean Square Error: 0.1252\n",
      "Mean Square Error: 0.0157\n",
      "\n",
      "Train RMSE: 0.125\n",
      "Train MSE: 0.016\n",
      "Train MAE: 0.121\n",
      "###########################\n",
      "\n",
      "MODEL:  DNN\n",
      "sequence:  7d\n",
      "units:  80\n",
      "dropout1:  0.11814836227952394\n",
      "optimizer: adadelta\n",
      "activationDense: tanh\n",
      "epochs: 90\n",
      "batchsize: 25\n",
      "validation_split: 0.1\n",
      "Model: \"sequential_229\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_687 (Dense)            (None, 1008, 80)          160       \n",
      "_________________________________________________________________\n",
      "dense_688 (Dense)            (None, 1008, 16)          1296      \n",
      "_________________________________________________________________\n",
      "dropout_229 (Dropout)        (None, 1008, 16)          0         \n",
      "_________________________________________________________________\n",
      "dense_689 (Dense)            (None, 1008, 1)           17        \n",
      "=================================================================\n",
      "Total params: 1,473\n",
      "Trainable params: 1,473\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/90\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "108/108 [==============================] - 3s 31ms/step - loss: 0.3898 - val_loss: 0.3594\n",
      "Epoch 2/90\n",
      "108/108 [==============================] - 3s 27ms/step - loss: 0.3881 - val_loss: 0.3577\n",
      "Epoch 3/90\n",
      "108/108 [==============================] - 3s 27ms/step - loss: 0.3863 - val_loss: 0.3558\n",
      "Epoch 4/90\n",
      "108/108 [==============================] - 3s 27ms/step - loss: 0.3843 - val_loss: 0.3538\n",
      "Epoch 5/90\n",
      "108/108 [==============================] - 3s 27ms/step - loss: 0.3822 - val_loss: 0.3517\n",
      "Epoch 6/90\n",
      "108/108 [==============================] - 3s 28ms/step - loss: 0.3800 - val_loss: 0.3495\n",
      "Epoch 7/90\n",
      "108/108 [==============================] - 3s 29ms/step - loss: 0.3776 - val_loss: 0.3471\n",
      "Epoch 8/90\n",
      "108/108 [==============================] - 3s 27ms/step - loss: 0.3752 - val_loss: 0.3446\n",
      "Epoch 9/90\n",
      "108/108 [==============================] - 3s 27ms/step - loss: 0.3726 - val_loss: 0.3421\n",
      "Epoch 10/90\n",
      "108/108 [==============================] - 3s 27ms/step - loss: 0.3699 - val_loss: 0.3394\n",
      "Epoch 11/90\n",
      "108/108 [==============================] - 3s 27ms/step - loss: 0.3672 - val_loss: 0.3367\n",
      "Epoch 12/90\n",
      "108/108 [==============================] - 3s 29ms/step - loss: 0.3643 - val_loss: 0.3339\n",
      "Epoch 13/90\n",
      "108/108 [==============================] - 3s 27ms/step - loss: 0.3614 - val_loss: 0.3310\n",
      "Epoch 14/90\n",
      "108/108 [==============================] - 3s 27ms/step - loss: 0.3584 - val_loss: 0.3280\n",
      "Epoch 15/90\n",
      "108/108 [==============================] - 3s 27ms/step - loss: 0.3553 - val_loss: 0.3249\n",
      "Epoch 16/90\n",
      "108/108 [==============================] - 3s 27ms/step - loss: 0.3521 - val_loss: 0.3217\n",
      "Epoch 17/90\n",
      "108/108 [==============================] - 3s 28ms/step - loss: 0.3488 - val_loss: 0.3184\n",
      "Epoch 18/90\n",
      "108/108 [==============================] - 3s 28ms/step - loss: 0.3454 - val_loss: 0.3150\n",
      "Epoch 19/90\n",
      "108/108 [==============================] - 3s 27ms/step - loss: 0.3420 - val_loss: 0.3116\n",
      "Epoch 20/90\n",
      "108/108 [==============================] - 3s 27ms/step - loss: 0.3384 - val_loss: 0.3080\n",
      "Epoch 21/90\n",
      "108/108 [==============================] - 3s 27ms/step - loss: 0.3348 - val_loss: 0.3045\n",
      "Epoch 22/90\n",
      "108/108 [==============================] - 3s 28ms/step - loss: 0.3311 - val_loss: 0.3009\n",
      "Epoch 23/90\n",
      "108/108 [==============================] - 3s 29ms/step - loss: 0.3274 - val_loss: 0.2972\n",
      "Epoch 24/90\n",
      "108/108 [==============================] - 3s 27ms/step - loss: 0.3236 - val_loss: 0.2934\n",
      "Epoch 25/90\n",
      "108/108 [==============================] - 3s 27ms/step - loss: 0.3197 - val_loss: 0.2896\n",
      "Epoch 26/90\n",
      "108/108 [==============================] - 3s 27ms/step - loss: 0.3158 - val_loss: 0.2858\n",
      "Epoch 27/90\n",
      "108/108 [==============================] - 3s 27ms/step - loss: 0.3120 - val_loss: 0.2821\n",
      "Epoch 28/90\n",
      "108/108 [==============================] - 3s 29ms/step - loss: 0.3081 - val_loss: 0.2783\n",
      "Epoch 29/90\n",
      "108/108 [==============================] - 3s 27ms/step - loss: 0.3042 - val_loss: 0.2745\n",
      "Epoch 30/90\n",
      "108/108 [==============================] - 3s 27ms/step - loss: 0.3002 - val_loss: 0.2705\n",
      "Epoch 31/90\n",
      "108/108 [==============================] - 3s 27ms/step - loss: 0.2962 - val_loss: 0.2665\n",
      "Epoch 32/90\n",
      "108/108 [==============================] - 3s 27ms/step - loss: 0.2921 - val_loss: 0.2624\n",
      "Epoch 33/90\n",
      "108/108 [==============================] - 3s 29ms/step - loss: 0.2878 - val_loss: 0.2582\n",
      "Epoch 34/90\n",
      "108/108 [==============================] - 3s 28ms/step - loss: 0.2835 - val_loss: 0.2539\n",
      "Epoch 35/90\n",
      "108/108 [==============================] - 3s 27ms/step - loss: 0.2769 - val_loss: 0.2443\n",
      "Epoch 36/90\n",
      "108/108 [==============================] - 3s 28ms/step - loss: 0.2665 - val_loss: 0.2339\n",
      "Epoch 37/90\n",
      "108/108 [==============================] - 3s 28ms/step - loss: 0.2560 - val_loss: 0.2234\n",
      "Epoch 38/90\n",
      "108/108 [==============================] - 3s 28ms/step - loss: 0.2453 - val_loss: 0.2127\n",
      "Epoch 39/90\n",
      "108/108 [==============================] - 3s 28ms/step - loss: 0.2343 - val_loss: 0.2018\n",
      "Epoch 40/90\n",
      "108/108 [==============================] - 3s 27ms/step - loss: 0.2232 - val_loss: 0.1906\n",
      "Epoch 41/90\n",
      "108/108 [==============================] - 3s 27ms/step - loss: 0.2119 - val_loss: 0.1792\n",
      "Epoch 42/90\n",
      "108/108 [==============================] - 3s 27ms/step - loss: 0.2001 - val_loss: 0.1675\n",
      "Epoch 43/90\n",
      "108/108 [==============================] - 3s 27ms/step - loss: 0.1881 - val_loss: 0.1554\n",
      "Epoch 44/90\n",
      "108/108 [==============================] - 3s 29ms/step - loss: 0.1758 - val_loss: 0.1430\n",
      "Epoch 45/90\n",
      "108/108 [==============================] - 3s 27ms/step - loss: 0.1631 - val_loss: 0.1303\n",
      "Epoch 46/90\n",
      "108/108 [==============================] - 3s 27ms/step - loss: 0.1501 - val_loss: 0.1171\n",
      "Epoch 47/90\n",
      "108/108 [==============================] - 3s 27ms/step - loss: 0.1367 - val_loss: 0.1035\n",
      "Epoch 48/90\n",
      "108/108 [==============================] - 3s 27ms/step - loss: 0.1229 - val_loss: 0.0896\n",
      "Epoch 49/90\n",
      "108/108 [==============================] - 3s 29ms/step - loss: 0.1088 - val_loss: 0.0754\n",
      "Epoch 50/90\n",
      "108/108 [==============================] - 3s 27ms/step - loss: 0.0946 - val_loss: 0.0609\n",
      "Epoch 51/90\n",
      "108/108 [==============================] - 3s 27ms/step - loss: 0.0807 - val_loss: 0.0469\n",
      "Epoch 52/90\n",
      "108/108 [==============================] - 3s 27ms/step - loss: 0.0695 - val_loss: 0.0354\n",
      "Epoch 53/90\n",
      "108/108 [==============================] - 3s 27ms/step - loss: 0.0635 - val_loss: 0.0281\n",
      "Epoch 54/90\n",
      "108/108 [==============================] - 3s 28ms/step - loss: 0.0611 - val_loss: 0.0253\n",
      "Epoch 55/90\n",
      "108/108 [==============================] - 3s 28ms/step - loss: 0.0607 - val_loss: 0.0236\n",
      "Epoch 56/90\n",
      "108/108 [==============================] - 3s 27ms/step - loss: 0.0605 - val_loss: 0.0223\n",
      "Epoch 57/90\n",
      "108/108 [==============================] - 3s 27ms/step - loss: 0.0604 - val_loss: 0.0215\n",
      "Epoch 58/90\n",
      "108/108 [==============================] - 3s 27ms/step - loss: 0.0603 - val_loss: 0.0211\n",
      "Epoch 59/90\n",
      "108/108 [==============================] - 3s 28ms/step - loss: 0.0602 - val_loss: 0.0207\n",
      "Epoch 60/90\n",
      "108/108 [==============================] - 3s 29ms/step - loss: 0.0602 - val_loss: 0.0204\n",
      "Epoch 61/90\n",
      "108/108 [==============================] - 3s 27ms/step - loss: 0.0601 - val_loss: 0.0202\n",
      "Epoch 62/90\n",
      "108/108 [==============================] - 3s 27ms/step - loss: 0.0601 - val_loss: 0.0201\n",
      "Epoch 63/90\n",
      "108/108 [==============================] - 3s 27ms/step - loss: 0.0602 - val_loss: 0.0199\n",
      "Epoch 64/90\n",
      "108/108 [==============================] - 3s 27ms/step - loss: 0.0601 - val_loss: 0.0198\n",
      "Epoch 65/90\n",
      "108/108 [==============================] - 3s 29ms/step - loss: 0.0601 - val_loss: 0.0196\n",
      "Epoch 66/90\n",
      "108/108 [==============================] - 3s 27ms/step - loss: 0.0602 - val_loss: 0.0195\n",
      "Epoch 67/90\n",
      "108/108 [==============================] - 3s 27ms/step - loss: 0.0601 - val_loss: 0.0194\n",
      "Epoch 68/90\n",
      "108/108 [==============================] - 3s 27ms/step - loss: 0.0601 - val_loss: 0.0193\n",
      "Epoch 69/90\n",
      "108/108 [==============================] - 3s 27ms/step - loss: 0.0601 - val_loss: 0.0192\n",
      "Epoch 70/90\n",
      "108/108 [==============================] - 3s 28ms/step - loss: 0.0601 - val_loss: 0.0191\n",
      "Epoch 71/90\n",
      "108/108 [==============================] - 3s 28ms/step - loss: 0.0600 - val_loss: 0.0190\n",
      "Epoch 72/90\n",
      "108/108 [==============================] - 3s 27ms/step - loss: 0.0600 - val_loss: 0.0190\n",
      "Epoch 73/90\n",
      "108/108 [==============================] - 3s 27ms/step - loss: 0.0600 - val_loss: 0.0189\n",
      "Epoch 74/90\n",
      "108/108 [==============================] - 3s 28ms/step - loss: 0.0600 - val_loss: 0.0189\n",
      "Epoch 75/90\n",
      "108/108 [==============================] - 3s 28ms/step - loss: 0.0600 - val_loss: 0.0188\n",
      "Epoch 76/90\n",
      "108/108 [==============================] - 3s 28ms/step - loss: 0.0600 - val_loss: 0.0187\n",
      "Epoch 77/90\n",
      "108/108 [==============================] - 3s 27ms/step - loss: 0.0599 - val_loss: 0.0187\n",
      "Epoch 78/90\n",
      "108/108 [==============================] - 3s 27ms/step - loss: 0.0599 - val_loss: 0.0186\n",
      "Epoch 79/90\n",
      "108/108 [==============================] - 3s 27ms/step - loss: 0.0600 - val_loss: 0.0186\n",
      "Epoch 80/90\n",
      "108/108 [==============================] - 3s 27ms/step - loss: 0.0599 - val_loss: 0.0185\n",
      "Epoch 81/90\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "108/108 [==============================] - 3s 29ms/step - loss: 0.0600 - val_loss: 0.0185\n",
      "Epoch 82/90\n",
      "108/108 [==============================] - 3s 27ms/step - loss: 0.0600 - val_loss: 0.0184\n",
      "Epoch 83/90\n",
      "108/108 [==============================] - 3s 27ms/step - loss: 0.0599 - val_loss: 0.0184\n",
      "Epoch 84/90\n",
      "108/108 [==============================] - 3s 27ms/step - loss: 0.0598 - val_loss: 0.0183\n",
      "Epoch 85/90\n",
      "108/108 [==============================] - 3s 27ms/step - loss: 0.0599 - val_loss: 0.0183\n",
      "Epoch 86/90\n",
      "108/108 [==============================] - 3s 29ms/step - loss: 0.0598 - val_loss: 0.0182\n",
      "Epoch 87/90\n",
      "108/108 [==============================] - 3s 28ms/step - loss: 0.0598 - val_loss: 0.0182\n",
      "Epoch 88/90\n",
      "108/108 [==============================] - 3s 27ms/step - loss: 0.0598 - val_loss: 0.0181\n",
      "Epoch 89/90\n",
      "108/108 [==============================] - 3s 27ms/step - loss: 0.0598 - val_loss: 0.0181\n",
      "Epoch 90/90\n",
      "108/108 [==============================] - 3s 27ms/step - loss: 0.0598 - val_loss: 0.0181\n",
      "Execution time:  272.74858951568604\n",
      "DNN:\n",
      "Mean Absolute Error: 0.0464\n",
      "Root Mean Square Error: 0.0555\n",
      "Mean Square Error: 0.0031\n",
      "\n",
      "Train RMSE: 0.055\n",
      "Train MSE: 0.003\n",
      "Train MAE: 0.046\n",
      "###########################\n",
      "\n",
      "MODEL:  DNN\n",
      "sequence:  7d\n",
      "units:  12\n",
      "dropout1:  0.48476373451509647\n",
      "optimizer: adadelta\n",
      "activationDense: tanh\n",
      "epochs: 52\n",
      "batchsize: 57\n",
      "validation_split: 0.1\n",
      "Model: \"sequential_230\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_690 (Dense)            (None, 1008, 12)          24        \n",
      "_________________________________________________________________\n",
      "dense_691 (Dense)            (None, 1008, 16)          208       \n",
      "_________________________________________________________________\n",
      "dropout_230 (Dropout)        (None, 1008, 16)          0         \n",
      "_________________________________________________________________\n",
      "dense_692 (Dense)            (None, 1008, 1)           17        \n",
      "=================================================================\n",
      "Total params: 249\n",
      "Trainable params: 249\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/52\n",
      "48/48 [==============================] - 2s 37ms/step - loss: 0.4199 - val_loss: 0.3890\n",
      "Epoch 2/52\n",
      "48/48 [==============================] - 1s 29ms/step - loss: 0.4192 - val_loss: 0.3883\n",
      "Epoch 3/52\n",
      "48/48 [==============================] - 1s 30ms/step - loss: 0.4187 - val_loss: 0.3876\n",
      "Epoch 4/52\n",
      "48/48 [==============================] - 1s 30ms/step - loss: 0.4179 - val_loss: 0.3869\n",
      "Epoch 5/52\n",
      "48/48 [==============================] - 1s 30ms/step - loss: 0.4173 - val_loss: 0.3862\n",
      "Epoch 6/52\n",
      "48/48 [==============================] - 1s 30ms/step - loss: 0.4164 - val_loss: 0.3855\n",
      "Epoch 7/52\n",
      "48/48 [==============================] - 1s 30ms/step - loss: 0.4157 - val_loss: 0.3847\n",
      "Epoch 8/52\n",
      "48/48 [==============================] - 1s 31ms/step - loss: 0.4150 - val_loss: 0.3839\n",
      "Epoch 9/52\n",
      "48/48 [==============================] - 1s 30ms/step - loss: 0.4142 - val_loss: 0.3831\n",
      "Epoch 10/52\n",
      "48/48 [==============================] - 1s 30ms/step - loss: 0.4133 - val_loss: 0.3822\n",
      "Epoch 11/52\n",
      "48/48 [==============================] - 2s 32ms/step - loss: 0.4123 - val_loss: 0.3813\n",
      "Epoch 12/52\n",
      "48/48 [==============================] - 2s 33ms/step - loss: 0.4113 - val_loss: 0.3804\n",
      "Epoch 13/52\n",
      "48/48 [==============================] - 1s 31ms/step - loss: 0.4106 - val_loss: 0.3795\n",
      "Epoch 14/52\n",
      "48/48 [==============================] - 1s 30ms/step - loss: 0.4097 - val_loss: 0.3786\n",
      "Epoch 15/52\n",
      "48/48 [==============================] - 1s 30ms/step - loss: 0.4087 - val_loss: 0.3776\n",
      "Epoch 16/52\n",
      "48/48 [==============================] - 1s 30ms/step - loss: 0.4077 - val_loss: 0.3766\n",
      "Epoch 17/52\n",
      "48/48 [==============================] - 1s 30ms/step - loss: 0.4066 - val_loss: 0.3756\n",
      "Epoch 18/52\n",
      "48/48 [==============================] - 1s 30ms/step - loss: 0.4058 - val_loss: 0.3746\n",
      "Epoch 19/52\n",
      "48/48 [==============================] - 1s 30ms/step - loss: 0.4047 - val_loss: 0.3736\n",
      "Epoch 20/52\n",
      "48/48 [==============================] - 1s 30ms/step - loss: 0.4036 - val_loss: 0.3725\n",
      "Epoch 21/52\n",
      "48/48 [==============================] - 1s 30ms/step - loss: 0.4026 - val_loss: 0.3715\n",
      "Epoch 22/52\n",
      "48/48 [==============================] - 2s 33ms/step - loss: 0.4015 - val_loss: 0.3704\n",
      "Epoch 23/52\n",
      "48/48 [==============================] - 2s 32ms/step - loss: 0.4004 - val_loss: 0.3693\n",
      "Epoch 24/52\n",
      "48/48 [==============================] - 1s 30ms/step - loss: 0.3994 - val_loss: 0.3681\n",
      "Epoch 25/52\n",
      "48/48 [==============================] - 1s 30ms/step - loss: 0.3982 - val_loss: 0.3670\n",
      "Epoch 26/52\n",
      "48/48 [==============================] - 1s 31ms/step - loss: 0.3971 - val_loss: 0.3659\n",
      "Epoch 27/52\n",
      "48/48 [==============================] - 2s 32ms/step - loss: 0.3959 - val_loss: 0.3647\n",
      "Epoch 28/52\n",
      "48/48 [==============================] - 1s 31ms/step - loss: 0.3947 - val_loss: 0.3635\n",
      "Epoch 29/52\n",
      "48/48 [==============================] - 1s 31ms/step - loss: 0.3935 - val_loss: 0.3623\n",
      "Epoch 30/52\n",
      "48/48 [==============================] - 1s 31ms/step - loss: 0.3922 - val_loss: 0.3611\n",
      "Epoch 31/52\n",
      "48/48 [==============================] - 1s 30ms/step - loss: 0.3909 - val_loss: 0.3598\n",
      "Epoch 32/52\n",
      "48/48 [==============================] - 1s 31ms/step - loss: 0.3897 - val_loss: 0.3586- ETA: 1s - loss - ETA: 0s - l\n",
      "Epoch 33/52\n",
      "48/48 [==============================] - 2s 33ms/step - loss: 0.3886 - val_loss: 0.3573\n",
      "Epoch 34/52\n",
      "48/48 [==============================] - 2s 31ms/step - loss: 0.3871 - val_loss: 0.3560\n",
      "Epoch 35/52\n",
      "48/48 [==============================] - 1s 30ms/step - loss: 0.3859 - val_loss: 0.3547\n",
      "Epoch 36/52\n",
      "48/48 [==============================] - 1s 31ms/step - loss: 0.3846 - val_loss: 0.3534\n",
      "Epoch 37/52\n",
      "48/48 [==============================] - 1s 30ms/step - loss: 0.3833 - val_loss: 0.3521\n",
      "Epoch 38/52\n",
      "48/48 [==============================] - 1s 30ms/step - loss: 0.3820 - val_loss: 0.3507\n",
      "Epoch 39/52\n",
      "48/48 [==============================] - 1s 30ms/step - loss: 0.3806 - val_loss: 0.3494\n",
      "Epoch 40/52\n",
      "48/48 [==============================] - 1s 30ms/step - loss: 0.3791 - val_loss: 0.3480\n",
      "Epoch 41/52\n",
      "48/48 [==============================] - 1s 30ms/step - loss: 0.3778 - val_loss: 0.3466\n",
      "Epoch 42/52\n",
      "48/48 [==============================] - 1s 30ms/step - loss: 0.3764 - val_loss: 0.3452\n",
      "Epoch 43/52\n",
      "48/48 [==============================] - 2s 32ms/step - loss: 0.3750 - val_loss: 0.3438\n",
      "Epoch 44/52\n",
      "48/48 [==============================] - 2s 32ms/step - loss: 0.3735 - val_loss: 0.3424\n",
      "Epoch 45/52\n",
      "48/48 [==============================] - 1s 31ms/step - loss: 0.3722 - val_loss: 0.3409\n",
      "Epoch 46/52\n",
      "48/48 [==============================] - 1s 30ms/step - loss: 0.3707 - val_loss: 0.3395\n",
      "Epoch 47/52\n",
      "48/48 [==============================] - 1s 30ms/step - loss: 0.3692 - val_loss: 0.3380\n",
      "Epoch 48/52\n",
      "48/48 [==============================] - 1s 30ms/step - loss: 0.3679 - val_loss: 0.3365\n",
      "Epoch 49/52\n",
      "48/48 [==============================] - 1s 31ms/step - loss: 0.3662 - val_loss: 0.3350\n",
      "Epoch 50/52\n",
      "48/48 [==============================] - 1s 30ms/step - loss: 0.3648 - val_loss: 0.3335\n",
      "Epoch 51/52\n",
      "48/48 [==============================] - 1s 30ms/step - loss: 0.3631 - val_loss: 0.3320\n",
      "Epoch 52/52\n",
      "48/48 [==============================] - 1s 30ms/step - loss: 0.3617 - val_loss: 0.3304\n",
      "Execution time:  79.0238242149353\n",
      "DNN:\n",
      "Mean Absolute Error: 0.3645\n",
      "Root Mean Square Error: 0.3668\n",
      "Mean Square Error: 0.1346\n",
      "\n",
      "Train RMSE: 0.367\n",
      "Train MSE: 0.135\n",
      "Train MAE: 0.364\n",
      "###########################\n",
      "\n",
      "MODEL:  DNN\n",
      "sequence:  7d\n",
      "units:  87\n",
      "dropout1:  0.40519643149940265\n",
      "optimizer: adadelta\n",
      "activationDense: tanh\n",
      "epochs: 80\n",
      "batchsize: 31\n",
      "validation_split: 0.2\n",
      "Model: \"sequential_231\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_693 (Dense)            (None, 1008, 87)          174       \n",
      "_________________________________________________________________\n",
      "dense_694 (Dense)            (None, 1008, 16)          1408      \n",
      "_________________________________________________________________\n",
      "dropout_231 (Dropout)        (None, 1008, 16)          0         \n",
      "_________________________________________________________________\n",
      "dense_695 (Dense)            (None, 1008, 1)           17        \n",
      "=================================================================\n",
      "Total params: 1,599\n",
      "Trainable params: 1,599\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/80\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "77/77 [==============================] - 3s 41ms/step - loss: 0.3916 - val_loss: 0.3662\n",
      "Epoch 2/80\n",
      "77/77 [==============================] - 3s 36ms/step - loss: 0.3895 - val_loss: 0.3641\n",
      "Epoch 3/80\n",
      "77/77 [==============================] - 3s 37ms/step - loss: 0.3873 - val_loss: 0.3619\n",
      "Epoch 4/80\n",
      "77/77 [==============================] - 3s 36ms/step - loss: 0.3849 - val_loss: 0.3595\n",
      "Epoch 5/80\n",
      "77/77 [==============================] - 3s 36ms/step - loss: 0.3824 - val_loss: 0.3570\n",
      "Epoch 6/80\n",
      "77/77 [==============================] - 3s 38ms/step - loss: 0.3798 - val_loss: 0.3543\n",
      "Epoch 7/80\n",
      "77/77 [==============================] - 3s 37ms/step - loss: 0.3770 - val_loss: 0.3516\n",
      "Epoch 8/80\n",
      "77/77 [==============================] - 3s 36ms/step - loss: 0.3742 - val_loss: 0.3487\n",
      "Epoch 9/80\n",
      "77/77 [==============================] - 3s 37ms/step - loss: 0.3712 - val_loss: 0.3457\n",
      "Epoch 10/80\n",
      "77/77 [==============================] - 3s 36ms/step - loss: 0.3681 - val_loss: 0.3427\n",
      "Epoch 11/80\n",
      "77/77 [==============================] - 3s 36ms/step - loss: 0.3650 - val_loss: 0.3397\n",
      "Epoch 12/80\n",
      "77/77 [==============================] - 3s 39ms/step - loss: 0.3619 - val_loss: 0.3367\n",
      "Epoch 13/80\n",
      "77/77 [==============================] - 3s 37ms/step - loss: 0.3588 - val_loss: 0.3336\n",
      "Epoch 14/80\n",
      "77/77 [==============================] - 3s 37ms/step - loss: 0.3556 - val_loss: 0.3303\n",
      "Epoch 15/80\n",
      "77/77 [==============================] - 3s 36ms/step - loss: 0.3522 - val_loss: 0.3270\n",
      "Epoch 16/80\n",
      "77/77 [==============================] - 3s 36ms/step - loss: 0.3488 - val_loss: 0.3239\n",
      "Epoch 17/80\n",
      "77/77 [==============================] - 3s 37ms/step - loss: 0.3457 - val_loss: 0.3208\n",
      "Epoch 18/80\n",
      "77/77 [==============================] - 3s 38ms/step - loss: 0.3424 - val_loss: 0.3176\n",
      "Epoch 19/80\n",
      "77/77 [==============================] - 3s 37ms/step - loss: 0.3391 - val_loss: 0.3143\n",
      "Epoch 20/80\n",
      "77/77 [==============================] - 3s 37ms/step - loss: 0.3358 - val_loss: 0.3112\n",
      "Epoch 21/80\n",
      "77/77 [==============================] - 3s 37ms/step - loss: 0.3327 - val_loss: 0.3083\n",
      "Epoch 22/80\n",
      "77/77 [==============================] - 3s 36ms/step - loss: 0.3297 - val_loss: 0.3053\n",
      "Epoch 23/80\n",
      "77/77 [==============================] - 3s 39ms/step - loss: 0.3266 - val_loss: 0.3023\n",
      "Epoch 24/80\n",
      "77/77 [==============================] - 3s 37ms/step - loss: 0.3234 - val_loss: 0.2991\n",
      "Epoch 25/80\n",
      "77/77 [==============================] - 3s 37ms/step - loss: 0.3202 - val_loss: 0.2959\n",
      "Epoch 26/80\n",
      "77/77 [==============================] - 3s 37ms/step - loss: 0.3169 - val_loss: 0.2927\n",
      "Epoch 27/80\n",
      "77/77 [==============================] - 3s 37ms/step - loss: 0.3135 - val_loss: 0.2893\n",
      "Epoch 28/80\n",
      "77/77 [==============================] - 3s 37ms/step - loss: 0.3102 - val_loss: 0.2861\n",
      "Epoch 29/80\n",
      "77/77 [==============================] - 3s 38ms/step - loss: 0.3068 - val_loss: 0.2828\n",
      "Epoch 30/80\n",
      "77/77 [==============================] - 3s 36ms/step - loss: 0.3035 - val_loss: 0.2794\n",
      "Epoch 31/80\n",
      "77/77 [==============================] - 3s 37ms/step - loss: 0.3000 - val_loss: 0.2760\n",
      "Epoch 32/80\n",
      "77/77 [==============================] - 3s 36ms/step - loss: 0.2965 - val_loss: 0.2726\n",
      "Epoch 33/80\n",
      "77/77 [==============================] - 3s 37ms/step - loss: 0.2930 - val_loss: 0.2690\n",
      "Epoch 34/80\n",
      "77/77 [==============================] - 3s 39ms/step - loss: 0.2893 - val_loss: 0.2654\n",
      "Epoch 35/80\n",
      "77/77 [==============================] - 3s 37ms/step - loss: 0.2847 - val_loss: 0.2583\n",
      "Epoch 36/80\n",
      "77/77 [==============================] - 3s 36ms/step - loss: 0.2759 - val_loss: 0.2490\n",
      "Epoch 37/80\n",
      "77/77 [==============================] - 3s 37ms/step - loss: 0.2667 - val_loss: 0.2397\n",
      "Epoch 38/80\n",
      "77/77 [==============================] - 3s 37ms/step - loss: 0.2572 - val_loss: 0.2304\n",
      "Epoch 39/80\n",
      "77/77 [==============================] - 3s 38ms/step - loss: 0.2478 - val_loss: 0.2211\n",
      "Epoch 40/80\n",
      "77/77 [==============================] - 3s 38ms/step - loss: 0.2385 - val_loss: 0.2118\n",
      "Epoch 41/80\n",
      "77/77 [==============================] - 3s 37ms/step - loss: 0.2292 - val_loss: 0.2024\n",
      "Epoch 42/80\n",
      "77/77 [==============================] - 3s 36ms/step - loss: 0.2196 - val_loss: 0.1929\n",
      "Epoch 43/80\n",
      "77/77 [==============================] - 3s 37ms/step - loss: 0.2099 - val_loss: 0.1832\n",
      "Epoch 44/80\n",
      "77/77 [==============================] - 3s 37ms/step - loss: 0.2002 - val_loss: 0.1733\n",
      "Epoch 45/80\n",
      "77/77 [==============================] - 3s 39ms/step - loss: 0.1904 - val_loss: 0.1633\n",
      "Epoch 46/80\n",
      "77/77 [==============================] - 3s 37ms/step - loss: 0.1804 - val_loss: 0.1533\n",
      "Epoch 47/80\n",
      "77/77 [==============================] - 3s 37ms/step - loss: 0.1707 - val_loss: 0.1434\n",
      "Epoch 48/80\n",
      "77/77 [==============================] - 3s 37ms/step - loss: 0.1618 - val_loss: 0.1340\n",
      "Epoch 49/80\n",
      "77/77 [==============================] - 3s 37ms/step - loss: 0.1539 - val_loss: 0.1252\n",
      "Epoch 50/80\n",
      "77/77 [==============================] - 3s 37ms/step - loss: 0.1474 - val_loss: 0.1170\n",
      "Epoch 51/80\n",
      "77/77 [==============================] - 3s 38ms/step - loss: 0.1415 - val_loss: 0.1094\n",
      "Epoch 52/80\n",
      "77/77 [==============================] - 3s 37ms/step - loss: 0.1366 - val_loss: 0.1024\n",
      "Epoch 53/80\n",
      "77/77 [==============================] - 3s 37ms/step - loss: 0.1328 - val_loss: 0.0963\n",
      "Epoch 54/80\n",
      "77/77 [==============================] - 3s 37ms/step - loss: 0.1295 - val_loss: 0.0908\n",
      "Epoch 55/80\n",
      "77/77 [==============================] - 3s 37ms/step - loss: 0.1270 - val_loss: 0.0860\n",
      "Epoch 56/80\n",
      "77/77 [==============================] - 3s 39ms/step - loss: 0.1248 - val_loss: 0.0819\n",
      "Epoch 57/80\n",
      "77/77 [==============================] - 3s 37ms/step - loss: 0.1232 - val_loss: 0.0785\n",
      "Epoch 58/80\n",
      "77/77 [==============================] - 3s 37ms/step - loss: 0.1221 - val_loss: 0.0757\n",
      "Epoch 59/80\n",
      "77/77 [==============================] - 3s 37ms/step - loss: 0.1211 - val_loss: 0.0734\n",
      "Epoch 60/80\n",
      "77/77 [==============================] - 3s 37ms/step - loss: 0.1204 - val_loss: 0.0715\n",
      "Epoch 61/80\n",
      "77/77 [==============================] - 3s 38ms/step - loss: 0.1197 - val_loss: 0.0698\n",
      "Epoch 62/80\n",
      "77/77 [==============================] - 3s 38ms/step - loss: 0.1192 - val_loss: 0.0683\n",
      "Epoch 63/80\n",
      "77/77 [==============================] - 3s 36ms/step - loss: 0.1188 - val_loss: 0.0669\n",
      "Epoch 64/80\n",
      "77/77 [==============================] - 3s 37ms/step - loss: 0.1182 - val_loss: 0.0657\n",
      "Epoch 65/80\n",
      "77/77 [==============================] - 3s 37ms/step - loss: 0.1179 - val_loss: 0.0645\n",
      "Epoch 66/80\n",
      "77/77 [==============================] - 3s 36ms/step - loss: 0.1175 - val_loss: 0.0634\n",
      "Epoch 67/80\n",
      "77/77 [==============================] - 3s 39ms/step - loss: 0.1171 - val_loss: 0.0624\n",
      "Epoch 68/80\n",
      "77/77 [==============================] - 3s 37ms/step - loss: 0.1167 - val_loss: 0.0614\n",
      "Epoch 69/80\n",
      "77/77 [==============================] - 3s 36ms/step - loss: 0.1163 - val_loss: 0.0604\n",
      "Epoch 70/80\n",
      "77/77 [==============================] - 3s 37ms/step - loss: 0.1161 - val_loss: 0.0594\n",
      "Epoch 71/80\n",
      "77/77 [==============================] - 3s 37ms/step - loss: 0.1157 - val_loss: 0.0585\n",
      "Epoch 72/80\n",
      "77/77 [==============================] - 3s 38ms/step - loss: 0.1154 - val_loss: 0.0576\n",
      "Epoch 73/80\n",
      "77/77 [==============================] - 3s 38ms/step - loss: 0.1150 - val_loss: 0.0568\n",
      "Epoch 74/80\n",
      "77/77 [==============================] - 3s 37ms/step - loss: 0.1148 - val_loss: 0.0559\n",
      "Epoch 75/80\n",
      "77/77 [==============================] - 3s 37ms/step - loss: 0.1144 - val_loss: 0.0551\n",
      "Epoch 76/80\n",
      "77/77 [==============================] - 3s 37ms/step - loss: 0.1141 - val_loss: 0.0542\n",
      "Epoch 77/80\n",
      "77/77 [==============================] - 3s 37ms/step - loss: 0.1138 - val_loss: 0.0534\n",
      "Epoch 78/80\n",
      "77/77 [==============================] - 3s 39ms/step - loss: 0.1136 - val_loss: 0.0527\n",
      "Epoch 79/80\n",
      "77/77 [==============================] - 3s 38ms/step - loss: 0.1133 - val_loss: 0.0519\n",
      "Epoch 80/80\n",
      "77/77 [==============================] - 3s 37ms/step - loss: 0.1131 - val_loss: 0.0511\n",
      "Execution time:  233.4064164161682\n",
      "DNN:\n",
      "Mean Absolute Error: 0.0731\n",
      "Root Mean Square Error: 0.0784\n",
      "Mean Square Error: 0.0061\n",
      "\n",
      "Train RMSE: 0.078\n",
      "Train MSE: 0.006\n",
      "Train MAE: 0.073\n",
      "###########################\n",
      "\n",
      "MODEL:  DNN\n",
      "sequence:  7d\n",
      "units:  80\n",
      "dropout1:  0.11814836227952394\n",
      "optimizer: adadelta\n",
      "activationDense: tanh\n",
      "epochs: 90\n",
      "batchsize: 25\n",
      "validation_split: 0.2\n",
      "Model: \"sequential_232\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_696 (Dense)            (None, 1008, 80)          160       \n",
      "_________________________________________________________________\n",
      "dense_697 (Dense)            (None, 1008, 16)          1296      \n",
      "_________________________________________________________________\n",
      "dropout_232 (Dropout)        (None, 1008, 16)          0         \n",
      "_________________________________________________________________\n",
      "dense_698 (Dense)            (None, 1008, 1)           17        \n",
      "=================================================================\n",
      "Total params: 1,473\n",
      "Trainable params: 1,473\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/90\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "96/96 [==============================] - 3s 30ms/step - loss: 0.3559 - val_loss: 0.3315\n",
      "Epoch 2/90\n",
      "96/96 [==============================] - 3s 28ms/step - loss: 0.3525 - val_loss: 0.3280\n",
      "Epoch 3/90\n",
      "96/96 [==============================] - 3s 30ms/step - loss: 0.3488 - val_loss: 0.3242\n",
      "Epoch 4/90\n",
      "96/96 [==============================] - 3s 28ms/step - loss: 0.3449 - val_loss: 0.3202\n",
      "Epoch 5/90\n",
      "96/96 [==============================] - 3s 28ms/step - loss: 0.3407 - val_loss: 0.3160\n",
      "Epoch 6/90\n",
      "96/96 [==============================] - 3s 28ms/step - loss: 0.3363 - val_loss: 0.3116\n",
      "Epoch 7/90\n",
      "96/96 [==============================] - 3s 28ms/step - loss: 0.3316 - val_loss: 0.3069\n",
      "Epoch 8/90\n",
      "96/96 [==============================] - 3s 28ms/step - loss: 0.3268 - val_loss: 0.3020\n",
      "Epoch 9/90\n",
      "96/96 [==============================] - 3s 30ms/step - loss: 0.3218 - val_loss: 0.2970\n",
      "Epoch 10/90\n",
      "96/96 [==============================] - 3s 28ms/step - loss: 0.3165 - val_loss: 0.2917\n",
      "Epoch 11/90\n",
      "96/96 [==============================] - 3s 28ms/step - loss: 0.3111 - val_loss: 0.2863\n",
      "Epoch 12/90\n",
      "96/96 [==============================] - 3s 28ms/step - loss: 0.3054 - val_loss: 0.2806\n",
      "Epoch 13/90\n",
      "96/96 [==============================] - 3s 28ms/step - loss: 0.2996 - val_loss: 0.2748\n",
      "Epoch 14/90\n",
      "96/96 [==============================] - 3s 29ms/step - loss: 0.2936 - val_loss: 0.2688\n",
      "Epoch 15/90\n",
      "96/96 [==============================] - 3s 30ms/step - loss: 0.2874 - val_loss: 0.2627\n",
      "Epoch 16/90\n",
      "96/96 [==============================] - 3s 28ms/step - loss: 0.2811 - val_loss: 0.2565\n",
      "Epoch 17/90\n",
      "96/96 [==============================] - 3s 28ms/step - loss: 0.2747 - val_loss: 0.2501\n",
      "Epoch 18/90\n",
      "96/96 [==============================] - 3s 28ms/step - loss: 0.2680 - val_loss: 0.2435\n",
      "Epoch 19/90\n",
      "96/96 [==============================] - 3s 28ms/step - loss: 0.2613 - val_loss: 0.2368\n",
      "Epoch 20/90\n",
      "96/96 [==============================] - 3s 30ms/step - loss: 0.2544 - val_loss: 0.2299\n",
      "Epoch 21/90\n",
      "96/96 [==============================] - 3s 29ms/step - loss: 0.2473 - val_loss: 0.2229\n",
      "Epoch 22/90\n",
      "96/96 [==============================] - 3s 28ms/step - loss: 0.2401 - val_loss: 0.2157\n",
      "Epoch 23/90\n",
      "96/96 [==============================] - 3s 28ms/step - loss: 0.2326 - val_loss: 0.2083\n",
      "Epoch 24/90\n",
      "96/96 [==============================] - 3s 28ms/step - loss: 0.2251 - val_loss: 0.2008\n",
      "Epoch 25/90\n",
      "96/96 [==============================] - 3s 28ms/step - loss: 0.2176 - val_loss: 0.1938\n",
      "Epoch 26/90\n",
      "96/96 [==============================] - 3s 30ms/step - loss: 0.2104 - val_loss: 0.1867\n",
      "Epoch 27/90\n",
      "96/96 [==============================] - 3s 29ms/step - loss: 0.2031 - val_loss: 0.1795\n",
      "Epoch 28/90\n",
      "96/96 [==============================] - 3s 28ms/step - loss: 0.1956 - val_loss: 0.1721\n",
      "Epoch 29/90\n",
      "96/96 [==============================] - 3s 28ms/step - loss: 0.1882 - val_loss: 0.1646\n",
      "Epoch 30/90\n",
      "96/96 [==============================] - 3s 28ms/step - loss: 0.1804 - val_loss: 0.1570\n",
      "Epoch 31/90\n",
      "96/96 [==============================] - 3s 29ms/step - loss: 0.1726 - val_loss: 0.1493\n",
      "Epoch 32/90\n",
      "96/96 [==============================] - 3s 30ms/step - loss: 0.1647 - val_loss: 0.1414\n",
      "Epoch 33/90\n",
      "96/96 [==============================] - 3s 28ms/step - loss: 0.1567 - val_loss: 0.1335\n",
      "Epoch 34/90\n",
      "96/96 [==============================] - 3s 28ms/step - loss: 0.1485 - val_loss: 0.1253\n",
      "Epoch 35/90\n",
      "96/96 [==============================] - 3s 28ms/step - loss: 0.1402 - val_loss: 0.1170\n",
      "Epoch 36/90\n",
      "96/96 [==============================] - 3s 28ms/step - loss: 0.1317 - val_loss: 0.1086\n",
      "Epoch 37/90\n",
      "96/96 [==============================] - 3s 29ms/step - loss: 0.1232 - val_loss: 0.1000\n",
      "Epoch 38/90\n",
      "96/96 [==============================] - 3s 29ms/step - loss: 0.1144 - val_loss: 0.0913\n",
      "Epoch 39/90\n",
      "96/96 [==============================] - 3s 28ms/step - loss: 0.1055 - val_loss: 0.0824\n",
      "Epoch 40/90\n",
      "96/96 [==============================] - 3s 29ms/step - loss: 0.0968 - val_loss: 0.0736\n",
      "Epoch 41/90\n",
      "96/96 [==============================] - 3s 28ms/step - loss: 0.0883 - val_loss: 0.0649\n",
      "Epoch 42/90\n",
      "96/96 [==============================] - 3s 29ms/step - loss: 0.0805 - val_loss: 0.0567\n",
      "Epoch 43/90\n",
      "96/96 [==============================] - 3s 30ms/step - loss: 0.0737 - val_loss: 0.0492\n",
      "Epoch 44/90\n",
      "96/96 [==============================] - 3s 29ms/step - loss: 0.0681 - val_loss: 0.0426\n",
      "Epoch 45/90\n",
      "96/96 [==============================] - 3s 28ms/step - loss: 0.0637 - val_loss: 0.0370\n",
      "Epoch 46/90\n",
      "96/96 [==============================] - 3s 28ms/step - loss: 0.0607 - val_loss: 0.0332\n",
      "Epoch 47/90\n",
      "96/96 [==============================] - 3s 28ms/step - loss: 0.0593 - val_loss: 0.0304\n",
      "Epoch 48/90\n",
      "96/96 [==============================] - 3s 29ms/step - loss: 0.0583 - val_loss: 0.0281\n",
      "Epoch 49/90\n",
      "96/96 [==============================] - 3s 30ms/step - loss: 0.0576 - val_loss: 0.0264\n",
      "Epoch 50/90\n",
      "96/96 [==============================] - 3s 28ms/step - loss: 0.0571 - val_loss: 0.0250\n",
      "Epoch 51/90\n",
      "96/96 [==============================] - 3s 28ms/step - loss: 0.0568 - val_loss: 0.0240\n",
      "Epoch 52/90\n",
      "96/96 [==============================] - 3s 28ms/step - loss: 0.0566 - val_loss: 0.0231\n",
      "Epoch 53/90\n",
      "96/96 [==============================] - 3s 28ms/step - loss: 0.0563 - val_loss: 0.0223\n",
      "Epoch 54/90\n",
      "96/96 [==============================] - 3s 29ms/step - loss: 0.0561 - val_loss: 0.0216\n",
      "Epoch 55/90\n",
      "96/96 [==============================] - 3s 30ms/step - loss: 0.0560 - val_loss: 0.0209\n",
      "Epoch 56/90\n",
      "96/96 [==============================] - 3s 28ms/step - loss: 0.0558 - val_loss: 0.0203\n",
      "Epoch 57/90\n",
      "96/96 [==============================] - 3s 28ms/step - loss: 0.0556 - val_loss: 0.0198\n",
      "Epoch 58/90\n",
      "96/96 [==============================] - 3s 29ms/step - loss: 0.0555 - val_loss: 0.0192\n",
      "Epoch 59/90\n",
      "96/96 [==============================] - 3s 28ms/step - loss: 0.0555 - val_loss: 0.0188\n",
      "Epoch 60/90\n",
      "96/96 [==============================] - 3s 29ms/step - loss: 0.0554 - val_loss: 0.0183\n",
      "Epoch 61/90\n",
      "96/96 [==============================] - 3s 30ms/step - loss: 0.0552 - val_loss: 0.0179\n",
      "Epoch 62/90\n",
      "96/96 [==============================] - 3s 28ms/step - loss: 0.0552 - val_loss: 0.0175\n",
      "Epoch 63/90\n",
      "96/96 [==============================] - 3s 28ms/step - loss: 0.0550 - val_loss: 0.0171\n",
      "Epoch 64/90\n",
      "96/96 [==============================] - 3s 28ms/step - loss: 0.0550 - val_loss: 0.0167\n",
      "Epoch 65/90\n",
      "96/96 [==============================] - 3s 28ms/step - loss: 0.0549 - val_loss: 0.0164\n",
      "Epoch 66/90\n",
      "96/96 [==============================] - 3s 30ms/step - loss: 0.0549 - val_loss: 0.0161\n",
      "Epoch 67/90\n",
      "96/96 [==============================] - 3s 29ms/step - loss: 0.0549 - val_loss: 0.0158\n",
      "Epoch 68/90\n",
      "96/96 [==============================] - 3s 28ms/step - loss: 0.0548 - val_loss: 0.0156\n",
      "Epoch 69/90\n",
      "96/96 [==============================] - 3s 28ms/step - loss: 0.0547 - val_loss: 0.0153\n",
      "Epoch 70/90\n",
      "96/96 [==============================] - 3s 28ms/step - loss: 0.0547 - val_loss: 0.0150\n",
      "Epoch 71/90\n",
      "96/96 [==============================] - 3s 29ms/step - loss: 0.0546 - val_loss: 0.0148\n",
      "Epoch 72/90\n",
      "96/96 [==============================] - 3s 30ms/step - loss: 0.0546 - val_loss: 0.0146\n",
      "Epoch 73/90\n",
      "96/96 [==============================] - 3s 28ms/step - loss: 0.0546 - val_loss: 0.0144\n",
      "Epoch 74/90\n",
      "96/96 [==============================] - 3s 29ms/step - loss: 0.0546 - val_loss: 0.0141\n",
      "Epoch 75/90\n",
      "96/96 [==============================] - 3s 28ms/step - loss: 0.0545 - val_loss: 0.0139\n",
      "Epoch 76/90\n",
      "96/96 [==============================] - 3s 29ms/step - loss: 0.0545 - val_loss: 0.0137\n",
      "Epoch 77/90\n",
      "96/96 [==============================] - 3s 29ms/step - loss: 0.0545 - val_loss: 0.0135\n",
      "Epoch 78/90\n",
      "96/96 [==============================] - 3s 29ms/step - loss: 0.0545 - val_loss: 0.0133\n",
      "Epoch 79/90\n",
      "96/96 [==============================] - 3s 29ms/step - loss: 0.0544 - val_loss: 0.0132\n",
      "Epoch 80/90\n",
      "96/96 [==============================] - 3s 29ms/step - loss: 0.0544 - val_loss: 0.0131\n",
      "Epoch 81/90\n",
      "96/96 [==============================] - 3s 28ms/step - loss: 0.0543 - val_loss: 0.0130\n",
      "Epoch 82/90\n",
      "96/96 [==============================] - 3s 28ms/step - loss: 0.0543 - val_loss: 0.0130\n",
      "Epoch 83/90\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "96/96 [==============================] - 3s 30ms/step - loss: 0.0543 - val_loss: 0.0129\n",
      "Epoch 84/90\n",
      "96/96 [==============================] - 3s 29ms/step - loss: 0.0543 - val_loss: 0.0129\n",
      "Epoch 85/90\n",
      "96/96 [==============================] - 3s 28ms/step - loss: 0.0543 - val_loss: 0.0129\n",
      "Epoch 86/90\n",
      "96/96 [==============================] - 3s 29ms/step - loss: 0.0542 - val_loss: 0.0128\n",
      "Epoch 87/90\n",
      "96/96 [==============================] - 3s 28ms/step - loss: 0.0542 - val_loss: 0.0128\n",
      "Epoch 88/90\n",
      "96/96 [==============================] - 3s 28ms/step - loss: 0.0542 - val_loss: 0.0127\n",
      "Epoch 89/90\n",
      "96/96 [==============================] - 3s 30ms/step - loss: 0.0542 - val_loss: 0.0127\n",
      "Epoch 90/90\n",
      "96/96 [==============================] - 3s 28ms/step - loss: 0.0542 - val_loss: 0.0127\n",
      "Execution time:  252.02367758750916\n",
      "DNN:\n",
      "Mean Absolute Error: 0.0265\n",
      "Root Mean Square Error: 0.0361\n",
      "Mean Square Error: 0.0013\n",
      "\n",
      "Train RMSE: 0.036\n",
      "Train MSE: 0.001\n",
      "Train MAE: 0.027\n",
      "###########################\n",
      "\n",
      "MODEL:  DNN\n",
      "sequence:  7d\n",
      "units:  12\n",
      "dropout1:  0.48476373451509647\n",
      "optimizer: adadelta\n",
      "activationDense: tanh\n",
      "epochs: 52\n",
      "batchsize: 57\n",
      "validation_split: 0.2\n",
      "Model: \"sequential_233\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_699 (Dense)            (None, 1008, 12)          24        \n",
      "_________________________________________________________________\n",
      "dense_700 (Dense)            (None, 1008, 16)          208       \n",
      "_________________________________________________________________\n",
      "dropout_233 (Dropout)        (None, 1008, 16)          0         \n",
      "_________________________________________________________________\n",
      "dense_701 (Dense)            (None, 1008, 1)           17        \n",
      "=================================================================\n",
      "Total params: 249\n",
      "Trainable params: 249\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/52\n",
      "42/42 [==============================] - 1s 35ms/step - loss: 0.4052 - val_loss: 0.3800\n",
      "Epoch 2/52\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 0.4046 - val_loss: 0.3795\n",
      "Epoch 3/52\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 0.4042 - val_loss: 0.3791\n",
      "Epoch 4/52\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 0.4037 - val_loss: 0.3786\n",
      "Epoch 5/52\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 0.4032 - val_loss: 0.3781\n",
      "Epoch 6/52\n",
      "42/42 [==============================] - 1s 32ms/step - loss: 0.4027 - val_loss: 0.3776\n",
      "Epoch 7/52\n",
      "42/42 [==============================] - 1s 34ms/step - loss: 0.4023 - val_loss: 0.3771\n",
      "Epoch 8/52\n",
      "42/42 [==============================] - 1s 33ms/step - loss: 0.4017 - val_loss: 0.3765\n",
      "Epoch 9/52\n",
      "42/42 [==============================] - 1s 32ms/step - loss: 0.4011 - val_loss: 0.3760\n",
      "Epoch 10/52\n",
      "42/42 [==============================] - 1s 32ms/step - loss: 0.4006 - val_loss: 0.3754\n",
      "Epoch 11/52\n",
      "42/42 [==============================] - 1s 32ms/step - loss: 0.4000 - val_loss: 0.3748\n",
      "Epoch 12/52\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 0.3994 - val_loss: 0.3742\n",
      "Epoch 13/52\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 0.3988 - val_loss: 0.3736\n",
      "Epoch 14/52\n",
      "42/42 [==============================] - 1s 32ms/step - loss: 0.3982 - val_loss: 0.3730\n",
      "Epoch 15/52\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.3975 - val_loss: 0.3724\n",
      "Epoch 16/52\n",
      "42/42 [==============================] - 1s 36ms/step - loss: 0.3969 - val_loss: 0.3717\n",
      "Epoch 17/52\n",
      "42/42 [==============================] - 1s 35ms/step - loss: 0.3961 - val_loss: 0.3711\n",
      "Epoch 18/52\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.3955 - val_loss: 0.3704\n",
      "Epoch 19/52\n",
      "42/42 [==============================] - 1s 35ms/step - loss: 0.3949 - val_loss: 0.3697\n",
      "Epoch 20/52\n",
      "42/42 [==============================] - 1s 33ms/step - loss: 0.3942 - val_loss: 0.3690\n",
      "Epoch 21/52\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 0.3934 - val_loss: 0.3683\n",
      "Epoch 22/52\n",
      "42/42 [==============================] - 1s 32ms/step - loss: 0.3927 - val_loss: 0.3676\n",
      "Epoch 23/52\n",
      "42/42 [==============================] - 1s 32ms/step - loss: 0.3920 - val_loss: 0.3669\n",
      "Epoch 24/52\n",
      "42/42 [==============================] - 1s 32ms/step - loss: 0.3913 - val_loss: 0.3661\n",
      "Epoch 25/52\n",
      "42/42 [==============================] - 1s 32ms/step - loss: 0.3905 - val_loss: 0.3654: 0s - loss: 0\n",
      "Epoch 26/52\n",
      "42/42 [==============================] - 1s 32ms/step - loss: 0.3898 - val_loss: 0.3647\n",
      "Epoch 27/52\n",
      "42/42 [==============================] - 1s 32ms/step - loss: 0.3890 - val_loss: 0.3639\n",
      "Epoch 28/52\n",
      "42/42 [==============================] - 1s 32ms/step - loss: 0.3882 - val_loss: 0.3632\n",
      "Epoch 29/52\n",
      "42/42 [==============================] - 1s 34ms/step - loss: 0.3874 - val_loss: 0.3624\n",
      "Epoch 30/52\n",
      "42/42 [==============================] - 1s 35ms/step - loss: 0.3867 - val_loss: 0.3616\n",
      "Epoch 31/52\n",
      "42/42 [==============================] - 1s 34ms/step - loss: 0.3859 - val_loss: 0.3608\n",
      "Epoch 32/52\n",
      "42/42 [==============================] - 1s 33ms/step - loss: 0.3851 - val_loss: 0.3600\n",
      "Epoch 33/52\n",
      "42/42 [==============================] - 1s 33ms/step - loss: 0.3843 - val_loss: 0.3592\n",
      "Epoch 34/52\n",
      "42/42 [==============================] - 1s 32ms/step - loss: 0.3836 - val_loss: 0.3584\n",
      "Epoch 35/52\n",
      "42/42 [==============================] - 1s 32ms/step - loss: 0.3827 - val_loss: 0.3576\n",
      "Epoch 36/52\n",
      "42/42 [==============================] - 1s 32ms/step - loss: 0.3817 - val_loss: 0.3567\n",
      "Epoch 37/52\n",
      "42/42 [==============================] - 1s 33ms/step - loss: 0.3809 - val_loss: 0.3559\n",
      "Epoch 38/52\n",
      "42/42 [==============================] - 1s 33ms/step - loss: 0.3800 - val_loss: 0.3550\n",
      "Epoch 39/52\n",
      "42/42 [==============================] - 1s 32ms/step - loss: 0.3793 - val_loss: 0.3542\n",
      "Epoch 40/52\n",
      "42/42 [==============================] - 1s 33ms/step - loss: 0.3782 - val_loss: 0.3533\n",
      "Epoch 41/52\n",
      "42/42 [==============================] - 1s 35ms/step - loss: 0.3773 - val_loss: 0.3524\n",
      "Epoch 42/52\n",
      "42/42 [==============================] - 1s 33ms/step - loss: 0.3765 - val_loss: 0.3515\n",
      "Epoch 43/52\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.375 - 1s 32ms/step - loss: 0.3756 - val_loss: 0.3506\n",
      "Epoch 44/52\n",
      "42/42 [==============================] - 1s 32ms/step - loss: 0.3747 - val_loss: 0.3497\n",
      "Epoch 45/52\n",
      "42/42 [==============================] - 1s 33ms/step - loss: 0.3737 - val_loss: 0.3488\n",
      "Epoch 46/52\n",
      "42/42 [==============================] - 1s 33ms/step - loss: 0.3728 - val_loss: 0.3478\n",
      "Epoch 47/52\n",
      "42/42 [==============================] - 1s 32ms/step - loss: 0.3718 - val_loss: 0.3469\n",
      "Epoch 48/52\n",
      "42/42 [==============================] - 1s 32ms/step - loss: 0.3709 - val_loss: 0.3460\n",
      "Epoch 49/52\n",
      "42/42 [==============================] - 1s 32ms/step - loss: 0.3700 - val_loss: 0.3450\n",
      "Epoch 50/52\n",
      "42/42 [==============================] - 1s 32ms/step - loss: 0.3690 - val_loss: 0.3440\n",
      "Epoch 51/52\n",
      "42/42 [==============================] - 1s 32ms/step - loss: 0.3680 - val_loss: 0.3431\n",
      "Epoch 52/52\n",
      "42/42 [==============================] - 1s 35ms/step - loss: 0.3670 - val_loss: 0.3421\n",
      "Execution time:  74.60365986824036\n",
      "DNN:\n",
      "Mean Absolute Error: 0.3688\n",
      "Root Mean Square Error: 0.3710\n",
      "Mean Square Error: 0.1377\n",
      "\n",
      "Train RMSE: 0.371\n",
      "Train MSE: 0.138\n",
      "Train MAE: 0.369\n",
      "###########################\n",
      "\n",
      "MODEL:  DNN\n",
      "sequence:  7d\n",
      "units:  87\n",
      "dropout1:  0.40519643149940265\n",
      "optimizer: adadelta\n",
      "activationDense: sigmoid\n",
      "epochs: 80\n",
      "batchsize: 31\n",
      "validation_split: 0.1\n",
      "Model: \"sequential_234\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_702 (Dense)            (None, 1008, 87)          174       \n",
      "_________________________________________________________________\n",
      "dense_703 (Dense)            (None, 1008, 16)          1408      \n",
      "_________________________________________________________________\n",
      "dropout_234 (Dropout)        (None, 1008, 16)          0         \n",
      "_________________________________________________________________\n",
      "dense_704 (Dense)            (None, 1008, 1)           17        \n",
      "=================================================================\n",
      "Total params: 1,599\n",
      "Trainable params: 1,599\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/80\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "87/87 [==============================] - 3s 37ms/step - loss: 0.1041 - val_loss: 0.1309\n",
      "Epoch 2/80\n",
      "87/87 [==============================] - 3s 35ms/step - loss: 0.1035 - val_loss: 0.1303\n",
      "Epoch 3/80\n",
      "87/87 [==============================] - 3s 35ms/step - loss: 0.1028 - val_loss: 0.1296\n",
      "Epoch 4/80\n",
      "87/87 [==============================] - 3s 35ms/step - loss: 0.1021 - val_loss: 0.1288\n",
      "Epoch 5/80\n",
      "87/87 [==============================] - 3s 37ms/step - loss: 0.1013 - val_loss: 0.1280\n",
      "Epoch 6/80\n",
      "87/87 [==============================] - 3s 36ms/step - loss: 0.1006 - val_loss: 0.1272\n",
      "Epoch 7/80\n",
      "87/87 [==============================] - 3s 35ms/step - loss: 0.0997 - val_loss: 0.1263\n",
      "Epoch 8/80\n",
      "87/87 [==============================] - 3s 36ms/step - loss: 0.0989 - val_loss: 0.1254\n",
      "Epoch 9/80\n",
      "87/87 [==============================] - 3s 35ms/step - loss: 0.0980 - val_loss: 0.1245\n",
      "Epoch 10/80\n",
      "87/87 [==============================] - 3s 37ms/step - loss: 0.0971 - val_loss: 0.1235\n",
      "Epoch 11/80\n",
      "87/87 [==============================] - 3s 35ms/step - loss: 0.0962 - val_loss: 0.1226\n",
      "Epoch 12/80\n",
      "87/87 [==============================] - 3s 35ms/step - loss: 0.0953 - val_loss: 0.1216\n",
      "Epoch 13/80\n",
      "87/87 [==============================] - 3s 35ms/step - loss: 0.0944 - val_loss: 0.1206\n",
      "Epoch 14/80\n",
      "87/87 [==============================] - 3s 35ms/step - loss: 0.0935 - val_loss: 0.1197\n",
      "Epoch 15/80\n",
      "87/87 [==============================] - 3s 36ms/step - loss: 0.0926 - val_loss: 0.1188\n",
      "Epoch 16/80\n",
      "87/87 [==============================] - 3s 36ms/step - loss: 0.0917 - val_loss: 0.1178\n",
      "Epoch 17/80\n",
      "87/87 [==============================] - 3s 35ms/step - loss: 0.0908 - val_loss: 0.1169\n",
      "Epoch 18/80\n",
      "87/87 [==============================] - 3s 35ms/step - loss: 0.0899 - val_loss: 0.1159\n",
      "Epoch 19/80\n",
      "87/87 [==============================] - 3s 35ms/step - loss: 0.0890 - val_loss: 0.1149\n",
      "Epoch 20/80\n",
      "87/87 [==============================] - 3s 36ms/step - loss: 0.0881 - val_loss: 0.1139\n",
      "Epoch 21/80\n",
      "87/87 [==============================] - 3s 36ms/step - loss: 0.0872 - val_loss: 0.1128\n",
      "Epoch 22/80\n",
      "87/87 [==============================] - 3s 35ms/step - loss: 0.0862 - val_loss: 0.1117\n",
      "Epoch 23/80\n",
      "87/87 [==============================] - 3s 35ms/step - loss: 0.0851 - val_loss: 0.1104\n",
      "Epoch 24/80\n",
      "87/87 [==============================] - 3s 35ms/step - loss: 0.0838 - val_loss: 0.1089\n",
      "Epoch 25/80\n",
      "87/87 [==============================] - 3s 35ms/step - loss: 0.0826 - val_loss: 0.1075\n",
      "Epoch 26/80\n",
      "87/87 [==============================] - 3s 36ms/step - loss: 0.0813 - val_loss: 0.1061\n",
      "Epoch 27/80\n",
      "87/87 [==============================] - 3s 35ms/step - loss: 0.0800 - val_loss: 0.1046\n",
      "Epoch 28/80\n",
      "87/87 [==============================] - 3s 35ms/step - loss: 0.0788 - val_loss: 0.1034\n",
      "Epoch 29/80\n",
      "87/87 [==============================] - 3s 35ms/step - loss: 0.0777 - val_loss: 0.1022\n",
      "Epoch 30/80\n",
      "87/87 [==============================] - 3s 35ms/step - loss: 0.0766 - val_loss: 0.1010\n",
      "Epoch 31/80\n",
      "87/87 [==============================] - 3s 37ms/step - loss: 0.0756 - val_loss: 0.0998\n",
      "Epoch 32/80\n",
      "87/87 [==============================] - 3s 35ms/step - loss: 0.0745 - val_loss: 0.0986\n",
      "Epoch 33/80\n",
      "87/87 [==============================] - 3s 35ms/step - loss: 0.0735 - val_loss: 0.0974\n",
      "Epoch 34/80\n",
      "87/87 [==============================] - 3s 36ms/step - loss: 0.0725 - val_loss: 0.0962\n",
      "Epoch 35/80\n",
      "87/87 [==============================] - 3s 35ms/step - loss: 0.0715 - val_loss: 0.0950\n",
      "Epoch 36/80\n",
      "87/87 [==============================] - 3s 37ms/step - loss: 0.0704 - val_loss: 0.0938\n",
      "Epoch 37/80\n",
      "87/87 [==============================] - 3s 35ms/step - loss: 0.0694 - val_loss: 0.0926\n",
      "Epoch 38/80\n",
      "87/87 [==============================] - 3s 35ms/step - loss: 0.0684 - val_loss: 0.0914\n",
      "Epoch 39/80\n",
      "87/87 [==============================] - 3s 35ms/step - loss: 0.0675 - val_loss: 0.0902\n",
      "Epoch 40/80\n",
      "87/87 [==============================] - 3s 35ms/step - loss: 0.0665 - val_loss: 0.0890\n",
      "Epoch 41/80\n",
      "87/87 [==============================] - 3s 37ms/step - loss: 0.0656 - val_loss: 0.0878\n",
      "Epoch 42/80\n",
      "87/87 [==============================] - 3s 35ms/step - loss: 0.0646 - val_loss: 0.0867\n",
      "Epoch 43/80\n",
      "87/87 [==============================] - 3s 35ms/step - loss: 0.0637 - val_loss: 0.0855\n",
      "Epoch 44/80\n",
      "87/87 [==============================] - 3s 35ms/step - loss: 0.0628 - val_loss: 0.0844\n",
      "Epoch 45/80\n",
      "87/87 [==============================] - 3s 35ms/step - loss: 0.0619 - val_loss: 0.0832\n",
      "Epoch 46/80\n",
      "87/87 [==============================] - 3s 37ms/step - loss: 0.0610 - val_loss: 0.0821\n",
      "Epoch 47/80\n",
      "87/87 [==============================] - 3s 36ms/step - loss: 0.0601 - val_loss: 0.0809\n",
      "Epoch 48/80\n",
      "87/87 [==============================] - 3s 35ms/step - loss: 0.0592 - val_loss: 0.0798\n",
      "Epoch 49/80\n",
      "87/87 [==============================] - 3s 35ms/step - loss: 0.0584 - val_loss: 0.0787\n",
      "Epoch 50/80\n",
      "87/87 [==============================] - 3s 35ms/step - loss: 0.0575 - val_loss: 0.0776\n",
      "Epoch 51/80\n",
      "87/87 [==============================] - 3s 37ms/step - loss: 0.0567 - val_loss: 0.0765\n",
      "Epoch 52/80\n",
      "87/87 [==============================] - 3s 35ms/step - loss: 0.0559 - val_loss: 0.0754\n",
      "Epoch 53/80\n",
      "87/87 [==============================] - 3s 35ms/step - loss: 0.0551 - val_loss: 0.0743\n",
      "Epoch 54/80\n",
      "87/87 [==============================] - 3s 35ms/step - loss: 0.0543 - val_loss: 0.0732\n",
      "Epoch 55/80\n",
      "87/87 [==============================] - 3s 35ms/step - loss: 0.0536 - val_loss: 0.0722\n",
      "Epoch 56/80\n",
      "87/87 [==============================] - 3s 37ms/step - loss: 0.0528 - val_loss: 0.0712\n",
      "Epoch 57/80\n",
      "87/87 [==============================] - 3s 35ms/step - loss: 0.0521 - val_loss: 0.0700\n",
      "Epoch 58/80\n",
      "87/87 [==============================] - 3s 35ms/step - loss: 0.0513 - val_loss: 0.0687\n",
      "Epoch 59/80\n",
      "87/87 [==============================] - 3s 35ms/step - loss: 0.0504 - val_loss: 0.0673\n",
      "Epoch 60/80\n",
      "87/87 [==============================] - 3s 35ms/step - loss: 0.0495 - val_loss: 0.0660\n",
      "Epoch 61/80\n",
      "87/87 [==============================] - 3s 36ms/step - loss: 0.0486 - val_loss: 0.0646\n",
      "Epoch 62/80\n",
      "87/87 [==============================] - 3s 36ms/step - loss: 0.0478 - val_loss: 0.0634\n",
      "Epoch 63/80\n",
      "87/87 [==============================] - 3s 35ms/step - loss: 0.0470 - val_loss: 0.0622\n",
      "Epoch 64/80\n",
      "87/87 [==============================] - 3s 35ms/step - loss: 0.0463 - val_loss: 0.0611\n",
      "Epoch 65/80\n",
      "87/87 [==============================] - 3s 35ms/step - loss: 0.0457 - val_loss: 0.0600\n",
      "Epoch 66/80\n",
      "87/87 [==============================] - 3s 36ms/step - loss: 0.0451 - val_loss: 0.0589\n",
      "Epoch 67/80\n",
      "87/87 [==============================] - 3s 36ms/step - loss: 0.0446 - val_loss: 0.0579\n",
      "Epoch 68/80\n",
      "87/87 [==============================] - 3s 35ms/step - loss: 0.0440 - val_loss: 0.0570\n",
      "Epoch 69/80\n",
      "87/87 [==============================] - 3s 35ms/step - loss: 0.0436 - val_loss: 0.0562\n",
      "Epoch 70/80\n",
      "87/87 [==============================] - 3s 35ms/step - loss: 0.0432 - val_loss: 0.0553\n",
      "Epoch 71/80\n",
      "87/87 [==============================] - 3s 36ms/step - loss: 0.0429 - val_loss: 0.0545\n",
      "Epoch 72/80\n",
      "87/87 [==============================] - 3s 36ms/step - loss: 0.0425 - val_loss: 0.0538\n",
      "Epoch 73/80\n",
      "87/87 [==============================] - 3s 35ms/step - loss: 0.0422 - val_loss: 0.0531\n",
      "Epoch 74/80\n",
      "87/87 [==============================] - 3s 35ms/step - loss: 0.0419 - val_loss: 0.0524\n",
      "Epoch 75/80\n",
      "87/87 [==============================] - 3s 35ms/step - loss: 0.0416 - val_loss: 0.0517\n",
      "Epoch 76/80\n",
      "87/87 [==============================] - 3s 36ms/step - loss: 0.0414 - val_loss: 0.0510\n",
      "Epoch 77/80\n",
      "87/87 [==============================] - 3s 37ms/step - loss: 0.0411 - val_loss: 0.0503\n",
      "Epoch 78/80\n",
      "87/87 [==============================] - 3s 35ms/step - loss: 0.0409 - val_loss: 0.0495\n",
      "Epoch 79/80\n",
      "87/87 [==============================] - 3s 35ms/step - loss: 0.0406 - val_loss: 0.0488\n",
      "Epoch 80/80\n",
      "87/87 [==============================] - 3s 35ms/step - loss: 0.0404 - val_loss: 0.0481\n",
      "Execution time:  251.3837537765503\n",
      "DNN:\n",
      "Mean Absolute Error: 0.0362\n",
      "Root Mean Square Error: 0.0476\n",
      "Mean Square Error: 0.0023\n",
      "\n",
      "Train RMSE: 0.048\n",
      "Train MSE: 0.002\n",
      "Train MAE: 0.036\n",
      "###########################\n",
      "\n",
      "MODEL:  DNN\n",
      "sequence:  7d\n",
      "units:  80\n",
      "dropout1:  0.11814836227952394\n",
      "optimizer: adadelta\n",
      "activationDense: sigmoid\n",
      "epochs: 90\n",
      "batchsize: 25\n",
      "validation_split: 0.1\n",
      "Model: \"sequential_235\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_705 (Dense)            (None, 1008, 80)          160       \n",
      "_________________________________________________________________\n",
      "dense_706 (Dense)            (None, 1008, 16)          1296      \n",
      "_________________________________________________________________\n",
      "dropout_235 (Dropout)        (None, 1008, 16)          0         \n",
      "_________________________________________________________________\n",
      "dense_707 (Dense)            (None, 1008, 1)           17        \n",
      "=================================================================\n",
      "Total params: 1,473\n",
      "Trainable params: 1,473\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/90\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "108/108 [==============================] - 3s 32ms/step - loss: 0.1139 - val_loss: 0.1409\n",
      "Epoch 2/90\n",
      "108/108 [==============================] - 3s 27ms/step - loss: 0.1135 - val_loss: 0.1405\n",
      "Epoch 3/90\n",
      "108/108 [==============================] - 3s 27ms/step - loss: 0.1131 - val_loss: 0.1401\n",
      "Epoch 4/90\n",
      "108/108 [==============================] - 3s 27ms/step - loss: 0.1127 - val_loss: 0.1397\n",
      "Epoch 5/90\n",
      "108/108 [==============================] - 3s 27ms/step - loss: 0.1122 - val_loss: 0.1392\n",
      "Epoch 6/90\n",
      "108/108 [==============================] - 3s 28ms/step - loss: 0.1117 - val_loss: 0.1387\n",
      "Epoch 7/90\n",
      "108/108 [==============================] - 3s 28ms/step - loss: 0.1112 - val_loss: 0.1382\n",
      "Epoch 8/90\n",
      "108/108 [==============================] - 3s 27ms/step - loss: 0.1107 - val_loss: 0.1376\n",
      "Epoch 9/90\n",
      "108/108 [==============================] - 3s 27ms/step - loss: 0.1102 - val_loss: 0.1371\n",
      "Epoch 10/90\n",
      "108/108 [==============================] - 3s 27ms/step - loss: 0.1096 - val_loss: 0.1365\n",
      "Epoch 11/90\n",
      "108/108 [==============================] - 3s 27ms/step - loss: 0.1091 - val_loss: 0.1359\n",
      "Epoch 12/90\n",
      "108/108 [==============================] - 3s 29ms/step - loss: 0.1085 - val_loss: 0.1353\n",
      "Epoch 13/90\n",
      "108/108 [==============================] - 3s 27ms/step - loss: 0.1079 - val_loss: 0.1347\n",
      "Epoch 14/90\n",
      "108/108 [==============================] - 3s 27ms/step - loss: 0.1074 - val_loss: 0.1342\n",
      "Epoch 15/90\n",
      "108/108 [==============================] - 3s 29ms/step - loss: 0.1068 - val_loss: 0.1336\n",
      "Epoch 16/90\n",
      "108/108 [==============================] - 3s 27ms/step - loss: 0.1062 - val_loss: 0.1329\n",
      "Epoch 17/90\n",
      "108/108 [==============================] - 3s 29ms/step - loss: 0.1056 - val_loss: 0.1324\n",
      "Epoch 18/90\n",
      "108/108 [==============================] - 3s 28ms/step - loss: 0.1051 - val_loss: 0.1318\n",
      "Epoch 19/90\n",
      "108/108 [==============================] - 3s 27ms/step - loss: 0.1045 - val_loss: 0.1312\n",
      "Epoch 20/90\n",
      "108/108 [==============================] - 3s 27ms/step - loss: 0.1039 - val_loss: 0.1306\n",
      "Epoch 21/90\n",
      "108/108 [==============================] - 3s 27ms/step - loss: 0.1033 - val_loss: 0.1300\n",
      "Epoch 22/90\n",
      "108/108 [==============================] - 3s 29ms/step - loss: 0.1028 - val_loss: 0.1294\n",
      "Epoch 23/90\n",
      "108/108 [==============================] - 3s 28ms/step - loss: 0.1022 - val_loss: 0.1288\n",
      "Epoch 24/90\n",
      "108/108 [==============================] - 3s 27ms/step - loss: 0.1016 - val_loss: 0.1282\n",
      "Epoch 25/90\n",
      "108/108 [==============================] - 3s 27ms/step - loss: 0.1010 - val_loss: 0.1275\n",
      "Epoch 26/90\n",
      "108/108 [==============================] - 3s 27ms/step - loss: 0.1003 - val_loss: 0.1269\n",
      "Epoch 27/90\n",
      "108/108 [==============================] - 3s 28ms/step - loss: 0.0997 - val_loss: 0.1263\n",
      "Epoch 28/90\n",
      "108/108 [==============================] - 3s 29ms/step - loss: 0.0991 - val_loss: 0.1256\n",
      "Epoch 29/90\n",
      "108/108 [==============================] - 3s 27ms/step - loss: 0.0985 - val_loss: 0.1249\n",
      "Epoch 30/90\n",
      "108/108 [==============================] - 3s 27ms/step - loss: 0.0978 - val_loss: 0.1242\n",
      "Epoch 31/90\n",
      "108/108 [==============================] - 3s 27ms/step - loss: 0.0972 - val_loss: 0.1236\n",
      "Epoch 32/90\n",
      "108/108 [==============================] - 3s 28ms/step - loss: 0.0965 - val_loss: 0.1229\n",
      "Epoch 33/90\n",
      "108/108 [==============================] - 3s 29ms/step - loss: 0.0959 - val_loss: 0.1222\n",
      "Epoch 34/90\n",
      "108/108 [==============================] - 3s 27ms/step - loss: 0.0952 - val_loss: 0.1215\n",
      "Epoch 35/90\n",
      "108/108 [==============================] - 3s 27ms/step - loss: 0.0946 - val_loss: 0.1208\n",
      "Epoch 36/90\n",
      "108/108 [==============================] - 3s 27ms/step - loss: 0.0939 - val_loss: 0.1201\n",
      "Epoch 37/90\n",
      "108/108 [==============================] - 3s 27ms/step - loss: 0.0932 - val_loss: 0.1194\n",
      "Epoch 38/90\n",
      "108/108 [==============================] - 3s 29ms/step - loss: 0.0926 - val_loss: 0.1187\n",
      "Epoch 39/90\n",
      "108/108 [==============================] - 3s 28ms/step - loss: 0.0919 - val_loss: 0.1180\n",
      "Epoch 40/90\n",
      "108/108 [==============================] - 3s 27ms/step - loss: 0.0913 - val_loss: 0.1173\n",
      "Epoch 41/90\n",
      "108/108 [==============================] - 3s 27ms/step - loss: 0.0906 - val_loss: 0.1166\n",
      "Epoch 42/90\n",
      "108/108 [==============================] - 3s 27ms/step - loss: 0.0900 - val_loss: 0.1159\n",
      "Epoch 43/90\n",
      "108/108 [==============================] - 3s 28ms/step - loss: 0.0893 - val_loss: 0.1152\n",
      "Epoch 44/90\n",
      "108/108 [==============================] - 3s 28ms/step - loss: 0.0887 - val_loss: 0.1145\n",
      "Epoch 45/90\n",
      "108/108 [==============================] - 3s 27ms/step - loss: 0.0880 - val_loss: 0.1137\n",
      "Epoch 46/90\n",
      "108/108 [==============================] - 3s 27ms/step - loss: 0.0873 - val_loss: 0.1130\n",
      "Epoch 47/90\n",
      "108/108 [==============================] - 3s 27ms/step - loss: 0.0867 - val_loss: 0.1123\n",
      "Epoch 48/90\n",
      "108/108 [==============================] - 3s 27ms/step - loss: 0.0860 - val_loss: 0.1116\n",
      "Epoch 49/90\n",
      "108/108 [==============================] - 3s 29ms/step - loss: 0.0854 - val_loss: 0.1109\n",
      "Epoch 50/90\n",
      "108/108 [==============================] - 3s 27ms/step - loss: 0.0847 - val_loss: 0.1102\n",
      "Epoch 51/90\n",
      "108/108 [==============================] - 3s 27ms/step - loss: 0.0841 - val_loss: 0.1095\n",
      "Epoch 52/90\n",
      "108/108 [==============================] - 3s 27ms/step - loss: 0.0835 - val_loss: 0.1088\n",
      "Epoch 53/90\n",
      "108/108 [==============================] - 3s 27ms/step - loss: 0.0828 - val_loss: 0.1081\n",
      "Epoch 54/90\n",
      "108/108 [==============================] - 3s 29ms/step - loss: 0.0822 - val_loss: 0.1074\n",
      "Epoch 55/90\n",
      "108/108 [==============================] - 3s 28ms/step - loss: 0.0816 - val_loss: 0.1067\n",
      "Epoch 56/90\n",
      "108/108 [==============================] - 3s 27ms/step - loss: 0.0809 - val_loss: 0.1060\n",
      "Epoch 57/90\n",
      "108/108 [==============================] - 3s 27ms/step - loss: 0.0803 - val_loss: 0.1052\n",
      "Epoch 58/90\n",
      "108/108 [==============================] - 3s 27ms/step - loss: 0.0796 - val_loss: 0.1045\n",
      "Epoch 59/90\n",
      "108/108 [==============================] - 3s 28ms/step - loss: 0.0790 - val_loss: 0.1038\n",
      "Epoch 60/90\n",
      "108/108 [==============================] - 3s 28ms/step - loss: 0.0783 - val_loss: 0.1030\n",
      "Epoch 61/90\n",
      "108/108 [==============================] - 3s 27ms/step - loss: 0.0777 - val_loss: 0.1023\n",
      "Epoch 62/90\n",
      "108/108 [==============================] - 3s 27ms/step - loss: 0.0770 - val_loss: 0.1016\n",
      "Epoch 63/90\n",
      "108/108 [==============================] - 3s 27ms/step - loss: 0.0764 - val_loss: 0.1008\n",
      "Epoch 64/90\n",
      "108/108 [==============================] - 3s 27ms/step - loss: 0.0758 - val_loss: 0.1001\n",
      "Epoch 65/90\n",
      "108/108 [==============================] - 3s 29ms/step - loss: 0.0751 - val_loss: 0.0993\n",
      "Epoch 66/90\n",
      "108/108 [==============================] - 3s 27ms/step - loss: 0.0744 - val_loss: 0.0985\n",
      "Epoch 67/90\n",
      "108/108 [==============================] - 3s 27ms/step - loss: 0.0737 - val_loss: 0.0977\n",
      "Epoch 68/90\n",
      "108/108 [==============================] - 3s 27ms/step - loss: 0.0730 - val_loss: 0.0968\n",
      "Epoch 69/90\n",
      "108/108 [==============================] - 3s 27ms/step - loss: 0.0723 - val_loss: 0.0960\n",
      "Epoch 70/90\n",
      "108/108 [==============================] - 3s 29ms/step - loss: 0.0716 - val_loss: 0.0952\n",
      "Epoch 71/90\n",
      "108/108 [==============================] - 3s 28ms/step - loss: 0.0709 - val_loss: 0.0944\n",
      "Epoch 72/90\n",
      "108/108 [==============================] - 3s 27ms/step - loss: 0.0701 - val_loss: 0.0935\n",
      "Epoch 73/90\n",
      "108/108 [==============================] - 3s 27ms/step - loss: 0.0694 - val_loss: 0.0927\n",
      "Epoch 74/90\n",
      "108/108 [==============================] - 3s 27ms/step - loss: 0.0687 - val_loss: 0.0918\n",
      "Epoch 75/90\n",
      "108/108 [==============================] - 3s 28ms/step - loss: 0.0680 - val_loss: 0.0910\n",
      "Epoch 76/90\n",
      "108/108 [==============================] - 3s 28ms/step - loss: 0.0673 - val_loss: 0.0901\n",
      "Epoch 77/90\n",
      "108/108 [==============================] - 3s 27ms/step - loss: 0.0666 - val_loss: 0.0893\n",
      "Epoch 78/90\n",
      "108/108 [==============================] - 3s 27ms/step - loss: 0.0659 - val_loss: 0.0884\n",
      "Epoch 79/90\n",
      "108/108 [==============================] - 3s 27ms/step - loss: 0.0651 - val_loss: 0.0876\n",
      "Epoch 80/90\n",
      "108/108 [==============================] - 3s 28ms/step - loss: 0.0644 - val_loss: 0.0867\n",
      "Epoch 81/90\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "108/108 [==============================] - 3s 28ms/step - loss: 0.0637 - val_loss: 0.0858\n",
      "Epoch 82/90\n",
      "108/108 [==============================] - 3s 27ms/step - loss: 0.0629 - val_loss: 0.0849\n",
      "Epoch 83/90\n",
      "108/108 [==============================] - 3s 28ms/step - loss: 0.0622 - val_loss: 0.0840\n",
      "Epoch 84/90\n",
      "108/108 [==============================] - 3s 27ms/step - loss: 0.0615 - val_loss: 0.0832\n",
      "Epoch 85/90\n",
      "108/108 [==============================] - 3s 27ms/step - loss: 0.0608 - val_loss: 0.0823\n",
      "Epoch 86/90\n",
      "108/108 [==============================] - 3s 29ms/step - loss: 0.0601 - val_loss: 0.0814\n",
      "Epoch 87/90\n",
      "108/108 [==============================] - 3s 27ms/step - loss: 0.0593 - val_loss: 0.0805\n",
      "Epoch 88/90\n",
      "108/108 [==============================] - 3s 28ms/step - loss: 0.0587 - val_loss: 0.0796\n",
      "Epoch 89/90\n",
      "108/108 [==============================] - 3s 27ms/step - loss: 0.0579 - val_loss: 0.0788\n",
      "Epoch 90/90\n",
      "108/108 [==============================] - 3s 27ms/step - loss: 0.0573 - val_loss: 0.0779\n",
      "Execution time:  272.5813035964966\n",
      "DNN:\n",
      "Mean Absolute Error: 0.0531\n",
      "Root Mean Square Error: 0.0614\n",
      "Mean Square Error: 0.0038\n",
      "\n",
      "Train RMSE: 0.061\n",
      "Train MSE: 0.004\n",
      "Train MAE: 0.053\n",
      "###########################\n",
      "\n",
      "MODEL:  DNN\n",
      "sequence:  7d\n",
      "units:  12\n",
      "dropout1:  0.48476373451509647\n",
      "optimizer: adadelta\n",
      "activationDense: sigmoid\n",
      "epochs: 52\n",
      "batchsize: 57\n",
      "validation_split: 0.1\n",
      "Model: \"sequential_236\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_708 (Dense)            (None, 1008, 12)          24        \n",
      "_________________________________________________________________\n",
      "dense_709 (Dense)            (None, 1008, 16)          208       \n",
      "_________________________________________________________________\n",
      "dropout_236 (Dropout)        (None, 1008, 16)          0         \n",
      "_________________________________________________________________\n",
      "dense_710 (Dense)            (None, 1008, 1)           17        \n",
      "=================================================================\n",
      "Total params: 249\n",
      "Trainable params: 249\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/52\n",
      "48/48 [==============================] - 2s 33ms/step - loss: 0.1197 - val_loss: 0.1461\n",
      "Epoch 2/52\n",
      "48/48 [==============================] - 1s 30ms/step - loss: 0.1195 - val_loss: 0.1458\n",
      "Epoch 3/52\n",
      "48/48 [==============================] - 1s 30ms/step - loss: 0.1192 - val_loss: 0.1456\n",
      "Epoch 4/52\n",
      "48/48 [==============================] - 1s 30ms/step - loss: 0.1190 - val_loss: 0.1453\n",
      "Epoch 5/52\n",
      "48/48 [==============================] - 1s 30ms/step - loss: 0.1188 - val_loss: 0.1450\n",
      "Epoch 6/52\n",
      "48/48 [==============================] - 1s 31ms/step - loss: 0.1185 - val_loss: 0.1448\n",
      "Epoch 7/52\n",
      "48/48 [==============================] - 1s 30ms/step - loss: 0.1182 - val_loss: 0.1445\n",
      "Epoch 8/52\n",
      "48/48 [==============================] - 1s 30ms/step - loss: 0.1179 - val_loss: 0.1442\n",
      "Epoch 9/52\n",
      "48/48 [==============================] - 1s 30ms/step - loss: 0.1176 - val_loss: 0.1439\n",
      "Epoch 10/52\n",
      "48/48 [==============================] - 1s 30ms/step - loss: 0.1173 - val_loss: 0.1436\n",
      "Epoch 11/52\n",
      "48/48 [==============================] - 2s 32ms/step - loss: 0.1170 - val_loss: 0.1432\n",
      "Epoch 12/52\n",
      "48/48 [==============================] - 1s 31ms/step - loss: 0.1167 - val_loss: 0.1429\n",
      "Epoch 13/52\n",
      "48/48 [==============================] - 1s 31ms/step - loss: 0.1164 - val_loss: 0.1426\n",
      "Epoch 14/52\n",
      "48/48 [==============================] - 1s 31ms/step - loss: 0.1161 - val_loss: 0.1422\n",
      "Epoch 15/52\n",
      "48/48 [==============================] - 1s 30ms/step - loss: 0.1157 - val_loss: 0.1419\n",
      "Epoch 16/52\n",
      "48/48 [==============================] - ETA: 0s - loss: 0.115 - 1s 30ms/step - loss: 0.1154 - val_loss: 0.1415\n",
      "Epoch 17/52\n",
      "48/48 [==============================] - 1s 31ms/step - loss: 0.1150 - val_loss: 0.1412\n",
      "Epoch 18/52\n",
      "48/48 [==============================] - 1s 30ms/step - loss: 0.1147 - val_loss: 0.1408\n",
      "Epoch 19/52\n",
      "48/48 [==============================] - 1s 30ms/step - loss: 0.1143 - val_loss: 0.1404\n",
      "Epoch 20/52\n",
      "48/48 [==============================] - 1s 30ms/step - loss: 0.1140 - val_loss: 0.1401\n",
      "Epoch 21/52\n",
      "48/48 [==============================] - 2s 31ms/step - loss: 0.1136 - val_loss: 0.1397\n",
      "Epoch 22/52\n",
      "48/48 [==============================] - 2s 32ms/step - loss: 0.1133 - val_loss: 0.1393\n",
      "Epoch 23/52\n",
      "48/48 [==============================] - 1s 31ms/step - loss: 0.1129 - val_loss: 0.1389\n",
      "Epoch 24/52\n",
      "48/48 [==============================] - 1s 31ms/step - loss: 0.1125 - val_loss: 0.1385\n",
      "Epoch 25/52\n",
      "48/48 [==============================] - 1s 30ms/step - loss: 0.1122 - val_loss: 0.1381\n",
      "Epoch 26/52\n",
      "48/48 [==============================] - 1s 31ms/step - loss: 0.1118 - val_loss: 0.1377\n",
      "Epoch 27/52\n",
      "48/48 [==============================] - 1s 30ms/step - loss: 0.1114 - val_loss: 0.1373\n",
      "Epoch 28/52\n",
      "48/48 [==============================] - 1s 30ms/step - loss: 0.1110 - val_loss: 0.1369\n",
      "Epoch 29/52\n",
      "48/48 [==============================] - 1s 30ms/step - loss: 0.1107 - val_loss: 0.1365\n",
      "Epoch 30/52\n",
      "48/48 [==============================] - 1s 30ms/step - loss: 0.1102 - val_loss: 0.1361\n",
      "Epoch 31/52\n",
      "48/48 [==============================] - 1s 30ms/step - loss: 0.1099 - val_loss: 0.1357\n",
      "Epoch 32/52\n",
      "48/48 [==============================] - 2s 32ms/step - loss: 0.1094 - val_loss: 0.1353\n",
      "Epoch 33/52\n",
      "48/48 [==============================] - 2s 32ms/step - loss: 0.1091 - val_loss: 0.1349\n",
      "Epoch 34/52\n",
      "48/48 [==============================] - 1s 31ms/step - loss: 0.1086 - val_loss: 0.1344\n",
      "Epoch 35/52\n",
      "48/48 [==============================] - 1s 30ms/step - loss: 0.1082 - val_loss: 0.1340\n",
      "Epoch 36/52\n",
      "48/48 [==============================] - 1s 30ms/step - loss: 0.1078 - val_loss: 0.1336\n",
      "Epoch 37/52\n",
      "48/48 [==============================] - 1s 30ms/step - loss: 0.1074 - val_loss: 0.1331\n",
      "Epoch 38/52\n",
      "48/48 [==============================] - 1s 30ms/step - loss: 0.1070 - val_loss: 0.1327\n",
      "Epoch 39/52\n",
      "48/48 [==============================] - 1s 30ms/step - loss: 0.1066 - val_loss: 0.1322\n",
      "Epoch 40/52\n",
      "48/48 [==============================] - 1s 30ms/step - loss: 0.1062 - val_loss: 0.1318\n",
      "Epoch 41/52\n",
      "48/48 [==============================] - 1s 30ms/step - loss: 0.1057 - val_loss: 0.1313\n",
      "Epoch 42/52\n",
      "48/48 [==============================] - 1s 31ms/step - loss: 0.1053 - val_loss: 0.1309\n",
      "Epoch 43/52\n",
      "48/48 [==============================] - 2s 32ms/step - loss: 0.1049 - val_loss: 0.1304\n",
      "Epoch 44/52\n",
      "48/48 [==============================] - 2s 32ms/step - loss: 0.1044 - val_loss: 0.1300\n",
      "Epoch 45/52\n",
      "48/48 [==============================] - 1s 31ms/step - loss: 0.1040 - val_loss: 0.1295\n",
      "Epoch 46/52\n",
      "48/48 [==============================] - 1s 31ms/step - loss: 0.1036 - val_loss: 0.1290\n",
      "Epoch 47/52\n",
      "48/48 [==============================] - 1s 30ms/step - loss: 0.1031 - val_loss: 0.1286\n",
      "Epoch 48/52\n",
      "48/48 [==============================] - 1s 30ms/step - loss: 0.1027 - val_loss: 0.1281\n",
      "Epoch 49/52\n",
      "48/48 [==============================] - 1s 30ms/step - loss: 0.1022 - val_loss: 0.1276\n",
      "Epoch 50/52\n",
      "48/48 [==============================] - 1s 30ms/step - loss: 0.1018 - val_loss: 0.1272\n",
      "Epoch 51/52\n",
      "48/48 [==============================] - 1s 30ms/step - loss: 0.1013 - val_loss: 0.1267\n",
      "Epoch 52/52\n",
      "48/48 [==============================] - 1s 31ms/step - loss: 0.1009 - val_loss: 0.1262\n",
      "Execution time:  78.73348450660706\n",
      "DNN:\n",
      "Mean Absolute Error: 0.0949\n",
      "Root Mean Square Error: 0.1012\n",
      "Mean Square Error: 0.0103\n",
      "\n",
      "Train RMSE: 0.101\n",
      "Train MSE: 0.010\n",
      "Train MAE: 0.095\n",
      "###########################\n",
      "\n",
      "MODEL:  DNN\n",
      "sequence:  7d\n",
      "units:  87\n",
      "dropout1:  0.40519643149940265\n",
      "optimizer: adadelta\n",
      "activationDense: sigmoid\n",
      "epochs: 80\n",
      "batchsize: 31\n",
      "validation_split: 0.2\n",
      "Model: \"sequential_237\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_711 (Dense)            (None, 1008, 87)          174       \n",
      "_________________________________________________________________\n",
      "dense_712 (Dense)            (None, 1008, 16)          1408      \n",
      "_________________________________________________________________\n",
      "dropout_237 (Dropout)        (None, 1008, 16)          0         \n",
      "_________________________________________________________________\n",
      "dense_713 (Dense)            (None, 1008, 1)           17        \n",
      "=================================================================\n",
      "Total params: 1,599\n",
      "Trainable params: 1,599\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/80\n",
      "77/77 [==============================] - 3s 39ms/step - loss: 0.1023 - val_loss: 0.1238\n",
      "Epoch 2/80\n",
      "77/77 [==============================] - 3s 37ms/step - loss: 0.1020 - val_loss: 0.1236\n",
      "Epoch 3/80\n",
      "77/77 [==============================] - 3s 36ms/step - loss: 0.1018 - val_loss: 0.1233\n",
      "Epoch 4/80\n",
      "77/77 [==============================] - 3s 37ms/step - loss: 0.1015 - val_loss: 0.1230\n",
      "Epoch 5/80\n",
      "77/77 [==============================] - 3s 37ms/step - loss: 0.1013 - val_loss: 0.1228\n",
      "Epoch 6/80\n",
      "77/77 [==============================] - 3s 39ms/step - loss: 0.1010 - val_loss: 0.1225\n",
      "Epoch 7/80\n",
      "77/77 [==============================] - 3s 38ms/step - loss: 0.1007 - val_loss: 0.1221\n",
      "Epoch 8/80\n",
      "77/77 [==============================] - 3s 37ms/step - loss: 0.1004 - val_loss: 0.1218\n",
      "Epoch 9/80\n",
      "77/77 [==============================] - 3s 37ms/step - loss: 0.1001 - val_loss: 0.1215\n",
      "Epoch 10/80\n",
      "77/77 [==============================] - 3s 37ms/step - loss: 0.0998 - val_loss: 0.1211\n",
      "Epoch 11/80\n",
      "77/77 [==============================] - 3s 38ms/step - loss: 0.0994 - val_loss: 0.1208\n",
      "Epoch 12/80\n",
      "77/77 [==============================] - 3s 38ms/step - loss: 0.0991 - val_loss: 0.1204\n",
      "Epoch 13/80\n",
      "77/77 [==============================] - 3s 37ms/step - loss: 0.0987 - val_loss: 0.1200\n",
      "Epoch 14/80\n",
      "77/77 [==============================] - 3s 37ms/step - loss: 0.0984 - val_loss: 0.1197\n",
      "Epoch 15/80\n",
      "77/77 [==============================] - 3s 37ms/step - loss: 0.0980 - val_loss: 0.1193\n",
      "Epoch 16/80\n",
      "77/77 [==============================] - 3s 36ms/step - loss: 0.0976 - val_loss: 0.1189\n",
      "Epoch 17/80\n",
      "77/77 [==============================] - 3s 39ms/step - loss: 0.0973 - val_loss: 0.1185\n",
      "Epoch 18/80\n",
      "77/77 [==============================] - 3s 37ms/step - loss: 0.0970 - val_loss: 0.1182\n",
      "Epoch 19/80\n",
      "77/77 [==============================] - 3s 36ms/step - loss: 0.0967 - val_loss: 0.1179\n",
      "Epoch 20/80\n",
      "77/77 [==============================] - 3s 37ms/step - loss: 0.0964 - val_loss: 0.1176\n",
      "Epoch 21/80\n",
      "77/77 [==============================] - 3s 37ms/step - loss: 0.0961 - val_loss: 0.1173\n",
      "Epoch 22/80\n",
      "77/77 [==============================] - 3s 37ms/step - loss: 0.0957 - val_loss: 0.1169\n",
      "Epoch 23/80\n",
      "77/77 [==============================] - 3s 38ms/step - loss: 0.0954 - val_loss: 0.1166\n",
      "Epoch 24/80\n",
      "77/77 [==============================] - 3s 37ms/step - loss: 0.0951 - val_loss: 0.1163\n",
      "Epoch 25/80\n",
      "77/77 [==============================] - 3s 37ms/step - loss: 0.0948 - val_loss: 0.1159\n",
      "Epoch 26/80\n",
      "77/77 [==============================] - 3s 37ms/step - loss: 0.0945 - val_loss: 0.1156\n",
      "Epoch 27/80\n",
      "77/77 [==============================] - 3s 37ms/step - loss: 0.0941 - val_loss: 0.1152\n",
      "Epoch 28/80\n",
      "77/77 [==============================] - 3s 38ms/step - loss: 0.0938 - val_loss: 0.1148\n",
      "Epoch 29/80\n",
      "77/77 [==============================] - 3s 37ms/step - loss: 0.0935 - val_loss: 0.1145\n",
      "Epoch 30/80\n",
      "77/77 [==============================] - 3s 37ms/step - loss: 0.0931 - val_loss: 0.1141\n",
      "Epoch 31/80\n",
      "77/77 [==============================] - 3s 37ms/step - loss: 0.0928 - val_loss: 0.1137\n",
      "Epoch 32/80\n",
      "77/77 [==============================] - 3s 37ms/step - loss: 0.0924 - val_loss: 0.1133\n",
      "Epoch 33/80\n",
      "77/77 [==============================] - 3s 37ms/step - loss: 0.0921 - val_loss: 0.1130\n",
      "Epoch 34/80\n",
      "77/77 [==============================] - 3s 38ms/step - loss: 0.0917 - val_loss: 0.1126\n",
      "Epoch 35/80\n",
      "77/77 [==============================] - 3s 37ms/step - loss: 0.0913 - val_loss: 0.1122\n",
      "Epoch 36/80\n",
      "77/77 [==============================] - 3s 37ms/step - loss: 0.0910 - val_loss: 0.1118\n",
      "Epoch 37/80\n",
      "77/77 [==============================] - 3s 37ms/step - loss: 0.0906 - val_loss: 0.1114\n",
      "Epoch 38/80\n",
      "77/77 [==============================] - 3s 37ms/step - loss: 0.0902 - val_loss: 0.1110\n",
      "Epoch 39/80\n",
      "77/77 [==============================] - 3s 39ms/step - loss: 0.0899 - val_loss: 0.1106\n",
      "Epoch 40/80\n",
      "77/77 [==============================] - 3s 37ms/step - loss: 0.0895 - val_loss: 0.1101\n",
      "Epoch 41/80\n",
      "77/77 [==============================] - 3s 37ms/step - loss: 0.0891 - val_loss: 0.1097\n",
      "Epoch 42/80\n",
      "77/77 [==============================] - 3s 37ms/step - loss: 0.0886 - val_loss: 0.1089\n",
      "Epoch 43/80\n",
      "77/77 [==============================] - 3s 37ms/step - loss: 0.0878 - val_loss: 0.1081\n",
      "Epoch 44/80\n",
      "77/77 [==============================] - 3s 38ms/step - loss: 0.0871 - val_loss: 0.1073\n",
      "Epoch 45/80\n",
      "77/77 [==============================] - 3s 38ms/step - loss: 0.0864 - val_loss: 0.1065\n",
      "Epoch 46/80\n",
      "77/77 [==============================] - 3s 37ms/step - loss: 0.0857 - val_loss: 0.1058\n",
      "Epoch 47/80\n",
      "77/77 [==============================] - 3s 37ms/step - loss: 0.0850 - val_loss: 0.1050\n",
      "Epoch 48/80\n",
      "77/77 [==============================] - 3s 37ms/step - loss: 0.0843 - val_loss: 0.1042\n",
      "Epoch 49/80\n",
      "77/77 [==============================] - 3s 37ms/step - loss: 0.0836 - val_loss: 0.1034\n",
      "Epoch 50/80\n",
      "77/77 [==============================] - 3s 39ms/step - loss: 0.0829 - val_loss: 0.1027\n",
      "Epoch 51/80\n",
      "77/77 [==============================] - 3s 37ms/step - loss: 0.0822 - val_loss: 0.1019\n",
      "Epoch 52/80\n",
      "77/77 [==============================] - 3s 37ms/step - loss: 0.0816 - val_loss: 0.1011\n",
      "Epoch 53/80\n",
      "77/77 [==============================] - 3s 37ms/step - loss: 0.0809 - val_loss: 0.1004\n",
      "Epoch 54/80\n",
      "77/77 [==============================] - 3s 37ms/step - loss: 0.0803 - val_loss: 0.0997\n",
      "Epoch 55/80\n",
      "77/77 [==============================] - 3s 38ms/step - loss: 0.0796 - val_loss: 0.0989\n",
      "Epoch 56/80\n",
      "77/77 [==============================] - 3s 38ms/step - loss: 0.0790 - val_loss: 0.0982\n",
      "Epoch 57/80\n",
      "77/77 [==============================] - 3s 37ms/step - loss: 0.0783 - val_loss: 0.0975\n",
      "Epoch 58/80\n",
      "77/77 [==============================] - 3s 37ms/step - loss: 0.0777 - val_loss: 0.0967\n",
      "Epoch 59/80\n",
      "77/77 [==============================] - 3s 37ms/step - loss: 0.0771 - val_loss: 0.0960\n",
      "Epoch 60/80\n",
      "77/77 [==============================] - 3s 37ms/step - loss: 0.0765 - val_loss: 0.0953\n",
      "Epoch 61/80\n",
      "77/77 [==============================] - 3s 39ms/step - loss: 0.0758 - val_loss: 0.0945\n",
      "Epoch 62/80\n",
      "77/77 [==============================] - 3s 37ms/step - loss: 0.0752 - val_loss: 0.0938\n",
      "Epoch 63/80\n",
      "77/77 [==============================] - 3s 37ms/step - loss: 0.0746 - val_loss: 0.0931\n",
      "Epoch 64/80\n",
      "77/77 [==============================] - 3s 37ms/step - loss: 0.0740 - val_loss: 0.0923\n",
      "Epoch 65/80\n",
      "77/77 [==============================] - 3s 37ms/step - loss: 0.0734 - val_loss: 0.0916\n",
      "Epoch 66/80\n",
      "77/77 [==============================] - 3s 38ms/step - loss: 0.0728 - val_loss: 0.0909\n",
      "Epoch 67/80\n",
      "77/77 [==============================] - 3s 38ms/step - loss: 0.0722 - val_loss: 0.0901\n",
      "Epoch 68/80\n",
      "77/77 [==============================] - 3s 37ms/step - loss: 0.0716 - val_loss: 0.0894\n",
      "Epoch 69/80\n",
      "77/77 [==============================] - 3s 37ms/step - loss: 0.0709 - val_loss: 0.0887\n",
      "Epoch 70/80\n",
      "77/77 [==============================] - 3s 37ms/step - loss: 0.0704 - val_loss: 0.0880\n",
      "Epoch 71/80\n",
      "77/77 [==============================] - 3s 37ms/step - loss: 0.0698 - val_loss: 0.0872\n",
      "Epoch 72/80\n",
      "77/77 [==============================] - 3s 39ms/step - loss: 0.0692 - val_loss: 0.0865\n",
      "Epoch 73/80\n",
      "77/77 [==============================] - 3s 37ms/step - loss: 0.0686 - val_loss: 0.0858\n",
      "Epoch 74/80\n",
      "77/77 [==============================] - 3s 37ms/step - loss: 0.0680 - val_loss: 0.0850\n",
      "Epoch 75/80\n",
      "77/77 [==============================] - 3s 37ms/step - loss: 0.0674 - val_loss: 0.0843\n",
      "Epoch 76/80\n",
      "77/77 [==============================] - 3s 37ms/step - loss: 0.0669 - val_loss: 0.0836\n",
      "Epoch 77/80\n",
      "77/77 [==============================] - 3s 38ms/step - loss: 0.0663 - val_loss: 0.0829\n",
      "Epoch 78/80\n",
      "77/77 [==============================] - 3s 38ms/step - loss: 0.0657 - val_loss: 0.0821\n",
      "Epoch 79/80\n",
      "77/77 [==============================] - 3s 37ms/step - loss: 0.0652 - val_loss: 0.0814\n",
      "Epoch 80/80\n",
      "77/77 [==============================] - 3s 37ms/step - loss: 0.0646 - val_loss: 0.0807\n",
      "Execution time:  233.5884566307068\n",
      "DNN:\n",
      "Mean Absolute Error: 0.0610\n",
      "Root Mean Square Error: 0.0690\n",
      "Mean Square Error: 0.0048\n",
      "\n",
      "Train RMSE: 0.069\n",
      "Train MSE: 0.005\n",
      "Train MAE: 0.061\n",
      "###########################\n",
      "\n",
      "MODEL:  DNN\n",
      "sequence:  7d\n",
      "units:  80\n",
      "dropout1:  0.11814836227952394\n",
      "optimizer: adadelta\n",
      "activationDense: sigmoid\n",
      "epochs: 90\n",
      "batchsize: 25\n",
      "validation_split: 0.2\n",
      "Model: \"sequential_238\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_714 (Dense)            (None, 1008, 80)          160       \n",
      "_________________________________________________________________\n",
      "dense_715 (Dense)            (None, 1008, 16)          1296      \n",
      "_________________________________________________________________\n",
      "dropout_238 (Dropout)        (None, 1008, 16)          0         \n",
      "_________________________________________________________________\n",
      "dense_716 (Dense)            (None, 1008, 1)           17        \n",
      "=================================================================\n",
      "Total params: 1,473\n",
      "Trainable params: 1,473\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/90\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "96/96 [==============================] - 3s 30ms/step - loss: 0.1214 - val_loss: 0.1425\n",
      "Epoch 2/90\n",
      "96/96 [==============================] - 3s 30ms/step - loss: 0.1206 - val_loss: 0.1417\n",
      "Epoch 3/90\n",
      "96/96 [==============================] - 3s 29ms/step - loss: 0.1197 - val_loss: 0.1408\n",
      "Epoch 4/90\n",
      "96/96 [==============================] - 3s 28ms/step - loss: 0.1188 - val_loss: 0.1399\n",
      "Epoch 5/90\n",
      "96/96 [==============================] - 3s 28ms/step - loss: 0.1179 - val_loss: 0.1389\n",
      "Epoch 6/90\n",
      "96/96 [==============================] - 3s 28ms/step - loss: 0.1168 - val_loss: 0.1378\n",
      "Epoch 7/90\n",
      "96/96 [==============================] - 3s 28ms/step - loss: 0.1158 - val_loss: 0.1367\n",
      "Epoch 8/90\n",
      "96/96 [==============================] - 3s 31ms/step - loss: 0.1147 - val_loss: 0.1356\n",
      "Epoch 9/90\n",
      "96/96 [==============================] - 3s 29ms/step - loss: 0.1135 - val_loss: 0.1344\n",
      "Epoch 10/90\n",
      "96/96 [==============================] - 3s 28ms/step - loss: 0.1123 - val_loss: 0.1332\n",
      "Epoch 11/90\n",
      "96/96 [==============================] - 3s 28ms/step - loss: 0.1111 - val_loss: 0.1319\n",
      "Epoch 12/90\n",
      "96/96 [==============================] - 3s 28ms/step - loss: 0.1099 - val_loss: 0.1307\n",
      "Epoch 13/90\n",
      "96/96 [==============================] - 3s 28ms/step - loss: 0.1086 - val_loss: 0.1294\n",
      "Epoch 14/90\n",
      "96/96 [==============================] - 3s 30ms/step - loss: 0.1074 - val_loss: 0.1280\n",
      "Epoch 15/90\n",
      "96/96 [==============================] - 3s 28ms/step - loss: 0.1060 - val_loss: 0.1267\n",
      "Epoch 16/90\n",
      "96/96 [==============================] - 3s 28ms/step - loss: 0.1047 - val_loss: 0.1253\n",
      "Epoch 17/90\n",
      "96/96 [==============================] - 3s 28ms/step - loss: 0.1034 - val_loss: 0.1239\n",
      "Epoch 18/90\n",
      "96/96 [==============================] - 3s 28ms/step - loss: 0.1020 - val_loss: 0.1225\n",
      "Epoch 19/90\n",
      "96/96 [==============================] - 3s 29ms/step - loss: 0.1006 - val_loss: 0.1210\n",
      "Epoch 20/90\n",
      "96/96 [==============================] - 3s 30ms/step - loss: 0.0993 - val_loss: 0.1196\n",
      "Epoch 21/90\n",
      "96/96 [==============================] - 3s 28ms/step - loss: 0.0979 - val_loss: 0.1182\n",
      "Epoch 22/90\n",
      "96/96 [==============================] - 3s 29ms/step - loss: 0.0965 - val_loss: 0.1167\n",
      "Epoch 23/90\n",
      "96/96 [==============================] - 3s 28ms/step - loss: 0.0952 - val_loss: 0.1152\n",
      "Epoch 24/90\n",
      "96/96 [==============================] - 3s 28ms/step - loss: 0.0938 - val_loss: 0.1138\n",
      "Epoch 25/90\n",
      "96/96 [==============================] - 3s 29ms/step - loss: 0.0924 - val_loss: 0.1123\n",
      "Epoch 26/90\n",
      "96/96 [==============================] - 3s 30ms/step - loss: 0.0910 - val_loss: 0.1108\n",
      "Epoch 27/90\n",
      "96/96 [==============================] - 3s 29ms/step - loss: 0.0896 - val_loss: 0.1093\n",
      "Epoch 28/90\n",
      "96/96 [==============================] - 3s 28ms/step - loss: 0.0882 - val_loss: 0.1077\n",
      "Epoch 29/90\n",
      "96/96 [==============================] - 3s 28ms/step - loss: 0.0868 - val_loss: 0.1062\n",
      "Epoch 30/90\n",
      "96/96 [==============================] - 3s 28ms/step - loss: 0.0854 - val_loss: 0.1047\n",
      "Epoch 31/90\n",
      "96/96 [==============================] - 3s 30ms/step - loss: 0.0840 - val_loss: 0.1032\n",
      "Epoch 32/90\n",
      "96/96 [==============================] - 3s 29ms/step - loss: 0.0826 - val_loss: 0.1017\n",
      "Epoch 33/90\n",
      "96/96 [==============================] - 3s 28ms/step - loss: 0.0813 - val_loss: 0.1002\n",
      "Epoch 34/90\n",
      "96/96 [==============================] - 3s 28ms/step - loss: 0.0801 - val_loss: 0.0988\n",
      "Epoch 35/90\n",
      "96/96 [==============================] - 3s 28ms/step - loss: 0.0789 - val_loss: 0.0976\n",
      "Epoch 36/90\n",
      "96/96 [==============================] - 3s 29ms/step - loss: 0.0777 - val_loss: 0.0963\n",
      "Epoch 37/90\n",
      "96/96 [==============================] - 3s 30ms/step - loss: 0.0767 - val_loss: 0.0951\n",
      "Epoch 38/90\n",
      "96/96 [==============================] - 3s 28ms/step - loss: 0.0756 - val_loss: 0.0939\n",
      "Epoch 39/90\n",
      "96/96 [==============================] - 3s 28ms/step - loss: 0.0745 - val_loss: 0.0927\n",
      "Epoch 40/90\n",
      "96/96 [==============================] - 3s 28ms/step - loss: 0.0734 - val_loss: 0.0915\n",
      "Epoch 41/90\n",
      "96/96 [==============================] - 3s 28ms/step - loss: 0.0724 - val_loss: 0.0902\n",
      "Epoch 42/90\n",
      "96/96 [==============================] - 3s 29ms/step - loss: 0.0713 - val_loss: 0.0890\n",
      "Epoch 43/90\n",
      "96/96 [==============================] - 3s 30ms/step - loss: 0.0703 - val_loss: 0.0878\n",
      "Epoch 44/90\n",
      "96/96 [==============================] - 3s 28ms/step - loss: 0.0693 - val_loss: 0.0866\n",
      "Epoch 45/90\n",
      "96/96 [==============================] - 3s 28ms/step - loss: 0.0683 - val_loss: 0.0854\n",
      "Epoch 46/90\n",
      "96/96 [==============================] - 3s 28ms/step - loss: 0.0673 - val_loss: 0.0842\n",
      "Epoch 47/90\n",
      "96/96 [==============================] - 3s 28ms/step - loss: 0.0662 - val_loss: 0.0829\n",
      "Epoch 48/90\n",
      "96/96 [==============================] - 3s 30ms/step - loss: 0.0652 - val_loss: 0.0817\n",
      "Epoch 49/90\n",
      "96/96 [==============================] - 3s 29ms/step - loss: 0.0642 - val_loss: 0.0805\n",
      "Epoch 50/90\n",
      "96/96 [==============================] - 3s 28ms/step - loss: 0.0632 - val_loss: 0.0793\n",
      "Epoch 51/90\n",
      "96/96 [==============================] - 3s 29ms/step - loss: 0.0623 - val_loss: 0.0781\n",
      "Epoch 52/90\n",
      "96/96 [==============================] - 3s 28ms/step - loss: 0.0613 - val_loss: 0.0769\n",
      "Epoch 53/90\n",
      "96/96 [==============================] - 3s 28ms/step - loss: 0.0604 - val_loss: 0.0758\n",
      "Epoch 54/90\n",
      "96/96 [==============================] - 3s 30ms/step - loss: 0.0595 - val_loss: 0.0747\n",
      "Epoch 55/90\n",
      "96/96 [==============================] - 3s 28ms/step - loss: 0.0587 - val_loss: 0.0736\n",
      "Epoch 56/90\n",
      "96/96 [==============================] - 3s 28ms/step - loss: 0.0578 - val_loss: 0.0725\n",
      "Epoch 57/90\n",
      "96/96 [==============================] - 3s 28ms/step - loss: 0.0570 - val_loss: 0.0715\n",
      "Epoch 58/90\n",
      "96/96 [==============================] - 3s 28ms/step - loss: 0.0561 - val_loss: 0.0704\n",
      "Epoch 59/90\n",
      "96/96 [==============================] - 3s 29ms/step - loss: 0.0553 - val_loss: 0.0693\n",
      "Epoch 60/90\n",
      "96/96 [==============================] - 3s 30ms/step - loss: 0.0546 - val_loss: 0.0683\n",
      "Epoch 61/90\n",
      "96/96 [==============================] - 3s 29ms/step - loss: 0.0537 - val_loss: 0.0672\n",
      "Epoch 62/90\n",
      "96/96 [==============================] - 3s 28ms/step - loss: 0.0529 - val_loss: 0.0661\n",
      "Epoch 63/90\n",
      "96/96 [==============================] - 3s 28ms/step - loss: 0.0522 - val_loss: 0.0651 0s\n",
      "Epoch 64/90\n",
      "96/96 [==============================] - 3s 28ms/step - loss: 0.0514 - val_loss: 0.0640\n",
      "Epoch 65/90\n",
      "96/96 [==============================] - 3s 29ms/step - loss: 0.0506 - val_loss: 0.0630\n",
      "Epoch 66/90\n",
      "96/96 [==============================] - 3s 29ms/step - loss: 0.0499 - val_loss: 0.0619\n",
      "Epoch 67/90\n",
      "96/96 [==============================] - 3s 28ms/step - loss: 0.0491 - val_loss: 0.0609\n",
      "Epoch 68/90\n",
      "96/96 [==============================] - 3s 28ms/step - loss: 0.0484 - val_loss: 0.0598\n",
      "Epoch 69/90\n",
      "96/96 [==============================] - 3s 28ms/step - loss: 0.0477 - val_loss: 0.0587\n",
      "Epoch 70/90\n",
      "96/96 [==============================] - 3s 28ms/step - loss: 0.0469 - val_loss: 0.0577\n",
      "Epoch 71/90\n",
      "96/96 [==============================] - 3s 30ms/step - loss: 0.0462 - val_loss: 0.0566\n",
      "Epoch 72/90\n",
      "96/96 [==============================] - 3s 29ms/step - loss: 0.0455 - val_loss: 0.0556\n",
      "Epoch 73/90\n",
      "96/96 [==============================] - 3s 29ms/step - loss: 0.0448 - val_loss: 0.0545\n",
      "Epoch 74/90\n",
      "96/96 [==============================] - 3s 28ms/step - loss: 0.0441 - val_loss: 0.0535\n",
      "Epoch 75/90\n",
      "96/96 [==============================] - 3s 28ms/step - loss: 0.0434 - val_loss: 0.0525\n",
      "Epoch 76/90\n",
      "96/96 [==============================] - 3s 28ms/step - loss: 0.0428 - val_loss: 0.0515\n",
      "Epoch 77/90\n",
      "96/96 [==============================] - 3s 30ms/step - loss: 0.0421 - val_loss: 0.0505\n",
      "Epoch 78/90\n",
      "96/96 [==============================] - 3s 29ms/step - loss: 0.0415 - val_loss: 0.0495\n",
      "Epoch 79/90\n",
      "96/96 [==============================] - 3s 29ms/step - loss: 0.0409 - val_loss: 0.0485\n",
      "Epoch 80/90\n",
      "96/96 [==============================] - 3s 28ms/step - loss: 0.0403 - val_loss: 0.0476\n",
      "Epoch 81/90\n",
      "96/96 [==============================] - 3s 28ms/step - loss: 0.0397 - val_loss: 0.0466\n",
      "Epoch 82/90\n",
      "96/96 [==============================] - 3s 29ms/step - loss: 0.0391 - val_loss: 0.0457\n",
      "Epoch 83/90\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "96/96 [==============================] - 3s 30ms/step - loss: 0.0386 - val_loss: 0.0448\n",
      "Epoch 84/90\n",
      "96/96 [==============================] - 3s 28ms/step - loss: 0.0381 - val_loss: 0.0440\n",
      "Epoch 85/90\n",
      "96/96 [==============================] - 3s 28ms/step - loss: 0.0376 - val_loss: 0.0432\n",
      "Epoch 86/90\n",
      "96/96 [==============================] - 3s 28ms/step - loss: 0.0371 - val_loss: 0.0425\n",
      "Epoch 87/90\n",
      "96/96 [==============================] - 3s 28ms/step - loss: 0.0367 - val_loss: 0.0418\n",
      "Epoch 88/90\n",
      "96/96 [==============================] - 3s 29ms/step - loss: 0.0363 - val_loss: 0.0411\n",
      "Epoch 89/90\n",
      "96/96 [==============================] - 3s 29ms/step - loss: 0.0359 - val_loss: 0.0404\n",
      "Epoch 90/90\n",
      "96/96 [==============================] - 3s 29ms/step - loss: 0.0356 - val_loss: 0.0397\n",
      "Execution time:  252.25831508636475\n",
      "DNN:\n",
      "Mean Absolute Error: 0.0361\n",
      "Root Mean Square Error: 0.0479\n",
      "Mean Square Error: 0.0023\n",
      "\n",
      "Train RMSE: 0.048\n",
      "Train MSE: 0.002\n",
      "Train MAE: 0.036\n",
      "###########################\n",
      "\n",
      "MODEL:  DNN\n",
      "sequence:  7d\n",
      "units:  12\n",
      "dropout1:  0.48476373451509647\n",
      "optimizer: adadelta\n",
      "activationDense: sigmoid\n",
      "epochs: 52\n",
      "batchsize: 57\n",
      "validation_split: 0.2\n",
      "Model: \"sequential_239\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_717 (Dense)            (None, 1008, 12)          24        \n",
      "_________________________________________________________________\n",
      "dense_718 (Dense)            (None, 1008, 16)          208       \n",
      "_________________________________________________________________\n",
      "dropout_239 (Dropout)        (None, 1008, 16)          0         \n",
      "_________________________________________________________________\n",
      "dense_719 (Dense)            (None, 1008, 1)           17        \n",
      "=================================================================\n",
      "Total params: 249\n",
      "Trainable params: 249\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/52\n",
      "42/42 [==============================] - 1s 35ms/step - loss: 0.0616 - val_loss: 0.0758\n",
      "Epoch 2/52\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 0.0615 - val_loss: 0.0756\n",
      "Epoch 3/52\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 0.0615 - val_loss: 0.0754\n",
      "Epoch 4/52\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 0.0613 - val_loss: 0.0753\n",
      "Epoch 5/52\n",
      "42/42 [==============================] - 1s 32ms/step - loss: 0.0612 - val_loss: 0.0751\n",
      "Epoch 6/52\n",
      "42/42 [==============================] - 1s 34ms/step - loss: 0.0611 - val_loss: 0.0750\n",
      "Epoch 7/52\n",
      "42/42 [==============================] - 1s 32ms/step - loss: 0.0610 - val_loss: 0.0748\n",
      "Epoch 8/52\n",
      "42/42 [==============================] - 1s 32ms/step - loss: 0.0608 - val_loss: 0.0746\n",
      "Epoch 9/52\n",
      "42/42 [==============================] - 1s 32ms/step - loss: 0.0608 - val_loss: 0.0745\n",
      "Epoch 10/52\n",
      "42/42 [==============================] - 1s 32ms/step - loss: 0.0606 - val_loss: 0.0743\n",
      "Epoch 11/52\n",
      "42/42 [==============================] - 1s 32ms/step - loss: 0.0605 - val_loss: 0.0741\n",
      "Epoch 12/52\n",
      "42/42 [==============================] - 1s 32ms/step - loss: 0.0604 - val_loss: 0.0739\n",
      "Epoch 13/52\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 0.0602 - val_loss: 0.0738\n",
      "Epoch 14/52\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 0.0601 - val_loss: 0.0736\n",
      "Epoch 15/52\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 0.0600 - val_loss: 0.0734\n",
      "Epoch 16/52\n",
      "42/42 [==============================] - 1s 32ms/step - loss: 0.0599 - val_loss: 0.0732\n",
      "Epoch 17/52\n",
      "42/42 [==============================] - 1s 32ms/step - loss: 0.0597 - val_loss: 0.0730\n",
      "Epoch 18/52\n",
      "42/42 [==============================] - 1s 33ms/step - loss: 0.0597 - val_loss: 0.0728\n",
      "Epoch 19/52\n",
      "42/42 [==============================] - 1s 33ms/step - loss: 0.0595 - val_loss: 0.0727\n",
      "Epoch 20/52\n",
      "42/42 [==============================] - 1s 32ms/step - loss: 0.0594 - val_loss: 0.0725\n",
      "Epoch 21/52\n",
      "42/42 [==============================] - 1s 32ms/step - loss: 0.0593 - val_loss: 0.0723\n",
      "Epoch 22/52\n",
      "42/42 [==============================] - 1s 30ms/step - loss: 0.0591 - val_loss: 0.0721\n",
      "Epoch 23/52\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 0.0590 - val_loss: 0.0719\n",
      "Epoch 24/52\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 0.0589 - val_loss: 0.0717\n",
      "Epoch 25/52\n",
      "42/42 [==============================] - 1s 32ms/step - loss: 0.0588 - val_loss: 0.0715\n",
      "Epoch 26/52\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 0.0587 - val_loss: 0.0713\n",
      "Epoch 27/52\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 0.0585 - val_loss: 0.0711\n",
      "Epoch 28/52\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 0.0584 - val_loss: 0.0709\n",
      "Epoch 29/52\n",
      "42/42 [==============================] - 1s 33ms/step - loss: 0.0582 - val_loss: 0.0708\n",
      "Epoch 30/52\n",
      "42/42 [==============================] - 1s 34ms/step - loss: 0.0581 - val_loss: 0.0706\n",
      "Epoch 31/52\n",
      "42/42 [==============================] - 1s 32ms/step - loss: 0.0580 - val_loss: 0.0704\n",
      "Epoch 32/52\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 0.0579 - val_loss: 0.0702\n",
      "Epoch 33/52\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 0.0577 - val_loss: 0.0700\n",
      "Epoch 34/52\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 0.0576 - val_loss: 0.0698\n",
      "Epoch 35/52\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 0.0575 - val_loss: 0.0696\n",
      "Epoch 36/52\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 0.0574 - val_loss: 0.0694\n",
      "Epoch 37/52\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 0.0572 - val_loss: 0.0692\n",
      "Epoch 38/52\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 0.0571 - val_loss: 0.0690\n",
      "Epoch 39/52\n",
      "42/42 [==============================] - 1s 32ms/step - loss: 0.0570 - val_loss: 0.0688\n",
      "Epoch 40/52\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 0.0569 - val_loss: 0.0686\n",
      "Epoch 41/52\n",
      "42/42 [==============================] - 1s 34ms/step - loss: 0.0568 - val_loss: 0.0684\n",
      "Epoch 42/52\n",
      "42/42 [==============================] - 1s 33ms/step - loss: 0.0566 - val_loss: 0.0682\n",
      "Epoch 43/52\n",
      "42/42 [==============================] - 1s 32ms/step - loss: 0.0565 - val_loss: 0.0680\n",
      "Epoch 44/52\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 0.0564 - val_loss: 0.0678\n",
      "Epoch 45/52\n",
      "42/42 [==============================] - 1s 32ms/step - loss: 0.0562 - val_loss: 0.0676\n",
      "Epoch 46/52\n",
      "42/42 [==============================] - 1s 32ms/step - loss: 0.0561 - val_loss: 0.0674\n",
      "Epoch 47/52\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 0.0560 - val_loss: 0.0672\n",
      "Epoch 48/52\n",
      "42/42 [==============================] - 1s 32ms/step - loss: 0.0559 - val_loss: 0.0670\n",
      "Epoch 49/52\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 0.0558 - val_loss: 0.0668\n",
      "Epoch 50/52\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 0.0556 - val_loss: 0.0666\n",
      "Epoch 51/52\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 0.0555 - val_loss: 0.0664\n",
      "Epoch 52/52\n",
      "42/42 [==============================] - 1s 32ms/step - loss: 0.0554 - val_loss: 0.0662\n",
      "Execution time:  72.07327222824097\n",
      "DNN:\n",
      "Mean Absolute Error: 0.0514\n",
      "Root Mean Square Error: 0.0607\n",
      "Mean Square Error: 0.0037\n",
      "\n",
      "Train RMSE: 0.061\n",
      "Train MSE: 0.004\n",
      "Train MAE: 0.051\n",
      "###########################\n",
      "\n",
      "MODEL:  DNN\n",
      "sequence:  7d\n",
      "units:  87\n",
      "dropout1:  0.40519643149940265\n",
      "optimizer: adamax\n",
      "activationDense: tanh\n",
      "epochs: 80\n",
      "batchsize: 31\n",
      "validation_split: 0.1\n",
      "Model: \"sequential_240\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_720 (Dense)            (None, 1008, 87)          174       \n",
      "_________________________________________________________________\n",
      "dense_721 (Dense)            (None, 1008, 16)          1408      \n",
      "_________________________________________________________________\n",
      "dropout_240 (Dropout)        (None, 1008, 16)          0         \n",
      "_________________________________________________________________\n",
      "dense_722 (Dense)            (None, 1008, 1)           17        \n",
      "=================================================================\n",
      "Total params: 1,599\n",
      "Trainable params: 1,599\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/80\n",
      "87/87 [==============================] - 3s 37ms/step - loss: 0.1544 - val_loss: 0.0303\n",
      "Epoch 2/80\n",
      "87/87 [==============================] - 3s 35ms/step - loss: 0.0973 - val_loss: 0.0213\n",
      "Epoch 3/80\n",
      "87/87 [==============================] - 3s 35ms/step - loss: 0.0882 - val_loss: 0.0140\n",
      "Epoch 4/80\n",
      "87/87 [==============================] - 3s 35ms/step - loss: 0.0814 - val_loss: 0.0114\n",
      "Epoch 5/80\n",
      "87/87 [==============================] - 3s 36ms/step - loss: 0.0757 - val_loss: 0.0101\n",
      "Epoch 6/80\n",
      "87/87 [==============================] - 3s 36ms/step - loss: 0.0706 - val_loss: 0.0091\n",
      "Epoch 7/80\n",
      "87/87 [==============================] - 3s 35ms/step - loss: 0.0657 - val_loss: 0.0079\n",
      "Epoch 8/80\n",
      "87/87 [==============================] - 3s 35ms/step - loss: 0.0610 - val_loss: 0.0062\n",
      "Epoch 9/80\n",
      "87/87 [==============================] - 3s 35ms/step - loss: 0.0565 - val_loss: 0.0056\n",
      "Epoch 10/80\n",
      "87/87 [==============================] - 3s 37ms/step - loss: 0.0521 - val_loss: 0.0068\n",
      "Epoch 11/80\n",
      "87/87 [==============================] - 3s 37ms/step - loss: 0.0473 - val_loss: 0.0084\n",
      "Epoch 12/80\n",
      "87/87 [==============================] - 3s 35ms/step - loss: 0.0425 - val_loss: 0.0147\n",
      "Epoch 13/80\n",
      "87/87 [==============================] - 3s 35ms/step - loss: 0.0380 - val_loss: 0.0179\n",
      "Epoch 14/80\n",
      "87/87 [==============================] - 3s 35ms/step - loss: 0.0355 - val_loss: 0.0194\n",
      "Epoch 15/80\n",
      "87/87 [==============================] - 3s 36ms/step - loss: 0.0333 - val_loss: 0.0215\n",
      "Epoch 16/80\n",
      "87/87 [==============================] - 3s 36ms/step - loss: 0.0317 - val_loss: 0.0236\n",
      "Epoch 17/80\n",
      "87/87 [==============================] - 3s 35ms/step - loss: 0.0302 - val_loss: 0.0242\n",
      "Epoch 18/80\n",
      "87/87 [==============================] - 3s 36ms/step - loss: 0.0290 - val_loss: 0.0248\n",
      "Epoch 19/80\n",
      "87/87 [==============================] - 3s 36ms/step - loss: 0.0281 - val_loss: 0.0203\n",
      "Epoch 20/80\n",
      "87/87 [==============================] - 3s 35ms/step - loss: 0.0273 - val_loss: 0.0146\n",
      "Epoch 21/80\n",
      "87/87 [==============================] - 3s 37ms/step - loss: 0.0261 - val_loss: 0.0129\n",
      "Epoch 22/80\n",
      "87/87 [==============================] - 3s 35ms/step - loss: 0.0252 - val_loss: 0.0107\n",
      "Epoch 23/80\n",
      "87/87 [==============================] - 3s 35ms/step - loss: 0.0242 - val_loss: 0.0114\n",
      "Epoch 24/80\n",
      "87/87 [==============================] - 3s 35ms/step - loss: 0.0241 - val_loss: 0.0120\n",
      "Epoch 25/80\n",
      "87/87 [==============================] - 3s 35ms/step - loss: 0.0239 - val_loss: 0.0166\n",
      "Epoch 26/80\n",
      "87/87 [==============================] - 3s 37ms/step - loss: 0.0236 - val_loss: 0.0122\n",
      "Epoch 27/80\n",
      "87/87 [==============================] - 3s 35ms/step - loss: 0.0237 - val_loss: 0.0113\n",
      "Epoch 28/80\n",
      "87/87 [==============================] - 3s 35ms/step - loss: 0.0234 - val_loss: 0.0139\n",
      "Epoch 29/80\n",
      "87/87 [==============================] - 3s 35ms/step - loss: 0.0234 - val_loss: 0.0132\n",
      "Epoch 30/80\n",
      "87/87 [==============================] - 3s 35ms/step - loss: 0.0234 - val_loss: 0.0136\n",
      "Epoch 31/80\n",
      "87/87 [==============================] - 3s 37ms/step - loss: 0.0234 - val_loss: 0.0136\n",
      "Epoch 32/80\n",
      "87/87 [==============================] - 3s 35ms/step - loss: 0.0234 - val_loss: 0.0137\n",
      "Epoch 33/80\n",
      "87/87 [==============================] - 3s 35ms/step - loss: 0.0234 - val_loss: 0.0135\n",
      "Epoch 34/80\n",
      "87/87 [==============================] - 3s 35ms/step - loss: 0.0234 - val_loss: 0.0136\n",
      "Epoch 35/80\n",
      "87/87 [==============================] - 3s 35ms/step - loss: 0.0234 - val_loss: 0.0135\n",
      "Epoch 36/80\n",
      "87/87 [==============================] - 3s 37ms/step - loss: 0.0234 - val_loss: 0.0136\n",
      "Epoch 37/80\n",
      "87/87 [==============================] - 3s 35ms/step - loss: 0.0234 - val_loss: 0.0135\n",
      "Epoch 38/80\n",
      "87/87 [==============================] - 3s 35ms/step - loss: 0.0234 - val_loss: 0.0136\n",
      "Epoch 39/80\n",
      "87/87 [==============================] - 3s 35ms/step - loss: 0.0234 - val_loss: 0.0135\n",
      "Epoch 40/80\n",
      "87/87 [==============================] - 3s 35ms/step - loss: 0.0234 - val_loss: 0.0136\n",
      "Epoch 41/80\n",
      "87/87 [==============================] - 3s 37ms/step - loss: 0.0234 - val_loss: 0.0135\n",
      "Epoch 42/80\n",
      "87/87 [==============================] - 3s 35ms/step - loss: 0.0234 - val_loss: 0.0136\n",
      "Epoch 43/80\n",
      "87/87 [==============================] - 3s 35ms/step - loss: 0.0234 - val_loss: 0.0135\n",
      "Epoch 44/80\n",
      "87/87 [==============================] - 3s 35ms/step - loss: 0.0234 - val_loss: 0.0137\n",
      "Epoch 45/80\n",
      "87/87 [==============================] - 3s 35ms/step - loss: 0.0234 - val_loss: 0.0135\n",
      "Epoch 46/80\n",
      "87/87 [==============================] - 3s 37ms/step - loss: 0.0234 - val_loss: 0.0137\n",
      "Epoch 47/80\n",
      "87/87 [==============================] - 3s 36ms/step - loss: 0.0234 - val_loss: 0.0136\n",
      "Epoch 48/80\n",
      "87/87 [==============================] - 3s 35ms/step - loss: 0.0234 - val_loss: 0.0137\n",
      "Epoch 49/80\n",
      "87/87 [==============================] - 3s 35ms/step - loss: 0.0234 - val_loss: 0.0136\n",
      "Epoch 50/80\n",
      "87/87 [==============================] - 3s 35ms/step - loss: 0.0234 - val_loss: 0.0137\n",
      "Epoch 51/80\n",
      "87/87 [==============================] - 3s 36ms/step - loss: 0.0234 - val_loss: 0.0136\n",
      "Epoch 52/80\n",
      "87/87 [==============================] - 3s 36ms/step - loss: 0.0234 - val_loss: 0.0137\n",
      "Epoch 53/80\n",
      "87/87 [==============================] - 3s 35ms/step - loss: 0.0234 - val_loss: 0.0136\n",
      "Epoch 54/80\n",
      "87/87 [==============================] - 3s 35ms/step - loss: 0.0234 - val_loss: 0.0135\n",
      "Epoch 55/80\n",
      "87/87 [==============================] - 3s 35ms/step - loss: 0.0234 - val_loss: 0.0138\n",
      "Epoch 56/80\n",
      "87/87 [==============================] - 3s 36ms/step - loss: 0.0234 - val_loss: 0.0137\n",
      "Epoch 57/80\n",
      "87/87 [==============================] - 3s 37ms/step - loss: 0.0234 - val_loss: 0.0136\n",
      "Epoch 58/80\n",
      "87/87 [==============================] - 3s 35ms/step - loss: 0.0234 - val_loss: 0.0137\n",
      "Epoch 59/80\n",
      "87/87 [==============================] - 3s 35ms/step - loss: 0.0234 - val_loss: 0.0136\n",
      "Epoch 60/80\n",
      "87/87 [==============================] - 3s 35ms/step - loss: 0.0234 - val_loss: 0.0137\n",
      "Epoch 61/80\n",
      "87/87 [==============================] - 3s 36ms/step - loss: 0.0234 - val_loss: 0.0136\n",
      "Epoch 62/80\n",
      "87/87 [==============================] - 3s 36ms/step - loss: 0.0234 - val_loss: 0.0137\n",
      "Epoch 63/80\n",
      "87/87 [==============================] - 3s 35ms/step - loss: 0.0234 - val_loss: 0.0136\n",
      "Epoch 64/80\n",
      "87/87 [==============================] - 3s 35ms/step - loss: 0.0234 - val_loss: 0.0137\n",
      "Epoch 65/80\n",
      "87/87 [==============================] - 3s 35ms/step - loss: 0.0234 - val_loss: 0.0136\n",
      "Epoch 66/80\n",
      "87/87 [==============================] - 3s 35ms/step - loss: 0.0234 - val_loss: 0.0137\n",
      "Epoch 67/80\n",
      "87/87 [==============================] - 3s 37ms/step - loss: 0.0234 - val_loss: 0.0136\n",
      "Epoch 68/80\n",
      "87/87 [==============================] - 3s 35ms/step - loss: 0.0234 - val_loss: 0.0137\n",
      "Epoch 69/80\n",
      "87/87 [==============================] - 3s 35ms/step - loss: 0.0234 - val_loss: 0.0136\n",
      "Epoch 70/80\n",
      "87/87 [==============================] - ETA: 0s - loss: 0.023 - 3s 35ms/step - loss: 0.0234 - val_loss: 0.0137\n",
      "Epoch 71/80\n",
      "87/87 [==============================] - 3s 35ms/step - loss: 0.0234 - val_loss: 0.0136\n",
      "Epoch 72/80\n",
      "87/87 [==============================] - 3s 37ms/step - loss: 0.0234 - val_loss: 0.0137\n",
      "Epoch 73/80\n",
      "87/87 [==============================] - 3s 35ms/step - loss: 0.0234 - val_loss: 0.0136\n",
      "Epoch 74/80\n",
      "87/87 [==============================] - 3s 35ms/step - loss: 0.0234 - val_loss: 0.0137\n",
      "Epoch 75/80\n",
      "87/87 [==============================] - 3s 35ms/step - loss: 0.0234 - val_loss: 0.0136\n",
      "Epoch 76/80\n",
      "87/87 [==============================] - 3s 35ms/step - loss: 0.0234 - val_loss: 0.0137\n",
      "Epoch 77/80\n",
      "87/87 [==============================] - 3s 37ms/step - loss: 0.0234 - val_loss: 0.0136\n",
      "Epoch 78/80\n",
      "87/87 [==============================] - 3s 35ms/step - loss: 0.0234 - val_loss: 0.0137\n",
      "Epoch 79/80\n",
      "87/87 [==============================] - 3s 35ms/step - loss: 0.0234 - val_loss: 0.0136\n",
      "Epoch 80/80\n",
      "87/87 [==============================] - 3s 35ms/step - loss: 0.0234 - val_loss: 0.0137\n",
      "Execution time:  251.38306307792664\n",
      "DNN:\n",
      "Mean Absolute Error: 0.0259\n",
      "Root Mean Square Error: 0.0468\n",
      "Mean Square Error: 0.0022\n",
      "\n",
      "Train RMSE: 0.047\n",
      "Train MSE: 0.002\n",
      "Train MAE: 0.026\n",
      "###########################\n",
      "\n",
      "MODEL:  DNN\n",
      "sequence:  7d\n",
      "units:  80\n",
      "dropout1:  0.11814836227952394\n",
      "optimizer: adamax\n",
      "activationDense: tanh\n",
      "epochs: 90\n",
      "batchsize: 25\n",
      "validation_split: 0.1\n",
      "Model: \"sequential_241\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_723 (Dense)            (None, 1008, 80)          160       \n",
      "_________________________________________________________________\n",
      "dense_724 (Dense)            (None, 1008, 16)          1296      \n",
      "_________________________________________________________________\n",
      "dropout_241 (Dropout)        (None, 1008, 16)          0         \n",
      "_________________________________________________________________\n",
      "dense_725 (Dense)            (None, 1008, 1)           17        \n",
      "=================================================================\n",
      "Total params: 1,473\n",
      "Trainable params: 1,473\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/90\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "108/108 [==============================] - 3s 32ms/step - loss: 0.0841 - val_loss: 0.0147\n",
      "Epoch 2/90\n",
      "108/108 [==============================] - 3s 28ms/step - loss: 0.0556 - val_loss: 0.0101\n",
      "Epoch 3/90\n",
      "108/108 [==============================] - 3s 27ms/step - loss: 0.0536 - val_loss: 0.0074\n",
      "Epoch 4/90\n",
      "108/108 [==============================] - 3s 27ms/step - loss: 0.0515 - val_loss: 0.0073\n",
      "Epoch 5/90\n",
      "108/108 [==============================] - 3s 27ms/step - loss: 0.0498 - val_loss: 0.0081\n",
      "Epoch 6/90\n",
      "108/108 [==============================] - 3s 28ms/step - loss: 0.0480 - val_loss: 0.0077\n",
      "Epoch 7/90\n",
      "108/108 [==============================] - ETA: 0s - loss: 0.046 - 3s 29ms/step - loss: 0.0465 - val_loss: 0.0091\n",
      "Epoch 8/90\n",
      "108/108 [==============================] - 3s 27ms/step - loss: 0.0450 - val_loss: 0.0085\n",
      "Epoch 9/90\n",
      "108/108 [==============================] - 3s 27ms/step - loss: 0.0437 - val_loss: 0.0093\n",
      "Epoch 10/90\n",
      "108/108 [==============================] - 3s 27ms/step - loss: 0.0425 - val_loss: 0.0102\n",
      "Epoch 11/90\n",
      "108/108 [==============================] - 3s 27ms/step - loss: 0.0412 - val_loss: 0.0093\n",
      "Epoch 12/90\n",
      "108/108 [==============================] - 3s 29ms/step - loss: 0.0401 - val_loss: 0.0090\n",
      "Epoch 13/90\n",
      "108/108 [==============================] - 3s 27ms/step - loss: 0.0391 - val_loss: 0.0085\n",
      "Epoch 14/90\n",
      "108/108 [==============================] - 3s 27ms/step - loss: 0.0382 - val_loss: 0.0087\n",
      "Epoch 15/90\n",
      "108/108 [==============================] - 3s 27ms/step - loss: 0.0372 - val_loss: 0.0095\n",
      "Epoch 16/90\n",
      "108/108 [==============================] - 3s 28ms/step - loss: 0.0362 - val_loss: 0.0099\n",
      "Epoch 17/90\n",
      "108/108 [==============================] - 3s 29ms/step - loss: 0.0354 - val_loss: 0.0101\n",
      "Epoch 18/90\n",
      "108/108 [==============================] - 3s 28ms/step - loss: 0.0344 - val_loss: 0.0096\n",
      "Epoch 19/90\n",
      "108/108 [==============================] - 3s 27ms/step - loss: 0.0337 - val_loss: 0.0097\n",
      "Epoch 20/90\n",
      "108/108 [==============================] - 3s 27ms/step - loss: 0.0331 - val_loss: 0.0093\n",
      "Epoch 21/90\n",
      "108/108 [==============================] - 3s 27ms/step - loss: 0.0323 - val_loss: 0.0108\n",
      "Epoch 22/90\n",
      "108/108 [==============================] - 3s 28ms/step - loss: 0.0316 - val_loss: 0.0096- los\n",
      "Epoch 23/90\n",
      "108/108 [==============================] - 3s 28ms/step - loss: 0.0313 - val_loss: 0.0115\n",
      "Epoch 24/90\n",
      "108/108 [==============================] - 3s 27ms/step - loss: 0.0309 - val_loss: 0.0118\n",
      "Epoch 25/90\n",
      "108/108 [==============================] - 3s 27ms/step - loss: 0.0307 - val_loss: 0.0129\n",
      "Epoch 26/90\n",
      "108/108 [==============================] - 3s 27ms/step - loss: 0.0303 - val_loss: 0.0130\n",
      "Epoch 27/90\n",
      "108/108 [==============================] - 3s 28ms/step - loss: 0.0297 - val_loss: 0.0132\n",
      "Epoch 28/90\n",
      "108/108 [==============================] - 3s 29ms/step - loss: 0.0291 - val_loss: 0.0141\n",
      "Epoch 29/90\n",
      "108/108 [==============================] - 3s 27ms/step - loss: 0.0289 - val_loss: 0.0159\n",
      "Epoch 30/90\n",
      "108/108 [==============================] - 3s 27ms/step - loss: 0.0283 - val_loss: 0.0175\n",
      "Epoch 31/90\n",
      "108/108 [==============================] - 3s 27ms/step - loss: 0.0279 - val_loss: 0.0178\n",
      "Epoch 32/90\n",
      "108/108 [==============================] - 3s 27ms/step - loss: 0.0277 - val_loss: 0.0193\n",
      "Epoch 33/90\n",
      "108/108 [==============================] - 3s 29ms/step - loss: 0.0273 - val_loss: 0.0206\n",
      "Epoch 34/90\n",
      "108/108 [==============================] - 3s 27ms/step - loss: 0.0271 - val_loss: 0.0224\n",
      "Epoch 35/90\n",
      "108/108 [==============================] - 3s 27ms/step - loss: 0.0269 - val_loss: 0.0222\n",
      "Epoch 36/90\n",
      "108/108 [==============================] - 3s 27ms/step - loss: 0.0268 - val_loss: 0.0248\n",
      "Epoch 37/90\n",
      "108/108 [==============================] - 3s 27ms/step - loss: 0.0265 - val_loss: 0.0237\n",
      "Epoch 38/90\n",
      "108/108 [==============================] - 3s 29ms/step - loss: 0.0262 - val_loss: 0.0232\n",
      "Epoch 39/90\n",
      "108/108 [==============================] - 3s 28ms/step - loss: 0.0258 - val_loss: 0.0233\n",
      "Epoch 40/90\n",
      "108/108 [==============================] - 3s 27ms/step - loss: 0.0257 - val_loss: 0.0224\n",
      "Epoch 41/90\n",
      "108/108 [==============================] - 3s 28ms/step - loss: 0.0256 - val_loss: 0.0208\n",
      "Epoch 42/90\n",
      "108/108 [==============================] - 3s 27ms/step - loss: 0.0254 - val_loss: 0.0183\n",
      "Epoch 43/90\n",
      "108/108 [==============================] - 3s 28ms/step - loss: 0.0254 - val_loss: 0.0160\n",
      "Epoch 44/90\n",
      "108/108 [==============================] - 3s 28ms/step - loss: 0.0251 - val_loss: 0.0161\n",
      "Epoch 45/90\n",
      "108/108 [==============================] - 3s 27ms/step - loss: 0.0249 - val_loss: 0.0147\n",
      "Epoch 46/90\n",
      "108/108 [==============================] - 3s 27ms/step - loss: 0.0246 - val_loss: 0.0147\n",
      "Epoch 47/90\n",
      "108/108 [==============================] - 3s 27ms/step - loss: 0.0245 - val_loss: 0.0133\n",
      "Epoch 48/90\n",
      "108/108 [==============================] - 3s 27ms/step - loss: 0.0243 - val_loss: 0.0131\n",
      "Epoch 49/90\n",
      "108/108 [==============================] - 3s 29ms/step - loss: 0.0243 - val_loss: 0.0124\n",
      "Epoch 50/90\n",
      "108/108 [==============================] - 3s 27ms/step - loss: 0.0244 - val_loss: 0.0121\n",
      "Epoch 51/90\n",
      "108/108 [==============================] - 3s 27ms/step - loss: 0.0241 - val_loss: 0.0136\n",
      "Epoch 52/90\n",
      "108/108 [==============================] - 3s 27ms/step - loss: 0.0243 - val_loss: 0.0121\n",
      "Epoch 53/90\n",
      "108/108 [==============================] - 3s 27ms/step - loss: 0.0240 - val_loss: 0.0123\n",
      "Epoch 54/90\n",
      "108/108 [==============================] - 3s 29ms/step - loss: 0.0238 - val_loss: 0.0112\n",
      "Epoch 55/90\n",
      "108/108 [==============================] - 3s 28ms/step - loss: 0.0237 - val_loss: 0.0113\n",
      "Epoch 56/90\n",
      "108/108 [==============================] - 3s 27ms/step - loss: 0.0236 - val_loss: 0.0115\n",
      "Epoch 57/90\n",
      "108/108 [==============================] - 3s 27ms/step - loss: 0.0236 - val_loss: 0.0118\n",
      "Epoch 58/90\n",
      "108/108 [==============================] - 3s 27ms/step - loss: 0.0235 - val_loss: 0.0120\n",
      "Epoch 59/90\n",
      "108/108 [==============================] - 3s 28ms/step - loss: 0.0235 - val_loss: 0.0123\n",
      "Epoch 60/90\n",
      "108/108 [==============================] - 3s 28ms/step - loss: 0.0234 - val_loss: 0.0124\n",
      "Epoch 61/90\n",
      "108/108 [==============================] - 3s 27ms/step - loss: 0.0234 - val_loss: 0.0126\n",
      "Epoch 62/90\n",
      "108/108 [==============================] - 3s 27ms/step - loss: 0.0234 - val_loss: 0.0128\n",
      "Epoch 63/90\n",
      "108/108 [==============================] - 3s 27ms/step - loss: 0.0236 - val_loss: 0.0125\n",
      "Epoch 64/90\n",
      "108/108 [==============================] - 3s 27ms/step - loss: 0.0234 - val_loss: 0.0126\n",
      "Epoch 65/90\n",
      "108/108 [==============================] - 3s 29ms/step - loss: 0.0234 - val_loss: 0.0129\n",
      "Epoch 66/90\n",
      "108/108 [==============================] - 3s 27ms/step - loss: 0.0234 - val_loss: 0.0126\n",
      "Epoch 67/90\n",
      "108/108 [==============================] - 3s 27ms/step - loss: 0.0234 - val_loss: 0.0129\n",
      "Epoch 68/90\n",
      "108/108 [==============================] - 3s 27ms/step - loss: 0.0234 - val_loss: 0.0131\n",
      "Epoch 69/90\n",
      "108/108 [==============================] - 3s 27ms/step - loss: 0.0234 - val_loss: 0.0126\n",
      "Epoch 70/90\n",
      "108/108 [==============================] - 3s 29ms/step - loss: 0.0234 - val_loss: 0.0129\n",
      "Epoch 71/90\n",
      "108/108 [==============================] - 3s 28ms/step - loss: 0.0234 - val_loss: 0.0126\n",
      "Epoch 72/90\n",
      "108/108 [==============================] - 3s 27ms/step - loss: 0.0234 - val_loss: 0.0129\n",
      "Epoch 73/90\n",
      "108/108 [==============================] - 3s 27ms/step - loss: 0.0234 - val_loss: 0.0127\n",
      "Epoch 74/90\n",
      "108/108 [==============================] - 3s 27ms/step - loss: 0.0234 - val_loss: 0.0130\n",
      "Epoch 75/90\n",
      "108/108 [==============================] - 3s 28ms/step - loss: 0.0234 - val_loss: 0.0125\n",
      "Epoch 76/90\n",
      "108/108 [==============================] - 3s 28ms/step - loss: 0.0234 - val_loss: 0.0128\n",
      "Epoch 77/90\n",
      "108/108 [==============================] - 3s 27ms/step - loss: 0.0234 - val_loss: 0.0131\n",
      "Epoch 78/90\n",
      "108/108 [==============================] - 3s 27ms/step - loss: 0.0234 - val_loss: 0.0126\n",
      "Epoch 79/90\n",
      "108/108 [==============================] - 3s 27ms/step - loss: 0.0234 - val_loss: 0.0129\n",
      "Epoch 80/90\n",
      "108/108 [==============================] - 3s 27ms/step - loss: 0.0234 - val_loss: 0.0126\n",
      "Epoch 81/90\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "108/108 [==============================] - 3s 29ms/step - loss: 0.0234 - val_loss: 0.0129\n",
      "Epoch 82/90\n",
      "108/108 [==============================] - 3s 27ms/step - loss: 0.0234 - val_loss: 0.0132\n",
      "Epoch 83/90\n",
      "108/108 [==============================] - 3s 27ms/step - loss: 0.0234 - val_loss: 0.0125\n",
      "Epoch 84/90\n",
      "108/108 [==============================] - 3s 27ms/step - loss: 0.0234 - val_loss: 0.0129\n",
      "Epoch 85/90\n",
      "108/108 [==============================] - 3s 27ms/step - loss: 0.0234 - val_loss: 0.0132\n",
      "Epoch 86/90\n",
      "108/108 [==============================] - 3s 29ms/step - loss: 0.0234 - val_loss: 0.0125\n",
      "Epoch 87/90\n",
      "108/108 [==============================] - 3s 27ms/step - loss: 0.0234 - val_loss: 0.0129\n",
      "Epoch 88/90\n",
      "108/108 [==============================] - 3s 27ms/step - loss: 0.0234 - val_loss: 0.0132\n",
      "Epoch 89/90\n",
      "108/108 [==============================] - 3s 27ms/step - loss: 0.0234 - val_loss: 0.0125\n",
      "Epoch 90/90\n",
      "108/108 [==============================] - 3s 28ms/step - loss: 0.0234 - val_loss: 0.0128\n",
      "Execution time:  273.0604820251465\n",
      "DNN:\n",
      "Mean Absolute Error: 0.0260\n",
      "Root Mean Square Error: 0.0470\n",
      "Mean Square Error: 0.0022\n",
      "\n",
      "Train RMSE: 0.047\n",
      "Train MSE: 0.002\n",
      "Train MAE: 0.026\n",
      "###########################\n",
      "\n",
      "MODEL:  DNN\n",
      "sequence:  7d\n",
      "units:  12\n",
      "dropout1:  0.48476373451509647\n",
      "optimizer: adamax\n",
      "activationDense: tanh\n",
      "epochs: 52\n",
      "batchsize: 57\n",
      "validation_split: 0.1\n",
      "Model: \"sequential_242\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_726 (Dense)            (None, 1008, 12)          24        \n",
      "_________________________________________________________________\n",
      "dense_727 (Dense)            (None, 1008, 16)          208       \n",
      "_________________________________________________________________\n",
      "dropout_242 (Dropout)        (None, 1008, 16)          0         \n",
      "_________________________________________________________________\n",
      "dense_728 (Dense)            (None, 1008, 1)           17        \n",
      "=================================================================\n",
      "Total params: 249\n",
      "Trainable params: 249\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/52\n",
      "48/48 [==============================] - 2s 34ms/step - loss: 0.3995 - val_loss: 0.1772\n",
      "Epoch 2/52\n",
      "48/48 [==============================] - 1s 30ms/step - loss: 0.1722 - val_loss: 0.0489\n",
      "Epoch 3/52\n",
      "48/48 [==============================] - 1s 30ms/step - loss: 0.1416 - val_loss: 0.0081\n",
      "Epoch 4/52\n",
      "48/48 [==============================] - 1s 30ms/step - loss: 0.1256 - val_loss: 0.0075\n",
      "Epoch 5/52\n",
      "48/48 [==============================] - 1s 30ms/step - loss: 0.1138 - val_loss: 0.0170\n",
      "Epoch 6/52\n",
      "48/48 [==============================] - 1s 31ms/step - loss: 0.1033 - val_loss: 0.0248\n",
      "Epoch 7/52\n",
      "48/48 [==============================] - 1s 30ms/step - loss: 0.0938 - val_loss: 0.0264\n",
      "Epoch 8/52\n",
      "48/48 [==============================] - 1s 31ms/step - loss: 0.0856 - val_loss: 0.0208\n",
      "Epoch 9/52\n",
      "48/48 [==============================] - 1s 30ms/step - loss: 0.0778 - val_loss: 0.0142\n",
      "Epoch 10/52\n",
      "48/48 [==============================] - 1s 31ms/step - loss: 0.0703 - val_loss: 0.0087\n",
      "Epoch 11/52\n",
      "48/48 [==============================] - 2s 32ms/step - loss: 0.0635 - val_loss: 0.0049\n",
      "Epoch 12/52\n",
      "48/48 [==============================] - 2s 32ms/step - loss: 0.0570 - val_loss: 0.0064\n",
      "Epoch 13/52\n",
      "48/48 [==============================] - 1s 31ms/step - loss: 0.0519 - val_loss: 0.0069\n",
      "Epoch 14/52\n",
      "48/48 [==============================] - 1s 30ms/step - loss: 0.0478 - val_loss: 0.0061\n",
      "Epoch 15/52\n",
      "48/48 [==============================] - 1s 29ms/step - loss: 0.0442 - val_loss: 0.0061\n",
      "Epoch 16/52\n",
      "48/48 [==============================] - 1s 30ms/step - loss: 0.0410 - val_loss: 0.0068\n",
      "Epoch 17/52\n",
      "48/48 [==============================] - 1s 30ms/step - loss: 0.0382 - val_loss: 0.0076\n",
      "Epoch 18/52\n",
      "48/48 [==============================] - 1s 30ms/step - loss: 0.0356 - val_loss: 0.0084\n",
      "Epoch 19/52\n",
      "48/48 [==============================] - 1s 30ms/step - loss: 0.0332 - val_loss: 0.0092\n",
      "Epoch 20/52\n",
      "48/48 [==============================] - 1s 30ms/step - loss: 0.0312 - val_loss: 0.0092\n",
      "Epoch 21/52\n",
      "48/48 [==============================] - 1s 31ms/step - loss: 0.0295 - val_loss: 0.0088\n",
      "Epoch 22/52\n",
      "48/48 [==============================] - 2s 33ms/step - loss: 0.0284 - val_loss: 0.0087\n",
      "Epoch 23/52\n",
      "48/48 [==============================] - 1s 30ms/step - loss: 0.0274 - val_loss: 0.0109\n",
      "Epoch 24/52\n",
      "48/48 [==============================] - 1s 31ms/step - loss: 0.0245 - val_loss: 0.0163\n",
      "Epoch 25/52\n",
      "48/48 [==============================] - 1s 30ms/step - loss: 0.0232 - val_loss: 0.0159\n",
      "Epoch 26/52\n",
      "48/48 [==============================] - 1s 30ms/step - loss: 0.0232 - val_loss: 0.0152\n",
      "Epoch 27/52\n",
      "48/48 [==============================] - 1s 30ms/step - loss: 0.0232 - val_loss: 0.0150\n",
      "Epoch 28/52\n",
      "48/48 [==============================] - 1s 31ms/step - loss: 0.0231 - val_loss: 0.0143\n",
      "Epoch 29/52\n",
      "48/48 [==============================] - 1s 30ms/step - loss: 0.0231 - val_loss: 0.0141\n",
      "Epoch 30/52\n",
      "48/48 [==============================] - 1s 30ms/step - loss: 0.0230 - val_loss: 0.0128\n",
      "Epoch 31/52\n",
      "48/48 [==============================] - 1s 30ms/step - loss: 0.0230 - val_loss: 0.0144\n",
      "Epoch 32/52\n",
      "48/48 [==============================] - 2s 33ms/step - loss: 0.0229 - val_loss: 0.0130\n",
      "Epoch 33/52\n",
      "48/48 [==============================] - 2s 32ms/step - loss: 0.0231 - val_loss: 0.0142\n",
      "Epoch 34/52\n",
      "48/48 [==============================] - 1s 30ms/step - loss: 0.0229 - val_loss: 0.0128\n",
      "Epoch 35/52\n",
      "48/48 [==============================] - 1s 30ms/step - loss: 0.0230 - val_loss: 0.0145\n",
      "Epoch 36/52\n",
      "48/48 [==============================] - 1s 30ms/step - loss: 0.0229 - val_loss: 0.0130\n",
      "Epoch 37/52\n",
      "48/48 [==============================] - 1s 30ms/step - loss: 0.0231 - val_loss: 0.0143\n",
      "Epoch 38/52\n",
      "48/48 [==============================] - 1s 30ms/step - loss: 0.0229 - val_loss: 0.0129\n",
      "Epoch 39/52\n",
      "48/48 [==============================] - 1s 30ms/step - loss: 0.0230 - val_loss: 0.0145 ETA: 0s - loss: 0.02\n",
      "Epoch 40/52\n",
      "48/48 [==============================] - 1s 30ms/step - loss: 0.0229 - val_loss: 0.0130\n",
      "Epoch 41/52\n",
      "48/48 [==============================] - 1s 30ms/step - loss: 0.0230 - val_loss: 0.0142\n",
      "Epoch 42/52\n",
      "48/48 [==============================] - 2s 31ms/step - loss: 0.0229 - val_loss: 0.0128\n",
      "Epoch 43/52\n",
      "48/48 [==============================] - 2s 33ms/step - loss: 0.0230 - val_loss: 0.0144\n",
      "Epoch 44/52\n",
      "48/48 [==============================] - 2s 31ms/step - loss: 0.0229 - val_loss: 0.0129\n",
      "Epoch 45/52\n",
      "48/48 [==============================] - 1s 30ms/step - loss: 0.0230 - val_loss: 0.0145\n",
      "Epoch 46/52\n",
      "48/48 [==============================] - 1s 30ms/step - loss: 0.0229 - val_loss: 0.0130\n",
      "Epoch 47/52\n",
      "48/48 [==============================] - 1s 30ms/step - loss: 0.0230 - val_loss: 0.0142\n",
      "Epoch 48/52\n",
      "48/48 [==============================] - 1s 30ms/step - loss: 0.0228 - val_loss: 0.0127\n",
      "Epoch 49/52\n",
      "48/48 [==============================] - 1s 30ms/step - loss: 0.0230 - val_loss: 0.0143\n",
      "Epoch 50/52\n",
      "48/48 [==============================] - 1s 30ms/step - loss: 0.0229 - val_loss: 0.0119\n",
      "Epoch 51/52\n",
      "48/48 [==============================] - 1s 30ms/step - loss: 0.0230 - val_loss: 0.0139\n",
      "Epoch 52/52\n",
      "48/48 [==============================] - 1s 30ms/step - loss: 0.0228 - val_loss: 0.0124\n",
      "Execution time:  79.42036509513855\n",
      "DNN:\n",
      "Mean Absolute Error: 0.0261\n",
      "Root Mean Square Error: 0.0475\n",
      "Mean Square Error: 0.0023\n",
      "\n",
      "Train RMSE: 0.047\n",
      "Train MSE: 0.002\n",
      "Train MAE: 0.026\n",
      "###########################\n",
      "\n",
      "MODEL:  DNN\n",
      "sequence:  7d\n",
      "units:  87\n",
      "dropout1:  0.40519643149940265\n",
      "optimizer: adamax\n",
      "activationDense: tanh\n",
      "epochs: 80\n",
      "batchsize: 31\n",
      "validation_split: 0.2\n",
      "Model: \"sequential_243\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_729 (Dense)            (None, 1008, 87)          174       \n",
      "_________________________________________________________________\n",
      "dense_730 (Dense)            (None, 1008, 16)          1408      \n",
      "_________________________________________________________________\n",
      "dropout_243 (Dropout)        (None, 1008, 16)          0         \n",
      "_________________________________________________________________\n",
      "dense_731 (Dense)            (None, 1008, 1)           17        \n",
      "=================================================================\n",
      "Total params: 1,599\n",
      "Trainable params: 1,599\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/80\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "77/77 [==============================] - 3s 39ms/step - loss: 0.1409 - val_loss: 0.0363\n",
      "Epoch 2/80\n",
      "77/77 [==============================] - 3s 37ms/step - loss: 0.1084 - val_loss: 0.0225\n",
      "Epoch 3/80\n",
      "77/77 [==============================] - 3s 38ms/step - loss: 0.1021 - val_loss: 0.0201\n",
      "Epoch 4/80\n",
      "77/77 [==============================] - 3s 39ms/step - loss: 0.0956 - val_loss: 0.0197\n",
      "Epoch 5/80\n",
      "77/77 [==============================] - 3s 36ms/step - loss: 0.0887 - val_loss: 0.0197\n",
      "Epoch 6/80\n",
      "77/77 [==============================] - 3s 39ms/step - loss: 0.0821 - val_loss: 0.0193\n",
      "Epoch 7/80\n",
      "77/77 [==============================] - 3s 37ms/step - loss: 0.0759 - val_loss: 0.0201\n",
      "Epoch 8/80\n",
      "77/77 [==============================] - 3s 37ms/step - loss: 0.0700 - val_loss: 0.0206\n",
      "Epoch 9/80\n",
      "77/77 [==============================] - 3s 37ms/step - loss: 0.0645 - val_loss: 0.0222\n",
      "Epoch 10/80\n",
      "77/77 [==============================] - 3s 37ms/step - loss: 0.0594 - val_loss: 0.0241\n",
      "Epoch 11/80\n",
      "77/77 [==============================] - 3s 38ms/step - loss: 0.0546 - val_loss: 0.0220\n",
      "Epoch 12/80\n",
      "77/77 [==============================] - 3s 38ms/step - loss: 0.0502 - val_loss: 0.0177\n",
      "Epoch 13/80\n",
      "77/77 [==============================] - 3s 37ms/step - loss: 0.0460 - val_loss: 0.0143\n",
      "Epoch 14/80\n",
      "77/77 [==============================] - 3s 37ms/step - loss: 0.0421 - val_loss: 0.0113\n",
      "Epoch 15/80\n",
      "77/77 [==============================] - 3s 37ms/step - loss: 0.0387 - val_loss: 0.0106\n",
      "Epoch 16/80\n",
      "77/77 [==============================] - 3s 37ms/step - loss: 0.0357 - val_loss: 0.0102\n",
      "Epoch 17/80\n",
      "77/77 [==============================] - 3s 39ms/step - loss: 0.0329 - val_loss: 0.0105\n",
      "Epoch 18/80\n",
      "77/77 [==============================] - 3s 37ms/step - loss: 0.0311 - val_loss: 0.0114\n",
      "Epoch 19/80\n",
      "77/77 [==============================] - 3s 37ms/step - loss: 0.0302 - val_loss: 0.0104\n",
      "Epoch 20/80\n",
      "77/77 [==============================] - 3s 37ms/step - loss: 0.0283 - val_loss: 0.0101\n",
      "Epoch 21/80\n",
      "77/77 [==============================] - 3s 37ms/step - loss: 0.0262 - val_loss: 0.0106\n",
      "Epoch 22/80\n",
      "77/77 [==============================] - 3s 38ms/step - loss: 0.0249 - val_loss: 0.0129\n",
      "Epoch 23/80\n",
      "77/77 [==============================] - 3s 38ms/step - loss: 0.0251 - val_loss: 0.0121\n",
      "Epoch 24/80\n",
      "77/77 [==============================] - 3s 37ms/step - loss: 0.0250 - val_loss: 0.0123\n",
      "Epoch 25/80\n",
      "77/77 [==============================] - 3s 37ms/step - loss: 0.0251 - val_loss: 0.0124\n",
      "Epoch 26/80\n",
      "77/77 [==============================] - 3s 37ms/step - loss: 0.0251 - val_loss: 0.0120\n",
      "Epoch 27/80\n",
      "77/77 [==============================] - 3s 37ms/step - loss: 0.0250 - val_loss: 0.0122\n",
      "Epoch 28/80\n",
      "77/77 [==============================] - 3s 39ms/step - loss: 0.0251 - val_loss: 0.0121\n",
      "Epoch 29/80\n",
      "77/77 [==============================] - 3s 37ms/step - loss: 0.0251 - val_loss: 0.0122\n",
      "Epoch 30/80\n",
      "77/77 [==============================] - 3s 37ms/step - loss: 0.0251 - val_loss: 0.0122\n",
      "Epoch 31/80\n",
      "77/77 [==============================] - 3s 37ms/step - loss: 0.0251 - val_loss: 0.0122\n",
      "Epoch 32/80\n",
      "77/77 [==============================] - 3s 37ms/step - loss: 0.0251 - val_loss: 0.0121\n",
      "Epoch 33/80\n",
      "77/77 [==============================] - 3s 38ms/step - loss: 0.0251 - val_loss: 0.0122\n",
      "Epoch 34/80\n",
      "77/77 [==============================] - 3s 38ms/step - loss: 0.0251 - val_loss: 0.0122\n",
      "Epoch 35/80\n",
      "77/77 [==============================] - 3s 37ms/step - loss: 0.0251 - val_loss: 0.0122\n",
      "Epoch 36/80\n",
      "77/77 [==============================] - 3s 37ms/step - loss: 0.0251 - val_loss: 0.0121\n",
      "Epoch 37/80\n",
      "77/77 [==============================] - 3s 37ms/step - loss: 0.0251 - val_loss: 0.0122\n",
      "Epoch 38/80\n",
      "77/77 [==============================] - 3s 37ms/step - loss: 0.0251 - val_loss: 0.0122\n",
      "Epoch 39/80\n",
      "77/77 [==============================] - 3s 39ms/step - loss: 0.0251 - val_loss: 0.0121\n",
      "Epoch 40/80\n",
      "77/77 [==============================] - 3s 37ms/step - loss: 0.0251 - val_loss: 0.0121\n",
      "Epoch 41/80\n",
      "77/77 [==============================] - 3s 37ms/step - loss: 0.0251 - val_loss: 0.0122\n",
      "Epoch 42/80\n",
      "77/77 [==============================] - 3s 37ms/step - loss: 0.0251 - val_loss: 0.0122\n",
      "Epoch 43/80\n",
      "77/77 [==============================] - 3s 37ms/step - loss: 0.0251 - val_loss: 0.0121\n",
      "Epoch 44/80\n",
      "77/77 [==============================] - 3s 37ms/step - loss: 0.0251 - val_loss: 0.0122\n",
      "Epoch 45/80\n",
      "77/77 [==============================] - 3s 38ms/step - loss: 0.0251 - val_loss: 0.0122\n",
      "Epoch 46/80\n",
      "77/77 [==============================] - 3s 37ms/step - loss: 0.0251 - val_loss: 0.0122\n",
      "Epoch 47/80\n",
      "77/77 [==============================] - 3s 37ms/step - loss: 0.0251 - val_loss: 0.0121\n",
      "Epoch 48/80\n",
      "77/77 [==============================] - 3s 37ms/step - loss: 0.0251 - val_loss: 0.0122\n",
      "Epoch 49/80\n",
      "77/77 [==============================] - 3s 37ms/step - loss: 0.0251 - val_loss: 0.0122\n",
      "Epoch 50/80\n",
      "77/77 [==============================] - 3s 39ms/step - loss: 0.0251 - val_loss: 0.0121\n",
      "Epoch 51/80\n",
      "77/77 [==============================] - 3s 37ms/step - loss: 0.0250 - val_loss: 0.0123\n",
      "Epoch 52/80\n",
      "77/77 [==============================] - 3s 37ms/step - loss: 0.0251 - val_loss: 0.0124\n",
      "Epoch 53/80\n",
      "77/77 [==============================] - 3s 37ms/step - loss: 0.0251 - val_loss: 0.0120\n",
      "Epoch 54/80\n",
      "77/77 [==============================] - 3s 37ms/step - loss: 0.0250 - val_loss: 0.0123\n",
      "Epoch 55/80\n",
      "77/77 [==============================] - 3s 37ms/step - loss: 0.0251 - val_loss: 0.0122\n",
      "Epoch 56/80\n",
      "77/77 [==============================] - 3s 38ms/step - loss: 0.0251 - val_loss: 0.0122\n",
      "Epoch 57/80\n",
      "77/77 [==============================] - 3s 37ms/step - loss: 0.0251 - val_loss: 0.0122\n",
      "Epoch 58/80\n",
      "77/77 [==============================] - 3s 37ms/step - loss: 0.0251 - val_loss: 0.0121\n",
      "Epoch 59/80\n",
      "77/77 [==============================] - 3s 37ms/step - loss: 0.0251 - val_loss: 0.0122\n",
      "Epoch 60/80\n",
      "77/77 [==============================] - 3s 37ms/step - loss: 0.0251 - val_loss: 0.0122\n",
      "Epoch 61/80\n",
      "77/77 [==============================] - 3s 39ms/step - loss: 0.0251 - val_loss: 0.0121\n",
      "Epoch 62/80\n",
      "77/77 [==============================] - 3s 37ms/step - loss: 0.0250 - val_loss: 0.0123\n",
      "Epoch 63/80\n",
      "77/77 [==============================] - 3s 37ms/step - loss: 0.0251 - val_loss: 0.0124\n",
      "Epoch 64/80\n",
      "77/77 [==============================] - 3s 37ms/step - loss: 0.0251 - val_loss: 0.0120\n",
      "Epoch 65/80\n",
      "77/77 [==============================] - 3s 37ms/step - loss: 0.0250 - val_loss: 0.0122\n",
      "Epoch 66/80\n",
      "77/77 [==============================] - 3s 38ms/step - loss: 0.0251 - val_loss: 0.0121\n",
      "Epoch 67/80\n",
      "77/77 [==============================] - 3s 38ms/step - loss: 0.0251 - val_loss: 0.0122\n",
      "Epoch 68/80\n",
      "77/77 [==============================] - 3s 37ms/step - loss: 0.0251 - val_loss: 0.0122\n",
      "Epoch 69/80\n",
      "77/77 [==============================] - 3s 37ms/step - loss: 0.0251 - val_loss: 0.0122\n",
      "Epoch 70/80\n",
      "77/77 [==============================] - 3s 37ms/step - loss: 0.0251 - val_loss: 0.0121\n",
      "Epoch 71/80\n",
      "77/77 [==============================] - 3s 37ms/step - loss: 0.0251 - val_loss: 0.0121\n",
      "Epoch 72/80\n",
      "77/77 [==============================] - 3s 39ms/step - loss: 0.0251 - val_loss: 0.0122\n",
      "Epoch 73/80\n",
      "77/77 [==============================] - 3s 37ms/step - loss: 0.0251 - val_loss: 0.0122\n",
      "Epoch 74/80\n",
      "77/77 [==============================] - 3s 37ms/step - loss: 0.0251 - val_loss: 0.0122\n",
      "Epoch 75/80\n",
      "77/77 [==============================] - 3s 37ms/step - loss: 0.0251 - val_loss: 0.0121\n",
      "Epoch 76/80\n",
      "77/77 [==============================] - 3s 37ms/step - loss: 0.0251 - val_loss: 0.0122\n",
      "Epoch 77/80\n",
      "77/77 [==============================] - 3s 37ms/step - loss: 0.0251 - val_loss: 0.0122\n",
      "Epoch 78/80\n",
      "77/77 [==============================] - 3s 38ms/step - loss: 0.0251 - val_loss: 0.0122\n",
      "Epoch 79/80\n",
      "77/77 [==============================] - 3s 37ms/step - loss: 0.0251 - val_loss: 0.0121\n",
      "Epoch 80/80\n",
      "77/77 [==============================] - 3s 37ms/step - loss: 0.0250 - val_loss: 0.0123\n",
      "Execution time:  234.0260627269745\n",
      "DNN:\n",
      "Mean Absolute Error: 0.0258\n",
      "Root Mean Square Error: 0.0464\n",
      "Mean Square Error: 0.0022\n",
      "\n",
      "Train RMSE: 0.046\n",
      "Train MSE: 0.002\n",
      "Train MAE: 0.026\n",
      "###########################\n",
      "\n",
      "MODEL:  DNN\n",
      "sequence:  7d\n",
      "units:  80\n",
      "dropout1:  0.11814836227952394\n",
      "optimizer: adamax\n",
      "activationDense: tanh\n",
      "epochs: 90\n",
      "batchsize: 25\n",
      "validation_split: 0.2\n",
      "Model: \"sequential_244\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_732 (Dense)            (None, 1008, 80)          160       \n",
      "_________________________________________________________________\n",
      "dense_733 (Dense)            (None, 1008, 16)          1296      \n",
      "_________________________________________________________________\n",
      "dropout_244 (Dropout)        (None, 1008, 16)          0         \n",
      "_________________________________________________________________\n",
      "dense_734 (Dense)            (None, 1008, 1)           17        \n",
      "=================================================================\n",
      "Total params: 1,473\n",
      "Trainable params: 1,473\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/90\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "96/96 [==============================] - 3s 30ms/step - loss: 0.1522 - val_loss: 0.0277\n",
      "Epoch 2/90\n",
      "96/96 [==============================] - 3s 29ms/step - loss: 0.0599 - val_loss: 0.0230\n",
      "Epoch 3/90\n",
      "96/96 [==============================] - 3s 29ms/step - loss: 0.0585 - val_loss: 0.0228\n",
      "Epoch 4/90\n",
      "96/96 [==============================] - 3s 28ms/step - loss: 0.0566 - val_loss: 0.0208\n",
      "Epoch 5/90\n",
      "96/96 [==============================] - 3s 28ms/step - loss: 0.0550 - val_loss: 0.0193\n",
      "Epoch 6/90\n",
      "96/96 [==============================] - 3s 28ms/step - loss: 0.0533 - val_loss: 0.0190\n",
      "Epoch 7/90\n",
      "96/96 [==============================] - 3s 28ms/step - loss: 0.0518 - val_loss: 0.0173\n",
      "Epoch 8/90\n",
      "96/96 [==============================] - 3s 30ms/step - loss: 0.0504 - val_loss: 0.0174\n",
      "Epoch 9/90\n",
      "96/96 [==============================] - 3s 29ms/step - loss: 0.0489 - val_loss: 0.0160\n",
      "Epoch 10/90\n",
      "96/96 [==============================] - 3s 28ms/step - loss: 0.0475 - val_loss: 0.0162\n",
      "Epoch 11/90\n",
      "96/96 [==============================] - 3s 28ms/step - loss: 0.0460 - val_loss: 0.0117\n",
      "Epoch 12/90\n",
      "96/96 [==============================] - 3s 28ms/step - loss: 0.0448 - val_loss: 0.0167\n",
      "Epoch 13/90\n",
      "96/96 [==============================] - 3s 29ms/step - loss: 0.0434 - val_loss: 0.0155\n",
      "Epoch 14/90\n",
      "96/96 [==============================] - 3s 30ms/step - loss: 0.0421 - val_loss: 0.0126\n",
      "Epoch 15/90\n",
      "96/96 [==============================] - 3s 28ms/step - loss: 0.0410 - val_loss: 0.0118\n",
      "Epoch 16/90\n",
      "96/96 [==============================] - 3s 28ms/step - loss: 0.0400 - val_loss: 0.0113\n",
      "Epoch 17/90\n",
      "96/96 [==============================] - 3s 28ms/step - loss: 0.0391 - val_loss: 0.0110\n",
      "Epoch 18/90\n",
      "96/96 [==============================] - 3s 28ms/step - loss: 0.0380 - val_loss: 0.0107\n",
      "Epoch 19/90\n",
      "96/96 [==============================] - 3s 29ms/step - loss: 0.0373 - val_loss: 0.0107\n",
      "Epoch 20/90\n",
      "96/96 [==============================] - 3s 30ms/step - loss: 0.0363 - val_loss: 0.0103\n",
      "Epoch 21/90\n",
      "96/96 [==============================] - 3s 29ms/step - loss: 0.0349 - val_loss: 0.0102\n",
      "Epoch 22/90\n",
      "96/96 [==============================] - 3s 28ms/step - loss: 0.0343 - val_loss: 0.0102\n",
      "Epoch 23/90\n",
      "96/96 [==============================] - 3s 29ms/step - loss: 0.0336 - val_loss: 0.0102\n",
      "Epoch 24/90\n",
      "96/96 [==============================] - 3s 28ms/step - loss: 0.0330 - val_loss: 0.0102\n",
      "Epoch 25/90\n",
      "96/96 [==============================] - 3s 29ms/step - loss: 0.0322 - val_loss: 0.0105\n",
      "Epoch 26/90\n",
      "96/96 [==============================] - 3s 29ms/step - loss: 0.0318 - val_loss: 0.0102\n",
      "Epoch 27/90\n",
      "96/96 [==============================] - 3s 28ms/step - loss: 0.0312 - val_loss: 0.0101\n",
      "Epoch 28/90\n",
      "96/96 [==============================] - 3s 28ms/step - loss: 0.0307 - val_loss: 0.0103\n",
      "Epoch 29/90\n",
      "96/96 [==============================] - 3s 28ms/step - loss: 0.0303 - val_loss: 0.0102\n",
      "Epoch 30/90\n",
      "96/96 [==============================] - 3s 28ms/step - loss: 0.0297 - val_loss: 0.0102\n",
      "Epoch 31/90\n",
      "96/96 [==============================] - 3s 30ms/step - loss: 0.0292 - val_loss: 0.0101\n",
      "Epoch 32/90\n",
      "96/96 [==============================] - 3s 29ms/step - loss: 0.0289 - val_loss: 0.0102\n",
      "Epoch 33/90\n",
      "96/96 [==============================] - 3s 28ms/step - loss: 0.0286 - val_loss: 0.0103\n",
      "Epoch 34/90\n",
      "96/96 [==============================] - 3s 28ms/step - loss: 0.0283 - val_loss: 0.0101\n",
      "Epoch 35/90\n",
      "96/96 [==============================] - 3s 28ms/step - loss: 0.0278 - val_loss: 0.0103\n",
      "Epoch 36/90\n",
      "96/96 [==============================] - 3s 29ms/step - loss: 0.0278 - val_loss: 0.0102\n",
      "Epoch 37/90\n",
      "96/96 [==============================] - 3s 31ms/step - loss: 0.0274 - val_loss: 0.0102\n",
      "Epoch 38/90\n",
      "96/96 [==============================] - 3s 29ms/step - loss: 0.0271 - val_loss: 0.0105\n",
      "Epoch 39/90\n",
      "96/96 [==============================] - 3s 28ms/step - loss: 0.0269 - val_loss: 0.0102\n",
      "Epoch 40/90\n",
      "96/96 [==============================] - 3s 28ms/step - loss: 0.0267 - val_loss: 0.0101\n",
      "Epoch 41/90\n",
      "96/96 [==============================] - 3s 28ms/step - loss: 0.0265 - val_loss: 0.0101\n",
      "Epoch 42/90\n",
      "96/96 [==============================] - 3s 29ms/step - loss: 0.0264 - val_loss: 0.0102\n",
      "Epoch 43/90\n",
      "96/96 [==============================] - 3s 30ms/step - loss: 0.0263 - val_loss: 0.0102\n",
      "Epoch 44/90\n",
      "96/96 [==============================] - 3s 28ms/step - loss: 0.0263 - val_loss: 0.0101\n",
      "Epoch 45/90\n",
      "96/96 [==============================] - 3s 29ms/step - loss: 0.0263 - val_loss: 0.0101\n",
      "Epoch 46/90\n",
      "96/96 [==============================] - 3s 28ms/step - loss: 0.0261 - val_loss: 0.0102\n",
      "Epoch 47/90\n",
      "96/96 [==============================] - 3s 28ms/step - loss: 0.0259 - val_loss: 0.0114\n",
      "Epoch 48/90\n",
      "96/96 [==============================] - 3s 30ms/step - loss: 0.0262 - val_loss: 0.0103\n",
      "Epoch 49/90\n",
      "96/96 [==============================] - 3s 29ms/step - loss: 0.0260 - val_loss: 0.0104\n",
      "Epoch 50/90\n",
      "96/96 [==============================] - 3s 29ms/step - loss: 0.0258 - val_loss: 0.0105\n",
      "Epoch 51/90\n",
      "96/96 [==============================] - 3s 29ms/step - loss: 0.0258 - val_loss: 0.0106\n",
      "Epoch 52/90\n",
      "96/96 [==============================] - 3s 28ms/step - loss: 0.0258 - val_loss: 0.0105\n",
      "Epoch 53/90\n",
      "96/96 [==============================] - 3s 29ms/step - loss: 0.0255 - val_loss: 0.0107\n",
      "Epoch 54/90\n",
      "96/96 [==============================] - 3s 30ms/step - loss: 0.0255 - val_loss: 0.0106\n",
      "Epoch 55/90\n",
      "96/96 [==============================] - 3s 28ms/step - loss: 0.0254 - val_loss: 0.0107\n",
      "Epoch 56/90\n",
      "96/96 [==============================] - 3s 29ms/step - loss: 0.0254 - val_loss: 0.0107\n",
      "Epoch 57/90\n",
      "96/96 [==============================] - 3s 28ms/step - loss: 0.0253 - val_loss: 0.0109\n",
      "Epoch 58/90\n",
      "96/96 [==============================] - 3s 28ms/step - loss: 0.0254 - val_loss: 0.0111\n",
      "Epoch 59/90\n",
      "96/96 [==============================] - 3s 29ms/step - loss: 0.0253 - val_loss: 0.0111\n",
      "Epoch 60/90\n",
      "96/96 [==============================] - 3s 30ms/step - loss: 0.0253 - val_loss: 0.0113\n",
      "Epoch 61/90\n",
      "96/96 [==============================] - 3s 28ms/step - loss: 0.0253 - val_loss: 0.0113\n",
      "Epoch 62/90\n",
      "96/96 [==============================] - 3s 28ms/step - loss: 0.0252 - val_loss: 0.0112\n",
      "Epoch 63/90\n",
      "96/96 [==============================] - 3s 28ms/step - loss: 0.0251 - val_loss: 0.0108\n",
      "Epoch 64/90\n",
      "96/96 [==============================] - 3s 29ms/step - loss: 0.0251 - val_loss: 0.0121\n",
      "Epoch 65/90\n",
      "96/96 [==============================] - 3s 30ms/step - loss: 0.0251 - val_loss: 0.0114\n",
      "Epoch 66/90\n",
      "96/96 [==============================] - 3s 29ms/step - loss: 0.0250 - val_loss: 0.0115\n",
      "Epoch 67/90\n",
      "96/96 [==============================] - 3s 28ms/step - loss: 0.0250 - val_loss: 0.0117\n",
      "Epoch 68/90\n",
      "96/96 [==============================] - 3s 28ms/step - loss: 0.0250 - val_loss: 0.0116\n",
      "Epoch 69/90\n",
      "96/96 [==============================] - 3s 28ms/step - loss: 0.0251 - val_loss: 0.0118\n",
      "Epoch 70/90\n",
      "96/96 [==============================] - 3s 28ms/step - loss: 0.0250 - val_loss: 0.0116\n",
      "Epoch 71/90\n",
      "96/96 [==============================] - 3s 30ms/step - loss: 0.0251 - val_loss: 0.0117\n",
      "Epoch 72/90\n",
      "96/96 [==============================] - 3s 29ms/step - loss: 0.0250 - val_loss: 0.0116\n",
      "Epoch 73/90\n",
      "96/96 [==============================] - 3s 28ms/step - loss: 0.0250 - val_loss: 0.0116\n",
      "Epoch 74/90\n",
      "96/96 [==============================] - 3s 29ms/step - loss: 0.0251 - val_loss: 0.0118\n",
      "Epoch 75/90\n",
      "96/96 [==============================] - 3s 28ms/step - loss: 0.0251 - val_loss: 0.0118\n",
      "Epoch 76/90\n",
      "96/96 [==============================] - 3s 29ms/step - loss: 0.0250 - val_loss: 0.0116\n",
      "Epoch 77/90\n",
      "96/96 [==============================] - 3s 30ms/step - loss: 0.0250 - val_loss: 0.0116\n",
      "Epoch 78/90\n",
      "96/96 [==============================] - 3s 28ms/step - loss: 0.0251 - val_loss: 0.0117\n",
      "Epoch 79/90\n",
      "96/96 [==============================] - 3s 29ms/step - loss: 0.0250 - val_loss: 0.0116\n",
      "Epoch 80/90\n",
      "96/96 [==============================] - 3s 29ms/step - loss: 0.0250 - val_loss: 0.0116\n",
      "Epoch 81/90\n",
      "96/96 [==============================] - 3s 28ms/step - loss: 0.0251 - val_loss: 0.0117\n",
      "Epoch 82/90\n",
      "96/96 [==============================] - 3s 29ms/step - loss: 0.0250 - val_loss: 0.0116\n",
      "Epoch 83/90\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "96/96 [==============================] - 3s 29ms/step - loss: 0.0251 - val_loss: 0.0118\n",
      "Epoch 84/90\n",
      "96/96 [==============================] - 3s 28ms/step - loss: 0.0250 - val_loss: 0.0116\n",
      "Epoch 85/90\n",
      "96/96 [==============================] - 3s 28ms/step - loss: 0.0250 - val_loss: 0.0116\n",
      "Epoch 86/90\n",
      "96/96 [==============================] - 3s 28ms/step - loss: 0.0250 - val_loss: 0.0116\n",
      "Epoch 87/90\n",
      "96/96 [==============================] - 3s 28ms/step - loss: 0.0251 - val_loss: 0.0118\n",
      "Epoch 88/90\n",
      "96/96 [==============================] - 3s 30ms/step - loss: 0.0250 - val_loss: 0.0116\n",
      "Epoch 89/90\n",
      "96/96 [==============================] - 3s 29ms/step - loss: 0.0251 - val_loss: 0.0118\n",
      "Epoch 90/90\n",
      "96/96 [==============================] - 3s 28ms/step - loss: 0.0250 - val_loss: 0.0116\n",
      "Execution time:  252.53930497169495\n",
      "DNN:\n",
      "Mean Absolute Error: 0.0263\n",
      "Root Mean Square Error: 0.0479\n",
      "Mean Square Error: 0.0023\n",
      "\n",
      "Train RMSE: 0.048\n",
      "Train MSE: 0.002\n",
      "Train MAE: 0.026\n",
      "###########################\n",
      "\n",
      "MODEL:  DNN\n",
      "sequence:  7d\n",
      "units:  12\n",
      "dropout1:  0.48476373451509647\n",
      "optimizer: adamax\n",
      "activationDense: tanh\n",
      "epochs: 52\n",
      "batchsize: 57\n",
      "validation_split: 0.2\n",
      "Model: \"sequential_245\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_735 (Dense)            (None, 1008, 12)          24        \n",
      "_________________________________________________________________\n",
      "dense_736 (Dense)            (None, 1008, 16)          208       \n",
      "_________________________________________________________________\n",
      "dropout_245 (Dropout)        (None, 1008, 16)          0         \n",
      "_________________________________________________________________\n",
      "dense_737 (Dense)            (None, 1008, 1)           17        \n",
      "=================================================================\n",
      "Total params: 249\n",
      "Trainable params: 249\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/52\n",
      "42/42 [==============================] - 1s 36ms/step - loss: 0.3376 - val_loss: 0.1624\n",
      "Epoch 2/52\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 0.1480 - val_loss: 0.0330\n",
      "Epoch 3/52\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 0.1211 - val_loss: 0.0200\n",
      "Epoch 4/52\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 0.1095 - val_loss: 0.0173\n",
      "Epoch 5/52\n",
      "42/42 [==============================] - 1s 33ms/step - loss: 0.1014 - val_loss: 0.0144\n",
      "Epoch 6/52\n",
      "42/42 [==============================] - 1s 34ms/step - loss: 0.0953 - val_loss: 0.0124\n",
      "Epoch 7/52\n",
      "42/42 [==============================] - 1s 33ms/step - loss: 0.0905 - val_loss: 0.0128\n",
      "Epoch 8/52\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 0.0860 - val_loss: 0.0137\n",
      "Epoch 9/52\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 0.0820 - val_loss: 0.0133\n",
      "Epoch 10/52\n",
      "42/42 [==============================] - 1s 32ms/step - loss: 0.0780 - val_loss: 0.0121\n",
      "Epoch 11/52\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 0.0740 - val_loss: 0.0116\n",
      "Epoch 12/52\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 0.0701 - val_loss: 0.0112\n",
      "Epoch 13/52\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 0.0665 - val_loss: 0.0109\n",
      "Epoch 14/52\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 0.0630 - val_loss: 0.0108\n",
      "Epoch 15/52\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 0.0596 - val_loss: 0.0108\n",
      "Epoch 16/52\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 0.0564 - val_loss: 0.0108\n",
      "Epoch 17/52\n",
      "42/42 [==============================] - 1s 34ms/step - loss: 0.0532 - val_loss: 0.0111\n",
      "Epoch 18/52\n",
      "42/42 [==============================] - 1s 33ms/step - loss: 0.0504 - val_loss: 0.0113\n",
      "Epoch 19/52\n",
      "42/42 [==============================] - 1s 32ms/step - loss: 0.0476 - val_loss: 0.0116\n",
      "Epoch 20/52\n",
      "42/42 [==============================] - 1s 32ms/step - loss: 0.0450 - val_loss: 0.0121\n",
      "Epoch 21/52\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 0.0425 - val_loss: 0.0125\n",
      "Epoch 22/52\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 0.0402 - val_loss: 0.0129\n",
      "Epoch 23/52\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 0.0381 - val_loss: 0.0131\n",
      "Epoch 24/52\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 0.0361 - val_loss: 0.0132\n",
      "Epoch 25/52\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 0.0343 - val_loss: 0.0129\n",
      "Epoch 26/52\n",
      "42/42 [==============================] - 1s 32ms/step - loss: 0.0327 - val_loss: 0.0128\n",
      "Epoch 27/52\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 0.0313 - val_loss: 0.0125\n",
      "Epoch 28/52\n",
      "42/42 [==============================] - 1s 32ms/step - loss: 0.0302 - val_loss: 0.0125\n",
      "Epoch 29/52\n",
      "42/42 [==============================] - 1s 34ms/step - loss: 0.0294 - val_loss: 0.0128\n",
      "Epoch 30/52\n",
      "42/42 [==============================] - 1s 33ms/step - loss: 0.0287 - val_loss: 0.0131\n",
      "Epoch 31/52\n",
      "42/42 [==============================] - 1s 33ms/step - loss: 0.0280 - val_loss: 0.0130\n",
      "Epoch 32/52\n",
      "42/42 [==============================] - 1s 32ms/step - loss: 0.0276 - val_loss: 0.0128\n",
      "Epoch 33/52\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 0.0271 - val_loss: 0.0130\n",
      "Epoch 34/52\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 0.0266 - val_loss: 0.0135\n",
      "Epoch 35/52\n",
      "42/42 [==============================] - 1s 32ms/step - loss: 0.0258 - val_loss: 0.0130\n",
      "Epoch 36/52\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 0.0258 - val_loss: 0.0133\n",
      "Epoch 37/52\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 0.0253 - val_loss: 0.0132\n",
      "Epoch 38/52\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 0.0250 - val_loss: 0.0132\n",
      "Epoch 39/52\n",
      "42/42 [==============================] - 1s 32ms/step - loss: 0.0249 - val_loss: 0.0131\n",
      "Epoch 40/52\n",
      "42/42 [==============================] - 1s 33ms/step - loss: 0.0247 - val_loss: 0.0125\n",
      "Epoch 41/52\n",
      "42/42 [==============================] - 1s 34ms/step - loss: 0.0246 - val_loss: 0.0124\n",
      "Epoch 42/52\n",
      "42/42 [==============================] - 1s 32ms/step - loss: 0.0246 - val_loss: 0.0123\n",
      "Epoch 43/52\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 0.0246 - val_loss: 0.0122\n",
      "Epoch 44/52\n",
      "42/42 [==============================] - 1s 32ms/step - loss: 0.0246 - val_loss: 0.0125\n",
      "Epoch 45/52\n",
      "42/42 [==============================] - 1s 32ms/step - loss: 0.0245 - val_loss: 0.0123\n",
      "Epoch 46/52\n",
      "42/42 [==============================] - 1s 32ms/step - loss: 0.0245 - val_loss: 0.0122\n",
      "Epoch 47/52\n",
      "42/42 [==============================] - 1s 33ms/step - loss: 0.0245 - val_loss: 0.0121\n",
      "Epoch 48/52\n",
      "42/42 [==============================] - 1s 32ms/step - loss: 0.0245 - val_loss: 0.0119\n",
      "Epoch 49/52\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 0.0245 - val_loss: 0.0118\n",
      "Epoch 50/52\n",
      "42/42 [==============================] - 1s 32ms/step - loss: 0.0245 - val_loss: 0.0117\n",
      "Epoch 51/52\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 0.0245 - val_loss: 0.0122\n",
      "Epoch 52/52\n",
      "42/42 [==============================] - 1s 34ms/step - loss: 0.0245 - val_loss: 0.0121\n",
      "Execution time:  72.59026646614075\n",
      "DNN:\n",
      "Mean Absolute Error: 0.0259\n",
      "Root Mean Square Error: 0.0470\n",
      "Mean Square Error: 0.0022\n",
      "\n",
      "Train RMSE: 0.047\n",
      "Train MSE: 0.002\n",
      "Train MAE: 0.026\n",
      "###########################\n",
      "\n",
      "MODEL:  DNN\n",
      "sequence:  7d\n",
      "units:  87\n",
      "dropout1:  0.40519643149940265\n",
      "optimizer: adamax\n",
      "activationDense: sigmoid\n",
      "epochs: 80\n",
      "batchsize: 31\n",
      "validation_split: 0.1\n",
      "Model: \"sequential_246\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_738 (Dense)            (None, 1008, 87)          174       \n",
      "_________________________________________________________________\n",
      "dense_739 (Dense)            (None, 1008, 16)          1408      \n",
      "_________________________________________________________________\n",
      "dropout_246 (Dropout)        (None, 1008, 16)          0         \n",
      "_________________________________________________________________\n",
      "dense_740 (Dense)            (None, 1008, 1)           17        \n",
      "=================================================================\n",
      "Total params: 1,599\n",
      "Trainable params: 1,599\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/80\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "87/87 [==============================] - 3s 37ms/step - loss: 0.0562 - val_loss: 0.0326\n",
      "Epoch 2/80\n",
      "87/87 [==============================] - 3s 35ms/step - loss: 0.0391 - val_loss: 0.0283\n",
      "Epoch 3/80\n",
      "87/87 [==============================] - 3s 35ms/step - loss: 0.0370 - val_loss: 0.0262\n",
      "Epoch 4/80\n",
      "87/87 [==============================] - 3s 35ms/step - loss: 0.0358 - val_loss: 0.0248\n",
      "Epoch 5/80\n",
      "87/87 [==============================] - 3s 37ms/step - loss: 0.0348 - val_loss: 0.0238\n",
      "Epoch 6/80\n",
      "87/87 [==============================] - 3s 35ms/step - loss: 0.0340 - val_loss: 0.0234\n",
      "Epoch 7/80\n",
      "87/87 [==============================] - 3s 35ms/step - loss: 0.0332 - val_loss: 0.0227\n",
      "Epoch 8/80\n",
      "87/87 [==============================] - 3s 35ms/step - loss: 0.0326 - val_loss: 0.0220\n",
      "Epoch 9/80\n",
      "87/87 [==============================] - 3s 35ms/step - loss: 0.0320 - val_loss: 0.0214\n",
      "Epoch 10/80\n",
      "87/87 [==============================] - 3s 37ms/step - loss: 0.0314 - val_loss: 0.0208\n",
      "Epoch 11/80\n",
      "87/87 [==============================] - 3s 36ms/step - loss: 0.0309 - val_loss: 0.0203\n",
      "Epoch 12/80\n",
      "87/87 [==============================] - 3s 35ms/step - loss: 0.0303 - val_loss: 0.0201\n",
      "Epoch 13/80\n",
      "87/87 [==============================] - 3s 35ms/step - loss: 0.0299 - val_loss: 0.0199\n",
      "Epoch 14/80\n",
      "87/87 [==============================] - 3s 35ms/step - loss: 0.0294 - val_loss: 0.0196\n",
      "Epoch 15/80\n",
      "87/87 [==============================] - 3s 36ms/step - loss: 0.0289 - val_loss: 0.0190\n",
      "Epoch 16/80\n",
      "87/87 [==============================] - 3s 36ms/step - loss: 0.0285 - val_loss: 0.0188\n",
      "Epoch 17/80\n",
      "87/87 [==============================] - 3s 35ms/step - loss: 0.0281 - val_loss: 0.0186\n",
      "Epoch 18/80\n",
      "87/87 [==============================] - 3s 35ms/step - loss: 0.0277 - val_loss: 0.0183\n",
      "Epoch 19/80\n",
      "87/87 [==============================] - 3s 35ms/step - loss: 0.0273 - val_loss: 0.0183\n",
      "Epoch 20/80\n",
      "87/87 [==============================] - 3s 36ms/step - loss: 0.0270 - val_loss: 0.0182\n",
      "Epoch 21/80\n",
      "87/87 [==============================] - 3s 36ms/step - loss: 0.0266 - val_loss: 0.0177\n",
      "Epoch 22/80\n",
      "87/87 [==============================] - 3s 35ms/step - loss: 0.0263 - val_loss: 0.0175\n",
      "Epoch 23/80\n",
      "87/87 [==============================] - 3s 35ms/step - loss: 0.0260 - val_loss: 0.0172\n",
      "Epoch 24/80\n",
      "87/87 [==============================] - 3s 35ms/step - loss: 0.0257 - val_loss: 0.0170\n",
      "Epoch 25/80\n",
      "87/87 [==============================] - 3s 36ms/step - loss: 0.0255 - val_loss: 0.0169\n",
      "Epoch 26/80\n",
      "87/87 [==============================] - 3s 36ms/step - loss: 0.0252 - val_loss: 0.0170\n",
      "Epoch 27/80\n",
      "87/87 [==============================] - 3s 35ms/step - loss: 0.0250 - val_loss: 0.0169\n",
      "Epoch 28/80\n",
      "87/87 [==============================] - 3s 35ms/step - loss: 0.0248 - val_loss: 0.0169\n",
      "Epoch 29/80\n",
      "87/87 [==============================] - 3s 35ms/step - loss: 0.0246 - val_loss: 0.0169\n",
      "Epoch 30/80\n",
      "87/87 [==============================] - 3s 35ms/step - loss: 0.0245 - val_loss: 0.0169\n",
      "Epoch 31/80\n",
      "87/87 [==============================] - 3s 37ms/step - loss: 0.0243 - val_loss: 0.0170\n",
      "Epoch 32/80\n",
      "87/87 [==============================] - 3s 35ms/step - loss: 0.0242 - val_loss: 0.0169\n",
      "Epoch 33/80\n",
      "87/87 [==============================] - 3s 35ms/step - loss: 0.0240 - val_loss: 0.0167\n",
      "Epoch 34/80\n",
      "87/87 [==============================] - 3s 35ms/step - loss: 0.0241 - val_loss: 0.0165\n",
      "Epoch 35/80\n",
      "87/87 [==============================] - 3s 35ms/step - loss: 0.0238 - val_loss: 0.0164\n",
      "Epoch 36/80\n",
      "87/87 [==============================] - 3s 37ms/step - loss: 0.0237 - val_loss: 0.0163\n",
      "Epoch 37/80\n",
      "87/87 [==============================] - 3s 35ms/step - loss: 0.0237 - val_loss: 0.0163\n",
      "Epoch 38/80\n",
      "87/87 [==============================] - 3s 35ms/step - loss: 0.0236 - val_loss: 0.0162\n",
      "Epoch 39/80\n",
      "87/87 [==============================] - 3s 35ms/step - loss: 0.0235 - val_loss: 0.0162\n",
      "Epoch 40/80\n",
      "87/87 [==============================] - 3s 35ms/step - loss: 0.0235 - val_loss: 0.0162\n",
      "Epoch 41/80\n",
      "87/87 [==============================] - 3s 38ms/step - loss: 0.0234 - val_loss: 0.0162\n",
      "Epoch 42/80\n",
      "87/87 [==============================] - 3s 35ms/step - loss: 0.0233 - val_loss: 0.0161\n",
      "Epoch 43/80\n",
      "87/87 [==============================] - 3s 35ms/step - loss: 0.0233 - val_loss: 0.0162\n",
      "Epoch 44/80\n",
      "87/87 [==============================] - 3s 35ms/step - loss: 0.0233 - val_loss: 0.0166\n",
      "Epoch 45/80\n",
      "87/87 [==============================] - 3s 35ms/step - loss: 0.0231 - val_loss: 0.0158\n",
      "Epoch 46/80\n",
      "87/87 [==============================] - 3s 37ms/step - loss: 0.0231 - val_loss: 0.0158\n",
      "Epoch 47/80\n",
      "87/87 [==============================] - 3s 35ms/step - loss: 0.0231 - val_loss: 0.0157\n",
      "Epoch 48/80\n",
      "87/87 [==============================] - 3s 35ms/step - loss: 0.0231 - val_loss: 0.0156\n",
      "Epoch 49/80\n",
      "87/87 [==============================] - 3s 35ms/step - loss: 0.0230 - val_loss: 0.0155\n",
      "Epoch 50/80\n",
      "87/87 [==============================] - 3s 35ms/step - loss: 0.0230 - val_loss: 0.0154\n",
      "Epoch 51/80\n",
      "87/87 [==============================] - 3s 37ms/step - loss: 0.0230 - val_loss: 0.0157\n",
      "Epoch 52/80\n",
      "87/87 [==============================] - 3s 36ms/step - loss: 0.0229 - val_loss: 0.0156\n",
      "Epoch 53/80\n",
      "87/87 [==============================] - 3s 35ms/step - loss: 0.0228 - val_loss: 0.0150\n",
      "Epoch 54/80\n",
      "87/87 [==============================] - 3s 35ms/step - loss: 0.0228 - val_loss: 0.0148\n",
      "Epoch 55/80\n",
      "87/87 [==============================] - 3s 35ms/step - loss: 0.0228 - val_loss: 0.0146\n",
      "Epoch 56/80\n",
      "87/87 [==============================] - 3s 36ms/step - loss: 0.0228 - val_loss: 0.0144\n",
      "Epoch 57/80\n",
      "87/87 [==============================] - 3s 36ms/step - loss: 0.0228 - val_loss: 0.0143\n",
      "Epoch 58/80\n",
      "87/87 [==============================] - 3s 35ms/step - loss: 0.0228 - val_loss: 0.0142\n",
      "Epoch 59/80\n",
      "87/87 [==============================] - 3s 35ms/step - loss: 0.0228 - val_loss: 0.0142\n",
      "Epoch 60/80\n",
      "87/87 [==============================] - 3s 35ms/step - loss: 0.0228 - val_loss: 0.0141\n",
      "Epoch 61/80\n",
      "87/87 [==============================] - 3s 36ms/step - loss: 0.0228 - val_loss: 0.0140\n",
      "Epoch 62/80\n",
      "87/87 [==============================] - 3s 36ms/step - loss: 0.0228 - val_loss: 0.0139\n",
      "Epoch 63/80\n",
      "87/87 [==============================] - 3s 35ms/step - loss: 0.0227 - val_loss: 0.0138\n",
      "Epoch 64/80\n",
      "87/87 [==============================] - 3s 35ms/step - loss: 0.0227 - val_loss: 0.0136\n",
      "Epoch 65/80\n",
      "87/87 [==============================] - 3s 35ms/step - loss: 0.0227 - val_loss: 0.0136\n",
      "Epoch 66/80\n",
      "87/87 [==============================] - 3s 36ms/step - loss: 0.0227 - val_loss: 0.0135\n",
      "Epoch 67/80\n",
      "87/87 [==============================] - 3s 37ms/step - loss: 0.0227 - val_loss: 0.0133\n",
      "Epoch 68/80\n",
      "87/87 [==============================] - 3s 35ms/step - loss: 0.0227 - val_loss: 0.0132\n",
      "Epoch 69/80\n",
      "87/87 [==============================] - 3s 35ms/step - loss: 0.0227 - val_loss: 0.0131\n",
      "Epoch 70/80\n",
      "87/87 [==============================] - 3s 35ms/step - loss: 0.0227 - val_loss: 0.0131\n",
      "Epoch 71/80\n",
      "87/87 [==============================] - 3s 36ms/step - loss: 0.0227 - val_loss: 0.0130\n",
      "Epoch 72/80\n",
      "87/87 [==============================] - 3s 36ms/step - loss: 0.0226 - val_loss: 0.0130\n",
      "Epoch 73/80\n",
      "87/87 [==============================] - 3s 35ms/step - loss: 0.0226 - val_loss: 0.0125\n",
      "Epoch 74/80\n",
      "87/87 [==============================] - 3s 35ms/step - loss: 0.0226 - val_loss: 0.0126\n",
      "Epoch 75/80\n",
      "87/87 [==============================] - 3s 35ms/step - loss: 0.0226 - val_loss: 0.0125\n",
      "Epoch 76/80\n",
      "87/87 [==============================] - 3s 36ms/step - loss: 0.0226 - val_loss: 0.0126\n",
      "Epoch 77/80\n",
      "87/87 [==============================] - 3s 37ms/step - loss: 0.0226 - val_loss: 0.0122\n",
      "Epoch 78/80\n",
      "87/87 [==============================] - 3s 35ms/step - loss: 0.0226 - val_loss: 0.0128\n",
      "Epoch 79/80\n",
      "87/87 [==============================] - 3s 35ms/step - loss: 0.0226 - val_loss: 0.0123\n",
      "Epoch 80/80\n",
      "87/87 [==============================] - 3s 35ms/step - loss: 0.0226 - val_loss: 0.0121\n",
      "Execution time:  251.10111236572266\n",
      "DNN:\n",
      "Mean Absolute Error: 0.0261\n",
      "Root Mean Square Error: 0.0474\n",
      "Mean Square Error: 0.0022\n",
      "\n",
      "Train RMSE: 0.047\n",
      "Train MSE: 0.002\n",
      "Train MAE: 0.026\n",
      "###########################\n",
      "\n",
      "MODEL:  DNN\n",
      "sequence:  7d\n",
      "units:  80\n",
      "dropout1:  0.11814836227952394\n",
      "optimizer: adamax\n",
      "activationDense: sigmoid\n",
      "epochs: 90\n",
      "batchsize: 25\n",
      "validation_split: 0.1\n",
      "Model: \"sequential_247\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_741 (Dense)            (None, 1008, 80)          160       \n",
      "_________________________________________________________________\n",
      "dense_742 (Dense)            (None, 1008, 16)          1296      \n",
      "_________________________________________________________________\n",
      "dropout_247 (Dropout)        (None, 1008, 16)          0         \n",
      "_________________________________________________________________\n",
      "dense_743 (Dense)            (None, 1008, 1)           17        \n",
      "=================================================================\n",
      "Total params: 1,473\n",
      "Trainable params: 1,473\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/90\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "108/108 [==============================] - 4s 34ms/step - loss: 0.0419 - val_loss: 0.0233\n",
      "Epoch 2/90\n",
      "108/108 [==============================] - 3s 27ms/step - loss: 0.0287 - val_loss: 0.0219\n",
      "Epoch 3/90\n",
      "108/108 [==============================] - 3s 27ms/step - loss: 0.0286 - val_loss: 0.0214\n",
      "Epoch 4/90\n",
      "108/108 [==============================] - 3s 27ms/step - loss: 0.0284 - val_loss: 0.0212\n",
      "Epoch 5/90\n",
      "108/108 [==============================] - 3s 27ms/step - loss: 0.0282 - val_loss: 0.0207\n",
      "Epoch 6/90\n",
      "108/108 [==============================] - 3s 29ms/step - loss: 0.0280 - val_loss: 0.0205\n",
      "Epoch 7/90\n",
      "108/108 [==============================] - 3s 28ms/step - loss: 0.0279 - val_loss: 0.0203\n",
      "Epoch 8/90\n",
      "108/108 [==============================] - 3s 27ms/step - loss: 0.0277 - val_loss: 0.0201\n",
      "Epoch 9/90\n",
      "108/108 [==============================] - 3s 27ms/step - loss: 0.0276 - val_loss: 0.0199\n",
      "Epoch 10/90\n",
      "108/108 [==============================] - 3s 27ms/step - loss: 0.0275 - val_loss: 0.0203\n",
      "Epoch 11/90\n",
      "108/108 [==============================] - 3s 28ms/step - loss: 0.0274 - val_loss: 0.0199\n",
      "Epoch 12/90\n",
      "108/108 [==============================] - 3s 28ms/step - loss: 0.0272 - val_loss: 0.0191\n",
      "Epoch 13/90\n",
      "108/108 [==============================] - 3s 27ms/step - loss: 0.0270 - val_loss: 0.0190\n",
      "Epoch 14/90\n",
      "108/108 [==============================] - 3s 28ms/step - loss: 0.0269 - val_loss: 0.0189\n",
      "Epoch 15/90\n",
      "108/108 [==============================] - 3s 27ms/step - loss: 0.0268 - val_loss: 0.0189\n",
      "Epoch 16/90\n",
      "108/108 [==============================] - 3s 27ms/step - loss: 0.0267 - val_loss: 0.0184\n",
      "Epoch 17/90\n",
      "108/108 [==============================] - 3s 29ms/step - loss: 0.0266 - val_loss: 0.0182\n",
      "Epoch 18/90\n",
      "108/108 [==============================] - 3s 27ms/step - loss: 0.0265 - val_loss: 0.0184\n",
      "Epoch 19/90\n",
      "108/108 [==============================] - 3s 27ms/step - loss: 0.0263 - val_loss: 0.0184\n",
      "Epoch 20/90\n",
      "108/108 [==============================] - 3s 27ms/step - loss: 0.0263 - val_loss: 0.0177\n",
      "Epoch 21/90\n",
      "108/108 [==============================] - 3s 27ms/step - loss: 0.0262 - val_loss: 0.0178\n",
      "Epoch 22/90\n",
      "108/108 [==============================] - 3s 29ms/step - loss: 0.0261 - val_loss: 0.0178\n",
      "Epoch 23/90\n",
      "108/108 [==============================] - 3s 28ms/step - loss: 0.0259 - val_loss: 0.0178\n",
      "Epoch 24/90\n",
      "108/108 [==============================] - 3s 28ms/step - loss: 0.0258 - val_loss: 0.0178\n",
      "Epoch 25/90\n",
      "108/108 [==============================] - 3s 28ms/step - loss: 0.0257 - val_loss: 0.0171\n",
      "Epoch 26/90\n",
      "108/108 [==============================] - 3s 28ms/step - loss: 0.0257 - val_loss: 0.0172\n",
      "Epoch 27/90\n",
      "108/108 [==============================] - 3s 28ms/step - loss: 0.0255 - val_loss: 0.0172\n",
      "Epoch 28/90\n",
      "108/108 [==============================] - 3s 28ms/step - loss: 0.0255 - val_loss: 0.0169\n",
      "Epoch 29/90\n",
      "108/108 [==============================] - 3s 27ms/step - loss: 0.0254 - val_loss: 0.0163\n",
      "Epoch 30/90\n",
      "108/108 [==============================] - 3s 27ms/step - loss: 0.0253 - val_loss: 0.0163\n",
      "Epoch 31/90\n",
      "108/108 [==============================] - 3s 27ms/step - loss: 0.0252 - val_loss: 0.0164\n",
      "Epoch 32/90\n",
      "108/108 [==============================] - 3s 28ms/step - loss: 0.0251 - val_loss: 0.0164\n",
      "Epoch 33/90\n",
      "108/108 [==============================] - 3s 29ms/step - loss: 0.0249 - val_loss: 0.0159\n",
      "Epoch 34/90\n",
      "108/108 [==============================] - 3s 27ms/step - loss: 0.0251 - val_loss: 0.0150\n",
      "Epoch 35/90\n",
      "108/108 [==============================] - 3s 27ms/step - loss: 0.0250 - val_loss: 0.0161\n",
      "Epoch 36/90\n",
      "108/108 [==============================] - 3s 27ms/step - loss: 0.0248 - val_loss: 0.0160\n",
      "Epoch 37/90\n",
      "108/108 [==============================] - 3s 27ms/step - loss: 0.0248 - val_loss: 0.0159\n",
      "Epoch 38/90\n",
      "108/108 [==============================] - 3s 29ms/step - loss: 0.0247 - val_loss: 0.0159\n",
      "Epoch 39/90\n",
      "108/108 [==============================] - 3s 27ms/step - loss: 0.0246 - val_loss: 0.0160\n",
      "Epoch 40/90\n",
      "108/108 [==============================] - 3s 27ms/step - loss: 0.0246 - val_loss: 0.0158\n",
      "Epoch 41/90\n",
      "108/108 [==============================] - 3s 28ms/step - loss: 0.0245 - val_loss: 0.0159\n",
      "Epoch 42/90\n",
      "108/108 [==============================] - 3s 27ms/step - loss: 0.0244 - val_loss: 0.0156\n",
      "Epoch 43/90\n",
      "108/108 [==============================] - 3s 28ms/step - loss: 0.0246 - val_loss: 0.0161\n",
      "Epoch 44/90\n",
      "108/108 [==============================] - 3s 28ms/step - loss: 0.0244 - val_loss: 0.0156\n",
      "Epoch 45/90\n",
      "108/108 [==============================] - 3s 27ms/step - loss: 0.0243 - val_loss: 0.0159\n",
      "Epoch 46/90\n",
      "108/108 [==============================] - 3s 27ms/step - loss: 0.0243 - val_loss: 0.0159\n",
      "Epoch 47/90\n",
      "108/108 [==============================] - 3s 27ms/step - loss: 0.0242 - val_loss: 0.0159\n",
      "Epoch 48/90\n",
      "108/108 [==============================] - 3s 28ms/step - loss: 0.0241 - val_loss: 0.0152\n",
      "Epoch 49/90\n",
      "108/108 [==============================] - 3s 28ms/step - loss: 0.0241 - val_loss: 0.0144\n",
      "Epoch 50/90\n",
      "108/108 [==============================] - 3s 27ms/step - loss: 0.0242 - val_loss: 0.0156\n",
      "Epoch 51/90\n",
      "108/108 [==============================] - 3s 27ms/step - loss: 0.0241 - val_loss: 0.0154\n",
      "Epoch 52/90\n",
      "108/108 [==============================] - 3s 28ms/step - loss: 0.0240 - val_loss: 0.0155\n",
      "Epoch 53/90\n",
      "108/108 [==============================] - 3s 27ms/step - loss: 0.0240 - val_loss: 0.0155\n",
      "Epoch 54/90\n",
      "108/108 [==============================] - 3s 29ms/step - loss: 0.0239 - val_loss: 0.0151\n",
      "Epoch 55/90\n",
      "108/108 [==============================] - 3s 28ms/step - loss: 0.0239 - val_loss: 0.0152\n",
      "Epoch 56/90\n",
      "108/108 [==============================] - 3s 27ms/step - loss: 0.0239 - val_loss: 0.0151\n",
      "Epoch 57/90\n",
      "108/108 [==============================] - 3s 27ms/step - loss: 0.0238 - val_loss: 0.0150\n",
      "Epoch 58/90\n",
      "108/108 [==============================] - 3s 27ms/step - loss: 0.0238 - val_loss: 0.0150\n",
      "Epoch 59/90\n",
      "108/108 [==============================] - 3s 29ms/step - loss: 0.0238 - val_loss: 0.0150\n",
      "Epoch 60/90\n",
      "108/108 [==============================] - 3s 28ms/step - loss: 0.0237 - val_loss: 0.0147\n",
      "Epoch 61/90\n",
      "108/108 [==============================] - 3s 27ms/step - loss: 0.0237 - val_loss: 0.0146\n",
      "Epoch 62/90\n",
      "108/108 [==============================] - 3s 27ms/step - loss: 0.0237 - val_loss: 0.0146\n",
      "Epoch 63/90\n",
      "108/108 [==============================] - 3s 27ms/step - loss: 0.0237 - val_loss: 0.0146\n",
      "Epoch 64/90\n",
      "108/108 [==============================] - 3s 28ms/step - loss: 0.0236 - val_loss: 0.0146\n",
      "Epoch 65/90\n",
      "108/108 [==============================] - 3s 29ms/step - loss: 0.0236 - val_loss: 0.0146\n",
      "Epoch 66/90\n",
      "108/108 [==============================] - 3s 28ms/step - loss: 0.0236 - val_loss: 0.0145\n",
      "Epoch 67/90\n",
      "108/108 [==============================] - 3s 27ms/step - loss: 0.0235 - val_loss: 0.0147\n",
      "Epoch 68/90\n",
      "108/108 [==============================] - 3s 27ms/step - loss: 0.0236 - val_loss: 0.0147\n",
      "Epoch 69/90\n",
      "108/108 [==============================] - 3s 28ms/step - loss: 0.0235 - val_loss: 0.0146\n",
      "Epoch 70/90\n",
      "108/108 [==============================] - 3s 28ms/step - loss: 0.0235 - val_loss: 0.0136\n",
      "Epoch 71/90\n",
      "108/108 [==============================] - 3s 27ms/step - loss: 0.0236 - val_loss: 0.0156\n",
      "Epoch 72/90\n",
      "108/108 [==============================] - 3s 27ms/step - loss: 0.0234 - val_loss: 0.0148\n",
      "Epoch 73/90\n",
      "108/108 [==============================] - 3s 27ms/step - loss: 0.0234 - val_loss: 0.0146\n",
      "Epoch 74/90\n",
      "108/108 [==============================] - 3s 27ms/step - loss: 0.0234 - val_loss: 0.0146\n",
      "Epoch 75/90\n",
      "108/108 [==============================] - 3s 29ms/step - loss: 0.0234 - val_loss: 0.0146\n",
      "Epoch 76/90\n",
      "108/108 [==============================] - 3s 28ms/step - loss: 0.0234 - val_loss: 0.0146\n",
      "Epoch 77/90\n",
      "108/108 [==============================] - 3s 27ms/step - loss: 0.0234 - val_loss: 0.0146\n",
      "Epoch 78/90\n",
      "108/108 [==============================] - 3s 27ms/step - loss: 0.0233 - val_loss: 0.0146\n",
      "Epoch 79/90\n",
      "108/108 [==============================] - 3s 27ms/step - loss: 0.0233 - val_loss: 0.0146\n",
      "Epoch 80/90\n",
      "108/108 [==============================] - 3s 28ms/step - loss: 0.0233 - val_loss: 0.0147\n",
      "Epoch 81/90\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "108/108 [==============================] - 3s 28ms/step - loss: 0.0233 - val_loss: 0.0146\n",
      "Epoch 82/90\n",
      "108/108 [==============================] - 3s 27ms/step - loss: 0.0233 - val_loss: 0.0147\n",
      "Epoch 83/90\n",
      "108/108 [==============================] - 3s 27ms/step - loss: 0.0233 - val_loss: 0.0147\n",
      "Epoch 84/90\n",
      "108/108 [==============================] - 3s 27ms/step - loss: 0.0233 - val_loss: 0.0147\n",
      "Epoch 85/90\n",
      "108/108 [==============================] - 3s 28ms/step - loss: 0.0233 - val_loss: 0.0148\n",
      "Epoch 86/90\n",
      "108/108 [==============================] - 3s 29ms/step - loss: 0.0233 - val_loss: 0.0148\n",
      "Epoch 87/90\n",
      "108/108 [==============================] - 3s 27ms/step - loss: 0.0232 - val_loss: 0.0148\n",
      "Epoch 88/90\n",
      "108/108 [==============================] - 3s 27ms/step - loss: 0.0232 - val_loss: 0.0139\n",
      "Epoch 89/90\n",
      "108/108 [==============================] - 3s 27ms/step - loss: 0.0233 - val_loss: 0.0149\n",
      "Epoch 90/90\n",
      "108/108 [==============================] - 3s 27ms/step - loss: 0.0232 - val_loss: 0.0150\n",
      "Execution time:  273.47749066352844\n",
      "DNN:\n",
      "Mean Absolute Error: 0.0260\n",
      "Root Mean Square Error: 0.0466\n",
      "Mean Square Error: 0.0022\n",
      "\n",
      "Train RMSE: 0.047\n",
      "Train MSE: 0.002\n",
      "Train MAE: 0.026\n",
      "###########################\n",
      "\n",
      "MODEL:  DNN\n",
      "sequence:  7d\n",
      "units:  12\n",
      "dropout1:  0.48476373451509647\n",
      "optimizer: adamax\n",
      "activationDense: sigmoid\n",
      "epochs: 52\n",
      "batchsize: 57\n",
      "validation_split: 0.1\n",
      "Model: \"sequential_248\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_744 (Dense)            (None, 1008, 12)          24        \n",
      "_________________________________________________________________\n",
      "dense_745 (Dense)            (None, 1008, 16)          208       \n",
      "_________________________________________________________________\n",
      "dropout_248 (Dropout)        (None, 1008, 16)          0         \n",
      "_________________________________________________________________\n",
      "dense_746 (Dense)            (None, 1008, 1)           17        \n",
      "=================================================================\n",
      "Total params: 249\n",
      "Trainable params: 249\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/52\n",
      "48/48 [==============================] - 2s 34ms/step - loss: 0.0531 - val_loss: 0.0413\n",
      "Epoch 2/52\n",
      "48/48 [==============================] - 1s 30ms/step - loss: 0.0427 - val_loss: 0.0397\n",
      "Epoch 3/52\n",
      "48/48 [==============================] - 1s 30ms/step - loss: 0.0407 - val_loss: 0.0371\n",
      "Epoch 4/52\n",
      "48/48 [==============================] - 1s 30ms/step - loss: 0.0391 - val_loss: 0.0356\n",
      "Epoch 5/52\n",
      "48/48 [==============================] - 1s 30ms/step - loss: 0.0380 - val_loss: 0.0348\n",
      "Epoch 6/52\n",
      "48/48 [==============================] - 1s 30ms/step - loss: 0.0370 - val_loss: 0.0341\n",
      "Epoch 7/52\n",
      "48/48 [==============================] - 1s 30ms/step - loss: 0.0362 - val_loss: 0.0335\n",
      "Epoch 8/52\n",
      "48/48 [==============================] - 1s 30ms/step - loss: 0.0356 - val_loss: 0.0330\n",
      "Epoch 9/52\n",
      "48/48 [==============================] - 1s 30ms/step - loss: 0.0350 - val_loss: 0.0324\n",
      "Epoch 10/52\n",
      "48/48 [==============================] - 2s 32ms/step - loss: 0.0345 - val_loss: 0.0320\n",
      "Epoch 11/52\n",
      "48/48 [==============================] - 2s 32ms/step - loss: 0.0340 - val_loss: 0.0316\n",
      "Epoch 12/52\n",
      "48/48 [==============================] - 1s 31ms/step - loss: 0.0336 - val_loss: 0.0312\n",
      "Epoch 13/52\n",
      "48/48 [==============================] - 1s 30ms/step - loss: 0.0330 - val_loss: 0.0297\n",
      "Epoch 14/52\n",
      "48/48 [==============================] - 1s 31ms/step - loss: 0.0324 - val_loss: 0.0295\n",
      "Epoch 15/52\n",
      "48/48 [==============================] - 1s 30ms/step - loss: 0.0319 - val_loss: 0.0289\n",
      "Epoch 16/52\n",
      "48/48 [==============================] - 1s 30ms/step - loss: 0.0315 - val_loss: 0.0284\n",
      "Epoch 17/52\n",
      "48/48 [==============================] - 1s 30ms/step - loss: 0.0312 - val_loss: 0.0279\n",
      "Epoch 18/52\n",
      "48/48 [==============================] - 1s 30ms/step - loss: 0.0308 - val_loss: 0.0275\n",
      "Epoch 19/52\n",
      "48/48 [==============================] - 1s 31ms/step - loss: 0.0305 - val_loss: 0.0272\n",
      "Epoch 20/52\n",
      "48/48 [==============================] - 1s 30ms/step - loss: 0.0302 - val_loss: 0.0270\n",
      "Epoch 21/52\n",
      "48/48 [==============================] - 2s 33ms/step - loss: 0.0300 - val_loss: 0.0267\n",
      "Epoch 22/52\n",
      "48/48 [==============================] - 1s 31ms/step - loss: 0.0297 - val_loss: 0.0266\n",
      "Epoch 23/52\n",
      "48/48 [==============================] - 1s 30ms/step - loss: 0.0294 - val_loss: 0.0262\n",
      "Epoch 24/52\n",
      "48/48 [==============================] - 1s 30ms/step - loss: 0.0291 - val_loss: 0.0259\n",
      "Epoch 25/52\n",
      "48/48 [==============================] - 1s 30ms/step - loss: 0.0288 - val_loss: 0.0256\n",
      "Epoch 26/52\n",
      "48/48 [==============================] - 1s 30ms/step - loss: 0.0286 - val_loss: 0.0254\n",
      "Epoch 27/52\n",
      "48/48 [==============================] - 1s 30ms/step - loss: 0.0284 - val_loss: 0.0251\n",
      "Epoch 28/52\n",
      "48/48 [==============================] - 2s 32ms/step - loss: 0.0282 - val_loss: 0.0248\n",
      "Epoch 29/52\n",
      "48/48 [==============================] - 1s 30ms/step - loss: 0.0279 - val_loss: 0.0245\n",
      "Epoch 30/52\n",
      "48/48 [==============================] - 1s 30ms/step - loss: 0.0277 - val_loss: 0.0242\n",
      "Epoch 31/52\n",
      "48/48 [==============================] - 1s 31ms/step - loss: 0.0275 - val_loss: 0.0239\n",
      "Epoch 32/52\n",
      "48/48 [==============================] - 2s 32ms/step - loss: 0.0273 - val_loss: 0.0236\n",
      "Epoch 33/52\n",
      "48/48 [==============================] - 1s 31ms/step - loss: 0.0271 - val_loss: 0.0233\n",
      "Epoch 34/52\n",
      "48/48 [==============================] - 1s 30ms/step - loss: 0.0268 - val_loss: 0.0230\n",
      "Epoch 35/52\n",
      "48/48 [==============================] - 1s 31ms/step - loss: 0.0267 - val_loss: 0.0226\n",
      "Epoch 36/52\n",
      "48/48 [==============================] - 2s 33ms/step - loss: 0.0265 - val_loss: 0.0224\n",
      "Epoch 37/52\n",
      "48/48 [==============================] - 1s 31ms/step - loss: 0.0263 - val_loss: 0.0220\n",
      "Epoch 38/52\n",
      "48/48 [==============================] - 1s 30ms/step - loss: 0.0261 - val_loss: 0.0218\n",
      "Epoch 39/52\n",
      "48/48 [==============================] - 1s 30ms/step - loss: 0.0260 - val_loss: 0.0215\n",
      "Epoch 40/52\n",
      "48/48 [==============================] - 1s 30ms/step - loss: 0.0258 - val_loss: 0.0212\n",
      "Epoch 41/52\n",
      "48/48 [==============================] - 1s 31ms/step - loss: 0.0257 - val_loss: 0.0210\n",
      "Epoch 42/52\n",
      "48/48 [==============================] - 2s 32ms/step - loss: 0.0255 - val_loss: 0.0208\n",
      "Epoch 43/52\n",
      "48/48 [==============================] - 2s 32ms/step - loss: 0.0254 - val_loss: 0.0206\n",
      "Epoch 44/52\n",
      "48/48 [==============================] - 1s 30ms/step - loss: 0.0253 - val_loss: 0.0204\n",
      "Epoch 45/52\n",
      "48/48 [==============================] - 1s 31ms/step - loss: 0.0251 - val_loss: 0.0202\n",
      "Epoch 46/52\n",
      "48/48 [==============================] - 1s 30ms/step - loss: 0.0250 - val_loss: 0.0200\n",
      "Epoch 47/52\n",
      "48/48 [==============================] - 1s 30ms/step - loss: 0.0249 - val_loss: 0.0198\n",
      "Epoch 48/52\n",
      "48/48 [==============================] - 1s 30ms/step - loss: 0.0248 - val_loss: 0.0197\n",
      "Epoch 49/52\n",
      "48/48 [==============================] - 1s 30ms/step - loss: 0.0247 - val_loss: 0.0194\n",
      "Epoch 50/52\n",
      "48/48 [==============================] - 1s 30ms/step - loss: 0.0246 - val_loss: 0.0193\n",
      "Epoch 51/52\n",
      "48/48 [==============================] - 1s 30ms/step - loss: 0.0245 - val_loss: 0.0191\n",
      "Epoch 52/52\n",
      "48/48 [==============================] - 1s 31ms/step - loss: 0.0244 - val_loss: 0.0188\n",
      "Execution time:  79.1154522895813\n",
      "DNN:\n",
      "Mean Absolute Error: 0.0266\n",
      "Root Mean Square Error: 0.0465\n",
      "Mean Square Error: 0.0022\n",
      "\n",
      "Train RMSE: 0.047\n",
      "Train MSE: 0.002\n",
      "Train MAE: 0.027\n",
      "###########################\n",
      "\n",
      "MODEL:  DNN\n",
      "sequence:  7d\n",
      "units:  87\n",
      "dropout1:  0.40519643149940265\n",
      "optimizer: adamax\n",
      "activationDense: sigmoid\n",
      "epochs: 80\n",
      "batchsize: 31\n",
      "validation_split: 0.2\n",
      "Model: \"sequential_249\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_747 (Dense)            (None, 1008, 87)          174       \n",
      "_________________________________________________________________\n",
      "dense_748 (Dense)            (None, 1008, 16)          1408      \n",
      "_________________________________________________________________\n",
      "dropout_249 (Dropout)        (None, 1008, 16)          0         \n",
      "_________________________________________________________________\n",
      "dense_749 (Dense)            (None, 1008, 1)           17        \n",
      "=================================================================\n",
      "Total params: 1,599\n",
      "Trainable params: 1,599\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/80\n",
      "77/77 [==============================] - 3s 39ms/step - loss: 0.0544 - val_loss: 0.0251\n",
      "Epoch 2/80\n",
      "77/77 [==============================] - 3s 36ms/step - loss: 0.0404 - val_loss: 0.0224\n",
      "Epoch 3/80\n",
      "77/77 [==============================] - 3s 37ms/step - loss: 0.0385 - val_loss: 0.0198\n",
      "Epoch 4/80\n",
      "77/77 [==============================] - 3s 36ms/step - loss: 0.0368 - val_loss: 0.0160\n",
      "Epoch 5/80\n",
      "77/77 [==============================] - 3s 37ms/step - loss: 0.0353 - val_loss: 0.0154\n",
      "Epoch 6/80\n",
      "77/77 [==============================] - 3s 39ms/step - loss: 0.0346 - val_loss: 0.0154\n",
      "Epoch 7/80\n",
      "77/77 [==============================] - 3s 37ms/step - loss: 0.0340 - val_loss: 0.0151\n",
      "Epoch 8/80\n",
      "77/77 [==============================] - 3s 37ms/step - loss: 0.0336 - val_loss: 0.0148\n",
      "Epoch 9/80\n",
      "77/77 [==============================] - 3s 37ms/step - loss: 0.0332 - val_loss: 0.0146\n",
      "Epoch 10/80\n",
      "77/77 [==============================] - 3s 37ms/step - loss: 0.0328 - val_loss: 0.0145\n",
      "Epoch 11/80\n",
      "77/77 [==============================] - 3s 38ms/step - loss: 0.0325 - val_loss: 0.0144\n",
      "Epoch 12/80\n",
      "77/77 [==============================] - 3s 37ms/step - loss: 0.0322 - val_loss: 0.0143\n",
      "Epoch 13/80\n",
      "77/77 [==============================] - 3s 37ms/step - loss: 0.0318 - val_loss: 0.0142\n",
      "Epoch 14/80\n",
      "77/77 [==============================] - 3s 37ms/step - loss: 0.0315 - val_loss: 0.0143\n",
      "Epoch 15/80\n",
      "77/77 [==============================] - 3s 37ms/step - loss: 0.0312 - val_loss: 0.0143\n",
      "Epoch 16/80\n",
      "77/77 [==============================] - 3s 37ms/step - loss: 0.0309 - val_loss: 0.0143\n",
      "Epoch 17/80\n",
      "77/77 [==============================] - 3s 39ms/step - loss: 0.0306 - val_loss: 0.0145\n",
      "Epoch 18/80\n",
      "77/77 [==============================] - 3s 37ms/step - loss: 0.0303 - val_loss: 0.0145\n",
      "Epoch 19/80\n",
      "77/77 [==============================] - 3s 37ms/step - loss: 0.0300 - val_loss: 0.0144\n",
      "Epoch 20/80\n",
      "77/77 [==============================] - 3s 37ms/step - loss: 0.0298 - val_loss: 0.0138\n",
      "Epoch 21/80\n",
      "77/77 [==============================] - 3s 37ms/step - loss: 0.0295 - val_loss: 0.0146\n",
      "Epoch 22/80\n",
      "77/77 [==============================] - 3s 38ms/step - loss: 0.0292 - val_loss: 0.0145\n",
      "Epoch 23/80\n",
      "77/77 [==============================] - 3s 38ms/step - loss: 0.0290 - val_loss: 0.0145\n",
      "Epoch 24/80\n",
      "77/77 [==============================] - 3s 37ms/step - loss: 0.0287 - val_loss: 0.0145\n",
      "Epoch 25/80\n",
      "77/77 [==============================] - 3s 37ms/step - loss: 0.0285 - val_loss: 0.0145\n",
      "Epoch 26/80\n",
      "77/77 [==============================] - 3s 37ms/step - loss: 0.0283 - val_loss: 0.0145\n",
      "Epoch 27/80\n",
      "77/77 [==============================] - 3s 37ms/step - loss: 0.0281 - val_loss: 0.0145\n",
      "Epoch 28/80\n",
      "77/77 [==============================] - 3s 40ms/step - loss: 0.0279 - val_loss: 0.0145\n",
      "Epoch 29/80\n",
      "77/77 [==============================] - 3s 37ms/step - loss: 0.0276 - val_loss: 0.0146\n",
      "Epoch 30/80\n",
      "77/77 [==============================] - 3s 37ms/step - loss: 0.0275 - val_loss: 0.0139\n",
      "Epoch 31/80\n",
      "77/77 [==============================] - 3s 37ms/step - loss: 0.0272 - val_loss: 0.0147\n",
      "Epoch 32/80\n",
      "77/77 [==============================] - 3s 37ms/step - loss: 0.0271 - val_loss: 0.0148\n",
      "Epoch 33/80\n",
      "77/77 [==============================] - 3s 38ms/step - loss: 0.0269 - val_loss: 0.0147\n",
      "Epoch 34/80\n",
      "77/77 [==============================] - 3s 37ms/step - loss: 0.0267 - val_loss: 0.0147\n",
      "Epoch 35/80\n",
      "77/77 [==============================] - 3s 37ms/step - loss: 0.0266 - val_loss: 0.0146\n",
      "Epoch 36/80\n",
      "77/77 [==============================] - 3s 37ms/step - loss: 0.0264 - val_loss: 0.0138\n",
      "Epoch 37/80\n",
      "77/77 [==============================] - 3s 37ms/step - loss: 0.0264 - val_loss: 0.0139\n",
      "Epoch 38/80\n",
      "77/77 [==============================] - 3s 37ms/step - loss: 0.0262 - val_loss: 0.0147\n",
      "Epoch 39/80\n",
      "77/77 [==============================] - 3s 39ms/step - loss: 0.0261 - val_loss: 0.0144\n",
      "Epoch 40/80\n",
      "77/77 [==============================] - 3s 37ms/step - loss: 0.0259 - val_loss: 0.0143\n",
      "Epoch 41/80\n",
      "77/77 [==============================] - 3s 37ms/step - loss: 0.0258 - val_loss: 0.0139\n",
      "Epoch 42/80\n",
      "77/77 [==============================] - 3s 37ms/step - loss: 0.0258 - val_loss: 0.0141\n",
      "Epoch 43/80\n",
      "77/77 [==============================] - 3s 37ms/step - loss: 0.0257 - val_loss: 0.0143\n",
      "Epoch 44/80\n",
      "77/77 [==============================] - 3s 38ms/step - loss: 0.0256 - val_loss: 0.0142\n",
      "Epoch 45/80\n",
      "77/77 [==============================] - 3s 38ms/step - loss: 0.0254 - val_loss: 0.0127\n",
      "Epoch 46/80\n",
      "77/77 [==============================] - 3s 37ms/step - loss: 0.0255 - val_loss: 0.0143\n",
      "Epoch 47/80\n",
      "77/77 [==============================] - 3s 36ms/step - loss: 0.0254 - val_loss: 0.0141\n",
      "Epoch 48/80\n",
      "77/77 [==============================] - 3s 37ms/step - loss: 0.0253 - val_loss: 0.0140\n",
      "Epoch 49/80\n",
      "77/77 [==============================] - 3s 37ms/step - loss: 0.0253 - val_loss: 0.0136\n",
      "Epoch 50/80\n",
      "77/77 [==============================] - 3s 39ms/step - loss: 0.0252 - val_loss: 0.0141\n",
      "Epoch 51/80\n",
      "77/77 [==============================] - 3s 37ms/step - loss: 0.0251 - val_loss: 0.0129\n",
      "Epoch 52/80\n",
      "77/77 [==============================] - 3s 37ms/step - loss: 0.0252 - val_loss: 0.0140\n",
      "Epoch 53/80\n",
      "77/77 [==============================] - 3s 37ms/step - loss: 0.0251 - val_loss: 0.0139\n",
      "Epoch 54/80\n",
      "77/77 [==============================] - 3s 37ms/step - loss: 0.0250 - val_loss: 0.0138\n",
      "Epoch 55/80\n",
      "77/77 [==============================] - 3s 38ms/step - loss: 0.0250 - val_loss: 0.0138\n",
      "Epoch 56/80\n",
      "77/77 [==============================] - 3s 37ms/step - loss: 0.0249 - val_loss: 0.0133\n",
      "Epoch 57/80\n",
      "77/77 [==============================] - 3s 37ms/step - loss: 0.0249 - val_loss: 0.0136\n",
      "Epoch 58/80\n",
      "77/77 [==============================] - 3s 37ms/step - loss: 0.0249 - val_loss: 0.0138\n",
      "Epoch 59/80\n",
      "77/77 [==============================] - 3s 37ms/step - loss: 0.0248 - val_loss: 0.0130\n",
      "Epoch 60/80\n",
      "77/77 [==============================] - 3s 37ms/step - loss: 0.0249 - val_loss: 0.0138\n",
      "Epoch 61/80\n",
      "77/77 [==============================] - 3s 39ms/step - loss: 0.0248 - val_loss: 0.0137\n",
      "Epoch 62/80\n",
      "77/77 [==============================] - 3s 36ms/step - loss: 0.0248 - val_loss: 0.0136\n",
      "Epoch 63/80\n",
      "77/77 [==============================] - 3s 37ms/step - loss: 0.0248 - val_loss: 0.0136\n",
      "Epoch 64/80\n",
      "77/77 [==============================] - 3s 37ms/step - loss: 0.0247 - val_loss: 0.0125\n",
      "Epoch 65/80\n",
      "77/77 [==============================] - 3s 37ms/step - loss: 0.0249 - val_loss: 0.0139\n",
      "Epoch 66/80\n",
      "77/77 [==============================] - 3s 38ms/step - loss: 0.0247 - val_loss: 0.0137\n",
      "Epoch 67/80\n",
      "77/77 [==============================] - 3s 38ms/step - loss: 0.0247 - val_loss: 0.0135\n",
      "Epoch 68/80\n",
      "77/77 [==============================] - 3s 37ms/step - loss: 0.0247 - val_loss: 0.0135\n",
      "Epoch 69/80\n",
      "77/77 [==============================] - 3s 37ms/step - loss: 0.0247 - val_loss: 0.0135\n",
      "Epoch 70/80\n",
      "77/77 [==============================] - 3s 37ms/step - loss: 0.0246 - val_loss: 0.0134\n",
      "Epoch 71/80\n",
      "77/77 [==============================] - 3s 37ms/step - loss: 0.0246 - val_loss: 0.0134\n",
      "Epoch 72/80\n",
      "77/77 [==============================] - 3s 39ms/step - loss: 0.0246 - val_loss: 0.0134\n",
      "Epoch 73/80\n",
      "77/77 [==============================] - 3s 37ms/step - loss: 0.0246 - val_loss: 0.0133\n",
      "Epoch 74/80\n",
      "77/77 [==============================] - 3s 37ms/step - loss: 0.0246 - val_loss: 0.0133\n",
      "Epoch 75/80\n",
      "77/77 [==============================] - 3s 37ms/step - loss: 0.0246 - val_loss: 0.0133\n",
      "Epoch 76/80\n",
      "77/77 [==============================] - 3s 37ms/step - loss: 0.0245 - val_loss: 0.0132\n",
      "Epoch 77/80\n",
      "77/77 [==============================] - 3s 38ms/step - loss: 0.0245 - val_loss: 0.0130\n",
      "Epoch 78/80\n",
      "77/77 [==============================] - 3s 38ms/step - loss: 0.0245 - val_loss: 0.0131\n",
      "Epoch 79/80\n",
      "77/77 [==============================] - 3s 37ms/step - loss: 0.0245 - val_loss: 0.0132\n",
      "Epoch 80/80\n",
      "77/77 [==============================] - 3s 37ms/step - loss: 0.0245 - val_loss: 0.0131\n",
      "Execution time:  233.4667613506317\n",
      "DNN:\n",
      "Mean Absolute Error: 0.0258\n",
      "Root Mean Square Error: 0.0462\n",
      "Mean Square Error: 0.0021\n",
      "\n",
      "Train RMSE: 0.046\n",
      "Train MSE: 0.002\n",
      "Train MAE: 0.026\n",
      "###########################\n",
      "\n",
      "MODEL:  DNN\n",
      "sequence:  7d\n",
      "units:  80\n",
      "dropout1:  0.11814836227952394\n",
      "optimizer: adamax\n",
      "activationDense: sigmoid\n",
      "epochs: 90\n",
      "batchsize: 25\n",
      "validation_split: 0.2\n",
      "Model: \"sequential_250\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_750 (Dense)            (None, 1008, 80)          160       \n",
      "_________________________________________________________________\n",
      "dense_751 (Dense)            (None, 1008, 16)          1296      \n",
      "_________________________________________________________________\n",
      "dropout_250 (Dropout)        (None, 1008, 16)          0         \n",
      "_________________________________________________________________\n",
      "dense_752 (Dense)            (None, 1008, 1)           17        \n",
      "=================================================================\n",
      "Total params: 1,473\n",
      "Trainable params: 1,473\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/90\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "96/96 [==============================] - 3s 30ms/step - loss: 0.0404 - val_loss: 0.0147\n",
      "Epoch 2/90\n",
      "96/96 [==============================] - 3s 30ms/step - loss: 0.0301 - val_loss: 0.0135\n",
      "Epoch 3/90\n",
      "96/96 [==============================] - 3s 29ms/step - loss: 0.0297 - val_loss: 0.0130\n",
      "Epoch 4/90\n",
      "96/96 [==============================] - 3s 28ms/step - loss: 0.0295 - val_loss: 0.0129\n",
      "Epoch 5/90\n",
      "96/96 [==============================] - 3s 28ms/step - loss: 0.0293 - val_loss: 0.0126\n",
      "Epoch 6/90\n",
      "96/96 [==============================] - 3s 28ms/step - loss: 0.0292 - val_loss: 0.0126\n",
      "Epoch 7/90\n",
      "96/96 [==============================] - 3s 28ms/step - loss: 0.0288 - val_loss: 0.0124\n",
      "Epoch 8/90\n",
      "96/96 [==============================] - 3s 30ms/step - loss: 0.0288 - val_loss: 0.0121\n",
      "Epoch 9/90\n",
      "96/96 [==============================] - 3s 29ms/step - loss: 0.0287 - val_loss: 0.0120\n",
      "Epoch 10/90\n",
      "96/96 [==============================] - 3s 28ms/step - loss: 0.0285 - val_loss: 0.0119\n",
      "Epoch 11/90\n",
      "96/96 [==============================] - 3s 28ms/step - loss: 0.0284 - val_loss: 0.0118\n",
      "Epoch 12/90\n",
      "96/96 [==============================] - 3s 28ms/step - loss: 0.0284 - val_loss: 0.0116\n",
      "Epoch 13/90\n",
      "96/96 [==============================] - 3s 29ms/step - loss: 0.0282 - val_loss: 0.0116\n",
      "Epoch 14/90\n",
      "96/96 [==============================] - 3s 30ms/step - loss: 0.0281 - val_loss: 0.0116\n",
      "Epoch 15/90\n",
      "96/96 [==============================] - 3s 28ms/step - loss: 0.0281 - val_loss: 0.0115\n",
      "Epoch 16/90\n",
      "96/96 [==============================] - 3s 29ms/step - loss: 0.0280 - val_loss: 0.0117\n",
      "Epoch 17/90\n",
      "96/96 [==============================] - 3s 28ms/step - loss: 0.0279 - val_loss: 0.0116\n",
      "Epoch 18/90\n",
      "96/96 [==============================] - 3s 28ms/step - loss: 0.0278 - val_loss: 0.0114\n",
      "Epoch 19/90\n",
      "96/96 [==============================] - 3s 29ms/step - loss: 0.0278 - val_loss: 0.0114\n",
      "Epoch 20/90\n",
      "96/96 [==============================] - 3s 30ms/step - loss: 0.0277 - val_loss: 0.0114\n",
      "Epoch 21/90\n",
      "96/96 [==============================] - 3s 29ms/step - loss: 0.0276 - val_loss: 0.0114\n",
      "Epoch 22/90\n",
      "96/96 [==============================] - 3s 28ms/step - loss: 0.0275 - val_loss: 0.0114\n",
      "Epoch 23/90\n",
      "96/96 [==============================] - 3s 28ms/step - loss: 0.0275 - val_loss: 0.0114\n",
      "Epoch 24/90\n",
      "96/96 [==============================] - 3s 28ms/step - loss: 0.0274 - val_loss: 0.0115\n",
      "Epoch 25/90\n",
      "96/96 [==============================] - 3s 30ms/step - loss: 0.0274 - val_loss: 0.0113\n",
      "Epoch 26/90\n",
      "96/96 [==============================] - 3s 29ms/step - loss: 0.0273 - val_loss: 0.0113\n",
      "Epoch 27/90\n",
      "96/96 [==============================] - 3s 28ms/step - loss: 0.0273 - val_loss: 0.0113\n",
      "Epoch 28/90\n",
      "96/96 [==============================] - 3s 28ms/step - loss: 0.0272 - val_loss: 0.0115\n",
      "Epoch 29/90\n",
      "96/96 [==============================] - 3s 28ms/step - loss: 0.0271 - val_loss: 0.0115\n",
      "Epoch 30/90\n",
      "96/96 [==============================] - 3s 28ms/step - loss: 0.0271 - val_loss: 0.0115\n",
      "Epoch 31/90\n",
      "96/96 [==============================] - 3s 30ms/step - loss: 0.0271 - val_loss: 0.0113\n",
      "Epoch 32/90\n",
      "96/96 [==============================] - 3s 29ms/step - loss: 0.0269 - val_loss: 0.0110\n",
      "Epoch 33/90\n",
      "96/96 [==============================] - 3s 28ms/step - loss: 0.0270 - val_loss: 0.0116\n",
      "Epoch 34/90\n",
      "96/96 [==============================] - 3s 28ms/step - loss: 0.0269 - val_loss: 0.0117\n",
      "Epoch 35/90\n",
      "96/96 [==============================] - 3s 28ms/step - loss: 0.0268 - val_loss: 0.0116\n",
      "Epoch 36/90\n",
      "96/96 [==============================] - 3s 29ms/step - loss: 0.0268 - val_loss: 0.0116\n",
      "Epoch 37/90\n",
      "96/96 [==============================] - 3s 29ms/step - loss: 0.0267 - val_loss: 0.0116\n",
      "Epoch 38/90\n",
      "96/96 [==============================] - 3s 29ms/step - loss: 0.0267 - val_loss: 0.0115\n",
      "Epoch 39/90\n",
      "96/96 [==============================] - 3s 28ms/step - loss: 0.0267 - val_loss: 0.0116\n",
      "Epoch 40/90\n",
      "96/96 [==============================] - 3s 28ms/step - loss: 0.0266 - val_loss: 0.0116\n",
      "Epoch 41/90\n",
      "96/96 [==============================] - 3s 28ms/step - loss: 0.0266 - val_loss: 0.0116\n",
      "Epoch 42/90\n",
      "96/96 [==============================] - 3s 29ms/step - loss: 0.0265 - val_loss: 0.0117\n",
      "Epoch 43/90\n",
      "96/96 [==============================] - 3s 29ms/step - loss: 0.0265 - val_loss: 0.0118\n",
      "Epoch 44/90\n",
      "96/96 [==============================] - 3s 29ms/step - loss: 0.0264 - val_loss: 0.0118\n",
      "Epoch 45/90\n",
      "96/96 [==============================] - 3s 28ms/step - loss: 0.0264 - val_loss: 0.0117\n",
      "Epoch 46/90\n",
      "96/96 [==============================] - 3s 28ms/step - loss: 0.0264 - val_loss: 0.0117\n",
      "Epoch 47/90\n",
      "96/96 [==============================] - 3s 28ms/step - loss: 0.0263 - val_loss: 0.0118\n",
      "Epoch 48/90\n",
      "96/96 [==============================] - 3s 30ms/step - loss: 0.0263 - val_loss: 0.0118\n",
      "Epoch 49/90\n",
      "96/96 [==============================] - 3s 29ms/step - loss: 0.0261 - val_loss: 0.0108\n",
      "Epoch 50/90\n",
      "96/96 [==============================] - 3s 28ms/step - loss: 0.0263 - val_loss: 0.0121\n",
      "Epoch 51/90\n",
      "96/96 [==============================] - 3s 28ms/step - loss: 0.0261 - val_loss: 0.0120\n",
      "Epoch 52/90\n",
      "96/96 [==============================] - 3s 28ms/step - loss: 0.0261 - val_loss: 0.0120\n",
      "Epoch 53/90\n",
      "96/96 [==============================] - 3s 29ms/step - loss: 0.0260 - val_loss: 0.0121\n",
      "Epoch 54/90\n",
      "96/96 [==============================] - 3s 30ms/step - loss: 0.0260 - val_loss: 0.0119\n",
      "Epoch 55/90\n",
      "96/96 [==============================] - 3s 28ms/step - loss: 0.0260 - val_loss: 0.0120\n",
      "Epoch 56/90\n",
      "96/96 [==============================] - 3s 28ms/step - loss: 0.0260 - val_loss: 0.0121\n",
      "Epoch 57/90\n",
      "96/96 [==============================] - 3s 28ms/step - loss: 0.0259 - val_loss: 0.0122\n",
      "Epoch 58/90\n",
      "96/96 [==============================] - 3s 28ms/step - loss: 0.0258 - val_loss: 0.0110\n",
      "Epoch 59/90\n",
      "96/96 [==============================] - 3s 29ms/step - loss: 0.0259 - val_loss: 0.0127\n",
      "Epoch 60/90\n",
      "96/96 [==============================] - 3s 29ms/step - loss: 0.0258 - val_loss: 0.0124\n",
      "Epoch 61/90\n",
      "96/96 [==============================] - 3s 28ms/step - loss: 0.0258 - val_loss: 0.0125\n",
      "Epoch 62/90\n",
      "96/96 [==============================] - 3s 29ms/step - loss: 0.0258 - val_loss: 0.0126\n",
      "Epoch 63/90\n",
      "96/96 [==============================] - 3s 28ms/step - loss: 0.0258 - val_loss: 0.0126\n",
      "Epoch 64/90\n",
      "96/96 [==============================] - 3s 28ms/step - loss: 0.0257 - val_loss: 0.0126\n",
      "Epoch 65/90\n",
      "96/96 [==============================] - 3s 30ms/step - loss: 0.0257 - val_loss: 0.0126\n",
      "Epoch 66/90\n",
      "96/96 [==============================] - 3s 29ms/step - loss: 0.0257 - val_loss: 0.0126\n",
      "Epoch 67/90\n",
      "96/96 [==============================] - 3s 28ms/step - loss: 0.0256 - val_loss: 0.0126\n",
      "Epoch 68/90\n",
      "96/96 [==============================] - 3s 28ms/step - loss: 0.0256 - val_loss: 0.0127\n",
      "Epoch 69/90\n",
      "96/96 [==============================] - 3s 28ms/step - loss: 0.0256 - val_loss: 0.0127\n",
      "Epoch 70/90\n",
      "96/96 [==============================] - 3s 28ms/step - loss: 0.0255 - val_loss: 0.0126\n",
      "Epoch 71/90\n",
      "96/96 [==============================] - 3s 30ms/step - loss: 0.0255 - val_loss: 0.0127\n",
      "Epoch 72/90\n",
      "96/96 [==============================] - 3s 29ms/step - loss: 0.0255 - val_loss: 0.0127\n",
      "Epoch 73/90\n",
      "96/96 [==============================] - 3s 28ms/step - loss: 0.0254 - val_loss: 0.0127\n",
      "Epoch 74/90\n",
      "96/96 [==============================] - 3s 28ms/step - loss: 0.0254 - val_loss: 0.0127\n",
      "Epoch 75/90\n",
      "96/96 [==============================] - 3s 29ms/step - loss: 0.0254 - val_loss: 0.0127\n",
      "Epoch 76/90\n",
      "96/96 [==============================] - 3s 29ms/step - loss: 0.0254 - val_loss: 0.0127\n",
      "Epoch 77/90\n",
      "96/96 [==============================] - 3s 30ms/step - loss: 0.0253 - val_loss: 0.0127\n",
      "Epoch 78/90\n",
      "96/96 [==============================] - 3s 28ms/step - loss: 0.0253 - val_loss: 0.0127\n",
      "Epoch 79/90\n",
      "96/96 [==============================] - 3s 28ms/step - loss: 0.0253 - val_loss: 0.0127\n",
      "Epoch 80/90\n",
      "96/96 [==============================] - 3s 28ms/step - loss: 0.0252 - val_loss: 0.0114\n",
      "Epoch 81/90\n",
      "96/96 [==============================] - 3s 28ms/step - loss: 0.0254 - val_loss: 0.0134\n",
      "Epoch 82/90\n",
      "96/96 [==============================] - 3s 29ms/step - loss: 0.0252 - val_loss: 0.0127\n",
      "Epoch 83/90\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "96/96 [==============================] - 3s 29ms/step - loss: 0.0252 - val_loss: 0.0126\n",
      "Epoch 84/90\n",
      "96/96 [==============================] - 3s 28ms/step - loss: 0.0252 - val_loss: 0.0127\n",
      "Epoch 85/90\n",
      "96/96 [==============================] - 3s 29ms/step - loss: 0.0252 - val_loss: 0.0127\n",
      "Epoch 86/90\n",
      "96/96 [==============================] - 3s 28ms/step - loss: 0.0252 - val_loss: 0.0126\n",
      "Epoch 87/90\n",
      "96/96 [==============================] - 3s 28ms/step - loss: 0.0251 - val_loss: 0.0120\n",
      "Epoch 88/90\n",
      "96/96 [==============================] - 3s 30ms/step - loss: 0.0252 - val_loss: 0.0129\n",
      "Epoch 89/90\n",
      "96/96 [==============================] - 3s 29ms/step - loss: 0.0251 - val_loss: 0.0126\n",
      "Epoch 90/90\n",
      "96/96 [==============================] - 3s 28ms/step - loss: 0.0251 - val_loss: 0.0126\n",
      "Execution time:  252.21988654136658\n",
      "DNN:\n",
      "Mean Absolute Error: 0.0261\n",
      "Root Mean Square Error: 0.0469\n",
      "Mean Square Error: 0.0022\n",
      "\n",
      "Train RMSE: 0.047\n",
      "Train MSE: 0.002\n",
      "Train MAE: 0.026\n",
      "###########################\n",
      "\n",
      "MODEL:  DNN\n",
      "sequence:  7d\n",
      "units:  12\n",
      "dropout1:  0.48476373451509647\n",
      "optimizer: adamax\n",
      "activationDense: sigmoid\n",
      "epochs: 52\n",
      "batchsize: 57\n",
      "validation_split: 0.2\n",
      "Model: \"sequential_251\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_753 (Dense)            (None, 1008, 12)          24        \n",
      "_________________________________________________________________\n",
      "dense_754 (Dense)            (None, 1008, 16)          208       \n",
      "_________________________________________________________________\n",
      "dropout_251 (Dropout)        (None, 1008, 16)          0         \n",
      "_________________________________________________________________\n",
      "dense_755 (Dense)            (None, 1008, 1)           17        \n",
      "=================================================================\n",
      "Total params: 249\n",
      "Trainable params: 249\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/52\n",
      "42/42 [==============================] - 2s 36ms/step - loss: 0.0601 - val_loss: 0.0470- ETA: 0s - loss: 0.\n",
      "Epoch 2/52\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 0.0446 - val_loss: 0.0354\n",
      "Epoch 3/52\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 0.0430 - val_loss: 0.0352\n",
      "Epoch 4/52\n",
      "42/42 [==============================] - 1s 32ms/step - loss: 0.0419 - val_loss: 0.0341\n",
      "Epoch 5/52\n",
      "42/42 [==============================] - 1s 32ms/step - loss: 0.0408 - val_loss: 0.0330\n",
      "Epoch 6/52\n",
      "42/42 [==============================] - 1s 34ms/step - loss: 0.0399 - val_loss: 0.0321\n",
      "Epoch 7/52\n",
      "42/42 [==============================] - 1s 32ms/step - loss: 0.0391 - val_loss: 0.0311\n",
      "Epoch 8/52\n",
      "42/42 [==============================] - 1s 32ms/step - loss: 0.0381 - val_loss: 0.0290\n",
      "Epoch 9/52\n",
      "42/42 [==============================] - 1s 32ms/step - loss: 0.0370 - val_loss: 0.0285\n",
      "Epoch 10/52\n",
      "42/42 [==============================] - 1s 30ms/step - loss: 0.0362 - val_loss: 0.0281\n",
      "Epoch 11/52\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 0.0355 - val_loss: 0.0273\n",
      "Epoch 12/52\n",
      "42/42 [==============================] - 1s 32ms/step - loss: 0.0350 - val_loss: 0.0269\n",
      "Epoch 13/52\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 0.0345 - val_loss: 0.0266\n",
      "Epoch 14/52\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 0.0341 - val_loss: 0.0261\n",
      "Epoch 15/52\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 0.0337 - val_loss: 0.0258\n",
      "Epoch 16/52\n",
      "42/42 [==============================] - 1s 30ms/step - loss: 0.0333 - val_loss: 0.0253\n",
      "Epoch 17/52\n",
      "42/42 [==============================] - 1s 33ms/step - loss: 0.0330 - val_loss: 0.0248\n",
      "Epoch 18/52\n",
      "42/42 [==============================] - 1s 33ms/step - loss: 0.0326 - val_loss: 0.0243\n",
      "Epoch 19/52\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 0.0323 - val_loss: 0.0240\n",
      "Epoch 20/52\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 0.0319 - val_loss: 0.0235\n",
      "Epoch 21/52\n",
      "42/42 [==============================] - 1s 32ms/step - loss: 0.0315 - val_loss: 0.0231\n",
      "Epoch 22/52\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 0.0312 - val_loss: 0.0228\n",
      "Epoch 23/52\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 0.0308 - val_loss: 0.0225\n",
      "Epoch 24/52\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 0.0305 - val_loss: 0.0221\n",
      "Epoch 25/52\n",
      "42/42 [==============================] - 1s 32ms/step - loss: 0.0303 - val_loss: 0.0218\n",
      "Epoch 26/52\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 0.0299 - val_loss: 0.0215\n",
      "Epoch 27/52\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 0.0297 - val_loss: 0.0212\n",
      "Epoch 28/52\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 0.0295 - val_loss: 0.0209\n",
      "Epoch 29/52\n",
      "42/42 [==============================] - 1s 34ms/step - loss: 0.0292 - val_loss: 0.0206\n",
      "Epoch 30/52\n",
      "42/42 [==============================] - 1s 34ms/step - loss: 0.0290 - val_loss: 0.0204\n",
      "Epoch 31/52\n",
      "42/42 [==============================] - 1s 32ms/step - loss: 0.0288 - val_loss: 0.0201\n",
      "Epoch 32/52\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 0.0286 - val_loss: 0.0200\n",
      "Epoch 33/52\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 0.0285 - val_loss: 0.0198\n",
      "Epoch 34/52\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 0.0283 - val_loss: 0.0196\n",
      "Epoch 35/52\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 0.0282 - val_loss: 0.0194\n",
      "Epoch 36/52\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 0.0280 - val_loss: 0.0193\n",
      "Epoch 37/52\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 0.0279 - val_loss: 0.0191\n",
      "Epoch 38/52\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 0.0277 - val_loss: 0.0189\n",
      "Epoch 39/52\n",
      "42/42 [==============================] - 1s 32ms/step - loss: 0.0276 - val_loss: 0.0187\n",
      "Epoch 40/52\n",
      "42/42 [==============================] - 1s 33ms/step - loss: 0.0274 - val_loss: 0.0185\n",
      "Epoch 41/52\n",
      "42/42 [==============================] - 1s 33ms/step - loss: 0.0273 - val_loss: 0.0183\n",
      "Epoch 42/52\n",
      "42/42 [==============================] - 1s 32ms/step - loss: 0.0272 - val_loss: 0.0181\n",
      "Epoch 43/52\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 0.0271 - val_loss: 0.0179\n",
      "Epoch 44/52\n",
      "42/42 [==============================] - 1s 32ms/step - loss: 0.0269 - val_loss: 0.0177\n",
      "Epoch 45/52\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 0.0268 - val_loss: 0.0176\n",
      "Epoch 46/52\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 0.0267 - val_loss: 0.0174\n",
      "Epoch 47/52\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 0.0266 - val_loss: 0.0172\n",
      "Epoch 48/52\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 0.0265 - val_loss: 0.0171\n",
      "Epoch 49/52\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 0.0264 - val_loss: 0.0169\n",
      "Epoch 50/52\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 0.0263 - val_loss: 0.0168TA: 0s - loss: 0.0\n",
      "Epoch 51/52\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 0.0262 - val_loss: 0.0167\n",
      "Epoch 52/52\n",
      "42/42 [==============================] - 1s 33ms/step - loss: 0.0262 - val_loss: 0.0165\n",
      "Execution time:  72.02425909042358\n",
      "DNN:\n",
      "Mean Absolute Error: 0.0263\n",
      "Root Mean Square Error: 0.0454\n",
      "Mean Square Error: 0.0021\n",
      "\n",
      "Train RMSE: 0.045\n",
      "Train MSE: 0.002\n",
      "Train MAE: 0.026\n"
     ]
    }
   ],
   "source": [
    "def _model(units,activationDense,dropout1,optimizer):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(units=units, input_shape=(X_train.shape[1], X_train.shape[2]), activation='relu'))\n",
    "    model.add(Dense(16, activation='relu'))\n",
    "    model.add(Dropout(rate=dropout1))\n",
    "    model.add(Dense(X_train.shape[2],activation=activationDense))\n",
    "    model.compile(optimizer=optimizer, loss='mae')\n",
    "    model.summary()\n",
    "    \n",
    "    return model\n",
    "\n",
    "sequences = [\"1h\",\"3h\",\"6h\",\"12h\",\"1d\", \"3d\", \"7d\"]\n",
    "X_trains = [X_train1h,X_train3h, X_train6h, X_train12h,X_train1d,X_train3d, X_train7d]\n",
    "y_trains= [y_train1h,y_train3h, y_train6h,y_train12h,y_train1d,y_train3d, y_train7d]\n",
    "activationsDense = ['tanh','sigmoid']\n",
    "optimizers = ['adam','adadelta','adamax']\n",
    "list_validationSplit = [0.1,0.2]\n",
    "list_dropout1 =  np.random.uniform(0.1,0.8,5)\n",
    "list_units = np.random.randint(5,high=100, size=5)\n",
    "list_epochs = np.random.randint(5,high=100, size=5) \n",
    "list_batchsize = np.random.randint(5,high=64, size=5)   \n",
    "\n",
    "list_results = pd.DataFrame()\n",
    "\n",
    "for X_train, y_train,sequence in zip(X_trains,y_trains,sequences):\n",
    "    for optimizer in optimizers:\n",
    "        #for activation in activations:\n",
    "            for activationDense in activationsDense:\n",
    "                for validationsplit in list_validationSplit: \n",
    "                    for units,epochs,batchsize,dropout1 in zip(list_units,list_epochs,list_batchsize,list_dropout1): \n",
    "                        start = time()\n",
    "                        print(\"###########################\\n\")\n",
    "                        print(\"MODEL: \", \"DNN\")\n",
    "                        print('sequence: ',sequence)\n",
    "                        print('units: ',units)\n",
    "                        print('dropout1: ',dropout1)\n",
    "                        print('optimizer:',optimizer)\n",
    "                        print('activationDense:',activationDense)\n",
    "                        print('epochs:',epochs)\n",
    "                        print('batchsize:',batchsize)\n",
    "                        print('validation_split:',validationsplit)\n",
    "\n",
    "                        model = _model(units,activationDense,dropout1,optimizer)\n",
    "                        history = model.fit(X_train, y_train, epochs=epochs, batch_size=batchsize, validation_split=validationsplit, shuffle=False)\n",
    "                        end = time()\n",
    "                        totalTime = end-start\n",
    "                        print ('Execution time: ',totalTime)\n",
    "\n",
    "                        X_train_pred = model.predict(X_train, verbose=0)\n",
    "\n",
    "                        mae,rmse,mse = evaluate_prediction(X_train_pred, X_train,\"DNN\")\n",
    "\n",
    "                        print('Train RMSE: %.3f' % rmse);\n",
    "                        print('Train MSE: %.3f' % mse);\n",
    "                        print('Train MAE: %.3f' % mae);\n",
    "\n",
    "                        result = pd.DataFrame({\n",
    "                                               #'activation':[activation],\n",
    "                                               'model':[\"DNN\"],\n",
    "                                               'sequence':[sequence],\n",
    "                                               'activationDense':[activationDense],\n",
    "                                               'optimizer':[optimizer],\n",
    "                                               'dropout1':[dropout1],\n",
    "                                               'units':[units],\n",
    "                                               'epochs':[epochs],\n",
    "                                               'batchsize':[batchsize],\n",
    "                                               'validation_split':[validationsplit],\n",
    "\n",
    "                                               'RMSE':[rmse],\n",
    "                                               'MSE':[mse],\n",
    "                                               'MAE':[mae],                            \n",
    "                                               'Time':[totalTime]})\n",
    "                        list_results = list_results.append(result) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_results.to_csv(\"resultats-cerca-optim-dnn-v1.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>sequence</th>\n",
       "      <th>activationDense</th>\n",
       "      <th>optimizer</th>\n",
       "      <th>dropout1</th>\n",
       "      <th>units</th>\n",
       "      <th>epochs</th>\n",
       "      <th>batchsize</th>\n",
       "      <th>validation_split</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>MSE</th>\n",
       "      <th>MAE</th>\n",
       "      <th>Time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>DNN</td>\n",
       "      <td>1h</td>\n",
       "      <td>tanh</td>\n",
       "      <td>adam</td>\n",
       "      <td>0.405196</td>\n",
       "      <td>87</td>\n",
       "      <td>80</td>\n",
       "      <td>31</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.019200</td>\n",
       "      <td>0.000369</td>\n",
       "      <td>0.009905</td>\n",
       "      <td>17.237772</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>DNN</td>\n",
       "      <td>1h</td>\n",
       "      <td>tanh</td>\n",
       "      <td>adam</td>\n",
       "      <td>0.118148</td>\n",
       "      <td>80</td>\n",
       "      <td>90</td>\n",
       "      <td>25</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.018856</td>\n",
       "      <td>0.000356</td>\n",
       "      <td>0.005032</td>\n",
       "      <td>22.277235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>DNN</td>\n",
       "      <td>1h</td>\n",
       "      <td>tanh</td>\n",
       "      <td>adam</td>\n",
       "      <td>0.484764</td>\n",
       "      <td>12</td>\n",
       "      <td>52</td>\n",
       "      <td>57</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.017678</td>\n",
       "      <td>0.000313</td>\n",
       "      <td>0.011355</td>\n",
       "      <td>6.903105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>DNN</td>\n",
       "      <td>1h</td>\n",
       "      <td>tanh</td>\n",
       "      <td>adam</td>\n",
       "      <td>0.405196</td>\n",
       "      <td>87</td>\n",
       "      <td>80</td>\n",
       "      <td>31</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.021332</td>\n",
       "      <td>0.000455</td>\n",
       "      <td>0.013577</td>\n",
       "      <td>16.152798</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>DNN</td>\n",
       "      <td>1h</td>\n",
       "      <td>tanh</td>\n",
       "      <td>adam</td>\n",
       "      <td>0.118148</td>\n",
       "      <td>80</td>\n",
       "      <td>90</td>\n",
       "      <td>25</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.021047</td>\n",
       "      <td>0.000443</td>\n",
       "      <td>0.008638</td>\n",
       "      <td>20.035282</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>DNN</td>\n",
       "      <td>1h</td>\n",
       "      <td>tanh</td>\n",
       "      <td>adam</td>\n",
       "      <td>0.484764</td>\n",
       "      <td>12</td>\n",
       "      <td>52</td>\n",
       "      <td>57</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.024989</td>\n",
       "      <td>0.000624</td>\n",
       "      <td>0.016478</td>\n",
       "      <td>6.411896</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>DNN</td>\n",
       "      <td>1h</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>adam</td>\n",
       "      <td>0.405196</td>\n",
       "      <td>87</td>\n",
       "      <td>80</td>\n",
       "      <td>31</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.018717</td>\n",
       "      <td>0.000350</td>\n",
       "      <td>0.010021</td>\n",
       "      <td>16.140609</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>DNN</td>\n",
       "      <td>1h</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>adam</td>\n",
       "      <td>0.118148</td>\n",
       "      <td>80</td>\n",
       "      <td>90</td>\n",
       "      <td>25</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.020069</td>\n",
       "      <td>0.000403</td>\n",
       "      <td>0.005485</td>\n",
       "      <td>20.425318</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>DNN</td>\n",
       "      <td>1h</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>adam</td>\n",
       "      <td>0.484764</td>\n",
       "      <td>12</td>\n",
       "      <td>52</td>\n",
       "      <td>57</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.019351</td>\n",
       "      <td>0.000374</td>\n",
       "      <td>0.010890</td>\n",
       "      <td>6.711839</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>DNN</td>\n",
       "      <td>1h</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>adam</td>\n",
       "      <td>0.405196</td>\n",
       "      <td>87</td>\n",
       "      <td>80</td>\n",
       "      <td>31</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.028214</td>\n",
       "      <td>0.000796</td>\n",
       "      <td>0.014225</td>\n",
       "      <td>15.500949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>DNN</td>\n",
       "      <td>1h</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>adam</td>\n",
       "      <td>0.118148</td>\n",
       "      <td>80</td>\n",
       "      <td>90</td>\n",
       "      <td>25</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.023030</td>\n",
       "      <td>0.000530</td>\n",
       "      <td>0.006963</td>\n",
       "      <td>19.581539</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>DNN</td>\n",
       "      <td>1h</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>adam</td>\n",
       "      <td>0.484764</td>\n",
       "      <td>12</td>\n",
       "      <td>52</td>\n",
       "      <td>57</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.024698</td>\n",
       "      <td>0.000610</td>\n",
       "      <td>0.014355</td>\n",
       "      <td>6.615545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>DNN</td>\n",
       "      <td>1h</td>\n",
       "      <td>tanh</td>\n",
       "      <td>adadelta</td>\n",
       "      <td>0.405196</td>\n",
       "      <td>87</td>\n",
       "      <td>80</td>\n",
       "      <td>31</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.061576</td>\n",
       "      <td>0.003792</td>\n",
       "      <td>0.055773</td>\n",
       "      <td>15.818824</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>DNN</td>\n",
       "      <td>1h</td>\n",
       "      <td>tanh</td>\n",
       "      <td>adadelta</td>\n",
       "      <td>0.118148</td>\n",
       "      <td>80</td>\n",
       "      <td>90</td>\n",
       "      <td>25</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.038144</td>\n",
       "      <td>0.001455</td>\n",
       "      <td>0.031027</td>\n",
       "      <td>19.608741</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>DNN</td>\n",
       "      <td>1h</td>\n",
       "      <td>tanh</td>\n",
       "      <td>adadelta</td>\n",
       "      <td>0.484764</td>\n",
       "      <td>12</td>\n",
       "      <td>52</td>\n",
       "      <td>57</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.328606</td>\n",
       "      <td>0.107982</td>\n",
       "      <td>0.326552</td>\n",
       "      <td>6.342408</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>DNN</td>\n",
       "      <td>1h</td>\n",
       "      <td>tanh</td>\n",
       "      <td>adadelta</td>\n",
       "      <td>0.405196</td>\n",
       "      <td>87</td>\n",
       "      <td>80</td>\n",
       "      <td>31</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.073644</td>\n",
       "      <td>0.005423</td>\n",
       "      <td>0.069398</td>\n",
       "      <td>15.335560</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>DNN</td>\n",
       "      <td>1h</td>\n",
       "      <td>tanh</td>\n",
       "      <td>adadelta</td>\n",
       "      <td>0.118148</td>\n",
       "      <td>80</td>\n",
       "      <td>90</td>\n",
       "      <td>25</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.048324</td>\n",
       "      <td>0.002335</td>\n",
       "      <td>0.041429</td>\n",
       "      <td>19.509650</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>DNN</td>\n",
       "      <td>1h</td>\n",
       "      <td>tanh</td>\n",
       "      <td>adadelta</td>\n",
       "      <td>0.484764</td>\n",
       "      <td>12</td>\n",
       "      <td>52</td>\n",
       "      <td>57</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.327068</td>\n",
       "      <td>0.106973</td>\n",
       "      <td>0.324953</td>\n",
       "      <td>6.494782</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>DNN</td>\n",
       "      <td>1h</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>adadelta</td>\n",
       "      <td>0.405196</td>\n",
       "      <td>87</td>\n",
       "      <td>80</td>\n",
       "      <td>31</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.059135</td>\n",
       "      <td>0.003497</td>\n",
       "      <td>0.051032</td>\n",
       "      <td>16.379211</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>DNN</td>\n",
       "      <td>1h</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>adadelta</td>\n",
       "      <td>0.118148</td>\n",
       "      <td>80</td>\n",
       "      <td>90</td>\n",
       "      <td>25</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.046956</td>\n",
       "      <td>0.002205</td>\n",
       "      <td>0.036599</td>\n",
       "      <td>19.777558</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  model sequence activationDense optimizer  dropout1  units  epochs  \\\n",
       "0   DNN       1h            tanh      adam  0.405196     87      80   \n",
       "0   DNN       1h            tanh      adam  0.118148     80      90   \n",
       "0   DNN       1h            tanh      adam  0.484764     12      52   \n",
       "0   DNN       1h            tanh      adam  0.405196     87      80   \n",
       "0   DNN       1h            tanh      adam  0.118148     80      90   \n",
       "0   DNN       1h            tanh      adam  0.484764     12      52   \n",
       "0   DNN       1h         sigmoid      adam  0.405196     87      80   \n",
       "0   DNN       1h         sigmoid      adam  0.118148     80      90   \n",
       "0   DNN       1h         sigmoid      adam  0.484764     12      52   \n",
       "0   DNN       1h         sigmoid      adam  0.405196     87      80   \n",
       "0   DNN       1h         sigmoid      adam  0.118148     80      90   \n",
       "0   DNN       1h         sigmoid      adam  0.484764     12      52   \n",
       "0   DNN       1h            tanh  adadelta  0.405196     87      80   \n",
       "0   DNN       1h            tanh  adadelta  0.118148     80      90   \n",
       "0   DNN       1h            tanh  adadelta  0.484764     12      52   \n",
       "0   DNN       1h            tanh  adadelta  0.405196     87      80   \n",
       "0   DNN       1h            tanh  adadelta  0.118148     80      90   \n",
       "0   DNN       1h            tanh  adadelta  0.484764     12      52   \n",
       "0   DNN       1h         sigmoid  adadelta  0.405196     87      80   \n",
       "0   DNN       1h         sigmoid  adadelta  0.118148     80      90   \n",
       "\n",
       "   batchsize  validation_split      RMSE       MSE       MAE       Time  \n",
       "0         31               0.1  0.019200  0.000369  0.009905  17.237772  \n",
       "0         25               0.1  0.018856  0.000356  0.005032  22.277235  \n",
       "0         57               0.1  0.017678  0.000313  0.011355   6.903105  \n",
       "0         31               0.2  0.021332  0.000455  0.013577  16.152798  \n",
       "0         25               0.2  0.021047  0.000443  0.008638  20.035282  \n",
       "0         57               0.2  0.024989  0.000624  0.016478   6.411896  \n",
       "0         31               0.1  0.018717  0.000350  0.010021  16.140609  \n",
       "0         25               0.1  0.020069  0.000403  0.005485  20.425318  \n",
       "0         57               0.1  0.019351  0.000374  0.010890   6.711839  \n",
       "0         31               0.2  0.028214  0.000796  0.014225  15.500949  \n",
       "0         25               0.2  0.023030  0.000530  0.006963  19.581539  \n",
       "0         57               0.2  0.024698  0.000610  0.014355   6.615545  \n",
       "0         31               0.1  0.061576  0.003792  0.055773  15.818824  \n",
       "0         25               0.1  0.038144  0.001455  0.031027  19.608741  \n",
       "0         57               0.1  0.328606  0.107982  0.326552   6.342408  \n",
       "0         31               0.2  0.073644  0.005423  0.069398  15.335560  \n",
       "0         25               0.2  0.048324  0.002335  0.041429  19.509650  \n",
       "0         57               0.2  0.327068  0.106973  0.324953   6.494782  \n",
       "0         31               0.1  0.059135  0.003497  0.051032  16.379211  \n",
       "0         25               0.1  0.046956  0.002205  0.036599  19.777558  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list_results.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>sequence</th>\n",
       "      <th>activationDense</th>\n",
       "      <th>optimizer</th>\n",
       "      <th>dropout1</th>\n",
       "      <th>units</th>\n",
       "      <th>epochs</th>\n",
       "      <th>batchsize</th>\n",
       "      <th>validation_split</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>MSE</th>\n",
       "      <th>MAE</th>\n",
       "      <th>Time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>DNN</td>\n",
       "      <td>1h</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>adamax</td>\n",
       "      <td>0.118148</td>\n",
       "      <td>80</td>\n",
       "      <td>90</td>\n",
       "      <td>25</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.013449</td>\n",
       "      <td>0.000181</td>\n",
       "      <td>0.005524</td>\n",
       "      <td>19.100332</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>DNN</td>\n",
       "      <td>1h</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>adamax</td>\n",
       "      <td>0.405196</td>\n",
       "      <td>87</td>\n",
       "      <td>80</td>\n",
       "      <td>31</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.013451</td>\n",
       "      <td>0.000181</td>\n",
       "      <td>0.007040</td>\n",
       "      <td>15.485010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>DNN</td>\n",
       "      <td>1h</td>\n",
       "      <td>tanh</td>\n",
       "      <td>adamax</td>\n",
       "      <td>0.405196</td>\n",
       "      <td>87</td>\n",
       "      <td>80</td>\n",
       "      <td>31</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.013571</td>\n",
       "      <td>0.000184</td>\n",
       "      <td>0.007138</td>\n",
       "      <td>15.828002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>DNN</td>\n",
       "      <td>1h</td>\n",
       "      <td>tanh</td>\n",
       "      <td>adamax</td>\n",
       "      <td>0.484764</td>\n",
       "      <td>12</td>\n",
       "      <td>52</td>\n",
       "      <td>57</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.013672</td>\n",
       "      <td>0.000187</td>\n",
       "      <td>0.007954</td>\n",
       "      <td>6.807474</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>DNN</td>\n",
       "      <td>1h</td>\n",
       "      <td>tanh</td>\n",
       "      <td>adamax</td>\n",
       "      <td>0.118148</td>\n",
       "      <td>80</td>\n",
       "      <td>90</td>\n",
       "      <td>25</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.014728</td>\n",
       "      <td>0.000217</td>\n",
       "      <td>0.009229</td>\n",
       "      <td>19.297134</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>DNN</td>\n",
       "      <td>7d</td>\n",
       "      <td>tanh</td>\n",
       "      <td>adadelta</td>\n",
       "      <td>0.484764</td>\n",
       "      <td>12</td>\n",
       "      <td>52</td>\n",
       "      <td>57</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.371034</td>\n",
       "      <td>0.137667</td>\n",
       "      <td>0.368752</td>\n",
       "      <td>74.603660</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>DNN</td>\n",
       "      <td>12h</td>\n",
       "      <td>tanh</td>\n",
       "      <td>adadelta</td>\n",
       "      <td>0.484764</td>\n",
       "      <td>12</td>\n",
       "      <td>52</td>\n",
       "      <td>57</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.380825</td>\n",
       "      <td>0.145028</td>\n",
       "      <td>0.378488</td>\n",
       "      <td>10.224256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>DNN</td>\n",
       "      <td>1d</td>\n",
       "      <td>tanh</td>\n",
       "      <td>adadelta</td>\n",
       "      <td>0.484764</td>\n",
       "      <td>12</td>\n",
       "      <td>52</td>\n",
       "      <td>57</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.443665</td>\n",
       "      <td>0.196839</td>\n",
       "      <td>0.440807</td>\n",
       "      <td>17.952344</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>DNN</td>\n",
       "      <td>6h</td>\n",
       "      <td>tanh</td>\n",
       "      <td>adadelta</td>\n",
       "      <td>0.484764</td>\n",
       "      <td>12</td>\n",
       "      <td>52</td>\n",
       "      <td>57</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.452307</td>\n",
       "      <td>0.204582</td>\n",
       "      <td>0.449499</td>\n",
       "      <td>9.281137</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>DNN</td>\n",
       "      <td>3d</td>\n",
       "      <td>tanh</td>\n",
       "      <td>adadelta</td>\n",
       "      <td>0.484764</td>\n",
       "      <td>12</td>\n",
       "      <td>52</td>\n",
       "      <td>57</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.473704</td>\n",
       "      <td>0.224396</td>\n",
       "      <td>0.470815</td>\n",
       "      <td>44.018067</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>252 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   model sequence activationDense optimizer  dropout1  units  epochs  \\\n",
       "0    DNN       1h         sigmoid    adamax  0.118148     80      90   \n",
       "0    DNN       1h         sigmoid    adamax  0.405196     87      80   \n",
       "0    DNN       1h            tanh    adamax  0.405196     87      80   \n",
       "0    DNN       1h            tanh    adamax  0.484764     12      52   \n",
       "0    DNN       1h            tanh    adamax  0.118148     80      90   \n",
       "..   ...      ...             ...       ...       ...    ...     ...   \n",
       "0    DNN       7d            tanh  adadelta  0.484764     12      52   \n",
       "0    DNN      12h            tanh  adadelta  0.484764     12      52   \n",
       "0    DNN       1d            tanh  adadelta  0.484764     12      52   \n",
       "0    DNN       6h            tanh  adadelta  0.484764     12      52   \n",
       "0    DNN       3d            tanh  adadelta  0.484764     12      52   \n",
       "\n",
       "    batchsize  validation_split      RMSE       MSE       MAE       Time  \n",
       "0          25               0.2  0.013449  0.000181  0.005524  19.100332  \n",
       "0          31               0.2  0.013451  0.000181  0.007040  15.485010  \n",
       "0          31               0.1  0.013571  0.000184  0.007138  15.828002  \n",
       "0          57               0.1  0.013672  0.000187  0.007954   6.807474  \n",
       "0          25               0.2  0.014728  0.000217  0.009229  19.297134  \n",
       "..        ...               ...       ...       ...       ...        ...  \n",
       "0          57               0.2  0.371034  0.137667  0.368752  74.603660  \n",
       "0          57               0.2  0.380825  0.145028  0.378488  10.224256  \n",
       "0          57               0.1  0.443665  0.196839  0.440807  17.952344  \n",
       "0          57               0.2  0.452307  0.204582  0.449499   9.281137  \n",
       "0          57               0.1  0.473704  0.224396  0.470815  44.018067  \n",
       "\n",
       "[252 rows x 13 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list_results.sort_values(by=['RMSE', 'sequence'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "PAC3_03.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
