<!DOCTYPE html>
<html>
<head><meta charset="utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0">

<title>cerca_optim_lstm_gru-dos-capes</title><script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.1.10/require.min.js"></script>




<style type="text/css">
    pre { line-height: 125%; margin: 0; }
td.linenos pre { color: #000000; background-color: #f0f0f0; padding-left: 5px; padding-right: 5px; }
span.linenos { color: #000000; background-color: #f0f0f0; padding-left: 5px; padding-right: 5px; }
td.linenos pre.special { color: #000000; background-color: #ffffc0; padding-left: 5px; padding-right: 5px; }
span.linenos.special { color: #000000; background-color: #ffffc0; padding-left: 5px; padding-right: 5px; }
.highlight .hll { background-color: var(--jp-cell-editor-active-background) }
.highlight { background: var(--jp-cell-editor-background); color: var(--jp-mirror-editor-variable-color) }
.highlight .c { color: var(--jp-mirror-editor-comment-color); font-style: italic } /* Comment */
.highlight .err { color: var(--jp-mirror-editor-error-color) } /* Error */
.highlight .k { color: var(--jp-mirror-editor-keyword-color); font-weight: bold } /* Keyword */
.highlight .o { color: var(--jp-mirror-editor-operator-color); font-weight: bold } /* Operator */
.highlight .p { color: var(--jp-mirror-editor-punctuation-color) } /* Punctuation */
.highlight .ch { color: var(--jp-mirror-editor-comment-color); font-style: italic } /* Comment.Hashbang */
.highlight .cm { color: var(--jp-mirror-editor-comment-color); font-style: italic } /* Comment.Multiline */
.highlight .cp { color: var(--jp-mirror-editor-comment-color); font-style: italic } /* Comment.Preproc */
.highlight .cpf { color: var(--jp-mirror-editor-comment-color); font-style: italic } /* Comment.PreprocFile */
.highlight .c1 { color: var(--jp-mirror-editor-comment-color); font-style: italic } /* Comment.Single */
.highlight .cs { color: var(--jp-mirror-editor-comment-color); font-style: italic } /* Comment.Special */
.highlight .kc { color: var(--jp-mirror-editor-keyword-color); font-weight: bold } /* Keyword.Constant */
.highlight .kd { color: var(--jp-mirror-editor-keyword-color); font-weight: bold } /* Keyword.Declaration */
.highlight .kn { color: var(--jp-mirror-editor-keyword-color); font-weight: bold } /* Keyword.Namespace */
.highlight .kp { color: var(--jp-mirror-editor-keyword-color); font-weight: bold } /* Keyword.Pseudo */
.highlight .kr { color: var(--jp-mirror-editor-keyword-color); font-weight: bold } /* Keyword.Reserved */
.highlight .kt { color: var(--jp-mirror-editor-keyword-color); font-weight: bold } /* Keyword.Type */
.highlight .m { color: var(--jp-mirror-editor-number-color) } /* Literal.Number */
.highlight .s { color: var(--jp-mirror-editor-string-color) } /* Literal.String */
.highlight .ow { color: var(--jp-mirror-editor-operator-color); font-weight: bold } /* Operator.Word */
.highlight .w { color: var(--jp-mirror-editor-variable-color) } /* Text.Whitespace */
.highlight .mb { color: var(--jp-mirror-editor-number-color) } /* Literal.Number.Bin */
.highlight .mf { color: var(--jp-mirror-editor-number-color) } /* Literal.Number.Float */
.highlight .mh { color: var(--jp-mirror-editor-number-color) } /* Literal.Number.Hex */
.highlight .mi { color: var(--jp-mirror-editor-number-color) } /* Literal.Number.Integer */
.highlight .mo { color: var(--jp-mirror-editor-number-color) } /* Literal.Number.Oct */
.highlight .sa { color: var(--jp-mirror-editor-string-color) } /* Literal.String.Affix */
.highlight .sb { color: var(--jp-mirror-editor-string-color) } /* Literal.String.Backtick */
.highlight .sc { color: var(--jp-mirror-editor-string-color) } /* Literal.String.Char */
.highlight .dl { color: var(--jp-mirror-editor-string-color) } /* Literal.String.Delimiter */
.highlight .sd { color: var(--jp-mirror-editor-string-color) } /* Literal.String.Doc */
.highlight .s2 { color: var(--jp-mirror-editor-string-color) } /* Literal.String.Double */
.highlight .se { color: var(--jp-mirror-editor-string-color) } /* Literal.String.Escape */
.highlight .sh { color: var(--jp-mirror-editor-string-color) } /* Literal.String.Heredoc */
.highlight .si { color: var(--jp-mirror-editor-string-color) } /* Literal.String.Interpol */
.highlight .sx { color: var(--jp-mirror-editor-string-color) } /* Literal.String.Other */
.highlight .sr { color: var(--jp-mirror-editor-string-color) } /* Literal.String.Regex */
.highlight .s1 { color: var(--jp-mirror-editor-string-color) } /* Literal.String.Single */
.highlight .ss { color: var(--jp-mirror-editor-string-color) } /* Literal.String.Symbol */
.highlight .il { color: var(--jp-mirror-editor-number-color) } /* Literal.Number.Integer.Long */
  </style>



<style type="text/css">
/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

/*
 * Mozilla scrollbar styling
 */

/* use standard opaque scrollbars for most nodes */
[data-jp-theme-scrollbars='true'] {
  scrollbar-color: rgb(var(--jp-scrollbar-thumb-color))
    var(--jp-scrollbar-background-color);
}

/* for code nodes, use a transparent style of scrollbar. These selectors
 * will match lower in the tree, and so will override the above */
[data-jp-theme-scrollbars='true'] .CodeMirror-hscrollbar,
[data-jp-theme-scrollbars='true'] .CodeMirror-vscrollbar {
  scrollbar-color: rgba(var(--jp-scrollbar-thumb-color), 0.5) transparent;
}

/*
 * Webkit scrollbar styling
 */

/* use standard opaque scrollbars for most nodes */

[data-jp-theme-scrollbars='true'] ::-webkit-scrollbar,
[data-jp-theme-scrollbars='true'] ::-webkit-scrollbar-corner {
  background: var(--jp-scrollbar-background-color);
}

[data-jp-theme-scrollbars='true'] ::-webkit-scrollbar-thumb {
  background: rgb(var(--jp-scrollbar-thumb-color));
  border: var(--jp-scrollbar-thumb-margin) solid transparent;
  background-clip: content-box;
  border-radius: var(--jp-scrollbar-thumb-radius);
}

[data-jp-theme-scrollbars='true'] ::-webkit-scrollbar-track:horizontal {
  border-left: var(--jp-scrollbar-endpad) solid
    var(--jp-scrollbar-background-color);
  border-right: var(--jp-scrollbar-endpad) solid
    var(--jp-scrollbar-background-color);
}

[data-jp-theme-scrollbars='true'] ::-webkit-scrollbar-track:vertical {
  border-top: var(--jp-scrollbar-endpad) solid
    var(--jp-scrollbar-background-color);
  border-bottom: var(--jp-scrollbar-endpad) solid
    var(--jp-scrollbar-background-color);
}

/* for code nodes, use a transparent style of scrollbar */

[data-jp-theme-scrollbars='true'] .CodeMirror-hscrollbar::-webkit-scrollbar,
[data-jp-theme-scrollbars='true'] .CodeMirror-vscrollbar::-webkit-scrollbar,
[data-jp-theme-scrollbars='true']
  .CodeMirror-hscrollbar::-webkit-scrollbar-corner,
[data-jp-theme-scrollbars='true']
  .CodeMirror-vscrollbar::-webkit-scrollbar-corner {
  background-color: transparent;
}

[data-jp-theme-scrollbars='true']
  .CodeMirror-hscrollbar::-webkit-scrollbar-thumb,
[data-jp-theme-scrollbars='true']
  .CodeMirror-vscrollbar::-webkit-scrollbar-thumb {
  background: rgba(var(--jp-scrollbar-thumb-color), 0.5);
  border: var(--jp-scrollbar-thumb-margin) solid transparent;
  background-clip: content-box;
  border-radius: var(--jp-scrollbar-thumb-radius);
}

[data-jp-theme-scrollbars='true']
  .CodeMirror-hscrollbar::-webkit-scrollbar-track:horizontal {
  border-left: var(--jp-scrollbar-endpad) solid transparent;
  border-right: var(--jp-scrollbar-endpad) solid transparent;
}

[data-jp-theme-scrollbars='true']
  .CodeMirror-vscrollbar::-webkit-scrollbar-track:vertical {
  border-top: var(--jp-scrollbar-endpad) solid transparent;
  border-bottom: var(--jp-scrollbar-endpad) solid transparent;
}

/*
 * Phosphor
 */

.lm-ScrollBar[data-orientation='horizontal'] {
  min-height: 16px;
  max-height: 16px;
  min-width: 45px;
  border-top: 1px solid #a0a0a0;
}

.lm-ScrollBar[data-orientation='vertical'] {
  min-width: 16px;
  max-width: 16px;
  min-height: 45px;
  border-left: 1px solid #a0a0a0;
}

.lm-ScrollBar-button {
  background-color: #f0f0f0;
  background-position: center center;
  min-height: 15px;
  max-height: 15px;
  min-width: 15px;
  max-width: 15px;
}

.lm-ScrollBar-button:hover {
  background-color: #dadada;
}

.lm-ScrollBar-button.lm-mod-active {
  background-color: #cdcdcd;
}

.lm-ScrollBar-track {
  background: #f0f0f0;
}

.lm-ScrollBar-thumb {
  background: #cdcdcd;
}

.lm-ScrollBar-thumb:hover {
  background: #bababa;
}

.lm-ScrollBar-thumb.lm-mod-active {
  background: #a0a0a0;
}

.lm-ScrollBar[data-orientation='horizontal'] .lm-ScrollBar-thumb {
  height: 100%;
  min-width: 15px;
  border-left: 1px solid #a0a0a0;
  border-right: 1px solid #a0a0a0;
}

.lm-ScrollBar[data-orientation='vertical'] .lm-ScrollBar-thumb {
  width: 100%;
  min-height: 15px;
  border-top: 1px solid #a0a0a0;
  border-bottom: 1px solid #a0a0a0;
}

.lm-ScrollBar[data-orientation='horizontal']
  .lm-ScrollBar-button[data-action='decrement'] {
  background-image: var(--jp-icon-caret-left);
  background-size: 17px;
}

.lm-ScrollBar[data-orientation='horizontal']
  .lm-ScrollBar-button[data-action='increment'] {
  background-image: var(--jp-icon-caret-right);
  background-size: 17px;
}

.lm-ScrollBar[data-orientation='vertical']
  .lm-ScrollBar-button[data-action='decrement'] {
  background-image: var(--jp-icon-caret-up);
  background-size: 17px;
}

.lm-ScrollBar[data-orientation='vertical']
  .lm-ScrollBar-button[data-action='increment'] {
  background-image: var(--jp-icon-caret-down);
  background-size: 17px;
}

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Copyright (c) 2014-2017, PhosphorJS Contributors
|
| Distributed under the terms of the BSD 3-Clause License.
|
| The full license is in the file LICENSE, distributed with this software.
|----------------------------------------------------------------------------*/


/* <DEPRECATED> */ .p-Widget, /* </DEPRECATED> */
.lm-Widget {
  box-sizing: border-box;
  position: relative;
  overflow: hidden;
  cursor: default;
}


/* <DEPRECATED> */ .p-Widget.p-mod-hidden, /* </DEPRECATED> */
.lm-Widget.lm-mod-hidden {
  display: none !important;
}

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Copyright (c) 2014-2017, PhosphorJS Contributors
|
| Distributed under the terms of the BSD 3-Clause License.
|
| The full license is in the file LICENSE, distributed with this software.
|----------------------------------------------------------------------------*/


/* <DEPRECATED> */ .p-CommandPalette, /* </DEPRECATED> */
.lm-CommandPalette {
  display: flex;
  flex-direction: column;
  -webkit-user-select: none;
  -moz-user-select: none;
  -ms-user-select: none;
  user-select: none;
}


/* <DEPRECATED> */ .p-CommandPalette-search, /* </DEPRECATED> */
.lm-CommandPalette-search {
  flex: 0 0 auto;
}


/* <DEPRECATED> */ .p-CommandPalette-content, /* </DEPRECATED> */
.lm-CommandPalette-content {
  flex: 1 1 auto;
  margin: 0;
  padding: 0;
  min-height: 0;
  overflow: auto;
  list-style-type: none;
}


/* <DEPRECATED> */ .p-CommandPalette-header, /* </DEPRECATED> */
.lm-CommandPalette-header {
  overflow: hidden;
  white-space: nowrap;
  text-overflow: ellipsis;
}


/* <DEPRECATED> */ .p-CommandPalette-item, /* </DEPRECATED> */
.lm-CommandPalette-item {
  display: flex;
  flex-direction: row;
}


/* <DEPRECATED> */ .p-CommandPalette-itemIcon, /* </DEPRECATED> */
.lm-CommandPalette-itemIcon {
  flex: 0 0 auto;
}


/* <DEPRECATED> */ .p-CommandPalette-itemContent, /* </DEPRECATED> */
.lm-CommandPalette-itemContent {
  flex: 1 1 auto;
  overflow: hidden;
}


/* <DEPRECATED> */ .p-CommandPalette-itemShortcut, /* </DEPRECATED> */
.lm-CommandPalette-itemShortcut {
  flex: 0 0 auto;
}


/* <DEPRECATED> */ .p-CommandPalette-itemLabel, /* </DEPRECATED> */
.lm-CommandPalette-itemLabel {
  overflow: hidden;
  white-space: nowrap;
  text-overflow: ellipsis;
}

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Copyright (c) 2014-2017, PhosphorJS Contributors
|
| Distributed under the terms of the BSD 3-Clause License.
|
| The full license is in the file LICENSE, distributed with this software.
|----------------------------------------------------------------------------*/


/* <DEPRECATED> */ .p-DockPanel, /* </DEPRECATED> */
.lm-DockPanel {
  z-index: 0;
}


/* <DEPRECATED> */ .p-DockPanel-widget, /* </DEPRECATED> */
.lm-DockPanel-widget {
  z-index: 0;
}


/* <DEPRECATED> */ .p-DockPanel-tabBar, /* </DEPRECATED> */
.lm-DockPanel-tabBar {
  z-index: 1;
}


/* <DEPRECATED> */ .p-DockPanel-handle, /* </DEPRECATED> */
.lm-DockPanel-handle {
  z-index: 2;
}


/* <DEPRECATED> */ .p-DockPanel-handle.p-mod-hidden, /* </DEPRECATED> */
.lm-DockPanel-handle.lm-mod-hidden {
  display: none !important;
}


/* <DEPRECATED> */ .p-DockPanel-handle:after, /* </DEPRECATED> */
.lm-DockPanel-handle:after {
  position: absolute;
  top: 0;
  left: 0;
  width: 100%;
  height: 100%;
  content: '';
}


/* <DEPRECATED> */
.p-DockPanel-handle[data-orientation='horizontal'],
/* </DEPRECATED> */
.lm-DockPanel-handle[data-orientation='horizontal'] {
  cursor: ew-resize;
}


/* <DEPRECATED> */
.p-DockPanel-handle[data-orientation='vertical'],
/* </DEPRECATED> */
.lm-DockPanel-handle[data-orientation='vertical'] {
  cursor: ns-resize;
}


/* <DEPRECATED> */
.p-DockPanel-handle[data-orientation='horizontal']:after,
/* </DEPRECATED> */
.lm-DockPanel-handle[data-orientation='horizontal']:after {
  left: 50%;
  min-width: 8px;
  transform: translateX(-50%);
}


/* <DEPRECATED> */
.p-DockPanel-handle[data-orientation='vertical']:after,
/* </DEPRECATED> */
.lm-DockPanel-handle[data-orientation='vertical']:after {
  top: 50%;
  min-height: 8px;
  transform: translateY(-50%);
}


/* <DEPRECATED> */ .p-DockPanel-overlay, /* </DEPRECATED> */
.lm-DockPanel-overlay {
  z-index: 3;
  box-sizing: border-box;
  pointer-events: none;
}


/* <DEPRECATED> */ .p-DockPanel-overlay.p-mod-hidden, /* </DEPRECATED> */
.lm-DockPanel-overlay.lm-mod-hidden {
  display: none !important;
}

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Copyright (c) 2014-2017, PhosphorJS Contributors
|
| Distributed under the terms of the BSD 3-Clause License.
|
| The full license is in the file LICENSE, distributed with this software.
|----------------------------------------------------------------------------*/


/* <DEPRECATED> */ .p-Menu, /* </DEPRECATED> */
.lm-Menu {
  z-index: 10000;
  position: absolute;
  white-space: nowrap;
  overflow-x: hidden;
  overflow-y: auto;
  outline: none;
  -webkit-user-select: none;
  -moz-user-select: none;
  -ms-user-select: none;
  user-select: none;
}


/* <DEPRECATED> */ .p-Menu-content, /* </DEPRECATED> */
.lm-Menu-content {
  margin: 0;
  padding: 0;
  display: table;
  list-style-type: none;
}


/* <DEPRECATED> */ .p-Menu-item, /* </DEPRECATED> */
.lm-Menu-item {
  display: table-row;
}


/* <DEPRECATED> */
.p-Menu-item.p-mod-hidden,
.p-Menu-item.p-mod-collapsed,
/* </DEPRECATED> */
.lm-Menu-item.lm-mod-hidden,
.lm-Menu-item.lm-mod-collapsed {
  display: none !important;
}


/* <DEPRECATED> */
.p-Menu-itemIcon,
.p-Menu-itemSubmenuIcon,
/* </DEPRECATED> */
.lm-Menu-itemIcon,
.lm-Menu-itemSubmenuIcon {
  display: table-cell;
  text-align: center;
}


/* <DEPRECATED> */ .p-Menu-itemLabel, /* </DEPRECATED> */
.lm-Menu-itemLabel {
  display: table-cell;
  text-align: left;
}


/* <DEPRECATED> */ .p-Menu-itemShortcut, /* </DEPRECATED> */
.lm-Menu-itemShortcut {
  display: table-cell;
  text-align: right;
}

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Copyright (c) 2014-2017, PhosphorJS Contributors
|
| Distributed under the terms of the BSD 3-Clause License.
|
| The full license is in the file LICENSE, distributed with this software.
|----------------------------------------------------------------------------*/


/* <DEPRECATED> */ .p-MenuBar, /* </DEPRECATED> */
.lm-MenuBar {
  outline: none;
  -webkit-user-select: none;
  -moz-user-select: none;
  -ms-user-select: none;
  user-select: none;
}


/* <DEPRECATED> */ .p-MenuBar-content, /* </DEPRECATED> */
.lm-MenuBar-content {
  margin: 0;
  padding: 0;
  display: flex;
  flex-direction: row;
  list-style-type: none;
}


/* <DEPRECATED> */ .p--MenuBar-item, /* </DEPRECATED> */
.lm-MenuBar-item {
  box-sizing: border-box;
}


/* <DEPRECATED> */
.p-MenuBar-itemIcon,
.p-MenuBar-itemLabel,
/* </DEPRECATED> */
.lm-MenuBar-itemIcon,
.lm-MenuBar-itemLabel {
  display: inline-block;
}

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Copyright (c) 2014-2017, PhosphorJS Contributors
|
| Distributed under the terms of the BSD 3-Clause License.
|
| The full license is in the file LICENSE, distributed with this software.
|----------------------------------------------------------------------------*/


/* <DEPRECATED> */ .p-ScrollBar, /* </DEPRECATED> */
.lm-ScrollBar {
  display: flex;
  -webkit-user-select: none;
  -moz-user-select: none;
  -ms-user-select: none;
  user-select: none;
}


/* <DEPRECATED> */
.p-ScrollBar[data-orientation='horizontal'],
/* </DEPRECATED> */
.lm-ScrollBar[data-orientation='horizontal'] {
  flex-direction: row;
}


/* <DEPRECATED> */
.p-ScrollBar[data-orientation='vertical'],
/* </DEPRECATED> */
.lm-ScrollBar[data-orientation='vertical'] {
  flex-direction: column;
}


/* <DEPRECATED> */ .p-ScrollBar-button, /* </DEPRECATED> */
.lm-ScrollBar-button {
  box-sizing: border-box;
  flex: 0 0 auto;
}


/* <DEPRECATED> */ .p-ScrollBar-track, /* </DEPRECATED> */
.lm-ScrollBar-track {
  box-sizing: border-box;
  position: relative;
  overflow: hidden;
  flex: 1 1 auto;
}


/* <DEPRECATED> */ .p-ScrollBar-thumb, /* </DEPRECATED> */
.lm-ScrollBar-thumb {
  box-sizing: border-box;
  position: absolute;
}

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Copyright (c) 2014-2017, PhosphorJS Contributors
|
| Distributed under the terms of the BSD 3-Clause License.
|
| The full license is in the file LICENSE, distributed with this software.
|----------------------------------------------------------------------------*/


/* <DEPRECATED> */ .p-SplitPanel-child, /* </DEPRECATED> */
.lm-SplitPanel-child {
  z-index: 0;
}


/* <DEPRECATED> */ .p-SplitPanel-handle, /* </DEPRECATED> */
.lm-SplitPanel-handle {
  z-index: 1;
}


/* <DEPRECATED> */ .p-SplitPanel-handle.p-mod-hidden, /* </DEPRECATED> */
.lm-SplitPanel-handle.lm-mod-hidden {
  display: none !important;
}


/* <DEPRECATED> */ .p-SplitPanel-handle:after, /* </DEPRECATED> */
.lm-SplitPanel-handle:after {
  position: absolute;
  top: 0;
  left: 0;
  width: 100%;
  height: 100%;
  content: '';
}


/* <DEPRECATED> */
.p-SplitPanel[data-orientation='horizontal'] > .p-SplitPanel-handle,
/* </DEPRECATED> */
.lm-SplitPanel[data-orientation='horizontal'] > .lm-SplitPanel-handle {
  cursor: ew-resize;
}


/* <DEPRECATED> */
.p-SplitPanel[data-orientation='vertical'] > .p-SplitPanel-handle,
/* </DEPRECATED> */
.lm-SplitPanel[data-orientation='vertical'] > .lm-SplitPanel-handle {
  cursor: ns-resize;
}


/* <DEPRECATED> */
.p-SplitPanel[data-orientation='horizontal'] > .p-SplitPanel-handle:after,
/* </DEPRECATED> */
.lm-SplitPanel[data-orientation='horizontal'] > .lm-SplitPanel-handle:after {
  left: 50%;
  min-width: 8px;
  transform: translateX(-50%);
}


/* <DEPRECATED> */
.p-SplitPanel[data-orientation='vertical'] > .p-SplitPanel-handle:after,
/* </DEPRECATED> */
.lm-SplitPanel[data-orientation='vertical'] > .lm-SplitPanel-handle:after {
  top: 50%;
  min-height: 8px;
  transform: translateY(-50%);
}

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Copyright (c) 2014-2017, PhosphorJS Contributors
|
| Distributed under the terms of the BSD 3-Clause License.
|
| The full license is in the file LICENSE, distributed with this software.
|----------------------------------------------------------------------------*/


/* <DEPRECATED> */ .p-TabBar, /* </DEPRECATED> */
.lm-TabBar {
  display: flex;
  -webkit-user-select: none;
  -moz-user-select: none;
  -ms-user-select: none;
  user-select: none;
}


/* <DEPRECATED> */ .p-TabBar[data-orientation='horizontal'], /* </DEPRECATED> */
.lm-TabBar[data-orientation='horizontal'] {
  flex-direction: row;
}


/* <DEPRECATED> */ .p-TabBar[data-orientation='vertical'], /* </DEPRECATED> */
.lm-TabBar[data-orientation='vertical'] {
  flex-direction: column;
}


/* <DEPRECATED> */ .p-TabBar-content, /* </DEPRECATED> */
.lm-TabBar-content {
  margin: 0;
  padding: 0;
  display: flex;
  flex: 1 1 auto;
  list-style-type: none;
}


/* <DEPRECATED> */
.p-TabBar[data-orientation='horizontal'] > .p-TabBar-content,
/* </DEPRECATED> */
.lm-TabBar[data-orientation='horizontal'] > .lm-TabBar-content {
  flex-direction: row;
}


/* <DEPRECATED> */
.p-TabBar[data-orientation='vertical'] > .p-TabBar-content,
/* </DEPRECATED> */
.lm-TabBar[data-orientation='vertical'] > .lm-TabBar-content {
  flex-direction: column;
}


/* <DEPRECATED> */ .p-TabBar-tab, /* </DEPRECATED> */
.lm-TabBar-tab {
  display: flex;
  flex-direction: row;
  box-sizing: border-box;
  overflow: hidden;
}


/* <DEPRECATED> */
.p-TabBar-tabIcon,
.p-TabBar-tabCloseIcon,
/* </DEPRECATED> */
.lm-TabBar-tabIcon,
.lm-TabBar-tabCloseIcon {
  flex: 0 0 auto;
}


/* <DEPRECATED> */ .p-TabBar-tabLabel, /* </DEPRECATED> */
.lm-TabBar-tabLabel {
  flex: 1 1 auto;
  overflow: hidden;
  white-space: nowrap;
}


/* <DEPRECATED> */ .p-TabBar-tab.p-mod-hidden, /* </DEPRECATED> */
.lm-TabBar-tab.lm-mod-hidden {
  display: none !important;
}


/* <DEPRECATED> */ .p-TabBar.p-mod-dragging .p-TabBar-tab, /* </DEPRECATED> */
.lm-TabBar.lm-mod-dragging .lm-TabBar-tab {
  position: relative;
}


/* <DEPRECATED> */
.p-TabBar.p-mod-dragging[data-orientation='horizontal'] .p-TabBar-tab,
/* </DEPRECATED> */
.lm-TabBar.lm-mod-dragging[data-orientation='horizontal'] .lm-TabBar-tab {
  left: 0;
  transition: left 150ms ease;
}


/* <DEPRECATED> */
.p-TabBar.p-mod-dragging[data-orientation='vertical'] .p-TabBar-tab,
/* </DEPRECATED> */
.lm-TabBar.lm-mod-dragging[data-orientation='vertical'] .lm-TabBar-tab {
  top: 0;
  transition: top 150ms ease;
}


/* <DEPRECATED> */
.p-TabBar.p-mod-dragging .p-TabBar-tab.p-mod-dragging
/* </DEPRECATED> */
.lm-TabBar.lm-mod-dragging .lm-TabBar-tab.lm-mod-dragging {
  transition: none;
}

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Copyright (c) 2014-2017, PhosphorJS Contributors
|
| Distributed under the terms of the BSD 3-Clause License.
|
| The full license is in the file LICENSE, distributed with this software.
|----------------------------------------------------------------------------*/


/* <DEPRECATED> */ .p-TabPanel-tabBar, /* </DEPRECATED> */
.lm-TabPanel-tabBar {
  z-index: 1;
}


/* <DEPRECATED> */ .p-TabPanel-stackedPanel, /* </DEPRECATED> */
.lm-TabPanel-stackedPanel {
  z-index: 0;
}

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Copyright (c) 2014-2017, PhosphorJS Contributors
|
| Distributed under the terms of the BSD 3-Clause License.
|
| The full license is in the file LICENSE, distributed with this software.
|----------------------------------------------------------------------------*/

@charset "UTF-8";
/*!

Copyright 2015-present Palantir Technologies, Inc. All rights reserved.
Licensed under the Apache License, Version 2.0.

*/
html{
  -webkit-box-sizing:border-box;
          box-sizing:border-box; }

*,
*::before,
*::after{
  -webkit-box-sizing:inherit;
          box-sizing:inherit; }

body{
  text-transform:none;
  line-height:1.28581;
  letter-spacing:0;
  font-size:14px;
  font-weight:400;
  color:#182026;
  font-family:-apple-system, "BlinkMacSystemFont", "Segoe UI", "Roboto", "Oxygen", "Ubuntu", "Cantarell", "Open Sans", "Helvetica Neue", "Icons16", sans-serif; }

p{
  margin-top:0;
  margin-bottom:10px; }

small{
  font-size:12px; }

strong{
  font-weight:600; }

::-moz-selection{
  background:rgba(125, 188, 255, 0.6); }

::selection{
  background:rgba(125, 188, 255, 0.6); }
.bp3-heading{
  color:#182026;
  font-weight:600;
  margin:0 0 10px;
  padding:0; }
  .bp3-dark .bp3-heading{
    color:#f5f8fa; }

h1.bp3-heading, .bp3-running-text h1{
  line-height:40px;
  font-size:36px; }

h2.bp3-heading, .bp3-running-text h2{
  line-height:32px;
  font-size:28px; }

h3.bp3-heading, .bp3-running-text h3{
  line-height:25px;
  font-size:22px; }

h4.bp3-heading, .bp3-running-text h4{
  line-height:21px;
  font-size:18px; }

h5.bp3-heading, .bp3-running-text h5{
  line-height:19px;
  font-size:16px; }

h6.bp3-heading, .bp3-running-text h6{
  line-height:16px;
  font-size:14px; }
.bp3-ui-text{
  text-transform:none;
  line-height:1.28581;
  letter-spacing:0;
  font-size:14px;
  font-weight:400; }

.bp3-monospace-text{
  text-transform:none;
  font-family:monospace; }

.bp3-text-muted{
  color:#5c7080; }
  .bp3-dark .bp3-text-muted{
    color:#a7b6c2; }

.bp3-text-disabled{
  color:rgba(92, 112, 128, 0.6); }
  .bp3-dark .bp3-text-disabled{
    color:rgba(167, 182, 194, 0.6); }

.bp3-text-overflow-ellipsis{
  overflow:hidden;
  text-overflow:ellipsis;
  white-space:nowrap;
  word-wrap:normal; }
.bp3-running-text{
  line-height:1.5;
  font-size:14px; }
  .bp3-running-text h1{
    color:#182026;
    font-weight:600;
    margin-top:40px;
    margin-bottom:20px; }
    .bp3-dark .bp3-running-text h1{
      color:#f5f8fa; }
  .bp3-running-text h2{
    color:#182026;
    font-weight:600;
    margin-top:40px;
    margin-bottom:20px; }
    .bp3-dark .bp3-running-text h2{
      color:#f5f8fa; }
  .bp3-running-text h3{
    color:#182026;
    font-weight:600;
    margin-top:40px;
    margin-bottom:20px; }
    .bp3-dark .bp3-running-text h3{
      color:#f5f8fa; }
  .bp3-running-text h4{
    color:#182026;
    font-weight:600;
    margin-top:40px;
    margin-bottom:20px; }
    .bp3-dark .bp3-running-text h4{
      color:#f5f8fa; }
  .bp3-running-text h5{
    color:#182026;
    font-weight:600;
    margin-top:40px;
    margin-bottom:20px; }
    .bp3-dark .bp3-running-text h5{
      color:#f5f8fa; }
  .bp3-running-text h6{
    color:#182026;
    font-weight:600;
    margin-top:40px;
    margin-bottom:20px; }
    .bp3-dark .bp3-running-text h6{
      color:#f5f8fa; }
  .bp3-running-text hr{
    margin:20px 0;
    border:none;
    border-bottom:1px solid rgba(16, 22, 26, 0.15); }
    .bp3-dark .bp3-running-text hr{
      border-color:rgba(255, 255, 255, 0.15); }
  .bp3-running-text p{
    margin:0 0 10px;
    padding:0; }

.bp3-text-large{
  font-size:16px; }

.bp3-text-small{
  font-size:12px; }
a{
  text-decoration:none;
  color:#106ba3; }
  a:hover{
    cursor:pointer;
    text-decoration:underline;
    color:#106ba3; }
  a .bp3-icon, a .bp3-icon-standard, a .bp3-icon-large{
    color:inherit; }
  a code,
  .bp3-dark a code{
    color:inherit; }
  .bp3-dark a,
  .bp3-dark a:hover{
    color:#48aff0; }
    .bp3-dark a .bp3-icon, .bp3-dark a .bp3-icon-standard, .bp3-dark a .bp3-icon-large,
    .bp3-dark a:hover .bp3-icon,
    .bp3-dark a:hover .bp3-icon-standard,
    .bp3-dark a:hover .bp3-icon-large{
      color:inherit; }
.bp3-running-text code, .bp3-code{
  text-transform:none;
  font-family:monospace;
  border-radius:3px;
  -webkit-box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.2);
          box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.2);
  background:rgba(255, 255, 255, 0.7);
  padding:2px 5px;
  color:#5c7080;
  font-size:smaller; }
  .bp3-dark .bp3-running-text code, .bp3-running-text .bp3-dark code, .bp3-dark .bp3-code{
    -webkit-box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.4);
            box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.4);
    background:rgba(16, 22, 26, 0.3);
    color:#a7b6c2; }
  .bp3-running-text a > code, a > .bp3-code{
    color:#137cbd; }
    .bp3-dark .bp3-running-text a > code, .bp3-running-text .bp3-dark a > code, .bp3-dark a > .bp3-code{
      color:inherit; }

.bp3-running-text pre, .bp3-code-block{
  text-transform:none;
  font-family:monospace;
  display:block;
  margin:10px 0;
  border-radius:3px;
  -webkit-box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.15);
          box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.15);
  background:rgba(255, 255, 255, 0.7);
  padding:13px 15px 12px;
  line-height:1.4;
  color:#182026;
  font-size:13px;
  word-break:break-all;
  word-wrap:break-word; }
  .bp3-dark .bp3-running-text pre, .bp3-running-text .bp3-dark pre, .bp3-dark .bp3-code-block{
    -webkit-box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.4);
            box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.4);
    background:rgba(16, 22, 26, 0.3);
    color:#f5f8fa; }
  .bp3-running-text pre > code, .bp3-code-block > code{
    -webkit-box-shadow:none;
            box-shadow:none;
    background:none;
    padding:0;
    color:inherit;
    font-size:inherit; }

.bp3-running-text kbd, .bp3-key{
  display:-webkit-inline-box;
  display:-ms-inline-flexbox;
  display:inline-flex;
  -webkit-box-align:center;
      -ms-flex-align:center;
          align-items:center;
  -webkit-box-pack:center;
      -ms-flex-pack:center;
          justify-content:center;
  border-radius:3px;
  -webkit-box-shadow:0 0 0 1px rgba(16, 22, 26, 0.1), 0 0 0 rgba(16, 22, 26, 0), 0 1px 1px rgba(16, 22, 26, 0.2);
          box-shadow:0 0 0 1px rgba(16, 22, 26, 0.1), 0 0 0 rgba(16, 22, 26, 0), 0 1px 1px rgba(16, 22, 26, 0.2);
  background:#ffffff;
  min-width:24px;
  height:24px;
  padding:3px 6px;
  vertical-align:middle;
  line-height:24px;
  color:#5c7080;
  font-family:inherit;
  font-size:12px; }
  .bp3-running-text kbd .bp3-icon, .bp3-key .bp3-icon, .bp3-running-text kbd .bp3-icon-standard, .bp3-key .bp3-icon-standard, .bp3-running-text kbd .bp3-icon-large, .bp3-key .bp3-icon-large{
    margin-right:5px; }
  .bp3-dark .bp3-running-text kbd, .bp3-running-text .bp3-dark kbd, .bp3-dark .bp3-key{
    -webkit-box-shadow:0 0 0 1px rgba(16, 22, 26, 0.2), 0 0 0 rgba(16, 22, 26, 0), 0 1px 1px rgba(16, 22, 26, 0.4);
            box-shadow:0 0 0 1px rgba(16, 22, 26, 0.2), 0 0 0 rgba(16, 22, 26, 0), 0 1px 1px rgba(16, 22, 26, 0.4);
    background:#394b59;
    color:#a7b6c2; }
.bp3-running-text blockquote, .bp3-blockquote{
  margin:0 0 10px;
  border-left:solid 4px rgba(167, 182, 194, 0.5);
  padding:0 20px; }
  .bp3-dark .bp3-running-text blockquote, .bp3-running-text .bp3-dark blockquote, .bp3-dark .bp3-blockquote{
    border-color:rgba(115, 134, 148, 0.5); }
.bp3-running-text ul,
.bp3-running-text ol, .bp3-list{
  margin:10px 0;
  padding-left:30px; }
  .bp3-running-text ul li:not(:last-child), .bp3-running-text ol li:not(:last-child), .bp3-list li:not(:last-child){
    margin-bottom:5px; }
  .bp3-running-text ul ol, .bp3-running-text ol ol, .bp3-list ol,
  .bp3-running-text ul ul,
  .bp3-running-text ol ul,
  .bp3-list ul{
    margin-top:5px; }

.bp3-list-unstyled{
  margin:0;
  padding:0;
  list-style:none; }
  .bp3-list-unstyled li{
    padding:0; }
.bp3-rtl{
  text-align:right; }

.bp3-dark{
  color:#f5f8fa; }

:focus{
  outline:rgba(19, 124, 189, 0.6) auto 2px;
  outline-offset:2px;
  -moz-outline-radius:6px; }

.bp3-focus-disabled :focus{
  outline:none !important; }
  .bp3-focus-disabled :focus ~ .bp3-control-indicator{
    outline:none !important; }

.bp3-alert{
  max-width:400px;
  padding:20px; }

.bp3-alert-body{
  display:-webkit-box;
  display:-ms-flexbox;
  display:flex; }
  .bp3-alert-body .bp3-icon{
    margin-top:0;
    margin-right:20px;
    font-size:40px; }

.bp3-alert-footer{
  display:-webkit-box;
  display:-ms-flexbox;
  display:flex;
  -webkit-box-orient:horizontal;
  -webkit-box-direction:reverse;
      -ms-flex-direction:row-reverse;
          flex-direction:row-reverse;
  margin-top:10px; }
  .bp3-alert-footer .bp3-button{
    margin-left:10px; }
.bp3-breadcrumbs{
  display:-webkit-box;
  display:-ms-flexbox;
  display:flex;
  -ms-flex-wrap:wrap;
      flex-wrap:wrap;
  -webkit-box-align:center;
      -ms-flex-align:center;
          align-items:center;
  margin:0;
  cursor:default;
  height:30px;
  padding:0;
  list-style:none; }
  .bp3-breadcrumbs > li{
    display:-webkit-box;
    display:-ms-flexbox;
    display:flex;
    -webkit-box-align:center;
        -ms-flex-align:center;
            align-items:center; }
    .bp3-breadcrumbs > li::after{
      display:block;
      margin:0 5px;
      background:url("data:image/svg+xml,%3csvg xmlns='http://www.w3.org/2000/svg' viewBox='0 0 16 16'%3e%3cpath fill-rule='evenodd' clip-rule='evenodd' d='M10.71 7.29l-4-4a1.003 1.003 0 0 0-1.42 1.42L8.59 8 5.3 11.29c-.19.18-.3.43-.3.71a1.003 1.003 0 0 0 1.71.71l4-4c.18-.18.29-.43.29-.71 0-.28-.11-.53-.29-.71z' fill='%235C7080'/%3e%3c/svg%3e");
      width:16px;
      height:16px;
      content:""; }
    .bp3-breadcrumbs > li:last-of-type::after{
      display:none; }

.bp3-breadcrumb,
.bp3-breadcrumb-current,
.bp3-breadcrumbs-collapsed{
  display:-webkit-inline-box;
  display:-ms-inline-flexbox;
  display:inline-flex;
  -webkit-box-align:center;
      -ms-flex-align:center;
          align-items:center;
  font-size:16px; }

.bp3-breadcrumb,
.bp3-breadcrumbs-collapsed{
  color:#5c7080; }

.bp3-breadcrumb:hover{
  text-decoration:none; }

.bp3-breadcrumb.bp3-disabled{
  cursor:not-allowed;
  color:rgba(92, 112, 128, 0.6); }

.bp3-breadcrumb .bp3-icon{
  margin-right:5px; }

.bp3-breadcrumb-current{
  color:inherit;
  font-weight:600; }
  .bp3-breadcrumb-current .bp3-input{
    vertical-align:baseline;
    font-size:inherit;
    font-weight:inherit; }

.bp3-breadcrumbs-collapsed{
  margin-right:2px;
  border:none;
  border-radius:3px;
  background:#ced9e0;
  cursor:pointer;
  padding:1px 5px;
  vertical-align:text-bottom; }
  .bp3-breadcrumbs-collapsed::before{
    display:block;
    background:url("data:image/svg+xml,%3csvg xmlns='http://www.w3.org/2000/svg' viewBox='0 0 16 16'%3e%3cg fill='%235C7080'%3e%3ccircle cx='2' cy='8.03' r='2'/%3e%3ccircle cx='14' cy='8.03' r='2'/%3e%3ccircle cx='8' cy='8.03' r='2'/%3e%3c/g%3e%3c/svg%3e") center no-repeat;
    width:16px;
    height:16px;
    content:""; }
  .bp3-breadcrumbs-collapsed:hover{
    background:#bfccd6;
    text-decoration:none;
    color:#182026; }

.bp3-dark .bp3-breadcrumb,
.bp3-dark .bp3-breadcrumbs-collapsed{
  color:#a7b6c2; }

.bp3-dark .bp3-breadcrumbs > li::after{
  color:#a7b6c2; }

.bp3-dark .bp3-breadcrumb.bp3-disabled{
  color:rgba(167, 182, 194, 0.6); }

.bp3-dark .bp3-breadcrumb-current{
  color:#f5f8fa; }

.bp3-dark .bp3-breadcrumbs-collapsed{
  background:rgba(16, 22, 26, 0.4); }
  .bp3-dark .bp3-breadcrumbs-collapsed:hover{
    background:rgba(16, 22, 26, 0.6);
    color:#f5f8fa; }
.bp3-button{
  display:-webkit-inline-box;
  display:-ms-inline-flexbox;
  display:inline-flex;
  -webkit-box-orient:horizontal;
  -webkit-box-direction:normal;
      -ms-flex-direction:row;
          flex-direction:row;
  -webkit-box-align:center;
      -ms-flex-align:center;
          align-items:center;
  -webkit-box-pack:center;
      -ms-flex-pack:center;
          justify-content:center;
  border:none;
  border-radius:3px;
  cursor:pointer;
  padding:5px 10px;
  vertical-align:middle;
  text-align:left;
  font-size:14px;
  min-width:30px;
  min-height:30px; }
  .bp3-button > *{
    -webkit-box-flex:0;
        -ms-flex-positive:0;
            flex-grow:0;
    -ms-flex-negative:0;
        flex-shrink:0; }
  .bp3-button > .bp3-fill{
    -webkit-box-flex:1;
        -ms-flex-positive:1;
            flex-grow:1;
    -ms-flex-negative:1;
        flex-shrink:1; }
  .bp3-button::before,
  .bp3-button > *{
    margin-right:7px; }
  .bp3-button:empty::before,
  .bp3-button > :last-child{
    margin-right:0; }
  .bp3-button:empty{
    padding:0 !important; }
  .bp3-button:disabled, .bp3-button.bp3-disabled{
    cursor:not-allowed; }
  .bp3-button.bp3-fill{
    display:-webkit-box;
    display:-ms-flexbox;
    display:flex;
    width:100%; }
  .bp3-button.bp3-align-right,
  .bp3-align-right .bp3-button{
    text-align:right; }
  .bp3-button.bp3-align-left,
  .bp3-align-left .bp3-button{
    text-align:left; }
  .bp3-button:not([class*="bp3-intent-"]){
    -webkit-box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.2), inset 0 -1px 0 rgba(16, 22, 26, 0.1);
            box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.2), inset 0 -1px 0 rgba(16, 22, 26, 0.1);
    background-color:#f5f8fa;
    background-image:-webkit-gradient(linear, left top, left bottom, from(rgba(255, 255, 255, 0.8)), to(rgba(255, 255, 255, 0)));
    background-image:linear-gradient(to bottom, rgba(255, 255, 255, 0.8), rgba(255, 255, 255, 0));
    color:#182026; }
    .bp3-button:not([class*="bp3-intent-"]):hover{
      -webkit-box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.2), inset 0 -1px 0 rgba(16, 22, 26, 0.1);
              box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.2), inset 0 -1px 0 rgba(16, 22, 26, 0.1);
      background-clip:padding-box;
      background-color:#ebf1f5; }
    .bp3-button:not([class*="bp3-intent-"]):active, .bp3-button:not([class*="bp3-intent-"]).bp3-active{
      -webkit-box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.2), inset 0 1px 2px rgba(16, 22, 26, 0.2);
              box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.2), inset 0 1px 2px rgba(16, 22, 26, 0.2);
      background-color:#d8e1e8;
      background-image:none; }
    .bp3-button:not([class*="bp3-intent-"]):disabled, .bp3-button:not([class*="bp3-intent-"]).bp3-disabled{
      outline:none;
      -webkit-box-shadow:none;
              box-shadow:none;
      background-color:rgba(206, 217, 224, 0.5);
      background-image:none;
      cursor:not-allowed;
      color:rgba(92, 112, 128, 0.6); }
      .bp3-button:not([class*="bp3-intent-"]):disabled.bp3-active, .bp3-button:not([class*="bp3-intent-"]):disabled.bp3-active:hover, .bp3-button:not([class*="bp3-intent-"]).bp3-disabled.bp3-active, .bp3-button:not([class*="bp3-intent-"]).bp3-disabled.bp3-active:hover{
        background:rgba(206, 217, 224, 0.7); }
  .bp3-button.bp3-intent-primary{
    -webkit-box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.4), inset 0 -1px 0 rgba(16, 22, 26, 0.2);
            box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.4), inset 0 -1px 0 rgba(16, 22, 26, 0.2);
    background-color:#137cbd;
    background-image:-webkit-gradient(linear, left top, left bottom, from(rgba(255, 255, 255, 0.1)), to(rgba(255, 255, 255, 0)));
    background-image:linear-gradient(to bottom, rgba(255, 255, 255, 0.1), rgba(255, 255, 255, 0));
    color:#ffffff; }
    .bp3-button.bp3-intent-primary:hover, .bp3-button.bp3-intent-primary:active, .bp3-button.bp3-intent-primary.bp3-active{
      color:#ffffff; }
    .bp3-button.bp3-intent-primary:hover{
      -webkit-box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.4), inset 0 -1px 0 rgba(16, 22, 26, 0.2);
              box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.4), inset 0 -1px 0 rgba(16, 22, 26, 0.2);
      background-color:#106ba3; }
    .bp3-button.bp3-intent-primary:active, .bp3-button.bp3-intent-primary.bp3-active{
      -webkit-box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.4), inset 0 1px 2px rgba(16, 22, 26, 0.2);
              box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.4), inset 0 1px 2px rgba(16, 22, 26, 0.2);
      background-color:#0e5a8a;
      background-image:none; }
    .bp3-button.bp3-intent-primary:disabled, .bp3-button.bp3-intent-primary.bp3-disabled{
      border-color:transparent;
      -webkit-box-shadow:none;
              box-shadow:none;
      background-color:rgba(19, 124, 189, 0.5);
      background-image:none;
      color:rgba(255, 255, 255, 0.6); }
  .bp3-button.bp3-intent-success{
    -webkit-box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.4), inset 0 -1px 0 rgba(16, 22, 26, 0.2);
            box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.4), inset 0 -1px 0 rgba(16, 22, 26, 0.2);
    background-color:#0f9960;
    background-image:-webkit-gradient(linear, left top, left bottom, from(rgba(255, 255, 255, 0.1)), to(rgba(255, 255, 255, 0)));
    background-image:linear-gradient(to bottom, rgba(255, 255, 255, 0.1), rgba(255, 255, 255, 0));
    color:#ffffff; }
    .bp3-button.bp3-intent-success:hover, .bp3-button.bp3-intent-success:active, .bp3-button.bp3-intent-success.bp3-active{
      color:#ffffff; }
    .bp3-button.bp3-intent-success:hover{
      -webkit-box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.4), inset 0 -1px 0 rgba(16, 22, 26, 0.2);
              box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.4), inset 0 -1px 0 rgba(16, 22, 26, 0.2);
      background-color:#0d8050; }
    .bp3-button.bp3-intent-success:active, .bp3-button.bp3-intent-success.bp3-active{
      -webkit-box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.4), inset 0 1px 2px rgba(16, 22, 26, 0.2);
              box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.4), inset 0 1px 2px rgba(16, 22, 26, 0.2);
      background-color:#0a6640;
      background-image:none; }
    .bp3-button.bp3-intent-success:disabled, .bp3-button.bp3-intent-success.bp3-disabled{
      border-color:transparent;
      -webkit-box-shadow:none;
              box-shadow:none;
      background-color:rgba(15, 153, 96, 0.5);
      background-image:none;
      color:rgba(255, 255, 255, 0.6); }
  .bp3-button.bp3-intent-warning{
    -webkit-box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.4), inset 0 -1px 0 rgba(16, 22, 26, 0.2);
            box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.4), inset 0 -1px 0 rgba(16, 22, 26, 0.2);
    background-color:#d9822b;
    background-image:-webkit-gradient(linear, left top, left bottom, from(rgba(255, 255, 255, 0.1)), to(rgba(255, 255, 255, 0)));
    background-image:linear-gradient(to bottom, rgba(255, 255, 255, 0.1), rgba(255, 255, 255, 0));
    color:#ffffff; }
    .bp3-button.bp3-intent-warning:hover, .bp3-button.bp3-intent-warning:active, .bp3-button.bp3-intent-warning.bp3-active{
      color:#ffffff; }
    .bp3-button.bp3-intent-warning:hover{
      -webkit-box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.4), inset 0 -1px 0 rgba(16, 22, 26, 0.2);
              box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.4), inset 0 -1px 0 rgba(16, 22, 26, 0.2);
      background-color:#bf7326; }
    .bp3-button.bp3-intent-warning:active, .bp3-button.bp3-intent-warning.bp3-active{
      -webkit-box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.4), inset 0 1px 2px rgba(16, 22, 26, 0.2);
              box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.4), inset 0 1px 2px rgba(16, 22, 26, 0.2);
      background-color:#a66321;
      background-image:none; }
    .bp3-button.bp3-intent-warning:disabled, .bp3-button.bp3-intent-warning.bp3-disabled{
      border-color:transparent;
      -webkit-box-shadow:none;
              box-shadow:none;
      background-color:rgba(217, 130, 43, 0.5);
      background-image:none;
      color:rgba(255, 255, 255, 0.6); }
  .bp3-button.bp3-intent-danger{
    -webkit-box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.4), inset 0 -1px 0 rgba(16, 22, 26, 0.2);
            box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.4), inset 0 -1px 0 rgba(16, 22, 26, 0.2);
    background-color:#db3737;
    background-image:-webkit-gradient(linear, left top, left bottom, from(rgba(255, 255, 255, 0.1)), to(rgba(255, 255, 255, 0)));
    background-image:linear-gradient(to bottom, rgba(255, 255, 255, 0.1), rgba(255, 255, 255, 0));
    color:#ffffff; }
    .bp3-button.bp3-intent-danger:hover, .bp3-button.bp3-intent-danger:active, .bp3-button.bp3-intent-danger.bp3-active{
      color:#ffffff; }
    .bp3-button.bp3-intent-danger:hover{
      -webkit-box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.4), inset 0 -1px 0 rgba(16, 22, 26, 0.2);
              box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.4), inset 0 -1px 0 rgba(16, 22, 26, 0.2);
      background-color:#c23030; }
    .bp3-button.bp3-intent-danger:active, .bp3-button.bp3-intent-danger.bp3-active{
      -webkit-box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.4), inset 0 1px 2px rgba(16, 22, 26, 0.2);
              box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.4), inset 0 1px 2px rgba(16, 22, 26, 0.2);
      background-color:#a82a2a;
      background-image:none; }
    .bp3-button.bp3-intent-danger:disabled, .bp3-button.bp3-intent-danger.bp3-disabled{
      border-color:transparent;
      -webkit-box-shadow:none;
              box-shadow:none;
      background-color:rgba(219, 55, 55, 0.5);
      background-image:none;
      color:rgba(255, 255, 255, 0.6); }
  .bp3-button[class*="bp3-intent-"] .bp3-button-spinner .bp3-spinner-head{
    stroke:#ffffff; }
  .bp3-button.bp3-large,
  .bp3-large .bp3-button{
    min-width:40px;
    min-height:40px;
    padding:5px 15px;
    font-size:16px; }
    .bp3-button.bp3-large::before,
    .bp3-button.bp3-large > *,
    .bp3-large .bp3-button::before,
    .bp3-large .bp3-button > *{
      margin-right:10px; }
    .bp3-button.bp3-large:empty::before,
    .bp3-button.bp3-large > :last-child,
    .bp3-large .bp3-button:empty::before,
    .bp3-large .bp3-button > :last-child{
      margin-right:0; }
  .bp3-button.bp3-small,
  .bp3-small .bp3-button{
    min-width:24px;
    min-height:24px;
    padding:0 7px; }
  .bp3-button.bp3-loading{
    position:relative; }
    .bp3-button.bp3-loading[class*="bp3-icon-"]::before{
      visibility:hidden; }
    .bp3-button.bp3-loading .bp3-button-spinner{
      position:absolute;
      margin:0; }
    .bp3-button.bp3-loading > :not(.bp3-button-spinner){
      visibility:hidden; }
  .bp3-button[class*="bp3-icon-"]::before{
    line-height:1;
    font-family:"Icons16", sans-serif;
    font-size:16px;
    font-weight:400;
    font-style:normal;
    -moz-osx-font-smoothing:grayscale;
    -webkit-font-smoothing:antialiased;
    color:#5c7080; }
  .bp3-button .bp3-icon, .bp3-button .bp3-icon-standard, .bp3-button .bp3-icon-large{
    color:#5c7080; }
    .bp3-button .bp3-icon.bp3-align-right, .bp3-button .bp3-icon-standard.bp3-align-right, .bp3-button .bp3-icon-large.bp3-align-right{
      margin-left:7px; }
  .bp3-button .bp3-icon:first-child:last-child,
  .bp3-button .bp3-spinner + .bp3-icon:last-child{
    margin:0 -7px; }
  .bp3-dark .bp3-button:not([class*="bp3-intent-"]){
    -webkit-box-shadow:0 0 0 1px rgba(16, 22, 26, 0.4);
            box-shadow:0 0 0 1px rgba(16, 22, 26, 0.4);
    background-color:#394b59;
    background-image:-webkit-gradient(linear, left top, left bottom, from(rgba(255, 255, 255, 0.05)), to(rgba(255, 255, 255, 0)));
    background-image:linear-gradient(to bottom, rgba(255, 255, 255, 0.05), rgba(255, 255, 255, 0));
    color:#f5f8fa; }
    .bp3-dark .bp3-button:not([class*="bp3-intent-"]):hover, .bp3-dark .bp3-button:not([class*="bp3-intent-"]):active, .bp3-dark .bp3-button:not([class*="bp3-intent-"]).bp3-active{
      color:#f5f8fa; }
    .bp3-dark .bp3-button:not([class*="bp3-intent-"]):hover{
      -webkit-box-shadow:0 0 0 1px rgba(16, 22, 26, 0.4);
              box-shadow:0 0 0 1px rgba(16, 22, 26, 0.4);
      background-color:#30404d; }
    .bp3-dark .bp3-button:not([class*="bp3-intent-"]):active, .bp3-dark .bp3-button:not([class*="bp3-intent-"]).bp3-active{
      -webkit-box-shadow:0 0 0 1px rgba(16, 22, 26, 0.6), inset 0 1px 2px rgba(16, 22, 26, 0.2);
              box-shadow:0 0 0 1px rgba(16, 22, 26, 0.6), inset 0 1px 2px rgba(16, 22, 26, 0.2);
      background-color:#202b33;
      background-image:none; }
    .bp3-dark .bp3-button:not([class*="bp3-intent-"]):disabled, .bp3-dark .bp3-button:not([class*="bp3-intent-"]).bp3-disabled{
      -webkit-box-shadow:none;
              box-shadow:none;
      background-color:rgba(57, 75, 89, 0.5);
      background-image:none;
      color:rgba(167, 182, 194, 0.6); }
      .bp3-dark .bp3-button:not([class*="bp3-intent-"]):disabled.bp3-active, .bp3-dark .bp3-button:not([class*="bp3-intent-"]).bp3-disabled.bp3-active{
        background:rgba(57, 75, 89, 0.7); }
    .bp3-dark .bp3-button:not([class*="bp3-intent-"]) .bp3-button-spinner .bp3-spinner-head{
      background:rgba(16, 22, 26, 0.5);
      stroke:#8a9ba8; }
    .bp3-dark .bp3-button:not([class*="bp3-intent-"])[class*="bp3-icon-"]::before{
      color:#a7b6c2; }
    .bp3-dark .bp3-button:not([class*="bp3-intent-"]) .bp3-icon, .bp3-dark .bp3-button:not([class*="bp3-intent-"]) .bp3-icon-standard, .bp3-dark .bp3-button:not([class*="bp3-intent-"]) .bp3-icon-large{
      color:#a7b6c2; }
  .bp3-dark .bp3-button[class*="bp3-intent-"]{
    -webkit-box-shadow:0 0 0 1px rgba(16, 22, 26, 0.4);
            box-shadow:0 0 0 1px rgba(16, 22, 26, 0.4); }
    .bp3-dark .bp3-button[class*="bp3-intent-"]:hover{
      -webkit-box-shadow:0 0 0 1px rgba(16, 22, 26, 0.4);
              box-shadow:0 0 0 1px rgba(16, 22, 26, 0.4); }
    .bp3-dark .bp3-button[class*="bp3-intent-"]:active, .bp3-dark .bp3-button[class*="bp3-intent-"].bp3-active{
      -webkit-box-shadow:0 0 0 1px rgba(16, 22, 26, 0.4), inset 0 1px 2px rgba(16, 22, 26, 0.2);
              box-shadow:0 0 0 1px rgba(16, 22, 26, 0.4), inset 0 1px 2px rgba(16, 22, 26, 0.2); }
    .bp3-dark .bp3-button[class*="bp3-intent-"]:disabled, .bp3-dark .bp3-button[class*="bp3-intent-"].bp3-disabled{
      -webkit-box-shadow:none;
              box-shadow:none;
      background-image:none;
      color:rgba(255, 255, 255, 0.3); }
    .bp3-dark .bp3-button[class*="bp3-intent-"] .bp3-button-spinner .bp3-spinner-head{
      stroke:#8a9ba8; }
  .bp3-button:disabled::before,
  .bp3-button:disabled .bp3-icon, .bp3-button:disabled .bp3-icon-standard, .bp3-button:disabled .bp3-icon-large, .bp3-button.bp3-disabled::before,
  .bp3-button.bp3-disabled .bp3-icon, .bp3-button.bp3-disabled .bp3-icon-standard, .bp3-button.bp3-disabled .bp3-icon-large, .bp3-button[class*="bp3-intent-"]::before,
  .bp3-button[class*="bp3-intent-"] .bp3-icon, .bp3-button[class*="bp3-intent-"] .bp3-icon-standard, .bp3-button[class*="bp3-intent-"] .bp3-icon-large{
    color:inherit !important; }
  .bp3-button.bp3-minimal{
    -webkit-box-shadow:none;
            box-shadow:none;
    background:none; }
    .bp3-button.bp3-minimal:hover{
      -webkit-box-shadow:none;
              box-shadow:none;
      background:rgba(167, 182, 194, 0.3);
      text-decoration:none;
      color:#182026; }
    .bp3-button.bp3-minimal:active, .bp3-button.bp3-minimal.bp3-active{
      -webkit-box-shadow:none;
              box-shadow:none;
      background:rgba(115, 134, 148, 0.3);
      color:#182026; }
    .bp3-button.bp3-minimal:disabled, .bp3-button.bp3-minimal:disabled:hover, .bp3-button.bp3-minimal.bp3-disabled, .bp3-button.bp3-minimal.bp3-disabled:hover{
      background:none;
      cursor:not-allowed;
      color:rgba(92, 112, 128, 0.6); }
      .bp3-button.bp3-minimal:disabled.bp3-active, .bp3-button.bp3-minimal:disabled:hover.bp3-active, .bp3-button.bp3-minimal.bp3-disabled.bp3-active, .bp3-button.bp3-minimal.bp3-disabled:hover.bp3-active{
        background:rgba(115, 134, 148, 0.3); }
    .bp3-dark .bp3-button.bp3-minimal{
      -webkit-box-shadow:none;
              box-shadow:none;
      background:none;
      color:inherit; }
      .bp3-dark .bp3-button.bp3-minimal:hover, .bp3-dark .bp3-button.bp3-minimal:active, .bp3-dark .bp3-button.bp3-minimal.bp3-active{
        -webkit-box-shadow:none;
                box-shadow:none;
        background:none; }
      .bp3-dark .bp3-button.bp3-minimal:hover{
        background:rgba(138, 155, 168, 0.15); }
      .bp3-dark .bp3-button.bp3-minimal:active, .bp3-dark .bp3-button.bp3-minimal.bp3-active{
        background:rgba(138, 155, 168, 0.3);
        color:#f5f8fa; }
      .bp3-dark .bp3-button.bp3-minimal:disabled, .bp3-dark .bp3-button.bp3-minimal:disabled:hover, .bp3-dark .bp3-button.bp3-minimal.bp3-disabled, .bp3-dark .bp3-button.bp3-minimal.bp3-disabled:hover{
        background:none;
        cursor:not-allowed;
        color:rgba(167, 182, 194, 0.6); }
        .bp3-dark .bp3-button.bp3-minimal:disabled.bp3-active, .bp3-dark .bp3-button.bp3-minimal:disabled:hover.bp3-active, .bp3-dark .bp3-button.bp3-minimal.bp3-disabled.bp3-active, .bp3-dark .bp3-button.bp3-minimal.bp3-disabled:hover.bp3-active{
          background:rgba(138, 155, 168, 0.3); }
    .bp3-button.bp3-minimal.bp3-intent-primary{
      color:#106ba3; }
      .bp3-button.bp3-minimal.bp3-intent-primary:hover, .bp3-button.bp3-minimal.bp3-intent-primary:active, .bp3-button.bp3-minimal.bp3-intent-primary.bp3-active{
        -webkit-box-shadow:none;
                box-shadow:none;
        background:none;
        color:#106ba3; }
      .bp3-button.bp3-minimal.bp3-intent-primary:hover{
        background:rgba(19, 124, 189, 0.15);
        color:#106ba3; }
      .bp3-button.bp3-minimal.bp3-intent-primary:active, .bp3-button.bp3-minimal.bp3-intent-primary.bp3-active{
        background:rgba(19, 124, 189, 0.3);
        color:#106ba3; }
      .bp3-button.bp3-minimal.bp3-intent-primary:disabled, .bp3-button.bp3-minimal.bp3-intent-primary.bp3-disabled{
        background:none;
        color:rgba(16, 107, 163, 0.5); }
        .bp3-button.bp3-minimal.bp3-intent-primary:disabled.bp3-active, .bp3-button.bp3-minimal.bp3-intent-primary.bp3-disabled.bp3-active{
          background:rgba(19, 124, 189, 0.3); }
      .bp3-button.bp3-minimal.bp3-intent-primary .bp3-button-spinner .bp3-spinner-head{
        stroke:#106ba3; }
      .bp3-dark .bp3-button.bp3-minimal.bp3-intent-primary{
        color:#48aff0; }
        .bp3-dark .bp3-button.bp3-minimal.bp3-intent-primary:hover{
          background:rgba(19, 124, 189, 0.2);
          color:#48aff0; }
        .bp3-dark .bp3-button.bp3-minimal.bp3-intent-primary:active, .bp3-dark .bp3-button.bp3-minimal.bp3-intent-primary.bp3-active{
          background:rgba(19, 124, 189, 0.3);
          color:#48aff0; }
        .bp3-dark .bp3-button.bp3-minimal.bp3-intent-primary:disabled, .bp3-dark .bp3-button.bp3-minimal.bp3-intent-primary.bp3-disabled{
          background:none;
          color:rgba(72, 175, 240, 0.5); }
          .bp3-dark .bp3-button.bp3-minimal.bp3-intent-primary:disabled.bp3-active, .bp3-dark .bp3-button.bp3-minimal.bp3-intent-primary.bp3-disabled.bp3-active{
            background:rgba(19, 124, 189, 0.3); }
    .bp3-button.bp3-minimal.bp3-intent-success{
      color:#0d8050; }
      .bp3-button.bp3-minimal.bp3-intent-success:hover, .bp3-button.bp3-minimal.bp3-intent-success:active, .bp3-button.bp3-minimal.bp3-intent-success.bp3-active{
        -webkit-box-shadow:none;
                box-shadow:none;
        background:none;
        color:#0d8050; }
      .bp3-button.bp3-minimal.bp3-intent-success:hover{
        background:rgba(15, 153, 96, 0.15);
        color:#0d8050; }
      .bp3-button.bp3-minimal.bp3-intent-success:active, .bp3-button.bp3-minimal.bp3-intent-success.bp3-active{
        background:rgba(15, 153, 96, 0.3);
        color:#0d8050; }
      .bp3-button.bp3-minimal.bp3-intent-success:disabled, .bp3-button.bp3-minimal.bp3-intent-success.bp3-disabled{
        background:none;
        color:rgba(13, 128, 80, 0.5); }
        .bp3-button.bp3-minimal.bp3-intent-success:disabled.bp3-active, .bp3-button.bp3-minimal.bp3-intent-success.bp3-disabled.bp3-active{
          background:rgba(15, 153, 96, 0.3); }
      .bp3-button.bp3-minimal.bp3-intent-success .bp3-button-spinner .bp3-spinner-head{
        stroke:#0d8050; }
      .bp3-dark .bp3-button.bp3-minimal.bp3-intent-success{
        color:#3dcc91; }
        .bp3-dark .bp3-button.bp3-minimal.bp3-intent-success:hover{
          background:rgba(15, 153, 96, 0.2);
          color:#3dcc91; }
        .bp3-dark .bp3-button.bp3-minimal.bp3-intent-success:active, .bp3-dark .bp3-button.bp3-minimal.bp3-intent-success.bp3-active{
          background:rgba(15, 153, 96, 0.3);
          color:#3dcc91; }
        .bp3-dark .bp3-button.bp3-minimal.bp3-intent-success:disabled, .bp3-dark .bp3-button.bp3-minimal.bp3-intent-success.bp3-disabled{
          background:none;
          color:rgba(61, 204, 145, 0.5); }
          .bp3-dark .bp3-button.bp3-minimal.bp3-intent-success:disabled.bp3-active, .bp3-dark .bp3-button.bp3-minimal.bp3-intent-success.bp3-disabled.bp3-active{
            background:rgba(15, 153, 96, 0.3); }
    .bp3-button.bp3-minimal.bp3-intent-warning{
      color:#bf7326; }
      .bp3-button.bp3-minimal.bp3-intent-warning:hover, .bp3-button.bp3-minimal.bp3-intent-warning:active, .bp3-button.bp3-minimal.bp3-intent-warning.bp3-active{
        -webkit-box-shadow:none;
                box-shadow:none;
        background:none;
        color:#bf7326; }
      .bp3-button.bp3-minimal.bp3-intent-warning:hover{
        background:rgba(217, 130, 43, 0.15);
        color:#bf7326; }
      .bp3-button.bp3-minimal.bp3-intent-warning:active, .bp3-button.bp3-minimal.bp3-intent-warning.bp3-active{
        background:rgba(217, 130, 43, 0.3);
        color:#bf7326; }
      .bp3-button.bp3-minimal.bp3-intent-warning:disabled, .bp3-button.bp3-minimal.bp3-intent-warning.bp3-disabled{
        background:none;
        color:rgba(191, 115, 38, 0.5); }
        .bp3-button.bp3-minimal.bp3-intent-warning:disabled.bp3-active, .bp3-button.bp3-minimal.bp3-intent-warning.bp3-disabled.bp3-active{
          background:rgba(217, 130, 43, 0.3); }
      .bp3-button.bp3-minimal.bp3-intent-warning .bp3-button-spinner .bp3-spinner-head{
        stroke:#bf7326; }
      .bp3-dark .bp3-button.bp3-minimal.bp3-intent-warning{
        color:#ffb366; }
        .bp3-dark .bp3-button.bp3-minimal.bp3-intent-warning:hover{
          background:rgba(217, 130, 43, 0.2);
          color:#ffb366; }
        .bp3-dark .bp3-button.bp3-minimal.bp3-intent-warning:active, .bp3-dark .bp3-button.bp3-minimal.bp3-intent-warning.bp3-active{
          background:rgba(217, 130, 43, 0.3);
          color:#ffb366; }
        .bp3-dark .bp3-button.bp3-minimal.bp3-intent-warning:disabled, .bp3-dark .bp3-button.bp3-minimal.bp3-intent-warning.bp3-disabled{
          background:none;
          color:rgba(255, 179, 102, 0.5); }
          .bp3-dark .bp3-button.bp3-minimal.bp3-intent-warning:disabled.bp3-active, .bp3-dark .bp3-button.bp3-minimal.bp3-intent-warning.bp3-disabled.bp3-active{
            background:rgba(217, 130, 43, 0.3); }
    .bp3-button.bp3-minimal.bp3-intent-danger{
      color:#c23030; }
      .bp3-button.bp3-minimal.bp3-intent-danger:hover, .bp3-button.bp3-minimal.bp3-intent-danger:active, .bp3-button.bp3-minimal.bp3-intent-danger.bp3-active{
        -webkit-box-shadow:none;
                box-shadow:none;
        background:none;
        color:#c23030; }
      .bp3-button.bp3-minimal.bp3-intent-danger:hover{
        background:rgba(219, 55, 55, 0.15);
        color:#c23030; }
      .bp3-button.bp3-minimal.bp3-intent-danger:active, .bp3-button.bp3-minimal.bp3-intent-danger.bp3-active{
        background:rgba(219, 55, 55, 0.3);
        color:#c23030; }
      .bp3-button.bp3-minimal.bp3-intent-danger:disabled, .bp3-button.bp3-minimal.bp3-intent-danger.bp3-disabled{
        background:none;
        color:rgba(194, 48, 48, 0.5); }
        .bp3-button.bp3-minimal.bp3-intent-danger:disabled.bp3-active, .bp3-button.bp3-minimal.bp3-intent-danger.bp3-disabled.bp3-active{
          background:rgba(219, 55, 55, 0.3); }
      .bp3-button.bp3-minimal.bp3-intent-danger .bp3-button-spinner .bp3-spinner-head{
        stroke:#c23030; }
      .bp3-dark .bp3-button.bp3-minimal.bp3-intent-danger{
        color:#ff7373; }
        .bp3-dark .bp3-button.bp3-minimal.bp3-intent-danger:hover{
          background:rgba(219, 55, 55, 0.2);
          color:#ff7373; }
        .bp3-dark .bp3-button.bp3-minimal.bp3-intent-danger:active, .bp3-dark .bp3-button.bp3-minimal.bp3-intent-danger.bp3-active{
          background:rgba(219, 55, 55, 0.3);
          color:#ff7373; }
        .bp3-dark .bp3-button.bp3-minimal.bp3-intent-danger:disabled, .bp3-dark .bp3-button.bp3-minimal.bp3-intent-danger.bp3-disabled{
          background:none;
          color:rgba(255, 115, 115, 0.5); }
          .bp3-dark .bp3-button.bp3-minimal.bp3-intent-danger:disabled.bp3-active, .bp3-dark .bp3-button.bp3-minimal.bp3-intent-danger.bp3-disabled.bp3-active{
            background:rgba(219, 55, 55, 0.3); }

a.bp3-button{
  text-align:center;
  text-decoration:none;
  -webkit-transition:none;
  transition:none; }
  a.bp3-button, a.bp3-button:hover, a.bp3-button:active{
    color:#182026; }
  a.bp3-button.bp3-disabled{
    color:rgba(92, 112, 128, 0.6); }

.bp3-button-text{
  -webkit-box-flex:0;
      -ms-flex:0 1 auto;
          flex:0 1 auto; }

.bp3-button.bp3-align-left .bp3-button-text, .bp3-button.bp3-align-right .bp3-button-text,
.bp3-button-group.bp3-align-left .bp3-button-text,
.bp3-button-group.bp3-align-right .bp3-button-text{
  -webkit-box-flex:1;
      -ms-flex:1 1 auto;
          flex:1 1 auto; }
.bp3-button-group{
  display:-webkit-inline-box;
  display:-ms-inline-flexbox;
  display:inline-flex; }
  .bp3-button-group .bp3-button{
    -webkit-box-flex:0;
        -ms-flex:0 0 auto;
            flex:0 0 auto;
    position:relative;
    z-index:4; }
    .bp3-button-group .bp3-button:focus{
      z-index:5; }
    .bp3-button-group .bp3-button:hover{
      z-index:6; }
    .bp3-button-group .bp3-button:active, .bp3-button-group .bp3-button.bp3-active{
      z-index:7; }
    .bp3-button-group .bp3-button:disabled, .bp3-button-group .bp3-button.bp3-disabled{
      z-index:3; }
    .bp3-button-group .bp3-button[class*="bp3-intent-"]{
      z-index:9; }
      .bp3-button-group .bp3-button[class*="bp3-intent-"]:focus{
        z-index:10; }
      .bp3-button-group .bp3-button[class*="bp3-intent-"]:hover{
        z-index:11; }
      .bp3-button-group .bp3-button[class*="bp3-intent-"]:active, .bp3-button-group .bp3-button[class*="bp3-intent-"].bp3-active{
        z-index:12; }
      .bp3-button-group .bp3-button[class*="bp3-intent-"]:disabled, .bp3-button-group .bp3-button[class*="bp3-intent-"].bp3-disabled{
        z-index:8; }
  .bp3-button-group:not(.bp3-minimal) > .bp3-popover-wrapper:not(:first-child) .bp3-button,
  .bp3-button-group:not(.bp3-minimal) > .bp3-button:not(:first-child){
    border-top-left-radius:0;
    border-bottom-left-radius:0; }
  .bp3-button-group:not(.bp3-minimal) > .bp3-popover-wrapper:not(:last-child) .bp3-button,
  .bp3-button-group:not(.bp3-minimal) > .bp3-button:not(:last-child){
    margin-right:-1px;
    border-top-right-radius:0;
    border-bottom-right-radius:0; }
  .bp3-button-group.bp3-minimal .bp3-button{
    -webkit-box-shadow:none;
            box-shadow:none;
    background:none; }
    .bp3-button-group.bp3-minimal .bp3-button:hover{
      -webkit-box-shadow:none;
              box-shadow:none;
      background:rgba(167, 182, 194, 0.3);
      text-decoration:none;
      color:#182026; }
    .bp3-button-group.bp3-minimal .bp3-button:active, .bp3-button-group.bp3-minimal .bp3-button.bp3-active{
      -webkit-box-shadow:none;
              box-shadow:none;
      background:rgba(115, 134, 148, 0.3);
      color:#182026; }
    .bp3-button-group.bp3-minimal .bp3-button:disabled, .bp3-button-group.bp3-minimal .bp3-button:disabled:hover, .bp3-button-group.bp3-minimal .bp3-button.bp3-disabled, .bp3-button-group.bp3-minimal .bp3-button.bp3-disabled:hover{
      background:none;
      cursor:not-allowed;
      color:rgba(92, 112, 128, 0.6); }
      .bp3-button-group.bp3-minimal .bp3-button:disabled.bp3-active, .bp3-button-group.bp3-minimal .bp3-button:disabled:hover.bp3-active, .bp3-button-group.bp3-minimal .bp3-button.bp3-disabled.bp3-active, .bp3-button-group.bp3-minimal .bp3-button.bp3-disabled:hover.bp3-active{
        background:rgba(115, 134, 148, 0.3); }
    .bp3-dark .bp3-button-group.bp3-minimal .bp3-button{
      -webkit-box-shadow:none;
              box-shadow:none;
      background:none;
      color:inherit; }
      .bp3-dark .bp3-button-group.bp3-minimal .bp3-button:hover, .bp3-dark .bp3-button-group.bp3-minimal .bp3-button:active, .bp3-dark .bp3-button-group.bp3-minimal .bp3-button.bp3-active{
        -webkit-box-shadow:none;
                box-shadow:none;
        background:none; }
      .bp3-dark .bp3-button-group.bp3-minimal .bp3-button:hover{
        background:rgba(138, 155, 168, 0.15); }
      .bp3-dark .bp3-button-group.bp3-minimal .bp3-button:active, .bp3-dark .bp3-button-group.bp3-minimal .bp3-button.bp3-active{
        background:rgba(138, 155, 168, 0.3);
        color:#f5f8fa; }
      .bp3-dark .bp3-button-group.bp3-minimal .bp3-button:disabled, .bp3-dark .bp3-button-group.bp3-minimal .bp3-button:disabled:hover, .bp3-dark .bp3-button-group.bp3-minimal .bp3-button.bp3-disabled, .bp3-dark .bp3-button-group.bp3-minimal .bp3-button.bp3-disabled:hover{
        background:none;
        cursor:not-allowed;
        color:rgba(167, 182, 194, 0.6); }
        .bp3-dark .bp3-button-group.bp3-minimal .bp3-button:disabled.bp3-active, .bp3-dark .bp3-button-group.bp3-minimal .bp3-button:disabled:hover.bp3-active, .bp3-dark .bp3-button-group.bp3-minimal .bp3-button.bp3-disabled.bp3-active, .bp3-dark .bp3-button-group.bp3-minimal .bp3-button.bp3-disabled:hover.bp3-active{
          background:rgba(138, 155, 168, 0.3); }
    .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-primary{
      color:#106ba3; }
      .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-primary:hover, .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-primary:active, .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-primary.bp3-active{
        -webkit-box-shadow:none;
                box-shadow:none;
        background:none;
        color:#106ba3; }
      .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-primary:hover{
        background:rgba(19, 124, 189, 0.15);
        color:#106ba3; }
      .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-primary:active, .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-primary.bp3-active{
        background:rgba(19, 124, 189, 0.3);
        color:#106ba3; }
      .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-primary:disabled, .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-primary.bp3-disabled{
        background:none;
        color:rgba(16, 107, 163, 0.5); }
        .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-primary:disabled.bp3-active, .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-primary.bp3-disabled.bp3-active{
          background:rgba(19, 124, 189, 0.3); }
      .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-primary .bp3-button-spinner .bp3-spinner-head{
        stroke:#106ba3; }
      .bp3-dark .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-primary{
        color:#48aff0; }
        .bp3-dark .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-primary:hover{
          background:rgba(19, 124, 189, 0.2);
          color:#48aff0; }
        .bp3-dark .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-primary:active, .bp3-dark .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-primary.bp3-active{
          background:rgba(19, 124, 189, 0.3);
          color:#48aff0; }
        .bp3-dark .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-primary:disabled, .bp3-dark .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-primary.bp3-disabled{
          background:none;
          color:rgba(72, 175, 240, 0.5); }
          .bp3-dark .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-primary:disabled.bp3-active, .bp3-dark .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-primary.bp3-disabled.bp3-active{
            background:rgba(19, 124, 189, 0.3); }
    .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-success{
      color:#0d8050; }
      .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-success:hover, .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-success:active, .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-success.bp3-active{
        -webkit-box-shadow:none;
                box-shadow:none;
        background:none;
        color:#0d8050; }
      .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-success:hover{
        background:rgba(15, 153, 96, 0.15);
        color:#0d8050; }
      .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-success:active, .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-success.bp3-active{
        background:rgba(15, 153, 96, 0.3);
        color:#0d8050; }
      .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-success:disabled, .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-success.bp3-disabled{
        background:none;
        color:rgba(13, 128, 80, 0.5); }
        .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-success:disabled.bp3-active, .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-success.bp3-disabled.bp3-active{
          background:rgba(15, 153, 96, 0.3); }
      .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-success .bp3-button-spinner .bp3-spinner-head{
        stroke:#0d8050; }
      .bp3-dark .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-success{
        color:#3dcc91; }
        .bp3-dark .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-success:hover{
          background:rgba(15, 153, 96, 0.2);
          color:#3dcc91; }
        .bp3-dark .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-success:active, .bp3-dark .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-success.bp3-active{
          background:rgba(15, 153, 96, 0.3);
          color:#3dcc91; }
        .bp3-dark .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-success:disabled, .bp3-dark .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-success.bp3-disabled{
          background:none;
          color:rgba(61, 204, 145, 0.5); }
          .bp3-dark .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-success:disabled.bp3-active, .bp3-dark .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-success.bp3-disabled.bp3-active{
            background:rgba(15, 153, 96, 0.3); }
    .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-warning{
      color:#bf7326; }
      .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-warning:hover, .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-warning:active, .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-warning.bp3-active{
        -webkit-box-shadow:none;
                box-shadow:none;
        background:none;
        color:#bf7326; }
      .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-warning:hover{
        background:rgba(217, 130, 43, 0.15);
        color:#bf7326; }
      .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-warning:active, .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-warning.bp3-active{
        background:rgba(217, 130, 43, 0.3);
        color:#bf7326; }
      .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-warning:disabled, .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-warning.bp3-disabled{
        background:none;
        color:rgba(191, 115, 38, 0.5); }
        .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-warning:disabled.bp3-active, .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-warning.bp3-disabled.bp3-active{
          background:rgba(217, 130, 43, 0.3); }
      .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-warning .bp3-button-spinner .bp3-spinner-head{
        stroke:#bf7326; }
      .bp3-dark .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-warning{
        color:#ffb366; }
        .bp3-dark .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-warning:hover{
          background:rgba(217, 130, 43, 0.2);
          color:#ffb366; }
        .bp3-dark .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-warning:active, .bp3-dark .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-warning.bp3-active{
          background:rgba(217, 130, 43, 0.3);
          color:#ffb366; }
        .bp3-dark .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-warning:disabled, .bp3-dark .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-warning.bp3-disabled{
          background:none;
          color:rgba(255, 179, 102, 0.5); }
          .bp3-dark .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-warning:disabled.bp3-active, .bp3-dark .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-warning.bp3-disabled.bp3-active{
            background:rgba(217, 130, 43, 0.3); }
    .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-danger{
      color:#c23030; }
      .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-danger:hover, .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-danger:active, .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-danger.bp3-active{
        -webkit-box-shadow:none;
                box-shadow:none;
        background:none;
        color:#c23030; }
      .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-danger:hover{
        background:rgba(219, 55, 55, 0.15);
        color:#c23030; }
      .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-danger:active, .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-danger.bp3-active{
        background:rgba(219, 55, 55, 0.3);
        color:#c23030; }
      .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-danger:disabled, .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-danger.bp3-disabled{
        background:none;
        color:rgba(194, 48, 48, 0.5); }
        .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-danger:disabled.bp3-active, .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-danger.bp3-disabled.bp3-active{
          background:rgba(219, 55, 55, 0.3); }
      .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-danger .bp3-button-spinner .bp3-spinner-head{
        stroke:#c23030; }
      .bp3-dark .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-danger{
        color:#ff7373; }
        .bp3-dark .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-danger:hover{
          background:rgba(219, 55, 55, 0.2);
          color:#ff7373; }
        .bp3-dark .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-danger:active, .bp3-dark .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-danger.bp3-active{
          background:rgba(219, 55, 55, 0.3);
          color:#ff7373; }
        .bp3-dark .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-danger:disabled, .bp3-dark .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-danger.bp3-disabled{
          background:none;
          color:rgba(255, 115, 115, 0.5); }
          .bp3-dark .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-danger:disabled.bp3-active, .bp3-dark .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-danger.bp3-disabled.bp3-active{
            background:rgba(219, 55, 55, 0.3); }
  .bp3-button-group .bp3-popover-wrapper,
  .bp3-button-group .bp3-popover-target{
    display:-webkit-box;
    display:-ms-flexbox;
    display:flex;
    -webkit-box-flex:1;
        -ms-flex:1 1 auto;
            flex:1 1 auto; }
  .bp3-button-group.bp3-fill{
    display:-webkit-box;
    display:-ms-flexbox;
    display:flex;
    width:100%; }
  .bp3-button-group .bp3-button.bp3-fill,
  .bp3-button-group.bp3-fill .bp3-button:not(.bp3-fixed){
    -webkit-box-flex:1;
        -ms-flex:1 1 auto;
            flex:1 1 auto; }
  .bp3-button-group.bp3-vertical{
    -webkit-box-orient:vertical;
    -webkit-box-direction:normal;
        -ms-flex-direction:column;
            flex-direction:column;
    -webkit-box-align:stretch;
        -ms-flex-align:stretch;
            align-items:stretch;
    vertical-align:top; }
    .bp3-button-group.bp3-vertical.bp3-fill{
      width:unset;
      height:100%; }
    .bp3-button-group.bp3-vertical .bp3-button{
      margin-right:0 !important;
      width:100%; }
    .bp3-button-group.bp3-vertical:not(.bp3-minimal) > .bp3-popover-wrapper:first-child .bp3-button,
    .bp3-button-group.bp3-vertical:not(.bp3-minimal) > .bp3-button:first-child{
      border-radius:3px 3px 0 0; }
    .bp3-button-group.bp3-vertical:not(.bp3-minimal) > .bp3-popover-wrapper:last-child .bp3-button,
    .bp3-button-group.bp3-vertical:not(.bp3-minimal) > .bp3-button:last-child{
      border-radius:0 0 3px 3px; }
    .bp3-button-group.bp3-vertical:not(.bp3-minimal) > .bp3-popover-wrapper:not(:last-child) .bp3-button,
    .bp3-button-group.bp3-vertical:not(.bp3-minimal) > .bp3-button:not(:last-child){
      margin-bottom:-1px; }
  .bp3-button-group.bp3-align-left .bp3-button{
    text-align:left; }
  .bp3-dark .bp3-button-group:not(.bp3-minimal) > .bp3-popover-wrapper:not(:last-child) .bp3-button,
  .bp3-dark .bp3-button-group:not(.bp3-minimal) > .bp3-button:not(:last-child){
    margin-right:1px; }
  .bp3-dark .bp3-button-group.bp3-vertical > .bp3-popover-wrapper:not(:last-child) .bp3-button,
  .bp3-dark .bp3-button-group.bp3-vertical > .bp3-button:not(:last-child){
    margin-bottom:1px; }
.bp3-callout{
  line-height:1.5;
  font-size:14px;
  position:relative;
  border-radius:3px;
  background-color:rgba(138, 155, 168, 0.15);
  width:100%;
  padding:10px 12px 9px; }
  .bp3-callout[class*="bp3-icon-"]{
    padding-left:40px; }
    .bp3-callout[class*="bp3-icon-"]::before{
      line-height:1;
      font-family:"Icons20", sans-serif;
      font-size:20px;
      font-weight:400;
      font-style:normal;
      -moz-osx-font-smoothing:grayscale;
      -webkit-font-smoothing:antialiased;
      position:absolute;
      top:10px;
      left:10px;
      color:#5c7080; }
  .bp3-callout.bp3-callout-icon{
    padding-left:40px; }
    .bp3-callout.bp3-callout-icon > .bp3-icon:first-child{
      position:absolute;
      top:10px;
      left:10px;
      color:#5c7080; }
  .bp3-callout .bp3-heading{
    margin-top:0;
    margin-bottom:5px;
    line-height:20px; }
    .bp3-callout .bp3-heading:last-child{
      margin-bottom:0; }
  .bp3-dark .bp3-callout{
    background-color:rgba(138, 155, 168, 0.2); }
    .bp3-dark .bp3-callout[class*="bp3-icon-"]::before{
      color:#a7b6c2; }
  .bp3-callout.bp3-intent-primary{
    background-color:rgba(19, 124, 189, 0.15); }
    .bp3-callout.bp3-intent-primary[class*="bp3-icon-"]::before,
    .bp3-callout.bp3-intent-primary > .bp3-icon:first-child,
    .bp3-callout.bp3-intent-primary .bp3-heading{
      color:#106ba3; }
    .bp3-dark .bp3-callout.bp3-intent-primary{
      background-color:rgba(19, 124, 189, 0.25); }
      .bp3-dark .bp3-callout.bp3-intent-primary[class*="bp3-icon-"]::before,
      .bp3-dark .bp3-callout.bp3-intent-primary > .bp3-icon:first-child,
      .bp3-dark .bp3-callout.bp3-intent-primary .bp3-heading{
        color:#48aff0; }
  .bp3-callout.bp3-intent-success{
    background-color:rgba(15, 153, 96, 0.15); }
    .bp3-callout.bp3-intent-success[class*="bp3-icon-"]::before,
    .bp3-callout.bp3-intent-success > .bp3-icon:first-child,
    .bp3-callout.bp3-intent-success .bp3-heading{
      color:#0d8050; }
    .bp3-dark .bp3-callout.bp3-intent-success{
      background-color:rgba(15, 153, 96, 0.25); }
      .bp3-dark .bp3-callout.bp3-intent-success[class*="bp3-icon-"]::before,
      .bp3-dark .bp3-callout.bp3-intent-success > .bp3-icon:first-child,
      .bp3-dark .bp3-callout.bp3-intent-success .bp3-heading{
        color:#3dcc91; }
  .bp3-callout.bp3-intent-warning{
    background-color:rgba(217, 130, 43, 0.15); }
    .bp3-callout.bp3-intent-warning[class*="bp3-icon-"]::before,
    .bp3-callout.bp3-intent-warning > .bp3-icon:first-child,
    .bp3-callout.bp3-intent-warning .bp3-heading{
      color:#bf7326; }
    .bp3-dark .bp3-callout.bp3-intent-warning{
      background-color:rgba(217, 130, 43, 0.25); }
      .bp3-dark .bp3-callout.bp3-intent-warning[class*="bp3-icon-"]::before,
      .bp3-dark .bp3-callout.bp3-intent-warning > .bp3-icon:first-child,
      .bp3-dark .bp3-callout.bp3-intent-warning .bp3-heading{
        color:#ffb366; }
  .bp3-callout.bp3-intent-danger{
    background-color:rgba(219, 55, 55, 0.15); }
    .bp3-callout.bp3-intent-danger[class*="bp3-icon-"]::before,
    .bp3-callout.bp3-intent-danger > .bp3-icon:first-child,
    .bp3-callout.bp3-intent-danger .bp3-heading{
      color:#c23030; }
    .bp3-dark .bp3-callout.bp3-intent-danger{
      background-color:rgba(219, 55, 55, 0.25); }
      .bp3-dark .bp3-callout.bp3-intent-danger[class*="bp3-icon-"]::before,
      .bp3-dark .bp3-callout.bp3-intent-danger > .bp3-icon:first-child,
      .bp3-dark .bp3-callout.bp3-intent-danger .bp3-heading{
        color:#ff7373; }
  .bp3-running-text .bp3-callout{
    margin:20px 0; }
.bp3-card{
  border-radius:3px;
  -webkit-box-shadow:0 0 0 1px rgba(16, 22, 26, 0.15), 0 0 0 rgba(16, 22, 26, 0), 0 0 0 rgba(16, 22, 26, 0);
          box-shadow:0 0 0 1px rgba(16, 22, 26, 0.15), 0 0 0 rgba(16, 22, 26, 0), 0 0 0 rgba(16, 22, 26, 0);
  background-color:#ffffff;
  padding:20px;
  -webkit-transition:-webkit-transform 200ms cubic-bezier(0.4, 1, 0.75, 0.9), -webkit-box-shadow 200ms cubic-bezier(0.4, 1, 0.75, 0.9);
  transition:-webkit-transform 200ms cubic-bezier(0.4, 1, 0.75, 0.9), -webkit-box-shadow 200ms cubic-bezier(0.4, 1, 0.75, 0.9);
  transition:transform 200ms cubic-bezier(0.4, 1, 0.75, 0.9), box-shadow 200ms cubic-bezier(0.4, 1, 0.75, 0.9);
  transition:transform 200ms cubic-bezier(0.4, 1, 0.75, 0.9), box-shadow 200ms cubic-bezier(0.4, 1, 0.75, 0.9), -webkit-transform 200ms cubic-bezier(0.4, 1, 0.75, 0.9), -webkit-box-shadow 200ms cubic-bezier(0.4, 1, 0.75, 0.9); }
  .bp3-card.bp3-dark,
  .bp3-dark .bp3-card{
    -webkit-box-shadow:0 0 0 1px rgba(16, 22, 26, 0.4), 0 0 0 rgba(16, 22, 26, 0), 0 0 0 rgba(16, 22, 26, 0);
            box-shadow:0 0 0 1px rgba(16, 22, 26, 0.4), 0 0 0 rgba(16, 22, 26, 0), 0 0 0 rgba(16, 22, 26, 0);
    background-color:#30404d; }

.bp3-elevation-0{
  -webkit-box-shadow:0 0 0 1px rgba(16, 22, 26, 0.15), 0 0 0 rgba(16, 22, 26, 0), 0 0 0 rgba(16, 22, 26, 0);
          box-shadow:0 0 0 1px rgba(16, 22, 26, 0.15), 0 0 0 rgba(16, 22, 26, 0), 0 0 0 rgba(16, 22, 26, 0); }
  .bp3-elevation-0.bp3-dark,
  .bp3-dark .bp3-elevation-0{
    -webkit-box-shadow:0 0 0 1px rgba(16, 22, 26, 0.4), 0 0 0 rgba(16, 22, 26, 0), 0 0 0 rgba(16, 22, 26, 0);
            box-shadow:0 0 0 1px rgba(16, 22, 26, 0.4), 0 0 0 rgba(16, 22, 26, 0), 0 0 0 rgba(16, 22, 26, 0); }

.bp3-elevation-1{
  -webkit-box-shadow:0 0 0 1px rgba(16, 22, 26, 0.1), 0 0 0 rgba(16, 22, 26, 0), 0 1px 1px rgba(16, 22, 26, 0.2);
          box-shadow:0 0 0 1px rgba(16, 22, 26, 0.1), 0 0 0 rgba(16, 22, 26, 0), 0 1px 1px rgba(16, 22, 26, 0.2); }
  .bp3-elevation-1.bp3-dark,
  .bp3-dark .bp3-elevation-1{
    -webkit-box-shadow:0 0 0 1px rgba(16, 22, 26, 0.2), 0 0 0 rgba(16, 22, 26, 0), 0 1px 1px rgba(16, 22, 26, 0.4);
            box-shadow:0 0 0 1px rgba(16, 22, 26, 0.2), 0 0 0 rgba(16, 22, 26, 0), 0 1px 1px rgba(16, 22, 26, 0.4); }

.bp3-elevation-2{
  -webkit-box-shadow:0 0 0 1px rgba(16, 22, 26, 0.1), 0 1px 1px rgba(16, 22, 26, 0.2), 0 2px 6px rgba(16, 22, 26, 0.2);
          box-shadow:0 0 0 1px rgba(16, 22, 26, 0.1), 0 1px 1px rgba(16, 22, 26, 0.2), 0 2px 6px rgba(16, 22, 26, 0.2); }
  .bp3-elevation-2.bp3-dark,
  .bp3-dark .bp3-elevation-2{
    -webkit-box-shadow:0 0 0 1px rgba(16, 22, 26, 0.2), 0 1px 1px rgba(16, 22, 26, 0.4), 0 2px 6px rgba(16, 22, 26, 0.4);
            box-shadow:0 0 0 1px rgba(16, 22, 26, 0.2), 0 1px 1px rgba(16, 22, 26, 0.4), 0 2px 6px rgba(16, 22, 26, 0.4); }

.bp3-elevation-3{
  -webkit-box-shadow:0 0 0 1px rgba(16, 22, 26, 0.1), 0 2px 4px rgba(16, 22, 26, 0.2), 0 8px 24px rgba(16, 22, 26, 0.2);
          box-shadow:0 0 0 1px rgba(16, 22, 26, 0.1), 0 2px 4px rgba(16, 22, 26, 0.2), 0 8px 24px rgba(16, 22, 26, 0.2); }
  .bp3-elevation-3.bp3-dark,
  .bp3-dark .bp3-elevation-3{
    -webkit-box-shadow:0 0 0 1px rgba(16, 22, 26, 0.2), 0 2px 4px rgba(16, 22, 26, 0.4), 0 8px 24px rgba(16, 22, 26, 0.4);
            box-shadow:0 0 0 1px rgba(16, 22, 26, 0.2), 0 2px 4px rgba(16, 22, 26, 0.4), 0 8px 24px rgba(16, 22, 26, 0.4); }

.bp3-elevation-4{
  -webkit-box-shadow:0 0 0 1px rgba(16, 22, 26, 0.1), 0 4px 8px rgba(16, 22, 26, 0.2), 0 18px 46px 6px rgba(16, 22, 26, 0.2);
          box-shadow:0 0 0 1px rgba(16, 22, 26, 0.1), 0 4px 8px rgba(16, 22, 26, 0.2), 0 18px 46px 6px rgba(16, 22, 26, 0.2); }
  .bp3-elevation-4.bp3-dark,
  .bp3-dark .bp3-elevation-4{
    -webkit-box-shadow:0 0 0 1px rgba(16, 22, 26, 0.2), 0 4px 8px rgba(16, 22, 26, 0.4), 0 18px 46px 6px rgba(16, 22, 26, 0.4);
            box-shadow:0 0 0 1px rgba(16, 22, 26, 0.2), 0 4px 8px rgba(16, 22, 26, 0.4), 0 18px 46px 6px rgba(16, 22, 26, 0.4); }

.bp3-card.bp3-interactive:hover{
  -webkit-box-shadow:0 0 0 1px rgba(16, 22, 26, 0.1), 0 2px 4px rgba(16, 22, 26, 0.2), 0 8px 24px rgba(16, 22, 26, 0.2);
          box-shadow:0 0 0 1px rgba(16, 22, 26, 0.1), 0 2px 4px rgba(16, 22, 26, 0.2), 0 8px 24px rgba(16, 22, 26, 0.2);
  cursor:pointer; }
  .bp3-card.bp3-interactive:hover.bp3-dark,
  .bp3-dark .bp3-card.bp3-interactive:hover{
    -webkit-box-shadow:0 0 0 1px rgba(16, 22, 26, 0.2), 0 2px 4px rgba(16, 22, 26, 0.4), 0 8px 24px rgba(16, 22, 26, 0.4);
            box-shadow:0 0 0 1px rgba(16, 22, 26, 0.2), 0 2px 4px rgba(16, 22, 26, 0.4), 0 8px 24px rgba(16, 22, 26, 0.4); }

.bp3-card.bp3-interactive:active{
  opacity:0.9;
  -webkit-box-shadow:0 0 0 1px rgba(16, 22, 26, 0.1), 0 0 0 rgba(16, 22, 26, 0), 0 1px 1px rgba(16, 22, 26, 0.2);
          box-shadow:0 0 0 1px rgba(16, 22, 26, 0.1), 0 0 0 rgba(16, 22, 26, 0), 0 1px 1px rgba(16, 22, 26, 0.2);
  -webkit-transition-duration:0;
          transition-duration:0; }
  .bp3-card.bp3-interactive:active.bp3-dark,
  .bp3-dark .bp3-card.bp3-interactive:active{
    -webkit-box-shadow:0 0 0 1px rgba(16, 22, 26, 0.2), 0 0 0 rgba(16, 22, 26, 0), 0 1px 1px rgba(16, 22, 26, 0.4);
            box-shadow:0 0 0 1px rgba(16, 22, 26, 0.2), 0 0 0 rgba(16, 22, 26, 0), 0 1px 1px rgba(16, 22, 26, 0.4); }

.bp3-collapse{
  height:0;
  overflow-y:hidden;
  -webkit-transition:height 200ms cubic-bezier(0.4, 1, 0.75, 0.9);
  transition:height 200ms cubic-bezier(0.4, 1, 0.75, 0.9); }
  .bp3-collapse .bp3-collapse-body{
    -webkit-transition:-webkit-transform 200ms cubic-bezier(0.4, 1, 0.75, 0.9);
    transition:-webkit-transform 200ms cubic-bezier(0.4, 1, 0.75, 0.9);
    transition:transform 200ms cubic-bezier(0.4, 1, 0.75, 0.9);
    transition:transform 200ms cubic-bezier(0.4, 1, 0.75, 0.9), -webkit-transform 200ms cubic-bezier(0.4, 1, 0.75, 0.9); }
    .bp3-collapse .bp3-collapse-body[aria-hidden="true"]{
      display:none; }

.bp3-context-menu .bp3-popover-target{
  display:block; }

.bp3-context-menu-popover-target{
  position:fixed; }

.bp3-divider{
  margin:5px;
  border-right:1px solid rgba(16, 22, 26, 0.15);
  border-bottom:1px solid rgba(16, 22, 26, 0.15); }
  .bp3-dark .bp3-divider{
    border-color:rgba(16, 22, 26, 0.4); }
.bp3-dialog-container{
  opacity:1;
  -webkit-transform:scale(1);
          transform:scale(1);
  display:-webkit-box;
  display:-ms-flexbox;
  display:flex;
  -webkit-box-align:center;
      -ms-flex-align:center;
          align-items:center;
  -webkit-box-pack:center;
      -ms-flex-pack:center;
          justify-content:center;
  width:100%;
  min-height:100%;
  pointer-events:none;
  -webkit-user-select:none;
     -moz-user-select:none;
      -ms-user-select:none;
          user-select:none; }
  .bp3-dialog-container.bp3-overlay-enter > .bp3-dialog, .bp3-dialog-container.bp3-overlay-appear > .bp3-dialog{
    opacity:0;
    -webkit-transform:scale(0.5);
            transform:scale(0.5); }
  .bp3-dialog-container.bp3-overlay-enter-active > .bp3-dialog, .bp3-dialog-container.bp3-overlay-appear-active > .bp3-dialog{
    opacity:1;
    -webkit-transform:scale(1);
            transform:scale(1);
    -webkit-transition-property:opacity, -webkit-transform;
    transition-property:opacity, -webkit-transform;
    transition-property:opacity, transform;
    transition-property:opacity, transform, -webkit-transform;
    -webkit-transition-duration:300ms;
            transition-duration:300ms;
    -webkit-transition-timing-function:cubic-bezier(0.54, 1.12, 0.38, 1.11);
            transition-timing-function:cubic-bezier(0.54, 1.12, 0.38, 1.11);
    -webkit-transition-delay:0;
            transition-delay:0; }
  .bp3-dialog-container.bp3-overlay-exit > .bp3-dialog{
    opacity:1;
    -webkit-transform:scale(1);
            transform:scale(1); }
  .bp3-dialog-container.bp3-overlay-exit-active > .bp3-dialog{
    opacity:0;
    -webkit-transform:scale(0.5);
            transform:scale(0.5);
    -webkit-transition-property:opacity, -webkit-transform;
    transition-property:opacity, -webkit-transform;
    transition-property:opacity, transform;
    transition-property:opacity, transform, -webkit-transform;
    -webkit-transition-duration:300ms;
            transition-duration:300ms;
    -webkit-transition-timing-function:cubic-bezier(0.54, 1.12, 0.38, 1.11);
            transition-timing-function:cubic-bezier(0.54, 1.12, 0.38, 1.11);
    -webkit-transition-delay:0;
            transition-delay:0; }

.bp3-dialog{
  display:-webkit-box;
  display:-ms-flexbox;
  display:flex;
  -webkit-box-orient:vertical;
  -webkit-box-direction:normal;
      -ms-flex-direction:column;
          flex-direction:column;
  margin:30px 0;
  border-radius:6px;
  -webkit-box-shadow:0 0 0 1px rgba(16, 22, 26, 0.1), 0 4px 8px rgba(16, 22, 26, 0.2), 0 18px 46px 6px rgba(16, 22, 26, 0.2);
          box-shadow:0 0 0 1px rgba(16, 22, 26, 0.1), 0 4px 8px rgba(16, 22, 26, 0.2), 0 18px 46px 6px rgba(16, 22, 26, 0.2);
  background:#ebf1f5;
  width:500px;
  padding-bottom:20px;
  pointer-events:all;
  -webkit-user-select:text;
     -moz-user-select:text;
      -ms-user-select:text;
          user-select:text; }
  .bp3-dialog:focus{
    outline:0; }
  .bp3-dialog.bp3-dark,
  .bp3-dark .bp3-dialog{
    -webkit-box-shadow:0 0 0 1px rgba(16, 22, 26, 0.2), 0 4px 8px rgba(16, 22, 26, 0.4), 0 18px 46px 6px rgba(16, 22, 26, 0.4);
            box-shadow:0 0 0 1px rgba(16, 22, 26, 0.2), 0 4px 8px rgba(16, 22, 26, 0.4), 0 18px 46px 6px rgba(16, 22, 26, 0.4);
    background:#293742;
    color:#f5f8fa; }

.bp3-dialog-header{
  display:-webkit-box;
  display:-ms-flexbox;
  display:flex;
  -webkit-box-flex:0;
      -ms-flex:0 0 auto;
          flex:0 0 auto;
  -webkit-box-align:center;
      -ms-flex-align:center;
          align-items:center;
  border-radius:6px 6px 0 0;
  -webkit-box-shadow:0 1px 0 rgba(16, 22, 26, 0.15);
          box-shadow:0 1px 0 rgba(16, 22, 26, 0.15);
  background:#ffffff;
  min-height:40px;
  padding-right:5px;
  padding-left:20px; }
  .bp3-dialog-header .bp3-icon-large,
  .bp3-dialog-header .bp3-icon{
    -webkit-box-flex:0;
        -ms-flex:0 0 auto;
            flex:0 0 auto;
    margin-right:10px;
    color:#5c7080; }
  .bp3-dialog-header .bp3-heading{
    overflow:hidden;
    text-overflow:ellipsis;
    white-space:nowrap;
    word-wrap:normal;
    -webkit-box-flex:1;
        -ms-flex:1 1 auto;
            flex:1 1 auto;
    margin:0;
    line-height:inherit; }
    .bp3-dialog-header .bp3-heading:last-child{
      margin-right:20px; }
  .bp3-dark .bp3-dialog-header{
    -webkit-box-shadow:0 1px 0 rgba(16, 22, 26, 0.4);
            box-shadow:0 1px 0 rgba(16, 22, 26, 0.4);
    background:#30404d; }
    .bp3-dark .bp3-dialog-header .bp3-icon-large,
    .bp3-dark .bp3-dialog-header .bp3-icon{
      color:#a7b6c2; }

.bp3-dialog-body{
  -webkit-box-flex:1;
      -ms-flex:1 1 auto;
          flex:1 1 auto;
  margin:20px;
  line-height:18px; }

.bp3-dialog-footer{
  -webkit-box-flex:0;
      -ms-flex:0 0 auto;
          flex:0 0 auto;
  margin:0 20px; }

.bp3-dialog-footer-actions{
  display:-webkit-box;
  display:-ms-flexbox;
  display:flex;
  -webkit-box-pack:end;
      -ms-flex-pack:end;
          justify-content:flex-end; }
  .bp3-dialog-footer-actions .bp3-button{
    margin-left:10px; }
.bp3-drawer{
  display:-webkit-box;
  display:-ms-flexbox;
  display:flex;
  -webkit-box-orient:vertical;
  -webkit-box-direction:normal;
      -ms-flex-direction:column;
          flex-direction:column;
  margin:0;
  -webkit-box-shadow:0 0 0 1px rgba(16, 22, 26, 0.1), 0 4px 8px rgba(16, 22, 26, 0.2), 0 18px 46px 6px rgba(16, 22, 26, 0.2);
          box-shadow:0 0 0 1px rgba(16, 22, 26, 0.1), 0 4px 8px rgba(16, 22, 26, 0.2), 0 18px 46px 6px rgba(16, 22, 26, 0.2);
  background:#ffffff;
  padding:0; }
  .bp3-drawer:focus{
    outline:0; }
  .bp3-drawer.bp3-position-top{
    top:0;
    right:0;
    left:0;
    height:50%; }
    .bp3-drawer.bp3-position-top.bp3-overlay-enter, .bp3-drawer.bp3-position-top.bp3-overlay-appear{
      -webkit-transform:translateY(-100%);
              transform:translateY(-100%); }
    .bp3-drawer.bp3-position-top.bp3-overlay-enter-active, .bp3-drawer.bp3-position-top.bp3-overlay-appear-active{
      -webkit-transform:translateY(0);
              transform:translateY(0);
      -webkit-transition-property:-webkit-transform;
      transition-property:-webkit-transform;
      transition-property:transform;
      transition-property:transform, -webkit-transform;
      -webkit-transition-duration:200ms;
              transition-duration:200ms;
      -webkit-transition-timing-function:cubic-bezier(0.4, 1, 0.75, 0.9);
              transition-timing-function:cubic-bezier(0.4, 1, 0.75, 0.9);
      -webkit-transition-delay:0;
              transition-delay:0; }
    .bp3-drawer.bp3-position-top.bp3-overlay-exit{
      -webkit-transform:translateY(0);
              transform:translateY(0); }
    .bp3-drawer.bp3-position-top.bp3-overlay-exit-active{
      -webkit-transform:translateY(-100%);
              transform:translateY(-100%);
      -webkit-transition-property:-webkit-transform;
      transition-property:-webkit-transform;
      transition-property:transform;
      transition-property:transform, -webkit-transform;
      -webkit-transition-duration:100ms;
              transition-duration:100ms;
      -webkit-transition-timing-function:cubic-bezier(0.4, 1, 0.75, 0.9);
              transition-timing-function:cubic-bezier(0.4, 1, 0.75, 0.9);
      -webkit-transition-delay:0;
              transition-delay:0; }
  .bp3-drawer.bp3-position-bottom{
    right:0;
    bottom:0;
    left:0;
    height:50%; }
    .bp3-drawer.bp3-position-bottom.bp3-overlay-enter, .bp3-drawer.bp3-position-bottom.bp3-overlay-appear{
      -webkit-transform:translateY(100%);
              transform:translateY(100%); }
    .bp3-drawer.bp3-position-bottom.bp3-overlay-enter-active, .bp3-drawer.bp3-position-bottom.bp3-overlay-appear-active{
      -webkit-transform:translateY(0);
              transform:translateY(0);
      -webkit-transition-property:-webkit-transform;
      transition-property:-webkit-transform;
      transition-property:transform;
      transition-property:transform, -webkit-transform;
      -webkit-transition-duration:200ms;
              transition-duration:200ms;
      -webkit-transition-timing-function:cubic-bezier(0.4, 1, 0.75, 0.9);
              transition-timing-function:cubic-bezier(0.4, 1, 0.75, 0.9);
      -webkit-transition-delay:0;
              transition-delay:0; }
    .bp3-drawer.bp3-position-bottom.bp3-overlay-exit{
      -webkit-transform:translateY(0);
              transform:translateY(0); }
    .bp3-drawer.bp3-position-bottom.bp3-overlay-exit-active{
      -webkit-transform:translateY(100%);
              transform:translateY(100%);
      -webkit-transition-property:-webkit-transform;
      transition-property:-webkit-transform;
      transition-property:transform;
      transition-property:transform, -webkit-transform;
      -webkit-transition-duration:100ms;
              transition-duration:100ms;
      -webkit-transition-timing-function:cubic-bezier(0.4, 1, 0.75, 0.9);
              transition-timing-function:cubic-bezier(0.4, 1, 0.75, 0.9);
      -webkit-transition-delay:0;
              transition-delay:0; }
  .bp3-drawer.bp3-position-left{
    top:0;
    bottom:0;
    left:0;
    width:50%; }
    .bp3-drawer.bp3-position-left.bp3-overlay-enter, .bp3-drawer.bp3-position-left.bp3-overlay-appear{
      -webkit-transform:translateX(-100%);
              transform:translateX(-100%); }
    .bp3-drawer.bp3-position-left.bp3-overlay-enter-active, .bp3-drawer.bp3-position-left.bp3-overlay-appear-active{
      -webkit-transform:translateX(0);
              transform:translateX(0);
      -webkit-transition-property:-webkit-transform;
      transition-property:-webkit-transform;
      transition-property:transform;
      transition-property:transform, -webkit-transform;
      -webkit-transition-duration:200ms;
              transition-duration:200ms;
      -webkit-transition-timing-function:cubic-bezier(0.4, 1, 0.75, 0.9);
              transition-timing-function:cubic-bezier(0.4, 1, 0.75, 0.9);
      -webkit-transition-delay:0;
              transition-delay:0; }
    .bp3-drawer.bp3-position-left.bp3-overlay-exit{
      -webkit-transform:translateX(0);
              transform:translateX(0); }
    .bp3-drawer.bp3-position-left.bp3-overlay-exit-active{
      -webkit-transform:translateX(-100%);
              transform:translateX(-100%);
      -webkit-transition-property:-webkit-transform;
      transition-property:-webkit-transform;
      transition-property:transform;
      transition-property:transform, -webkit-transform;
      -webkit-transition-duration:100ms;
              transition-duration:100ms;
      -webkit-transition-timing-function:cubic-bezier(0.4, 1, 0.75, 0.9);
              transition-timing-function:cubic-bezier(0.4, 1, 0.75, 0.9);
      -webkit-transition-delay:0;
              transition-delay:0; }
  .bp3-drawer.bp3-position-right{
    top:0;
    right:0;
    bottom:0;
    width:50%; }
    .bp3-drawer.bp3-position-right.bp3-overlay-enter, .bp3-drawer.bp3-position-right.bp3-overlay-appear{
      -webkit-transform:translateX(100%);
              transform:translateX(100%); }
    .bp3-drawer.bp3-position-right.bp3-overlay-enter-active, .bp3-drawer.bp3-position-right.bp3-overlay-appear-active{
      -webkit-transform:translateX(0);
              transform:translateX(0);
      -webkit-transition-property:-webkit-transform;
      transition-property:-webkit-transform;
      transition-property:transform;
      transition-property:transform, -webkit-transform;
      -webkit-transition-duration:200ms;
              transition-duration:200ms;
      -webkit-transition-timing-function:cubic-bezier(0.4, 1, 0.75, 0.9);
              transition-timing-function:cubic-bezier(0.4, 1, 0.75, 0.9);
      -webkit-transition-delay:0;
              transition-delay:0; }
    .bp3-drawer.bp3-position-right.bp3-overlay-exit{
      -webkit-transform:translateX(0);
              transform:translateX(0); }
    .bp3-drawer.bp3-position-right.bp3-overlay-exit-active{
      -webkit-transform:translateX(100%);
              transform:translateX(100%);
      -webkit-transition-property:-webkit-transform;
      transition-property:-webkit-transform;
      transition-property:transform;
      transition-property:transform, -webkit-transform;
      -webkit-transition-duration:100ms;
              transition-duration:100ms;
      -webkit-transition-timing-function:cubic-bezier(0.4, 1, 0.75, 0.9);
              transition-timing-function:cubic-bezier(0.4, 1, 0.75, 0.9);
      -webkit-transition-delay:0;
              transition-delay:0; }
  .bp3-drawer:not(.bp3-position-top):not(.bp3-position-bottom):not(.bp3-position-left):not(
  .bp3-position-right):not(.bp3-vertical){
    top:0;
    right:0;
    bottom:0;
    width:50%; }
    .bp3-drawer:not(.bp3-position-top):not(.bp3-position-bottom):not(.bp3-position-left):not(
    .bp3-position-right):not(.bp3-vertical).bp3-overlay-enter, .bp3-drawer:not(.bp3-position-top):not(.bp3-position-bottom):not(.bp3-position-left):not(
    .bp3-position-right):not(.bp3-vertical).bp3-overlay-appear{
      -webkit-transform:translateX(100%);
              transform:translateX(100%); }
    .bp3-drawer:not(.bp3-position-top):not(.bp3-position-bottom):not(.bp3-position-left):not(
    .bp3-position-right):not(.bp3-vertical).bp3-overlay-enter-active, .bp3-drawer:not(.bp3-position-top):not(.bp3-position-bottom):not(.bp3-position-left):not(
    .bp3-position-right):not(.bp3-vertical).bp3-overlay-appear-active{
      -webkit-transform:translateX(0);
              transform:translateX(0);
      -webkit-transition-property:-webkit-transform;
      transition-property:-webkit-transform;
      transition-property:transform;
      transition-property:transform, -webkit-transform;
      -webkit-transition-duration:200ms;
              transition-duration:200ms;
      -webkit-transition-timing-function:cubic-bezier(0.4, 1, 0.75, 0.9);
              transition-timing-function:cubic-bezier(0.4, 1, 0.75, 0.9);
      -webkit-transition-delay:0;
              transition-delay:0; }
    .bp3-drawer:not(.bp3-position-top):not(.bp3-position-bottom):not(.bp3-position-left):not(
    .bp3-position-right):not(.bp3-vertical).bp3-overlay-exit{
      -webkit-transform:translateX(0);
              transform:translateX(0); }
    .bp3-drawer:not(.bp3-position-top):not(.bp3-position-bottom):not(.bp3-position-left):not(
    .bp3-position-right):not(.bp3-vertical).bp3-overlay-exit-active{
      -webkit-transform:translateX(100%);
              transform:translateX(100%);
      -webkit-transition-property:-webkit-transform;
      transition-property:-webkit-transform;
      transition-property:transform;
      transition-property:transform, -webkit-transform;
      -webkit-transition-duration:100ms;
              transition-duration:100ms;
      -webkit-transition-timing-function:cubic-bezier(0.4, 1, 0.75, 0.9);
              transition-timing-function:cubic-bezier(0.4, 1, 0.75, 0.9);
      -webkit-transition-delay:0;
              transition-delay:0; }
  .bp3-drawer:not(.bp3-position-top):not(.bp3-position-bottom):not(.bp3-position-left):not(
  .bp3-position-right).bp3-vertical{
    right:0;
    bottom:0;
    left:0;
    height:50%; }
    .bp3-drawer:not(.bp3-position-top):not(.bp3-position-bottom):not(.bp3-position-left):not(
    .bp3-position-right).bp3-vertical.bp3-overlay-enter, .bp3-drawer:not(.bp3-position-top):not(.bp3-position-bottom):not(.bp3-position-left):not(
    .bp3-position-right).bp3-vertical.bp3-overlay-appear{
      -webkit-transform:translateY(100%);
              transform:translateY(100%); }
    .bp3-drawer:not(.bp3-position-top):not(.bp3-position-bottom):not(.bp3-position-left):not(
    .bp3-position-right).bp3-vertical.bp3-overlay-enter-active, .bp3-drawer:not(.bp3-position-top):not(.bp3-position-bottom):not(.bp3-position-left):not(
    .bp3-position-right).bp3-vertical.bp3-overlay-appear-active{
      -webkit-transform:translateY(0);
              transform:translateY(0);
      -webkit-transition-property:-webkit-transform;
      transition-property:-webkit-transform;
      transition-property:transform;
      transition-property:transform, -webkit-transform;
      -webkit-transition-duration:200ms;
              transition-duration:200ms;
      -webkit-transition-timing-function:cubic-bezier(0.4, 1, 0.75, 0.9);
              transition-timing-function:cubic-bezier(0.4, 1, 0.75, 0.9);
      -webkit-transition-delay:0;
              transition-delay:0; }
    .bp3-drawer:not(.bp3-position-top):not(.bp3-position-bottom):not(.bp3-position-left):not(
    .bp3-position-right).bp3-vertical.bp3-overlay-exit{
      -webkit-transform:translateY(0);
              transform:translateY(0); }
    .bp3-drawer:not(.bp3-position-top):not(.bp3-position-bottom):not(.bp3-position-left):not(
    .bp3-position-right).bp3-vertical.bp3-overlay-exit-active{
      -webkit-transform:translateY(100%);
              transform:translateY(100%);
      -webkit-transition-property:-webkit-transform;
      transition-property:-webkit-transform;
      transition-property:transform;
      transition-property:transform, -webkit-transform;
      -webkit-transition-duration:100ms;
              transition-duration:100ms;
      -webkit-transition-timing-function:cubic-bezier(0.4, 1, 0.75, 0.9);
              transition-timing-function:cubic-bezier(0.4, 1, 0.75, 0.9);
      -webkit-transition-delay:0;
              transition-delay:0; }
  .bp3-drawer.bp3-dark,
  .bp3-dark .bp3-drawer{
    -webkit-box-shadow:0 0 0 1px rgba(16, 22, 26, 0.2), 0 4px 8px rgba(16, 22, 26, 0.4), 0 18px 46px 6px rgba(16, 22, 26, 0.4);
            box-shadow:0 0 0 1px rgba(16, 22, 26, 0.2), 0 4px 8px rgba(16, 22, 26, 0.4), 0 18px 46px 6px rgba(16, 22, 26, 0.4);
    background:#30404d;
    color:#f5f8fa; }

.bp3-drawer-header{
  display:-webkit-box;
  display:-ms-flexbox;
  display:flex;
  -webkit-box-flex:0;
      -ms-flex:0 0 auto;
          flex:0 0 auto;
  -webkit-box-align:center;
      -ms-flex-align:center;
          align-items:center;
  position:relative;
  border-radius:0;
  -webkit-box-shadow:0 1px 0 rgba(16, 22, 26, 0.15);
          box-shadow:0 1px 0 rgba(16, 22, 26, 0.15);
  min-height:40px;
  padding:5px;
  padding-left:20px; }
  .bp3-drawer-header .bp3-icon-large,
  .bp3-drawer-header .bp3-icon{
    -webkit-box-flex:0;
        -ms-flex:0 0 auto;
            flex:0 0 auto;
    margin-right:10px;
    color:#5c7080; }
  .bp3-drawer-header .bp3-heading{
    overflow:hidden;
    text-overflow:ellipsis;
    white-space:nowrap;
    word-wrap:normal;
    -webkit-box-flex:1;
        -ms-flex:1 1 auto;
            flex:1 1 auto;
    margin:0;
    line-height:inherit; }
    .bp3-drawer-header .bp3-heading:last-child{
      margin-right:20px; }
  .bp3-dark .bp3-drawer-header{
    -webkit-box-shadow:0 1px 0 rgba(16, 22, 26, 0.4);
            box-shadow:0 1px 0 rgba(16, 22, 26, 0.4); }
    .bp3-dark .bp3-drawer-header .bp3-icon-large,
    .bp3-dark .bp3-drawer-header .bp3-icon{
      color:#a7b6c2; }

.bp3-drawer-body{
  -webkit-box-flex:1;
      -ms-flex:1 1 auto;
          flex:1 1 auto;
  overflow:auto;
  line-height:18px; }

.bp3-drawer-footer{
  -webkit-box-flex:0;
      -ms-flex:0 0 auto;
          flex:0 0 auto;
  position:relative;
  -webkit-box-shadow:inset 0 1px 0 rgba(16, 22, 26, 0.15);
          box-shadow:inset 0 1px 0 rgba(16, 22, 26, 0.15);
  padding:10px 20px; }
  .bp3-dark .bp3-drawer-footer{
    -webkit-box-shadow:inset 0 1px 0 rgba(16, 22, 26, 0.4);
            box-shadow:inset 0 1px 0 rgba(16, 22, 26, 0.4); }
.bp3-editable-text{
  display:inline-block;
  position:relative;
  cursor:text;
  max-width:100%;
  vertical-align:top;
  white-space:nowrap; }
  .bp3-editable-text::before{
    position:absolute;
    top:-3px;
    right:-3px;
    bottom:-3px;
    left:-3px;
    border-radius:3px;
    content:"";
    -webkit-transition:background-color 100ms cubic-bezier(0.4, 1, 0.75, 0.9), -webkit-box-shadow 100ms cubic-bezier(0.4, 1, 0.75, 0.9);
    transition:background-color 100ms cubic-bezier(0.4, 1, 0.75, 0.9), -webkit-box-shadow 100ms cubic-bezier(0.4, 1, 0.75, 0.9);
    transition:background-color 100ms cubic-bezier(0.4, 1, 0.75, 0.9), box-shadow 100ms cubic-bezier(0.4, 1, 0.75, 0.9);
    transition:background-color 100ms cubic-bezier(0.4, 1, 0.75, 0.9), box-shadow 100ms cubic-bezier(0.4, 1, 0.75, 0.9), -webkit-box-shadow 100ms cubic-bezier(0.4, 1, 0.75, 0.9); }
  .bp3-editable-text:hover::before{
    -webkit-box-shadow:0 0 0 0 rgba(19, 124, 189, 0), 0 0 0 0 rgba(19, 124, 189, 0), inset 0 0 0 1px rgba(16, 22, 26, 0.15);
            box-shadow:0 0 0 0 rgba(19, 124, 189, 0), 0 0 0 0 rgba(19, 124, 189, 0), inset 0 0 0 1px rgba(16, 22, 26, 0.15); }
  .bp3-editable-text.bp3-editable-text-editing::before{
    -webkit-box-shadow:0 0 0 1px #137cbd, 0 0 0 3px rgba(19, 124, 189, 0.3), inset 0 1px 1px rgba(16, 22, 26, 0.2);
            box-shadow:0 0 0 1px #137cbd, 0 0 0 3px rgba(19, 124, 189, 0.3), inset 0 1px 1px rgba(16, 22, 26, 0.2);
    background-color:#ffffff; }
  .bp3-editable-text.bp3-disabled::before{
    -webkit-box-shadow:none;
            box-shadow:none; }
  .bp3-editable-text.bp3-intent-primary .bp3-editable-text-input,
  .bp3-editable-text.bp3-intent-primary .bp3-editable-text-content{
    color:#137cbd; }
  .bp3-editable-text.bp3-intent-primary:hover::before{
    -webkit-box-shadow:0 0 0 0 rgba(19, 124, 189, 0), 0 0 0 0 rgba(19, 124, 189, 0), inset 0 0 0 1px rgba(19, 124, 189, 0.4);
            box-shadow:0 0 0 0 rgba(19, 124, 189, 0), 0 0 0 0 rgba(19, 124, 189, 0), inset 0 0 0 1px rgba(19, 124, 189, 0.4); }
  .bp3-editable-text.bp3-intent-primary.bp3-editable-text-editing::before{
    -webkit-box-shadow:0 0 0 1px #137cbd, 0 0 0 3px rgba(19, 124, 189, 0.3), inset 0 1px 1px rgba(16, 22, 26, 0.2);
            box-shadow:0 0 0 1px #137cbd, 0 0 0 3px rgba(19, 124, 189, 0.3), inset 0 1px 1px rgba(16, 22, 26, 0.2); }
  .bp3-editable-text.bp3-intent-success .bp3-editable-text-input,
  .bp3-editable-text.bp3-intent-success .bp3-editable-text-content{
    color:#0f9960; }
  .bp3-editable-text.bp3-intent-success:hover::before{
    -webkit-box-shadow:0 0 0 0 rgba(15, 153, 96, 0), 0 0 0 0 rgba(15, 153, 96, 0), inset 0 0 0 1px rgba(15, 153, 96, 0.4);
            box-shadow:0 0 0 0 rgba(15, 153, 96, 0), 0 0 0 0 rgba(15, 153, 96, 0), inset 0 0 0 1px rgba(15, 153, 96, 0.4); }
  .bp3-editable-text.bp3-intent-success.bp3-editable-text-editing::before{
    -webkit-box-shadow:0 0 0 1px #0f9960, 0 0 0 3px rgba(15, 153, 96, 0.3), inset 0 1px 1px rgba(16, 22, 26, 0.2);
            box-shadow:0 0 0 1px #0f9960, 0 0 0 3px rgba(15, 153, 96, 0.3), inset 0 1px 1px rgba(16, 22, 26, 0.2); }
  .bp3-editable-text.bp3-intent-warning .bp3-editable-text-input,
  .bp3-editable-text.bp3-intent-warning .bp3-editable-text-content{
    color:#d9822b; }
  .bp3-editable-text.bp3-intent-warning:hover::before{
    -webkit-box-shadow:0 0 0 0 rgba(217, 130, 43, 0), 0 0 0 0 rgba(217, 130, 43, 0), inset 0 0 0 1px rgba(217, 130, 43, 0.4);
            box-shadow:0 0 0 0 rgba(217, 130, 43, 0), 0 0 0 0 rgba(217, 130, 43, 0), inset 0 0 0 1px rgba(217, 130, 43, 0.4); }
  .bp3-editable-text.bp3-intent-warning.bp3-editable-text-editing::before{
    -webkit-box-shadow:0 0 0 1px #d9822b, 0 0 0 3px rgba(217, 130, 43, 0.3), inset 0 1px 1px rgba(16, 22, 26, 0.2);
            box-shadow:0 0 0 1px #d9822b, 0 0 0 3px rgba(217, 130, 43, 0.3), inset 0 1px 1px rgba(16, 22, 26, 0.2); }
  .bp3-editable-text.bp3-intent-danger .bp3-editable-text-input,
  .bp3-editable-text.bp3-intent-danger .bp3-editable-text-content{
    color:#db3737; }
  .bp3-editable-text.bp3-intent-danger:hover::before{
    -webkit-box-shadow:0 0 0 0 rgba(219, 55, 55, 0), 0 0 0 0 rgba(219, 55, 55, 0), inset 0 0 0 1px rgba(219, 55, 55, 0.4);
            box-shadow:0 0 0 0 rgba(219, 55, 55, 0), 0 0 0 0 rgba(219, 55, 55, 0), inset 0 0 0 1px rgba(219, 55, 55, 0.4); }
  .bp3-editable-text.bp3-intent-danger.bp3-editable-text-editing::before{
    -webkit-box-shadow:0 0 0 1px #db3737, 0 0 0 3px rgba(219, 55, 55, 0.3), inset 0 1px 1px rgba(16, 22, 26, 0.2);
            box-shadow:0 0 0 1px #db3737, 0 0 0 3px rgba(219, 55, 55, 0.3), inset 0 1px 1px rgba(16, 22, 26, 0.2); }
  .bp3-dark .bp3-editable-text:hover::before{
    -webkit-box-shadow:0 0 0 0 rgba(19, 124, 189, 0), 0 0 0 0 rgba(19, 124, 189, 0), inset 0 0 0 1px rgba(255, 255, 255, 0.15);
            box-shadow:0 0 0 0 rgba(19, 124, 189, 0), 0 0 0 0 rgba(19, 124, 189, 0), inset 0 0 0 1px rgba(255, 255, 255, 0.15); }
  .bp3-dark .bp3-editable-text.bp3-editable-text-editing::before{
    -webkit-box-shadow:0 0 0 1px #137cbd, 0 0 0 3px rgba(19, 124, 189, 0.3), inset 0 0 0 1px rgba(16, 22, 26, 0.3), inset 0 1px 1px rgba(16, 22, 26, 0.4);
            box-shadow:0 0 0 1px #137cbd, 0 0 0 3px rgba(19, 124, 189, 0.3), inset 0 0 0 1px rgba(16, 22, 26, 0.3), inset 0 1px 1px rgba(16, 22, 26, 0.4);
    background-color:rgba(16, 22, 26, 0.3); }
  .bp3-dark .bp3-editable-text.bp3-disabled::before{
    -webkit-box-shadow:none;
            box-shadow:none; }
  .bp3-dark .bp3-editable-text.bp3-intent-primary .bp3-editable-text-content{
    color:#48aff0; }
  .bp3-dark .bp3-editable-text.bp3-intent-primary:hover::before{
    -webkit-box-shadow:0 0 0 0 rgba(72, 175, 240, 0), 0 0 0 0 rgba(72, 175, 240, 0), inset 0 0 0 1px rgba(72, 175, 240, 0.4);
            box-shadow:0 0 0 0 rgba(72, 175, 240, 0), 0 0 0 0 rgba(72, 175, 240, 0), inset 0 0 0 1px rgba(72, 175, 240, 0.4); }
  .bp3-dark .bp3-editable-text.bp3-intent-primary.bp3-editable-text-editing::before{
    -webkit-box-shadow:0 0 0 1px #48aff0, 0 0 0 3px rgba(72, 175, 240, 0.3), inset 0 0 0 1px rgba(16, 22, 26, 0.3), inset 0 1px 1px rgba(16, 22, 26, 0.4);
            box-shadow:0 0 0 1px #48aff0, 0 0 0 3px rgba(72, 175, 240, 0.3), inset 0 0 0 1px rgba(16, 22, 26, 0.3), inset 0 1px 1px rgba(16, 22, 26, 0.4); }
  .bp3-dark .bp3-editable-text.bp3-intent-success .bp3-editable-text-content{
    color:#3dcc91; }
  .bp3-dark .bp3-editable-text.bp3-intent-success:hover::before{
    -webkit-box-shadow:0 0 0 0 rgba(61, 204, 145, 0), 0 0 0 0 rgba(61, 204, 145, 0), inset 0 0 0 1px rgba(61, 204, 145, 0.4);
            box-shadow:0 0 0 0 rgba(61, 204, 145, 0), 0 0 0 0 rgba(61, 204, 145, 0), inset 0 0 0 1px rgba(61, 204, 145, 0.4); }
  .bp3-dark .bp3-editable-text.bp3-intent-success.bp3-editable-text-editing::before{
    -webkit-box-shadow:0 0 0 1px #3dcc91, 0 0 0 3px rgba(61, 204, 145, 0.3), inset 0 0 0 1px rgba(16, 22, 26, 0.3), inset 0 1px 1px rgba(16, 22, 26, 0.4);
            box-shadow:0 0 0 1px #3dcc91, 0 0 0 3px rgba(61, 204, 145, 0.3), inset 0 0 0 1px rgba(16, 22, 26, 0.3), inset 0 1px 1px rgba(16, 22, 26, 0.4); }
  .bp3-dark .bp3-editable-text.bp3-intent-warning .bp3-editable-text-content{
    color:#ffb366; }
  .bp3-dark .bp3-editable-text.bp3-intent-warning:hover::before{
    -webkit-box-shadow:0 0 0 0 rgba(255, 179, 102, 0), 0 0 0 0 rgba(255, 179, 102, 0), inset 0 0 0 1px rgba(255, 179, 102, 0.4);
            box-shadow:0 0 0 0 rgba(255, 179, 102, 0), 0 0 0 0 rgba(255, 179, 102, 0), inset 0 0 0 1px rgba(255, 179, 102, 0.4); }
  .bp3-dark .bp3-editable-text.bp3-intent-warning.bp3-editable-text-editing::before{
    -webkit-box-shadow:0 0 0 1px #ffb366, 0 0 0 3px rgba(255, 179, 102, 0.3), inset 0 0 0 1px rgba(16, 22, 26, 0.3), inset 0 1px 1px rgba(16, 22, 26, 0.4);
            box-shadow:0 0 0 1px #ffb366, 0 0 0 3px rgba(255, 179, 102, 0.3), inset 0 0 0 1px rgba(16, 22, 26, 0.3), inset 0 1px 1px rgba(16, 22, 26, 0.4); }
  .bp3-dark .bp3-editable-text.bp3-intent-danger .bp3-editable-text-content{
    color:#ff7373; }
  .bp3-dark .bp3-editable-text.bp3-intent-danger:hover::before{
    -webkit-box-shadow:0 0 0 0 rgba(255, 115, 115, 0), 0 0 0 0 rgba(255, 115, 115, 0), inset 0 0 0 1px rgba(255, 115, 115, 0.4);
            box-shadow:0 0 0 0 rgba(255, 115, 115, 0), 0 0 0 0 rgba(255, 115, 115, 0), inset 0 0 0 1px rgba(255, 115, 115, 0.4); }
  .bp3-dark .bp3-editable-text.bp3-intent-danger.bp3-editable-text-editing::before{
    -webkit-box-shadow:0 0 0 1px #ff7373, 0 0 0 3px rgba(255, 115, 115, 0.3), inset 0 0 0 1px rgba(16, 22, 26, 0.3), inset 0 1px 1px rgba(16, 22, 26, 0.4);
            box-shadow:0 0 0 1px #ff7373, 0 0 0 3px rgba(255, 115, 115, 0.3), inset 0 0 0 1px rgba(16, 22, 26, 0.3), inset 0 1px 1px rgba(16, 22, 26, 0.4); }

.bp3-editable-text-input,
.bp3-editable-text-content{
  display:inherit;
  position:relative;
  min-width:inherit;
  max-width:inherit;
  vertical-align:top;
  text-transform:inherit;
  letter-spacing:inherit;
  color:inherit;
  font:inherit;
  resize:none; }

.bp3-editable-text-input{
  border:none;
  -webkit-box-shadow:none;
          box-shadow:none;
  background:none;
  width:100%;
  padding:0;
  white-space:pre-wrap; }
  .bp3-editable-text-input::-webkit-input-placeholder{
    opacity:1;
    color:rgba(92, 112, 128, 0.6); }
  .bp3-editable-text-input::-moz-placeholder{
    opacity:1;
    color:rgba(92, 112, 128, 0.6); }
  .bp3-editable-text-input:-ms-input-placeholder{
    opacity:1;
    color:rgba(92, 112, 128, 0.6); }
  .bp3-editable-text-input::-ms-input-placeholder{
    opacity:1;
    color:rgba(92, 112, 128, 0.6); }
  .bp3-editable-text-input::placeholder{
    opacity:1;
    color:rgba(92, 112, 128, 0.6); }
  .bp3-editable-text-input:focus{
    outline:none; }
  .bp3-editable-text-input::-ms-clear{
    display:none; }

.bp3-editable-text-content{
  overflow:hidden;
  padding-right:2px;
  text-overflow:ellipsis;
  white-space:pre; }
  .bp3-editable-text-editing > .bp3-editable-text-content{
    position:absolute;
    left:0;
    visibility:hidden; }
  .bp3-editable-text-placeholder > .bp3-editable-text-content{
    color:rgba(92, 112, 128, 0.6); }
    .bp3-dark .bp3-editable-text-placeholder > .bp3-editable-text-content{
      color:rgba(167, 182, 194, 0.6); }

.bp3-editable-text.bp3-multiline{
  display:block; }
  .bp3-editable-text.bp3-multiline .bp3-editable-text-content{
    overflow:auto;
    white-space:pre-wrap;
    word-wrap:break-word; }
.bp3-control-group{
  -webkit-transform:translateZ(0);
          transform:translateZ(0);
  display:-webkit-box;
  display:-ms-flexbox;
  display:flex;
  -webkit-box-orient:horizontal;
  -webkit-box-direction:normal;
      -ms-flex-direction:row;
          flex-direction:row;
  -webkit-box-align:stretch;
      -ms-flex-align:stretch;
          align-items:stretch; }
  .bp3-control-group > *{
    -webkit-box-flex:0;
        -ms-flex-positive:0;
            flex-grow:0;
    -ms-flex-negative:0;
        flex-shrink:0; }
  .bp3-control-group > .bp3-fill{
    -webkit-box-flex:1;
        -ms-flex-positive:1;
            flex-grow:1;
    -ms-flex-negative:1;
        flex-shrink:1; }
  .bp3-control-group .bp3-button,
  .bp3-control-group .bp3-html-select,
  .bp3-control-group .bp3-input,
  .bp3-control-group .bp3-select{
    position:relative; }
  .bp3-control-group .bp3-input{
    z-index:2;
    border-radius:inherit; }
    .bp3-control-group .bp3-input:focus{
      z-index:14;
      border-radius:3px; }
    .bp3-control-group .bp3-input[class*="bp3-intent"]{
      z-index:13; }
      .bp3-control-group .bp3-input[class*="bp3-intent"]:focus{
        z-index:15; }
    .bp3-control-group .bp3-input[readonly], .bp3-control-group .bp3-input:disabled, .bp3-control-group .bp3-input.bp3-disabled{
      z-index:1; }
  .bp3-control-group .bp3-input-group[class*="bp3-intent"] .bp3-input{
    z-index:13; }
    .bp3-control-group .bp3-input-group[class*="bp3-intent"] .bp3-input:focus{
      z-index:15; }
  .bp3-control-group .bp3-button,
  .bp3-control-group .bp3-html-select select,
  .bp3-control-group .bp3-select select{
    -webkit-transform:translateZ(0);
            transform:translateZ(0);
    z-index:4;
    border-radius:inherit; }
    .bp3-control-group .bp3-button:focus,
    .bp3-control-group .bp3-html-select select:focus,
    .bp3-control-group .bp3-select select:focus{
      z-index:5; }
    .bp3-control-group .bp3-button:hover,
    .bp3-control-group .bp3-html-select select:hover,
    .bp3-control-group .bp3-select select:hover{
      z-index:6; }
    .bp3-control-group .bp3-button:active,
    .bp3-control-group .bp3-html-select select:active,
    .bp3-control-group .bp3-select select:active{
      z-index:7; }
    .bp3-control-group .bp3-button[readonly], .bp3-control-group .bp3-button:disabled, .bp3-control-group .bp3-button.bp3-disabled,
    .bp3-control-group .bp3-html-select select[readonly],
    .bp3-control-group .bp3-html-select select:disabled,
    .bp3-control-group .bp3-html-select select.bp3-disabled,
    .bp3-control-group .bp3-select select[readonly],
    .bp3-control-group .bp3-select select:disabled,
    .bp3-control-group .bp3-select select.bp3-disabled{
      z-index:3; }
    .bp3-control-group .bp3-button[class*="bp3-intent"],
    .bp3-control-group .bp3-html-select select[class*="bp3-intent"],
    .bp3-control-group .bp3-select select[class*="bp3-intent"]{
      z-index:9; }
      .bp3-control-group .bp3-button[class*="bp3-intent"]:focus,
      .bp3-control-group .bp3-html-select select[class*="bp3-intent"]:focus,
      .bp3-control-group .bp3-select select[class*="bp3-intent"]:focus{
        z-index:10; }
      .bp3-control-group .bp3-button[class*="bp3-intent"]:hover,
      .bp3-control-group .bp3-html-select select[class*="bp3-intent"]:hover,
      .bp3-control-group .bp3-select select[class*="bp3-intent"]:hover{
        z-index:11; }
      .bp3-control-group .bp3-button[class*="bp3-intent"]:active,
      .bp3-control-group .bp3-html-select select[class*="bp3-intent"]:active,
      .bp3-control-group .bp3-select select[class*="bp3-intent"]:active{
        z-index:12; }
      .bp3-control-group .bp3-button[class*="bp3-intent"][readonly], .bp3-control-group .bp3-button[class*="bp3-intent"]:disabled, .bp3-control-group .bp3-button[class*="bp3-intent"].bp3-disabled,
      .bp3-control-group .bp3-html-select select[class*="bp3-intent"][readonly],
      .bp3-control-group .bp3-html-select select[class*="bp3-intent"]:disabled,
      .bp3-control-group .bp3-html-select select[class*="bp3-intent"].bp3-disabled,
      .bp3-control-group .bp3-select select[class*="bp3-intent"][readonly],
      .bp3-control-group .bp3-select select[class*="bp3-intent"]:disabled,
      .bp3-control-group .bp3-select select[class*="bp3-intent"].bp3-disabled{
        z-index:8; }
  .bp3-control-group .bp3-input-group > .bp3-icon,
  .bp3-control-group .bp3-input-group > .bp3-button,
  .bp3-control-group .bp3-input-group > .bp3-input-action{
    z-index:16; }
  .bp3-control-group .bp3-select::after,
  .bp3-control-group .bp3-html-select::after,
  .bp3-control-group .bp3-select > .bp3-icon,
  .bp3-control-group .bp3-html-select > .bp3-icon{
    z-index:17; }
  .bp3-control-group:not(.bp3-vertical) > *{
    margin-right:-1px; }
  .bp3-dark .bp3-control-group:not(.bp3-vertical) > *{
    margin-right:0; }
  .bp3-dark .bp3-control-group:not(.bp3-vertical) > .bp3-button + .bp3-button{
    margin-left:1px; }
  .bp3-control-group .bp3-popover-wrapper,
  .bp3-control-group .bp3-popover-target{
    border-radius:inherit; }
  .bp3-control-group > :first-child{
    border-radius:3px 0 0 3px; }
  .bp3-control-group > :last-child{
    margin-right:0;
    border-radius:0 3px 3px 0; }
  .bp3-control-group > :only-child{
    margin-right:0;
    border-radius:3px; }
  .bp3-control-group .bp3-input-group .bp3-button{
    border-radius:3px; }
  .bp3-control-group > .bp3-fill{
    -webkit-box-flex:1;
        -ms-flex:1 1 auto;
            flex:1 1 auto; }
  .bp3-control-group.bp3-fill > *:not(.bp3-fixed){
    -webkit-box-flex:1;
        -ms-flex:1 1 auto;
            flex:1 1 auto; }
  .bp3-control-group.bp3-vertical{
    -webkit-box-orient:vertical;
    -webkit-box-direction:normal;
        -ms-flex-direction:column;
            flex-direction:column; }
    .bp3-control-group.bp3-vertical > *{
      margin-top:-1px; }
    .bp3-control-group.bp3-vertical > :first-child{
      margin-top:0;
      border-radius:3px 3px 0 0; }
    .bp3-control-group.bp3-vertical > :last-child{
      border-radius:0 0 3px 3px; }
.bp3-control{
  display:block;
  position:relative;
  margin-bottom:10px;
  cursor:pointer;
  text-transform:none; }
  .bp3-control input:checked ~ .bp3-control-indicator{
    -webkit-box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.4), inset 0 -1px 0 rgba(16, 22, 26, 0.2);
            box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.4), inset 0 -1px 0 rgba(16, 22, 26, 0.2);
    background-color:#137cbd;
    background-image:-webkit-gradient(linear, left top, left bottom, from(rgba(255, 255, 255, 0.1)), to(rgba(255, 255, 255, 0)));
    background-image:linear-gradient(to bottom, rgba(255, 255, 255, 0.1), rgba(255, 255, 255, 0));
    color:#ffffff; }
  .bp3-control:hover input:checked ~ .bp3-control-indicator{
    -webkit-box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.4), inset 0 -1px 0 rgba(16, 22, 26, 0.2);
            box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.4), inset 0 -1px 0 rgba(16, 22, 26, 0.2);
    background-color:#106ba3; }
  .bp3-control input:not(:disabled):active:checked ~ .bp3-control-indicator{
    -webkit-box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.4), inset 0 1px 2px rgba(16, 22, 26, 0.2);
            box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.4), inset 0 1px 2px rgba(16, 22, 26, 0.2);
    background:#0e5a8a; }
  .bp3-control input:disabled:checked ~ .bp3-control-indicator{
    -webkit-box-shadow:none;
            box-shadow:none;
    background:rgba(19, 124, 189, 0.5); }
  .bp3-dark .bp3-control input:checked ~ .bp3-control-indicator{
    -webkit-box-shadow:0 0 0 1px rgba(16, 22, 26, 0.4);
            box-shadow:0 0 0 1px rgba(16, 22, 26, 0.4); }
  .bp3-dark .bp3-control:hover input:checked ~ .bp3-control-indicator{
    -webkit-box-shadow:0 0 0 1px rgba(16, 22, 26, 0.4);
            box-shadow:0 0 0 1px rgba(16, 22, 26, 0.4);
    background-color:#106ba3; }
  .bp3-dark .bp3-control input:not(:disabled):active:checked ~ .bp3-control-indicator{
    -webkit-box-shadow:0 0 0 1px rgba(16, 22, 26, 0.4), inset 0 1px 2px rgba(16, 22, 26, 0.2);
            box-shadow:0 0 0 1px rgba(16, 22, 26, 0.4), inset 0 1px 2px rgba(16, 22, 26, 0.2);
    background-color:#0e5a8a; }
  .bp3-dark .bp3-control input:disabled:checked ~ .bp3-control-indicator{
    -webkit-box-shadow:none;
            box-shadow:none;
    background:rgba(14, 90, 138, 0.5); }
  .bp3-control:not(.bp3-align-right){
    padding-left:26px; }
    .bp3-control:not(.bp3-align-right) .bp3-control-indicator{
      margin-left:-26px; }
  .bp3-control.bp3-align-right{
    padding-right:26px; }
    .bp3-control.bp3-align-right .bp3-control-indicator{
      margin-right:-26px; }
  .bp3-control.bp3-disabled{
    cursor:not-allowed;
    color:rgba(92, 112, 128, 0.6); }
  .bp3-control.bp3-inline{
    display:inline-block;
    margin-right:20px; }
  .bp3-control input{
    position:absolute;
    top:0;
    left:0;
    opacity:0;
    z-index:-1; }
  .bp3-control .bp3-control-indicator{
    display:inline-block;
    position:relative;
    margin-top:-3px;
    margin-right:10px;
    border:none;
    -webkit-box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.2), inset 0 -1px 0 rgba(16, 22, 26, 0.1);
            box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.2), inset 0 -1px 0 rgba(16, 22, 26, 0.1);
    background-clip:padding-box;
    background-color:#f5f8fa;
    background-image:-webkit-gradient(linear, left top, left bottom, from(rgba(255, 255, 255, 0.8)), to(rgba(255, 255, 255, 0)));
    background-image:linear-gradient(to bottom, rgba(255, 255, 255, 0.8), rgba(255, 255, 255, 0));
    cursor:pointer;
    width:1em;
    height:1em;
    vertical-align:middle;
    font-size:16px;
    -webkit-user-select:none;
       -moz-user-select:none;
        -ms-user-select:none;
            user-select:none; }
    .bp3-control .bp3-control-indicator::before{
      display:block;
      width:1em;
      height:1em;
      content:""; }
  .bp3-control:hover .bp3-control-indicator{
    background-color:#ebf1f5; }
  .bp3-control input:not(:disabled):active ~ .bp3-control-indicator{
    -webkit-box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.2), inset 0 1px 2px rgba(16, 22, 26, 0.2);
            box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.2), inset 0 1px 2px rgba(16, 22, 26, 0.2);
    background:#d8e1e8; }
  .bp3-control input:disabled ~ .bp3-control-indicator{
    -webkit-box-shadow:none;
            box-shadow:none;
    background:rgba(206, 217, 224, 0.5);
    cursor:not-allowed; }
  .bp3-control input:focus ~ .bp3-control-indicator{
    outline:rgba(19, 124, 189, 0.6) auto 2px;
    outline-offset:2px;
    -moz-outline-radius:6px; }
  .bp3-control.bp3-align-right .bp3-control-indicator{
    float:right;
    margin-top:1px;
    margin-left:10px; }
  .bp3-control.bp3-large{
    font-size:16px; }
    .bp3-control.bp3-large:not(.bp3-align-right){
      padding-left:30px; }
      .bp3-control.bp3-large:not(.bp3-align-right) .bp3-control-indicator{
        margin-left:-30px; }
    .bp3-control.bp3-large.bp3-align-right{
      padding-right:30px; }
      .bp3-control.bp3-large.bp3-align-right .bp3-control-indicator{
        margin-right:-30px; }
    .bp3-control.bp3-large .bp3-control-indicator{
      font-size:20px; }
    .bp3-control.bp3-large.bp3-align-right .bp3-control-indicator{
      margin-top:0; }
  .bp3-control.bp3-checkbox input:indeterminate ~ .bp3-control-indicator{
    -webkit-box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.4), inset 0 -1px 0 rgba(16, 22, 26, 0.2);
            box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.4), inset 0 -1px 0 rgba(16, 22, 26, 0.2);
    background-color:#137cbd;
    background-image:-webkit-gradient(linear, left top, left bottom, from(rgba(255, 255, 255, 0.1)), to(rgba(255, 255, 255, 0)));
    background-image:linear-gradient(to bottom, rgba(255, 255, 255, 0.1), rgba(255, 255, 255, 0));
    color:#ffffff; }
  .bp3-control.bp3-checkbox:hover input:indeterminate ~ .bp3-control-indicator{
    -webkit-box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.4), inset 0 -1px 0 rgba(16, 22, 26, 0.2);
            box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.4), inset 0 -1px 0 rgba(16, 22, 26, 0.2);
    background-color:#106ba3; }
  .bp3-control.bp3-checkbox input:not(:disabled):active:indeterminate ~ .bp3-control-indicator{
    -webkit-box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.4), inset 0 1px 2px rgba(16, 22, 26, 0.2);
            box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.4), inset 0 1px 2px rgba(16, 22, 26, 0.2);
    background:#0e5a8a; }
  .bp3-control.bp3-checkbox input:disabled:indeterminate ~ .bp3-control-indicator{
    -webkit-box-shadow:none;
            box-shadow:none;
    background:rgba(19, 124, 189, 0.5); }
  .bp3-dark .bp3-control.bp3-checkbox input:indeterminate ~ .bp3-control-indicator{
    -webkit-box-shadow:0 0 0 1px rgba(16, 22, 26, 0.4);
            box-shadow:0 0 0 1px rgba(16, 22, 26, 0.4); }
  .bp3-dark .bp3-control.bp3-checkbox:hover input:indeterminate ~ .bp3-control-indicator{
    -webkit-box-shadow:0 0 0 1px rgba(16, 22, 26, 0.4);
            box-shadow:0 0 0 1px rgba(16, 22, 26, 0.4);
    background-color:#106ba3; }
  .bp3-dark .bp3-control.bp3-checkbox input:not(:disabled):active:indeterminate ~ .bp3-control-indicator{
    -webkit-box-shadow:0 0 0 1px rgba(16, 22, 26, 0.4), inset 0 1px 2px rgba(16, 22, 26, 0.2);
            box-shadow:0 0 0 1px rgba(16, 22, 26, 0.4), inset 0 1px 2px rgba(16, 22, 26, 0.2);
    background-color:#0e5a8a; }
  .bp3-dark .bp3-control.bp3-checkbox input:disabled:indeterminate ~ .bp3-control-indicator{
    -webkit-box-shadow:none;
            box-shadow:none;
    background:rgba(14, 90, 138, 0.5); }
  .bp3-control.bp3-checkbox .bp3-control-indicator{
    border-radius:3px; }
  .bp3-control.bp3-checkbox input:checked ~ .bp3-control-indicator::before{
    background-image:url("data:image/svg+xml,%3csvg xmlns='http://www.w3.org/2000/svg' viewBox='0 0 16 16'%3e%3cpath fill-rule='evenodd' clip-rule='evenodd' d='M12 5c-.28 0-.53.11-.71.29L7 9.59l-2.29-2.3a1.003 1.003 0 0 0-1.42 1.42l3 3c.18.18.43.29.71.29s.53-.11.71-.29l5-5A1.003 1.003 0 0 0 12 5z' fill='white'/%3e%3c/svg%3e"); }
  .bp3-control.bp3-checkbox input:indeterminate ~ .bp3-control-indicator::before{
    background-image:url("data:image/svg+xml,%3csvg xmlns='http://www.w3.org/2000/svg' viewBox='0 0 16 16'%3e%3cpath fill-rule='evenodd' clip-rule='evenodd' d='M11 7H5c-.55 0-1 .45-1 1s.45 1 1 1h6c.55 0 1-.45 1-1s-.45-1-1-1z' fill='white'/%3e%3c/svg%3e"); }
  .bp3-control.bp3-radio .bp3-control-indicator{
    border-radius:50%; }
  .bp3-control.bp3-radio input:checked ~ .bp3-control-indicator::before{
    background-image:radial-gradient(#ffffff, #ffffff 28%, transparent 32%); }
  .bp3-control.bp3-radio input:checked:disabled ~ .bp3-control-indicator::before{
    opacity:0.5; }
  .bp3-control.bp3-radio input:focus ~ .bp3-control-indicator{
    -moz-outline-radius:16px; }
  .bp3-control.bp3-switch input ~ .bp3-control-indicator{
    background:rgba(167, 182, 194, 0.5); }
  .bp3-control.bp3-switch:hover input ~ .bp3-control-indicator{
    background:rgba(115, 134, 148, 0.5); }
  .bp3-control.bp3-switch input:not(:disabled):active ~ .bp3-control-indicator{
    background:rgba(92, 112, 128, 0.5); }
  .bp3-control.bp3-switch input:disabled ~ .bp3-control-indicator{
    background:rgba(206, 217, 224, 0.5); }
    .bp3-control.bp3-switch input:disabled ~ .bp3-control-indicator::before{
      background:rgba(255, 255, 255, 0.8); }
  .bp3-control.bp3-switch input:checked ~ .bp3-control-indicator{
    background:#137cbd; }
  .bp3-control.bp3-switch:hover input:checked ~ .bp3-control-indicator{
    background:#106ba3; }
  .bp3-control.bp3-switch input:checked:not(:disabled):active ~ .bp3-control-indicator{
    background:#0e5a8a; }
  .bp3-control.bp3-switch input:checked:disabled ~ .bp3-control-indicator{
    background:rgba(19, 124, 189, 0.5); }
    .bp3-control.bp3-switch input:checked:disabled ~ .bp3-control-indicator::before{
      background:rgba(255, 255, 255, 0.8); }
  .bp3-control.bp3-switch:not(.bp3-align-right){
    padding-left:38px; }
    .bp3-control.bp3-switch:not(.bp3-align-right) .bp3-control-indicator{
      margin-left:-38px; }
  .bp3-control.bp3-switch.bp3-align-right{
    padding-right:38px; }
    .bp3-control.bp3-switch.bp3-align-right .bp3-control-indicator{
      margin-right:-38px; }
  .bp3-control.bp3-switch .bp3-control-indicator{
    border:none;
    border-radius:1.75em;
    -webkit-box-shadow:none !important;
            box-shadow:none !important;
    width:auto;
    min-width:1.75em;
    -webkit-transition:background-color 100ms cubic-bezier(0.4, 1, 0.75, 0.9);
    transition:background-color 100ms cubic-bezier(0.4, 1, 0.75, 0.9); }
    .bp3-control.bp3-switch .bp3-control-indicator::before{
      position:absolute;
      left:0;
      margin:2px;
      border-radius:50%;
      -webkit-box-shadow:0 0 0 1px rgba(16, 22, 26, 0.2), 0 1px 1px rgba(16, 22, 26, 0.2);
              box-shadow:0 0 0 1px rgba(16, 22, 26, 0.2), 0 1px 1px rgba(16, 22, 26, 0.2);
      background:#ffffff;
      width:calc(1em - 4px);
      height:calc(1em - 4px);
      -webkit-transition:left 100ms cubic-bezier(0.4, 1, 0.75, 0.9);
      transition:left 100ms cubic-bezier(0.4, 1, 0.75, 0.9); }
  .bp3-control.bp3-switch input:checked ~ .bp3-control-indicator::before{
    left:calc(100% - 1em); }
  .bp3-control.bp3-switch.bp3-large:not(.bp3-align-right){
    padding-left:45px; }
    .bp3-control.bp3-switch.bp3-large:not(.bp3-align-right) .bp3-control-indicator{
      margin-left:-45px; }
  .bp3-control.bp3-switch.bp3-large.bp3-align-right{
    padding-right:45px; }
    .bp3-control.bp3-switch.bp3-large.bp3-align-right .bp3-control-indicator{
      margin-right:-45px; }
  .bp3-dark .bp3-control.bp3-switch input ~ .bp3-control-indicator{
    background:rgba(16, 22, 26, 0.5); }
  .bp3-dark .bp3-control.bp3-switch:hover input ~ .bp3-control-indicator{
    background:rgba(16, 22, 26, 0.7); }
  .bp3-dark .bp3-control.bp3-switch input:not(:disabled):active ~ .bp3-control-indicator{
    background:rgba(16, 22, 26, 0.9); }
  .bp3-dark .bp3-control.bp3-switch input:disabled ~ .bp3-control-indicator{
    background:rgba(57, 75, 89, 0.5); }
    .bp3-dark .bp3-control.bp3-switch input:disabled ~ .bp3-control-indicator::before{
      background:rgba(16, 22, 26, 0.4); }
  .bp3-dark .bp3-control.bp3-switch input:checked ~ .bp3-control-indicator{
    background:#137cbd; }
  .bp3-dark .bp3-control.bp3-switch:hover input:checked ~ .bp3-control-indicator{
    background:#106ba3; }
  .bp3-dark .bp3-control.bp3-switch input:checked:not(:disabled):active ~ .bp3-control-indicator{
    background:#0e5a8a; }
  .bp3-dark .bp3-control.bp3-switch input:checked:disabled ~ .bp3-control-indicator{
    background:rgba(14, 90, 138, 0.5); }
    .bp3-dark .bp3-control.bp3-switch input:checked:disabled ~ .bp3-control-indicator::before{
      background:rgba(16, 22, 26, 0.4); }
  .bp3-dark .bp3-control.bp3-switch .bp3-control-indicator::before{
    -webkit-box-shadow:0 0 0 1px rgba(16, 22, 26, 0.4);
            box-shadow:0 0 0 1px rgba(16, 22, 26, 0.4);
    background:#394b59; }
  .bp3-dark .bp3-control.bp3-switch input:checked ~ .bp3-control-indicator::before{
    -webkit-box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.4);
            box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.4); }
  .bp3-control.bp3-switch .bp3-switch-inner-text{
    text-align:center;
    font-size:0.7em; }
  .bp3-control.bp3-switch .bp3-control-indicator-child:first-child{
    visibility:hidden;
    margin-right:1.2em;
    margin-left:0.5em;
    line-height:0; }
  .bp3-control.bp3-switch .bp3-control-indicator-child:last-child{
    visibility:visible;
    margin-right:0.5em;
    margin-left:1.2em;
    line-height:1em; }
  .bp3-control.bp3-switch input:checked ~ .bp3-control-indicator .bp3-control-indicator-child:first-child{
    visibility:visible;
    line-height:1em; }
  .bp3-control.bp3-switch input:checked ~ .bp3-control-indicator .bp3-control-indicator-child:last-child{
    visibility:hidden;
    line-height:0; }
  .bp3-dark .bp3-control{
    color:#f5f8fa; }
    .bp3-dark .bp3-control.bp3-disabled{
      color:rgba(167, 182, 194, 0.6); }
    .bp3-dark .bp3-control .bp3-control-indicator{
      -webkit-box-shadow:0 0 0 1px rgba(16, 22, 26, 0.4);
              box-shadow:0 0 0 1px rgba(16, 22, 26, 0.4);
      background-color:#394b59;
      background-image:-webkit-gradient(linear, left top, left bottom, from(rgba(255, 255, 255, 0.05)), to(rgba(255, 255, 255, 0)));
      background-image:linear-gradient(to bottom, rgba(255, 255, 255, 0.05), rgba(255, 255, 255, 0)); }
    .bp3-dark .bp3-control:hover .bp3-control-indicator{
      background-color:#30404d; }
    .bp3-dark .bp3-control input:not(:disabled):active ~ .bp3-control-indicator{
      -webkit-box-shadow:0 0 0 1px rgba(16, 22, 26, 0.6), inset 0 1px 2px rgba(16, 22, 26, 0.2);
              box-shadow:0 0 0 1px rgba(16, 22, 26, 0.6), inset 0 1px 2px rgba(16, 22, 26, 0.2);
      background:#202b33; }
    .bp3-dark .bp3-control input:disabled ~ .bp3-control-indicator{
      -webkit-box-shadow:none;
              box-shadow:none;
      background:rgba(57, 75, 89, 0.5);
      cursor:not-allowed; }
    .bp3-dark .bp3-control.bp3-checkbox input:disabled:checked ~ .bp3-control-indicator, .bp3-dark .bp3-control.bp3-checkbox input:disabled:indeterminate ~ .bp3-control-indicator{
      color:rgba(167, 182, 194, 0.6); }
.bp3-file-input{
  display:inline-block;
  position:relative;
  cursor:pointer;
  height:30px; }
  .bp3-file-input input{
    opacity:0;
    margin:0;
    min-width:200px; }
    .bp3-file-input input:disabled + .bp3-file-upload-input,
    .bp3-file-input input.bp3-disabled + .bp3-file-upload-input{
      -webkit-box-shadow:none;
              box-shadow:none;
      background:rgba(206, 217, 224, 0.5);
      cursor:not-allowed;
      color:rgba(92, 112, 128, 0.6);
      resize:none; }
      .bp3-file-input input:disabled + .bp3-file-upload-input::after,
      .bp3-file-input input.bp3-disabled + .bp3-file-upload-input::after{
        outline:none;
        -webkit-box-shadow:none;
                box-shadow:none;
        background-color:rgba(206, 217, 224, 0.5);
        background-image:none;
        cursor:not-allowed;
        color:rgba(92, 112, 128, 0.6); }
        .bp3-file-input input:disabled + .bp3-file-upload-input::after.bp3-active, .bp3-file-input input:disabled + .bp3-file-upload-input::after.bp3-active:hover,
        .bp3-file-input input.bp3-disabled + .bp3-file-upload-input::after.bp3-active,
        .bp3-file-input input.bp3-disabled + .bp3-file-upload-input::after.bp3-active:hover{
          background:rgba(206, 217, 224, 0.7); }
      .bp3-dark .bp3-file-input input:disabled + .bp3-file-upload-input, .bp3-dark
      .bp3-file-input input.bp3-disabled + .bp3-file-upload-input{
        -webkit-box-shadow:none;
                box-shadow:none;
        background:rgba(57, 75, 89, 0.5);
        color:rgba(167, 182, 194, 0.6); }
        .bp3-dark .bp3-file-input input:disabled + .bp3-file-upload-input::after, .bp3-dark
        .bp3-file-input input.bp3-disabled + .bp3-file-upload-input::after{
          -webkit-box-shadow:none;
                  box-shadow:none;
          background-color:rgba(57, 75, 89, 0.5);
          background-image:none;
          color:rgba(167, 182, 194, 0.6); }
          .bp3-dark .bp3-file-input input:disabled + .bp3-file-upload-input::after.bp3-active, .bp3-dark
          .bp3-file-input input.bp3-disabled + .bp3-file-upload-input::after.bp3-active{
            background:rgba(57, 75, 89, 0.7); }
  .bp3-file-input.bp3-file-input-has-selection .bp3-file-upload-input{
    color:#182026; }
  .bp3-dark .bp3-file-input.bp3-file-input-has-selection .bp3-file-upload-input{
    color:#f5f8fa; }
  .bp3-file-input.bp3-fill{
    width:100%; }
  .bp3-file-input.bp3-large,
  .bp3-large .bp3-file-input{
    height:40px; }
  .bp3-file-input .bp3-file-upload-input-custom-text::after{
    content:attr(bp3-button-text); }

.bp3-file-upload-input{
  outline:none;
  border:none;
  border-radius:3px;
  -webkit-box-shadow:0 0 0 0 rgba(19, 124, 189, 0), 0 0 0 0 rgba(19, 124, 189, 0), inset 0 0 0 1px rgba(16, 22, 26, 0.15), inset 0 1px 1px rgba(16, 22, 26, 0.2);
          box-shadow:0 0 0 0 rgba(19, 124, 189, 0), 0 0 0 0 rgba(19, 124, 189, 0), inset 0 0 0 1px rgba(16, 22, 26, 0.15), inset 0 1px 1px rgba(16, 22, 26, 0.2);
  background:#ffffff;
  height:30px;
  padding:0 10px;
  vertical-align:middle;
  line-height:30px;
  color:#182026;
  font-size:14px;
  font-weight:400;
  -webkit-transition:-webkit-box-shadow 100ms cubic-bezier(0.4, 1, 0.75, 0.9);
  transition:-webkit-box-shadow 100ms cubic-bezier(0.4, 1, 0.75, 0.9);
  transition:box-shadow 100ms cubic-bezier(0.4, 1, 0.75, 0.9);
  transition:box-shadow 100ms cubic-bezier(0.4, 1, 0.75, 0.9), -webkit-box-shadow 100ms cubic-bezier(0.4, 1, 0.75, 0.9);
  -webkit-appearance:none;
     -moz-appearance:none;
          appearance:none;
  overflow:hidden;
  text-overflow:ellipsis;
  white-space:nowrap;
  word-wrap:normal;
  position:absolute;
  top:0;
  right:0;
  left:0;
  padding-right:80px;
  color:rgba(92, 112, 128, 0.6);
  -webkit-user-select:none;
     -moz-user-select:none;
      -ms-user-select:none;
          user-select:none; }
  .bp3-file-upload-input::-webkit-input-placeholder{
    opacity:1;
    color:rgba(92, 112, 128, 0.6); }
  .bp3-file-upload-input::-moz-placeholder{
    opacity:1;
    color:rgba(92, 112, 128, 0.6); }
  .bp3-file-upload-input:-ms-input-placeholder{
    opacity:1;
    color:rgba(92, 112, 128, 0.6); }
  .bp3-file-upload-input::-ms-input-placeholder{
    opacity:1;
    color:rgba(92, 112, 128, 0.6); }
  .bp3-file-upload-input::placeholder{
    opacity:1;
    color:rgba(92, 112, 128, 0.6); }
  .bp3-file-upload-input:focus, .bp3-file-upload-input.bp3-active{
    -webkit-box-shadow:0 0 0 1px #137cbd, 0 0 0 3px rgba(19, 124, 189, 0.3), inset 0 1px 1px rgba(16, 22, 26, 0.2);
            box-shadow:0 0 0 1px #137cbd, 0 0 0 3px rgba(19, 124, 189, 0.3), inset 0 1px 1px rgba(16, 22, 26, 0.2); }
  .bp3-file-upload-input[type="search"], .bp3-file-upload-input.bp3-round{
    border-radius:30px;
    -webkit-box-sizing:border-box;
            box-sizing:border-box;
    padding-left:10px; }
  .bp3-file-upload-input[readonly]{
    -webkit-box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.15);
            box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.15); }
  .bp3-file-upload-input:disabled, .bp3-file-upload-input.bp3-disabled{
    -webkit-box-shadow:none;
            box-shadow:none;
    background:rgba(206, 217, 224, 0.5);
    cursor:not-allowed;
    color:rgba(92, 112, 128, 0.6);
    resize:none; }
  .bp3-file-upload-input::after{
    -webkit-box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.2), inset 0 -1px 0 rgba(16, 22, 26, 0.1);
            box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.2), inset 0 -1px 0 rgba(16, 22, 26, 0.1);
    background-color:#f5f8fa;
    background-image:-webkit-gradient(linear, left top, left bottom, from(rgba(255, 255, 255, 0.8)), to(rgba(255, 255, 255, 0)));
    background-image:linear-gradient(to bottom, rgba(255, 255, 255, 0.8), rgba(255, 255, 255, 0));
    color:#182026;
    min-width:24px;
    min-height:24px;
    overflow:hidden;
    text-overflow:ellipsis;
    white-space:nowrap;
    word-wrap:normal;
    position:absolute;
    top:0;
    right:0;
    margin:3px;
    border-radius:3px;
    width:70px;
    text-align:center;
    line-height:24px;
    content:"Browse"; }
    .bp3-file-upload-input::after:hover{
      -webkit-box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.2), inset 0 -1px 0 rgba(16, 22, 26, 0.1);
              box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.2), inset 0 -1px 0 rgba(16, 22, 26, 0.1);
      background-clip:padding-box;
      background-color:#ebf1f5; }
    .bp3-file-upload-input::after:active, .bp3-file-upload-input::after.bp3-active{
      -webkit-box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.2), inset 0 1px 2px rgba(16, 22, 26, 0.2);
              box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.2), inset 0 1px 2px rgba(16, 22, 26, 0.2);
      background-color:#d8e1e8;
      background-image:none; }
    .bp3-file-upload-input::after:disabled, .bp3-file-upload-input::after.bp3-disabled{
      outline:none;
      -webkit-box-shadow:none;
              box-shadow:none;
      background-color:rgba(206, 217, 224, 0.5);
      background-image:none;
      cursor:not-allowed;
      color:rgba(92, 112, 128, 0.6); }
      .bp3-file-upload-input::after:disabled.bp3-active, .bp3-file-upload-input::after:disabled.bp3-active:hover, .bp3-file-upload-input::after.bp3-disabled.bp3-active, .bp3-file-upload-input::after.bp3-disabled.bp3-active:hover{
        background:rgba(206, 217, 224, 0.7); }
  .bp3-file-upload-input:hover::after{
    -webkit-box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.2), inset 0 -1px 0 rgba(16, 22, 26, 0.1);
            box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.2), inset 0 -1px 0 rgba(16, 22, 26, 0.1);
    background-clip:padding-box;
    background-color:#ebf1f5; }
  .bp3-file-upload-input:active::after{
    -webkit-box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.2), inset 0 1px 2px rgba(16, 22, 26, 0.2);
            box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.2), inset 0 1px 2px rgba(16, 22, 26, 0.2);
    background-color:#d8e1e8;
    background-image:none; }
  .bp3-large .bp3-file-upload-input{
    height:40px;
    line-height:40px;
    font-size:16px;
    padding-right:95px; }
    .bp3-large .bp3-file-upload-input[type="search"], .bp3-large .bp3-file-upload-input.bp3-round{
      padding:0 15px; }
    .bp3-large .bp3-file-upload-input::after{
      min-width:30px;
      min-height:30px;
      margin:5px;
      width:85px;
      line-height:30px; }
  .bp3-dark .bp3-file-upload-input{
    -webkit-box-shadow:0 0 0 0 rgba(19, 124, 189, 0), 0 0 0 0 rgba(19, 124, 189, 0), 0 0 0 0 rgba(19, 124, 189, 0), inset 0 0 0 1px rgba(16, 22, 26, 0.3), inset 0 1px 1px rgba(16, 22, 26, 0.4);
            box-shadow:0 0 0 0 rgba(19, 124, 189, 0), 0 0 0 0 rgba(19, 124, 189, 0), 0 0 0 0 rgba(19, 124, 189, 0), inset 0 0 0 1px rgba(16, 22, 26, 0.3), inset 0 1px 1px rgba(16, 22, 26, 0.4);
    background:rgba(16, 22, 26, 0.3);
    color:#f5f8fa;
    color:rgba(167, 182, 194, 0.6); }
    .bp3-dark .bp3-file-upload-input::-webkit-input-placeholder{
      color:rgba(167, 182, 194, 0.6); }
    .bp3-dark .bp3-file-upload-input::-moz-placeholder{
      color:rgba(167, 182, 194, 0.6); }
    .bp3-dark .bp3-file-upload-input:-ms-input-placeholder{
      color:rgba(167, 182, 194, 0.6); }
    .bp3-dark .bp3-file-upload-input::-ms-input-placeholder{
      color:rgba(167, 182, 194, 0.6); }
    .bp3-dark .bp3-file-upload-input::placeholder{
      color:rgba(167, 182, 194, 0.6); }
    .bp3-dark .bp3-file-upload-input:focus{
      -webkit-box-shadow:0 0 0 1px #137cbd, 0 0 0 1px #137cbd, 0 0 0 3px rgba(19, 124, 189, 0.3), inset 0 0 0 1px rgba(16, 22, 26, 0.3), inset 0 1px 1px rgba(16, 22, 26, 0.4);
              box-shadow:0 0 0 1px #137cbd, 0 0 0 1px #137cbd, 0 0 0 3px rgba(19, 124, 189, 0.3), inset 0 0 0 1px rgba(16, 22, 26, 0.3), inset 0 1px 1px rgba(16, 22, 26, 0.4); }
    .bp3-dark .bp3-file-upload-input[readonly]{
      -webkit-box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.4);
              box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.4); }
    .bp3-dark .bp3-file-upload-input:disabled, .bp3-dark .bp3-file-upload-input.bp3-disabled{
      -webkit-box-shadow:none;
              box-shadow:none;
      background:rgba(57, 75, 89, 0.5);
      color:rgba(167, 182, 194, 0.6); }
    .bp3-dark .bp3-file-upload-input::after{
      -webkit-box-shadow:0 0 0 1px rgba(16, 22, 26, 0.4);
              box-shadow:0 0 0 1px rgba(16, 22, 26, 0.4);
      background-color:#394b59;
      background-image:-webkit-gradient(linear, left top, left bottom, from(rgba(255, 255, 255, 0.05)), to(rgba(255, 255, 255, 0)));
      background-image:linear-gradient(to bottom, rgba(255, 255, 255, 0.05), rgba(255, 255, 255, 0));
      color:#f5f8fa; }
      .bp3-dark .bp3-file-upload-input::after:hover, .bp3-dark .bp3-file-upload-input::after:active, .bp3-dark .bp3-file-upload-input::after.bp3-active{
        color:#f5f8fa; }
      .bp3-dark .bp3-file-upload-input::after:hover{
        -webkit-box-shadow:0 0 0 1px rgba(16, 22, 26, 0.4);
                box-shadow:0 0 0 1px rgba(16, 22, 26, 0.4);
        background-color:#30404d; }
      .bp3-dark .bp3-file-upload-input::after:active, .bp3-dark .bp3-file-upload-input::after.bp3-active{
        -webkit-box-shadow:0 0 0 1px rgba(16, 22, 26, 0.6), inset 0 1px 2px rgba(16, 22, 26, 0.2);
                box-shadow:0 0 0 1px rgba(16, 22, 26, 0.6), inset 0 1px 2px rgba(16, 22, 26, 0.2);
        background-color:#202b33;
        background-image:none; }
      .bp3-dark .bp3-file-upload-input::after:disabled, .bp3-dark .bp3-file-upload-input::after.bp3-disabled{
        -webkit-box-shadow:none;
                box-shadow:none;
        background-color:rgba(57, 75, 89, 0.5);
        background-image:none;
        color:rgba(167, 182, 194, 0.6); }
        .bp3-dark .bp3-file-upload-input::after:disabled.bp3-active, .bp3-dark .bp3-file-upload-input::after.bp3-disabled.bp3-active{
          background:rgba(57, 75, 89, 0.7); }
      .bp3-dark .bp3-file-upload-input::after .bp3-button-spinner .bp3-spinner-head{
        background:rgba(16, 22, 26, 0.5);
        stroke:#8a9ba8; }
    .bp3-dark .bp3-file-upload-input:hover::after{
      -webkit-box-shadow:0 0 0 1px rgba(16, 22, 26, 0.4);
              box-shadow:0 0 0 1px rgba(16, 22, 26, 0.4);
      background-color:#30404d; }
    .bp3-dark .bp3-file-upload-input:active::after{
      -webkit-box-shadow:0 0 0 1px rgba(16, 22, 26, 0.6), inset 0 1px 2px rgba(16, 22, 26, 0.2);
              box-shadow:0 0 0 1px rgba(16, 22, 26, 0.6), inset 0 1px 2px rgba(16, 22, 26, 0.2);
      background-color:#202b33;
      background-image:none; }

.bp3-file-upload-input::after{
  -webkit-box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.2), inset 0 -1px 0 rgba(16, 22, 26, 0.1);
          box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.2), inset 0 -1px 0 rgba(16, 22, 26, 0.1); }
.bp3-form-group{
  display:-webkit-box;
  display:-ms-flexbox;
  display:flex;
  -webkit-box-orient:vertical;
  -webkit-box-direction:normal;
      -ms-flex-direction:column;
          flex-direction:column;
  margin:0 0 15px; }
  .bp3-form-group label.bp3-label{
    margin-bottom:5px; }
  .bp3-form-group .bp3-control{
    margin-top:7px; }
  .bp3-form-group .bp3-form-helper-text{
    margin-top:5px;
    color:#5c7080;
    font-size:12px; }
  .bp3-form-group.bp3-intent-primary .bp3-form-helper-text{
    color:#106ba3; }
  .bp3-form-group.bp3-intent-success .bp3-form-helper-text{
    color:#0d8050; }
  .bp3-form-group.bp3-intent-warning .bp3-form-helper-text{
    color:#bf7326; }
  .bp3-form-group.bp3-intent-danger .bp3-form-helper-text{
    color:#c23030; }
  .bp3-form-group.bp3-inline{
    -webkit-box-orient:horizontal;
    -webkit-box-direction:normal;
        -ms-flex-direction:row;
            flex-direction:row;
    -webkit-box-align:start;
        -ms-flex-align:start;
            align-items:flex-start; }
    .bp3-form-group.bp3-inline.bp3-large label.bp3-label{
      margin:0 10px 0 0;
      line-height:40px; }
    .bp3-form-group.bp3-inline label.bp3-label{
      margin:0 10px 0 0;
      line-height:30px; }
  .bp3-form-group.bp3-disabled .bp3-label,
  .bp3-form-group.bp3-disabled .bp3-text-muted,
  .bp3-form-group.bp3-disabled .bp3-form-helper-text{
    color:rgba(92, 112, 128, 0.6) !important; }
  .bp3-dark .bp3-form-group.bp3-intent-primary .bp3-form-helper-text{
    color:#48aff0; }
  .bp3-dark .bp3-form-group.bp3-intent-success .bp3-form-helper-text{
    color:#3dcc91; }
  .bp3-dark .bp3-form-group.bp3-intent-warning .bp3-form-helper-text{
    color:#ffb366; }
  .bp3-dark .bp3-form-group.bp3-intent-danger .bp3-form-helper-text{
    color:#ff7373; }
  .bp3-dark .bp3-form-group .bp3-form-helper-text{
    color:#a7b6c2; }
  .bp3-dark .bp3-form-group.bp3-disabled .bp3-label,
  .bp3-dark .bp3-form-group.bp3-disabled .bp3-text-muted,
  .bp3-dark .bp3-form-group.bp3-disabled .bp3-form-helper-text{
    color:rgba(167, 182, 194, 0.6) !important; }
.bp3-input-group{
  display:block;
  position:relative; }
  .bp3-input-group .bp3-input{
    position:relative;
    width:100%; }
    .bp3-input-group .bp3-input:not(:first-child){
      padding-left:30px; }
    .bp3-input-group .bp3-input:not(:last-child){
      padding-right:30px; }
  .bp3-input-group .bp3-input-action,
  .bp3-input-group > .bp3-button,
  .bp3-input-group > .bp3-icon{
    position:absolute;
    top:0; }
    .bp3-input-group .bp3-input-action:first-child,
    .bp3-input-group > .bp3-button:first-child,
    .bp3-input-group > .bp3-icon:first-child{
      left:0; }
    .bp3-input-group .bp3-input-action:last-child,
    .bp3-input-group > .bp3-button:last-child,
    .bp3-input-group > .bp3-icon:last-child{
      right:0; }
  .bp3-input-group .bp3-button{
    min-width:24px;
    min-height:24px;
    margin:3px;
    padding:0 7px; }
    .bp3-input-group .bp3-button:empty{
      padding:0; }
  .bp3-input-group > .bp3-icon{
    z-index:1;
    color:#5c7080; }
    .bp3-input-group > .bp3-icon:empty{
      line-height:1;
      font-family:"Icons16", sans-serif;
      font-size:16px;
      font-weight:400;
      font-style:normal;
      -moz-osx-font-smoothing:grayscale;
      -webkit-font-smoothing:antialiased; }
  .bp3-input-group > .bp3-icon,
  .bp3-input-group .bp3-input-action > .bp3-spinner{
    margin:7px; }
  .bp3-input-group .bp3-tag{
    margin:5px; }
  .bp3-input-group .bp3-input:not(:focus) + .bp3-button.bp3-minimal:not(:hover):not(:focus),
  .bp3-input-group .bp3-input:not(:focus) + .bp3-input-action .bp3-button.bp3-minimal:not(:hover):not(:focus){
    color:#5c7080; }
    .bp3-dark .bp3-input-group .bp3-input:not(:focus) + .bp3-button.bp3-minimal:not(:hover):not(:focus), .bp3-dark
    .bp3-input-group .bp3-input:not(:focus) + .bp3-input-action .bp3-button.bp3-minimal:not(:hover):not(:focus){
      color:#a7b6c2; }
    .bp3-input-group .bp3-input:not(:focus) + .bp3-button.bp3-minimal:not(:hover):not(:focus) .bp3-icon, .bp3-input-group .bp3-input:not(:focus) + .bp3-button.bp3-minimal:not(:hover):not(:focus) .bp3-icon-standard, .bp3-input-group .bp3-input:not(:focus) + .bp3-button.bp3-minimal:not(:hover):not(:focus) .bp3-icon-large,
    .bp3-input-group .bp3-input:not(:focus) + .bp3-input-action .bp3-button.bp3-minimal:not(:hover):not(:focus) .bp3-icon,
    .bp3-input-group .bp3-input:not(:focus) + .bp3-input-action .bp3-button.bp3-minimal:not(:hover):not(:focus) .bp3-icon-standard,
    .bp3-input-group .bp3-input:not(:focus) + .bp3-input-action .bp3-button.bp3-minimal:not(:hover):not(:focus) .bp3-icon-large{
      color:#5c7080; }
  .bp3-input-group .bp3-input:not(:focus) + .bp3-button.bp3-minimal:disabled,
  .bp3-input-group .bp3-input:not(:focus) + .bp3-input-action .bp3-button.bp3-minimal:disabled{
    color:rgba(92, 112, 128, 0.6) !important; }
    .bp3-input-group .bp3-input:not(:focus) + .bp3-button.bp3-minimal:disabled .bp3-icon, .bp3-input-group .bp3-input:not(:focus) + .bp3-button.bp3-minimal:disabled .bp3-icon-standard, .bp3-input-group .bp3-input:not(:focus) + .bp3-button.bp3-minimal:disabled .bp3-icon-large,
    .bp3-input-group .bp3-input:not(:focus) + .bp3-input-action .bp3-button.bp3-minimal:disabled .bp3-icon,
    .bp3-input-group .bp3-input:not(:focus) + .bp3-input-action .bp3-button.bp3-minimal:disabled .bp3-icon-standard,
    .bp3-input-group .bp3-input:not(:focus) + .bp3-input-action .bp3-button.bp3-minimal:disabled .bp3-icon-large{
      color:rgba(92, 112, 128, 0.6) !important; }
  .bp3-input-group.bp3-disabled{
    cursor:not-allowed; }
    .bp3-input-group.bp3-disabled .bp3-icon{
      color:rgba(92, 112, 128, 0.6); }
  .bp3-input-group.bp3-large .bp3-button{
    min-width:30px;
    min-height:30px;
    margin:5px; }
  .bp3-input-group.bp3-large > .bp3-icon,
  .bp3-input-group.bp3-large .bp3-input-action > .bp3-spinner{
    margin:12px; }
  .bp3-input-group.bp3-large .bp3-input{
    height:40px;
    line-height:40px;
    font-size:16px; }
    .bp3-input-group.bp3-large .bp3-input[type="search"], .bp3-input-group.bp3-large .bp3-input.bp3-round{
      padding:0 15px; }
    .bp3-input-group.bp3-large .bp3-input:not(:first-child){
      padding-left:40px; }
    .bp3-input-group.bp3-large .bp3-input:not(:last-child){
      padding-right:40px; }
  .bp3-input-group.bp3-small .bp3-button{
    min-width:20px;
    min-height:20px;
    margin:2px; }
  .bp3-input-group.bp3-small .bp3-tag{
    min-width:20px;
    min-height:20px;
    margin:2px; }
  .bp3-input-group.bp3-small > .bp3-icon,
  .bp3-input-group.bp3-small .bp3-input-action > .bp3-spinner{
    margin:4px; }
  .bp3-input-group.bp3-small .bp3-input{
    height:24px;
    padding-right:8px;
    padding-left:8px;
    line-height:24px;
    font-size:12px; }
    .bp3-input-group.bp3-small .bp3-input[type="search"], .bp3-input-group.bp3-small .bp3-input.bp3-round{
      padding:0 12px; }
    .bp3-input-group.bp3-small .bp3-input:not(:first-child){
      padding-left:24px; }
    .bp3-input-group.bp3-small .bp3-input:not(:last-child){
      padding-right:24px; }
  .bp3-input-group.bp3-fill{
    -webkit-box-flex:1;
        -ms-flex:1 1 auto;
            flex:1 1 auto;
    width:100%; }
  .bp3-input-group.bp3-round .bp3-button,
  .bp3-input-group.bp3-round .bp3-input,
  .bp3-input-group.bp3-round .bp3-tag{
    border-radius:30px; }
  .bp3-dark .bp3-input-group .bp3-icon{
    color:#a7b6c2; }
  .bp3-dark .bp3-input-group.bp3-disabled .bp3-icon{
    color:rgba(167, 182, 194, 0.6); }
  .bp3-input-group.bp3-intent-primary .bp3-input{
    -webkit-box-shadow:0 0 0 0 rgba(19, 124, 189, 0), 0 0 0 0 rgba(19, 124, 189, 0), inset 0 0 0 1px #137cbd, inset 0 0 0 1px rgba(16, 22, 26, 0.15), inset 0 1px 1px rgba(16, 22, 26, 0.2);
            box-shadow:0 0 0 0 rgba(19, 124, 189, 0), 0 0 0 0 rgba(19, 124, 189, 0), inset 0 0 0 1px #137cbd, inset 0 0 0 1px rgba(16, 22, 26, 0.15), inset 0 1px 1px rgba(16, 22, 26, 0.2); }
    .bp3-input-group.bp3-intent-primary .bp3-input:focus{
      -webkit-box-shadow:0 0 0 1px #137cbd, 0 0 0 3px rgba(19, 124, 189, 0.3), inset 0 1px 1px rgba(16, 22, 26, 0.2);
              box-shadow:0 0 0 1px #137cbd, 0 0 0 3px rgba(19, 124, 189, 0.3), inset 0 1px 1px rgba(16, 22, 26, 0.2); }
    .bp3-input-group.bp3-intent-primary .bp3-input[readonly]{
      -webkit-box-shadow:inset 0 0 0 1px #137cbd;
              box-shadow:inset 0 0 0 1px #137cbd; }
    .bp3-input-group.bp3-intent-primary .bp3-input:disabled, .bp3-input-group.bp3-intent-primary .bp3-input.bp3-disabled{
      -webkit-box-shadow:none;
              box-shadow:none; }
  .bp3-input-group.bp3-intent-primary > .bp3-icon{
    color:#106ba3; }
    .bp3-dark .bp3-input-group.bp3-intent-primary > .bp3-icon{
      color:#48aff0; }
  .bp3-input-group.bp3-intent-success .bp3-input{
    -webkit-box-shadow:0 0 0 0 rgba(15, 153, 96, 0), 0 0 0 0 rgba(15, 153, 96, 0), inset 0 0 0 1px #0f9960, inset 0 0 0 1px rgba(16, 22, 26, 0.15), inset 0 1px 1px rgba(16, 22, 26, 0.2);
            box-shadow:0 0 0 0 rgba(15, 153, 96, 0), 0 0 0 0 rgba(15, 153, 96, 0), inset 0 0 0 1px #0f9960, inset 0 0 0 1px rgba(16, 22, 26, 0.15), inset 0 1px 1px rgba(16, 22, 26, 0.2); }
    .bp3-input-group.bp3-intent-success .bp3-input:focus{
      -webkit-box-shadow:0 0 0 1px #0f9960, 0 0 0 3px rgba(15, 153, 96, 0.3), inset 0 1px 1px rgba(16, 22, 26, 0.2);
              box-shadow:0 0 0 1px #0f9960, 0 0 0 3px rgba(15, 153, 96, 0.3), inset 0 1px 1px rgba(16, 22, 26, 0.2); }
    .bp3-input-group.bp3-intent-success .bp3-input[readonly]{
      -webkit-box-shadow:inset 0 0 0 1px #0f9960;
              box-shadow:inset 0 0 0 1px #0f9960; }
    .bp3-input-group.bp3-intent-success .bp3-input:disabled, .bp3-input-group.bp3-intent-success .bp3-input.bp3-disabled{
      -webkit-box-shadow:none;
              box-shadow:none; }
  .bp3-input-group.bp3-intent-success > .bp3-icon{
    color:#0d8050; }
    .bp3-dark .bp3-input-group.bp3-intent-success > .bp3-icon{
      color:#3dcc91; }
  .bp3-input-group.bp3-intent-warning .bp3-input{
    -webkit-box-shadow:0 0 0 0 rgba(217, 130, 43, 0), 0 0 0 0 rgba(217, 130, 43, 0), inset 0 0 0 1px #d9822b, inset 0 0 0 1px rgba(16, 22, 26, 0.15), inset 0 1px 1px rgba(16, 22, 26, 0.2);
            box-shadow:0 0 0 0 rgba(217, 130, 43, 0), 0 0 0 0 rgba(217, 130, 43, 0), inset 0 0 0 1px #d9822b, inset 0 0 0 1px rgba(16, 22, 26, 0.15), inset 0 1px 1px rgba(16, 22, 26, 0.2); }
    .bp3-input-group.bp3-intent-warning .bp3-input:focus{
      -webkit-box-shadow:0 0 0 1px #d9822b, 0 0 0 3px rgba(217, 130, 43, 0.3), inset 0 1px 1px rgba(16, 22, 26, 0.2);
              box-shadow:0 0 0 1px #d9822b, 0 0 0 3px rgba(217, 130, 43, 0.3), inset 0 1px 1px rgba(16, 22, 26, 0.2); }
    .bp3-input-group.bp3-intent-warning .bp3-input[readonly]{
      -webkit-box-shadow:inset 0 0 0 1px #d9822b;
              box-shadow:inset 0 0 0 1px #d9822b; }
    .bp3-input-group.bp3-intent-warning .bp3-input:disabled, .bp3-input-group.bp3-intent-warning .bp3-input.bp3-disabled{
      -webkit-box-shadow:none;
              box-shadow:none; }
  .bp3-input-group.bp3-intent-warning > .bp3-icon{
    color:#bf7326; }
    .bp3-dark .bp3-input-group.bp3-intent-warning > .bp3-icon{
      color:#ffb366; }
  .bp3-input-group.bp3-intent-danger .bp3-input{
    -webkit-box-shadow:0 0 0 0 rgba(219, 55, 55, 0), 0 0 0 0 rgba(219, 55, 55, 0), inset 0 0 0 1px #db3737, inset 0 0 0 1px rgba(16, 22, 26, 0.15), inset 0 1px 1px rgba(16, 22, 26, 0.2);
            box-shadow:0 0 0 0 rgba(219, 55, 55, 0), 0 0 0 0 rgba(219, 55, 55, 0), inset 0 0 0 1px #db3737, inset 0 0 0 1px rgba(16, 22, 26, 0.15), inset 0 1px 1px rgba(16, 22, 26, 0.2); }
    .bp3-input-group.bp3-intent-danger .bp3-input:focus{
      -webkit-box-shadow:0 0 0 1px #db3737, 0 0 0 3px rgba(219, 55, 55, 0.3), inset 0 1px 1px rgba(16, 22, 26, 0.2);
              box-shadow:0 0 0 1px #db3737, 0 0 0 3px rgba(219, 55, 55, 0.3), inset 0 1px 1px rgba(16, 22, 26, 0.2); }
    .bp3-input-group.bp3-intent-danger .bp3-input[readonly]{
      -webkit-box-shadow:inset 0 0 0 1px #db3737;
              box-shadow:inset 0 0 0 1px #db3737; }
    .bp3-input-group.bp3-intent-danger .bp3-input:disabled, .bp3-input-group.bp3-intent-danger .bp3-input.bp3-disabled{
      -webkit-box-shadow:none;
              box-shadow:none; }
  .bp3-input-group.bp3-intent-danger > .bp3-icon{
    color:#c23030; }
    .bp3-dark .bp3-input-group.bp3-intent-danger > .bp3-icon{
      color:#ff7373; }
.bp3-input{
  outline:none;
  border:none;
  border-radius:3px;
  -webkit-box-shadow:0 0 0 0 rgba(19, 124, 189, 0), 0 0 0 0 rgba(19, 124, 189, 0), inset 0 0 0 1px rgba(16, 22, 26, 0.15), inset 0 1px 1px rgba(16, 22, 26, 0.2);
          box-shadow:0 0 0 0 rgba(19, 124, 189, 0), 0 0 0 0 rgba(19, 124, 189, 0), inset 0 0 0 1px rgba(16, 22, 26, 0.15), inset 0 1px 1px rgba(16, 22, 26, 0.2);
  background:#ffffff;
  height:30px;
  padding:0 10px;
  vertical-align:middle;
  line-height:30px;
  color:#182026;
  font-size:14px;
  font-weight:400;
  -webkit-transition:-webkit-box-shadow 100ms cubic-bezier(0.4, 1, 0.75, 0.9);
  transition:-webkit-box-shadow 100ms cubic-bezier(0.4, 1, 0.75, 0.9);
  transition:box-shadow 100ms cubic-bezier(0.4, 1, 0.75, 0.9);
  transition:box-shadow 100ms cubic-bezier(0.4, 1, 0.75, 0.9), -webkit-box-shadow 100ms cubic-bezier(0.4, 1, 0.75, 0.9);
  -webkit-appearance:none;
     -moz-appearance:none;
          appearance:none; }
  .bp3-input::-webkit-input-placeholder{
    opacity:1;
    color:rgba(92, 112, 128, 0.6); }
  .bp3-input::-moz-placeholder{
    opacity:1;
    color:rgba(92, 112, 128, 0.6); }
  .bp3-input:-ms-input-placeholder{
    opacity:1;
    color:rgba(92, 112, 128, 0.6); }
  .bp3-input::-ms-input-placeholder{
    opacity:1;
    color:rgba(92, 112, 128, 0.6); }
  .bp3-input::placeholder{
    opacity:1;
    color:rgba(92, 112, 128, 0.6); }
  .bp3-input:focus, .bp3-input.bp3-active{
    -webkit-box-shadow:0 0 0 1px #137cbd, 0 0 0 3px rgba(19, 124, 189, 0.3), inset 0 1px 1px rgba(16, 22, 26, 0.2);
            box-shadow:0 0 0 1px #137cbd, 0 0 0 3px rgba(19, 124, 189, 0.3), inset 0 1px 1px rgba(16, 22, 26, 0.2); }
  .bp3-input[type="search"], .bp3-input.bp3-round{
    border-radius:30px;
    -webkit-box-sizing:border-box;
            box-sizing:border-box;
    padding-left:10px; }
  .bp3-input[readonly]{
    -webkit-box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.15);
            box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.15); }
  .bp3-input:disabled, .bp3-input.bp3-disabled{
    -webkit-box-shadow:none;
            box-shadow:none;
    background:rgba(206, 217, 224, 0.5);
    cursor:not-allowed;
    color:rgba(92, 112, 128, 0.6);
    resize:none; }
  .bp3-input.bp3-large{
    height:40px;
    line-height:40px;
    font-size:16px; }
    .bp3-input.bp3-large[type="search"], .bp3-input.bp3-large.bp3-round{
      padding:0 15px; }
  .bp3-input.bp3-small{
    height:24px;
    padding-right:8px;
    padding-left:8px;
    line-height:24px;
    font-size:12px; }
    .bp3-input.bp3-small[type="search"], .bp3-input.bp3-small.bp3-round{
      padding:0 12px; }
  .bp3-input.bp3-fill{
    -webkit-box-flex:1;
        -ms-flex:1 1 auto;
            flex:1 1 auto;
    width:100%; }
  .bp3-dark .bp3-input{
    -webkit-box-shadow:0 0 0 0 rgba(19, 124, 189, 0), 0 0 0 0 rgba(19, 124, 189, 0), 0 0 0 0 rgba(19, 124, 189, 0), inset 0 0 0 1px rgba(16, 22, 26, 0.3), inset 0 1px 1px rgba(16, 22, 26, 0.4);
            box-shadow:0 0 0 0 rgba(19, 124, 189, 0), 0 0 0 0 rgba(19, 124, 189, 0), 0 0 0 0 rgba(19, 124, 189, 0), inset 0 0 0 1px rgba(16, 22, 26, 0.3), inset 0 1px 1px rgba(16, 22, 26, 0.4);
    background:rgba(16, 22, 26, 0.3);
    color:#f5f8fa; }
    .bp3-dark .bp3-input::-webkit-input-placeholder{
      color:rgba(167, 182, 194, 0.6); }
    .bp3-dark .bp3-input::-moz-placeholder{
      color:rgba(167, 182, 194, 0.6); }
    .bp3-dark .bp3-input:-ms-input-placeholder{
      color:rgba(167, 182, 194, 0.6); }
    .bp3-dark .bp3-input::-ms-input-placeholder{
      color:rgba(167, 182, 194, 0.6); }
    .bp3-dark .bp3-input::placeholder{
      color:rgba(167, 182, 194, 0.6); }
    .bp3-dark .bp3-input:focus{
      -webkit-box-shadow:0 0 0 1px #137cbd, 0 0 0 1px #137cbd, 0 0 0 3px rgba(19, 124, 189, 0.3), inset 0 0 0 1px rgba(16, 22, 26, 0.3), inset 0 1px 1px rgba(16, 22, 26, 0.4);
              box-shadow:0 0 0 1px #137cbd, 0 0 0 1px #137cbd, 0 0 0 3px rgba(19, 124, 189, 0.3), inset 0 0 0 1px rgba(16, 22, 26, 0.3), inset 0 1px 1px rgba(16, 22, 26, 0.4); }
    .bp3-dark .bp3-input[readonly]{
      -webkit-box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.4);
              box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.4); }
    .bp3-dark .bp3-input:disabled, .bp3-dark .bp3-input.bp3-disabled{
      -webkit-box-shadow:none;
              box-shadow:none;
      background:rgba(57, 75, 89, 0.5);
      color:rgba(167, 182, 194, 0.6); }
  .bp3-input.bp3-intent-primary{
    -webkit-box-shadow:0 0 0 0 rgba(19, 124, 189, 0), 0 0 0 0 rgba(19, 124, 189, 0), inset 0 0 0 1px #137cbd, inset 0 0 0 1px rgba(16, 22, 26, 0.15), inset 0 1px 1px rgba(16, 22, 26, 0.2);
            box-shadow:0 0 0 0 rgba(19, 124, 189, 0), 0 0 0 0 rgba(19, 124, 189, 0), inset 0 0 0 1px #137cbd, inset 0 0 0 1px rgba(16, 22, 26, 0.15), inset 0 1px 1px rgba(16, 22, 26, 0.2); }
    .bp3-input.bp3-intent-primary:focus{
      -webkit-box-shadow:0 0 0 1px #137cbd, 0 0 0 3px rgba(19, 124, 189, 0.3), inset 0 1px 1px rgba(16, 22, 26, 0.2);
              box-shadow:0 0 0 1px #137cbd, 0 0 0 3px rgba(19, 124, 189, 0.3), inset 0 1px 1px rgba(16, 22, 26, 0.2); }
    .bp3-input.bp3-intent-primary[readonly]{
      -webkit-box-shadow:inset 0 0 0 1px #137cbd;
              box-shadow:inset 0 0 0 1px #137cbd; }
    .bp3-input.bp3-intent-primary:disabled, .bp3-input.bp3-intent-primary.bp3-disabled{
      -webkit-box-shadow:none;
              box-shadow:none; }
    .bp3-dark .bp3-input.bp3-intent-primary{
      -webkit-box-shadow:0 0 0 0 rgba(19, 124, 189, 0), 0 0 0 0 rgba(19, 124, 189, 0), 0 0 0 0 rgba(19, 124, 189, 0), inset 0 0 0 1px #137cbd, inset 0 0 0 1px rgba(16, 22, 26, 0.3), inset 0 1px 1px rgba(16, 22, 26, 0.4);
              box-shadow:0 0 0 0 rgba(19, 124, 189, 0), 0 0 0 0 rgba(19, 124, 189, 0), 0 0 0 0 rgba(19, 124, 189, 0), inset 0 0 0 1px #137cbd, inset 0 0 0 1px rgba(16, 22, 26, 0.3), inset 0 1px 1px rgba(16, 22, 26, 0.4); }
      .bp3-dark .bp3-input.bp3-intent-primary:focus{
        -webkit-box-shadow:0 0 0 1px #137cbd, 0 0 0 1px #137cbd, 0 0 0 3px rgba(19, 124, 189, 0.3), inset 0 0 0 1px rgba(16, 22, 26, 0.3), inset 0 1px 1px rgba(16, 22, 26, 0.4);
                box-shadow:0 0 0 1px #137cbd, 0 0 0 1px #137cbd, 0 0 0 3px rgba(19, 124, 189, 0.3), inset 0 0 0 1px rgba(16, 22, 26, 0.3), inset 0 1px 1px rgba(16, 22, 26, 0.4); }
      .bp3-dark .bp3-input.bp3-intent-primary[readonly]{
        -webkit-box-shadow:inset 0 0 0 1px #137cbd;
                box-shadow:inset 0 0 0 1px #137cbd; }
      .bp3-dark .bp3-input.bp3-intent-primary:disabled, .bp3-dark .bp3-input.bp3-intent-primary.bp3-disabled{
        -webkit-box-shadow:none;
                box-shadow:none; }
  .bp3-input.bp3-intent-success{
    -webkit-box-shadow:0 0 0 0 rgba(15, 153, 96, 0), 0 0 0 0 rgba(15, 153, 96, 0), inset 0 0 0 1px #0f9960, inset 0 0 0 1px rgba(16, 22, 26, 0.15), inset 0 1px 1px rgba(16, 22, 26, 0.2);
            box-shadow:0 0 0 0 rgba(15, 153, 96, 0), 0 0 0 0 rgba(15, 153, 96, 0), inset 0 0 0 1px #0f9960, inset 0 0 0 1px rgba(16, 22, 26, 0.15), inset 0 1px 1px rgba(16, 22, 26, 0.2); }
    .bp3-input.bp3-intent-success:focus{
      -webkit-box-shadow:0 0 0 1px #0f9960, 0 0 0 3px rgba(15, 153, 96, 0.3), inset 0 1px 1px rgba(16, 22, 26, 0.2);
              box-shadow:0 0 0 1px #0f9960, 0 0 0 3px rgba(15, 153, 96, 0.3), inset 0 1px 1px rgba(16, 22, 26, 0.2); }
    .bp3-input.bp3-intent-success[readonly]{
      -webkit-box-shadow:inset 0 0 0 1px #0f9960;
              box-shadow:inset 0 0 0 1px #0f9960; }
    .bp3-input.bp3-intent-success:disabled, .bp3-input.bp3-intent-success.bp3-disabled{
      -webkit-box-shadow:none;
              box-shadow:none; }
    .bp3-dark .bp3-input.bp3-intent-success{
      -webkit-box-shadow:0 0 0 0 rgba(15, 153, 96, 0), 0 0 0 0 rgba(15, 153, 96, 0), 0 0 0 0 rgba(15, 153, 96, 0), inset 0 0 0 1px #0f9960, inset 0 0 0 1px rgba(16, 22, 26, 0.3), inset 0 1px 1px rgba(16, 22, 26, 0.4);
              box-shadow:0 0 0 0 rgba(15, 153, 96, 0), 0 0 0 0 rgba(15, 153, 96, 0), 0 0 0 0 rgba(15, 153, 96, 0), inset 0 0 0 1px #0f9960, inset 0 0 0 1px rgba(16, 22, 26, 0.3), inset 0 1px 1px rgba(16, 22, 26, 0.4); }
      .bp3-dark .bp3-input.bp3-intent-success:focus{
        -webkit-box-shadow:0 0 0 1px #0f9960, 0 0 0 1px #0f9960, 0 0 0 3px rgba(15, 153, 96, 0.3), inset 0 0 0 1px rgba(16, 22, 26, 0.3), inset 0 1px 1px rgba(16, 22, 26, 0.4);
                box-shadow:0 0 0 1px #0f9960, 0 0 0 1px #0f9960, 0 0 0 3px rgba(15, 153, 96, 0.3), inset 0 0 0 1px rgba(16, 22, 26, 0.3), inset 0 1px 1px rgba(16, 22, 26, 0.4); }
      .bp3-dark .bp3-input.bp3-intent-success[readonly]{
        -webkit-box-shadow:inset 0 0 0 1px #0f9960;
                box-shadow:inset 0 0 0 1px #0f9960; }
      .bp3-dark .bp3-input.bp3-intent-success:disabled, .bp3-dark .bp3-input.bp3-intent-success.bp3-disabled{
        -webkit-box-shadow:none;
                box-shadow:none; }
  .bp3-input.bp3-intent-warning{
    -webkit-box-shadow:0 0 0 0 rgba(217, 130, 43, 0), 0 0 0 0 rgba(217, 130, 43, 0), inset 0 0 0 1px #d9822b, inset 0 0 0 1px rgba(16, 22, 26, 0.15), inset 0 1px 1px rgba(16, 22, 26, 0.2);
            box-shadow:0 0 0 0 rgba(217, 130, 43, 0), 0 0 0 0 rgba(217, 130, 43, 0), inset 0 0 0 1px #d9822b, inset 0 0 0 1px rgba(16, 22, 26, 0.15), inset 0 1px 1px rgba(16, 22, 26, 0.2); }
    .bp3-input.bp3-intent-warning:focus{
      -webkit-box-shadow:0 0 0 1px #d9822b, 0 0 0 3px rgba(217, 130, 43, 0.3), inset 0 1px 1px rgba(16, 22, 26, 0.2);
              box-shadow:0 0 0 1px #d9822b, 0 0 0 3px rgba(217, 130, 43, 0.3), inset 0 1px 1px rgba(16, 22, 26, 0.2); }
    .bp3-input.bp3-intent-warning[readonly]{
      -webkit-box-shadow:inset 0 0 0 1px #d9822b;
              box-shadow:inset 0 0 0 1px #d9822b; }
    .bp3-input.bp3-intent-warning:disabled, .bp3-input.bp3-intent-warning.bp3-disabled{
      -webkit-box-shadow:none;
              box-shadow:none; }
    .bp3-dark .bp3-input.bp3-intent-warning{
      -webkit-box-shadow:0 0 0 0 rgba(217, 130, 43, 0), 0 0 0 0 rgba(217, 130, 43, 0), 0 0 0 0 rgba(217, 130, 43, 0), inset 0 0 0 1px #d9822b, inset 0 0 0 1px rgba(16, 22, 26, 0.3), inset 0 1px 1px rgba(16, 22, 26, 0.4);
              box-shadow:0 0 0 0 rgba(217, 130, 43, 0), 0 0 0 0 rgba(217, 130, 43, 0), 0 0 0 0 rgba(217, 130, 43, 0), inset 0 0 0 1px #d9822b, inset 0 0 0 1px rgba(16, 22, 26, 0.3), inset 0 1px 1px rgba(16, 22, 26, 0.4); }
      .bp3-dark .bp3-input.bp3-intent-warning:focus{
        -webkit-box-shadow:0 0 0 1px #d9822b, 0 0 0 1px #d9822b, 0 0 0 3px rgba(217, 130, 43, 0.3), inset 0 0 0 1px rgba(16, 22, 26, 0.3), inset 0 1px 1px rgba(16, 22, 26, 0.4);
                box-shadow:0 0 0 1px #d9822b, 0 0 0 1px #d9822b, 0 0 0 3px rgba(217, 130, 43, 0.3), inset 0 0 0 1px rgba(16, 22, 26, 0.3), inset 0 1px 1px rgba(16, 22, 26, 0.4); }
      .bp3-dark .bp3-input.bp3-intent-warning[readonly]{
        -webkit-box-shadow:inset 0 0 0 1px #d9822b;
                box-shadow:inset 0 0 0 1px #d9822b; }
      .bp3-dark .bp3-input.bp3-intent-warning:disabled, .bp3-dark .bp3-input.bp3-intent-warning.bp3-disabled{
        -webkit-box-shadow:none;
                box-shadow:none; }
  .bp3-input.bp3-intent-danger{
    -webkit-box-shadow:0 0 0 0 rgba(219, 55, 55, 0), 0 0 0 0 rgba(219, 55, 55, 0), inset 0 0 0 1px #db3737, inset 0 0 0 1px rgba(16, 22, 26, 0.15), inset 0 1px 1px rgba(16, 22, 26, 0.2);
            box-shadow:0 0 0 0 rgba(219, 55, 55, 0), 0 0 0 0 rgba(219, 55, 55, 0), inset 0 0 0 1px #db3737, inset 0 0 0 1px rgba(16, 22, 26, 0.15), inset 0 1px 1px rgba(16, 22, 26, 0.2); }
    .bp3-input.bp3-intent-danger:focus{
      -webkit-box-shadow:0 0 0 1px #db3737, 0 0 0 3px rgba(219, 55, 55, 0.3), inset 0 1px 1px rgba(16, 22, 26, 0.2);
              box-shadow:0 0 0 1px #db3737, 0 0 0 3px rgba(219, 55, 55, 0.3), inset 0 1px 1px rgba(16, 22, 26, 0.2); }
    .bp3-input.bp3-intent-danger[readonly]{
      -webkit-box-shadow:inset 0 0 0 1px #db3737;
              box-shadow:inset 0 0 0 1px #db3737; }
    .bp3-input.bp3-intent-danger:disabled, .bp3-input.bp3-intent-danger.bp3-disabled{
      -webkit-box-shadow:none;
              box-shadow:none; }
    .bp3-dark .bp3-input.bp3-intent-danger{
      -webkit-box-shadow:0 0 0 0 rgba(219, 55, 55, 0), 0 0 0 0 rgba(219, 55, 55, 0), 0 0 0 0 rgba(219, 55, 55, 0), inset 0 0 0 1px #db3737, inset 0 0 0 1px rgba(16, 22, 26, 0.3), inset 0 1px 1px rgba(16, 22, 26, 0.4);
              box-shadow:0 0 0 0 rgba(219, 55, 55, 0), 0 0 0 0 rgba(219, 55, 55, 0), 0 0 0 0 rgba(219, 55, 55, 0), inset 0 0 0 1px #db3737, inset 0 0 0 1px rgba(16, 22, 26, 0.3), inset 0 1px 1px rgba(16, 22, 26, 0.4); }
      .bp3-dark .bp3-input.bp3-intent-danger:focus{
        -webkit-box-shadow:0 0 0 1px #db3737, 0 0 0 1px #db3737, 0 0 0 3px rgba(219, 55, 55, 0.3), inset 0 0 0 1px rgba(16, 22, 26, 0.3), inset 0 1px 1px rgba(16, 22, 26, 0.4);
                box-shadow:0 0 0 1px #db3737, 0 0 0 1px #db3737, 0 0 0 3px rgba(219, 55, 55, 0.3), inset 0 0 0 1px rgba(16, 22, 26, 0.3), inset 0 1px 1px rgba(16, 22, 26, 0.4); }
      .bp3-dark .bp3-input.bp3-intent-danger[readonly]{
        -webkit-box-shadow:inset 0 0 0 1px #db3737;
                box-shadow:inset 0 0 0 1px #db3737; }
      .bp3-dark .bp3-input.bp3-intent-danger:disabled, .bp3-dark .bp3-input.bp3-intent-danger.bp3-disabled{
        -webkit-box-shadow:none;
                box-shadow:none; }
  .bp3-input::-ms-clear{
    display:none; }
textarea.bp3-input{
  max-width:100%;
  padding:10px; }
  textarea.bp3-input, textarea.bp3-input.bp3-large, textarea.bp3-input.bp3-small{
    height:auto;
    line-height:inherit; }
  textarea.bp3-input.bp3-small{
    padding:8px; }
  .bp3-dark textarea.bp3-input{
    -webkit-box-shadow:0 0 0 0 rgba(19, 124, 189, 0), 0 0 0 0 rgba(19, 124, 189, 0), 0 0 0 0 rgba(19, 124, 189, 0), inset 0 0 0 1px rgba(16, 22, 26, 0.3), inset 0 1px 1px rgba(16, 22, 26, 0.4);
            box-shadow:0 0 0 0 rgba(19, 124, 189, 0), 0 0 0 0 rgba(19, 124, 189, 0), 0 0 0 0 rgba(19, 124, 189, 0), inset 0 0 0 1px rgba(16, 22, 26, 0.3), inset 0 1px 1px rgba(16, 22, 26, 0.4);
    background:rgba(16, 22, 26, 0.3);
    color:#f5f8fa; }
    .bp3-dark textarea.bp3-input::-webkit-input-placeholder{
      color:rgba(167, 182, 194, 0.6); }
    .bp3-dark textarea.bp3-input::-moz-placeholder{
      color:rgba(167, 182, 194, 0.6); }
    .bp3-dark textarea.bp3-input:-ms-input-placeholder{
      color:rgba(167, 182, 194, 0.6); }
    .bp3-dark textarea.bp3-input::-ms-input-placeholder{
      color:rgba(167, 182, 194, 0.6); }
    .bp3-dark textarea.bp3-input::placeholder{
      color:rgba(167, 182, 194, 0.6); }
    .bp3-dark textarea.bp3-input:focus{
      -webkit-box-shadow:0 0 0 1px #137cbd, 0 0 0 1px #137cbd, 0 0 0 3px rgba(19, 124, 189, 0.3), inset 0 0 0 1px rgba(16, 22, 26, 0.3), inset 0 1px 1px rgba(16, 22, 26, 0.4);
              box-shadow:0 0 0 1px #137cbd, 0 0 0 1px #137cbd, 0 0 0 3px rgba(19, 124, 189, 0.3), inset 0 0 0 1px rgba(16, 22, 26, 0.3), inset 0 1px 1px rgba(16, 22, 26, 0.4); }
    .bp3-dark textarea.bp3-input[readonly]{
      -webkit-box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.4);
              box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.4); }
    .bp3-dark textarea.bp3-input:disabled, .bp3-dark textarea.bp3-input.bp3-disabled{
      -webkit-box-shadow:none;
              box-shadow:none;
      background:rgba(57, 75, 89, 0.5);
      color:rgba(167, 182, 194, 0.6); }
label.bp3-label{
  display:block;
  margin-top:0;
  margin-bottom:15px; }
  label.bp3-label .bp3-html-select,
  label.bp3-label .bp3-input,
  label.bp3-label .bp3-select,
  label.bp3-label .bp3-slider,
  label.bp3-label .bp3-popover-wrapper{
    display:block;
    margin-top:5px;
    text-transform:none; }
  label.bp3-label .bp3-button-group{
    margin-top:5px; }
  label.bp3-label .bp3-select select,
  label.bp3-label .bp3-html-select select{
    width:100%;
    vertical-align:top;
    font-weight:400; }
  label.bp3-label.bp3-disabled,
  label.bp3-label.bp3-disabled .bp3-text-muted{
    color:rgba(92, 112, 128, 0.6); }
  label.bp3-label.bp3-inline{
    line-height:30px; }
    label.bp3-label.bp3-inline .bp3-html-select,
    label.bp3-label.bp3-inline .bp3-input,
    label.bp3-label.bp3-inline .bp3-input-group,
    label.bp3-label.bp3-inline .bp3-select,
    label.bp3-label.bp3-inline .bp3-popover-wrapper{
      display:inline-block;
      margin:0 0 0 5px;
      vertical-align:top; }
    label.bp3-label.bp3-inline .bp3-button-group{
      margin:0 0 0 5px; }
    label.bp3-label.bp3-inline .bp3-input-group .bp3-input{
      margin-left:0; }
    label.bp3-label.bp3-inline.bp3-large{
      line-height:40px; }
  label.bp3-label:not(.bp3-inline) .bp3-popover-target{
    display:block; }
  .bp3-dark label.bp3-label{
    color:#f5f8fa; }
    .bp3-dark label.bp3-label.bp3-disabled,
    .bp3-dark label.bp3-label.bp3-disabled .bp3-text-muted{
      color:rgba(167, 182, 194, 0.6); }
.bp3-numeric-input .bp3-button-group.bp3-vertical > .bp3-button{
  -webkit-box-flex:1;
      -ms-flex:1 1 14px;
          flex:1 1 14px;
  width:30px;
  min-height:0;
  padding:0; }
  .bp3-numeric-input .bp3-button-group.bp3-vertical > .bp3-button:first-child{
    border-radius:0 3px 0 0; }
  .bp3-numeric-input .bp3-button-group.bp3-vertical > .bp3-button:last-child{
    border-radius:0 0 3px 0; }

.bp3-numeric-input .bp3-button-group.bp3-vertical:first-child > .bp3-button:first-child{
  border-radius:3px 0 0 0; }

.bp3-numeric-input .bp3-button-group.bp3-vertical:first-child > .bp3-button:last-child{
  border-radius:0 0 0 3px; }

.bp3-numeric-input.bp3-large .bp3-button-group.bp3-vertical > .bp3-button{
  width:40px; }

form{
  display:block; }
.bp3-html-select select,
.bp3-select select{
  display:-webkit-inline-box;
  display:-ms-inline-flexbox;
  display:inline-flex;
  -webkit-box-orient:horizontal;
  -webkit-box-direction:normal;
      -ms-flex-direction:row;
          flex-direction:row;
  -webkit-box-align:center;
      -ms-flex-align:center;
          align-items:center;
  -webkit-box-pack:center;
      -ms-flex-pack:center;
          justify-content:center;
  border:none;
  border-radius:3px;
  cursor:pointer;
  padding:5px 10px;
  vertical-align:middle;
  text-align:left;
  font-size:14px;
  -webkit-box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.2), inset 0 -1px 0 rgba(16, 22, 26, 0.1);
          box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.2), inset 0 -1px 0 rgba(16, 22, 26, 0.1);
  background-color:#f5f8fa;
  background-image:-webkit-gradient(linear, left top, left bottom, from(rgba(255, 255, 255, 0.8)), to(rgba(255, 255, 255, 0)));
  background-image:linear-gradient(to bottom, rgba(255, 255, 255, 0.8), rgba(255, 255, 255, 0));
  color:#182026;
  border-radius:3px;
  width:100%;
  height:30px;
  padding:0 25px 0 10px;
  -moz-appearance:none;
  -webkit-appearance:none; }
  .bp3-html-select select > *, .bp3-select select > *{
    -webkit-box-flex:0;
        -ms-flex-positive:0;
            flex-grow:0;
    -ms-flex-negative:0;
        flex-shrink:0; }
  .bp3-html-select select > .bp3-fill, .bp3-select select > .bp3-fill{
    -webkit-box-flex:1;
        -ms-flex-positive:1;
            flex-grow:1;
    -ms-flex-negative:1;
        flex-shrink:1; }
  .bp3-html-select select::before,
  .bp3-select select::before, .bp3-html-select select > *, .bp3-select select > *{
    margin-right:7px; }
  .bp3-html-select select:empty::before,
  .bp3-select select:empty::before,
  .bp3-html-select select > :last-child,
  .bp3-select select > :last-child{
    margin-right:0; }
  .bp3-html-select select:hover,
  .bp3-select select:hover{
    -webkit-box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.2), inset 0 -1px 0 rgba(16, 22, 26, 0.1);
            box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.2), inset 0 -1px 0 rgba(16, 22, 26, 0.1);
    background-clip:padding-box;
    background-color:#ebf1f5; }
  .bp3-html-select select:active,
  .bp3-select select:active, .bp3-html-select select.bp3-active,
  .bp3-select select.bp3-active{
    -webkit-box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.2), inset 0 1px 2px rgba(16, 22, 26, 0.2);
            box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.2), inset 0 1px 2px rgba(16, 22, 26, 0.2);
    background-color:#d8e1e8;
    background-image:none; }
  .bp3-html-select select:disabled,
  .bp3-select select:disabled, .bp3-html-select select.bp3-disabled,
  .bp3-select select.bp3-disabled{
    outline:none;
    -webkit-box-shadow:none;
            box-shadow:none;
    background-color:rgba(206, 217, 224, 0.5);
    background-image:none;
    cursor:not-allowed;
    color:rgba(92, 112, 128, 0.6); }
    .bp3-html-select select:disabled.bp3-active,
    .bp3-select select:disabled.bp3-active, .bp3-html-select select:disabled.bp3-active:hover,
    .bp3-select select:disabled.bp3-active:hover, .bp3-html-select select.bp3-disabled.bp3-active,
    .bp3-select select.bp3-disabled.bp3-active, .bp3-html-select select.bp3-disabled.bp3-active:hover,
    .bp3-select select.bp3-disabled.bp3-active:hover{
      background:rgba(206, 217, 224, 0.7); }

.bp3-html-select.bp3-minimal select,
.bp3-select.bp3-minimal select{
  -webkit-box-shadow:none;
          box-shadow:none;
  background:none; }
  .bp3-html-select.bp3-minimal select:hover,
  .bp3-select.bp3-minimal select:hover{
    -webkit-box-shadow:none;
            box-shadow:none;
    background:rgba(167, 182, 194, 0.3);
    text-decoration:none;
    color:#182026; }
  .bp3-html-select.bp3-minimal select:active,
  .bp3-select.bp3-minimal select:active, .bp3-html-select.bp3-minimal select.bp3-active,
  .bp3-select.bp3-minimal select.bp3-active{
    -webkit-box-shadow:none;
            box-shadow:none;
    background:rgba(115, 134, 148, 0.3);
    color:#182026; }
  .bp3-html-select.bp3-minimal select:disabled,
  .bp3-select.bp3-minimal select:disabled, .bp3-html-select.bp3-minimal select:disabled:hover,
  .bp3-select.bp3-minimal select:disabled:hover, .bp3-html-select.bp3-minimal select.bp3-disabled,
  .bp3-select.bp3-minimal select.bp3-disabled, .bp3-html-select.bp3-minimal select.bp3-disabled:hover,
  .bp3-select.bp3-minimal select.bp3-disabled:hover{
    background:none;
    cursor:not-allowed;
    color:rgba(92, 112, 128, 0.6); }
    .bp3-html-select.bp3-minimal select:disabled.bp3-active,
    .bp3-select.bp3-minimal select:disabled.bp3-active, .bp3-html-select.bp3-minimal select:disabled:hover.bp3-active,
    .bp3-select.bp3-minimal select:disabled:hover.bp3-active, .bp3-html-select.bp3-minimal select.bp3-disabled.bp3-active,
    .bp3-select.bp3-minimal select.bp3-disabled.bp3-active, .bp3-html-select.bp3-minimal select.bp3-disabled:hover.bp3-active,
    .bp3-select.bp3-minimal select.bp3-disabled:hover.bp3-active{
      background:rgba(115, 134, 148, 0.3); }
  .bp3-dark .bp3-html-select.bp3-minimal select, .bp3-html-select.bp3-minimal .bp3-dark select,
  .bp3-dark .bp3-select.bp3-minimal select, .bp3-select.bp3-minimal .bp3-dark select{
    -webkit-box-shadow:none;
            box-shadow:none;
    background:none;
    color:inherit; }
    .bp3-dark .bp3-html-select.bp3-minimal select:hover, .bp3-html-select.bp3-minimal .bp3-dark select:hover,
    .bp3-dark .bp3-select.bp3-minimal select:hover, .bp3-select.bp3-minimal .bp3-dark select:hover, .bp3-dark .bp3-html-select.bp3-minimal select:active, .bp3-html-select.bp3-minimal .bp3-dark select:active,
    .bp3-dark .bp3-select.bp3-minimal select:active, .bp3-select.bp3-minimal .bp3-dark select:active, .bp3-dark .bp3-html-select.bp3-minimal select.bp3-active, .bp3-html-select.bp3-minimal .bp3-dark select.bp3-active,
    .bp3-dark .bp3-select.bp3-minimal select.bp3-active, .bp3-select.bp3-minimal .bp3-dark select.bp3-active{
      -webkit-box-shadow:none;
              box-shadow:none;
      background:none; }
    .bp3-dark .bp3-html-select.bp3-minimal select:hover, .bp3-html-select.bp3-minimal .bp3-dark select:hover,
    .bp3-dark .bp3-select.bp3-minimal select:hover, .bp3-select.bp3-minimal .bp3-dark select:hover{
      background:rgba(138, 155, 168, 0.15); }
    .bp3-dark .bp3-html-select.bp3-minimal select:active, .bp3-html-select.bp3-minimal .bp3-dark select:active,
    .bp3-dark .bp3-select.bp3-minimal select:active, .bp3-select.bp3-minimal .bp3-dark select:active, .bp3-dark .bp3-html-select.bp3-minimal select.bp3-active, .bp3-html-select.bp3-minimal .bp3-dark select.bp3-active,
    .bp3-dark .bp3-select.bp3-minimal select.bp3-active, .bp3-select.bp3-minimal .bp3-dark select.bp3-active{
      background:rgba(138, 155, 168, 0.3);
      color:#f5f8fa; }
    .bp3-dark .bp3-html-select.bp3-minimal select:disabled, .bp3-html-select.bp3-minimal .bp3-dark select:disabled,
    .bp3-dark .bp3-select.bp3-minimal select:disabled, .bp3-select.bp3-minimal .bp3-dark select:disabled, .bp3-dark .bp3-html-select.bp3-minimal select:disabled:hover, .bp3-html-select.bp3-minimal .bp3-dark select:disabled:hover,
    .bp3-dark .bp3-select.bp3-minimal select:disabled:hover, .bp3-select.bp3-minimal .bp3-dark select:disabled:hover, .bp3-dark .bp3-html-select.bp3-minimal select.bp3-disabled, .bp3-html-select.bp3-minimal .bp3-dark select.bp3-disabled,
    .bp3-dark .bp3-select.bp3-minimal select.bp3-disabled, .bp3-select.bp3-minimal .bp3-dark select.bp3-disabled, .bp3-dark .bp3-html-select.bp3-minimal select.bp3-disabled:hover, .bp3-html-select.bp3-minimal .bp3-dark select.bp3-disabled:hover,
    .bp3-dark .bp3-select.bp3-minimal select.bp3-disabled:hover, .bp3-select.bp3-minimal .bp3-dark select.bp3-disabled:hover{
      background:none;
      cursor:not-allowed;
      color:rgba(167, 182, 194, 0.6); }
      .bp3-dark .bp3-html-select.bp3-minimal select:disabled.bp3-active, .bp3-html-select.bp3-minimal .bp3-dark select:disabled.bp3-active,
      .bp3-dark .bp3-select.bp3-minimal select:disabled.bp3-active, .bp3-select.bp3-minimal .bp3-dark select:disabled.bp3-active, .bp3-dark .bp3-html-select.bp3-minimal select:disabled:hover.bp3-active, .bp3-html-select.bp3-minimal .bp3-dark select:disabled:hover.bp3-active,
      .bp3-dark .bp3-select.bp3-minimal select:disabled:hover.bp3-active, .bp3-select.bp3-minimal .bp3-dark select:disabled:hover.bp3-active, .bp3-dark .bp3-html-select.bp3-minimal select.bp3-disabled.bp3-active, .bp3-html-select.bp3-minimal .bp3-dark select.bp3-disabled.bp3-active,
      .bp3-dark .bp3-select.bp3-minimal select.bp3-disabled.bp3-active, .bp3-select.bp3-minimal .bp3-dark select.bp3-disabled.bp3-active, .bp3-dark .bp3-html-select.bp3-minimal select.bp3-disabled:hover.bp3-active, .bp3-html-select.bp3-minimal .bp3-dark select.bp3-disabled:hover.bp3-active,
      .bp3-dark .bp3-select.bp3-minimal select.bp3-disabled:hover.bp3-active, .bp3-select.bp3-minimal .bp3-dark select.bp3-disabled:hover.bp3-active{
        background:rgba(138, 155, 168, 0.3); }
  .bp3-html-select.bp3-minimal select.bp3-intent-primary,
  .bp3-select.bp3-minimal select.bp3-intent-primary{
    color:#106ba3; }
    .bp3-html-select.bp3-minimal select.bp3-intent-primary:hover,
    .bp3-select.bp3-minimal select.bp3-intent-primary:hover, .bp3-html-select.bp3-minimal select.bp3-intent-primary:active,
    .bp3-select.bp3-minimal select.bp3-intent-primary:active, .bp3-html-select.bp3-minimal select.bp3-intent-primary.bp3-active,
    .bp3-select.bp3-minimal select.bp3-intent-primary.bp3-active{
      -webkit-box-shadow:none;
              box-shadow:none;
      background:none;
      color:#106ba3; }
    .bp3-html-select.bp3-minimal select.bp3-intent-primary:hover,
    .bp3-select.bp3-minimal select.bp3-intent-primary:hover{
      background:rgba(19, 124, 189, 0.15);
      color:#106ba3; }
    .bp3-html-select.bp3-minimal select.bp3-intent-primary:active,
    .bp3-select.bp3-minimal select.bp3-intent-primary:active, .bp3-html-select.bp3-minimal select.bp3-intent-primary.bp3-active,
    .bp3-select.bp3-minimal select.bp3-intent-primary.bp3-active{
      background:rgba(19, 124, 189, 0.3);
      color:#106ba3; }
    .bp3-html-select.bp3-minimal select.bp3-intent-primary:disabled,
    .bp3-select.bp3-minimal select.bp3-intent-primary:disabled, .bp3-html-select.bp3-minimal select.bp3-intent-primary.bp3-disabled,
    .bp3-select.bp3-minimal select.bp3-intent-primary.bp3-disabled{
      background:none;
      color:rgba(16, 107, 163, 0.5); }
      .bp3-html-select.bp3-minimal select.bp3-intent-primary:disabled.bp3-active,
      .bp3-select.bp3-minimal select.bp3-intent-primary:disabled.bp3-active, .bp3-html-select.bp3-minimal select.bp3-intent-primary.bp3-disabled.bp3-active,
      .bp3-select.bp3-minimal select.bp3-intent-primary.bp3-disabled.bp3-active{
        background:rgba(19, 124, 189, 0.3); }
    .bp3-html-select.bp3-minimal select.bp3-intent-primary .bp3-button-spinner .bp3-spinner-head, .bp3-select.bp3-minimal select.bp3-intent-primary .bp3-button-spinner .bp3-spinner-head{
      stroke:#106ba3; }
    .bp3-dark .bp3-html-select.bp3-minimal select.bp3-intent-primary, .bp3-html-select.bp3-minimal .bp3-dark select.bp3-intent-primary,
    .bp3-dark .bp3-select.bp3-minimal select.bp3-intent-primary, .bp3-select.bp3-minimal .bp3-dark select.bp3-intent-primary{
      color:#48aff0; }
      .bp3-dark .bp3-html-select.bp3-minimal select.bp3-intent-primary:hover, .bp3-html-select.bp3-minimal .bp3-dark select.bp3-intent-primary:hover,
      .bp3-dark .bp3-select.bp3-minimal select.bp3-intent-primary:hover, .bp3-select.bp3-minimal .bp3-dark select.bp3-intent-primary:hover{
        background:rgba(19, 124, 189, 0.2);
        color:#48aff0; }
      .bp3-dark .bp3-html-select.bp3-minimal select.bp3-intent-primary:active, .bp3-html-select.bp3-minimal .bp3-dark select.bp3-intent-primary:active,
      .bp3-dark .bp3-select.bp3-minimal select.bp3-intent-primary:active, .bp3-select.bp3-minimal .bp3-dark select.bp3-intent-primary:active, .bp3-dark .bp3-html-select.bp3-minimal select.bp3-intent-primary.bp3-active, .bp3-html-select.bp3-minimal .bp3-dark select.bp3-intent-primary.bp3-active,
      .bp3-dark .bp3-select.bp3-minimal select.bp3-intent-primary.bp3-active, .bp3-select.bp3-minimal .bp3-dark select.bp3-intent-primary.bp3-active{
        background:rgba(19, 124, 189, 0.3);
        color:#48aff0; }
      .bp3-dark .bp3-html-select.bp3-minimal select.bp3-intent-primary:disabled, .bp3-html-select.bp3-minimal .bp3-dark select.bp3-intent-primary:disabled,
      .bp3-dark .bp3-select.bp3-minimal select.bp3-intent-primary:disabled, .bp3-select.bp3-minimal .bp3-dark select.bp3-intent-primary:disabled, .bp3-dark .bp3-html-select.bp3-minimal select.bp3-intent-primary.bp3-disabled, .bp3-html-select.bp3-minimal .bp3-dark select.bp3-intent-primary.bp3-disabled,
      .bp3-dark .bp3-select.bp3-minimal select.bp3-intent-primary.bp3-disabled, .bp3-select.bp3-minimal .bp3-dark select.bp3-intent-primary.bp3-disabled{
        background:none;
        color:rgba(72, 175, 240, 0.5); }
        .bp3-dark .bp3-html-select.bp3-minimal select.bp3-intent-primary:disabled.bp3-active, .bp3-html-select.bp3-minimal .bp3-dark select.bp3-intent-primary:disabled.bp3-active,
        .bp3-dark .bp3-select.bp3-minimal select.bp3-intent-primary:disabled.bp3-active, .bp3-select.bp3-minimal .bp3-dark select.bp3-intent-primary:disabled.bp3-active, .bp3-dark .bp3-html-select.bp3-minimal select.bp3-intent-primary.bp3-disabled.bp3-active, .bp3-html-select.bp3-minimal .bp3-dark select.bp3-intent-primary.bp3-disabled.bp3-active,
        .bp3-dark .bp3-select.bp3-minimal select.bp3-intent-primary.bp3-disabled.bp3-active, .bp3-select.bp3-minimal .bp3-dark select.bp3-intent-primary.bp3-disabled.bp3-active{
          background:rgba(19, 124, 189, 0.3); }
  .bp3-html-select.bp3-minimal select.bp3-intent-success,
  .bp3-select.bp3-minimal select.bp3-intent-success{
    color:#0d8050; }
    .bp3-html-select.bp3-minimal select.bp3-intent-success:hover,
    .bp3-select.bp3-minimal select.bp3-intent-success:hover, .bp3-html-select.bp3-minimal select.bp3-intent-success:active,
    .bp3-select.bp3-minimal select.bp3-intent-success:active, .bp3-html-select.bp3-minimal select.bp3-intent-success.bp3-active,
    .bp3-select.bp3-minimal select.bp3-intent-success.bp3-active{
      -webkit-box-shadow:none;
              box-shadow:none;
      background:none;
      color:#0d8050; }
    .bp3-html-select.bp3-minimal select.bp3-intent-success:hover,
    .bp3-select.bp3-minimal select.bp3-intent-success:hover{
      background:rgba(15, 153, 96, 0.15);
      color:#0d8050; }
    .bp3-html-select.bp3-minimal select.bp3-intent-success:active,
    .bp3-select.bp3-minimal select.bp3-intent-success:active, .bp3-html-select.bp3-minimal select.bp3-intent-success.bp3-active,
    .bp3-select.bp3-minimal select.bp3-intent-success.bp3-active{
      background:rgba(15, 153, 96, 0.3);
      color:#0d8050; }
    .bp3-html-select.bp3-minimal select.bp3-intent-success:disabled,
    .bp3-select.bp3-minimal select.bp3-intent-success:disabled, .bp3-html-select.bp3-minimal select.bp3-intent-success.bp3-disabled,
    .bp3-select.bp3-minimal select.bp3-intent-success.bp3-disabled{
      background:none;
      color:rgba(13, 128, 80, 0.5); }
      .bp3-html-select.bp3-minimal select.bp3-intent-success:disabled.bp3-active,
      .bp3-select.bp3-minimal select.bp3-intent-success:disabled.bp3-active, .bp3-html-select.bp3-minimal select.bp3-intent-success.bp3-disabled.bp3-active,
      .bp3-select.bp3-minimal select.bp3-intent-success.bp3-disabled.bp3-active{
        background:rgba(15, 153, 96, 0.3); }
    .bp3-html-select.bp3-minimal select.bp3-intent-success .bp3-button-spinner .bp3-spinner-head, .bp3-select.bp3-minimal select.bp3-intent-success .bp3-button-spinner .bp3-spinner-head{
      stroke:#0d8050; }
    .bp3-dark .bp3-html-select.bp3-minimal select.bp3-intent-success, .bp3-html-select.bp3-minimal .bp3-dark select.bp3-intent-success,
    .bp3-dark .bp3-select.bp3-minimal select.bp3-intent-success, .bp3-select.bp3-minimal .bp3-dark select.bp3-intent-success{
      color:#3dcc91; }
      .bp3-dark .bp3-html-select.bp3-minimal select.bp3-intent-success:hover, .bp3-html-select.bp3-minimal .bp3-dark select.bp3-intent-success:hover,
      .bp3-dark .bp3-select.bp3-minimal select.bp3-intent-success:hover, .bp3-select.bp3-minimal .bp3-dark select.bp3-intent-success:hover{
        background:rgba(15, 153, 96, 0.2);
        color:#3dcc91; }
      .bp3-dark .bp3-html-select.bp3-minimal select.bp3-intent-success:active, .bp3-html-select.bp3-minimal .bp3-dark select.bp3-intent-success:active,
      .bp3-dark .bp3-select.bp3-minimal select.bp3-intent-success:active, .bp3-select.bp3-minimal .bp3-dark select.bp3-intent-success:active, .bp3-dark .bp3-html-select.bp3-minimal select.bp3-intent-success.bp3-active, .bp3-html-select.bp3-minimal .bp3-dark select.bp3-intent-success.bp3-active,
      .bp3-dark .bp3-select.bp3-minimal select.bp3-intent-success.bp3-active, .bp3-select.bp3-minimal .bp3-dark select.bp3-intent-success.bp3-active{
        background:rgba(15, 153, 96, 0.3);
        color:#3dcc91; }
      .bp3-dark .bp3-html-select.bp3-minimal select.bp3-intent-success:disabled, .bp3-html-select.bp3-minimal .bp3-dark select.bp3-intent-success:disabled,
      .bp3-dark .bp3-select.bp3-minimal select.bp3-intent-success:disabled, .bp3-select.bp3-minimal .bp3-dark select.bp3-intent-success:disabled, .bp3-dark .bp3-html-select.bp3-minimal select.bp3-intent-success.bp3-disabled, .bp3-html-select.bp3-minimal .bp3-dark select.bp3-intent-success.bp3-disabled,
      .bp3-dark .bp3-select.bp3-minimal select.bp3-intent-success.bp3-disabled, .bp3-select.bp3-minimal .bp3-dark select.bp3-intent-success.bp3-disabled{
        background:none;
        color:rgba(61, 204, 145, 0.5); }
        .bp3-dark .bp3-html-select.bp3-minimal select.bp3-intent-success:disabled.bp3-active, .bp3-html-select.bp3-minimal .bp3-dark select.bp3-intent-success:disabled.bp3-active,
        .bp3-dark .bp3-select.bp3-minimal select.bp3-intent-success:disabled.bp3-active, .bp3-select.bp3-minimal .bp3-dark select.bp3-intent-success:disabled.bp3-active, .bp3-dark .bp3-html-select.bp3-minimal select.bp3-intent-success.bp3-disabled.bp3-active, .bp3-html-select.bp3-minimal .bp3-dark select.bp3-intent-success.bp3-disabled.bp3-active,
        .bp3-dark .bp3-select.bp3-minimal select.bp3-intent-success.bp3-disabled.bp3-active, .bp3-select.bp3-minimal .bp3-dark select.bp3-intent-success.bp3-disabled.bp3-active{
          background:rgba(15, 153, 96, 0.3); }
  .bp3-html-select.bp3-minimal select.bp3-intent-warning,
  .bp3-select.bp3-minimal select.bp3-intent-warning{
    color:#bf7326; }
    .bp3-html-select.bp3-minimal select.bp3-intent-warning:hover,
    .bp3-select.bp3-minimal select.bp3-intent-warning:hover, .bp3-html-select.bp3-minimal select.bp3-intent-warning:active,
    .bp3-select.bp3-minimal select.bp3-intent-warning:active, .bp3-html-select.bp3-minimal select.bp3-intent-warning.bp3-active,
    .bp3-select.bp3-minimal select.bp3-intent-warning.bp3-active{
      -webkit-box-shadow:none;
              box-shadow:none;
      background:none;
      color:#bf7326; }
    .bp3-html-select.bp3-minimal select.bp3-intent-warning:hover,
    .bp3-select.bp3-minimal select.bp3-intent-warning:hover{
      background:rgba(217, 130, 43, 0.15);
      color:#bf7326; }
    .bp3-html-select.bp3-minimal select.bp3-intent-warning:active,
    .bp3-select.bp3-minimal select.bp3-intent-warning:active, .bp3-html-select.bp3-minimal select.bp3-intent-warning.bp3-active,
    .bp3-select.bp3-minimal select.bp3-intent-warning.bp3-active{
      background:rgba(217, 130, 43, 0.3);
      color:#bf7326; }
    .bp3-html-select.bp3-minimal select.bp3-intent-warning:disabled,
    .bp3-select.bp3-minimal select.bp3-intent-warning:disabled, .bp3-html-select.bp3-minimal select.bp3-intent-warning.bp3-disabled,
    .bp3-select.bp3-minimal select.bp3-intent-warning.bp3-disabled{
      background:none;
      color:rgba(191, 115, 38, 0.5); }
      .bp3-html-select.bp3-minimal select.bp3-intent-warning:disabled.bp3-active,
      .bp3-select.bp3-minimal select.bp3-intent-warning:disabled.bp3-active, .bp3-html-select.bp3-minimal select.bp3-intent-warning.bp3-disabled.bp3-active,
      .bp3-select.bp3-minimal select.bp3-intent-warning.bp3-disabled.bp3-active{
        background:rgba(217, 130, 43, 0.3); }
    .bp3-html-select.bp3-minimal select.bp3-intent-warning .bp3-button-spinner .bp3-spinner-head, .bp3-select.bp3-minimal select.bp3-intent-warning .bp3-button-spinner .bp3-spinner-head{
      stroke:#bf7326; }
    .bp3-dark .bp3-html-select.bp3-minimal select.bp3-intent-warning, .bp3-html-select.bp3-minimal .bp3-dark select.bp3-intent-warning,
    .bp3-dark .bp3-select.bp3-minimal select.bp3-intent-warning, .bp3-select.bp3-minimal .bp3-dark select.bp3-intent-warning{
      color:#ffb366; }
      .bp3-dark .bp3-html-select.bp3-minimal select.bp3-intent-warning:hover, .bp3-html-select.bp3-minimal .bp3-dark select.bp3-intent-warning:hover,
      .bp3-dark .bp3-select.bp3-minimal select.bp3-intent-warning:hover, .bp3-select.bp3-minimal .bp3-dark select.bp3-intent-warning:hover{
        background:rgba(217, 130, 43, 0.2);
        color:#ffb366; }
      .bp3-dark .bp3-html-select.bp3-minimal select.bp3-intent-warning:active, .bp3-html-select.bp3-minimal .bp3-dark select.bp3-intent-warning:active,
      .bp3-dark .bp3-select.bp3-minimal select.bp3-intent-warning:active, .bp3-select.bp3-minimal .bp3-dark select.bp3-intent-warning:active, .bp3-dark .bp3-html-select.bp3-minimal select.bp3-intent-warning.bp3-active, .bp3-html-select.bp3-minimal .bp3-dark select.bp3-intent-warning.bp3-active,
      .bp3-dark .bp3-select.bp3-minimal select.bp3-intent-warning.bp3-active, .bp3-select.bp3-minimal .bp3-dark select.bp3-intent-warning.bp3-active{
        background:rgba(217, 130, 43, 0.3);
        color:#ffb366; }
      .bp3-dark .bp3-html-select.bp3-minimal select.bp3-intent-warning:disabled, .bp3-html-select.bp3-minimal .bp3-dark select.bp3-intent-warning:disabled,
      .bp3-dark .bp3-select.bp3-minimal select.bp3-intent-warning:disabled, .bp3-select.bp3-minimal .bp3-dark select.bp3-intent-warning:disabled, .bp3-dark .bp3-html-select.bp3-minimal select.bp3-intent-warning.bp3-disabled, .bp3-html-select.bp3-minimal .bp3-dark select.bp3-intent-warning.bp3-disabled,
      .bp3-dark .bp3-select.bp3-minimal select.bp3-intent-warning.bp3-disabled, .bp3-select.bp3-minimal .bp3-dark select.bp3-intent-warning.bp3-disabled{
        background:none;
        color:rgba(255, 179, 102, 0.5); }
        .bp3-dark .bp3-html-select.bp3-minimal select.bp3-intent-warning:disabled.bp3-active, .bp3-html-select.bp3-minimal .bp3-dark select.bp3-intent-warning:disabled.bp3-active,
        .bp3-dark .bp3-select.bp3-minimal select.bp3-intent-warning:disabled.bp3-active, .bp3-select.bp3-minimal .bp3-dark select.bp3-intent-warning:disabled.bp3-active, .bp3-dark .bp3-html-select.bp3-minimal select.bp3-intent-warning.bp3-disabled.bp3-active, .bp3-html-select.bp3-minimal .bp3-dark select.bp3-intent-warning.bp3-disabled.bp3-active,
        .bp3-dark .bp3-select.bp3-minimal select.bp3-intent-warning.bp3-disabled.bp3-active, .bp3-select.bp3-minimal .bp3-dark select.bp3-intent-warning.bp3-disabled.bp3-active{
          background:rgba(217, 130, 43, 0.3); }
  .bp3-html-select.bp3-minimal select.bp3-intent-danger,
  .bp3-select.bp3-minimal select.bp3-intent-danger{
    color:#c23030; }
    .bp3-html-select.bp3-minimal select.bp3-intent-danger:hover,
    .bp3-select.bp3-minimal select.bp3-intent-danger:hover, .bp3-html-select.bp3-minimal select.bp3-intent-danger:active,
    .bp3-select.bp3-minimal select.bp3-intent-danger:active, .bp3-html-select.bp3-minimal select.bp3-intent-danger.bp3-active,
    .bp3-select.bp3-minimal select.bp3-intent-danger.bp3-active{
      -webkit-box-shadow:none;
              box-shadow:none;
      background:none;
      color:#c23030; }
    .bp3-html-select.bp3-minimal select.bp3-intent-danger:hover,
    .bp3-select.bp3-minimal select.bp3-intent-danger:hover{
      background:rgba(219, 55, 55, 0.15);
      color:#c23030; }
    .bp3-html-select.bp3-minimal select.bp3-intent-danger:active,
    .bp3-select.bp3-minimal select.bp3-intent-danger:active, .bp3-html-select.bp3-minimal select.bp3-intent-danger.bp3-active,
    .bp3-select.bp3-minimal select.bp3-intent-danger.bp3-active{
      background:rgba(219, 55, 55, 0.3);
      color:#c23030; }
    .bp3-html-select.bp3-minimal select.bp3-intent-danger:disabled,
    .bp3-select.bp3-minimal select.bp3-intent-danger:disabled, .bp3-html-select.bp3-minimal select.bp3-intent-danger.bp3-disabled,
    .bp3-select.bp3-minimal select.bp3-intent-danger.bp3-disabled{
      background:none;
      color:rgba(194, 48, 48, 0.5); }
      .bp3-html-select.bp3-minimal select.bp3-intent-danger:disabled.bp3-active,
      .bp3-select.bp3-minimal select.bp3-intent-danger:disabled.bp3-active, .bp3-html-select.bp3-minimal select.bp3-intent-danger.bp3-disabled.bp3-active,
      .bp3-select.bp3-minimal select.bp3-intent-danger.bp3-disabled.bp3-active{
        background:rgba(219, 55, 55, 0.3); }
    .bp3-html-select.bp3-minimal select.bp3-intent-danger .bp3-button-spinner .bp3-spinner-head, .bp3-select.bp3-minimal select.bp3-intent-danger .bp3-button-spinner .bp3-spinner-head{
      stroke:#c23030; }
    .bp3-dark .bp3-html-select.bp3-minimal select.bp3-intent-danger, .bp3-html-select.bp3-minimal .bp3-dark select.bp3-intent-danger,
    .bp3-dark .bp3-select.bp3-minimal select.bp3-intent-danger, .bp3-select.bp3-minimal .bp3-dark select.bp3-intent-danger{
      color:#ff7373; }
      .bp3-dark .bp3-html-select.bp3-minimal select.bp3-intent-danger:hover, .bp3-html-select.bp3-minimal .bp3-dark select.bp3-intent-danger:hover,
      .bp3-dark .bp3-select.bp3-minimal select.bp3-intent-danger:hover, .bp3-select.bp3-minimal .bp3-dark select.bp3-intent-danger:hover{
        background:rgba(219, 55, 55, 0.2);
        color:#ff7373; }
      .bp3-dark .bp3-html-select.bp3-minimal select.bp3-intent-danger:active, .bp3-html-select.bp3-minimal .bp3-dark select.bp3-intent-danger:active,
      .bp3-dark .bp3-select.bp3-minimal select.bp3-intent-danger:active, .bp3-select.bp3-minimal .bp3-dark select.bp3-intent-danger:active, .bp3-dark .bp3-html-select.bp3-minimal select.bp3-intent-danger.bp3-active, .bp3-html-select.bp3-minimal .bp3-dark select.bp3-intent-danger.bp3-active,
      .bp3-dark .bp3-select.bp3-minimal select.bp3-intent-danger.bp3-active, .bp3-select.bp3-minimal .bp3-dark select.bp3-intent-danger.bp3-active{
        background:rgba(219, 55, 55, 0.3);
        color:#ff7373; }
      .bp3-dark .bp3-html-select.bp3-minimal select.bp3-intent-danger:disabled, .bp3-html-select.bp3-minimal .bp3-dark select.bp3-intent-danger:disabled,
      .bp3-dark .bp3-select.bp3-minimal select.bp3-intent-danger:disabled, .bp3-select.bp3-minimal .bp3-dark select.bp3-intent-danger:disabled, .bp3-dark .bp3-html-select.bp3-minimal select.bp3-intent-danger.bp3-disabled, .bp3-html-select.bp3-minimal .bp3-dark select.bp3-intent-danger.bp3-disabled,
      .bp3-dark .bp3-select.bp3-minimal select.bp3-intent-danger.bp3-disabled, .bp3-select.bp3-minimal .bp3-dark select.bp3-intent-danger.bp3-disabled{
        background:none;
        color:rgba(255, 115, 115, 0.5); }
        .bp3-dark .bp3-html-select.bp3-minimal select.bp3-intent-danger:disabled.bp3-active, .bp3-html-select.bp3-minimal .bp3-dark select.bp3-intent-danger:disabled.bp3-active,
        .bp3-dark .bp3-select.bp3-minimal select.bp3-intent-danger:disabled.bp3-active, .bp3-select.bp3-minimal .bp3-dark select.bp3-intent-danger:disabled.bp3-active, .bp3-dark .bp3-html-select.bp3-minimal select.bp3-intent-danger.bp3-disabled.bp3-active, .bp3-html-select.bp3-minimal .bp3-dark select.bp3-intent-danger.bp3-disabled.bp3-active,
        .bp3-dark .bp3-select.bp3-minimal select.bp3-intent-danger.bp3-disabled.bp3-active, .bp3-select.bp3-minimal .bp3-dark select.bp3-intent-danger.bp3-disabled.bp3-active{
          background:rgba(219, 55, 55, 0.3); }

.bp3-html-select.bp3-large select,
.bp3-select.bp3-large select{
  height:40px;
  padding-right:35px;
  font-size:16px; }

.bp3-dark .bp3-html-select select, .bp3-dark .bp3-select select{
  -webkit-box-shadow:0 0 0 1px rgba(16, 22, 26, 0.4);
          box-shadow:0 0 0 1px rgba(16, 22, 26, 0.4);
  background-color:#394b59;
  background-image:-webkit-gradient(linear, left top, left bottom, from(rgba(255, 255, 255, 0.05)), to(rgba(255, 255, 255, 0)));
  background-image:linear-gradient(to bottom, rgba(255, 255, 255, 0.05), rgba(255, 255, 255, 0));
  color:#f5f8fa; }
  .bp3-dark .bp3-html-select select:hover, .bp3-dark .bp3-select select:hover, .bp3-dark .bp3-html-select select:active, .bp3-dark .bp3-select select:active, .bp3-dark .bp3-html-select select.bp3-active, .bp3-dark .bp3-select select.bp3-active{
    color:#f5f8fa; }
  .bp3-dark .bp3-html-select select:hover, .bp3-dark .bp3-select select:hover{
    -webkit-box-shadow:0 0 0 1px rgba(16, 22, 26, 0.4);
            box-shadow:0 0 0 1px rgba(16, 22, 26, 0.4);
    background-color:#30404d; }
  .bp3-dark .bp3-html-select select:active, .bp3-dark .bp3-select select:active, .bp3-dark .bp3-html-select select.bp3-active, .bp3-dark .bp3-select select.bp3-active{
    -webkit-box-shadow:0 0 0 1px rgba(16, 22, 26, 0.6), inset 0 1px 2px rgba(16, 22, 26, 0.2);
            box-shadow:0 0 0 1px rgba(16, 22, 26, 0.6), inset 0 1px 2px rgba(16, 22, 26, 0.2);
    background-color:#202b33;
    background-image:none; }
  .bp3-dark .bp3-html-select select:disabled, .bp3-dark .bp3-select select:disabled, .bp3-dark .bp3-html-select select.bp3-disabled, .bp3-dark .bp3-select select.bp3-disabled{
    -webkit-box-shadow:none;
            box-shadow:none;
    background-color:rgba(57, 75, 89, 0.5);
    background-image:none;
    color:rgba(167, 182, 194, 0.6); }
    .bp3-dark .bp3-html-select select:disabled.bp3-active, .bp3-dark .bp3-select select:disabled.bp3-active, .bp3-dark .bp3-html-select select.bp3-disabled.bp3-active, .bp3-dark .bp3-select select.bp3-disabled.bp3-active{
      background:rgba(57, 75, 89, 0.7); }
  .bp3-dark .bp3-html-select select .bp3-button-spinner .bp3-spinner-head, .bp3-dark .bp3-select select .bp3-button-spinner .bp3-spinner-head{
    background:rgba(16, 22, 26, 0.5);
    stroke:#8a9ba8; }

.bp3-html-select select:disabled,
.bp3-select select:disabled{
  -webkit-box-shadow:none;
          box-shadow:none;
  background-color:rgba(206, 217, 224, 0.5);
  cursor:not-allowed;
  color:rgba(92, 112, 128, 0.6); }

.bp3-html-select .bp3-icon,
.bp3-select .bp3-icon, .bp3-select::after{
  position:absolute;
  top:7px;
  right:7px;
  color:#5c7080;
  pointer-events:none; }
  .bp3-html-select .bp3-disabled.bp3-icon,
  .bp3-select .bp3-disabled.bp3-icon, .bp3-disabled.bp3-select::after{
    color:rgba(92, 112, 128, 0.6); }
.bp3-html-select,
.bp3-select{
  display:inline-block;
  position:relative;
  vertical-align:middle;
  letter-spacing:normal; }
  .bp3-html-select select::-ms-expand,
  .bp3-select select::-ms-expand{
    display:none; }
  .bp3-html-select .bp3-icon,
  .bp3-select .bp3-icon{
    color:#5c7080; }
    .bp3-html-select .bp3-icon:hover,
    .bp3-select .bp3-icon:hover{
      color:#182026; }
    .bp3-dark .bp3-html-select .bp3-icon, .bp3-dark
    .bp3-select .bp3-icon{
      color:#a7b6c2; }
      .bp3-dark .bp3-html-select .bp3-icon:hover, .bp3-dark
      .bp3-select .bp3-icon:hover{
        color:#f5f8fa; }
  .bp3-html-select.bp3-large::after,
  .bp3-html-select.bp3-large .bp3-icon,
  .bp3-select.bp3-large::after,
  .bp3-select.bp3-large .bp3-icon{
    top:12px;
    right:12px; }
  .bp3-html-select.bp3-fill,
  .bp3-html-select.bp3-fill select,
  .bp3-select.bp3-fill,
  .bp3-select.bp3-fill select{
    width:100%; }
  .bp3-dark .bp3-html-select option, .bp3-dark
  .bp3-select option{
    background-color:#30404d;
    color:#f5f8fa; }
  .bp3-dark .bp3-html-select::after, .bp3-dark
  .bp3-select::after{
    color:#a7b6c2; }

.bp3-select::after{
  line-height:1;
  font-family:"Icons16", sans-serif;
  font-size:16px;
  font-weight:400;
  font-style:normal;
  -moz-osx-font-smoothing:grayscale;
  -webkit-font-smoothing:antialiased;
  content:""; }
.bp3-running-text table, table.bp3-html-table{
  border-spacing:0;
  font-size:14px; }
  .bp3-running-text table th, table.bp3-html-table th,
  .bp3-running-text table td,
  table.bp3-html-table td{
    padding:11px;
    vertical-align:top;
    text-align:left; }
  .bp3-running-text table th, table.bp3-html-table th{
    color:#182026;
    font-weight:600; }
  
  .bp3-running-text table td,
  table.bp3-html-table td{
    color:#182026; }
  .bp3-running-text table tbody tr:first-child th, table.bp3-html-table tbody tr:first-child th,
  .bp3-running-text table tbody tr:first-child td,
  table.bp3-html-table tbody tr:first-child td{
    -webkit-box-shadow:inset 0 1px 0 0 rgba(16, 22, 26, 0.15);
            box-shadow:inset 0 1px 0 0 rgba(16, 22, 26, 0.15); }
  .bp3-dark .bp3-running-text table th, .bp3-running-text .bp3-dark table th, .bp3-dark table.bp3-html-table th{
    color:#f5f8fa; }
  .bp3-dark .bp3-running-text table td, .bp3-running-text .bp3-dark table td, .bp3-dark table.bp3-html-table td{
    color:#f5f8fa; }
  .bp3-dark .bp3-running-text table tbody tr:first-child th, .bp3-running-text .bp3-dark table tbody tr:first-child th, .bp3-dark table.bp3-html-table tbody tr:first-child th,
  .bp3-dark .bp3-running-text table tbody tr:first-child td,
  .bp3-running-text .bp3-dark table tbody tr:first-child td,
  .bp3-dark table.bp3-html-table tbody tr:first-child td{
    -webkit-box-shadow:inset 0 1px 0 0 rgba(255, 255, 255, 0.15);
            box-shadow:inset 0 1px 0 0 rgba(255, 255, 255, 0.15); }

table.bp3-html-table.bp3-html-table-condensed th,
table.bp3-html-table.bp3-html-table-condensed td, table.bp3-html-table.bp3-small th,
table.bp3-html-table.bp3-small td{
  padding-top:6px;
  padding-bottom:6px; }

table.bp3-html-table.bp3-html-table-striped tbody tr:nth-child(odd) td{
  background:rgba(191, 204, 214, 0.15); }

table.bp3-html-table.bp3-html-table-bordered th:not(:first-child){
  -webkit-box-shadow:inset 1px 0 0 0 rgba(16, 22, 26, 0.15);
          box-shadow:inset 1px 0 0 0 rgba(16, 22, 26, 0.15); }

table.bp3-html-table.bp3-html-table-bordered tbody tr td{
  -webkit-box-shadow:inset 0 1px 0 0 rgba(16, 22, 26, 0.15);
          box-shadow:inset 0 1px 0 0 rgba(16, 22, 26, 0.15); }
  table.bp3-html-table.bp3-html-table-bordered tbody tr td:not(:first-child){
    -webkit-box-shadow:inset 1px 1px 0 0 rgba(16, 22, 26, 0.15);
            box-shadow:inset 1px 1px 0 0 rgba(16, 22, 26, 0.15); }

table.bp3-html-table.bp3-html-table-bordered.bp3-html-table-striped tbody tr:not(:first-child) td{
  -webkit-box-shadow:none;
          box-shadow:none; }
  table.bp3-html-table.bp3-html-table-bordered.bp3-html-table-striped tbody tr:not(:first-child) td:not(:first-child){
    -webkit-box-shadow:inset 1px 0 0 0 rgba(16, 22, 26, 0.15);
            box-shadow:inset 1px 0 0 0 rgba(16, 22, 26, 0.15); }

table.bp3-html-table.bp3-interactive tbody tr:hover td{
  background-color:rgba(191, 204, 214, 0.3);
  cursor:pointer; }

table.bp3-html-table.bp3-interactive tbody tr:active td{
  background-color:rgba(191, 204, 214, 0.4); }

.bp3-dark table.bp3-html-table.bp3-html-table-striped tbody tr:nth-child(odd) td{
  background:rgba(92, 112, 128, 0.15); }

.bp3-dark table.bp3-html-table.bp3-html-table-bordered th:not(:first-child){
  -webkit-box-shadow:inset 1px 0 0 0 rgba(255, 255, 255, 0.15);
          box-shadow:inset 1px 0 0 0 rgba(255, 255, 255, 0.15); }

.bp3-dark table.bp3-html-table.bp3-html-table-bordered tbody tr td{
  -webkit-box-shadow:inset 0 1px 0 0 rgba(255, 255, 255, 0.15);
          box-shadow:inset 0 1px 0 0 rgba(255, 255, 255, 0.15); }
  .bp3-dark table.bp3-html-table.bp3-html-table-bordered tbody tr td:not(:first-child){
    -webkit-box-shadow:inset 1px 1px 0 0 rgba(255, 255, 255, 0.15);
            box-shadow:inset 1px 1px 0 0 rgba(255, 255, 255, 0.15); }

.bp3-dark table.bp3-html-table.bp3-html-table-bordered.bp3-html-table-striped tbody tr:not(:first-child) td{
  -webkit-box-shadow:inset 1px 0 0 0 rgba(255, 255, 255, 0.15);
          box-shadow:inset 1px 0 0 0 rgba(255, 255, 255, 0.15); }
  .bp3-dark table.bp3-html-table.bp3-html-table-bordered.bp3-html-table-striped tbody tr:not(:first-child) td:first-child{
    -webkit-box-shadow:none;
            box-shadow:none; }

.bp3-dark table.bp3-html-table.bp3-interactive tbody tr:hover td{
  background-color:rgba(92, 112, 128, 0.3);
  cursor:pointer; }

.bp3-dark table.bp3-html-table.bp3-interactive tbody tr:active td{
  background-color:rgba(92, 112, 128, 0.4); }

.bp3-key-combo{
  display:-webkit-box;
  display:-ms-flexbox;
  display:flex;
  -webkit-box-orient:horizontal;
  -webkit-box-direction:normal;
      -ms-flex-direction:row;
          flex-direction:row;
  -webkit-box-align:center;
      -ms-flex-align:center;
          align-items:center; }
  .bp3-key-combo > *{
    -webkit-box-flex:0;
        -ms-flex-positive:0;
            flex-grow:0;
    -ms-flex-negative:0;
        flex-shrink:0; }
  .bp3-key-combo > .bp3-fill{
    -webkit-box-flex:1;
        -ms-flex-positive:1;
            flex-grow:1;
    -ms-flex-negative:1;
        flex-shrink:1; }
  .bp3-key-combo::before,
  .bp3-key-combo > *{
    margin-right:5px; }
  .bp3-key-combo:empty::before,
  .bp3-key-combo > :last-child{
    margin-right:0; }

.bp3-hotkey-dialog{
  top:40px;
  padding-bottom:0; }
  .bp3-hotkey-dialog .bp3-dialog-body{
    margin:0;
    padding:0; }
  .bp3-hotkey-dialog .bp3-hotkey-label{
    -webkit-box-flex:1;
        -ms-flex-positive:1;
            flex-grow:1; }

.bp3-hotkey-column{
  margin:auto;
  max-height:80vh;
  overflow-y:auto;
  padding:30px; }
  .bp3-hotkey-column .bp3-heading{
    margin-bottom:20px; }
    .bp3-hotkey-column .bp3-heading:not(:first-child){
      margin-top:40px; }

.bp3-hotkey{
  display:-webkit-box;
  display:-ms-flexbox;
  display:flex;
  -webkit-box-align:center;
      -ms-flex-align:center;
          align-items:center;
  -webkit-box-pack:justify;
      -ms-flex-pack:justify;
          justify-content:space-between;
  margin-right:0;
  margin-left:0; }
  .bp3-hotkey:not(:last-child){
    margin-bottom:10px; }
.bp3-icon{
  display:inline-block;
  -webkit-box-flex:0;
      -ms-flex:0 0 auto;
          flex:0 0 auto;
  vertical-align:text-bottom; }
  .bp3-icon:not(:empty)::before{
    content:"" !important;
    content:unset !important; }
  .bp3-icon > svg{
    display:block; }
    .bp3-icon > svg:not([fill]){
      fill:currentColor; }

.bp3-icon.bp3-intent-primary, .bp3-icon-standard.bp3-intent-primary, .bp3-icon-large.bp3-intent-primary{
  color:#106ba3; }
  .bp3-dark .bp3-icon.bp3-intent-primary, .bp3-dark .bp3-icon-standard.bp3-intent-primary, .bp3-dark .bp3-icon-large.bp3-intent-primary{
    color:#48aff0; }

.bp3-icon.bp3-intent-success, .bp3-icon-standard.bp3-intent-success, .bp3-icon-large.bp3-intent-success{
  color:#0d8050; }
  .bp3-dark .bp3-icon.bp3-intent-success, .bp3-dark .bp3-icon-standard.bp3-intent-success, .bp3-dark .bp3-icon-large.bp3-intent-success{
    color:#3dcc91; }

.bp3-icon.bp3-intent-warning, .bp3-icon-standard.bp3-intent-warning, .bp3-icon-large.bp3-intent-warning{
  color:#bf7326; }
  .bp3-dark .bp3-icon.bp3-intent-warning, .bp3-dark .bp3-icon-standard.bp3-intent-warning, .bp3-dark .bp3-icon-large.bp3-intent-warning{
    color:#ffb366; }

.bp3-icon.bp3-intent-danger, .bp3-icon-standard.bp3-intent-danger, .bp3-icon-large.bp3-intent-danger{
  color:#c23030; }
  .bp3-dark .bp3-icon.bp3-intent-danger, .bp3-dark .bp3-icon-standard.bp3-intent-danger, .bp3-dark .bp3-icon-large.bp3-intent-danger{
    color:#ff7373; }

span.bp3-icon-standard{
  line-height:1;
  font-family:"Icons16", sans-serif;
  font-size:16px;
  font-weight:400;
  font-style:normal;
  -moz-osx-font-smoothing:grayscale;
  -webkit-font-smoothing:antialiased;
  display:inline-block; }

span.bp3-icon-large{
  line-height:1;
  font-family:"Icons20", sans-serif;
  font-size:20px;
  font-weight:400;
  font-style:normal;
  -moz-osx-font-smoothing:grayscale;
  -webkit-font-smoothing:antialiased;
  display:inline-block; }

span.bp3-icon:empty{
  line-height:1;
  font-family:"Icons20";
  font-size:inherit;
  font-weight:400;
  font-style:normal; }
  span.bp3-icon:empty::before{
    -moz-osx-font-smoothing:grayscale;
    -webkit-font-smoothing:antialiased; }

.bp3-icon-add::before{
  content:""; }

.bp3-icon-add-column-left::before{
  content:""; }

.bp3-icon-add-column-right::before{
  content:""; }

.bp3-icon-add-row-bottom::before{
  content:""; }

.bp3-icon-add-row-top::before{
  content:""; }

.bp3-icon-add-to-artifact::before{
  content:""; }

.bp3-icon-add-to-folder::before{
  content:""; }

.bp3-icon-airplane::before{
  content:""; }

.bp3-icon-align-center::before{
  content:""; }

.bp3-icon-align-justify::before{
  content:""; }

.bp3-icon-align-left::before{
  content:""; }

.bp3-icon-align-right::before{
  content:""; }

.bp3-icon-alignment-bottom::before{
  content:""; }

.bp3-icon-alignment-horizontal-center::before{
  content:""; }

.bp3-icon-alignment-left::before{
  content:""; }

.bp3-icon-alignment-right::before{
  content:""; }

.bp3-icon-alignment-top::before{
  content:""; }

.bp3-icon-alignment-vertical-center::before{
  content:""; }

.bp3-icon-annotation::before{
  content:""; }

.bp3-icon-application::before{
  content:""; }

.bp3-icon-applications::before{
  content:""; }

.bp3-icon-archive::before{
  content:""; }

.bp3-icon-arrow-bottom-left::before{
  content:"↙"; }

.bp3-icon-arrow-bottom-right::before{
  content:"↘"; }

.bp3-icon-arrow-down::before{
  content:"↓"; }

.bp3-icon-arrow-left::before{
  content:"←"; }

.bp3-icon-arrow-right::before{
  content:"→"; }

.bp3-icon-arrow-top-left::before{
  content:"↖"; }

.bp3-icon-arrow-top-right::before{
  content:"↗"; }

.bp3-icon-arrow-up::before{
  content:"↑"; }

.bp3-icon-arrows-horizontal::before{
  content:"↔"; }

.bp3-icon-arrows-vertical::before{
  content:"↕"; }

.bp3-icon-asterisk::before{
  content:"*"; }

.bp3-icon-automatic-updates::before{
  content:""; }

.bp3-icon-badge::before{
  content:""; }

.bp3-icon-ban-circle::before{
  content:""; }

.bp3-icon-bank-account::before{
  content:""; }

.bp3-icon-barcode::before{
  content:""; }

.bp3-icon-blank::before{
  content:""; }

.bp3-icon-blocked-person::before{
  content:""; }

.bp3-icon-bold::before{
  content:""; }

.bp3-icon-book::before{
  content:""; }

.bp3-icon-bookmark::before{
  content:""; }

.bp3-icon-box::before{
  content:""; }

.bp3-icon-briefcase::before{
  content:""; }

.bp3-icon-bring-data::before{
  content:""; }

.bp3-icon-build::before{
  content:""; }

.bp3-icon-calculator::before{
  content:""; }

.bp3-icon-calendar::before{
  content:""; }

.bp3-icon-camera::before{
  content:""; }

.bp3-icon-caret-down::before{
  content:"⌄"; }

.bp3-icon-caret-left::before{
  content:"〈"; }

.bp3-icon-caret-right::before{
  content:"〉"; }

.bp3-icon-caret-up::before{
  content:"⌃"; }

.bp3-icon-cell-tower::before{
  content:""; }

.bp3-icon-changes::before{
  content:""; }

.bp3-icon-chart::before{
  content:""; }

.bp3-icon-chat::before{
  content:""; }

.bp3-icon-chevron-backward::before{
  content:""; }

.bp3-icon-chevron-down::before{
  content:""; }

.bp3-icon-chevron-forward::before{
  content:""; }

.bp3-icon-chevron-left::before{
  content:""; }

.bp3-icon-chevron-right::before{
  content:""; }

.bp3-icon-chevron-up::before{
  content:""; }

.bp3-icon-circle::before{
  content:""; }

.bp3-icon-circle-arrow-down::before{
  content:""; }

.bp3-icon-circle-arrow-left::before{
  content:""; }

.bp3-icon-circle-arrow-right::before{
  content:""; }

.bp3-icon-circle-arrow-up::before{
  content:""; }

.bp3-icon-citation::before{
  content:""; }

.bp3-icon-clean::before{
  content:""; }

.bp3-icon-clipboard::before{
  content:""; }

.bp3-icon-cloud::before{
  content:"☁"; }

.bp3-icon-cloud-download::before{
  content:""; }

.bp3-icon-cloud-upload::before{
  content:""; }

.bp3-icon-code::before{
  content:""; }

.bp3-icon-code-block::before{
  content:""; }

.bp3-icon-cog::before{
  content:""; }

.bp3-icon-collapse-all::before{
  content:""; }

.bp3-icon-column-layout::before{
  content:""; }

.bp3-icon-comment::before{
  content:""; }

.bp3-icon-comparison::before{
  content:""; }

.bp3-icon-compass::before{
  content:""; }

.bp3-icon-compressed::before{
  content:""; }

.bp3-icon-confirm::before{
  content:""; }

.bp3-icon-console::before{
  content:""; }

.bp3-icon-contrast::before{
  content:""; }

.bp3-icon-control::before{
  content:""; }

.bp3-icon-credit-card::before{
  content:""; }

.bp3-icon-cross::before{
  content:"✗"; }

.bp3-icon-crown::before{
  content:""; }

.bp3-icon-cube::before{
  content:""; }

.bp3-icon-cube-add::before{
  content:""; }

.bp3-icon-cube-remove::before{
  content:""; }

.bp3-icon-curved-range-chart::before{
  content:""; }

.bp3-icon-cut::before{
  content:""; }

.bp3-icon-dashboard::before{
  content:""; }

.bp3-icon-data-lineage::before{
  content:""; }

.bp3-icon-database::before{
  content:""; }

.bp3-icon-delete::before{
  content:""; }

.bp3-icon-delta::before{
  content:"Δ"; }

.bp3-icon-derive-column::before{
  content:""; }

.bp3-icon-desktop::before{
  content:""; }

.bp3-icon-diagram-tree::before{
  content:""; }

.bp3-icon-direction-left::before{
  content:""; }

.bp3-icon-direction-right::before{
  content:""; }

.bp3-icon-disable::before{
  content:""; }

.bp3-icon-document::before{
  content:""; }

.bp3-icon-document-open::before{
  content:""; }

.bp3-icon-document-share::before{
  content:""; }

.bp3-icon-dollar::before{
  content:"$"; }

.bp3-icon-dot::before{
  content:"•"; }

.bp3-icon-double-caret-horizontal::before{
  content:""; }

.bp3-icon-double-caret-vertical::before{
  content:""; }

.bp3-icon-double-chevron-down::before{
  content:""; }

.bp3-icon-double-chevron-left::before{
  content:""; }

.bp3-icon-double-chevron-right::before{
  content:""; }

.bp3-icon-double-chevron-up::before{
  content:""; }

.bp3-icon-doughnut-chart::before{
  content:""; }

.bp3-icon-download::before{
  content:""; }

.bp3-icon-drag-handle-horizontal::before{
  content:""; }

.bp3-icon-drag-handle-vertical::before{
  content:""; }

.bp3-icon-draw::before{
  content:""; }

.bp3-icon-drive-time::before{
  content:""; }

.bp3-icon-duplicate::before{
  content:""; }

.bp3-icon-edit::before{
  content:"✎"; }

.bp3-icon-eject::before{
  content:"⏏"; }

.bp3-icon-endorsed::before{
  content:""; }

.bp3-icon-envelope::before{
  content:"✉"; }

.bp3-icon-equals::before{
  content:""; }

.bp3-icon-eraser::before{
  content:""; }

.bp3-icon-error::before{
  content:""; }

.bp3-icon-euro::before{
  content:"€"; }

.bp3-icon-exchange::before{
  content:""; }

.bp3-icon-exclude-row::before{
  content:""; }

.bp3-icon-expand-all::before{
  content:""; }

.bp3-icon-export::before{
  content:""; }

.bp3-icon-eye-off::before{
  content:""; }

.bp3-icon-eye-on::before{
  content:""; }

.bp3-icon-eye-open::before{
  content:""; }

.bp3-icon-fast-backward::before{
  content:""; }

.bp3-icon-fast-forward::before{
  content:""; }

.bp3-icon-feed::before{
  content:""; }

.bp3-icon-feed-subscribed::before{
  content:""; }

.bp3-icon-film::before{
  content:""; }

.bp3-icon-filter::before{
  content:""; }

.bp3-icon-filter-keep::before{
  content:""; }

.bp3-icon-filter-list::before{
  content:""; }

.bp3-icon-filter-open::before{
  content:""; }

.bp3-icon-filter-remove::before{
  content:""; }

.bp3-icon-flag::before{
  content:"⚑"; }

.bp3-icon-flame::before{
  content:""; }

.bp3-icon-flash::before{
  content:""; }

.bp3-icon-floppy-disk::before{
  content:""; }

.bp3-icon-flow-branch::before{
  content:""; }

.bp3-icon-flow-end::before{
  content:""; }

.bp3-icon-flow-linear::before{
  content:""; }

.bp3-icon-flow-review::before{
  content:""; }

.bp3-icon-flow-review-branch::before{
  content:""; }

.bp3-icon-flows::before{
  content:""; }

.bp3-icon-folder-close::before{
  content:""; }

.bp3-icon-folder-new::before{
  content:""; }

.bp3-icon-folder-open::before{
  content:""; }

.bp3-icon-folder-shared::before{
  content:""; }

.bp3-icon-folder-shared-open::before{
  content:""; }

.bp3-icon-follower::before{
  content:""; }

.bp3-icon-following::before{
  content:""; }

.bp3-icon-font::before{
  content:""; }

.bp3-icon-fork::before{
  content:""; }

.bp3-icon-form::before{
  content:""; }

.bp3-icon-full-circle::before{
  content:""; }

.bp3-icon-full-stacked-chart::before{
  content:""; }

.bp3-icon-fullscreen::before{
  content:""; }

.bp3-icon-function::before{
  content:""; }

.bp3-icon-gantt-chart::before{
  content:""; }

.bp3-icon-geolocation::before{
  content:""; }

.bp3-icon-geosearch::before{
  content:""; }

.bp3-icon-git-branch::before{
  content:""; }

.bp3-icon-git-commit::before{
  content:""; }

.bp3-icon-git-merge::before{
  content:""; }

.bp3-icon-git-new-branch::before{
  content:""; }

.bp3-icon-git-pull::before{
  content:""; }

.bp3-icon-git-push::before{
  content:""; }

.bp3-icon-git-repo::before{
  content:""; }

.bp3-icon-glass::before{
  content:""; }

.bp3-icon-globe::before{
  content:""; }

.bp3-icon-globe-network::before{
  content:""; }

.bp3-icon-graph::before{
  content:""; }

.bp3-icon-graph-remove::before{
  content:""; }

.bp3-icon-greater-than::before{
  content:""; }

.bp3-icon-greater-than-or-equal-to::before{
  content:""; }

.bp3-icon-grid::before{
  content:""; }

.bp3-icon-grid-view::before{
  content:""; }

.bp3-icon-group-objects::before{
  content:""; }

.bp3-icon-grouped-bar-chart::before{
  content:""; }

.bp3-icon-hand::before{
  content:""; }

.bp3-icon-hand-down::before{
  content:""; }

.bp3-icon-hand-left::before{
  content:""; }

.bp3-icon-hand-right::before{
  content:""; }

.bp3-icon-hand-up::before{
  content:""; }

.bp3-icon-header::before{
  content:""; }

.bp3-icon-header-one::before{
  content:""; }

.bp3-icon-header-two::before{
  content:""; }

.bp3-icon-headset::before{
  content:""; }

.bp3-icon-heart::before{
  content:"♥"; }

.bp3-icon-heart-broken::before{
  content:""; }

.bp3-icon-heat-grid::before{
  content:""; }

.bp3-icon-heatmap::before{
  content:""; }

.bp3-icon-help::before{
  content:"?"; }

.bp3-icon-helper-management::before{
  content:""; }

.bp3-icon-highlight::before{
  content:""; }

.bp3-icon-history::before{
  content:""; }

.bp3-icon-home::before{
  content:"⌂"; }

.bp3-icon-horizontal-bar-chart::before{
  content:""; }

.bp3-icon-horizontal-bar-chart-asc::before{
  content:""; }

.bp3-icon-horizontal-bar-chart-desc::before{
  content:""; }

.bp3-icon-horizontal-distribution::before{
  content:""; }

.bp3-icon-id-number::before{
  content:""; }

.bp3-icon-image-rotate-left::before{
  content:""; }

.bp3-icon-image-rotate-right::before{
  content:""; }

.bp3-icon-import::before{
  content:""; }

.bp3-icon-inbox::before{
  content:""; }

.bp3-icon-inbox-filtered::before{
  content:""; }

.bp3-icon-inbox-geo::before{
  content:""; }

.bp3-icon-inbox-search::before{
  content:""; }

.bp3-icon-inbox-update::before{
  content:""; }

.bp3-icon-info-sign::before{
  content:"ℹ"; }

.bp3-icon-inheritance::before{
  content:""; }

.bp3-icon-inner-join::before{
  content:""; }

.bp3-icon-insert::before{
  content:""; }

.bp3-icon-intersection::before{
  content:""; }

.bp3-icon-ip-address::before{
  content:""; }

.bp3-icon-issue::before{
  content:""; }

.bp3-icon-issue-closed::before{
  content:""; }

.bp3-icon-issue-new::before{
  content:""; }

.bp3-icon-italic::before{
  content:""; }

.bp3-icon-join-table::before{
  content:""; }

.bp3-icon-key::before{
  content:""; }

.bp3-icon-key-backspace::before{
  content:""; }

.bp3-icon-key-command::before{
  content:""; }

.bp3-icon-key-control::before{
  content:""; }

.bp3-icon-key-delete::before{
  content:""; }

.bp3-icon-key-enter::before{
  content:""; }

.bp3-icon-key-escape::before{
  content:""; }

.bp3-icon-key-option::before{
  content:""; }

.bp3-icon-key-shift::before{
  content:""; }

.bp3-icon-key-tab::before{
  content:""; }

.bp3-icon-known-vehicle::before{
  content:""; }

.bp3-icon-label::before{
  content:""; }

.bp3-icon-layer::before{
  content:""; }

.bp3-icon-layers::before{
  content:""; }

.bp3-icon-layout::before{
  content:""; }

.bp3-icon-layout-auto::before{
  content:""; }

.bp3-icon-layout-balloon::before{
  content:""; }

.bp3-icon-layout-circle::before{
  content:""; }

.bp3-icon-layout-grid::before{
  content:""; }

.bp3-icon-layout-group-by::before{
  content:""; }

.bp3-icon-layout-hierarchy::before{
  content:""; }

.bp3-icon-layout-linear::before{
  content:""; }

.bp3-icon-layout-skew-grid::before{
  content:""; }

.bp3-icon-layout-sorted-clusters::before{
  content:""; }

.bp3-icon-learning::before{
  content:""; }

.bp3-icon-left-join::before{
  content:""; }

.bp3-icon-less-than::before{
  content:""; }

.bp3-icon-less-than-or-equal-to::before{
  content:""; }

.bp3-icon-lifesaver::before{
  content:""; }

.bp3-icon-lightbulb::before{
  content:""; }

.bp3-icon-link::before{
  content:""; }

.bp3-icon-list::before{
  content:"☰"; }

.bp3-icon-list-columns::before{
  content:""; }

.bp3-icon-list-detail-view::before{
  content:""; }

.bp3-icon-locate::before{
  content:""; }

.bp3-icon-lock::before{
  content:""; }

.bp3-icon-log-in::before{
  content:""; }

.bp3-icon-log-out::before{
  content:""; }

.bp3-icon-manual::before{
  content:""; }

.bp3-icon-manually-entered-data::before{
  content:""; }

.bp3-icon-map::before{
  content:""; }

.bp3-icon-map-create::before{
  content:""; }

.bp3-icon-map-marker::before{
  content:""; }

.bp3-icon-maximize::before{
  content:""; }

.bp3-icon-media::before{
  content:""; }

.bp3-icon-menu::before{
  content:""; }

.bp3-icon-menu-closed::before{
  content:""; }

.bp3-icon-menu-open::before{
  content:""; }

.bp3-icon-merge-columns::before{
  content:""; }

.bp3-icon-merge-links::before{
  content:""; }

.bp3-icon-minimize::before{
  content:""; }

.bp3-icon-minus::before{
  content:"−"; }

.bp3-icon-mobile-phone::before{
  content:""; }

.bp3-icon-mobile-video::before{
  content:""; }

.bp3-icon-moon::before{
  content:""; }

.bp3-icon-more::before{
  content:""; }

.bp3-icon-mountain::before{
  content:""; }

.bp3-icon-move::before{
  content:""; }

.bp3-icon-mugshot::before{
  content:""; }

.bp3-icon-multi-select::before{
  content:""; }

.bp3-icon-music::before{
  content:""; }

.bp3-icon-new-drawing::before{
  content:""; }

.bp3-icon-new-grid-item::before{
  content:""; }

.bp3-icon-new-layer::before{
  content:""; }

.bp3-icon-new-layers::before{
  content:""; }

.bp3-icon-new-link::before{
  content:""; }

.bp3-icon-new-object::before{
  content:""; }

.bp3-icon-new-person::before{
  content:""; }

.bp3-icon-new-prescription::before{
  content:""; }

.bp3-icon-new-text-box::before{
  content:""; }

.bp3-icon-ninja::before{
  content:""; }

.bp3-icon-not-equal-to::before{
  content:""; }

.bp3-icon-notifications::before{
  content:""; }

.bp3-icon-notifications-updated::before{
  content:""; }

.bp3-icon-numbered-list::before{
  content:""; }

.bp3-icon-numerical::before{
  content:""; }

.bp3-icon-office::before{
  content:""; }

.bp3-icon-offline::before{
  content:""; }

.bp3-icon-oil-field::before{
  content:""; }

.bp3-icon-one-column::before{
  content:""; }

.bp3-icon-outdated::before{
  content:""; }

.bp3-icon-page-layout::before{
  content:""; }

.bp3-icon-panel-stats::before{
  content:""; }

.bp3-icon-panel-table::before{
  content:""; }

.bp3-icon-paperclip::before{
  content:""; }

.bp3-icon-paragraph::before{
  content:""; }

.bp3-icon-path::before{
  content:""; }

.bp3-icon-path-search::before{
  content:""; }

.bp3-icon-pause::before{
  content:""; }

.bp3-icon-people::before{
  content:""; }

.bp3-icon-percentage::before{
  content:""; }

.bp3-icon-person::before{
  content:""; }

.bp3-icon-phone::before{
  content:"☎"; }

.bp3-icon-pie-chart::before{
  content:""; }

.bp3-icon-pin::before{
  content:""; }

.bp3-icon-pivot::before{
  content:""; }

.bp3-icon-pivot-table::before{
  content:""; }

.bp3-icon-play::before{
  content:""; }

.bp3-icon-plus::before{
  content:"+"; }

.bp3-icon-polygon-filter::before{
  content:""; }

.bp3-icon-power::before{
  content:""; }

.bp3-icon-predictive-analysis::before{
  content:""; }

.bp3-icon-prescription::before{
  content:""; }

.bp3-icon-presentation::before{
  content:""; }

.bp3-icon-print::before{
  content:"⎙"; }

.bp3-icon-projects::before{
  content:""; }

.bp3-icon-properties::before{
  content:""; }

.bp3-icon-property::before{
  content:""; }

.bp3-icon-publish-function::before{
  content:""; }

.bp3-icon-pulse::before{
  content:""; }

.bp3-icon-random::before{
  content:""; }

.bp3-icon-record::before{
  content:""; }

.bp3-icon-redo::before{
  content:""; }

.bp3-icon-refresh::before{
  content:""; }

.bp3-icon-regression-chart::before{
  content:""; }

.bp3-icon-remove::before{
  content:""; }

.bp3-icon-remove-column::before{
  content:""; }

.bp3-icon-remove-column-left::before{
  content:""; }

.bp3-icon-remove-column-right::before{
  content:""; }

.bp3-icon-remove-row-bottom::before{
  content:""; }

.bp3-icon-remove-row-top::before{
  content:""; }

.bp3-icon-repeat::before{
  content:""; }

.bp3-icon-reset::before{
  content:""; }

.bp3-icon-resolve::before{
  content:""; }

.bp3-icon-rig::before{
  content:""; }

.bp3-icon-right-join::before{
  content:""; }

.bp3-icon-ring::before{
  content:""; }

.bp3-icon-rotate-document::before{
  content:""; }

.bp3-icon-rotate-page::before{
  content:""; }

.bp3-icon-satellite::before{
  content:""; }

.bp3-icon-saved::before{
  content:""; }

.bp3-icon-scatter-plot::before{
  content:""; }

.bp3-icon-search::before{
  content:""; }

.bp3-icon-search-around::before{
  content:""; }

.bp3-icon-search-template::before{
  content:""; }

.bp3-icon-search-text::before{
  content:""; }

.bp3-icon-segmented-control::before{
  content:""; }

.bp3-icon-select::before{
  content:""; }

.bp3-icon-selection::before{
  content:"⦿"; }

.bp3-icon-send-to::before{
  content:""; }

.bp3-icon-send-to-graph::before{
  content:""; }

.bp3-icon-send-to-map::before{
  content:""; }

.bp3-icon-series-add::before{
  content:""; }

.bp3-icon-series-configuration::before{
  content:""; }

.bp3-icon-series-derived::before{
  content:""; }

.bp3-icon-series-filtered::before{
  content:""; }

.bp3-icon-series-search::before{
  content:""; }

.bp3-icon-settings::before{
  content:""; }

.bp3-icon-share::before{
  content:""; }

.bp3-icon-shield::before{
  content:""; }

.bp3-icon-shop::before{
  content:""; }

.bp3-icon-shopping-cart::before{
  content:""; }

.bp3-icon-signal-search::before{
  content:""; }

.bp3-icon-sim-card::before{
  content:""; }

.bp3-icon-slash::before{
  content:""; }

.bp3-icon-small-cross::before{
  content:""; }

.bp3-icon-small-minus::before{
  content:""; }

.bp3-icon-small-plus::before{
  content:""; }

.bp3-icon-small-tick::before{
  content:""; }

.bp3-icon-snowflake::before{
  content:""; }

.bp3-icon-social-media::before{
  content:""; }

.bp3-icon-sort::before{
  content:""; }

.bp3-icon-sort-alphabetical::before{
  content:""; }

.bp3-icon-sort-alphabetical-desc::before{
  content:""; }

.bp3-icon-sort-asc::before{
  content:""; }

.bp3-icon-sort-desc::before{
  content:""; }

.bp3-icon-sort-numerical::before{
  content:""; }

.bp3-icon-sort-numerical-desc::before{
  content:""; }

.bp3-icon-split-columns::before{
  content:""; }

.bp3-icon-square::before{
  content:""; }

.bp3-icon-stacked-chart::before{
  content:""; }

.bp3-icon-star::before{
  content:"★"; }

.bp3-icon-star-empty::before{
  content:"☆"; }

.bp3-icon-step-backward::before{
  content:""; }

.bp3-icon-step-chart::before{
  content:""; }

.bp3-icon-step-forward::before{
  content:""; }

.bp3-icon-stop::before{
  content:""; }

.bp3-icon-stopwatch::before{
  content:""; }

.bp3-icon-strikethrough::before{
  content:""; }

.bp3-icon-style::before{
  content:""; }

.bp3-icon-swap-horizontal::before{
  content:""; }

.bp3-icon-swap-vertical::before{
  content:""; }

.bp3-icon-symbol-circle::before{
  content:""; }

.bp3-icon-symbol-cross::before{
  content:""; }

.bp3-icon-symbol-diamond::before{
  content:""; }

.bp3-icon-symbol-square::before{
  content:""; }

.bp3-icon-symbol-triangle-down::before{
  content:""; }

.bp3-icon-symbol-triangle-up::before{
  content:""; }

.bp3-icon-tag::before{
  content:""; }

.bp3-icon-take-action::before{
  content:""; }

.bp3-icon-taxi::before{
  content:""; }

.bp3-icon-text-highlight::before{
  content:""; }

.bp3-icon-th::before{
  content:""; }

.bp3-icon-th-derived::before{
  content:""; }

.bp3-icon-th-disconnect::before{
  content:""; }

.bp3-icon-th-filtered::before{
  content:""; }

.bp3-icon-th-list::before{
  content:""; }

.bp3-icon-thumbs-down::before{
  content:""; }

.bp3-icon-thumbs-up::before{
  content:""; }

.bp3-icon-tick::before{
  content:"✓"; }

.bp3-icon-tick-circle::before{
  content:""; }

.bp3-icon-time::before{
  content:"⏲"; }

.bp3-icon-timeline-area-chart::before{
  content:""; }

.bp3-icon-timeline-bar-chart::before{
  content:""; }

.bp3-icon-timeline-events::before{
  content:""; }

.bp3-icon-timeline-line-chart::before{
  content:""; }

.bp3-icon-tint::before{
  content:""; }

.bp3-icon-torch::before{
  content:""; }

.bp3-icon-tractor::before{
  content:""; }

.bp3-icon-train::before{
  content:""; }

.bp3-icon-translate::before{
  content:""; }

.bp3-icon-trash::before{
  content:""; }

.bp3-icon-tree::before{
  content:""; }

.bp3-icon-trending-down::before{
  content:""; }

.bp3-icon-trending-up::before{
  content:""; }

.bp3-icon-truck::before{
  content:""; }

.bp3-icon-two-columns::before{
  content:""; }

.bp3-icon-unarchive::before{
  content:""; }

.bp3-icon-underline::before{
  content:"⎁"; }

.bp3-icon-undo::before{
  content:"⎌"; }

.bp3-icon-ungroup-objects::before{
  content:""; }

.bp3-icon-unknown-vehicle::before{
  content:""; }

.bp3-icon-unlock::before{
  content:""; }

.bp3-icon-unpin::before{
  content:""; }

.bp3-icon-unresolve::before{
  content:""; }

.bp3-icon-updated::before{
  content:""; }

.bp3-icon-upload::before{
  content:""; }

.bp3-icon-user::before{
  content:""; }

.bp3-icon-variable::before{
  content:""; }

.bp3-icon-vertical-bar-chart-asc::before{
  content:""; }

.bp3-icon-vertical-bar-chart-desc::before{
  content:""; }

.bp3-icon-vertical-distribution::before{
  content:""; }

.bp3-icon-video::before{
  content:""; }

.bp3-icon-volume-down::before{
  content:""; }

.bp3-icon-volume-off::before{
  content:""; }

.bp3-icon-volume-up::before{
  content:""; }

.bp3-icon-walk::before{
  content:""; }

.bp3-icon-warning-sign::before{
  content:""; }

.bp3-icon-waterfall-chart::before{
  content:""; }

.bp3-icon-widget::before{
  content:""; }

.bp3-icon-widget-button::before{
  content:""; }

.bp3-icon-widget-footer::before{
  content:""; }

.bp3-icon-widget-header::before{
  content:""; }

.bp3-icon-wrench::before{
  content:""; }

.bp3-icon-zoom-in::before{
  content:""; }

.bp3-icon-zoom-out::before{
  content:""; }

.bp3-icon-zoom-to-fit::before{
  content:""; }
.bp3-submenu > .bp3-popover-wrapper{
  display:block; }

.bp3-submenu .bp3-popover-target{
  display:block; }

.bp3-submenu.bp3-popover{
  -webkit-box-shadow:none;
          box-shadow:none;
  padding:0 5px; }
  .bp3-submenu.bp3-popover > .bp3-popover-content{
    -webkit-box-shadow:0 0 0 1px rgba(16, 22, 26, 0.1), 0 2px 4px rgba(16, 22, 26, 0.2), 0 8px 24px rgba(16, 22, 26, 0.2);
            box-shadow:0 0 0 1px rgba(16, 22, 26, 0.1), 0 2px 4px rgba(16, 22, 26, 0.2), 0 8px 24px rgba(16, 22, 26, 0.2); }
  .bp3-dark .bp3-submenu.bp3-popover, .bp3-submenu.bp3-popover.bp3-dark{
    -webkit-box-shadow:none;
            box-shadow:none; }
    .bp3-dark .bp3-submenu.bp3-popover > .bp3-popover-content, .bp3-submenu.bp3-popover.bp3-dark > .bp3-popover-content{
      -webkit-box-shadow:0 0 0 1px rgba(16, 22, 26, 0.2), 0 2px 4px rgba(16, 22, 26, 0.4), 0 8px 24px rgba(16, 22, 26, 0.4);
              box-shadow:0 0 0 1px rgba(16, 22, 26, 0.2), 0 2px 4px rgba(16, 22, 26, 0.4), 0 8px 24px rgba(16, 22, 26, 0.4); }
.bp3-menu{
  margin:0;
  border-radius:3px;
  background:#ffffff;
  min-width:180px;
  padding:5px;
  list-style:none;
  text-align:left;
  color:#182026; }

.bp3-menu-divider{
  display:block;
  margin:5px;
  border-top:1px solid rgba(16, 22, 26, 0.15); }
  .bp3-dark .bp3-menu-divider{
    border-top-color:rgba(255, 255, 255, 0.15); }

.bp3-menu-item{
  display:-webkit-box;
  display:-ms-flexbox;
  display:flex;
  -webkit-box-orient:horizontal;
  -webkit-box-direction:normal;
      -ms-flex-direction:row;
          flex-direction:row;
  -webkit-box-align:start;
      -ms-flex-align:start;
          align-items:flex-start;
  border-radius:2px;
  padding:5px 7px;
  text-decoration:none;
  line-height:20px;
  color:inherit;
  -webkit-user-select:none;
     -moz-user-select:none;
      -ms-user-select:none;
          user-select:none; }
  .bp3-menu-item > *{
    -webkit-box-flex:0;
        -ms-flex-positive:0;
            flex-grow:0;
    -ms-flex-negative:0;
        flex-shrink:0; }
  .bp3-menu-item > .bp3-fill{
    -webkit-box-flex:1;
        -ms-flex-positive:1;
            flex-grow:1;
    -ms-flex-negative:1;
        flex-shrink:1; }
  .bp3-menu-item::before,
  .bp3-menu-item > *{
    margin-right:7px; }
  .bp3-menu-item:empty::before,
  .bp3-menu-item > :last-child{
    margin-right:0; }
  .bp3-menu-item > .bp3-fill{
    word-break:break-word; }
  .bp3-menu-item:hover, .bp3-submenu .bp3-popover-target.bp3-popover-open > .bp3-menu-item{
    background-color:rgba(167, 182, 194, 0.3);
    cursor:pointer;
    text-decoration:none; }
  .bp3-menu-item.bp3-disabled{
    background-color:inherit;
    cursor:not-allowed;
    color:rgba(92, 112, 128, 0.6); }
  .bp3-dark .bp3-menu-item{
    color:inherit; }
    .bp3-dark .bp3-menu-item:hover, .bp3-dark .bp3-submenu .bp3-popover-target.bp3-popover-open > .bp3-menu-item, .bp3-submenu .bp3-dark .bp3-popover-target.bp3-popover-open > .bp3-menu-item{
      background-color:rgba(138, 155, 168, 0.15);
      color:inherit; }
    .bp3-dark .bp3-menu-item.bp3-disabled{
      background-color:inherit;
      color:rgba(167, 182, 194, 0.6); }
  .bp3-menu-item.bp3-intent-primary{
    color:#106ba3; }
    .bp3-menu-item.bp3-intent-primary .bp3-icon{
      color:inherit; }
    .bp3-menu-item.bp3-intent-primary::before, .bp3-menu-item.bp3-intent-primary::after,
    .bp3-menu-item.bp3-intent-primary .bp3-menu-item-label{
      color:#106ba3; }
    .bp3-menu-item.bp3-intent-primary:hover, .bp3-submenu .bp3-popover-target.bp3-popover-open > .bp3-intent-primary.bp3-menu-item, .bp3-menu-item.bp3-intent-primary.bp3-active{
      background-color:#137cbd; }
    .bp3-menu-item.bp3-intent-primary:active{
      background-color:#106ba3; }
    .bp3-menu-item.bp3-intent-primary:hover, .bp3-submenu .bp3-popover-target.bp3-popover-open > .bp3-intent-primary.bp3-menu-item, .bp3-menu-item.bp3-intent-primary:hover::before, .bp3-submenu .bp3-popover-target.bp3-popover-open > .bp3-intent-primary.bp3-menu-item::before, .bp3-menu-item.bp3-intent-primary:hover::after, .bp3-submenu .bp3-popover-target.bp3-popover-open > .bp3-intent-primary.bp3-menu-item::after,
    .bp3-menu-item.bp3-intent-primary:hover .bp3-menu-item-label,
    .bp3-submenu .bp3-popover-target.bp3-popover-open > .bp3-intent-primary.bp3-menu-item .bp3-menu-item-label, .bp3-menu-item.bp3-intent-primary:active, .bp3-menu-item.bp3-intent-primary:active::before, .bp3-menu-item.bp3-intent-primary:active::after,
    .bp3-menu-item.bp3-intent-primary:active .bp3-menu-item-label, .bp3-menu-item.bp3-intent-primary.bp3-active, .bp3-menu-item.bp3-intent-primary.bp3-active::before, .bp3-menu-item.bp3-intent-primary.bp3-active::after,
    .bp3-menu-item.bp3-intent-primary.bp3-active .bp3-menu-item-label{
      color:#ffffff; }
  .bp3-menu-item.bp3-intent-success{
    color:#0d8050; }
    .bp3-menu-item.bp3-intent-success .bp3-icon{
      color:inherit; }
    .bp3-menu-item.bp3-intent-success::before, .bp3-menu-item.bp3-intent-success::after,
    .bp3-menu-item.bp3-intent-success .bp3-menu-item-label{
      color:#0d8050; }
    .bp3-menu-item.bp3-intent-success:hover, .bp3-submenu .bp3-popover-target.bp3-popover-open > .bp3-intent-success.bp3-menu-item, .bp3-menu-item.bp3-intent-success.bp3-active{
      background-color:#0f9960; }
    .bp3-menu-item.bp3-intent-success:active{
      background-color:#0d8050; }
    .bp3-menu-item.bp3-intent-success:hover, .bp3-submenu .bp3-popover-target.bp3-popover-open > .bp3-intent-success.bp3-menu-item, .bp3-menu-item.bp3-intent-success:hover::before, .bp3-submenu .bp3-popover-target.bp3-popover-open > .bp3-intent-success.bp3-menu-item::before, .bp3-menu-item.bp3-intent-success:hover::after, .bp3-submenu .bp3-popover-target.bp3-popover-open > .bp3-intent-success.bp3-menu-item::after,
    .bp3-menu-item.bp3-intent-success:hover .bp3-menu-item-label,
    .bp3-submenu .bp3-popover-target.bp3-popover-open > .bp3-intent-success.bp3-menu-item .bp3-menu-item-label, .bp3-menu-item.bp3-intent-success:active, .bp3-menu-item.bp3-intent-success:active::before, .bp3-menu-item.bp3-intent-success:active::after,
    .bp3-menu-item.bp3-intent-success:active .bp3-menu-item-label, .bp3-menu-item.bp3-intent-success.bp3-active, .bp3-menu-item.bp3-intent-success.bp3-active::before, .bp3-menu-item.bp3-intent-success.bp3-active::after,
    .bp3-menu-item.bp3-intent-success.bp3-active .bp3-menu-item-label{
      color:#ffffff; }
  .bp3-menu-item.bp3-intent-warning{
    color:#bf7326; }
    .bp3-menu-item.bp3-intent-warning .bp3-icon{
      color:inherit; }
    .bp3-menu-item.bp3-intent-warning::before, .bp3-menu-item.bp3-intent-warning::after,
    .bp3-menu-item.bp3-intent-warning .bp3-menu-item-label{
      color:#bf7326; }
    .bp3-menu-item.bp3-intent-warning:hover, .bp3-submenu .bp3-popover-target.bp3-popover-open > .bp3-intent-warning.bp3-menu-item, .bp3-menu-item.bp3-intent-warning.bp3-active{
      background-color:#d9822b; }
    .bp3-menu-item.bp3-intent-warning:active{
      background-color:#bf7326; }
    .bp3-menu-item.bp3-intent-warning:hover, .bp3-submenu .bp3-popover-target.bp3-popover-open > .bp3-intent-warning.bp3-menu-item, .bp3-menu-item.bp3-intent-warning:hover::before, .bp3-submenu .bp3-popover-target.bp3-popover-open > .bp3-intent-warning.bp3-menu-item::before, .bp3-menu-item.bp3-intent-warning:hover::after, .bp3-submenu .bp3-popover-target.bp3-popover-open > .bp3-intent-warning.bp3-menu-item::after,
    .bp3-menu-item.bp3-intent-warning:hover .bp3-menu-item-label,
    .bp3-submenu .bp3-popover-target.bp3-popover-open > .bp3-intent-warning.bp3-menu-item .bp3-menu-item-label, .bp3-menu-item.bp3-intent-warning:active, .bp3-menu-item.bp3-intent-warning:active::before, .bp3-menu-item.bp3-intent-warning:active::after,
    .bp3-menu-item.bp3-intent-warning:active .bp3-menu-item-label, .bp3-menu-item.bp3-intent-warning.bp3-active, .bp3-menu-item.bp3-intent-warning.bp3-active::before, .bp3-menu-item.bp3-intent-warning.bp3-active::after,
    .bp3-menu-item.bp3-intent-warning.bp3-active .bp3-menu-item-label{
      color:#ffffff; }
  .bp3-menu-item.bp3-intent-danger{
    color:#c23030; }
    .bp3-menu-item.bp3-intent-danger .bp3-icon{
      color:inherit; }
    .bp3-menu-item.bp3-intent-danger::before, .bp3-menu-item.bp3-intent-danger::after,
    .bp3-menu-item.bp3-intent-danger .bp3-menu-item-label{
      color:#c23030; }
    .bp3-menu-item.bp3-intent-danger:hover, .bp3-submenu .bp3-popover-target.bp3-popover-open > .bp3-intent-danger.bp3-menu-item, .bp3-menu-item.bp3-intent-danger.bp3-active{
      background-color:#db3737; }
    .bp3-menu-item.bp3-intent-danger:active{
      background-color:#c23030; }
    .bp3-menu-item.bp3-intent-danger:hover, .bp3-submenu .bp3-popover-target.bp3-popover-open > .bp3-intent-danger.bp3-menu-item, .bp3-menu-item.bp3-intent-danger:hover::before, .bp3-submenu .bp3-popover-target.bp3-popover-open > .bp3-intent-danger.bp3-menu-item::before, .bp3-menu-item.bp3-intent-danger:hover::after, .bp3-submenu .bp3-popover-target.bp3-popover-open > .bp3-intent-danger.bp3-menu-item::after,
    .bp3-menu-item.bp3-intent-danger:hover .bp3-menu-item-label,
    .bp3-submenu .bp3-popover-target.bp3-popover-open > .bp3-intent-danger.bp3-menu-item .bp3-menu-item-label, .bp3-menu-item.bp3-intent-danger:active, .bp3-menu-item.bp3-intent-danger:active::before, .bp3-menu-item.bp3-intent-danger:active::after,
    .bp3-menu-item.bp3-intent-danger:active .bp3-menu-item-label, .bp3-menu-item.bp3-intent-danger.bp3-active, .bp3-menu-item.bp3-intent-danger.bp3-active::before, .bp3-menu-item.bp3-intent-danger.bp3-active::after,
    .bp3-menu-item.bp3-intent-danger.bp3-active .bp3-menu-item-label{
      color:#ffffff; }
  .bp3-menu-item::before{
    line-height:1;
    font-family:"Icons16", sans-serif;
    font-size:16px;
    font-weight:400;
    font-style:normal;
    -moz-osx-font-smoothing:grayscale;
    -webkit-font-smoothing:antialiased;
    margin-right:7px; }
  .bp3-menu-item::before,
  .bp3-menu-item > .bp3-icon{
    margin-top:2px;
    color:#5c7080; }
  .bp3-menu-item .bp3-menu-item-label{
    color:#5c7080; }
  .bp3-menu-item:hover, .bp3-submenu .bp3-popover-target.bp3-popover-open > .bp3-menu-item{
    color:inherit; }
  .bp3-menu-item.bp3-active, .bp3-menu-item:active{
    background-color:rgba(115, 134, 148, 0.3); }
  .bp3-menu-item.bp3-disabled{
    outline:none !important;
    background-color:inherit !important;
    cursor:not-allowed !important;
    color:rgba(92, 112, 128, 0.6) !important; }
    .bp3-menu-item.bp3-disabled::before,
    .bp3-menu-item.bp3-disabled > .bp3-icon,
    .bp3-menu-item.bp3-disabled .bp3-menu-item-label{
      color:rgba(92, 112, 128, 0.6) !important; }
  .bp3-large .bp3-menu-item{
    padding:9px 7px;
    line-height:22px;
    font-size:16px; }
    .bp3-large .bp3-menu-item .bp3-icon{
      margin-top:3px; }
    .bp3-large .bp3-menu-item::before{
      line-height:1;
      font-family:"Icons20", sans-serif;
      font-size:20px;
      font-weight:400;
      font-style:normal;
      -moz-osx-font-smoothing:grayscale;
      -webkit-font-smoothing:antialiased;
      margin-top:1px;
      margin-right:10px; }

button.bp3-menu-item{
  border:none;
  background:none;
  width:100%;
  text-align:left; }
.bp3-menu-header{
  display:block;
  margin:5px;
  border-top:1px solid rgba(16, 22, 26, 0.15);
  cursor:default;
  padding-left:2px; }
  .bp3-dark .bp3-menu-header{
    border-top-color:rgba(255, 255, 255, 0.15); }
  .bp3-menu-header:first-of-type{
    border-top:none; }
  .bp3-menu-header > h6{
    color:#182026;
    font-weight:600;
    overflow:hidden;
    text-overflow:ellipsis;
    white-space:nowrap;
    word-wrap:normal;
    margin:0;
    padding:10px 7px 0 1px;
    line-height:17px; }
    .bp3-dark .bp3-menu-header > h6{
      color:#f5f8fa; }
  .bp3-menu-header:first-of-type > h6{
    padding-top:0; }
  .bp3-large .bp3-menu-header > h6{
    padding-top:15px;
    padding-bottom:5px;
    font-size:18px; }
  .bp3-large .bp3-menu-header:first-of-type > h6{
    padding-top:0; }

.bp3-dark .bp3-menu{
  background:#30404d;
  color:#f5f8fa; }

.bp3-dark .bp3-menu-item.bp3-intent-primary{
  color:#48aff0; }
  .bp3-dark .bp3-menu-item.bp3-intent-primary .bp3-icon{
    color:inherit; }
  .bp3-dark .bp3-menu-item.bp3-intent-primary::before, .bp3-dark .bp3-menu-item.bp3-intent-primary::after,
  .bp3-dark .bp3-menu-item.bp3-intent-primary .bp3-menu-item-label{
    color:#48aff0; }
  .bp3-dark .bp3-menu-item.bp3-intent-primary:hover, .bp3-dark .bp3-submenu .bp3-popover-target.bp3-popover-open > .bp3-intent-primary.bp3-menu-item, .bp3-submenu .bp3-dark .bp3-popover-target.bp3-popover-open > .bp3-intent-primary.bp3-menu-item, .bp3-dark .bp3-menu-item.bp3-intent-primary.bp3-active{
    background-color:#137cbd; }
  .bp3-dark .bp3-menu-item.bp3-intent-primary:active{
    background-color:#106ba3; }
  .bp3-dark .bp3-menu-item.bp3-intent-primary:hover, .bp3-dark .bp3-submenu .bp3-popover-target.bp3-popover-open > .bp3-intent-primary.bp3-menu-item, .bp3-submenu .bp3-dark .bp3-popover-target.bp3-popover-open > .bp3-intent-primary.bp3-menu-item, .bp3-dark .bp3-menu-item.bp3-intent-primary:hover::before, .bp3-dark .bp3-submenu .bp3-popover-target.bp3-popover-open > .bp3-intent-primary.bp3-menu-item::before, .bp3-submenu .bp3-dark .bp3-popover-target.bp3-popover-open > .bp3-intent-primary.bp3-menu-item::before, .bp3-dark .bp3-menu-item.bp3-intent-primary:hover::after, .bp3-dark .bp3-submenu .bp3-popover-target.bp3-popover-open > .bp3-intent-primary.bp3-menu-item::after, .bp3-submenu .bp3-dark .bp3-popover-target.bp3-popover-open > .bp3-intent-primary.bp3-menu-item::after,
  .bp3-dark .bp3-menu-item.bp3-intent-primary:hover .bp3-menu-item-label,
  .bp3-dark .bp3-submenu .bp3-popover-target.bp3-popover-open > .bp3-intent-primary.bp3-menu-item .bp3-menu-item-label,
  .bp3-submenu .bp3-dark .bp3-popover-target.bp3-popover-open > .bp3-intent-primary.bp3-menu-item .bp3-menu-item-label, .bp3-dark .bp3-menu-item.bp3-intent-primary:active, .bp3-dark .bp3-menu-item.bp3-intent-primary:active::before, .bp3-dark .bp3-menu-item.bp3-intent-primary:active::after,
  .bp3-dark .bp3-menu-item.bp3-intent-primary:active .bp3-menu-item-label, .bp3-dark .bp3-menu-item.bp3-intent-primary.bp3-active, .bp3-dark .bp3-menu-item.bp3-intent-primary.bp3-active::before, .bp3-dark .bp3-menu-item.bp3-intent-primary.bp3-active::after,
  .bp3-dark .bp3-menu-item.bp3-intent-primary.bp3-active .bp3-menu-item-label{
    color:#ffffff; }

.bp3-dark .bp3-menu-item.bp3-intent-success{
  color:#3dcc91; }
  .bp3-dark .bp3-menu-item.bp3-intent-success .bp3-icon{
    color:inherit; }
  .bp3-dark .bp3-menu-item.bp3-intent-success::before, .bp3-dark .bp3-menu-item.bp3-intent-success::after,
  .bp3-dark .bp3-menu-item.bp3-intent-success .bp3-menu-item-label{
    color:#3dcc91; }
  .bp3-dark .bp3-menu-item.bp3-intent-success:hover, .bp3-dark .bp3-submenu .bp3-popover-target.bp3-popover-open > .bp3-intent-success.bp3-menu-item, .bp3-submenu .bp3-dark .bp3-popover-target.bp3-popover-open > .bp3-intent-success.bp3-menu-item, .bp3-dark .bp3-menu-item.bp3-intent-success.bp3-active{
    background-color:#0f9960; }
  .bp3-dark .bp3-menu-item.bp3-intent-success:active{
    background-color:#0d8050; }
  .bp3-dark .bp3-menu-item.bp3-intent-success:hover, .bp3-dark .bp3-submenu .bp3-popover-target.bp3-popover-open > .bp3-intent-success.bp3-menu-item, .bp3-submenu .bp3-dark .bp3-popover-target.bp3-popover-open > .bp3-intent-success.bp3-menu-item, .bp3-dark .bp3-menu-item.bp3-intent-success:hover::before, .bp3-dark .bp3-submenu .bp3-popover-target.bp3-popover-open > .bp3-intent-success.bp3-menu-item::before, .bp3-submenu .bp3-dark .bp3-popover-target.bp3-popover-open > .bp3-intent-success.bp3-menu-item::before, .bp3-dark .bp3-menu-item.bp3-intent-success:hover::after, .bp3-dark .bp3-submenu .bp3-popover-target.bp3-popover-open > .bp3-intent-success.bp3-menu-item::after, .bp3-submenu .bp3-dark .bp3-popover-target.bp3-popover-open > .bp3-intent-success.bp3-menu-item::after,
  .bp3-dark .bp3-menu-item.bp3-intent-success:hover .bp3-menu-item-label,
  .bp3-dark .bp3-submenu .bp3-popover-target.bp3-popover-open > .bp3-intent-success.bp3-menu-item .bp3-menu-item-label,
  .bp3-submenu .bp3-dark .bp3-popover-target.bp3-popover-open > .bp3-intent-success.bp3-menu-item .bp3-menu-item-label, .bp3-dark .bp3-menu-item.bp3-intent-success:active, .bp3-dark .bp3-menu-item.bp3-intent-success:active::before, .bp3-dark .bp3-menu-item.bp3-intent-success:active::after,
  .bp3-dark .bp3-menu-item.bp3-intent-success:active .bp3-menu-item-label, .bp3-dark .bp3-menu-item.bp3-intent-success.bp3-active, .bp3-dark .bp3-menu-item.bp3-intent-success.bp3-active::before, .bp3-dark .bp3-menu-item.bp3-intent-success.bp3-active::after,
  .bp3-dark .bp3-menu-item.bp3-intent-success.bp3-active .bp3-menu-item-label{
    color:#ffffff; }

.bp3-dark .bp3-menu-item.bp3-intent-warning{
  color:#ffb366; }
  .bp3-dark .bp3-menu-item.bp3-intent-warning .bp3-icon{
    color:inherit; }
  .bp3-dark .bp3-menu-item.bp3-intent-warning::before, .bp3-dark .bp3-menu-item.bp3-intent-warning::after,
  .bp3-dark .bp3-menu-item.bp3-intent-warning .bp3-menu-item-label{
    color:#ffb366; }
  .bp3-dark .bp3-menu-item.bp3-intent-warning:hover, .bp3-dark .bp3-submenu .bp3-popover-target.bp3-popover-open > .bp3-intent-warning.bp3-menu-item, .bp3-submenu .bp3-dark .bp3-popover-target.bp3-popover-open > .bp3-intent-warning.bp3-menu-item, .bp3-dark .bp3-menu-item.bp3-intent-warning.bp3-active{
    background-color:#d9822b; }
  .bp3-dark .bp3-menu-item.bp3-intent-warning:active{
    background-color:#bf7326; }
  .bp3-dark .bp3-menu-item.bp3-intent-warning:hover, .bp3-dark .bp3-submenu .bp3-popover-target.bp3-popover-open > .bp3-intent-warning.bp3-menu-item, .bp3-submenu .bp3-dark .bp3-popover-target.bp3-popover-open > .bp3-intent-warning.bp3-menu-item, .bp3-dark .bp3-menu-item.bp3-intent-warning:hover::before, .bp3-dark .bp3-submenu .bp3-popover-target.bp3-popover-open > .bp3-intent-warning.bp3-menu-item::before, .bp3-submenu .bp3-dark .bp3-popover-target.bp3-popover-open > .bp3-intent-warning.bp3-menu-item::before, .bp3-dark .bp3-menu-item.bp3-intent-warning:hover::after, .bp3-dark .bp3-submenu .bp3-popover-target.bp3-popover-open > .bp3-intent-warning.bp3-menu-item::after, .bp3-submenu .bp3-dark .bp3-popover-target.bp3-popover-open > .bp3-intent-warning.bp3-menu-item::after,
  .bp3-dark .bp3-menu-item.bp3-intent-warning:hover .bp3-menu-item-label,
  .bp3-dark .bp3-submenu .bp3-popover-target.bp3-popover-open > .bp3-intent-warning.bp3-menu-item .bp3-menu-item-label,
  .bp3-submenu .bp3-dark .bp3-popover-target.bp3-popover-open > .bp3-intent-warning.bp3-menu-item .bp3-menu-item-label, .bp3-dark .bp3-menu-item.bp3-intent-warning:active, .bp3-dark .bp3-menu-item.bp3-intent-warning:active::before, .bp3-dark .bp3-menu-item.bp3-intent-warning:active::after,
  .bp3-dark .bp3-menu-item.bp3-intent-warning:active .bp3-menu-item-label, .bp3-dark .bp3-menu-item.bp3-intent-warning.bp3-active, .bp3-dark .bp3-menu-item.bp3-intent-warning.bp3-active::before, .bp3-dark .bp3-menu-item.bp3-intent-warning.bp3-active::after,
  .bp3-dark .bp3-menu-item.bp3-intent-warning.bp3-active .bp3-menu-item-label{
    color:#ffffff; }

.bp3-dark .bp3-menu-item.bp3-intent-danger{
  color:#ff7373; }
  .bp3-dark .bp3-menu-item.bp3-intent-danger .bp3-icon{
    color:inherit; }
  .bp3-dark .bp3-menu-item.bp3-intent-danger::before, .bp3-dark .bp3-menu-item.bp3-intent-danger::after,
  .bp3-dark .bp3-menu-item.bp3-intent-danger .bp3-menu-item-label{
    color:#ff7373; }
  .bp3-dark .bp3-menu-item.bp3-intent-danger:hover, .bp3-dark .bp3-submenu .bp3-popover-target.bp3-popover-open > .bp3-intent-danger.bp3-menu-item, .bp3-submenu .bp3-dark .bp3-popover-target.bp3-popover-open > .bp3-intent-danger.bp3-menu-item, .bp3-dark .bp3-menu-item.bp3-intent-danger.bp3-active{
    background-color:#db3737; }
  .bp3-dark .bp3-menu-item.bp3-intent-danger:active{
    background-color:#c23030; }
  .bp3-dark .bp3-menu-item.bp3-intent-danger:hover, .bp3-dark .bp3-submenu .bp3-popover-target.bp3-popover-open > .bp3-intent-danger.bp3-menu-item, .bp3-submenu .bp3-dark .bp3-popover-target.bp3-popover-open > .bp3-intent-danger.bp3-menu-item, .bp3-dark .bp3-menu-item.bp3-intent-danger:hover::before, .bp3-dark .bp3-submenu .bp3-popover-target.bp3-popover-open > .bp3-intent-danger.bp3-menu-item::before, .bp3-submenu .bp3-dark .bp3-popover-target.bp3-popover-open > .bp3-intent-danger.bp3-menu-item::before, .bp3-dark .bp3-menu-item.bp3-intent-danger:hover::after, .bp3-dark .bp3-submenu .bp3-popover-target.bp3-popover-open > .bp3-intent-danger.bp3-menu-item::after, .bp3-submenu .bp3-dark .bp3-popover-target.bp3-popover-open > .bp3-intent-danger.bp3-menu-item::after,
  .bp3-dark .bp3-menu-item.bp3-intent-danger:hover .bp3-menu-item-label,
  .bp3-dark .bp3-submenu .bp3-popover-target.bp3-popover-open > .bp3-intent-danger.bp3-menu-item .bp3-menu-item-label,
  .bp3-submenu .bp3-dark .bp3-popover-target.bp3-popover-open > .bp3-intent-danger.bp3-menu-item .bp3-menu-item-label, .bp3-dark .bp3-menu-item.bp3-intent-danger:active, .bp3-dark .bp3-menu-item.bp3-intent-danger:active::before, .bp3-dark .bp3-menu-item.bp3-intent-danger:active::after,
  .bp3-dark .bp3-menu-item.bp3-intent-danger:active .bp3-menu-item-label, .bp3-dark .bp3-menu-item.bp3-intent-danger.bp3-active, .bp3-dark .bp3-menu-item.bp3-intent-danger.bp3-active::before, .bp3-dark .bp3-menu-item.bp3-intent-danger.bp3-active::after,
  .bp3-dark .bp3-menu-item.bp3-intent-danger.bp3-active .bp3-menu-item-label{
    color:#ffffff; }

.bp3-dark .bp3-menu-item::before,
.bp3-dark .bp3-menu-item > .bp3-icon{
  color:#a7b6c2; }

.bp3-dark .bp3-menu-item .bp3-menu-item-label{
  color:#a7b6c2; }

.bp3-dark .bp3-menu-item.bp3-active, .bp3-dark .bp3-menu-item:active{
  background-color:rgba(138, 155, 168, 0.3); }

.bp3-dark .bp3-menu-item.bp3-disabled{
  color:rgba(167, 182, 194, 0.6) !important; }
  .bp3-dark .bp3-menu-item.bp3-disabled::before,
  .bp3-dark .bp3-menu-item.bp3-disabled > .bp3-icon,
  .bp3-dark .bp3-menu-item.bp3-disabled .bp3-menu-item-label{
    color:rgba(167, 182, 194, 0.6) !important; }

.bp3-dark .bp3-menu-divider,
.bp3-dark .bp3-menu-header{
  border-color:rgba(255, 255, 255, 0.15); }

.bp3-dark .bp3-menu-header > h6{
  color:#f5f8fa; }

.bp3-label .bp3-menu{
  margin-top:5px; }
.bp3-navbar{
  position:relative;
  z-index:10;
  -webkit-box-shadow:0 0 0 1px rgba(16, 22, 26, 0.1), 0 0 0 rgba(16, 22, 26, 0), 0 1px 1px rgba(16, 22, 26, 0.2);
          box-shadow:0 0 0 1px rgba(16, 22, 26, 0.1), 0 0 0 rgba(16, 22, 26, 0), 0 1px 1px rgba(16, 22, 26, 0.2);
  background-color:#ffffff;
  width:100%;
  height:50px;
  padding:0 15px; }
  .bp3-navbar.bp3-dark,
  .bp3-dark .bp3-navbar{
    background-color:#394b59; }
  .bp3-navbar.bp3-dark{
    -webkit-box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.2), 0 0 0 rgba(16, 22, 26, 0), 0 1px 1px rgba(16, 22, 26, 0.4);
            box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.2), 0 0 0 rgba(16, 22, 26, 0), 0 1px 1px rgba(16, 22, 26, 0.4); }
  .bp3-dark .bp3-navbar{
    -webkit-box-shadow:0 0 0 1px rgba(16, 22, 26, 0.2), 0 0 0 rgba(16, 22, 26, 0), 0 1px 1px rgba(16, 22, 26, 0.4);
            box-shadow:0 0 0 1px rgba(16, 22, 26, 0.2), 0 0 0 rgba(16, 22, 26, 0), 0 1px 1px rgba(16, 22, 26, 0.4); }
  .bp3-navbar.bp3-fixed-top{
    position:fixed;
    top:0;
    right:0;
    left:0; }

.bp3-navbar-heading{
  margin-right:15px;
  font-size:16px; }

.bp3-navbar-group{
  display:-webkit-box;
  display:-ms-flexbox;
  display:flex;
  -webkit-box-align:center;
      -ms-flex-align:center;
          align-items:center;
  height:50px; }
  .bp3-navbar-group.bp3-align-left{
    float:left; }
  .bp3-navbar-group.bp3-align-right{
    float:right; }

.bp3-navbar-divider{
  margin:0 10px;
  border-left:1px solid rgba(16, 22, 26, 0.15);
  height:20px; }
  .bp3-dark .bp3-navbar-divider{
    border-left-color:rgba(255, 255, 255, 0.15); }
.bp3-non-ideal-state{
  display:-webkit-box;
  display:-ms-flexbox;
  display:flex;
  -webkit-box-orient:vertical;
  -webkit-box-direction:normal;
      -ms-flex-direction:column;
          flex-direction:column;
  -webkit-box-align:center;
      -ms-flex-align:center;
          align-items:center;
  -webkit-box-pack:center;
      -ms-flex-pack:center;
          justify-content:center;
  width:100%;
  height:100%;
  text-align:center; }
  .bp3-non-ideal-state > *{
    -webkit-box-flex:0;
        -ms-flex-positive:0;
            flex-grow:0;
    -ms-flex-negative:0;
        flex-shrink:0; }
  .bp3-non-ideal-state > .bp3-fill{
    -webkit-box-flex:1;
        -ms-flex-positive:1;
            flex-grow:1;
    -ms-flex-negative:1;
        flex-shrink:1; }
  .bp3-non-ideal-state::before,
  .bp3-non-ideal-state > *{
    margin-bottom:20px; }
  .bp3-non-ideal-state:empty::before,
  .bp3-non-ideal-state > :last-child{
    margin-bottom:0; }
  .bp3-non-ideal-state > *{
    max-width:400px; }

.bp3-non-ideal-state-visual{
  color:rgba(92, 112, 128, 0.6);
  font-size:60px; }
  .bp3-dark .bp3-non-ideal-state-visual{
    color:rgba(167, 182, 194, 0.6); }

.bp3-overflow-list{
  display:-webkit-box;
  display:-ms-flexbox;
  display:flex;
  -ms-flex-wrap:nowrap;
      flex-wrap:nowrap;
  min-width:0; }

.bp3-overflow-list-spacer{
  -ms-flex-negative:1;
      flex-shrink:1;
  width:1px; }

body.bp3-overlay-open{
  overflow:hidden; }

.bp3-overlay{
  position:static;
  top:0;
  right:0;
  bottom:0;
  left:0;
  z-index:20; }
  .bp3-overlay:not(.bp3-overlay-open){
    pointer-events:none; }
  .bp3-overlay.bp3-overlay-container{
    position:fixed;
    overflow:hidden; }
    .bp3-overlay.bp3-overlay-container.bp3-overlay-inline{
      position:absolute; }
  .bp3-overlay.bp3-overlay-scroll-container{
    position:fixed;
    overflow:auto; }
    .bp3-overlay.bp3-overlay-scroll-container.bp3-overlay-inline{
      position:absolute; }
  .bp3-overlay.bp3-overlay-inline{
    display:inline;
    overflow:visible; }

.bp3-overlay-content{
  position:fixed;
  z-index:20; }
  .bp3-overlay-inline .bp3-overlay-content,
  .bp3-overlay-scroll-container .bp3-overlay-content{
    position:absolute; }

.bp3-overlay-backdrop{
  position:fixed;
  top:0;
  right:0;
  bottom:0;
  left:0;
  opacity:1;
  z-index:20;
  background-color:rgba(16, 22, 26, 0.7);
  overflow:auto;
  -webkit-user-select:none;
     -moz-user-select:none;
      -ms-user-select:none;
          user-select:none; }
  .bp3-overlay-backdrop.bp3-overlay-enter, .bp3-overlay-backdrop.bp3-overlay-appear{
    opacity:0; }
  .bp3-overlay-backdrop.bp3-overlay-enter-active, .bp3-overlay-backdrop.bp3-overlay-appear-active{
    opacity:1;
    -webkit-transition-property:opacity;
    transition-property:opacity;
    -webkit-transition-duration:200ms;
            transition-duration:200ms;
    -webkit-transition-timing-function:cubic-bezier(0.4, 1, 0.75, 0.9);
            transition-timing-function:cubic-bezier(0.4, 1, 0.75, 0.9);
    -webkit-transition-delay:0;
            transition-delay:0; }
  .bp3-overlay-backdrop.bp3-overlay-exit{
    opacity:1; }
  .bp3-overlay-backdrop.bp3-overlay-exit-active{
    opacity:0;
    -webkit-transition-property:opacity;
    transition-property:opacity;
    -webkit-transition-duration:200ms;
            transition-duration:200ms;
    -webkit-transition-timing-function:cubic-bezier(0.4, 1, 0.75, 0.9);
            transition-timing-function:cubic-bezier(0.4, 1, 0.75, 0.9);
    -webkit-transition-delay:0;
            transition-delay:0; }
  .bp3-overlay-backdrop:focus{
    outline:none; }
  .bp3-overlay-inline .bp3-overlay-backdrop{
    position:absolute; }
.bp3-panel-stack{
  position:relative;
  overflow:hidden; }

.bp3-panel-stack-header{
  display:-webkit-box;
  display:-ms-flexbox;
  display:flex;
  -ms-flex-negative:0;
      flex-shrink:0;
  -webkit-box-align:center;
      -ms-flex-align:center;
          align-items:center;
  z-index:1;
  -webkit-box-shadow:0 1px rgba(16, 22, 26, 0.15);
          box-shadow:0 1px rgba(16, 22, 26, 0.15);
  height:30px; }
  .bp3-dark .bp3-panel-stack-header{
    -webkit-box-shadow:0 1px rgba(255, 255, 255, 0.15);
            box-shadow:0 1px rgba(255, 255, 255, 0.15); }
  .bp3-panel-stack-header > span{
    display:-webkit-box;
    display:-ms-flexbox;
    display:flex;
    -webkit-box-flex:1;
        -ms-flex:1;
            flex:1;
    -webkit-box-align:stretch;
        -ms-flex-align:stretch;
            align-items:stretch; }
  .bp3-panel-stack-header .bp3-heading{
    margin:0 5px; }

.bp3-button.bp3-panel-stack-header-back{
  margin-left:5px;
  padding-left:0;
  white-space:nowrap; }
  .bp3-button.bp3-panel-stack-header-back .bp3-icon{
    margin:0 2px; }

.bp3-panel-stack-view{
  position:absolute;
  top:0;
  right:0;
  bottom:0;
  left:0;
  display:-webkit-box;
  display:-ms-flexbox;
  display:flex;
  -webkit-box-orient:vertical;
  -webkit-box-direction:normal;
      -ms-flex-direction:column;
          flex-direction:column;
  margin-right:-1px;
  border-right:1px solid rgba(16, 22, 26, 0.15);
  background-color:#ffffff;
  overflow-y:auto; }
  .bp3-dark .bp3-panel-stack-view{
    background-color:#30404d; }

.bp3-panel-stack-push .bp3-panel-stack-enter, .bp3-panel-stack-push .bp3-panel-stack-appear{
  -webkit-transform:translateX(100%);
          transform:translateX(100%);
  opacity:0; }

.bp3-panel-stack-push .bp3-panel-stack-enter-active, .bp3-panel-stack-push .bp3-panel-stack-appear-active{
  -webkit-transform:translate(0%);
          transform:translate(0%);
  opacity:1;
  -webkit-transition-property:opacity, -webkit-transform;
  transition-property:opacity, -webkit-transform;
  transition-property:transform, opacity;
  transition-property:transform, opacity, -webkit-transform;
  -webkit-transition-duration:400ms;
          transition-duration:400ms;
  -webkit-transition-timing-function:ease;
          transition-timing-function:ease;
  -webkit-transition-delay:0;
          transition-delay:0; }

.bp3-panel-stack-push .bp3-panel-stack-exit{
  -webkit-transform:translate(0%);
          transform:translate(0%);
  opacity:1; }

.bp3-panel-stack-push .bp3-panel-stack-exit-active{
  -webkit-transform:translateX(-50%);
          transform:translateX(-50%);
  opacity:0;
  -webkit-transition-property:opacity, -webkit-transform;
  transition-property:opacity, -webkit-transform;
  transition-property:transform, opacity;
  transition-property:transform, opacity, -webkit-transform;
  -webkit-transition-duration:400ms;
          transition-duration:400ms;
  -webkit-transition-timing-function:ease;
          transition-timing-function:ease;
  -webkit-transition-delay:0;
          transition-delay:0; }

.bp3-panel-stack-pop .bp3-panel-stack-enter, .bp3-panel-stack-pop .bp3-panel-stack-appear{
  -webkit-transform:translateX(-50%);
          transform:translateX(-50%);
  opacity:0; }

.bp3-panel-stack-pop .bp3-panel-stack-enter-active, .bp3-panel-stack-pop .bp3-panel-stack-appear-active{
  -webkit-transform:translate(0%);
          transform:translate(0%);
  opacity:1;
  -webkit-transition-property:opacity, -webkit-transform;
  transition-property:opacity, -webkit-transform;
  transition-property:transform, opacity;
  transition-property:transform, opacity, -webkit-transform;
  -webkit-transition-duration:400ms;
          transition-duration:400ms;
  -webkit-transition-timing-function:ease;
          transition-timing-function:ease;
  -webkit-transition-delay:0;
          transition-delay:0; }

.bp3-panel-stack-pop .bp3-panel-stack-exit{
  -webkit-transform:translate(0%);
          transform:translate(0%);
  opacity:1; }

.bp3-panel-stack-pop .bp3-panel-stack-exit-active{
  -webkit-transform:translateX(100%);
          transform:translateX(100%);
  opacity:0;
  -webkit-transition-property:opacity, -webkit-transform;
  transition-property:opacity, -webkit-transform;
  transition-property:transform, opacity;
  transition-property:transform, opacity, -webkit-transform;
  -webkit-transition-duration:400ms;
          transition-duration:400ms;
  -webkit-transition-timing-function:ease;
          transition-timing-function:ease;
  -webkit-transition-delay:0;
          transition-delay:0; }
.bp3-popover{
  -webkit-box-shadow:0 0 0 1px rgba(16, 22, 26, 0.1), 0 2px 4px rgba(16, 22, 26, 0.2), 0 8px 24px rgba(16, 22, 26, 0.2);
          box-shadow:0 0 0 1px rgba(16, 22, 26, 0.1), 0 2px 4px rgba(16, 22, 26, 0.2), 0 8px 24px rgba(16, 22, 26, 0.2);
  -webkit-transform:scale(1);
          transform:scale(1);
  display:inline-block;
  z-index:20;
  border-radius:3px; }
  .bp3-popover .bp3-popover-arrow{
    position:absolute;
    width:30px;
    height:30px; }
    .bp3-popover .bp3-popover-arrow::before{
      margin:5px;
      width:20px;
      height:20px; }
  .bp3-tether-element-attached-bottom.bp3-tether-target-attached-top > .bp3-popover{
    margin-top:-17px;
    margin-bottom:17px; }
    .bp3-tether-element-attached-bottom.bp3-tether-target-attached-top > .bp3-popover > .bp3-popover-arrow{
      bottom:-11px; }
      .bp3-tether-element-attached-bottom.bp3-tether-target-attached-top > .bp3-popover > .bp3-popover-arrow svg{
        -webkit-transform:rotate(-90deg);
                transform:rotate(-90deg); }
  .bp3-tether-element-attached-left.bp3-tether-target-attached-right > .bp3-popover{
    margin-left:17px; }
    .bp3-tether-element-attached-left.bp3-tether-target-attached-right > .bp3-popover > .bp3-popover-arrow{
      left:-11px; }
      .bp3-tether-element-attached-left.bp3-tether-target-attached-right > .bp3-popover > .bp3-popover-arrow svg{
        -webkit-transform:rotate(0);
                transform:rotate(0); }
  .bp3-tether-element-attached-top.bp3-tether-target-attached-bottom > .bp3-popover{
    margin-top:17px; }
    .bp3-tether-element-attached-top.bp3-tether-target-attached-bottom > .bp3-popover > .bp3-popover-arrow{
      top:-11px; }
      .bp3-tether-element-attached-top.bp3-tether-target-attached-bottom > .bp3-popover > .bp3-popover-arrow svg{
        -webkit-transform:rotate(90deg);
                transform:rotate(90deg); }
  .bp3-tether-element-attached-right.bp3-tether-target-attached-left > .bp3-popover{
    margin-right:17px;
    margin-left:-17px; }
    .bp3-tether-element-attached-right.bp3-tether-target-attached-left > .bp3-popover > .bp3-popover-arrow{
      right:-11px; }
      .bp3-tether-element-attached-right.bp3-tether-target-attached-left > .bp3-popover > .bp3-popover-arrow svg{
        -webkit-transform:rotate(180deg);
                transform:rotate(180deg); }
  .bp3-tether-element-attached-middle > .bp3-popover > .bp3-popover-arrow{
    top:50%;
    -webkit-transform:translateY(-50%);
            transform:translateY(-50%); }
  .bp3-tether-element-attached-center > .bp3-popover > .bp3-popover-arrow{
    right:50%;
    -webkit-transform:translateX(50%);
            transform:translateX(50%); }
  .bp3-tether-element-attached-top.bp3-tether-target-attached-top > .bp3-popover > .bp3-popover-arrow{
    top:-0.3934px; }
  .bp3-tether-element-attached-right.bp3-tether-target-attached-right > .bp3-popover > .bp3-popover-arrow{
    right:-0.3934px; }
  .bp3-tether-element-attached-left.bp3-tether-target-attached-left > .bp3-popover > .bp3-popover-arrow{
    left:-0.3934px; }
  .bp3-tether-element-attached-bottom.bp3-tether-target-attached-bottom > .bp3-popover > .bp3-popover-arrow{
    bottom:-0.3934px; }
  .bp3-tether-element-attached-top.bp3-tether-element-attached-left > .bp3-popover{
    -webkit-transform-origin:top left;
            transform-origin:top left; }
  .bp3-tether-element-attached-top.bp3-tether-element-attached-center > .bp3-popover{
    -webkit-transform-origin:top center;
            transform-origin:top center; }
  .bp3-tether-element-attached-top.bp3-tether-element-attached-right > .bp3-popover{
    -webkit-transform-origin:top right;
            transform-origin:top right; }
  .bp3-tether-element-attached-middle.bp3-tether-element-attached-left > .bp3-popover{
    -webkit-transform-origin:center left;
            transform-origin:center left; }
  .bp3-tether-element-attached-middle.bp3-tether-element-attached-center > .bp3-popover{
    -webkit-transform-origin:center center;
            transform-origin:center center; }
  .bp3-tether-element-attached-middle.bp3-tether-element-attached-right > .bp3-popover{
    -webkit-transform-origin:center right;
            transform-origin:center right; }
  .bp3-tether-element-attached-bottom.bp3-tether-element-attached-left > .bp3-popover{
    -webkit-transform-origin:bottom left;
            transform-origin:bottom left; }
  .bp3-tether-element-attached-bottom.bp3-tether-element-attached-center > .bp3-popover{
    -webkit-transform-origin:bottom center;
            transform-origin:bottom center; }
  .bp3-tether-element-attached-bottom.bp3-tether-element-attached-right > .bp3-popover{
    -webkit-transform-origin:bottom right;
            transform-origin:bottom right; }
  .bp3-popover .bp3-popover-content{
    background:#ffffff;
    color:inherit; }
  .bp3-popover .bp3-popover-arrow::before{
    -webkit-box-shadow:1px 1px 6px rgba(16, 22, 26, 0.2);
            box-shadow:1px 1px 6px rgba(16, 22, 26, 0.2); }
  .bp3-popover .bp3-popover-arrow-border{
    fill:#10161a;
    fill-opacity:0.1; }
  .bp3-popover .bp3-popover-arrow-fill{
    fill:#ffffff; }
  .bp3-popover-enter > .bp3-popover, .bp3-popover-appear > .bp3-popover{
    -webkit-transform:scale(0.3);
            transform:scale(0.3); }
  .bp3-popover-enter-active > .bp3-popover, .bp3-popover-appear-active > .bp3-popover{
    -webkit-transform:scale(1);
            transform:scale(1);
    -webkit-transition-property:-webkit-transform;
    transition-property:-webkit-transform;
    transition-property:transform;
    transition-property:transform, -webkit-transform;
    -webkit-transition-duration:300ms;
            transition-duration:300ms;
    -webkit-transition-timing-function:cubic-bezier(0.54, 1.12, 0.38, 1.11);
            transition-timing-function:cubic-bezier(0.54, 1.12, 0.38, 1.11);
    -webkit-transition-delay:0;
            transition-delay:0; }
  .bp3-popover-exit > .bp3-popover{
    -webkit-transform:scale(1);
            transform:scale(1); }
  .bp3-popover-exit-active > .bp3-popover{
    -webkit-transform:scale(0.3);
            transform:scale(0.3);
    -webkit-transition-property:-webkit-transform;
    transition-property:-webkit-transform;
    transition-property:transform;
    transition-property:transform, -webkit-transform;
    -webkit-transition-duration:300ms;
            transition-duration:300ms;
    -webkit-transition-timing-function:cubic-bezier(0.54, 1.12, 0.38, 1.11);
            transition-timing-function:cubic-bezier(0.54, 1.12, 0.38, 1.11);
    -webkit-transition-delay:0;
            transition-delay:0; }
  .bp3-popover .bp3-popover-content{
    position:relative;
    border-radius:3px; }
  .bp3-popover.bp3-popover-content-sizing .bp3-popover-content{
    max-width:350px;
    padding:20px; }
  .bp3-popover-target + .bp3-overlay .bp3-popover.bp3-popover-content-sizing{
    width:350px; }
  .bp3-popover.bp3-minimal{
    margin:0 !important; }
    .bp3-popover.bp3-minimal .bp3-popover-arrow{
      display:none; }
    .bp3-popover.bp3-minimal.bp3-popover{
      -webkit-transform:scale(1);
              transform:scale(1); }
      .bp3-popover-enter > .bp3-popover.bp3-minimal.bp3-popover, .bp3-popover-appear > .bp3-popover.bp3-minimal.bp3-popover{
        -webkit-transform:scale(1);
                transform:scale(1); }
      .bp3-popover-enter-active > .bp3-popover.bp3-minimal.bp3-popover, .bp3-popover-appear-active > .bp3-popover.bp3-minimal.bp3-popover{
        -webkit-transform:scale(1);
                transform:scale(1);
        -webkit-transition-property:-webkit-transform;
        transition-property:-webkit-transform;
        transition-property:transform;
        transition-property:transform, -webkit-transform;
        -webkit-transition-duration:100ms;
                transition-duration:100ms;
        -webkit-transition-timing-function:cubic-bezier(0.4, 1, 0.75, 0.9);
                transition-timing-function:cubic-bezier(0.4, 1, 0.75, 0.9);
        -webkit-transition-delay:0;
                transition-delay:0; }
      .bp3-popover-exit > .bp3-popover.bp3-minimal.bp3-popover{
        -webkit-transform:scale(1);
                transform:scale(1); }
      .bp3-popover-exit-active > .bp3-popover.bp3-minimal.bp3-popover{
        -webkit-transform:scale(1);
                transform:scale(1);
        -webkit-transition-property:-webkit-transform;
        transition-property:-webkit-transform;
        transition-property:transform;
        transition-property:transform, -webkit-transform;
        -webkit-transition-duration:100ms;
                transition-duration:100ms;
        -webkit-transition-timing-function:cubic-bezier(0.4, 1, 0.75, 0.9);
                transition-timing-function:cubic-bezier(0.4, 1, 0.75, 0.9);
        -webkit-transition-delay:0;
                transition-delay:0; }
  .bp3-popover.bp3-dark,
  .bp3-dark .bp3-popover{
    -webkit-box-shadow:0 0 0 1px rgba(16, 22, 26, 0.2), 0 2px 4px rgba(16, 22, 26, 0.4), 0 8px 24px rgba(16, 22, 26, 0.4);
            box-shadow:0 0 0 1px rgba(16, 22, 26, 0.2), 0 2px 4px rgba(16, 22, 26, 0.4), 0 8px 24px rgba(16, 22, 26, 0.4); }
    .bp3-popover.bp3-dark .bp3-popover-content,
    .bp3-dark .bp3-popover .bp3-popover-content{
      background:#30404d;
      color:inherit; }
    .bp3-popover.bp3-dark .bp3-popover-arrow::before,
    .bp3-dark .bp3-popover .bp3-popover-arrow::before{
      -webkit-box-shadow:1px 1px 6px rgba(16, 22, 26, 0.4);
              box-shadow:1px 1px 6px rgba(16, 22, 26, 0.4); }
    .bp3-popover.bp3-dark .bp3-popover-arrow-border,
    .bp3-dark .bp3-popover .bp3-popover-arrow-border{
      fill:#10161a;
      fill-opacity:0.2; }
    .bp3-popover.bp3-dark .bp3-popover-arrow-fill,
    .bp3-dark .bp3-popover .bp3-popover-arrow-fill{
      fill:#30404d; }

.bp3-popover-arrow::before{
  display:block;
  position:absolute;
  -webkit-transform:rotate(45deg);
          transform:rotate(45deg);
  border-radius:2px;
  content:""; }

.bp3-tether-pinned .bp3-popover-arrow{
  display:none; }

.bp3-popover-backdrop{
  background:rgba(255, 255, 255, 0); }

.bp3-transition-container{
  opacity:1;
  display:-webkit-box;
  display:-ms-flexbox;
  display:flex;
  z-index:20; }
  .bp3-transition-container.bp3-popover-enter, .bp3-transition-container.bp3-popover-appear{
    opacity:0; }
  .bp3-transition-container.bp3-popover-enter-active, .bp3-transition-container.bp3-popover-appear-active{
    opacity:1;
    -webkit-transition-property:opacity;
    transition-property:opacity;
    -webkit-transition-duration:100ms;
            transition-duration:100ms;
    -webkit-transition-timing-function:cubic-bezier(0.4, 1, 0.75, 0.9);
            transition-timing-function:cubic-bezier(0.4, 1, 0.75, 0.9);
    -webkit-transition-delay:0;
            transition-delay:0; }
  .bp3-transition-container.bp3-popover-exit{
    opacity:1; }
  .bp3-transition-container.bp3-popover-exit-active{
    opacity:0;
    -webkit-transition-property:opacity;
    transition-property:opacity;
    -webkit-transition-duration:100ms;
            transition-duration:100ms;
    -webkit-transition-timing-function:cubic-bezier(0.4, 1, 0.75, 0.9);
            transition-timing-function:cubic-bezier(0.4, 1, 0.75, 0.9);
    -webkit-transition-delay:0;
            transition-delay:0; }
  .bp3-transition-container:focus{
    outline:none; }
  .bp3-transition-container.bp3-popover-leave .bp3-popover-content{
    pointer-events:none; }
  .bp3-transition-container[data-x-out-of-boundaries]{
    display:none; }

span.bp3-popover-target{
  display:inline-block; }

.bp3-popover-wrapper.bp3-fill{
  width:100%; }

.bp3-portal{
  position:absolute;
  top:0;
  right:0;
  left:0; }
@-webkit-keyframes linear-progress-bar-stripes{
  from{
    background-position:0 0; }
  to{
    background-position:30px 0; } }
@keyframes linear-progress-bar-stripes{
  from{
    background-position:0 0; }
  to{
    background-position:30px 0; } }

.bp3-progress-bar{
  display:block;
  position:relative;
  border-radius:40px;
  background:rgba(92, 112, 128, 0.2);
  width:100%;
  height:8px;
  overflow:hidden; }
  .bp3-progress-bar .bp3-progress-meter{
    position:absolute;
    border-radius:40px;
    background:linear-gradient(-45deg, rgba(255, 255, 255, 0.2) 25%, transparent 25%, transparent 50%, rgba(255, 255, 255, 0.2) 50%, rgba(255, 255, 255, 0.2) 75%, transparent 75%);
    background-color:rgba(92, 112, 128, 0.8);
    background-size:30px 30px;
    width:100%;
    height:100%;
    -webkit-transition:width 200ms cubic-bezier(0.4, 1, 0.75, 0.9);
    transition:width 200ms cubic-bezier(0.4, 1, 0.75, 0.9); }
  .bp3-progress-bar:not(.bp3-no-animation):not(.bp3-no-stripes) .bp3-progress-meter{
    animation:linear-progress-bar-stripes 300ms linear infinite reverse; }
  .bp3-progress-bar.bp3-no-stripes .bp3-progress-meter{
    background-image:none; }

.bp3-dark .bp3-progress-bar{
  background:rgba(16, 22, 26, 0.5); }
  .bp3-dark .bp3-progress-bar .bp3-progress-meter{
    background-color:#8a9ba8; }

.bp3-progress-bar.bp3-intent-primary .bp3-progress-meter{
  background-color:#137cbd; }

.bp3-progress-bar.bp3-intent-success .bp3-progress-meter{
  background-color:#0f9960; }

.bp3-progress-bar.bp3-intent-warning .bp3-progress-meter{
  background-color:#d9822b; }

.bp3-progress-bar.bp3-intent-danger .bp3-progress-meter{
  background-color:#db3737; }
@-webkit-keyframes skeleton-glow{
  from{
    border-color:rgba(206, 217, 224, 0.2);
    background:rgba(206, 217, 224, 0.2); }
  to{
    border-color:rgba(92, 112, 128, 0.2);
    background:rgba(92, 112, 128, 0.2); } }
@keyframes skeleton-glow{
  from{
    border-color:rgba(206, 217, 224, 0.2);
    background:rgba(206, 217, 224, 0.2); }
  to{
    border-color:rgba(92, 112, 128, 0.2);
    background:rgba(92, 112, 128, 0.2); } }
.bp3-skeleton{
  border-color:rgba(206, 217, 224, 0.2) !important;
  border-radius:2px;
  -webkit-box-shadow:none !important;
          box-shadow:none !important;
  background:rgba(206, 217, 224, 0.2);
  background-clip:padding-box !important;
  cursor:default;
  color:transparent !important;
  -webkit-animation:1000ms linear infinite alternate skeleton-glow;
          animation:1000ms linear infinite alternate skeleton-glow;
  pointer-events:none;
  -webkit-user-select:none;
     -moz-user-select:none;
      -ms-user-select:none;
          user-select:none; }
  .bp3-skeleton::before, .bp3-skeleton::after,
  .bp3-skeleton *{
    visibility:hidden !important; }
.bp3-slider{
  width:100%;
  min-width:150px;
  height:40px;
  position:relative;
  outline:none;
  cursor:default;
  -webkit-user-select:none;
     -moz-user-select:none;
      -ms-user-select:none;
          user-select:none; }
  .bp3-slider:hover{
    cursor:pointer; }
  .bp3-slider:active{
    cursor:-webkit-grabbing;
    cursor:grabbing; }
  .bp3-slider.bp3-disabled{
    opacity:0.5;
    cursor:not-allowed; }
  .bp3-slider.bp3-slider-unlabeled{
    height:16px; }

.bp3-slider-track,
.bp3-slider-progress{
  top:5px;
  right:0;
  left:0;
  height:6px;
  position:absolute; }

.bp3-slider-track{
  border-radius:3px;
  overflow:hidden; }

.bp3-slider-progress{
  background:rgba(92, 112, 128, 0.2); }
  .bp3-dark .bp3-slider-progress{
    background:rgba(16, 22, 26, 0.5); }
  .bp3-slider-progress.bp3-intent-primary{
    background-color:#137cbd; }
  .bp3-slider-progress.bp3-intent-success{
    background-color:#0f9960; }
  .bp3-slider-progress.bp3-intent-warning{
    background-color:#d9822b; }
  .bp3-slider-progress.bp3-intent-danger{
    background-color:#db3737; }

.bp3-slider-handle{
  -webkit-box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.2), inset 0 -1px 0 rgba(16, 22, 26, 0.1);
          box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.2), inset 0 -1px 0 rgba(16, 22, 26, 0.1);
  background-color:#f5f8fa;
  background-image:-webkit-gradient(linear, left top, left bottom, from(rgba(255, 255, 255, 0.8)), to(rgba(255, 255, 255, 0)));
  background-image:linear-gradient(to bottom, rgba(255, 255, 255, 0.8), rgba(255, 255, 255, 0));
  color:#182026;
  position:absolute;
  top:0;
  left:0;
  border-radius:3px;
  -webkit-box-shadow:0 0 0 1px rgba(16, 22, 26, 0.2), 0 1px 1px rgba(16, 22, 26, 0.2);
          box-shadow:0 0 0 1px rgba(16, 22, 26, 0.2), 0 1px 1px rgba(16, 22, 26, 0.2);
  cursor:pointer;
  width:16px;
  height:16px; }
  .bp3-slider-handle:hover{
    -webkit-box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.2), inset 0 -1px 0 rgba(16, 22, 26, 0.1);
            box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.2), inset 0 -1px 0 rgba(16, 22, 26, 0.1);
    background-clip:padding-box;
    background-color:#ebf1f5; }
  .bp3-slider-handle:active, .bp3-slider-handle.bp3-active{
    -webkit-box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.2), inset 0 1px 2px rgba(16, 22, 26, 0.2);
            box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.2), inset 0 1px 2px rgba(16, 22, 26, 0.2);
    background-color:#d8e1e8;
    background-image:none; }
  .bp3-slider-handle:disabled, .bp3-slider-handle.bp3-disabled{
    outline:none;
    -webkit-box-shadow:none;
            box-shadow:none;
    background-color:rgba(206, 217, 224, 0.5);
    background-image:none;
    cursor:not-allowed;
    color:rgba(92, 112, 128, 0.6); }
    .bp3-slider-handle:disabled.bp3-active, .bp3-slider-handle:disabled.bp3-active:hover, .bp3-slider-handle.bp3-disabled.bp3-active, .bp3-slider-handle.bp3-disabled.bp3-active:hover{
      background:rgba(206, 217, 224, 0.7); }
  .bp3-slider-handle:focus{
    z-index:1; }
  .bp3-slider-handle:hover{
    -webkit-box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.2), inset 0 -1px 0 rgba(16, 22, 26, 0.1);
            box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.2), inset 0 -1px 0 rgba(16, 22, 26, 0.1);
    background-clip:padding-box;
    background-color:#ebf1f5;
    z-index:2;
    -webkit-box-shadow:0 0 0 1px rgba(16, 22, 26, 0.2), 0 1px 1px rgba(16, 22, 26, 0.2);
            box-shadow:0 0 0 1px rgba(16, 22, 26, 0.2), 0 1px 1px rgba(16, 22, 26, 0.2);
    cursor:-webkit-grab;
    cursor:grab; }
  .bp3-slider-handle.bp3-active{
    -webkit-box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.2), inset 0 1px 2px rgba(16, 22, 26, 0.2);
            box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.2), inset 0 1px 2px rgba(16, 22, 26, 0.2);
    background-color:#d8e1e8;
    background-image:none;
    -webkit-box-shadow:0 0 0 1px rgba(16, 22, 26, 0.2), inset 0 1px 1px rgba(16, 22, 26, 0.1);
            box-shadow:0 0 0 1px rgba(16, 22, 26, 0.2), inset 0 1px 1px rgba(16, 22, 26, 0.1);
    cursor:-webkit-grabbing;
    cursor:grabbing; }
  .bp3-disabled .bp3-slider-handle{
    -webkit-box-shadow:none;
            box-shadow:none;
    background:#bfccd6;
    pointer-events:none; }
  .bp3-dark .bp3-slider-handle{
    -webkit-box-shadow:0 0 0 1px rgba(16, 22, 26, 0.4);
            box-shadow:0 0 0 1px rgba(16, 22, 26, 0.4);
    background-color:#394b59;
    background-image:-webkit-gradient(linear, left top, left bottom, from(rgba(255, 255, 255, 0.05)), to(rgba(255, 255, 255, 0)));
    background-image:linear-gradient(to bottom, rgba(255, 255, 255, 0.05), rgba(255, 255, 255, 0));
    color:#f5f8fa; }
    .bp3-dark .bp3-slider-handle:hover, .bp3-dark .bp3-slider-handle:active, .bp3-dark .bp3-slider-handle.bp3-active{
      color:#f5f8fa; }
    .bp3-dark .bp3-slider-handle:hover{
      -webkit-box-shadow:0 0 0 1px rgba(16, 22, 26, 0.4);
              box-shadow:0 0 0 1px rgba(16, 22, 26, 0.4);
      background-color:#30404d; }
    .bp3-dark .bp3-slider-handle:active, .bp3-dark .bp3-slider-handle.bp3-active{
      -webkit-box-shadow:0 0 0 1px rgba(16, 22, 26, 0.6), inset 0 1px 2px rgba(16, 22, 26, 0.2);
              box-shadow:0 0 0 1px rgba(16, 22, 26, 0.6), inset 0 1px 2px rgba(16, 22, 26, 0.2);
      background-color:#202b33;
      background-image:none; }
    .bp3-dark .bp3-slider-handle:disabled, .bp3-dark .bp3-slider-handle.bp3-disabled{
      -webkit-box-shadow:none;
              box-shadow:none;
      background-color:rgba(57, 75, 89, 0.5);
      background-image:none;
      color:rgba(167, 182, 194, 0.6); }
      .bp3-dark .bp3-slider-handle:disabled.bp3-active, .bp3-dark .bp3-slider-handle.bp3-disabled.bp3-active{
        background:rgba(57, 75, 89, 0.7); }
    .bp3-dark .bp3-slider-handle .bp3-button-spinner .bp3-spinner-head{
      background:rgba(16, 22, 26, 0.5);
      stroke:#8a9ba8; }
    .bp3-dark .bp3-slider-handle, .bp3-dark .bp3-slider-handle:hover{
      background-color:#394b59; }
    .bp3-dark .bp3-slider-handle.bp3-active{
      background-color:#293742; }
  .bp3-dark .bp3-disabled .bp3-slider-handle{
    border-color:#5c7080;
    -webkit-box-shadow:none;
            box-shadow:none;
    background:#5c7080; }
  .bp3-slider-handle .bp3-slider-label{
    margin-left:8px;
    border-radius:3px;
    -webkit-box-shadow:0 0 0 1px rgba(16, 22, 26, 0.1), 0 2px 4px rgba(16, 22, 26, 0.2), 0 8px 24px rgba(16, 22, 26, 0.2);
            box-shadow:0 0 0 1px rgba(16, 22, 26, 0.1), 0 2px 4px rgba(16, 22, 26, 0.2), 0 8px 24px rgba(16, 22, 26, 0.2);
    background:#394b59;
    color:#f5f8fa; }
    .bp3-dark .bp3-slider-handle .bp3-slider-label{
      -webkit-box-shadow:0 0 0 1px rgba(16, 22, 26, 0.2), 0 2px 4px rgba(16, 22, 26, 0.4), 0 8px 24px rgba(16, 22, 26, 0.4);
              box-shadow:0 0 0 1px rgba(16, 22, 26, 0.2), 0 2px 4px rgba(16, 22, 26, 0.4), 0 8px 24px rgba(16, 22, 26, 0.4);
      background:#e1e8ed;
      color:#394b59; }
    .bp3-disabled .bp3-slider-handle .bp3-slider-label{
      -webkit-box-shadow:none;
              box-shadow:none; }
  .bp3-slider-handle.bp3-start, .bp3-slider-handle.bp3-end{
    width:8px; }
  .bp3-slider-handle.bp3-start{
    border-top-right-radius:0;
    border-bottom-right-radius:0; }
  .bp3-slider-handle.bp3-end{
    margin-left:8px;
    border-top-left-radius:0;
    border-bottom-left-radius:0; }
    .bp3-slider-handle.bp3-end .bp3-slider-label{
      margin-left:0; }

.bp3-slider-label{
  -webkit-transform:translate(-50%, 20px);
          transform:translate(-50%, 20px);
  display:inline-block;
  position:absolute;
  padding:2px 5px;
  vertical-align:top;
  line-height:1;
  font-size:12px; }

.bp3-slider.bp3-vertical{
  width:40px;
  min-width:40px;
  height:150px; }
  .bp3-slider.bp3-vertical .bp3-slider-track,
  .bp3-slider.bp3-vertical .bp3-slider-progress{
    top:0;
    bottom:0;
    left:5px;
    width:6px;
    height:auto; }
  .bp3-slider.bp3-vertical .bp3-slider-progress{
    top:auto; }
  .bp3-slider.bp3-vertical .bp3-slider-label{
    -webkit-transform:translate(20px, 50%);
            transform:translate(20px, 50%); }
  .bp3-slider.bp3-vertical .bp3-slider-handle{
    top:auto; }
    .bp3-slider.bp3-vertical .bp3-slider-handle .bp3-slider-label{
      margin-top:-8px;
      margin-left:0; }
    .bp3-slider.bp3-vertical .bp3-slider-handle.bp3-end, .bp3-slider.bp3-vertical .bp3-slider-handle.bp3-start{
      margin-left:0;
      width:16px;
      height:8px; }
    .bp3-slider.bp3-vertical .bp3-slider-handle.bp3-start{
      border-top-left-radius:0;
      border-bottom-right-radius:3px; }
      .bp3-slider.bp3-vertical .bp3-slider-handle.bp3-start .bp3-slider-label{
        -webkit-transform:translate(20px);
                transform:translate(20px); }
    .bp3-slider.bp3-vertical .bp3-slider-handle.bp3-end{
      margin-bottom:8px;
      border-top-left-radius:3px;
      border-bottom-left-radius:0;
      border-bottom-right-radius:0; }

@-webkit-keyframes pt-spinner-animation{
  from{
    -webkit-transform:rotate(0deg);
            transform:rotate(0deg); }
  to{
    -webkit-transform:rotate(360deg);
            transform:rotate(360deg); } }

@keyframes pt-spinner-animation{
  from{
    -webkit-transform:rotate(0deg);
            transform:rotate(0deg); }
  to{
    -webkit-transform:rotate(360deg);
            transform:rotate(360deg); } }

.bp3-spinner{
  display:-webkit-box;
  display:-ms-flexbox;
  display:flex;
  -webkit-box-align:center;
      -ms-flex-align:center;
          align-items:center;
  -webkit-box-pack:center;
      -ms-flex-pack:center;
          justify-content:center;
  overflow:visible;
  vertical-align:middle; }
  .bp3-spinner svg{
    display:block; }
  .bp3-spinner path{
    fill-opacity:0; }
  .bp3-spinner .bp3-spinner-head{
    -webkit-transform-origin:center;
            transform-origin:center;
    -webkit-transition:stroke-dashoffset 200ms cubic-bezier(0.4, 1, 0.75, 0.9);
    transition:stroke-dashoffset 200ms cubic-bezier(0.4, 1, 0.75, 0.9);
    stroke:rgba(92, 112, 128, 0.8);
    stroke-linecap:round; }
  .bp3-spinner .bp3-spinner-track{
    stroke:rgba(92, 112, 128, 0.2); }

.bp3-spinner-animation{
  -webkit-animation:pt-spinner-animation 500ms linear infinite;
          animation:pt-spinner-animation 500ms linear infinite; }
  .bp3-no-spin > .bp3-spinner-animation{
    -webkit-animation:none;
            animation:none; }

.bp3-dark .bp3-spinner .bp3-spinner-head{
  stroke:#8a9ba8; }

.bp3-dark .bp3-spinner .bp3-spinner-track{
  stroke:rgba(16, 22, 26, 0.5); }

.bp3-spinner.bp3-intent-primary .bp3-spinner-head{
  stroke:#137cbd; }

.bp3-spinner.bp3-intent-success .bp3-spinner-head{
  stroke:#0f9960; }

.bp3-spinner.bp3-intent-warning .bp3-spinner-head{
  stroke:#d9822b; }

.bp3-spinner.bp3-intent-danger .bp3-spinner-head{
  stroke:#db3737; }
.bp3-tabs.bp3-vertical{
  display:-webkit-box;
  display:-ms-flexbox;
  display:flex; }
  .bp3-tabs.bp3-vertical > .bp3-tab-list{
    -webkit-box-orient:vertical;
    -webkit-box-direction:normal;
        -ms-flex-direction:column;
            flex-direction:column;
    -webkit-box-align:start;
        -ms-flex-align:start;
            align-items:flex-start; }
    .bp3-tabs.bp3-vertical > .bp3-tab-list .bp3-tab{
      border-radius:3px;
      width:100%;
      padding:0 10px; }
      .bp3-tabs.bp3-vertical > .bp3-tab-list .bp3-tab[aria-selected="true"]{
        -webkit-box-shadow:none;
                box-shadow:none;
        background-color:rgba(19, 124, 189, 0.2); }
    .bp3-tabs.bp3-vertical > .bp3-tab-list .bp3-tab-indicator-wrapper .bp3-tab-indicator{
      top:0;
      right:0;
      bottom:0;
      left:0;
      border-radius:3px;
      background-color:rgba(19, 124, 189, 0.2);
      height:auto; }
  .bp3-tabs.bp3-vertical > .bp3-tab-panel{
    margin-top:0;
    padding-left:20px; }

.bp3-tab-list{
  display:-webkit-box;
  display:-ms-flexbox;
  display:flex;
  -webkit-box-flex:0;
      -ms-flex:0 0 auto;
          flex:0 0 auto;
  -webkit-box-align:end;
      -ms-flex-align:end;
          align-items:flex-end;
  position:relative;
  margin:0;
  border:none;
  padding:0;
  list-style:none; }
  .bp3-tab-list > *:not(:last-child){
    margin-right:20px; }

.bp3-tab{
  overflow:hidden;
  text-overflow:ellipsis;
  white-space:nowrap;
  word-wrap:normal;
  -webkit-box-flex:0;
      -ms-flex:0 0 auto;
          flex:0 0 auto;
  position:relative;
  cursor:pointer;
  max-width:100%;
  vertical-align:top;
  line-height:30px;
  color:#182026;
  font-size:14px; }
  .bp3-tab a{
    display:block;
    text-decoration:none;
    color:inherit; }
  .bp3-tab-indicator-wrapper ~ .bp3-tab{
    -webkit-box-shadow:none !important;
            box-shadow:none !important;
    background-color:transparent !important; }
  .bp3-tab[aria-disabled="true"]{
    cursor:not-allowed;
    color:rgba(92, 112, 128, 0.6); }
  .bp3-tab[aria-selected="true"]{
    border-radius:0;
    -webkit-box-shadow:inset 0 -3px 0 #106ba3;
            box-shadow:inset 0 -3px 0 #106ba3; }
  .bp3-tab[aria-selected="true"], .bp3-tab:not([aria-disabled="true"]):hover{
    color:#106ba3; }
  .bp3-tab:focus{
    -moz-outline-radius:0; }
  .bp3-large > .bp3-tab{
    line-height:40px;
    font-size:16px; }

.bp3-tab-panel{
  margin-top:20px; }
  .bp3-tab-panel[aria-hidden="true"]{
    display:none; }

.bp3-tab-indicator-wrapper{
  position:absolute;
  top:0;
  left:0;
  -webkit-transform:translateX(0), translateY(0);
          transform:translateX(0), translateY(0);
  -webkit-transition:height, width, -webkit-transform;
  transition:height, width, -webkit-transform;
  transition:height, transform, width;
  transition:height, transform, width, -webkit-transform;
  -webkit-transition-duration:200ms;
          transition-duration:200ms;
  -webkit-transition-timing-function:cubic-bezier(0.4, 1, 0.75, 0.9);
          transition-timing-function:cubic-bezier(0.4, 1, 0.75, 0.9);
  pointer-events:none; }
  .bp3-tab-indicator-wrapper .bp3-tab-indicator{
    position:absolute;
    right:0;
    bottom:0;
    left:0;
    background-color:#106ba3;
    height:3px; }
  .bp3-tab-indicator-wrapper.bp3-no-animation{
    -webkit-transition:none;
    transition:none; }

.bp3-dark .bp3-tab{
  color:#f5f8fa; }
  .bp3-dark .bp3-tab[aria-disabled="true"]{
    color:rgba(167, 182, 194, 0.6); }
  .bp3-dark .bp3-tab[aria-selected="true"]{
    -webkit-box-shadow:inset 0 -3px 0 #48aff0;
            box-shadow:inset 0 -3px 0 #48aff0; }
  .bp3-dark .bp3-tab[aria-selected="true"], .bp3-dark .bp3-tab:not([aria-disabled="true"]):hover{
    color:#48aff0; }

.bp3-dark .bp3-tab-indicator{
  background-color:#48aff0; }

.bp3-flex-expander{
  -webkit-box-flex:1;
      -ms-flex:1 1;
          flex:1 1; }
.bp3-tag{
  display:-webkit-inline-box;
  display:-ms-inline-flexbox;
  display:inline-flex;
  -webkit-box-orient:horizontal;
  -webkit-box-direction:normal;
      -ms-flex-direction:row;
          flex-direction:row;
  -webkit-box-align:center;
      -ms-flex-align:center;
          align-items:center;
  position:relative;
  border:none;
  border-radius:3px;
  -webkit-box-shadow:none;
          box-shadow:none;
  background-color:#5c7080;
  min-width:20px;
  max-width:100%;
  min-height:20px;
  padding:2px 6px;
  line-height:16px;
  color:#f5f8fa;
  font-size:12px; }
  .bp3-tag.bp3-interactive{
    cursor:pointer; }
    .bp3-tag.bp3-interactive:hover{
      background-color:rgba(92, 112, 128, 0.85); }
    .bp3-tag.bp3-interactive.bp3-active, .bp3-tag.bp3-interactive:active{
      background-color:rgba(92, 112, 128, 0.7); }
  .bp3-tag > *{
    -webkit-box-flex:0;
        -ms-flex-positive:0;
            flex-grow:0;
    -ms-flex-negative:0;
        flex-shrink:0; }
  .bp3-tag > .bp3-fill{
    -webkit-box-flex:1;
        -ms-flex-positive:1;
            flex-grow:1;
    -ms-flex-negative:1;
        flex-shrink:1; }
  .bp3-tag::before,
  .bp3-tag > *{
    margin-right:4px; }
  .bp3-tag:empty::before,
  .bp3-tag > :last-child{
    margin-right:0; }
  .bp3-tag:focus{
    outline:rgba(19, 124, 189, 0.6) auto 2px;
    outline-offset:0;
    -moz-outline-radius:6px; }
  .bp3-tag.bp3-round{
    border-radius:30px;
    padding-right:8px;
    padding-left:8px; }
  .bp3-dark .bp3-tag{
    background-color:#bfccd6;
    color:#182026; }
    .bp3-dark .bp3-tag.bp3-interactive{
      cursor:pointer; }
      .bp3-dark .bp3-tag.bp3-interactive:hover{
        background-color:rgba(191, 204, 214, 0.85); }
      .bp3-dark .bp3-tag.bp3-interactive.bp3-active, .bp3-dark .bp3-tag.bp3-interactive:active{
        background-color:rgba(191, 204, 214, 0.7); }
    .bp3-dark .bp3-tag > .bp3-icon, .bp3-dark .bp3-tag .bp3-icon-standard, .bp3-dark .bp3-tag .bp3-icon-large{
      fill:currentColor; }
  .bp3-tag > .bp3-icon, .bp3-tag .bp3-icon-standard, .bp3-tag .bp3-icon-large{
    fill:#ffffff; }
  .bp3-tag.bp3-large,
  .bp3-large .bp3-tag{
    min-width:30px;
    min-height:30px;
    padding:0 10px;
    line-height:20px;
    font-size:14px; }
    .bp3-tag.bp3-large::before,
    .bp3-tag.bp3-large > *,
    .bp3-large .bp3-tag::before,
    .bp3-large .bp3-tag > *{
      margin-right:7px; }
    .bp3-tag.bp3-large:empty::before,
    .bp3-tag.bp3-large > :last-child,
    .bp3-large .bp3-tag:empty::before,
    .bp3-large .bp3-tag > :last-child{
      margin-right:0; }
    .bp3-tag.bp3-large.bp3-round,
    .bp3-large .bp3-tag.bp3-round{
      padding-right:12px;
      padding-left:12px; }
  .bp3-tag.bp3-intent-primary{
    background:#137cbd;
    color:#ffffff; }
    .bp3-tag.bp3-intent-primary.bp3-interactive{
      cursor:pointer; }
      .bp3-tag.bp3-intent-primary.bp3-interactive:hover{
        background-color:rgba(19, 124, 189, 0.85); }
      .bp3-tag.bp3-intent-primary.bp3-interactive.bp3-active, .bp3-tag.bp3-intent-primary.bp3-interactive:active{
        background-color:rgba(19, 124, 189, 0.7); }
  .bp3-tag.bp3-intent-success{
    background:#0f9960;
    color:#ffffff; }
    .bp3-tag.bp3-intent-success.bp3-interactive{
      cursor:pointer; }
      .bp3-tag.bp3-intent-success.bp3-interactive:hover{
        background-color:rgba(15, 153, 96, 0.85); }
      .bp3-tag.bp3-intent-success.bp3-interactive.bp3-active, .bp3-tag.bp3-intent-success.bp3-interactive:active{
        background-color:rgba(15, 153, 96, 0.7); }
  .bp3-tag.bp3-intent-warning{
    background:#d9822b;
    color:#ffffff; }
    .bp3-tag.bp3-intent-warning.bp3-interactive{
      cursor:pointer; }
      .bp3-tag.bp3-intent-warning.bp3-interactive:hover{
        background-color:rgba(217, 130, 43, 0.85); }
      .bp3-tag.bp3-intent-warning.bp3-interactive.bp3-active, .bp3-tag.bp3-intent-warning.bp3-interactive:active{
        background-color:rgba(217, 130, 43, 0.7); }
  .bp3-tag.bp3-intent-danger{
    background:#db3737;
    color:#ffffff; }
    .bp3-tag.bp3-intent-danger.bp3-interactive{
      cursor:pointer; }
      .bp3-tag.bp3-intent-danger.bp3-interactive:hover{
        background-color:rgba(219, 55, 55, 0.85); }
      .bp3-tag.bp3-intent-danger.bp3-interactive.bp3-active, .bp3-tag.bp3-intent-danger.bp3-interactive:active{
        background-color:rgba(219, 55, 55, 0.7); }
  .bp3-tag.bp3-fill{
    display:-webkit-box;
    display:-ms-flexbox;
    display:flex;
    width:100%; }
  .bp3-tag.bp3-minimal > .bp3-icon, .bp3-tag.bp3-minimal .bp3-icon-standard, .bp3-tag.bp3-minimal .bp3-icon-large{
    fill:#5c7080; }
  .bp3-tag.bp3-minimal:not([class*="bp3-intent-"]){
    background-color:rgba(138, 155, 168, 0.2);
    color:#182026; }
    .bp3-tag.bp3-minimal:not([class*="bp3-intent-"]).bp3-interactive{
      cursor:pointer; }
      .bp3-tag.bp3-minimal:not([class*="bp3-intent-"]).bp3-interactive:hover{
        background-color:rgba(92, 112, 128, 0.3); }
      .bp3-tag.bp3-minimal:not([class*="bp3-intent-"]).bp3-interactive.bp3-active, .bp3-tag.bp3-minimal:not([class*="bp3-intent-"]).bp3-interactive:active{
        background-color:rgba(92, 112, 128, 0.4); }
    .bp3-dark .bp3-tag.bp3-minimal:not([class*="bp3-intent-"]){
      color:#f5f8fa; }
      .bp3-dark .bp3-tag.bp3-minimal:not([class*="bp3-intent-"]).bp3-interactive{
        cursor:pointer; }
        .bp3-dark .bp3-tag.bp3-minimal:not([class*="bp3-intent-"]).bp3-interactive:hover{
          background-color:rgba(191, 204, 214, 0.3); }
        .bp3-dark .bp3-tag.bp3-minimal:not([class*="bp3-intent-"]).bp3-interactive.bp3-active, .bp3-dark .bp3-tag.bp3-minimal:not([class*="bp3-intent-"]).bp3-interactive:active{
          background-color:rgba(191, 204, 214, 0.4); }
      .bp3-dark .bp3-tag.bp3-minimal:not([class*="bp3-intent-"]) > .bp3-icon, .bp3-dark .bp3-tag.bp3-minimal:not([class*="bp3-intent-"]) .bp3-icon-standard, .bp3-dark .bp3-tag.bp3-minimal:not([class*="bp3-intent-"]) .bp3-icon-large{
        fill:#a7b6c2; }
  .bp3-tag.bp3-minimal.bp3-intent-primary{
    background-color:rgba(19, 124, 189, 0.15);
    color:#106ba3; }
    .bp3-tag.bp3-minimal.bp3-intent-primary.bp3-interactive{
      cursor:pointer; }
      .bp3-tag.bp3-minimal.bp3-intent-primary.bp3-interactive:hover{
        background-color:rgba(19, 124, 189, 0.25); }
      .bp3-tag.bp3-minimal.bp3-intent-primary.bp3-interactive.bp3-active, .bp3-tag.bp3-minimal.bp3-intent-primary.bp3-interactive:active{
        background-color:rgba(19, 124, 189, 0.35); }
    .bp3-tag.bp3-minimal.bp3-intent-primary > .bp3-icon, .bp3-tag.bp3-minimal.bp3-intent-primary .bp3-icon-standard, .bp3-tag.bp3-minimal.bp3-intent-primary .bp3-icon-large{
      fill:#137cbd; }
    .bp3-dark .bp3-tag.bp3-minimal.bp3-intent-primary{
      background-color:rgba(19, 124, 189, 0.25);
      color:#48aff0; }
      .bp3-dark .bp3-tag.bp3-minimal.bp3-intent-primary.bp3-interactive{
        cursor:pointer; }
        .bp3-dark .bp3-tag.bp3-minimal.bp3-intent-primary.bp3-interactive:hover{
          background-color:rgba(19, 124, 189, 0.35); }
        .bp3-dark .bp3-tag.bp3-minimal.bp3-intent-primary.bp3-interactive.bp3-active, .bp3-dark .bp3-tag.bp3-minimal.bp3-intent-primary.bp3-interactive:active{
          background-color:rgba(19, 124, 189, 0.45); }
  .bp3-tag.bp3-minimal.bp3-intent-success{
    background-color:rgba(15, 153, 96, 0.15);
    color:#0d8050; }
    .bp3-tag.bp3-minimal.bp3-intent-success.bp3-interactive{
      cursor:pointer; }
      .bp3-tag.bp3-minimal.bp3-intent-success.bp3-interactive:hover{
        background-color:rgba(15, 153, 96, 0.25); }
      .bp3-tag.bp3-minimal.bp3-intent-success.bp3-interactive.bp3-active, .bp3-tag.bp3-minimal.bp3-intent-success.bp3-interactive:active{
        background-color:rgba(15, 153, 96, 0.35); }
    .bp3-tag.bp3-minimal.bp3-intent-success > .bp3-icon, .bp3-tag.bp3-minimal.bp3-intent-success .bp3-icon-standard, .bp3-tag.bp3-minimal.bp3-intent-success .bp3-icon-large{
      fill:#0f9960; }
    .bp3-dark .bp3-tag.bp3-minimal.bp3-intent-success{
      background-color:rgba(15, 153, 96, 0.25);
      color:#3dcc91; }
      .bp3-dark .bp3-tag.bp3-minimal.bp3-intent-success.bp3-interactive{
        cursor:pointer; }
        .bp3-dark .bp3-tag.bp3-minimal.bp3-intent-success.bp3-interactive:hover{
          background-color:rgba(15, 153, 96, 0.35); }
        .bp3-dark .bp3-tag.bp3-minimal.bp3-intent-success.bp3-interactive.bp3-active, .bp3-dark .bp3-tag.bp3-minimal.bp3-intent-success.bp3-interactive:active{
          background-color:rgba(15, 153, 96, 0.45); }
  .bp3-tag.bp3-minimal.bp3-intent-warning{
    background-color:rgba(217, 130, 43, 0.15);
    color:#bf7326; }
    .bp3-tag.bp3-minimal.bp3-intent-warning.bp3-interactive{
      cursor:pointer; }
      .bp3-tag.bp3-minimal.bp3-intent-warning.bp3-interactive:hover{
        background-color:rgba(217, 130, 43, 0.25); }
      .bp3-tag.bp3-minimal.bp3-intent-warning.bp3-interactive.bp3-active, .bp3-tag.bp3-minimal.bp3-intent-warning.bp3-interactive:active{
        background-color:rgba(217, 130, 43, 0.35); }
    .bp3-tag.bp3-minimal.bp3-intent-warning > .bp3-icon, .bp3-tag.bp3-minimal.bp3-intent-warning .bp3-icon-standard, .bp3-tag.bp3-minimal.bp3-intent-warning .bp3-icon-large{
      fill:#d9822b; }
    .bp3-dark .bp3-tag.bp3-minimal.bp3-intent-warning{
      background-color:rgba(217, 130, 43, 0.25);
      color:#ffb366; }
      .bp3-dark .bp3-tag.bp3-minimal.bp3-intent-warning.bp3-interactive{
        cursor:pointer; }
        .bp3-dark .bp3-tag.bp3-minimal.bp3-intent-warning.bp3-interactive:hover{
          background-color:rgba(217, 130, 43, 0.35); }
        .bp3-dark .bp3-tag.bp3-minimal.bp3-intent-warning.bp3-interactive.bp3-active, .bp3-dark .bp3-tag.bp3-minimal.bp3-intent-warning.bp3-interactive:active{
          background-color:rgba(217, 130, 43, 0.45); }
  .bp3-tag.bp3-minimal.bp3-intent-danger{
    background-color:rgba(219, 55, 55, 0.15);
    color:#c23030; }
    .bp3-tag.bp3-minimal.bp3-intent-danger.bp3-interactive{
      cursor:pointer; }
      .bp3-tag.bp3-minimal.bp3-intent-danger.bp3-interactive:hover{
        background-color:rgba(219, 55, 55, 0.25); }
      .bp3-tag.bp3-minimal.bp3-intent-danger.bp3-interactive.bp3-active, .bp3-tag.bp3-minimal.bp3-intent-danger.bp3-interactive:active{
        background-color:rgba(219, 55, 55, 0.35); }
    .bp3-tag.bp3-minimal.bp3-intent-danger > .bp3-icon, .bp3-tag.bp3-minimal.bp3-intent-danger .bp3-icon-standard, .bp3-tag.bp3-minimal.bp3-intent-danger .bp3-icon-large{
      fill:#db3737; }
    .bp3-dark .bp3-tag.bp3-minimal.bp3-intent-danger{
      background-color:rgba(219, 55, 55, 0.25);
      color:#ff7373; }
      .bp3-dark .bp3-tag.bp3-minimal.bp3-intent-danger.bp3-interactive{
        cursor:pointer; }
        .bp3-dark .bp3-tag.bp3-minimal.bp3-intent-danger.bp3-interactive:hover{
          background-color:rgba(219, 55, 55, 0.35); }
        .bp3-dark .bp3-tag.bp3-minimal.bp3-intent-danger.bp3-interactive.bp3-active, .bp3-dark .bp3-tag.bp3-minimal.bp3-intent-danger.bp3-interactive:active{
          background-color:rgba(219, 55, 55, 0.45); }

.bp3-tag-remove{
  display:-webkit-box;
  display:-ms-flexbox;
  display:flex;
  opacity:0.5;
  margin-top:-2px;
  margin-right:-6px !important;
  margin-bottom:-2px;
  border:none;
  background:none;
  cursor:pointer;
  padding:2px;
  padding-left:0;
  color:inherit; }
  .bp3-tag-remove:hover{
    opacity:0.8;
    background:none;
    text-decoration:none; }
  .bp3-tag-remove:active{
    opacity:1; }
  .bp3-tag-remove:empty::before{
    line-height:1;
    font-family:"Icons16", sans-serif;
    font-size:16px;
    font-weight:400;
    font-style:normal;
    -moz-osx-font-smoothing:grayscale;
    -webkit-font-smoothing:antialiased;
    content:""; }
  .bp3-large .bp3-tag-remove{
    margin-right:-10px !important;
    padding:5px;
    padding-left:0; }
    .bp3-large .bp3-tag-remove:empty::before{
      line-height:1;
      font-family:"Icons20", sans-serif;
      font-size:20px;
      font-weight:400;
      font-style:normal; }
.bp3-tag-input{
  display:-webkit-box;
  display:-ms-flexbox;
  display:flex;
  -webkit-box-orient:horizontal;
  -webkit-box-direction:normal;
      -ms-flex-direction:row;
          flex-direction:row;
  -webkit-box-align:start;
      -ms-flex-align:start;
          align-items:flex-start;
  cursor:text;
  height:auto;
  min-height:30px;
  padding-right:0;
  padding-left:5px;
  line-height:inherit; }
  .bp3-tag-input > *{
    -webkit-box-flex:0;
        -ms-flex-positive:0;
            flex-grow:0;
    -ms-flex-negative:0;
        flex-shrink:0; }
  .bp3-tag-input > .bp3-tag-input-values{
    -webkit-box-flex:1;
        -ms-flex-positive:1;
            flex-grow:1;
    -ms-flex-negative:1;
        flex-shrink:1; }
  .bp3-tag-input .bp3-tag-input-icon{
    margin-top:7px;
    margin-right:7px;
    margin-left:2px;
    color:#5c7080; }
  .bp3-tag-input .bp3-tag-input-values{
    display:-webkit-box;
    display:-ms-flexbox;
    display:flex;
    -webkit-box-orient:horizontal;
    -webkit-box-direction:normal;
        -ms-flex-direction:row;
            flex-direction:row;
    -ms-flex-wrap:wrap;
        flex-wrap:wrap;
    -webkit-box-align:center;
        -ms-flex-align:center;
            align-items:center;
    -ms-flex-item-align:stretch;
        align-self:stretch;
    margin-top:5px;
    margin-right:7px;
    min-width:0; }
    .bp3-tag-input .bp3-tag-input-values > *{
      -webkit-box-flex:0;
          -ms-flex-positive:0;
              flex-grow:0;
      -ms-flex-negative:0;
          flex-shrink:0; }
    .bp3-tag-input .bp3-tag-input-values > .bp3-fill{
      -webkit-box-flex:1;
          -ms-flex-positive:1;
              flex-grow:1;
      -ms-flex-negative:1;
          flex-shrink:1; }
    .bp3-tag-input .bp3-tag-input-values::before,
    .bp3-tag-input .bp3-tag-input-values > *{
      margin-right:5px; }
    .bp3-tag-input .bp3-tag-input-values:empty::before,
    .bp3-tag-input .bp3-tag-input-values > :last-child{
      margin-right:0; }
    .bp3-tag-input .bp3-tag-input-values:first-child .bp3-input-ghost:first-child{
      padding-left:5px; }
    .bp3-tag-input .bp3-tag-input-values > *{
      margin-bottom:5px; }
  .bp3-tag-input .bp3-tag{
    overflow-wrap:break-word; }
    .bp3-tag-input .bp3-tag.bp3-active{
      outline:rgba(19, 124, 189, 0.6) auto 2px;
      outline-offset:0;
      -moz-outline-radius:6px; }
  .bp3-tag-input .bp3-input-ghost{
    -webkit-box-flex:1;
        -ms-flex:1 1 auto;
            flex:1 1 auto;
    width:80px;
    line-height:20px; }
    .bp3-tag-input .bp3-input-ghost:disabled, .bp3-tag-input .bp3-input-ghost.bp3-disabled{
      cursor:not-allowed; }
  .bp3-tag-input .bp3-button,
  .bp3-tag-input .bp3-spinner{
    margin:3px;
    margin-left:0; }
  .bp3-tag-input .bp3-button{
    min-width:24px;
    min-height:24px;
    padding:0 7px; }
  .bp3-tag-input.bp3-large{
    height:auto;
    min-height:40px; }
    .bp3-tag-input.bp3-large::before,
    .bp3-tag-input.bp3-large > *{
      margin-right:10px; }
    .bp3-tag-input.bp3-large:empty::before,
    .bp3-tag-input.bp3-large > :last-child{
      margin-right:0; }
    .bp3-tag-input.bp3-large .bp3-tag-input-icon{
      margin-top:10px;
      margin-left:5px; }
    .bp3-tag-input.bp3-large .bp3-input-ghost{
      line-height:30px; }
    .bp3-tag-input.bp3-large .bp3-button{
      min-width:30px;
      min-height:30px;
      padding:5px 10px;
      margin:5px;
      margin-left:0; }
    .bp3-tag-input.bp3-large .bp3-spinner{
      margin:8px;
      margin-left:0; }
  .bp3-tag-input.bp3-active{
    -webkit-box-shadow:0 0 0 1px #137cbd, 0 0 0 3px rgba(19, 124, 189, 0.3), inset 0 1px 1px rgba(16, 22, 26, 0.2);
            box-shadow:0 0 0 1px #137cbd, 0 0 0 3px rgba(19, 124, 189, 0.3), inset 0 1px 1px rgba(16, 22, 26, 0.2);
    background-color:#ffffff; }
    .bp3-tag-input.bp3-active.bp3-intent-primary{
      -webkit-box-shadow:0 0 0 1px #106ba3, 0 0 0 3px rgba(16, 107, 163, 0.3), inset 0 1px 1px rgba(16, 22, 26, 0.2);
              box-shadow:0 0 0 1px #106ba3, 0 0 0 3px rgba(16, 107, 163, 0.3), inset 0 1px 1px rgba(16, 22, 26, 0.2); }
    .bp3-tag-input.bp3-active.bp3-intent-success{
      -webkit-box-shadow:0 0 0 1px #0d8050, 0 0 0 3px rgba(13, 128, 80, 0.3), inset 0 1px 1px rgba(16, 22, 26, 0.2);
              box-shadow:0 0 0 1px #0d8050, 0 0 0 3px rgba(13, 128, 80, 0.3), inset 0 1px 1px rgba(16, 22, 26, 0.2); }
    .bp3-tag-input.bp3-active.bp3-intent-warning{
      -webkit-box-shadow:0 0 0 1px #bf7326, 0 0 0 3px rgba(191, 115, 38, 0.3), inset 0 1px 1px rgba(16, 22, 26, 0.2);
              box-shadow:0 0 0 1px #bf7326, 0 0 0 3px rgba(191, 115, 38, 0.3), inset 0 1px 1px rgba(16, 22, 26, 0.2); }
    .bp3-tag-input.bp3-active.bp3-intent-danger{
      -webkit-box-shadow:0 0 0 1px #c23030, 0 0 0 3px rgba(194, 48, 48, 0.3), inset 0 1px 1px rgba(16, 22, 26, 0.2);
              box-shadow:0 0 0 1px #c23030, 0 0 0 3px rgba(194, 48, 48, 0.3), inset 0 1px 1px rgba(16, 22, 26, 0.2); }
  .bp3-dark .bp3-tag-input .bp3-tag-input-icon, .bp3-tag-input.bp3-dark .bp3-tag-input-icon{
    color:#a7b6c2; }
  .bp3-dark .bp3-tag-input .bp3-input-ghost, .bp3-tag-input.bp3-dark .bp3-input-ghost{
    color:#f5f8fa; }
    .bp3-dark .bp3-tag-input .bp3-input-ghost::-webkit-input-placeholder, .bp3-tag-input.bp3-dark .bp3-input-ghost::-webkit-input-placeholder{
      color:rgba(167, 182, 194, 0.6); }
    .bp3-dark .bp3-tag-input .bp3-input-ghost::-moz-placeholder, .bp3-tag-input.bp3-dark .bp3-input-ghost::-moz-placeholder{
      color:rgba(167, 182, 194, 0.6); }
    .bp3-dark .bp3-tag-input .bp3-input-ghost:-ms-input-placeholder, .bp3-tag-input.bp3-dark .bp3-input-ghost:-ms-input-placeholder{
      color:rgba(167, 182, 194, 0.6); }
    .bp3-dark .bp3-tag-input .bp3-input-ghost::-ms-input-placeholder, .bp3-tag-input.bp3-dark .bp3-input-ghost::-ms-input-placeholder{
      color:rgba(167, 182, 194, 0.6); }
    .bp3-dark .bp3-tag-input .bp3-input-ghost::placeholder, .bp3-tag-input.bp3-dark .bp3-input-ghost::placeholder{
      color:rgba(167, 182, 194, 0.6); }
  .bp3-dark .bp3-tag-input.bp3-active, .bp3-tag-input.bp3-dark.bp3-active{
    -webkit-box-shadow:0 0 0 1px #137cbd, 0 0 0 1px #137cbd, 0 0 0 3px rgba(19, 124, 189, 0.3), inset 0 0 0 1px rgba(16, 22, 26, 0.3), inset 0 1px 1px rgba(16, 22, 26, 0.4);
            box-shadow:0 0 0 1px #137cbd, 0 0 0 1px #137cbd, 0 0 0 3px rgba(19, 124, 189, 0.3), inset 0 0 0 1px rgba(16, 22, 26, 0.3), inset 0 1px 1px rgba(16, 22, 26, 0.4);
    background-color:rgba(16, 22, 26, 0.3); }
    .bp3-dark .bp3-tag-input.bp3-active.bp3-intent-primary, .bp3-tag-input.bp3-dark.bp3-active.bp3-intent-primary{
      -webkit-box-shadow:0 0 0 1px #106ba3, 0 0 0 3px rgba(16, 107, 163, 0.3), inset 0 0 0 1px rgba(16, 22, 26, 0.3), inset 0 1px 1px rgba(16, 22, 26, 0.4);
              box-shadow:0 0 0 1px #106ba3, 0 0 0 3px rgba(16, 107, 163, 0.3), inset 0 0 0 1px rgba(16, 22, 26, 0.3), inset 0 1px 1px rgba(16, 22, 26, 0.4); }
    .bp3-dark .bp3-tag-input.bp3-active.bp3-intent-success, .bp3-tag-input.bp3-dark.bp3-active.bp3-intent-success{
      -webkit-box-shadow:0 0 0 1px #0d8050, 0 0 0 3px rgba(13, 128, 80, 0.3), inset 0 0 0 1px rgba(16, 22, 26, 0.3), inset 0 1px 1px rgba(16, 22, 26, 0.4);
              box-shadow:0 0 0 1px #0d8050, 0 0 0 3px rgba(13, 128, 80, 0.3), inset 0 0 0 1px rgba(16, 22, 26, 0.3), inset 0 1px 1px rgba(16, 22, 26, 0.4); }
    .bp3-dark .bp3-tag-input.bp3-active.bp3-intent-warning, .bp3-tag-input.bp3-dark.bp3-active.bp3-intent-warning{
      -webkit-box-shadow:0 0 0 1px #bf7326, 0 0 0 3px rgba(191, 115, 38, 0.3), inset 0 0 0 1px rgba(16, 22, 26, 0.3), inset 0 1px 1px rgba(16, 22, 26, 0.4);
              box-shadow:0 0 0 1px #bf7326, 0 0 0 3px rgba(191, 115, 38, 0.3), inset 0 0 0 1px rgba(16, 22, 26, 0.3), inset 0 1px 1px rgba(16, 22, 26, 0.4); }
    .bp3-dark .bp3-tag-input.bp3-active.bp3-intent-danger, .bp3-tag-input.bp3-dark.bp3-active.bp3-intent-danger{
      -webkit-box-shadow:0 0 0 1px #c23030, 0 0 0 3px rgba(194, 48, 48, 0.3), inset 0 0 0 1px rgba(16, 22, 26, 0.3), inset 0 1px 1px rgba(16, 22, 26, 0.4);
              box-shadow:0 0 0 1px #c23030, 0 0 0 3px rgba(194, 48, 48, 0.3), inset 0 0 0 1px rgba(16, 22, 26, 0.3), inset 0 1px 1px rgba(16, 22, 26, 0.4); }

.bp3-input-ghost{
  border:none;
  -webkit-box-shadow:none;
          box-shadow:none;
  background:none;
  padding:0; }
  .bp3-input-ghost::-webkit-input-placeholder{
    opacity:1;
    color:rgba(92, 112, 128, 0.6); }
  .bp3-input-ghost::-moz-placeholder{
    opacity:1;
    color:rgba(92, 112, 128, 0.6); }
  .bp3-input-ghost:-ms-input-placeholder{
    opacity:1;
    color:rgba(92, 112, 128, 0.6); }
  .bp3-input-ghost::-ms-input-placeholder{
    opacity:1;
    color:rgba(92, 112, 128, 0.6); }
  .bp3-input-ghost::placeholder{
    opacity:1;
    color:rgba(92, 112, 128, 0.6); }
  .bp3-input-ghost:focus{
    outline:none !important; }
.bp3-toast{
  display:-webkit-box;
  display:-ms-flexbox;
  display:flex;
  -webkit-box-align:start;
      -ms-flex-align:start;
          align-items:flex-start;
  position:relative !important;
  margin:20px 0 0;
  border-radius:3px;
  -webkit-box-shadow:0 0 0 1px rgba(16, 22, 26, 0.1), 0 2px 4px rgba(16, 22, 26, 0.2), 0 8px 24px rgba(16, 22, 26, 0.2);
          box-shadow:0 0 0 1px rgba(16, 22, 26, 0.1), 0 2px 4px rgba(16, 22, 26, 0.2), 0 8px 24px rgba(16, 22, 26, 0.2);
  background-color:#ffffff;
  min-width:300px;
  max-width:500px;
  pointer-events:all; }
  .bp3-toast.bp3-toast-enter, .bp3-toast.bp3-toast-appear{
    -webkit-transform:translateY(-40px);
            transform:translateY(-40px); }
  .bp3-toast.bp3-toast-enter-active, .bp3-toast.bp3-toast-appear-active{
    -webkit-transform:translateY(0);
            transform:translateY(0);
    -webkit-transition-property:-webkit-transform;
    transition-property:-webkit-transform;
    transition-property:transform;
    transition-property:transform, -webkit-transform;
    -webkit-transition-duration:300ms;
            transition-duration:300ms;
    -webkit-transition-timing-function:cubic-bezier(0.54, 1.12, 0.38, 1.11);
            transition-timing-function:cubic-bezier(0.54, 1.12, 0.38, 1.11);
    -webkit-transition-delay:0;
            transition-delay:0; }
  .bp3-toast.bp3-toast-enter ~ .bp3-toast, .bp3-toast.bp3-toast-appear ~ .bp3-toast{
    -webkit-transform:translateY(-40px);
            transform:translateY(-40px); }
  .bp3-toast.bp3-toast-enter-active ~ .bp3-toast, .bp3-toast.bp3-toast-appear-active ~ .bp3-toast{
    -webkit-transform:translateY(0);
            transform:translateY(0);
    -webkit-transition-property:-webkit-transform;
    transition-property:-webkit-transform;
    transition-property:transform;
    transition-property:transform, -webkit-transform;
    -webkit-transition-duration:300ms;
            transition-duration:300ms;
    -webkit-transition-timing-function:cubic-bezier(0.54, 1.12, 0.38, 1.11);
            transition-timing-function:cubic-bezier(0.54, 1.12, 0.38, 1.11);
    -webkit-transition-delay:0;
            transition-delay:0; }
  .bp3-toast.bp3-toast-exit{
    opacity:1;
    -webkit-filter:blur(0);
            filter:blur(0); }
  .bp3-toast.bp3-toast-exit-active{
    opacity:0;
    -webkit-filter:blur(10px);
            filter:blur(10px);
    -webkit-transition-property:opacity, -webkit-filter;
    transition-property:opacity, -webkit-filter;
    transition-property:opacity, filter;
    transition-property:opacity, filter, -webkit-filter;
    -webkit-transition-duration:300ms;
            transition-duration:300ms;
    -webkit-transition-timing-function:cubic-bezier(0.4, 1, 0.75, 0.9);
            transition-timing-function:cubic-bezier(0.4, 1, 0.75, 0.9);
    -webkit-transition-delay:0;
            transition-delay:0; }
  .bp3-toast.bp3-toast-exit ~ .bp3-toast{
    -webkit-transform:translateY(0);
            transform:translateY(0); }
  .bp3-toast.bp3-toast-exit-active ~ .bp3-toast{
    -webkit-transform:translateY(-40px);
            transform:translateY(-40px);
    -webkit-transition-property:-webkit-transform;
    transition-property:-webkit-transform;
    transition-property:transform;
    transition-property:transform, -webkit-transform;
    -webkit-transition-duration:100ms;
            transition-duration:100ms;
    -webkit-transition-timing-function:cubic-bezier(0.4, 1, 0.75, 0.9);
            transition-timing-function:cubic-bezier(0.4, 1, 0.75, 0.9);
    -webkit-transition-delay:50ms;
            transition-delay:50ms; }
  .bp3-toast .bp3-button-group{
    -webkit-box-flex:0;
        -ms-flex:0 0 auto;
            flex:0 0 auto;
    padding:5px;
    padding-left:0; }
  .bp3-toast > .bp3-icon{
    margin:12px;
    margin-right:0;
    color:#5c7080; }
  .bp3-toast.bp3-dark,
  .bp3-dark .bp3-toast{
    -webkit-box-shadow:0 0 0 1px rgba(16, 22, 26, 0.2), 0 2px 4px rgba(16, 22, 26, 0.4), 0 8px 24px rgba(16, 22, 26, 0.4);
            box-shadow:0 0 0 1px rgba(16, 22, 26, 0.2), 0 2px 4px rgba(16, 22, 26, 0.4), 0 8px 24px rgba(16, 22, 26, 0.4);
    background-color:#394b59; }
    .bp3-toast.bp3-dark > .bp3-icon,
    .bp3-dark .bp3-toast > .bp3-icon{
      color:#a7b6c2; }
  .bp3-toast[class*="bp3-intent-"] a{
    color:rgba(255, 255, 255, 0.7); }
    .bp3-toast[class*="bp3-intent-"] a:hover{
      color:#ffffff; }
  .bp3-toast[class*="bp3-intent-"] > .bp3-icon{
    color:#ffffff; }
  .bp3-toast[class*="bp3-intent-"] .bp3-button, .bp3-toast[class*="bp3-intent-"] .bp3-button::before,
  .bp3-toast[class*="bp3-intent-"] .bp3-button .bp3-icon, .bp3-toast[class*="bp3-intent-"] .bp3-button:active{
    color:rgba(255, 255, 255, 0.7) !important; }
  .bp3-toast[class*="bp3-intent-"] .bp3-button:focus{
    outline-color:rgba(255, 255, 255, 0.5); }
  .bp3-toast[class*="bp3-intent-"] .bp3-button:hover{
    background-color:rgba(255, 255, 255, 0.15) !important;
    color:#ffffff !important; }
  .bp3-toast[class*="bp3-intent-"] .bp3-button:active{
    background-color:rgba(255, 255, 255, 0.3) !important;
    color:#ffffff !important; }
  .bp3-toast[class*="bp3-intent-"] .bp3-button::after{
    background:rgba(255, 255, 255, 0.3) !important; }
  .bp3-toast.bp3-intent-primary{
    background-color:#137cbd;
    color:#ffffff; }
  .bp3-toast.bp3-intent-success{
    background-color:#0f9960;
    color:#ffffff; }
  .bp3-toast.bp3-intent-warning{
    background-color:#d9822b;
    color:#ffffff; }
  .bp3-toast.bp3-intent-danger{
    background-color:#db3737;
    color:#ffffff; }

.bp3-toast-message{
  -webkit-box-flex:1;
      -ms-flex:1 1 auto;
          flex:1 1 auto;
  padding:11px;
  word-break:break-word; }

.bp3-toast-container{
  display:-webkit-box !important;
  display:-ms-flexbox !important;
  display:flex !important;
  -webkit-box-orient:vertical;
  -webkit-box-direction:normal;
      -ms-flex-direction:column;
          flex-direction:column;
  -webkit-box-align:center;
      -ms-flex-align:center;
          align-items:center;
  position:fixed;
  right:0;
  left:0;
  z-index:40;
  overflow:hidden;
  padding:0 20px 20px;
  pointer-events:none; }
  .bp3-toast-container.bp3-toast-container-top{
    top:0;
    bottom:auto; }
  .bp3-toast-container.bp3-toast-container-bottom{
    -webkit-box-orient:vertical;
    -webkit-box-direction:reverse;
        -ms-flex-direction:column-reverse;
            flex-direction:column-reverse;
    top:auto;
    bottom:0; }
  .bp3-toast-container.bp3-toast-container-left{
    -webkit-box-align:start;
        -ms-flex-align:start;
            align-items:flex-start; }
  .bp3-toast-container.bp3-toast-container-right{
    -webkit-box-align:end;
        -ms-flex-align:end;
            align-items:flex-end; }

.bp3-toast-container-bottom .bp3-toast.bp3-toast-enter:not(.bp3-toast-enter-active),
.bp3-toast-container-bottom .bp3-toast.bp3-toast-enter:not(.bp3-toast-enter-active) ~ .bp3-toast, .bp3-toast-container-bottom .bp3-toast.bp3-toast-appear:not(.bp3-toast-appear-active),
.bp3-toast-container-bottom .bp3-toast.bp3-toast-appear:not(.bp3-toast-appear-active) ~ .bp3-toast,
.bp3-toast-container-bottom .bp3-toast.bp3-toast-leave-active ~ .bp3-toast{
  -webkit-transform:translateY(60px);
          transform:translateY(60px); }
.bp3-tooltip{
  -webkit-box-shadow:0 0 0 1px rgba(16, 22, 26, 0.1), 0 2px 4px rgba(16, 22, 26, 0.2), 0 8px 24px rgba(16, 22, 26, 0.2);
          box-shadow:0 0 0 1px rgba(16, 22, 26, 0.1), 0 2px 4px rgba(16, 22, 26, 0.2), 0 8px 24px rgba(16, 22, 26, 0.2);
  -webkit-transform:scale(1);
          transform:scale(1); }
  .bp3-tooltip .bp3-popover-arrow{
    position:absolute;
    width:22px;
    height:22px; }
    .bp3-tooltip .bp3-popover-arrow::before{
      margin:4px;
      width:14px;
      height:14px; }
  .bp3-tether-element-attached-bottom.bp3-tether-target-attached-top > .bp3-tooltip{
    margin-top:-11px;
    margin-bottom:11px; }
    .bp3-tether-element-attached-bottom.bp3-tether-target-attached-top > .bp3-tooltip > .bp3-popover-arrow{
      bottom:-8px; }
      .bp3-tether-element-attached-bottom.bp3-tether-target-attached-top > .bp3-tooltip > .bp3-popover-arrow svg{
        -webkit-transform:rotate(-90deg);
                transform:rotate(-90deg); }
  .bp3-tether-element-attached-left.bp3-tether-target-attached-right > .bp3-tooltip{
    margin-left:11px; }
    .bp3-tether-element-attached-left.bp3-tether-target-attached-right > .bp3-tooltip > .bp3-popover-arrow{
      left:-8px; }
      .bp3-tether-element-attached-left.bp3-tether-target-attached-right > .bp3-tooltip > .bp3-popover-arrow svg{
        -webkit-transform:rotate(0);
                transform:rotate(0); }
  .bp3-tether-element-attached-top.bp3-tether-target-attached-bottom > .bp3-tooltip{
    margin-top:11px; }
    .bp3-tether-element-attached-top.bp3-tether-target-attached-bottom > .bp3-tooltip > .bp3-popover-arrow{
      top:-8px; }
      .bp3-tether-element-attached-top.bp3-tether-target-attached-bottom > .bp3-tooltip > .bp3-popover-arrow svg{
        -webkit-transform:rotate(90deg);
                transform:rotate(90deg); }
  .bp3-tether-element-attached-right.bp3-tether-target-attached-left > .bp3-tooltip{
    margin-right:11px;
    margin-left:-11px; }
    .bp3-tether-element-attached-right.bp3-tether-target-attached-left > .bp3-tooltip > .bp3-popover-arrow{
      right:-8px; }
      .bp3-tether-element-attached-right.bp3-tether-target-attached-left > .bp3-tooltip > .bp3-popover-arrow svg{
        -webkit-transform:rotate(180deg);
                transform:rotate(180deg); }
  .bp3-tether-element-attached-middle > .bp3-tooltip > .bp3-popover-arrow{
    top:50%;
    -webkit-transform:translateY(-50%);
            transform:translateY(-50%); }
  .bp3-tether-element-attached-center > .bp3-tooltip > .bp3-popover-arrow{
    right:50%;
    -webkit-transform:translateX(50%);
            transform:translateX(50%); }
  .bp3-tether-element-attached-top.bp3-tether-target-attached-top > .bp3-tooltip > .bp3-popover-arrow{
    top:-0.22183px; }
  .bp3-tether-element-attached-right.bp3-tether-target-attached-right > .bp3-tooltip > .bp3-popover-arrow{
    right:-0.22183px; }
  .bp3-tether-element-attached-left.bp3-tether-target-attached-left > .bp3-tooltip > .bp3-popover-arrow{
    left:-0.22183px; }
  .bp3-tether-element-attached-bottom.bp3-tether-target-attached-bottom > .bp3-tooltip > .bp3-popover-arrow{
    bottom:-0.22183px; }
  .bp3-tether-element-attached-top.bp3-tether-element-attached-left > .bp3-tooltip{
    -webkit-transform-origin:top left;
            transform-origin:top left; }
  .bp3-tether-element-attached-top.bp3-tether-element-attached-center > .bp3-tooltip{
    -webkit-transform-origin:top center;
            transform-origin:top center; }
  .bp3-tether-element-attached-top.bp3-tether-element-attached-right > .bp3-tooltip{
    -webkit-transform-origin:top right;
            transform-origin:top right; }
  .bp3-tether-element-attached-middle.bp3-tether-element-attached-left > .bp3-tooltip{
    -webkit-transform-origin:center left;
            transform-origin:center left; }
  .bp3-tether-element-attached-middle.bp3-tether-element-attached-center > .bp3-tooltip{
    -webkit-transform-origin:center center;
            transform-origin:center center; }
  .bp3-tether-element-attached-middle.bp3-tether-element-attached-right > .bp3-tooltip{
    -webkit-transform-origin:center right;
            transform-origin:center right; }
  .bp3-tether-element-attached-bottom.bp3-tether-element-attached-left > .bp3-tooltip{
    -webkit-transform-origin:bottom left;
            transform-origin:bottom left; }
  .bp3-tether-element-attached-bottom.bp3-tether-element-attached-center > .bp3-tooltip{
    -webkit-transform-origin:bottom center;
            transform-origin:bottom center; }
  .bp3-tether-element-attached-bottom.bp3-tether-element-attached-right > .bp3-tooltip{
    -webkit-transform-origin:bottom right;
            transform-origin:bottom right; }
  .bp3-tooltip .bp3-popover-content{
    background:#394b59;
    color:#f5f8fa; }
  .bp3-tooltip .bp3-popover-arrow::before{
    -webkit-box-shadow:1px 1px 6px rgba(16, 22, 26, 0.2);
            box-shadow:1px 1px 6px rgba(16, 22, 26, 0.2); }
  .bp3-tooltip .bp3-popover-arrow-border{
    fill:#10161a;
    fill-opacity:0.1; }
  .bp3-tooltip .bp3-popover-arrow-fill{
    fill:#394b59; }
  .bp3-popover-enter > .bp3-tooltip, .bp3-popover-appear > .bp3-tooltip{
    -webkit-transform:scale(0.8);
            transform:scale(0.8); }
  .bp3-popover-enter-active > .bp3-tooltip, .bp3-popover-appear-active > .bp3-tooltip{
    -webkit-transform:scale(1);
            transform:scale(1);
    -webkit-transition-property:-webkit-transform;
    transition-property:-webkit-transform;
    transition-property:transform;
    transition-property:transform, -webkit-transform;
    -webkit-transition-duration:100ms;
            transition-duration:100ms;
    -webkit-transition-timing-function:cubic-bezier(0.4, 1, 0.75, 0.9);
            transition-timing-function:cubic-bezier(0.4, 1, 0.75, 0.9);
    -webkit-transition-delay:0;
            transition-delay:0; }
  .bp3-popover-exit > .bp3-tooltip{
    -webkit-transform:scale(1);
            transform:scale(1); }
  .bp3-popover-exit-active > .bp3-tooltip{
    -webkit-transform:scale(0.8);
            transform:scale(0.8);
    -webkit-transition-property:-webkit-transform;
    transition-property:-webkit-transform;
    transition-property:transform;
    transition-property:transform, -webkit-transform;
    -webkit-transition-duration:100ms;
            transition-duration:100ms;
    -webkit-transition-timing-function:cubic-bezier(0.4, 1, 0.75, 0.9);
            transition-timing-function:cubic-bezier(0.4, 1, 0.75, 0.9);
    -webkit-transition-delay:0;
            transition-delay:0; }
  .bp3-tooltip .bp3-popover-content{
    padding:10px 12px; }
  .bp3-tooltip.bp3-dark,
  .bp3-dark .bp3-tooltip{
    -webkit-box-shadow:0 0 0 1px rgba(16, 22, 26, 0.2), 0 2px 4px rgba(16, 22, 26, 0.4), 0 8px 24px rgba(16, 22, 26, 0.4);
            box-shadow:0 0 0 1px rgba(16, 22, 26, 0.2), 0 2px 4px rgba(16, 22, 26, 0.4), 0 8px 24px rgba(16, 22, 26, 0.4); }
    .bp3-tooltip.bp3-dark .bp3-popover-content,
    .bp3-dark .bp3-tooltip .bp3-popover-content{
      background:#e1e8ed;
      color:#394b59; }
    .bp3-tooltip.bp3-dark .bp3-popover-arrow::before,
    .bp3-dark .bp3-tooltip .bp3-popover-arrow::before{
      -webkit-box-shadow:1px 1px 6px rgba(16, 22, 26, 0.4);
              box-shadow:1px 1px 6px rgba(16, 22, 26, 0.4); }
    .bp3-tooltip.bp3-dark .bp3-popover-arrow-border,
    .bp3-dark .bp3-tooltip .bp3-popover-arrow-border{
      fill:#10161a;
      fill-opacity:0.2; }
    .bp3-tooltip.bp3-dark .bp3-popover-arrow-fill,
    .bp3-dark .bp3-tooltip .bp3-popover-arrow-fill{
      fill:#e1e8ed; }
  .bp3-tooltip.bp3-intent-primary .bp3-popover-content{
    background:#137cbd;
    color:#ffffff; }
  .bp3-tooltip.bp3-intent-primary .bp3-popover-arrow-fill{
    fill:#137cbd; }
  .bp3-tooltip.bp3-intent-success .bp3-popover-content{
    background:#0f9960;
    color:#ffffff; }
  .bp3-tooltip.bp3-intent-success .bp3-popover-arrow-fill{
    fill:#0f9960; }
  .bp3-tooltip.bp3-intent-warning .bp3-popover-content{
    background:#d9822b;
    color:#ffffff; }
  .bp3-tooltip.bp3-intent-warning .bp3-popover-arrow-fill{
    fill:#d9822b; }
  .bp3-tooltip.bp3-intent-danger .bp3-popover-content{
    background:#db3737;
    color:#ffffff; }
  .bp3-tooltip.bp3-intent-danger .bp3-popover-arrow-fill{
    fill:#db3737; }

.bp3-tooltip-indicator{
  border-bottom:dotted 1px;
  cursor:help; }
.bp3-tree .bp3-icon, .bp3-tree .bp3-icon-standard, .bp3-tree .bp3-icon-large{
  color:#5c7080; }
  .bp3-tree .bp3-icon.bp3-intent-primary, .bp3-tree .bp3-icon-standard.bp3-intent-primary, .bp3-tree .bp3-icon-large.bp3-intent-primary{
    color:#137cbd; }
  .bp3-tree .bp3-icon.bp3-intent-success, .bp3-tree .bp3-icon-standard.bp3-intent-success, .bp3-tree .bp3-icon-large.bp3-intent-success{
    color:#0f9960; }
  .bp3-tree .bp3-icon.bp3-intent-warning, .bp3-tree .bp3-icon-standard.bp3-intent-warning, .bp3-tree .bp3-icon-large.bp3-intent-warning{
    color:#d9822b; }
  .bp3-tree .bp3-icon.bp3-intent-danger, .bp3-tree .bp3-icon-standard.bp3-intent-danger, .bp3-tree .bp3-icon-large.bp3-intent-danger{
    color:#db3737; }

.bp3-tree-node-list{
  margin:0;
  padding-left:0;
  list-style:none; }

.bp3-tree-root{
  position:relative;
  background-color:transparent;
  cursor:default;
  padding-left:0; }

.bp3-tree-node-content-0{
  padding-left:0px; }

.bp3-tree-node-content-1{
  padding-left:23px; }

.bp3-tree-node-content-2{
  padding-left:46px; }

.bp3-tree-node-content-3{
  padding-left:69px; }

.bp3-tree-node-content-4{
  padding-left:92px; }

.bp3-tree-node-content-5{
  padding-left:115px; }

.bp3-tree-node-content-6{
  padding-left:138px; }

.bp3-tree-node-content-7{
  padding-left:161px; }

.bp3-tree-node-content-8{
  padding-left:184px; }

.bp3-tree-node-content-9{
  padding-left:207px; }

.bp3-tree-node-content-10{
  padding-left:230px; }

.bp3-tree-node-content-11{
  padding-left:253px; }

.bp3-tree-node-content-12{
  padding-left:276px; }

.bp3-tree-node-content-13{
  padding-left:299px; }

.bp3-tree-node-content-14{
  padding-left:322px; }

.bp3-tree-node-content-15{
  padding-left:345px; }

.bp3-tree-node-content-16{
  padding-left:368px; }

.bp3-tree-node-content-17{
  padding-left:391px; }

.bp3-tree-node-content-18{
  padding-left:414px; }

.bp3-tree-node-content-19{
  padding-left:437px; }

.bp3-tree-node-content-20{
  padding-left:460px; }

.bp3-tree-node-content{
  display:-webkit-box;
  display:-ms-flexbox;
  display:flex;
  -webkit-box-align:center;
      -ms-flex-align:center;
          align-items:center;
  width:100%;
  height:30px;
  padding-right:5px; }
  .bp3-tree-node-content:hover{
    background-color:rgba(191, 204, 214, 0.4); }

.bp3-tree-node-caret,
.bp3-tree-node-caret-none{
  min-width:30px; }

.bp3-tree-node-caret{
  color:#5c7080;
  -webkit-transform:rotate(0deg);
          transform:rotate(0deg);
  cursor:pointer;
  padding:7px;
  -webkit-transition:-webkit-transform 200ms cubic-bezier(0.4, 1, 0.75, 0.9);
  transition:-webkit-transform 200ms cubic-bezier(0.4, 1, 0.75, 0.9);
  transition:transform 200ms cubic-bezier(0.4, 1, 0.75, 0.9);
  transition:transform 200ms cubic-bezier(0.4, 1, 0.75, 0.9), -webkit-transform 200ms cubic-bezier(0.4, 1, 0.75, 0.9); }
  .bp3-tree-node-caret:hover{
    color:#182026; }
  .bp3-dark .bp3-tree-node-caret{
    color:#a7b6c2; }
    .bp3-dark .bp3-tree-node-caret:hover{
      color:#f5f8fa; }
  .bp3-tree-node-caret.bp3-tree-node-caret-open{
    -webkit-transform:rotate(90deg);
            transform:rotate(90deg); }
  .bp3-tree-node-caret.bp3-icon-standard::before{
    content:""; }

.bp3-tree-node-icon{
  position:relative;
  margin-right:7px; }

.bp3-tree-node-label{
  overflow:hidden;
  text-overflow:ellipsis;
  white-space:nowrap;
  word-wrap:normal;
  -webkit-box-flex:1;
      -ms-flex:1 1 auto;
          flex:1 1 auto;
  position:relative;
  -webkit-user-select:none;
     -moz-user-select:none;
      -ms-user-select:none;
          user-select:none; }
  .bp3-tree-node-label span{
    display:inline; }

.bp3-tree-node-secondary-label{
  padding:0 5px;
  -webkit-user-select:none;
     -moz-user-select:none;
      -ms-user-select:none;
          user-select:none; }
  .bp3-tree-node-secondary-label .bp3-popover-wrapper,
  .bp3-tree-node-secondary-label .bp3-popover-target{
    display:-webkit-box;
    display:-ms-flexbox;
    display:flex;
    -webkit-box-align:center;
        -ms-flex-align:center;
            align-items:center; }

.bp3-tree-node.bp3-disabled .bp3-tree-node-content{
  background-color:inherit;
  cursor:not-allowed;
  color:rgba(92, 112, 128, 0.6); }

.bp3-tree-node.bp3-disabled .bp3-tree-node-caret,
.bp3-tree-node.bp3-disabled .bp3-tree-node-icon{
  cursor:not-allowed;
  color:rgba(92, 112, 128, 0.6); }

.bp3-tree-node.bp3-tree-node-selected > .bp3-tree-node-content{
  background-color:#137cbd; }
  .bp3-tree-node.bp3-tree-node-selected > .bp3-tree-node-content,
  .bp3-tree-node.bp3-tree-node-selected > .bp3-tree-node-content .bp3-icon, .bp3-tree-node.bp3-tree-node-selected > .bp3-tree-node-content .bp3-icon-standard, .bp3-tree-node.bp3-tree-node-selected > .bp3-tree-node-content .bp3-icon-large{
    color:#ffffff; }
  .bp3-tree-node.bp3-tree-node-selected > .bp3-tree-node-content .bp3-tree-node-caret::before{
    color:rgba(255, 255, 255, 0.7); }
  .bp3-tree-node.bp3-tree-node-selected > .bp3-tree-node-content .bp3-tree-node-caret:hover::before{
    color:#ffffff; }

.bp3-dark .bp3-tree-node-content:hover{
  background-color:rgba(92, 112, 128, 0.3); }

.bp3-dark .bp3-tree .bp3-icon, .bp3-dark .bp3-tree .bp3-icon-standard, .bp3-dark .bp3-tree .bp3-icon-large{
  color:#a7b6c2; }
  .bp3-dark .bp3-tree .bp3-icon.bp3-intent-primary, .bp3-dark .bp3-tree .bp3-icon-standard.bp3-intent-primary, .bp3-dark .bp3-tree .bp3-icon-large.bp3-intent-primary{
    color:#137cbd; }
  .bp3-dark .bp3-tree .bp3-icon.bp3-intent-success, .bp3-dark .bp3-tree .bp3-icon-standard.bp3-intent-success, .bp3-dark .bp3-tree .bp3-icon-large.bp3-intent-success{
    color:#0f9960; }
  .bp3-dark .bp3-tree .bp3-icon.bp3-intent-warning, .bp3-dark .bp3-tree .bp3-icon-standard.bp3-intent-warning, .bp3-dark .bp3-tree .bp3-icon-large.bp3-intent-warning{
    color:#d9822b; }
  .bp3-dark .bp3-tree .bp3-icon.bp3-intent-danger, .bp3-dark .bp3-tree .bp3-icon-standard.bp3-intent-danger, .bp3-dark .bp3-tree .bp3-icon-large.bp3-intent-danger{
    color:#db3737; }

.bp3-dark .bp3-tree-node.bp3-tree-node-selected > .bp3-tree-node-content{
  background-color:#137cbd; }
/*!

Copyright 2017-present Palantir Technologies, Inc. All rights reserved.
Licensed under the Apache License, Version 2.0.

*/
.bp3-omnibar{
  -webkit-filter:blur(0);
          filter:blur(0);
  opacity:1;
  top:20vh;
  left:calc(50% - 250px);
  z-index:21;
  border-radius:3px;
  -webkit-box-shadow:0 0 0 1px rgba(16, 22, 26, 0.1), 0 4px 8px rgba(16, 22, 26, 0.2), 0 18px 46px 6px rgba(16, 22, 26, 0.2);
          box-shadow:0 0 0 1px rgba(16, 22, 26, 0.1), 0 4px 8px rgba(16, 22, 26, 0.2), 0 18px 46px 6px rgba(16, 22, 26, 0.2);
  background-color:#ffffff;
  width:500px; }
  .bp3-omnibar.bp3-overlay-enter, .bp3-omnibar.bp3-overlay-appear{
    -webkit-filter:blur(20px);
            filter:blur(20px);
    opacity:0.2; }
  .bp3-omnibar.bp3-overlay-enter-active, .bp3-omnibar.bp3-overlay-appear-active{
    -webkit-filter:blur(0);
            filter:blur(0);
    opacity:1;
    -webkit-transition-property:opacity, -webkit-filter;
    transition-property:opacity, -webkit-filter;
    transition-property:filter, opacity;
    transition-property:filter, opacity, -webkit-filter;
    -webkit-transition-duration:200ms;
            transition-duration:200ms;
    -webkit-transition-timing-function:cubic-bezier(0.4, 1, 0.75, 0.9);
            transition-timing-function:cubic-bezier(0.4, 1, 0.75, 0.9);
    -webkit-transition-delay:0;
            transition-delay:0; }
  .bp3-omnibar.bp3-overlay-exit{
    -webkit-filter:blur(0);
            filter:blur(0);
    opacity:1; }
  .bp3-omnibar.bp3-overlay-exit-active{
    -webkit-filter:blur(20px);
            filter:blur(20px);
    opacity:0.2;
    -webkit-transition-property:opacity, -webkit-filter;
    transition-property:opacity, -webkit-filter;
    transition-property:filter, opacity;
    transition-property:filter, opacity, -webkit-filter;
    -webkit-transition-duration:200ms;
            transition-duration:200ms;
    -webkit-transition-timing-function:cubic-bezier(0.4, 1, 0.75, 0.9);
            transition-timing-function:cubic-bezier(0.4, 1, 0.75, 0.9);
    -webkit-transition-delay:0;
            transition-delay:0; }
  .bp3-omnibar .bp3-input{
    border-radius:0;
    background-color:transparent; }
    .bp3-omnibar .bp3-input, .bp3-omnibar .bp3-input:focus{
      -webkit-box-shadow:none;
              box-shadow:none; }
  .bp3-omnibar .bp3-menu{
    border-radius:0;
    -webkit-box-shadow:inset 0 1px 0 rgba(16, 22, 26, 0.15);
            box-shadow:inset 0 1px 0 rgba(16, 22, 26, 0.15);
    background-color:transparent;
    max-height:calc(60vh - 40px);
    overflow:auto; }
    .bp3-omnibar .bp3-menu:empty{
      display:none; }
  .bp3-dark .bp3-omnibar, .bp3-omnibar.bp3-dark{
    -webkit-box-shadow:0 0 0 1px rgba(16, 22, 26, 0.2), 0 4px 8px rgba(16, 22, 26, 0.4), 0 18px 46px 6px rgba(16, 22, 26, 0.4);
            box-shadow:0 0 0 1px rgba(16, 22, 26, 0.2), 0 4px 8px rgba(16, 22, 26, 0.4), 0 18px 46px 6px rgba(16, 22, 26, 0.4);
    background-color:#30404d; }

.bp3-omnibar-overlay .bp3-overlay-backdrop{
  background-color:rgba(16, 22, 26, 0.2); }

.bp3-select-popover .bp3-popover-content{
  padding:5px; }

.bp3-select-popover .bp3-input-group{
  margin-bottom:0; }

.bp3-select-popover .bp3-menu{
  max-width:400px;
  max-height:300px;
  overflow:auto;
  padding:0; }
  .bp3-select-popover .bp3-menu:not(:first-child){
    padding-top:5px; }

.bp3-multi-select{
  min-width:150px; }

.bp3-multi-select-popover .bp3-menu{
  max-width:400px;
  max-height:300px;
  overflow:auto; }

.bp3-select-popover .bp3-popover-content{
  padding:5px; }

.bp3-select-popover .bp3-input-group{
  margin-bottom:0; }

.bp3-select-popover .bp3-menu{
  max-width:400px;
  max-height:300px;
  overflow:auto;
  padding:0; }
  .bp3-select-popover .bp3-menu:not(:first-child){
    padding-top:5px; }
/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

/* This file was auto-generated by ensureUiComponents() in @jupyterlab/buildutils */

/**
 * (DEPRECATED) Support for consuming icons as CSS background images
 */

/* Icons urls */

:root {
  --jp-icon-add: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDI0IDI0Ij4KICA8ZyBjbGFzcz0ianAtaWNvbjMiIGZpbGw9IiM2MTYxNjEiPgogICAgPHBhdGggZD0iTTE5IDEzaC02djZoLTJ2LTZINXYtMmg2VjVoMnY2aDZ2MnoiLz4KICA8L2c+Cjwvc3ZnPgo=);
  --jp-icon-bug: url(data:image/svg+xml;base64,PHN2ZyB2aWV3Qm94PSIwIDAgMjQgMjQiIHdpZHRoPSIxNiIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KICA8ZyBjbGFzcz0ianAtaWNvbjMiIGZpbGw9IiM2MTYxNjEiPgogICAgPHBhdGggZD0iTTIwIDhoLTIuODFjLS40NS0uNzgtMS4wNy0xLjQ1LTEuODItMS45NkwxNyA0LjQxIDE1LjU5IDNsLTIuMTcgMi4xN0MxMi45NiA1LjA2IDEyLjQ5IDUgMTIgNWMtLjQ5IDAtLjk2LjA2LTEuNDEuMTdMOC40MSAzIDcgNC40MWwxLjYyIDEuNjNDNy44OCA2LjU1IDcuMjYgNy4yMiA2LjgxIDhINHYyaDIuMDljLS4wNS4zMy0uMDkuNjYtLjA5IDF2MUg0djJoMnYxYzAgLjM0LjA0LjY3LjA5IDFINHYyaDIuODFjMS4wNCAxLjc5IDIuOTcgMyA1LjE5IDNzNC4xNS0xLjIxIDUuMTktM0gyMHYtMmgtMi4wOWMuMDUtLjMzLjA5LS42Ni4wOS0xdi0xaDJ2LTJoLTJ2LTFjMC0uMzQtLjA0LS42Ny0uMDktMUgyMFY4em0tNiA4aC00di0yaDR2MnptMC00aC00di0yaDR2MnoiLz4KICA8L2c+Cjwvc3ZnPgo=);
  --jp-icon-build: url(data:image/svg+xml;base64,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);
  --jp-icon-caret-down-empty-thin: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDIwIDIwIj4KCTxnIGNsYXNzPSJqcC1pY29uMyIgZmlsbD0iIzYxNjE2MSIgc2hhcGUtcmVuZGVyaW5nPSJnZW9tZXRyaWNQcmVjaXNpb24iPgoJCTxwb2x5Z29uIGNsYXNzPSJzdDEiIHBvaW50cz0iOS45LDEzLjYgMy42LDcuNCA0LjQsNi42IDkuOSwxMi4yIDE1LjQsNi43IDE2LjEsNy40ICIvPgoJPC9nPgo8L3N2Zz4K);
  --jp-icon-caret-down-empty: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDE4IDE4Ij4KICA8ZyBjbGFzcz0ianAtaWNvbjMiIGZpbGw9IiM2MTYxNjEiIHNoYXBlLXJlbmRlcmluZz0iZ2VvbWV0cmljUHJlY2lzaW9uIj4KICAgIDxwYXRoIGQ9Ik01LjIsNS45TDksOS43bDMuOC0zLjhsMS4yLDEuMmwtNC45LDVsLTQuOS01TDUuMiw1Ljl6Ii8+CiAgPC9nPgo8L3N2Zz4K);
  --jp-icon-caret-down: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDE4IDE4Ij4KICA8ZyBjbGFzcz0ianAtaWNvbjMiIGZpbGw9IiM2MTYxNjEiIHNoYXBlLXJlbmRlcmluZz0iZ2VvbWV0cmljUHJlY2lzaW9uIj4KICAgIDxwYXRoIGQ9Ik01LjIsNy41TDksMTEuMmwzLjgtMy44SDUuMnoiLz4KICA8L2c+Cjwvc3ZnPgo=);
  --jp-icon-caret-left: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDE4IDE4Ij4KCTxnIGNsYXNzPSJqcC1pY29uMyIgZmlsbD0iIzYxNjE2MSIgc2hhcGUtcmVuZGVyaW5nPSJnZW9tZXRyaWNQcmVjaXNpb24iPgoJCTxwYXRoIGQ9Ik0xMC44LDEyLjhMNy4xLDlsMy44LTMuOGwwLDcuNkgxMC44eiIvPgogIDwvZz4KPC9zdmc+Cg==);
  --jp-icon-caret-right: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDE4IDE4Ij4KICA8ZyBjbGFzcz0ianAtaWNvbjMiIGZpbGw9IiM2MTYxNjEiIHNoYXBlLXJlbmRlcmluZz0iZ2VvbWV0cmljUHJlY2lzaW9uIj4KICAgIDxwYXRoIGQ9Ik03LjIsNS4yTDEwLjksOWwtMy44LDMuOFY1LjJINy4yeiIvPgogIDwvZz4KPC9zdmc+Cg==);
  --jp-icon-caret-up-empty-thin: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDIwIDIwIj4KCTxnIGNsYXNzPSJqcC1pY29uMyIgZmlsbD0iIzYxNjE2MSIgc2hhcGUtcmVuZGVyaW5nPSJnZW9tZXRyaWNQcmVjaXNpb24iPgoJCTxwb2x5Z29uIGNsYXNzPSJzdDEiIHBvaW50cz0iMTUuNCwxMy4zIDkuOSw3LjcgNC40LDEzLjIgMy42LDEyLjUgOS45LDYuMyAxNi4xLDEyLjYgIi8+Cgk8L2c+Cjwvc3ZnPgo=);
  --jp-icon-caret-up: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDE4IDE4Ij4KCTxnIGNsYXNzPSJqcC1pY29uMyIgZmlsbD0iIzYxNjE2MSIgc2hhcGUtcmVuZGVyaW5nPSJnZW9tZXRyaWNQcmVjaXNpb24iPgoJCTxwYXRoIGQ9Ik01LjIsMTAuNUw5LDYuOGwzLjgsMy44SDUuMnoiLz4KICA8L2c+Cjwvc3ZnPgo=);
  --jp-icon-case-sensitive: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDIwIDIwIj4KICA8ZyBjbGFzcz0ianAtaWNvbjIiIGZpbGw9IiM0MTQxNDEiPgogICAgPHJlY3QgeD0iMiIgeT0iMiIgd2lkdGg9IjE2IiBoZWlnaHQ9IjE2Ii8+CiAgPC9nPgogIDxnIGNsYXNzPSJqcC1pY29uLWFjY2VudDIiIGZpbGw9IiNGRkYiPgogICAgPHBhdGggZD0iTTcuNiw4aDAuOWwzLjUsOGgtMS4xTDEwLDE0SDZsLTAuOSwySDRMNy42LDh6IE04LDkuMUw2LjQsMTNoMy4yTDgsOS4xeiIvPgogICAgPHBhdGggZD0iTTE2LjYsOS44Yy0wLjIsMC4xLTAuNCwwLjEtMC43LDAuMWMtMC4yLDAtMC40LTAuMS0wLjYtMC4yYy0wLjEtMC4xLTAuMi0wLjQtMC4yLTAuNyBjLTAuMywwLjMtMC42LDAuNS0wLjksMC43Yy0wLjMsMC4xLTAuNywwLjItMS4xLDAuMmMtMC4zLDAtMC41LDAtMC43LTAuMWMtMC4yLTAuMS0wLjQtMC4yLTAuNi0wLjNjLTAuMi0wLjEtMC4zLTAuMy0wLjQtMC41IGMtMC4xLTAuMi0wLjEtMC40LTAuMS0wLjdjMC0wLjMsMC4xLTAuNiwwLjItMC44YzAuMS0wLjIsMC4zLTAuNCwwLjQtMC41QzEyLDcsMTIuMiw2LjksMTIuNSw2LjhjMC4yLTAuMSwwLjUtMC4xLDAuNy0wLjIgYzAuMy0wLjEsMC41LTAuMSwwLjctMC4xYzAuMiwwLDAuNC0wLjEsMC42LTAuMWMwLjIsMCwwLjMtMC4xLDAuNC0wLjJjMC4xLTAuMSwwLjItMC4yLDAuMi0wLjRjMC0xLTEuMS0xLTEuMy0xIGMtMC40LDAtMS40LDAtMS40LDEuMmgtMC45YzAtMC40LDAuMS0wLjcsMC4yLTFjMC4xLTAuMiwwLjMtMC40LDAuNS0wLjZjMC4yLTAuMiwwLjUtMC4zLDAuOC0wLjNDMTMuMyw0LDEzLjYsNCwxMy45LDQgYzAuMywwLDAuNSwwLDAuOCwwLjFjMC4zLDAsMC41LDAuMSwwLjcsMC4yYzAuMiwwLjEsMC40LDAuMywwLjUsMC41QzE2LDUsMTYsNS4yLDE2LDUuNnYyLjljMCwwLjIsMCwwLjQsMCwwLjUgYzAsMC4xLDAuMSwwLjIsMC4zLDAuMmMwLjEsMCwwLjIsMCwwLjMsMFY5Ljh6IE0xNS4yLDYuOWMtMS4yLDAuNi0zLjEsMC4yLTMuMSwxLjRjMCwxLjQsMy4xLDEsMy4xLTAuNVY2Ljl6Ii8+CiAgPC9nPgo8L3N2Zz4K);
  --jp-icon-check: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDI0IDI0Ij4KICA8ZyBjbGFzcz0ianAtaWNvbjMiIGZpbGw9IiM2MTYxNjEiPgogICAgPHBhdGggZD0iTTkgMTYuMTdMNC44MyAxMmwtMS40MiAxLjQxTDkgMTkgMjEgN2wtMS40MS0xLjQxeiIvPgogIDwvZz4KPC9zdmc+Cg==);
  --jp-icon-circle-empty: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDI0IDI0Ij4KICA8ZyBjbGFzcz0ianAtaWNvbjMiIGZpbGw9IiM2MTYxNjEiPgogICAgPHBhdGggZD0iTTEyIDJDNi40NyAyIDIgNi40NyAyIDEyczQuNDcgMTAgMTAgMTAgMTAtNC40NyAxMC0xMFMxNy41MyAyIDEyIDJ6bTAgMThjLTQuNDEgMC04LTMuNTktOC04czMuNTktOCA4LTggOCAzLjU5IDggOC0zLjU5IDgtOCA4eiIvPgogIDwvZz4KPC9zdmc+Cg==);
  --jp-icon-circle: url(data:image/svg+xml;base64,PHN2ZyB2aWV3Qm94PSIwIDAgMTggMTgiIHdpZHRoPSIxNiIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KICA8ZyBjbGFzcz0ianAtaWNvbjMiIGZpbGw9IiM2MTYxNjEiPgogICAgPGNpcmNsZSBjeD0iOSIgY3k9IjkiIHI9IjgiLz4KICA8L2c+Cjwvc3ZnPgo=);
  --jp-icon-clear: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDI0IDI0Ij4KICA8bWFzayBpZD0iZG9udXRIb2xlIj4KICAgIDxyZWN0IHdpZHRoPSIyNCIgaGVpZ2h0PSIyNCIgZmlsbD0id2hpdGUiIC8+CiAgICA8Y2lyY2xlIGN4PSIxMiIgY3k9IjEyIiByPSI4IiBmaWxsPSJibGFjayIvPgogIDwvbWFzaz4KCiAgPGcgY2xhc3M9ImpwLWljb24zIiBmaWxsPSIjNjE2MTYxIj4KICAgIDxyZWN0IGhlaWdodD0iMTgiIHdpZHRoPSIyIiB4PSIxMSIgeT0iMyIgdHJhbnNmb3JtPSJyb3RhdGUoMzE1LCAxMiwgMTIpIi8+CiAgICA8Y2lyY2xlIGN4PSIxMiIgY3k9IjEyIiByPSIxMCIgbWFzaz0idXJsKCNkb251dEhvbGUpIi8+CiAgPC9nPgo8L3N2Zz4K);
  --jp-icon-close: url(data:image/svg+xml;base64,PHN2ZyB2aWV3Qm94PSIwIDAgMjQgMjQiIHdpZHRoPSIxNiIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KICA8ZyBjbGFzcz0ianAtaWNvbi1ub25lIGpwLWljb24tc2VsZWN0YWJsZS1pbnZlcnNlIGpwLWljb24zLWhvdmVyIiBmaWxsPSJub25lIj4KICAgIDxjaXJjbGUgY3g9IjEyIiBjeT0iMTIiIHI9IjExIi8+CiAgPC9nPgoKICA8ZyBjbGFzcz0ianAtaWNvbjMganAtaWNvbi1zZWxlY3RhYmxlIGpwLWljb24tYWNjZW50Mi1ob3ZlciIgZmlsbD0iIzYxNjE2MSI+CiAgICA8cGF0aCBkPSJNMTkgNi40MUwxNy41OSA1IDEyIDEwLjU5IDYuNDEgNSA1IDYuNDEgMTAuNTkgMTIgNSAxNy41OSA2LjQxIDE5IDEyIDEzLjQxIDE3LjU5IDE5IDE5IDE3LjU5IDEzLjQxIDEyeiIvPgogIDwvZz4KCiAgPGcgY2xhc3M9ImpwLWljb24tbm9uZSBqcC1pY29uLWJ1c3kiIGZpbGw9Im5vbmUiPgogICAgPGNpcmNsZSBjeD0iMTIiIGN5PSIxMiIgcj0iNyIvPgogIDwvZz4KPC9zdmc+Cg==);
  --jp-icon-console: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDIwMCAyMDAiPgogIDxnIGNsYXNzPSJqcC1pY29uLWJyYW5kMSBqcC1pY29uLXNlbGVjdGFibGUiIGZpbGw9IiMwMjg4RDEiPgogICAgPHBhdGggZD0iTTIwIDE5LjhoMTYwdjE1OS45SDIweiIvPgogIDwvZz4KICA8ZyBjbGFzcz0ianAtaWNvbi1zZWxlY3RhYmxlLWludmVyc2UiIGZpbGw9IiNmZmYiPgogICAgPHBhdGggZD0iTTEwNSAxMjcuM2g0MHYxMi44aC00MHpNNTEuMSA3N0w3NCA5OS45bC0yMy4zIDIzLjMgMTAuNSAxMC41IDIzLjMtMjMuM0w5NSA5OS45IDg0LjUgODkuNCA2MS42IDY2LjV6Ii8+CiAgPC9nPgo8L3N2Zz4K);
  --jp-icon-copy: url(data:image/svg+xml;base64,PHN2ZyB2aWV3Qm94PSIwIDAgMTggMTgiIHdpZHRoPSIxNiIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KICA8ZyBjbGFzcz0ianAtaWNvbjMiIGZpbGw9IiM2MTYxNjEiPgogICAgPHBhdGggZD0iTTExLjksMUgzLjJDMi40LDEsMS43LDEuNywxLjcsMi41djEwLjJoMS41VjIuNWg4LjdWMXogTTE0LjEsMy45aC04Yy0wLjgsMC0xLjUsMC43LTEuNSwxLjV2MTAuMmMwLDAuOCwwLjcsMS41LDEuNSwxLjVoOCBjMC44LDAsMS41LTAuNywxLjUtMS41VjUuNEMxNS41LDQuNiwxNC45LDMuOSwxNC4xLDMuOXogTTE0LjEsMTUuNWgtOFY1LjRoOFYxNS41eiIvPgogIDwvZz4KPC9zdmc+Cg==);
  --jp-icon-cut: url(data:image/svg+xml;base64,PHN2ZyB2aWV3Qm94PSIwIDAgMjQgMjQiIHdpZHRoPSIxNiIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KICA8ZyBjbGFzcz0ianAtaWNvbjMiIGZpbGw9IiM2MTYxNjEiPgogICAgPHBhdGggZD0iTTkuNjQgNy42NGMuMjMtLjUuMzYtMS4wNS4zNi0xLjY0IDAtMi4yMS0xLjc5LTQtNC00UzIgMy43OSAyIDZzMS43OSA0IDQgNGMuNTkgMCAxLjE0LS4xMyAxLjY0LS4zNkwxMCAxMmwtMi4zNiAyLjM2QzcuMTQgMTQuMTMgNi41OSAxNCA2IDE0Yy0yLjIxIDAtNCAxLjc5LTQgNHMxLjc5IDQgNCA0IDQtMS43OSA0LTRjMC0uNTktLjEzLTEuMTQtLjM2LTEuNjRMMTIgMTRsNyA3aDN2LTFMOS42NCA3LjY0ek02IDhjLTEuMSAwLTItLjg5LTItMnMuOS0yIDItMiAyIC44OSAyIDItLjkgMi0yIDJ6bTAgMTJjLTEuMSAwLTItLjg5LTItMnMuOS0yIDItMiAyIC44OSAyIDItLjkgMi0yIDJ6bTYtNy41Yy0uMjggMC0uNS0uMjItLjUtLjVzLjIyLS41LjUtLjUuNS4yMi41LjUtLjIyLjUtLjUuNXpNMTkgM2wtNiA2IDIgMiA3LTdWM3oiLz4KICA8L2c+Cjwvc3ZnPgo=);
  --jp-icon-download: url(data:image/svg+xml;base64,PHN2ZyB2aWV3Qm94PSIwIDAgMjQgMjQiIHdpZHRoPSIxNiIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KICA8ZyBjbGFzcz0ianAtaWNvbjMiIGZpbGw9IiM2MTYxNjEiPgogICAgPHBhdGggZD0iTTE5IDloLTRWM0g5djZINWw3IDcgNy03ek01IDE4djJoMTR2LTJINXoiLz4KICA8L2c+Cjwvc3ZnPgo=);
  --jp-icon-edit: url(data:image/svg+xml;base64,PHN2ZyB2aWV3Qm94PSIwIDAgMjQgMjQiIHdpZHRoPSIxNiIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KICA8ZyBjbGFzcz0ianAtaWNvbjMiIGZpbGw9IiM2MTYxNjEiPgogICAgPHBhdGggZD0iTTMgMTcuMjVWMjFoMy43NUwxNy44MSA5Ljk0bC0zLjc1LTMuNzVMMyAxNy4yNXpNMjAuNzEgNy4wNGMuMzktLjM5LjM5LTEuMDIgMC0xLjQxbC0yLjM0LTIuMzRjLS4zOS0uMzktMS4wMi0uMzktMS40MSAwbC0xLjgzIDEuODMgMy43NSAzLjc1IDEuODMtMS44M3oiLz4KICA8L2c+Cjwvc3ZnPgo=);
  --jp-icon-ellipses: url(data:image/svg+xml;base64,PHN2ZyB2aWV3Qm94PSIwIDAgMjQgMjQiIHdpZHRoPSIxNiIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KICA8ZyBjbGFzcz0ianAtaWNvbjMiIGZpbGw9IiM2MTYxNjEiPgogICAgPGNpcmNsZSBjeD0iNSIgY3k9IjEyIiByPSIyIi8+CiAgICA8Y2lyY2xlIGN4PSIxMiIgY3k9IjEyIiByPSIyIi8+CiAgICA8Y2lyY2xlIGN4PSIxOSIgY3k9IjEyIiByPSIyIi8+CiAgPC9nPgo8L3N2Zz4K);
  --jp-icon-extension: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDI0IDI0Ij4KICA8ZyBjbGFzcz0ianAtaWNvbjMiIGZpbGw9IiM2MTYxNjEiPgogICAgPHBhdGggZD0iTTIwLjUgMTFIMTlWN2MwLTEuMS0uOS0yLTItMmgtNFYzLjVDMTMgMi4xMiAxMS44OCAxIDEwLjUgMVM4IDIuMTIgOCAzLjVWNUg0Yy0xLjEgMC0xLjk5LjktMS45OSAydjMuOEgzLjVjMS40OSAwIDIuNyAxLjIxIDIuNyAyLjdzLTEuMjEgMi43LTIuNyAyLjdIMlYyMGMwIDEuMS45IDIgMiAyaDMuOHYtMS41YzAtMS40OSAxLjIxLTIuNyAyLjctMi43IDEuNDkgMCAyLjcgMS4yMSAyLjcgMi43VjIySDE3YzEuMSAwIDItLjkgMi0ydi00aDEuNWMxLjM4IDAgMi41LTEuMTIgMi41LTIuNVMyMS44OCAxMSAyMC41IDExeiIvPgogIDwvZz4KPC9zdmc+Cg==);
  --jp-icon-fast-forward: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIyNCIgaGVpZ2h0PSIyNCIgdmlld0JveD0iMCAwIDI0IDI0Ij4KICAgIDxnIGNsYXNzPSJqcC1pY29uMyIgZmlsbD0iIzYxNjE2MSI+CiAgICAgICAgPHBhdGggZD0iTTQgMThsOC41LTZMNCA2djEyem05LTEydjEybDguNS02TDEzIDZ6Ii8+CiAgICA8L2c+Cjwvc3ZnPgo=);
  --jp-icon-file-upload: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDI0IDI0Ij4KICA8ZyBjbGFzcz0ianAtaWNvbjMiIGZpbGw9IiM2MTYxNjEiPgogICAgPHBhdGggZD0iTTkgMTZoNnYtNmg0bC03LTctNyA3aDR6bS00IDJoMTR2Mkg1eiIvPgogIDwvZz4KPC9zdmc+Cg==);
  --jp-icon-file: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDIyIDIyIj4KICA8cGF0aCBjbGFzcz0ianAtaWNvbjMganAtaWNvbi1zZWxlY3RhYmxlIiBmaWxsPSIjNjE2MTYxIiBkPSJNMTkuMyA4LjJsLTUuNS01LjVjLS4zLS4zLS43LS41LTEuMi0uNUgzLjljLS44LjEtMS42LjktMS42IDEuOHYxNC4xYzAgLjkuNyAxLjYgMS42IDEuNmgxNC4yYy45IDAgMS42LS43IDEuNi0xLjZWOS40Yy4xLS41LS4xLS45LS40LTEuMnptLTUuOC0zLjNsMy40IDMuNmgtMy40VjQuOXptMy45IDEyLjdINC43Yy0uMSAwLS4yIDAtLjItLjJWNC43YzAtLjIuMS0uMy4yLS4zaDcuMnY0LjRzMCAuOC4zIDEuMWMuMy4zIDEuMS4zIDEuMS4zaDQuM3Y3LjJzLS4xLjItLjIuMnoiLz4KPC9zdmc+Cg==);
  --jp-icon-filter-list: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDI0IDI0Ij4KICA8ZyBjbGFzcz0ianAtaWNvbjMiIGZpbGw9IiM2MTYxNjEiPgogICAgPHBhdGggZD0iTTEwIDE4aDR2LTJoLTR2MnpNMyA2djJoMThWNkgzem0zIDdoMTJ2LTJINnYyeiIvPgogIDwvZz4KPC9zdmc+Cg==);
  --jp-icon-folder: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDI0IDI0Ij4KICA8cGF0aCBjbGFzcz0ianAtaWNvbjMganAtaWNvbi1zZWxlY3RhYmxlIiBmaWxsPSIjNjE2MTYxIiBkPSJNMTAgNEg0Yy0xLjEgMC0xLjk5LjktMS45OSAyTDIgMThjMCAxLjEuOSAyIDIgMmgxNmMxLjEgMCAyLS45IDItMlY4YzAtMS4xLS45LTItMi0yaC04bC0yLTJ6Ii8+Cjwvc3ZnPgo=);
  --jp-icon-html5: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDUxMiA1MTIiPgogIDxwYXRoIGNsYXNzPSJqcC1pY29uMCBqcC1pY29uLXNlbGVjdGFibGUiIGZpbGw9IiMwMDAiIGQ9Ik0xMDguNCAwaDIzdjIyLjhoMjEuMlYwaDIzdjY5aC0yM1Y0NmgtMjF2MjNoLTIzLjJNMjA2IDIzaC0yMC4zVjBoNjMuN3YyM0gyMjl2NDZoLTIzbTUzLjUtNjloMjQuMWwxNC44IDI0LjNMMzEzLjIgMGgyNC4xdjY5aC0yM1YzNC44bC0xNi4xIDI0LjgtMTYuMS0yNC44VjY5aC0yMi42bTg5LjItNjloMjN2NDYuMmgzMi42VjY5aC01NS42Ii8+CiAgPHBhdGggY2xhc3M9ImpwLWljb24tc2VsZWN0YWJsZSIgZmlsbD0iI2U0NGQyNiIgZD0iTTEwNy42IDQ3MWwtMzMtMzcwLjRoMzYyLjhsLTMzIDM3MC4yTDI1NS43IDUxMiIvPgogIDxwYXRoIGNsYXNzPSJqcC1pY29uLXNlbGVjdGFibGUiIGZpbGw9IiNmMTY1MjkiIGQ9Ik0yNTYgNDgwLjVWMTMxaDE0OC4zTDM3NiA0NDciLz4KICA8cGF0aCBjbGFzcz0ianAtaWNvbi1zZWxlY3RhYmxlLWludmVyc2UiIGZpbGw9IiNlYmViZWIiIGQ9Ik0xNDIgMTc2LjNoMTE0djQ1LjRoLTY0LjJsNC4yIDQ2LjVoNjB2NDUuM0gxNTQuNG0yIDIyLjhIMjAybDMuMiAzNi4zIDUwLjggMTMuNnY0Ny40bC05My4yLTI2Ii8+CiAgPHBhdGggY2xhc3M9ImpwLWljb24tc2VsZWN0YWJsZS1pbnZlcnNlIiBmaWxsPSIjZmZmIiBkPSJNMzY5LjYgMTc2LjNIMjU1Ljh2NDUuNGgxMDkuNm0tNC4xIDQ2LjVIMjU1Ljh2NDUuNGg1NmwtNS4zIDU5LTUwLjcgMTMuNnY0Ny4ybDkzLTI1LjgiLz4KPC9zdmc+Cg==);
  --jp-icon-image: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDIyIDIyIj4KICA8cGF0aCBjbGFzcz0ianAtaWNvbi1icmFuZDQganAtaWNvbi1zZWxlY3RhYmxlLWludmVyc2UiIGZpbGw9IiNGRkYiIGQ9Ik0yLjIgMi4yaDE3LjV2MTcuNUgyLjJ6Ii8+CiAgPHBhdGggY2xhc3M9ImpwLWljb24tYnJhbmQwIGpwLWljb24tc2VsZWN0YWJsZSIgZmlsbD0iIzNGNTFCNSIgZD0iTTIuMiAyLjJ2MTcuNWgxNy41bC4xLTE3LjVIMi4yem0xMi4xIDIuMmMxLjIgMCAyLjIgMSAyLjIgMi4ycy0xIDIuMi0yLjIgMi4yLTIuMi0xLTIuMi0yLjIgMS0yLjIgMi4yLTIuMnpNNC40IDE3LjZsMy4zLTguOCAzLjMgNi42IDIuMi0zLjIgNC40IDUuNEg0LjR6Ii8+Cjwvc3ZnPgo=);
  --jp-icon-inspector: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDI0IDI0Ij4KICA8cGF0aCBjbGFzcz0ianAtaWNvbjMganAtaWNvbi1zZWxlY3RhYmxlIiBmaWxsPSIjNjE2MTYxIiBkPSJNMjAgNEg0Yy0xLjEgMC0xLjk5LjktMS45OSAyTDIgMThjMCAxLjEuOSAyIDIgMmgxNmMxLjEgMCAyLS45IDItMlY2YzAtMS4xLS45LTItMi0yem0tNSAxNEg0di00aDExdjR6bTAtNUg0VjloMTF2NHptNSA1aC00VjloNHY5eiIvPgo8L3N2Zz4K);
  --jp-icon-json: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDIyIDIyIj4KICA8ZyBjbGFzcz0ianAtaWNvbi13YXJuMSBqcC1pY29uLXNlbGVjdGFibGUiIGZpbGw9IiNGOUE4MjUiPgogICAgPHBhdGggZD0iTTIwLjIgMTEuOGMtMS42IDAtMS43LjUtMS43IDEgMCAuNC4xLjkuMSAxLjMuMS41LjEuOS4xIDEuMyAwIDEuNy0xLjQgMi4zLTMuNSAyLjNoLS45di0xLjloLjVjMS4xIDAgMS40IDAgMS40LS44IDAtLjMgMC0uNi0uMS0xIDAtLjQtLjEtLjgtLjEtMS4yIDAtMS4zIDAtMS44IDEuMy0yLTEuMy0uMi0xLjMtLjctMS4zLTIgMC0uNC4xLS44LjEtMS4yLjEtLjQuMS0uNy4xLTEgMC0uOC0uNC0uNy0xLjQtLjhoLS41VjQuMWguOWMyLjIgMCAzLjUuNyAzLjUgMi4zIDAgLjQtLjEuOS0uMSAxLjMtLjEuNS0uMS45LS4xIDEuMyAwIC41LjIgMSAxLjcgMXYxLjh6TTEuOCAxMC4xYzEuNiAwIDEuNy0uNSAxLjctMSAwLS40LS4xLS45LS4xLTEuMy0uMS0uNS0uMS0uOS0uMS0xLjMgMC0xLjYgMS40LTIuMyAzLjUtMi4zaC45djEuOWgtLjVjLTEgMC0xLjQgMC0xLjQuOCAwIC4zIDAgLjYuMSAxIDAgLjIuMS42LjEgMSAwIDEuMyAwIDEuOC0xLjMgMkM2IDExLjIgNiAxMS43IDYgMTNjMCAuNC0uMS44LS4xIDEuMi0uMS4zLS4xLjctLjEgMSAwIC44LjMuOCAxLjQuOGguNXYxLjloLS45Yy0yLjEgMC0zLjUtLjYtMy41LTIuMyAwLS40LjEtLjkuMS0xLjMuMS0uNS4xLS45LjEtMS4zIDAtLjUtLjItMS0xLjctMXYtMS45eiIvPgogICAgPGNpcmNsZSBjeD0iMTEiIGN5PSIxMy44IiByPSIyLjEiLz4KICAgIDxjaXJjbGUgY3g9IjExIiBjeT0iOC4yIiByPSIyLjEiLz4KICA8L2c+Cjwvc3ZnPgo=);
  --jp-icon-jupyter-favicon: url(data:image/svg+xml;base64,PHN2ZyB3aWR0aD0iMTUyIiBoZWlnaHQ9IjE2NSIgdmlld0JveD0iMCAwIDE1MiAxNjUiIHZlcnNpb249IjEuMSIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KICA8ZyBjbGFzcz0ianAtaWNvbi13YXJuMCIgZmlsbD0iI0YzNzcyNiI+CiAgICA8cGF0aCB0cmFuc2Zvcm09InRyYW5zbGF0ZSgwLjA3ODk0NywgMTEwLjU4MjkyNykiIGQ9Ik03NS45NDIyODQyLDI5LjU4MDQ1NjEgQzQzLjMwMjM5NDcsMjkuNTgwNDU2MSAxNC43OTY3ODMyLDE3LjY1MzQ2MzQgMCwwIEM1LjUxMDgzMjExLDE1Ljg0MDY4MjkgMTUuNzgxNTM4OSwyOS41NjY3NzMyIDI5LjM5MDQ5NDcsMzkuMjc4NDE3MSBDNDIuOTk5Nyw0OC45ODk4NTM3IDU5LjI3MzcsNTQuMjA2NzgwNSA3NS45NjA1Nzg5LDU0LjIwNjc4MDUgQzkyLjY0NzQ1NzksNTQuMjA2NzgwNSAxMDguOTIxNDU4LDQ4Ljk4OTg1MzcgMTIyLjUzMDY2MywzOS4yNzg0MTcxIEMxMzYuMTM5NDUzLDI5LjU2Njc3MzIgMTQ2LjQxMDI4NCwxNS44NDA2ODI5IDE1MS45MjExNTgsMCBDMTM3LjA4Nzg2OCwxNy42NTM0NjM0IDEwOC41ODI1ODksMjkuNTgwNDU2MSA3NS45NDIyODQyLDI5LjU4MDQ1NjEgTDc1Ljk0MjI4NDIsMjkuNTgwNDU2MSBaIiAvPgogICAgPHBhdGggdHJhbnNmb3JtPSJ0cmFuc2xhdGUoMC4wMzczNjgsIDAuNzA0ODc4KSIgZD0iTTc1Ljk3ODQ1NzksMjQuNjI2NDA3MyBDMTA4LjYxODc2MywyNC42MjY0MDczIDEzNy4xMjQ0NTgsMzYuNTUzNDQxNSAxNTEuOTIxMTU4LDU0LjIwNjc4MDUgQzE0Ni40MTAyODQsMzguMzY2MjIyIDEzNi4xMzk0NTMsMjQuNjQwMTMxNyAxMjIuNTMwNjYzLDE0LjkyODQ4NzggQzEwOC45MjE0NTgsNS4yMTY4NDM5IDkyLjY0NzQ1NzksMCA3NS45NjA1Nzg5LDAgQzU5LjI3MzcsMCA0Mi45OTk3LDUuMjE2ODQzOSAyOS4zOTA0OTQ3LDE0LjkyODQ4NzggQzE1Ljc4MTUzODksMjQuNjQwMTMxNyA1LjUxMDgzMjExLDM4LjM2NjIyMiAwLDU0LjIwNjc4MDUgQzE0LjgzMzA4MTYsMzYuNTg5OTI5MyA0My4zMzg1Njg0LDI0LjYyNjQwNzMgNzUuOTc4NDU3OSwyNC42MjY0MDczIEw3NS45Nzg0NTc5LDI0LjYyNjQwNzMgWiIgLz4KICA8L2c+Cjwvc3ZnPgo=);
  --jp-icon-jupyter: url(data:image/svg+xml;base64,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);
  --jp-icon-jupyterlab-wordmark: url(data:image/svg+xml;base64,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);
  --jp-icon-kernel: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDI0IDI0Ij4KICAgIDxwYXRoIGNsYXNzPSJqcC1pY29uMiIgZmlsbD0iIzYxNjE2MSIgZD0iTTE1IDlIOXY2aDZWOXptLTIgNGgtMnYtMmgydjJ6bTgtMlY5aC0yVjdjMC0xLjEtLjktMi0yLTJoLTJWM2gtMnYyaC0yVjNIOXYySDdjLTEuMSAwLTIgLjktMiAydjJIM3YyaDJ2MkgzdjJoMnYyYzAgMS4xLjkgMiAyIDJoMnYyaDJ2LTJoMnYyaDJ2LTJoMmMxLjEgMCAyLS45IDItMnYtMmgydi0yaC0ydi0yaDJ6bS00IDZIN1Y3aDEwdjEweiIvPgo8L3N2Zz4K);
  --jp-icon-keyboard: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDI0IDI0Ij4KICA8cGF0aCBjbGFzcz0ianAtaWNvbjMganAtaWNvbi1zZWxlY3RhYmxlIiBmaWxsPSIjNjE2MTYxIiBkPSJNMjAgNUg0Yy0xLjEgMC0xLjk5LjktMS45OSAyTDIgMTdjMCAxLjEuOSAyIDIgMmgxNmMxLjEgMCAyLS45IDItMlY3YzAtMS4xLS45LTItMi0yem0tOSAzaDJ2MmgtMlY4em0wIDNoMnYyaC0ydi0yek04IDhoMnYySDhWOHptMCAzaDJ2Mkg4di0yem0tMSAySDV2LTJoMnYyem0wLTNINVY4aDJ2MnptOSA3SDh2LTJoOHYyem0wLTRoLTJ2LTJoMnYyem0wLTNoLTJWOGgydjJ6bTMgM2gtMnYtMmgydjJ6bTAtM2gtMlY4aDJ2MnoiLz4KPC9zdmc+Cg==);
  --jp-icon-launcher: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDI0IDI0Ij4KICA8cGF0aCBjbGFzcz0ianAtaWNvbjMganAtaWNvbi1zZWxlY3RhYmxlIiBmaWxsPSIjNjE2MTYxIiBkPSJNMTkgMTlINVY1aDdWM0g1YTIgMiAwIDAwLTIgMnYxNGEyIDIgMCAwMDIgMmgxNGMxLjEgMCAyLS45IDItMnYtN2gtMnY3ek0xNCAzdjJoMy41OWwtOS44MyA5LjgzIDEuNDEgMS40MUwxOSA2LjQxVjEwaDJWM2gtN3oiLz4KPC9zdmc+Cg==);
  --jp-icon-line-form: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDI0IDI0Ij4KICAgIDxwYXRoIGZpbGw9IndoaXRlIiBkPSJNNS44OCA0LjEyTDEzLjc2IDEybC03Ljg4IDcuODhMOCAyMmwxMC0xMEw4IDJ6Ii8+Cjwvc3ZnPgo=);
  --jp-icon-link: url(data:image/svg+xml;base64,PHN2ZyB2aWV3Qm94PSIwIDAgMjQgMjQiIHdpZHRoPSIxNiIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KICA8ZyBjbGFzcz0ianAtaWNvbjMiIGZpbGw9IiM2MTYxNjEiPgogICAgPHBhdGggZD0iTTMuOSAxMmMwLTEuNzEgMS4zOS0zLjEgMy4xLTMuMWg0VjdIN2MtMi43NiAwLTUgMi4yNC01IDVzMi4yNCA1IDUgNWg0di0xLjlIN2MtMS43MSAwLTMuMS0xLjM5LTMuMS0zLjF6TTggMTNoOHYtMkg4djJ6bTktNmgtNHYxLjloNGMxLjcxIDAgMy4xIDEuMzkgMy4xIDMuMXMtMS4zOSAzLjEtMy4xIDMuMWgtNFYxN2g0YzIuNzYgMCA1LTIuMjQgNS01cy0yLjI0LTUtNS01eiIvPgogIDwvZz4KPC9zdmc+Cg==);
  --jp-icon-list: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDI0IDI0Ij4KICAgIDxwYXRoIGNsYXNzPSJqcC1pY29uMiBqcC1pY29uLXNlbGVjdGFibGUiIGZpbGw9IiM2MTYxNjEiIGQ9Ik0xOSA1djE0SDVWNWgxNG0xLjEtMkgzLjljLS41IDAtLjkuNC0uOS45djE2LjJjMCAuNC40LjkuOS45aDE2LjJjLjQgMCAuOS0uNS45LS45VjMuOWMwLS41LS41LS45LS45LS45ek0xMSA3aDZ2MmgtNlY3em0wIDRoNnYyaC02di0yem0wIDRoNnYyaC02ek03IDdoMnYySDd6bTAgNGgydjJIN3ptMCA0aDJ2Mkg3eiIvPgo8L3N2Zz4=);
  --jp-icon-listings-info: url(data:image/svg+xml;base64,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);
  --jp-icon-markdown: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDIyIDIyIj4KICA8cGF0aCBjbGFzcz0ianAtaWNvbi1jb250cmFzdDAganAtaWNvbi1zZWxlY3RhYmxlIiBmaWxsPSIjN0IxRkEyIiBkPSJNNSAxNC45aDEybC02LjEgNnptOS40LTYuOGMwLTEuMy0uMS0yLjktLjEtNC41LS40IDEuNC0uOSAyLjktMS4zIDQuM2wtMS4zIDQuM2gtMkw4LjUgNy45Yy0uNC0xLjMtLjctMi45LTEtNC4zLS4xIDEuNi0uMSAzLjItLjIgNC42TDcgMTIuNEg0LjhsLjctMTFoMy4zTDEwIDVjLjQgMS4yLjcgMi43IDEgMy45LjMtMS4yLjctMi42IDEtMy45bDEuMi0zLjdoMy4zbC42IDExaC0yLjRsLS4zLTQuMnoiLz4KPC9zdmc+Cg==);
  --jp-icon-new-folder: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDI0IDI0Ij4KICA8ZyBjbGFzcz0ianAtaWNvbjMiIGZpbGw9IiM2MTYxNjEiPgogICAgPHBhdGggZD0iTTIwIDZoLThsLTItMkg0Yy0xLjExIDAtMS45OS44OS0xLjk5IDJMMiAxOGMwIDEuMTEuODkgMiAyIDJoMTZjMS4xMSAwIDItLjg5IDItMlY4YzAtMS4xMS0uODktMi0yLTJ6bS0xIDhoLTN2M2gtMnYtM2gtM3YtMmgzVjloMnYzaDN2MnoiLz4KICA8L2c+Cjwvc3ZnPgo=);
  --jp-icon-not-trusted: url(data:image/svg+xml;base64,PHN2ZyBmaWxsPSJub25lIiB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDI1IDI1Ij4KICAgIDxwYXRoIGNsYXNzPSJqcC1pY29uMiIgc3Ryb2tlPSIjMzMzMzMzIiBzdHJva2Utd2lkdGg9IjIiIHRyYW5zZm9ybT0idHJhbnNsYXRlKDMgMykiIGQ9Ik0xLjg2MDk0IDExLjQ0MDlDMC44MjY0NDggOC43NzAyNyAwLjg2Mzc3OSA2LjA1NzY0IDEuMjQ5MDcgNC4xOTkzMkMyLjQ4MjA2IDMuOTMzNDcgNC4wODA2OCAzLjQwMzQ3IDUuNjAxMDIgMi44NDQ5QzcuMjM1NDkgMi4yNDQ0IDguODU2NjYgMS41ODE1IDkuOTg3NiAxLjA5NTM5QzExLjA1OTcgMS41ODM0MSAxMi42MDk0IDIuMjQ0NCAxNC4yMTggMi44NDMzOUMxNS43NTAzIDMuNDEzOTQgMTcuMzk5NSAzLjk1MjU4IDE4Ljc1MzkgNC4yMTM4NUMxOS4xMzY0IDYuMDcxNzcgMTkuMTcwOSA4Ljc3NzIyIDE4LjEzOSAxMS40NDA5QzE3LjAzMDMgMTQuMzAzMiAxNC42NjY4IDE3LjE4NDQgOS45OTk5OSAxOC45MzU0QzUuMzMzMTkgMTcuMTg0NCAyLjk2OTY4IDE0LjMwMzIgMS44NjA5NCAxMS40NDA5WiIvPgogICAgPHBhdGggY2xhc3M9ImpwLWljb24yIiBzdHJva2U9IiMzMzMzMzMiIHN0cm9rZS13aWR0aD0iMiIgdHJhbnNmb3JtPSJ0cmFuc2xhdGUoOS4zMTU5MiA5LjMyMDMxKSIgZD0iTTcuMzY4NDIgMEwwIDcuMzY0NzkiLz4KICAgIDxwYXRoIGNsYXNzPSJqcC1pY29uMiIgc3Ryb2tlPSIjMzMzMzMzIiBzdHJva2Utd2lkdGg9IjIiIHRyYW5zZm9ybT0idHJhbnNsYXRlKDkuMzE1OTIgMTYuNjgzNikgc2NhbGUoMSAtMSkiIGQ9Ik03LjM2ODQyIDBMMCA3LjM2NDc5Ii8+Cjwvc3ZnPgo=);
  --jp-icon-notebook: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDIyIDIyIj4KICA8ZyBjbGFzcz0ianAtaWNvbi13YXJuMCBqcC1pY29uLXNlbGVjdGFibGUiIGZpbGw9IiNFRjZDMDAiPgogICAgPHBhdGggZD0iTTE4LjcgMy4zdjE1LjRIMy4zVjMuM2gxNS40bTEuNS0xLjVIMS44djE4LjNoMTguM2wuMS0xOC4zeiIvPgogICAgPHBhdGggZD0iTTE2LjUgMTYuNWwtNS40LTQuMy01LjYgNC4zdi0xMWgxMXoiLz4KICA8L2c+Cjwvc3ZnPgo=);
  --jp-icon-palette: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDI0IDI0Ij4KICA8ZyBjbGFzcz0ianAtaWNvbjMiIGZpbGw9IiM2MTYxNjEiPgogICAgPHBhdGggZD0iTTE4IDEzVjIwSDRWNkg5LjAyQzkuMDcgNS4yOSA5LjI0IDQuNjIgOS41IDRINEMyLjkgNCAyIDQuOSAyIDZWMjBDMiAyMS4xIDIuOSAyMiA0IDIySDE4QzE5LjEgMjIgMjAgMjEuMSAyMCAyMFYxNUwxOCAxM1pNMTkuMyA4Ljg5QzE5Ljc0IDguMTkgMjAgNy4zOCAyMCA2LjVDMjAgNC4wMSAxNy45OSAyIDE1LjUgMkMxMy4wMSAyIDExIDQuMDEgMTEgNi41QzExIDguOTkgMTMuMDEgMTEgMTUuNDkgMTFDMTYuMzcgMTEgMTcuMTkgMTAuNzQgMTcuODggMTAuM0wyMSAxMy40MkwyMi40MiAxMkwxOS4zIDguODlaTTE1LjUgOUMxNC4xMiA5IDEzIDcuODggMTMgNi41QzEzIDUuMTIgMTQuMTIgNCAxNS41IDRDMTYuODggNCAxOCA1LjEyIDE4IDYuNUMxOCA3Ljg4IDE2Ljg4IDkgMTUuNSA5WiIvPgogICAgPHBhdGggZmlsbC1ydWxlPSJldmVub2RkIiBjbGlwLXJ1bGU9ImV2ZW5vZGQiIGQ9Ik00IDZIOS4wMTg5NEM5LjAwNjM5IDYuMTY1MDIgOSA2LjMzMTc2IDkgNi41QzkgOC44MTU3NyAxMC4yMTEgMTAuODQ4NyAxMi4wMzQzIDEySDlWMTRIMTZWMTIuOTgxMUMxNi41NzAzIDEyLjkzNzcgMTcuMTIgMTIuODIwNyAxNy42Mzk2IDEyLjYzOTZMMTggMTNWMjBINFY2Wk04IDhINlYxMEg4VjhaTTYgMTJIOFYxNEg2VjEyWk04IDE2SDZWMThIOFYxNlpNOSAxNkgxNlYxOEg5VjE2WiIvPgogIDwvZz4KPC9zdmc+Cg==);
  --jp-icon-paste: url(data:image/svg+xml;base64,PHN2ZyBoZWlnaHQ9IjI0IiB2aWV3Qm94PSIwIDAgMjQgMjQiIHdpZHRoPSIyNCIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KICAgIDxnIGNsYXNzPSJqcC1pY29uMyIgZmlsbD0iIzYxNjE2MSI+CiAgICAgICAgPHBhdGggZD0iTTE5IDJoLTQuMThDMTQuNC44NCAxMy4zIDAgMTIgMGMtMS4zIDAtMi40Ljg0LTIuODIgMkg1Yy0xLjEgMC0yIC45LTIgMnYxNmMwIDEuMS45IDIgMiAyaDE0YzEuMSAwIDItLjkgMi0yVjRjMC0xLjEtLjktMi0yLTJ6bS03IDBjLjU1IDAgMSAuNDUgMSAxcy0uNDUgMS0xIDEtMS0uNDUtMS0xIC40NS0xIDEtMXptNyAxOEg1VjRoMnYzaDEwVjRoMnYxNnoiLz4KICAgIDwvZz4KPC9zdmc+Cg==);
  --jp-icon-python: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDIyIDIyIj4KICA8ZyBjbGFzcz0ianAtaWNvbi1icmFuZDAganAtaWNvbi1zZWxlY3RhYmxlIiBmaWxsPSIjMEQ0N0ExIj4KICAgIDxwYXRoIGQ9Ik0xMS4xIDYuOVY1LjhINi45YzAtLjUgMC0xLjMuMi0xLjYuNC0uNy44LTEuMSAxLjctMS40IDEuNy0uMyAyLjUtLjMgMy45LS4xIDEgLjEgMS45LjkgMS45IDEuOXY0LjJjMCAuNS0uOSAxLjYtMiAxLjZIOC44Yy0xLjUgMC0yLjQgMS40LTIuNCAyLjh2Mi4ySDQuN0MzLjUgMTUuMSAzIDE0IDMgMTMuMVY5Yy0uMS0xIC42LTIgMS44LTIgMS41LS4xIDYuMy0uMSA2LjMtLjF6Ii8+CiAgICA8cGF0aCBkPSJNMTAuOSAxNS4xdjEuMWg0LjJjMCAuNSAwIDEuMy0uMiAxLjYtLjQuNy0uOCAxLjEtMS43IDEuNC0xLjcuMy0yLjUuMy0zLjkuMS0xLS4xLTEuOS0uOS0xLjktMS45di00LjJjMC0uNS45LTEuNiAyLTEuNmgzLjhjMS41IDAgMi40LTEuNCAyLjQtMi44VjYuNmgxLjdDMTguNSA2LjkgMTkgOCAxOSA4LjlWMTNjMCAxLS43IDIuMS0xLjkgMi4xaC02LjJ6Ii8+CiAgPC9nPgo8L3N2Zz4K);
  --jp-icon-r-kernel: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDIyIDIyIj4KICA8cGF0aCBjbGFzcz0ianAtaWNvbi1jb250cmFzdDMganAtaWNvbi1zZWxlY3RhYmxlIiBmaWxsPSIjMjE5NkYzIiBkPSJNNC40IDIuNWMxLjItLjEgMi45LS4zIDQuOS0uMyAyLjUgMCA0LjEuNCA1LjIgMS4zIDEgLjcgMS41IDEuOSAxLjUgMy41IDAgMi0xLjQgMy41LTIuOSA0LjEgMS4yLjQgMS43IDEuNiAyLjIgMyAuNiAxLjkgMSAzLjkgMS4zIDQuNmgtMy44Yy0uMy0uNC0uOC0xLjctMS4yLTMuN3MtMS4yLTIuNi0yLjYtMi42aC0uOXY2LjRINC40VjIuNXptMy43IDYuOWgxLjRjMS45IDAgMi45LS45IDIuOS0yLjNzLTEtMi4zLTIuOC0yLjNjLS43IDAtMS4zIDAtMS42LjJ2NC41aC4xdi0uMXoiLz4KPC9zdmc+Cg==);
  --jp-icon-react: url(data:image/svg+xml;base64,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);
  --jp-icon-refresh: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDE4IDE4Ij4KICAgIDxnIGNsYXNzPSJqcC1pY29uMyIgZmlsbD0iIzYxNjE2MSI+CiAgICAgICAgPHBhdGggZD0iTTkgMTMuNWMtMi40OSAwLTQuNS0yLjAxLTQuNS00LjVTNi41MSA0LjUgOSA0LjVjMS4yNCAwIDIuMzYuNTIgMy4xNyAxLjMzTDEwIDhoNVYzbC0xLjc2IDEuNzZDMTIuMTUgMy42OCAxMC42NiAzIDkgMyA1LjY5IDMgMy4wMSA1LjY5IDMuMDEgOVM1LjY5IDE1IDkgMTVjMi45NyAwIDUuNDMtMi4xNiA1LjktNWgtMS41MmMtLjQ2IDItMi4yNCAzLjUtNC4zOCAzLjV6Ii8+CiAgICA8L2c+Cjwvc3ZnPgo=);
  --jp-icon-regex: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDIwIDIwIj4KICA8ZyBjbGFzcz0ianAtaWNvbjIiIGZpbGw9IiM0MTQxNDEiPgogICAgPHJlY3QgeD0iMiIgeT0iMiIgd2lkdGg9IjE2IiBoZWlnaHQ9IjE2Ii8+CiAgPC9nPgoKICA8ZyBjbGFzcz0ianAtaWNvbi1hY2NlbnQyIiBmaWxsPSIjRkZGIj4KICAgIDxjaXJjbGUgY2xhc3M9InN0MiIgY3g9IjUuNSIgY3k9IjE0LjUiIHI9IjEuNSIvPgogICAgPHJlY3QgeD0iMTIiIHk9IjQiIGNsYXNzPSJzdDIiIHdpZHRoPSIxIiBoZWlnaHQ9IjgiLz4KICAgIDxyZWN0IHg9IjguNSIgeT0iNy41IiB0cmFuc2Zvcm09Im1hdHJpeCgwLjg2NiAtMC41IDAuNSAwLjg2NiAtMi4zMjU1IDcuMzIxOSkiIGNsYXNzPSJzdDIiIHdpZHRoPSI4IiBoZWlnaHQ9IjEiLz4KICAgIDxyZWN0IHg9IjEyIiB5PSI0IiB0cmFuc2Zvcm09Im1hdHJpeCgwLjUgLTAuODY2IDAuODY2IDAuNSAtMC42Nzc5IDE0LjgyNTIpIiBjbGFzcz0ic3QyIiB3aWR0aD0iMSIgaGVpZ2h0PSI4Ii8+CiAgPC9nPgo8L3N2Zz4K);
  --jp-icon-run: url(data:image/svg+xml;base64,PHN2ZyBoZWlnaHQ9IjI0IiB2aWV3Qm94PSIwIDAgMjQgMjQiIHdpZHRoPSIyNCIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KICAgIDxnIGNsYXNzPSJqcC1pY29uMyIgZmlsbD0iIzYxNjE2MSI+CiAgICAgICAgPHBhdGggZD0iTTggNXYxNGwxMS03eiIvPgogICAgPC9nPgo8L3N2Zz4K);
  --jp-icon-running: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDUxMiA1MTIiPgogIDxnIGNsYXNzPSJqcC1pY29uMyIgZmlsbD0iIzYxNjE2MSI+CiAgICA8cGF0aCBkPSJNMjU2IDhDMTE5IDggOCAxMTkgOCAyNTZzMTExIDI0OCAyNDggMjQ4IDI0OC0xMTEgMjQ4LTI0OFMzOTMgOCAyNTYgOHptOTYgMzI4YzAgOC44LTcuMiAxNi0xNiAxNkgxNzZjLTguOCAwLTE2LTcuMi0xNi0xNlYxNzZjMC04LjggNy4yLTE2IDE2LTE2aDE2MGM4LjggMCAxNiA3LjIgMTYgMTZ2MTYweiIvPgogIDwvZz4KPC9zdmc+Cg==);
  --jp-icon-save: url(data:image/svg+xml;base64,PHN2ZyBoZWlnaHQ9IjI0IiB2aWV3Qm94PSIwIDAgMjQgMjQiIHdpZHRoPSIyNCIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KICAgIDxnIGNsYXNzPSJqcC1pY29uMyIgZmlsbD0iIzYxNjE2MSI+CiAgICAgICAgPHBhdGggZD0iTTE3IDNINWMtMS4xMSAwLTIgLjktMiAydjE0YzAgMS4xLjg5IDIgMiAyaDE0YzEuMSAwIDItLjkgMi0yVjdsLTQtNHptLTUgMTZjLTEuNjYgMC0zLTEuMzQtMy0zczEuMzQtMyAzLTMgMyAxLjM0IDMgMy0xLjM0IDMtMyAzem0zLTEwSDVWNWgxMHY0eiIvPgogICAgPC9nPgo8L3N2Zz4K);
  --jp-icon-search: url(data:image/svg+xml;base64,PHN2ZyB2aWV3Qm94PSIwIDAgMTggMTgiIHdpZHRoPSIxNiIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KICA8ZyBjbGFzcz0ianAtaWNvbjMiIGZpbGw9IiM2MTYxNjEiPgogICAgPHBhdGggZD0iTTEyLjEsMTAuOWgtMC43bC0wLjItMC4yYzAuOC0wLjksMS4zLTIuMiwxLjMtMy41YzAtMy0yLjQtNS40LTUuNC01LjRTMS44LDQuMiwxLjgsNy4xczIuNCw1LjQsNS40LDUuNCBjMS4zLDAsMi41LTAuNSwzLjUtMS4zbDAuMiwwLjJ2MC43bDQuMSw0LjFsMS4yLTEuMkwxMi4xLDEwLjl6IE03LjEsMTAuOWMtMi4xLDAtMy43LTEuNy0zLjctMy43czEuNy0zLjcsMy43LTMuN3MzLjcsMS43LDMuNywzLjcgUzkuMiwxMC45LDcuMSwxMC45eiIvPgogIDwvZz4KPC9zdmc+Cg==);
  --jp-icon-settings: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDI0IDI0Ij4KICA8cGF0aCBjbGFzcz0ianAtaWNvbjMganAtaWNvbi1zZWxlY3RhYmxlIiBmaWxsPSIjNjE2MTYxIiBkPSJNMTkuNDMgMTIuOThjLjA0LS4zMi4wNy0uNjQuMDctLjk4cy0uMDMtLjY2LS4wNy0uOThsMi4xMS0xLjY1Yy4xOS0uMTUuMjQtLjQyLjEyLS42NGwtMi0zLjQ2Yy0uMTItLjIyLS4zOS0uMy0uNjEtLjIybC0yLjQ5IDFjLS41Mi0uNC0xLjA4LS43My0xLjY5LS45OGwtLjM4LTIuNjVBLjQ4OC40ODggMCAwMDE0IDJoLTRjLS4yNSAwLS40Ni4xOC0uNDkuNDJsLS4zOCAyLjY1Yy0uNjEuMjUtMS4xNy41OS0xLjY5Ljk4bC0yLjQ5LTFjLS4yMy0uMDktLjQ5IDAtLjYxLjIybC0yIDMuNDZjLS4xMy4yMi0uMDcuNDkuMTIuNjRsMi4xMSAxLjY1Yy0uMDQuMzItLjA3LjY1LS4wNy45OHMuMDMuNjYuMDcuOThsLTIuMTEgMS42NWMtLjE5LjE1LS4yNC40Mi0uMTIuNjRsMiAzLjQ2Yy4xMi4yMi4zOS4zLjYxLjIybDIuNDktMWMuNTIuNCAxLjA4LjczIDEuNjkuOThsLjM4IDIuNjVjLjAzLjI0LjI0LjQyLjQ5LjQyaDRjLjI1IDAgLjQ2LS4xOC40OS0uNDJsLjM4LTIuNjVjLjYxLS4yNSAxLjE3LS41OSAxLjY5LS45OGwyLjQ5IDFjLjIzLjA5LjQ5IDAgLjYxLS4yMmwyLTMuNDZjLjEyLS4yMi4wNy0uNDktLjEyLS42NGwtMi4xMS0xLjY1ek0xMiAxNS41Yy0xLjkzIDAtMy41LTEuNTctMy41LTMuNXMxLjU3LTMuNSAzLjUtMy41IDMuNSAxLjU3IDMuNSAzLjUtMS41NyAzLjUtMy41IDMuNXoiLz4KPC9zdmc+Cg==);
  --jp-icon-spreadsheet: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDIyIDIyIj4KICA8cGF0aCBjbGFzcz0ianAtaWNvbi1jb250cmFzdDEganAtaWNvbi1zZWxlY3RhYmxlIiBmaWxsPSIjNENBRjUwIiBkPSJNMi4yIDIuMnYxNy42aDE3LjZWMi4ySDIuMnptMTUuNCA3LjdoLTUuNVY0LjRoNS41djUuNXpNOS45IDQuNHY1LjVINC40VjQuNGg1LjV6bS01LjUgNy43aDUuNXY1LjVINC40di01LjV6bTcuNyA1LjV2LTUuNWg1LjV2NS41aC01LjV6Ii8+Cjwvc3ZnPgo=);
  --jp-icon-stop: url(data:image/svg+xml;base64,PHN2ZyBoZWlnaHQ9IjI0IiB2aWV3Qm94PSIwIDAgMjQgMjQiIHdpZHRoPSIyNCIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KICAgIDxnIGNsYXNzPSJqcC1pY29uMyIgZmlsbD0iIzYxNjE2MSI+CiAgICAgICAgPHBhdGggZD0iTTAgMGgyNHYyNEgweiIgZmlsbD0ibm9uZSIvPgogICAgICAgIDxwYXRoIGQ9Ik02IDZoMTJ2MTJINnoiLz4KICAgIDwvZz4KPC9zdmc+Cg==);
  --jp-icon-tab: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDI0IDI0Ij4KICA8ZyBjbGFzcz0ianAtaWNvbjMiIGZpbGw9IiM2MTYxNjEiPgogICAgPHBhdGggZD0iTTIxIDNIM2MtMS4xIDAtMiAuOS0yIDJ2MTRjMCAxLjEuOSAyIDIgMmgxOGMxLjEgMCAyLS45IDItMlY1YzAtMS4xLS45LTItMi0yem0wIDE2SDNWNWgxMHY0aDh2MTB6Ii8+CiAgPC9nPgo8L3N2Zz4K);
  --jp-icon-terminal: url(data:image/svg+xml;base64,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);
  --jp-icon-text-editor: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDI0IDI0Ij4KICA8cGF0aCBjbGFzcz0ianAtaWNvbjMganAtaWNvbi1zZWxlY3RhYmxlIiBmaWxsPSIjNjE2MTYxIiBkPSJNMTUgMTVIM3YyaDEydi0yem0wLThIM3YyaDEyVjd6TTMgMTNoMTh2LTJIM3Yyem0wIDhoMTh2LTJIM3Yyek0zIDN2MmgxOFYzSDN6Ii8+Cjwvc3ZnPgo=);
  --jp-icon-trusted: url(data:image/svg+xml;base64,PHN2ZyBmaWxsPSJub25lIiB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDI0IDI1Ij4KICAgIDxwYXRoIGNsYXNzPSJqcC1pY29uMiIgc3Ryb2tlPSIjMzMzMzMzIiBzdHJva2Utd2lkdGg9IjIiIHRyYW5zZm9ybT0idHJhbnNsYXRlKDIgMykiIGQ9Ik0xLjg2MDk0IDExLjQ0MDlDMC44MjY0NDggOC43NzAyNyAwLjg2Mzc3OSA2LjA1NzY0IDEuMjQ5MDcgNC4xOTkzMkMyLjQ4MjA2IDMuOTMzNDcgNC4wODA2OCAzLjQwMzQ3IDUuNjAxMDIgMi44NDQ5QzcuMjM1NDkgMi4yNDQ0IDguODU2NjYgMS41ODE1IDkuOTg3NiAxLjA5NTM5QzExLjA1OTcgMS41ODM0MSAxMi42MDk0IDIuMjQ0NCAxNC4yMTggMi44NDMzOUMxNS43NTAzIDMuNDEzOTQgMTcuMzk5NSAzLjk1MjU4IDE4Ljc1MzkgNC4yMTM4NUMxOS4xMzY0IDYuMDcxNzcgMTkuMTcwOSA4Ljc3NzIyIDE4LjEzOSAxMS40NDA5QzE3LjAzMDMgMTQuMzAzMiAxNC42NjY4IDE3LjE4NDQgOS45OTk5OSAxOC45MzU0QzUuMzMzMiAxNy4xODQ0IDIuOTY5NjggMTQuMzAzMiAxLjg2MDk0IDExLjQ0MDlaIi8+CiAgICA8cGF0aCBjbGFzcz0ianAtaWNvbjIiIGZpbGw9IiMzMzMzMzMiIHN0cm9rZT0iIzMzMzMzMyIgdHJhbnNmb3JtPSJ0cmFuc2xhdGUoOCA5Ljg2NzE5KSIgZD0iTTIuODYwMTUgNC44NjUzNUwwLjcyNjU0OSAyLjk5OTU5TDAgMy42MzA0NUwyLjg2MDE1IDYuMTMxNTdMOCAwLjYzMDg3Mkw3LjI3ODU3IDBMMi44NjAxNSA0Ljg2NTM1WiIvPgo8L3N2Zz4K);
  --jp-icon-undo: url(data:image/svg+xml;base64,PHN2ZyB2aWV3Qm94PSIwIDAgMjQgMjQiIHdpZHRoPSIxNiIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KICA8ZyBjbGFzcz0ianAtaWNvbjMiIGZpbGw9IiM2MTYxNjEiPgogICAgPHBhdGggZD0iTTEyLjUgOGMtMi42NSAwLTUuMDUuOTktNi45IDIuNkwyIDd2OWg5bC0zLjYyLTMuNjJjMS4zOS0xLjE2IDMuMTYtMS44OCA1LjEyLTEuODggMy41NCAwIDYuNTUgMi4zMSA3LjYgNS41bDIuMzctLjc4QzIxLjA4IDExLjAzIDE3LjE1IDggMTIuNSA4eiIvPgogIDwvZz4KPC9zdmc+Cg==);
  --jp-icon-vega: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDIyIDIyIj4KICA8ZyBjbGFzcz0ianAtaWNvbjEganAtaWNvbi1zZWxlY3RhYmxlIiBmaWxsPSIjMjEyMTIxIj4KICAgIDxwYXRoIGQ9Ik0xMC42IDUuNGwyLjItMy4ySDIuMnY3LjNsNC02LjZ6Ii8+CiAgICA8cGF0aCBkPSJNMTUuOCAyLjJsLTQuNCA2LjZMNyA2LjNsLTQuOCA4djUuNWgxNy42VjIuMmgtNHptLTcgMTUuNEg1LjV2LTQuNGgzLjN2NC40em00LjQgMEg5LjhWOS44aDMuNHY3Ljh6bTQuNCAwaC0zLjRWNi41aDMuNHYxMS4xeiIvPgogIDwvZz4KPC9zdmc+Cg==);
  --jp-icon-yaml: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDIyIDIyIj4KICA8ZyBjbGFzcz0ianAtaWNvbi1jb250cmFzdDIganAtaWNvbi1zZWxlY3RhYmxlIiBmaWxsPSIjRDgxQjYwIj4KICAgIDxwYXRoIGQ9Ik03LjIgMTguNnYtNS40TDMgNS42aDMuM2wxLjQgMy4xYy4zLjkuNiAxLjYgMSAyLjUuMy0uOC42LTEuNiAxLTIuNWwxLjQtMy4xaDMuNGwtNC40IDcuNnY1LjVsLTIuOS0uMXoiLz4KICAgIDxjaXJjbGUgY2xhc3M9InN0MCIgY3g9IjE3LjYiIGN5PSIxNi41IiByPSIyLjEiLz4KICAgIDxjaXJjbGUgY2xhc3M9InN0MCIgY3g9IjE3LjYiIGN5PSIxMSIgcj0iMi4xIi8+CiAgPC9nPgo8L3N2Zz4K);
}

/* Icon CSS class declarations */

.jp-AddIcon {
  background-image: var(--jp-icon-add);
}
.jp-BugIcon {
  background-image: var(--jp-icon-bug);
}
.jp-BuildIcon {
  background-image: var(--jp-icon-build);
}
.jp-CaretDownEmptyIcon {
  background-image: var(--jp-icon-caret-down-empty);
}
.jp-CaretDownEmptyThinIcon {
  background-image: var(--jp-icon-caret-down-empty-thin);
}
.jp-CaretDownIcon {
  background-image: var(--jp-icon-caret-down);
}
.jp-CaretLeftIcon {
  background-image: var(--jp-icon-caret-left);
}
.jp-CaretRightIcon {
  background-image: var(--jp-icon-caret-right);
}
.jp-CaretUpEmptyThinIcon {
  background-image: var(--jp-icon-caret-up-empty-thin);
}
.jp-CaretUpIcon {
  background-image: var(--jp-icon-caret-up);
}
.jp-CaseSensitiveIcon {
  background-image: var(--jp-icon-case-sensitive);
}
.jp-CheckIcon {
  background-image: var(--jp-icon-check);
}
.jp-CircleEmptyIcon {
  background-image: var(--jp-icon-circle-empty);
}
.jp-CircleIcon {
  background-image: var(--jp-icon-circle);
}
.jp-ClearIcon {
  background-image: var(--jp-icon-clear);
}
.jp-CloseIcon {
  background-image: var(--jp-icon-close);
}
.jp-ConsoleIcon {
  background-image: var(--jp-icon-console);
}
.jp-CopyIcon {
  background-image: var(--jp-icon-copy);
}
.jp-CutIcon {
  background-image: var(--jp-icon-cut);
}
.jp-DownloadIcon {
  background-image: var(--jp-icon-download);
}
.jp-EditIcon {
  background-image: var(--jp-icon-edit);
}
.jp-EllipsesIcon {
  background-image: var(--jp-icon-ellipses);
}
.jp-ExtensionIcon {
  background-image: var(--jp-icon-extension);
}
.jp-FastForwardIcon {
  background-image: var(--jp-icon-fast-forward);
}
.jp-FileIcon {
  background-image: var(--jp-icon-file);
}
.jp-FileUploadIcon {
  background-image: var(--jp-icon-file-upload);
}
.jp-FilterListIcon {
  background-image: var(--jp-icon-filter-list);
}
.jp-FolderIcon {
  background-image: var(--jp-icon-folder);
}
.jp-Html5Icon {
  background-image: var(--jp-icon-html5);
}
.jp-ImageIcon {
  background-image: var(--jp-icon-image);
}
.jp-InspectorIcon {
  background-image: var(--jp-icon-inspector);
}
.jp-JsonIcon {
  background-image: var(--jp-icon-json);
}
.jp-JupyterFaviconIcon {
  background-image: var(--jp-icon-jupyter-favicon);
}
.jp-JupyterIcon {
  background-image: var(--jp-icon-jupyter);
}
.jp-JupyterlabWordmarkIcon {
  background-image: var(--jp-icon-jupyterlab-wordmark);
}
.jp-KernelIcon {
  background-image: var(--jp-icon-kernel);
}
.jp-KeyboardIcon {
  background-image: var(--jp-icon-keyboard);
}
.jp-LauncherIcon {
  background-image: var(--jp-icon-launcher);
}
.jp-LineFormIcon {
  background-image: var(--jp-icon-line-form);
}
.jp-LinkIcon {
  background-image: var(--jp-icon-link);
}
.jp-ListIcon {
  background-image: var(--jp-icon-list);
}
.jp-ListingsInfoIcon {
  background-image: var(--jp-icon-listings-info);
}
.jp-MarkdownIcon {
  background-image: var(--jp-icon-markdown);
}
.jp-NewFolderIcon {
  background-image: var(--jp-icon-new-folder);
}
.jp-NotTrustedIcon {
  background-image: var(--jp-icon-not-trusted);
}
.jp-NotebookIcon {
  background-image: var(--jp-icon-notebook);
}
.jp-PaletteIcon {
  background-image: var(--jp-icon-palette);
}
.jp-PasteIcon {
  background-image: var(--jp-icon-paste);
}
.jp-PythonIcon {
  background-image: var(--jp-icon-python);
}
.jp-RKernelIcon {
  background-image: var(--jp-icon-r-kernel);
}
.jp-ReactIcon {
  background-image: var(--jp-icon-react);
}
.jp-RefreshIcon {
  background-image: var(--jp-icon-refresh);
}
.jp-RegexIcon {
  background-image: var(--jp-icon-regex);
}
.jp-RunIcon {
  background-image: var(--jp-icon-run);
}
.jp-RunningIcon {
  background-image: var(--jp-icon-running);
}
.jp-SaveIcon {
  background-image: var(--jp-icon-save);
}
.jp-SearchIcon {
  background-image: var(--jp-icon-search);
}
.jp-SettingsIcon {
  background-image: var(--jp-icon-settings);
}
.jp-SpreadsheetIcon {
  background-image: var(--jp-icon-spreadsheet);
}
.jp-StopIcon {
  background-image: var(--jp-icon-stop);
}
.jp-TabIcon {
  background-image: var(--jp-icon-tab);
}
.jp-TerminalIcon {
  background-image: var(--jp-icon-terminal);
}
.jp-TextEditorIcon {
  background-image: var(--jp-icon-text-editor);
}
.jp-TrustedIcon {
  background-image: var(--jp-icon-trusted);
}
.jp-UndoIcon {
  background-image: var(--jp-icon-undo);
}
.jp-VegaIcon {
  background-image: var(--jp-icon-vega);
}
.jp-YamlIcon {
  background-image: var(--jp-icon-yaml);
}

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

/**
 * (DEPRECATED) Support for consuming icons as CSS background images
 */

:root {
  --jp-icon-search-white: url(data:image/svg+xml;base64,PHN2ZyB2aWV3Qm94PSIwIDAgMTggMTgiIHdpZHRoPSIxNiIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KICA8ZyBjbGFzcz0ianAtaWNvbjMiIGZpbGw9IiM2MTYxNjEiPgogICAgPHBhdGggZD0iTTEyLjEsMTAuOWgtMC43bC0wLjItMC4yYzAuOC0wLjksMS4zLTIuMiwxLjMtMy41YzAtMy0yLjQtNS40LTUuNC01LjRTMS44LDQuMiwxLjgsNy4xczIuNCw1LjQsNS40LDUuNCBjMS4zLDAsMi41LTAuNSwzLjUtMS4zbDAuMiwwLjJ2MC43bDQuMSw0LjFsMS4yLTEuMkwxMi4xLDEwLjl6IE03LjEsMTAuOWMtMi4xLDAtMy43LTEuNy0zLjctMy43czEuNy0zLjcsMy43LTMuN3MzLjcsMS43LDMuNywzLjcgUzkuMiwxMC45LDcuMSwxMC45eiIvPgogIDwvZz4KPC9zdmc+Cg==);
}

.jp-Icon,
.jp-MaterialIcon {
  background-position: center;
  background-repeat: no-repeat;
  background-size: 16px;
  min-width: 16px;
  min-height: 16px;
}

.jp-Icon-cover {
  background-position: center;
  background-repeat: no-repeat;
  background-size: cover;
}

/**
 * (DEPRECATED) Support for specific CSS icon sizes
 */

.jp-Icon-16 {
  background-size: 16px;
  min-width: 16px;
  min-height: 16px;
}

.jp-Icon-18 {
  background-size: 18px;
  min-width: 18px;
  min-height: 18px;
}

.jp-Icon-20 {
  background-size: 20px;
  min-width: 20px;
  min-height: 20px;
}

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

/**
 * Support for icons as inline SVG HTMLElements
 */

/* recolor the primary elements of an icon */
.jp-icon0[fill] {
  fill: var(--jp-inverse-layout-color0);
}
.jp-icon1[fill] {
  fill: var(--jp-inverse-layout-color1);
}
.jp-icon2[fill] {
  fill: var(--jp-inverse-layout-color2);
}
.jp-icon3[fill] {
  fill: var(--jp-inverse-layout-color3);
}
.jp-icon4[fill] {
  fill: var(--jp-inverse-layout-color4);
}

.jp-icon0[stroke] {
  stroke: var(--jp-inverse-layout-color0);
}
.jp-icon1[stroke] {
  stroke: var(--jp-inverse-layout-color1);
}
.jp-icon2[stroke] {
  stroke: var(--jp-inverse-layout-color2);
}
.jp-icon3[stroke] {
  stroke: var(--jp-inverse-layout-color3);
}
.jp-icon4[stroke] {
  stroke: var(--jp-inverse-layout-color4);
}
/* recolor the accent elements of an icon */
.jp-icon-accent0[fill] {
  fill: var(--jp-layout-color0);
}
.jp-icon-accent1[fill] {
  fill: var(--jp-layout-color1);
}
.jp-icon-accent2[fill] {
  fill: var(--jp-layout-color2);
}
.jp-icon-accent3[fill] {
  fill: var(--jp-layout-color3);
}
.jp-icon-accent4[fill] {
  fill: var(--jp-layout-color4);
}

.jp-icon-accent0[stroke] {
  stroke: var(--jp-layout-color0);
}
.jp-icon-accent1[stroke] {
  stroke: var(--jp-layout-color1);
}
.jp-icon-accent2[stroke] {
  stroke: var(--jp-layout-color2);
}
.jp-icon-accent3[stroke] {
  stroke: var(--jp-layout-color3);
}
.jp-icon-accent4[stroke] {
  stroke: var(--jp-layout-color4);
}
/* set the color of an icon to transparent */
.jp-icon-none[fill] {
  fill: none;
}

.jp-icon-none[stroke] {
  stroke: none;
}
/* brand icon colors. Same for light and dark */
.jp-icon-brand0[fill] {
  fill: var(--jp-brand-color0);
}
.jp-icon-brand1[fill] {
  fill: var(--jp-brand-color1);
}
.jp-icon-brand2[fill] {
  fill: var(--jp-brand-color2);
}
.jp-icon-brand3[fill] {
  fill: var(--jp-brand-color3);
}
.jp-icon-brand4[fill] {
  fill: var(--jp-brand-color4);
}

.jp-icon-brand0[stroke] {
  stroke: var(--jp-brand-color0);
}
.jp-icon-brand1[stroke] {
  stroke: var(--jp-brand-color1);
}
.jp-icon-brand2[stroke] {
  stroke: var(--jp-brand-color2);
}
.jp-icon-brand3[stroke] {
  stroke: var(--jp-brand-color3);
}
.jp-icon-brand4[stroke] {
  stroke: var(--jp-brand-color4);
}
/* warn icon colors. Same for light and dark */
.jp-icon-warn0[fill] {
  fill: var(--jp-warn-color0);
}
.jp-icon-warn1[fill] {
  fill: var(--jp-warn-color1);
}
.jp-icon-warn2[fill] {
  fill: var(--jp-warn-color2);
}
.jp-icon-warn3[fill] {
  fill: var(--jp-warn-color3);
}

.jp-icon-warn0[stroke] {
  stroke: var(--jp-warn-color0);
}
.jp-icon-warn1[stroke] {
  stroke: var(--jp-warn-color1);
}
.jp-icon-warn2[stroke] {
  stroke: var(--jp-warn-color2);
}
.jp-icon-warn3[stroke] {
  stroke: var(--jp-warn-color3);
}
/* icon colors that contrast well with each other and most backgrounds */
.jp-icon-contrast0[fill] {
  fill: var(--jp-icon-contrast-color0);
}
.jp-icon-contrast1[fill] {
  fill: var(--jp-icon-contrast-color1);
}
.jp-icon-contrast2[fill] {
  fill: var(--jp-icon-contrast-color2);
}
.jp-icon-contrast3[fill] {
  fill: var(--jp-icon-contrast-color3);
}

.jp-icon-contrast0[stroke] {
  stroke: var(--jp-icon-contrast-color0);
}
.jp-icon-contrast1[stroke] {
  stroke: var(--jp-icon-contrast-color1);
}
.jp-icon-contrast2[stroke] {
  stroke: var(--jp-icon-contrast-color2);
}
.jp-icon-contrast3[stroke] {
  stroke: var(--jp-icon-contrast-color3);
}

/* CSS for icons in selected items in the settings editor */
#setting-editor .jp-PluginList .jp-mod-selected .jp-icon-selectable[fill] {
  fill: #fff;
}
#setting-editor
  .jp-PluginList
  .jp-mod-selected
  .jp-icon-selectable-inverse[fill] {
  fill: var(--jp-brand-color1);
}

/* CSS for icons in selected filebrowser listing items */
.jp-DirListing-item.jp-mod-selected .jp-icon-selectable[fill] {
  fill: #fff;
}
.jp-DirListing-item.jp-mod-selected .jp-icon-selectable-inverse[fill] {
  fill: var(--jp-brand-color1);
}

/* CSS for icons in selected tabs in the sidebar tab manager */
#tab-manager .lm-TabBar-tab.jp-mod-active .jp-icon-selectable[fill] {
  fill: #fff;
}

#tab-manager .lm-TabBar-tab.jp-mod-active .jp-icon-selectable-inverse[fill] {
  fill: var(--jp-brand-color1);
}
#tab-manager
  .lm-TabBar-tab.jp-mod-active
  .jp-icon-hover
  :hover
  .jp-icon-selectable[fill] {
  fill: var(--jp-brand-color1);
}

#tab-manager
  .lm-TabBar-tab.jp-mod-active
  .jp-icon-hover
  :hover
  .jp-icon-selectable-inverse[fill] {
  fill: #fff;
}

/**
 * TODO: come up with non css-hack solution for showing the busy icon on top
 *  of the close icon
 * CSS for complex behavior of close icon of tabs in the sidebar tab manager
 */
#tab-manager
  .lm-TabBar-tab.jp-mod-dirty
  > .lm-TabBar-tabCloseIcon
  > :not(:hover)
  > .jp-icon3[fill] {
  fill: none;
}
#tab-manager
  .lm-TabBar-tab.jp-mod-dirty
  > .lm-TabBar-tabCloseIcon
  > :not(:hover)
  > .jp-icon-busy[fill] {
  fill: var(--jp-inverse-layout-color3);
}

#tab-manager
  .lm-TabBar-tab.jp-mod-dirty.jp-mod-active
  > .lm-TabBar-tabCloseIcon
  > :not(:hover)
  > .jp-icon-busy[fill] {
  fill: #fff;
}

/**
* TODO: come up with non css-hack solution for showing the busy icon on top
*  of the close icon
* CSS for complex behavior of close icon of tabs in the main area tabbar
*/
.lm-DockPanel-tabBar
  .lm-TabBar-tab.lm-mod-closable.jp-mod-dirty
  > .lm-TabBar-tabCloseIcon
  > :not(:hover)
  > .jp-icon3[fill] {
  fill: none;
}
.lm-DockPanel-tabBar
  .lm-TabBar-tab.lm-mod-closable.jp-mod-dirty
  > .lm-TabBar-tabCloseIcon
  > :not(:hover)
  > .jp-icon-busy[fill] {
  fill: var(--jp-inverse-layout-color3);
}

/* CSS for icons in status bar */
#jp-main-statusbar .jp-mod-selected .jp-icon-selectable[fill] {
  fill: #fff;
}

#jp-main-statusbar .jp-mod-selected .jp-icon-selectable-inverse[fill] {
  fill: var(--jp-brand-color1);
}
/* special handling for splash icon CSS. While the theme CSS reloads during
   splash, the splash icon can loose theming. To prevent that, we set a
   default for its color variable */
:root {
  --jp-warn-color0: var(--md-orange-700);
}

/* not sure what to do with this one, used in filebrowser listing */
.jp-DragIcon {
  margin-right: 4px;
}

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

/**
 * Support for alt colors for icons as inline SVG HTMLElements
 */

/* alt recolor the primary elements of an icon */
.jp-icon-alt .jp-icon0[fill] {
  fill: var(--jp-layout-color0);
}
.jp-icon-alt .jp-icon1[fill] {
  fill: var(--jp-layout-color1);
}
.jp-icon-alt .jp-icon2[fill] {
  fill: var(--jp-layout-color2);
}
.jp-icon-alt .jp-icon3[fill] {
  fill: var(--jp-layout-color3);
}
.jp-icon-alt .jp-icon4[fill] {
  fill: var(--jp-layout-color4);
}

.jp-icon-alt .jp-icon0[stroke] {
  stroke: var(--jp-layout-color0);
}
.jp-icon-alt .jp-icon1[stroke] {
  stroke: var(--jp-layout-color1);
}
.jp-icon-alt .jp-icon2[stroke] {
  stroke: var(--jp-layout-color2);
}
.jp-icon-alt .jp-icon3[stroke] {
  stroke: var(--jp-layout-color3);
}
.jp-icon-alt .jp-icon4[stroke] {
  stroke: var(--jp-layout-color4);
}

/* alt recolor the accent elements of an icon */
.jp-icon-alt .jp-icon-accent0[fill] {
  fill: var(--jp-inverse-layout-color0);
}
.jp-icon-alt .jp-icon-accent1[fill] {
  fill: var(--jp-inverse-layout-color1);
}
.jp-icon-alt .jp-icon-accent2[fill] {
  fill: var(--jp-inverse-layout-color2);
}
.jp-icon-alt .jp-icon-accent3[fill] {
  fill: var(--jp-inverse-layout-color3);
}
.jp-icon-alt .jp-icon-accent4[fill] {
  fill: var(--jp-inverse-layout-color4);
}

.jp-icon-alt .jp-icon-accent0[stroke] {
  stroke: var(--jp-inverse-layout-color0);
}
.jp-icon-alt .jp-icon-accent1[stroke] {
  stroke: var(--jp-inverse-layout-color1);
}
.jp-icon-alt .jp-icon-accent2[stroke] {
  stroke: var(--jp-inverse-layout-color2);
}
.jp-icon-alt .jp-icon-accent3[stroke] {
  stroke: var(--jp-inverse-layout-color3);
}
.jp-icon-alt .jp-icon-accent4[stroke] {
  stroke: var(--jp-inverse-layout-color4);
}

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

.jp-icon-hoverShow:not(:hover) svg {
  display: none !important;
}

/**
 * Support for hover colors for icons as inline SVG HTMLElements
 */

/**
 * regular colors
 */

/* recolor the primary elements of an icon */
.jp-icon-hover :hover .jp-icon0-hover[fill] {
  fill: var(--jp-inverse-layout-color0);
}
.jp-icon-hover :hover .jp-icon1-hover[fill] {
  fill: var(--jp-inverse-layout-color1);
}
.jp-icon-hover :hover .jp-icon2-hover[fill] {
  fill: var(--jp-inverse-layout-color2);
}
.jp-icon-hover :hover .jp-icon3-hover[fill] {
  fill: var(--jp-inverse-layout-color3);
}
.jp-icon-hover :hover .jp-icon4-hover[fill] {
  fill: var(--jp-inverse-layout-color4);
}

.jp-icon-hover :hover .jp-icon0-hover[stroke] {
  stroke: var(--jp-inverse-layout-color0);
}
.jp-icon-hover :hover .jp-icon1-hover[stroke] {
  stroke: var(--jp-inverse-layout-color1);
}
.jp-icon-hover :hover .jp-icon2-hover[stroke] {
  stroke: var(--jp-inverse-layout-color2);
}
.jp-icon-hover :hover .jp-icon3-hover[stroke] {
  stroke: var(--jp-inverse-layout-color3);
}
.jp-icon-hover :hover .jp-icon4-hover[stroke] {
  stroke: var(--jp-inverse-layout-color4);
}

/* recolor the accent elements of an icon */
.jp-icon-hover :hover .jp-icon-accent0-hover[fill] {
  fill: var(--jp-layout-color0);
}
.jp-icon-hover :hover .jp-icon-accent1-hover[fill] {
  fill: var(--jp-layout-color1);
}
.jp-icon-hover :hover .jp-icon-accent2-hover[fill] {
  fill: var(--jp-layout-color2);
}
.jp-icon-hover :hover .jp-icon-accent3-hover[fill] {
  fill: var(--jp-layout-color3);
}
.jp-icon-hover :hover .jp-icon-accent4-hover[fill] {
  fill: var(--jp-layout-color4);
}

.jp-icon-hover :hover .jp-icon-accent0-hover[stroke] {
  stroke: var(--jp-layout-color0);
}
.jp-icon-hover :hover .jp-icon-accent1-hover[stroke] {
  stroke: var(--jp-layout-color1);
}
.jp-icon-hover :hover .jp-icon-accent2-hover[stroke] {
  stroke: var(--jp-layout-color2);
}
.jp-icon-hover :hover .jp-icon-accent3-hover[stroke] {
  stroke: var(--jp-layout-color3);
}
.jp-icon-hover :hover .jp-icon-accent4-hover[stroke] {
  stroke: var(--jp-layout-color4);
}

/* set the color of an icon to transparent */
.jp-icon-hover :hover .jp-icon-none-hover[fill] {
  fill: none;
}

.jp-icon-hover :hover .jp-icon-none-hover[stroke] {
  stroke: none;
}

/**
 * inverse colors
 */

/* inverse recolor the primary elements of an icon */
.jp-icon-hover.jp-icon-alt :hover .jp-icon0-hover[fill] {
  fill: var(--jp-layout-color0);
}
.jp-icon-hover.jp-icon-alt :hover .jp-icon1-hover[fill] {
  fill: var(--jp-layout-color1);
}
.jp-icon-hover.jp-icon-alt :hover .jp-icon2-hover[fill] {
  fill: var(--jp-layout-color2);
}
.jp-icon-hover.jp-icon-alt :hover .jp-icon3-hover[fill] {
  fill: var(--jp-layout-color3);
}
.jp-icon-hover.jp-icon-alt :hover .jp-icon4-hover[fill] {
  fill: var(--jp-layout-color4);
}

.jp-icon-hover.jp-icon-alt :hover .jp-icon0-hover[stroke] {
  stroke: var(--jp-layout-color0);
}
.jp-icon-hover.jp-icon-alt :hover .jp-icon1-hover[stroke] {
  stroke: var(--jp-layout-color1);
}
.jp-icon-hover.jp-icon-alt :hover .jp-icon2-hover[stroke] {
  stroke: var(--jp-layout-color2);
}
.jp-icon-hover.jp-icon-alt :hover .jp-icon3-hover[stroke] {
  stroke: var(--jp-layout-color3);
}
.jp-icon-hover.jp-icon-alt :hover .jp-icon4-hover[stroke] {
  stroke: var(--jp-layout-color4);
}

/* inverse recolor the accent elements of an icon */
.jp-icon-hover.jp-icon-alt :hover .jp-icon-accent0-hover[fill] {
  fill: var(--jp-inverse-layout-color0);
}
.jp-icon-hover.jp-icon-alt :hover .jp-icon-accent1-hover[fill] {
  fill: var(--jp-inverse-layout-color1);
}
.jp-icon-hover.jp-icon-alt :hover .jp-icon-accent2-hover[fill] {
  fill: var(--jp-inverse-layout-color2);
}
.jp-icon-hover.jp-icon-alt :hover .jp-icon-accent3-hover[fill] {
  fill: var(--jp-inverse-layout-color3);
}
.jp-icon-hover.jp-icon-alt :hover .jp-icon-accent4-hover[fill] {
  fill: var(--jp-inverse-layout-color4);
}

.jp-icon-hover.jp-icon-alt :hover .jp-icon-accent0-hover[stroke] {
  stroke: var(--jp-inverse-layout-color0);
}
.jp-icon-hover.jp-icon-alt :hover .jp-icon-accent1-hover[stroke] {
  stroke: var(--jp-inverse-layout-color1);
}
.jp-icon-hover.jp-icon-alt :hover .jp-icon-accent2-hover[stroke] {
  stroke: var(--jp-inverse-layout-color2);
}
.jp-icon-hover.jp-icon-alt :hover .jp-icon-accent3-hover[stroke] {
  stroke: var(--jp-inverse-layout-color3);
}
.jp-icon-hover.jp-icon-alt :hover .jp-icon-accent4-hover[stroke] {
  stroke: var(--jp-inverse-layout-color4);
}

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

/* Sibling imports */

/* Override Blueprint's _reset.scss styles */
html {
  box-sizing: unset;
}

*,
*::before,
*::after {
  box-sizing: unset;
}

body {
  color: unset;
  font-family: var(--jp-ui-font-family);
}

p {
  margin-top: unset;
  margin-bottom: unset;
}

small {
  font-size: unset;
}

strong {
  font-weight: unset;
}

/* Override Blueprint's _typography.scss styles */
a {
  text-decoration: unset;
  color: unset;
}
a:hover {
  text-decoration: unset;
  color: unset;
}

/* Override Blueprint's _accessibility.scss styles */
:focus {
  outline: unset;
  outline-offset: unset;
  -moz-outline-radius: unset;
}

/* Styles for ui-components */
.jp-Button {
  border-radius: var(--jp-border-radius);
  padding: 0px 12px;
  font-size: var(--jp-ui-font-size1);
}

/* Use our own theme for hover styles */
button.jp-Button.bp3-button.bp3-minimal:hover {
  background-color: var(--jp-layout-color2);
}
.jp-Button.minimal {
  color: unset !important;
}

.jp-Button.jp-ToolbarButtonComponent {
  text-transform: none;
}

.jp-InputGroup input {
  box-sizing: border-box;
  border-radius: 0;
  background-color: transparent;
  color: var(--jp-ui-font-color0);
  box-shadow: inset 0 0 0 var(--jp-border-width) var(--jp-input-border-color);
}

.jp-InputGroup input:focus {
  box-shadow: inset 0 0 0 var(--jp-border-width)
      var(--jp-input-active-box-shadow-color),
    inset 0 0 0 3px var(--jp-input-active-box-shadow-color);
}

.jp-InputGroup input::placeholder,
input::placeholder {
  color: var(--jp-ui-font-color3);
}

.jp-BPIcon {
  display: inline-block;
  vertical-align: middle;
  margin: auto;
}

/* Stop blueprint futzing with our icon fills */
.bp3-icon.jp-BPIcon > svg:not([fill]) {
  fill: var(--jp-inverse-layout-color3);
}

.jp-InputGroupAction {
  padding: 6px;
}

.jp-HTMLSelect.jp-DefaultStyle select {
  background-color: initial;
  border: none;
  border-radius: 0;
  box-shadow: none;
  color: var(--jp-ui-font-color0);
  display: block;
  font-size: var(--jp-ui-font-size1);
  height: 24px;
  line-height: 14px;
  padding: 0 25px 0 10px;
  text-align: left;
  -moz-appearance: none;
  -webkit-appearance: none;
}

/* Use our own theme for hover and option styles */
.jp-HTMLSelect.jp-DefaultStyle select:hover,
.jp-HTMLSelect.jp-DefaultStyle select > option {
  background-color: var(--jp-layout-color2);
  color: var(--jp-ui-font-color0);
}
select {
  box-sizing: border-box;
}

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

/* This file was auto-generated by ensurePackage() in @jupyterlab/buildutils */

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

.jp-Collapse {
  display: flex;
  flex-direction: column;
  align-items: stretch;
  border-top: 1px solid var(--jp-border-color2);
  border-bottom: 1px solid var(--jp-border-color2);
}

.jp-Collapse-header {
  padding: 1px 12px;
  color: var(--jp-ui-font-color1);
  background-color: var(--jp-layout-color1);
  font-size: var(--jp-ui-font-size2);
}

.jp-Collapse-header:hover {
  background-color: var(--jp-layout-color2);
}

.jp-Collapse-contents {
  padding: 0px 12px 0px 12px;
  background-color: var(--jp-layout-color1);
  color: var(--jp-ui-font-color1);
  overflow: auto;
}

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------
| Variables
|----------------------------------------------------------------------------*/

:root {
  --jp-private-commandpalette-search-height: 28px;
}

/*-----------------------------------------------------------------------------
| Overall styles
|----------------------------------------------------------------------------*/

.lm-CommandPalette {
  padding-bottom: 0px;
  color: var(--jp-ui-font-color1);
  background: var(--jp-layout-color1);
  /* This is needed so that all font sizing of children done in ems is
   * relative to this base size */
  font-size: var(--jp-ui-font-size1);
}

/*-----------------------------------------------------------------------------
| Search
|----------------------------------------------------------------------------*/

.lm-CommandPalette-search {
  padding: 4px;
  background-color: var(--jp-layout-color1);
  z-index: 2;
}

.lm-CommandPalette-wrapper {
  overflow: overlay;
  padding: 0px 9px;
  background-color: var(--jp-input-active-background);
  height: 30px;
  box-shadow: inset 0 0 0 var(--jp-border-width) var(--jp-input-border-color);
}

.lm-CommandPalette.lm-mod-focused .lm-CommandPalette-wrapper {
  box-shadow: inset 0 0 0 1px var(--jp-input-active-box-shadow-color),
    inset 0 0 0 3px var(--jp-input-active-box-shadow-color);
}

.lm-CommandPalette-wrapper::after {
  content: ' ';
  color: white;
  background-color: var(--jp-brand-color1);
  position: absolute;
  top: 4px;
  right: 4px;
  height: 30px;
  width: 10px;
  padding: 0px 10px;
  background-image: var(--jp-icon-search-white);
  background-size: 20px;
  background-repeat: no-repeat;
  background-position: center;
}

.lm-CommandPalette-input {
  background: transparent;
  width: calc(100% - 18px);
  float: left;
  border: none;
  outline: none;
  font-size: var(--jp-ui-font-size1);
  color: var(--jp-ui-font-color0);
  line-height: var(--jp-private-commandpalette-search-height);
}

.lm-CommandPalette-input::-webkit-input-placeholder,
.lm-CommandPalette-input::-moz-placeholder,
.lm-CommandPalette-input:-ms-input-placeholder {
  color: var(--jp-ui-font-color3);
  font-size: var(--jp-ui-font-size1);
}

/*-----------------------------------------------------------------------------
| Results
|----------------------------------------------------------------------------*/

.lm-CommandPalette-header:first-child {
  margin-top: 0px;
}

.lm-CommandPalette-header {
  border-bottom: solid var(--jp-border-width) var(--jp-border-color2);
  color: var(--jp-ui-font-color1);
  cursor: pointer;
  display: flex;
  font-size: var(--jp-ui-font-size0);
  font-weight: 600;
  letter-spacing: 1px;
  margin-top: 8px;
  padding: 8px 0 8px 12px;
  text-transform: uppercase;
}

.lm-CommandPalette-header.lm-mod-active {
  background: var(--jp-layout-color2);
}

.lm-CommandPalette-header > mark {
  background-color: transparent;
  font-weight: bold;
  color: var(--jp-ui-font-color1);
}

.lm-CommandPalette-item {
  padding: 4px 12px 4px 4px;
  color: var(--jp-ui-font-color1);
  font-size: var(--jp-ui-font-size1);
  font-weight: 400;
  display: flex;
}

.lm-CommandPalette-item.lm-mod-disabled {
  color: var(--jp-ui-font-color3);
}

.lm-CommandPalette-item.lm-mod-active {
  background: var(--jp-layout-color3);
}

.lm-CommandPalette-item.lm-mod-active:hover:not(.lm-mod-disabled) {
  background: var(--jp-layout-color4);
}

.lm-CommandPalette-item:hover:not(.lm-mod-active):not(.lm-mod-disabled) {
  background: var(--jp-layout-color2);
}

.lm-CommandPalette-itemContent {
  overflow: hidden;
}

.lm-CommandPalette-itemLabel > mark {
  color: var(--jp-ui-font-color0);
  background-color: transparent;
  font-weight: bold;
}

.lm-CommandPalette-item.lm-mod-disabled mark {
  color: var(--jp-ui-font-color3);
}

.lm-CommandPalette-item .lm-CommandPalette-itemIcon {
  margin: 0 4px 0 0;
  position: relative;
  width: 16px;
  top: 2px;
  flex: 0 0 auto;
}

.lm-CommandPalette-item.lm-mod-disabled .lm-CommandPalette-itemIcon {
  opacity: 0.4;
}

.lm-CommandPalette-item .lm-CommandPalette-itemShortcut {
  flex: 0 0 auto;
}

.lm-CommandPalette-itemCaption {
  display: none;
}

.lm-CommandPalette-content {
  background-color: var(--jp-layout-color1);
}

.lm-CommandPalette-content:empty:after {
  content: 'No results';
  margin: auto;
  margin-top: 20px;
  width: 100px;
  display: block;
  font-size: var(--jp-ui-font-size2);
  font-family: var(--jp-ui-font-family);
  font-weight: lighter;
}

.lm-CommandPalette-emptyMessage {
  text-align: center;
  margin-top: 24px;
  line-height: 1.32;
  padding: 0px 8px;
  color: var(--jp-content-font-color3);
}

/*-----------------------------------------------------------------------------
| Copyright (c) 2014-2017, Jupyter Development Team.
|
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

.jp-Dialog {
  position: absolute;
  z-index: 10000;
  display: flex;
  flex-direction: column;
  align-items: center;
  justify-content: center;
  top: 0px;
  left: 0px;
  margin: 0;
  padding: 0;
  width: 100%;
  height: 100%;
  background: var(--jp-dialog-background);
}

.jp-Dialog-content {
  display: flex;
  flex-direction: column;
  margin-left: auto;
  margin-right: auto;
  background: var(--jp-layout-color1);
  padding: 24px;
  padding-bottom: 12px;
  min-width: 300px;
  min-height: 150px;
  max-width: 1000px;
  max-height: 500px;
  box-sizing: border-box;
  box-shadow: var(--jp-elevation-z20);
  word-wrap: break-word;
  border-radius: var(--jp-border-radius);
  /* This is needed so that all font sizing of children done in ems is
   * relative to this base size */
  font-size: var(--jp-ui-font-size1);
  color: var(--jp-ui-font-color1);
}

.jp-Dialog-button {
  overflow: visible;
}

button.jp-Dialog-button:focus {
  outline: 1px solid var(--jp-brand-color1);
  outline-offset: 4px;
  -moz-outline-radius: 0px;
}

button.jp-Dialog-button:focus::-moz-focus-inner {
  border: 0;
}

.jp-Dialog-header {
  flex: 0 0 auto;
  padding-bottom: 12px;
  font-size: var(--jp-ui-font-size3);
  font-weight: 400;
  color: var(--jp-ui-font-color0);
}

.jp-Dialog-body {
  display: flex;
  flex-direction: column;
  flex: 1 1 auto;
  font-size: var(--jp-ui-font-size1);
  background: var(--jp-layout-color1);
  overflow: auto;
}

.jp-Dialog-footer {
  display: flex;
  flex-direction: row;
  justify-content: flex-end;
  flex: 0 0 auto;
  margin-left: -12px;
  margin-right: -12px;
  padding: 12px;
}

.jp-Dialog-title {
  overflow: hidden;
  white-space: nowrap;
  text-overflow: ellipsis;
}

.jp-Dialog-body > .jp-select-wrapper {
  width: 100%;
}

.jp-Dialog-body > button {
  padding: 0px 16px;
}

.jp-Dialog-body > label {
  line-height: 1.4;
  color: var(--jp-ui-font-color0);
}

.jp-Dialog-button.jp-mod-styled:not(:last-child) {
  margin-right: 12px;
}

/*-----------------------------------------------------------------------------
| Copyright (c) 2014-2016, Jupyter Development Team.
|
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

.jp-HoverBox {
  position: fixed;
}

.jp-HoverBox.jp-mod-outofview {
  display: none;
}

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

.jp-IFrame {
  width: 100%;
  height: 100%;
}

.jp-IFrame > iframe {
  border: none;
}

/*
When drag events occur, `p-mod-override-cursor` is added to the body.
Because iframes steal all cursor events, the following two rules are necessary
to suppress pointer events while resize drags are occurring. There may be a
better solution to this problem.
*/
body.lm-mod-override-cursor .jp-IFrame {
  position: relative;
}

body.lm-mod-override-cursor .jp-IFrame:before {
  content: '';
  position: absolute;
  top: 0;
  left: 0;
  right: 0;
  bottom: 0;
  background: transparent;
}

/*-----------------------------------------------------------------------------
| Copyright (c) 2014-2016, Jupyter Development Team.
|
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

.jp-MainAreaWidget > :focus {
  outline: none;
}

/**
 * google-material-color v1.2.6
 * https://github.com/danlevan/google-material-color
 */
:root {
  --md-red-50: #ffebee;
  --md-red-100: #ffcdd2;
  --md-red-200: #ef9a9a;
  --md-red-300: #e57373;
  --md-red-400: #ef5350;
  --md-red-500: #f44336;
  --md-red-600: #e53935;
  --md-red-700: #d32f2f;
  --md-red-800: #c62828;
  --md-red-900: #b71c1c;
  --md-red-A100: #ff8a80;
  --md-red-A200: #ff5252;
  --md-red-A400: #ff1744;
  --md-red-A700: #d50000;

  --md-pink-50: #fce4ec;
  --md-pink-100: #f8bbd0;
  --md-pink-200: #f48fb1;
  --md-pink-300: #f06292;
  --md-pink-400: #ec407a;
  --md-pink-500: #e91e63;
  --md-pink-600: #d81b60;
  --md-pink-700: #c2185b;
  --md-pink-800: #ad1457;
  --md-pink-900: #880e4f;
  --md-pink-A100: #ff80ab;
  --md-pink-A200: #ff4081;
  --md-pink-A400: #f50057;
  --md-pink-A700: #c51162;

  --md-purple-50: #f3e5f5;
  --md-purple-100: #e1bee7;
  --md-purple-200: #ce93d8;
  --md-purple-300: #ba68c8;
  --md-purple-400: #ab47bc;
  --md-purple-500: #9c27b0;
  --md-purple-600: #8e24aa;
  --md-purple-700: #7b1fa2;
  --md-purple-800: #6a1b9a;
  --md-purple-900: #4a148c;
  --md-purple-A100: #ea80fc;
  --md-purple-A200: #e040fb;
  --md-purple-A400: #d500f9;
  --md-purple-A700: #aa00ff;

  --md-deep-purple-50: #ede7f6;
  --md-deep-purple-100: #d1c4e9;
  --md-deep-purple-200: #b39ddb;
  --md-deep-purple-300: #9575cd;
  --md-deep-purple-400: #7e57c2;
  --md-deep-purple-500: #673ab7;
  --md-deep-purple-600: #5e35b1;
  --md-deep-purple-700: #512da8;
  --md-deep-purple-800: #4527a0;
  --md-deep-purple-900: #311b92;
  --md-deep-purple-A100: #b388ff;
  --md-deep-purple-A200: #7c4dff;
  --md-deep-purple-A400: #651fff;
  --md-deep-purple-A700: #6200ea;

  --md-indigo-50: #e8eaf6;
  --md-indigo-100: #c5cae9;
  --md-indigo-200: #9fa8da;
  --md-indigo-300: #7986cb;
  --md-indigo-400: #5c6bc0;
  --md-indigo-500: #3f51b5;
  --md-indigo-600: #3949ab;
  --md-indigo-700: #303f9f;
  --md-indigo-800: #283593;
  --md-indigo-900: #1a237e;
  --md-indigo-A100: #8c9eff;
  --md-indigo-A200: #536dfe;
  --md-indigo-A400: #3d5afe;
  --md-indigo-A700: #304ffe;

  --md-blue-50: #e3f2fd;
  --md-blue-100: #bbdefb;
  --md-blue-200: #90caf9;
  --md-blue-300: #64b5f6;
  --md-blue-400: #42a5f5;
  --md-blue-500: #2196f3;
  --md-blue-600: #1e88e5;
  --md-blue-700: #1976d2;
  --md-blue-800: #1565c0;
  --md-blue-900: #0d47a1;
  --md-blue-A100: #82b1ff;
  --md-blue-A200: #448aff;
  --md-blue-A400: #2979ff;
  --md-blue-A700: #2962ff;

  --md-light-blue-50: #e1f5fe;
  --md-light-blue-100: #b3e5fc;
  --md-light-blue-200: #81d4fa;
  --md-light-blue-300: #4fc3f7;
  --md-light-blue-400: #29b6f6;
  --md-light-blue-500: #03a9f4;
  --md-light-blue-600: #039be5;
  --md-light-blue-700: #0288d1;
  --md-light-blue-800: #0277bd;
  --md-light-blue-900: #01579b;
  --md-light-blue-A100: #80d8ff;
  --md-light-blue-A200: #40c4ff;
  --md-light-blue-A400: #00b0ff;
  --md-light-blue-A700: #0091ea;

  --md-cyan-50: #e0f7fa;
  --md-cyan-100: #b2ebf2;
  --md-cyan-200: #80deea;
  --md-cyan-300: #4dd0e1;
  --md-cyan-400: #26c6da;
  --md-cyan-500: #00bcd4;
  --md-cyan-600: #00acc1;
  --md-cyan-700: #0097a7;
  --md-cyan-800: #00838f;
  --md-cyan-900: #006064;
  --md-cyan-A100: #84ffff;
  --md-cyan-A200: #18ffff;
  --md-cyan-A400: #00e5ff;
  --md-cyan-A700: #00b8d4;

  --md-teal-50: #e0f2f1;
  --md-teal-100: #b2dfdb;
  --md-teal-200: #80cbc4;
  --md-teal-300: #4db6ac;
  --md-teal-400: #26a69a;
  --md-teal-500: #009688;
  --md-teal-600: #00897b;
  --md-teal-700: #00796b;
  --md-teal-800: #00695c;
  --md-teal-900: #004d40;
  --md-teal-A100: #a7ffeb;
  --md-teal-A200: #64ffda;
  --md-teal-A400: #1de9b6;
  --md-teal-A700: #00bfa5;

  --md-green-50: #e8f5e9;
  --md-green-100: #c8e6c9;
  --md-green-200: #a5d6a7;
  --md-green-300: #81c784;
  --md-green-400: #66bb6a;
  --md-green-500: #4caf50;
  --md-green-600: #43a047;
  --md-green-700: #388e3c;
  --md-green-800: #2e7d32;
  --md-green-900: #1b5e20;
  --md-green-A100: #b9f6ca;
  --md-green-A200: #69f0ae;
  --md-green-A400: #00e676;
  --md-green-A700: #00c853;

  --md-light-green-50: #f1f8e9;
  --md-light-green-100: #dcedc8;
  --md-light-green-200: #c5e1a5;
  --md-light-green-300: #aed581;
  --md-light-green-400: #9ccc65;
  --md-light-green-500: #8bc34a;
  --md-light-green-600: #7cb342;
  --md-light-green-700: #689f38;
  --md-light-green-800: #558b2f;
  --md-light-green-900: #33691e;
  --md-light-green-A100: #ccff90;
  --md-light-green-A200: #b2ff59;
  --md-light-green-A400: #76ff03;
  --md-light-green-A700: #64dd17;

  --md-lime-50: #f9fbe7;
  --md-lime-100: #f0f4c3;
  --md-lime-200: #e6ee9c;
  --md-lime-300: #dce775;
  --md-lime-400: #d4e157;
  --md-lime-500: #cddc39;
  --md-lime-600: #c0ca33;
  --md-lime-700: #afb42b;
  --md-lime-800: #9e9d24;
  --md-lime-900: #827717;
  --md-lime-A100: #f4ff81;
  --md-lime-A200: #eeff41;
  --md-lime-A400: #c6ff00;
  --md-lime-A700: #aeea00;

  --md-yellow-50: #fffde7;
  --md-yellow-100: #fff9c4;
  --md-yellow-200: #fff59d;
  --md-yellow-300: #fff176;
  --md-yellow-400: #ffee58;
  --md-yellow-500: #ffeb3b;
  --md-yellow-600: #fdd835;
  --md-yellow-700: #fbc02d;
  --md-yellow-800: #f9a825;
  --md-yellow-900: #f57f17;
  --md-yellow-A100: #ffff8d;
  --md-yellow-A200: #ffff00;
  --md-yellow-A400: #ffea00;
  --md-yellow-A700: #ffd600;

  --md-amber-50: #fff8e1;
  --md-amber-100: #ffecb3;
  --md-amber-200: #ffe082;
  --md-amber-300: #ffd54f;
  --md-amber-400: #ffca28;
  --md-amber-500: #ffc107;
  --md-amber-600: #ffb300;
  --md-amber-700: #ffa000;
  --md-amber-800: #ff8f00;
  --md-amber-900: #ff6f00;
  --md-amber-A100: #ffe57f;
  --md-amber-A200: #ffd740;
  --md-amber-A400: #ffc400;
  --md-amber-A700: #ffab00;

  --md-orange-50: #fff3e0;
  --md-orange-100: #ffe0b2;
  --md-orange-200: #ffcc80;
  --md-orange-300: #ffb74d;
  --md-orange-400: #ffa726;
  --md-orange-500: #ff9800;
  --md-orange-600: #fb8c00;
  --md-orange-700: #f57c00;
  --md-orange-800: #ef6c00;
  --md-orange-900: #e65100;
  --md-orange-A100: #ffd180;
  --md-orange-A200: #ffab40;
  --md-orange-A400: #ff9100;
  --md-orange-A700: #ff6d00;

  --md-deep-orange-50: #fbe9e7;
  --md-deep-orange-100: #ffccbc;
  --md-deep-orange-200: #ffab91;
  --md-deep-orange-300: #ff8a65;
  --md-deep-orange-400: #ff7043;
  --md-deep-orange-500: #ff5722;
  --md-deep-orange-600: #f4511e;
  --md-deep-orange-700: #e64a19;
  --md-deep-orange-800: #d84315;
  --md-deep-orange-900: #bf360c;
  --md-deep-orange-A100: #ff9e80;
  --md-deep-orange-A200: #ff6e40;
  --md-deep-orange-A400: #ff3d00;
  --md-deep-orange-A700: #dd2c00;

  --md-brown-50: #efebe9;
  --md-brown-100: #d7ccc8;
  --md-brown-200: #bcaaa4;
  --md-brown-300: #a1887f;
  --md-brown-400: #8d6e63;
  --md-brown-500: #795548;
  --md-brown-600: #6d4c41;
  --md-brown-700: #5d4037;
  --md-brown-800: #4e342e;
  --md-brown-900: #3e2723;

  --md-grey-50: #fafafa;
  --md-grey-100: #f5f5f5;
  --md-grey-200: #eeeeee;
  --md-grey-300: #e0e0e0;
  --md-grey-400: #bdbdbd;
  --md-grey-500: #9e9e9e;
  --md-grey-600: #757575;
  --md-grey-700: #616161;
  --md-grey-800: #424242;
  --md-grey-900: #212121;

  --md-blue-grey-50: #eceff1;
  --md-blue-grey-100: #cfd8dc;
  --md-blue-grey-200: #b0bec5;
  --md-blue-grey-300: #90a4ae;
  --md-blue-grey-400: #78909c;
  --md-blue-grey-500: #607d8b;
  --md-blue-grey-600: #546e7a;
  --md-blue-grey-700: #455a64;
  --md-blue-grey-800: #37474f;
  --md-blue-grey-900: #263238;
}

/*-----------------------------------------------------------------------------
| Copyright (c) 2017, Jupyter Development Team.
|
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

.jp-Spinner {
  position: absolute;
  display: flex;
  justify-content: center;
  align-items: center;
  z-index: 10;
  left: 0;
  top: 0;
  width: 100%;
  height: 100%;
  background: var(--jp-layout-color0);
  outline: none;
}

.jp-SpinnerContent {
  font-size: 10px;
  margin: 50px auto;
  text-indent: -9999em;
  width: 3em;
  height: 3em;
  border-radius: 50%;
  background: var(--jp-brand-color3);
  background: linear-gradient(
    to right,
    #f37626 10%,
    rgba(255, 255, 255, 0) 42%
  );
  position: relative;
  animation: load3 1s infinite linear, fadeIn 1s;
}

.jp-SpinnerContent:before {
  width: 50%;
  height: 50%;
  background: #f37626;
  border-radius: 100% 0 0 0;
  position: absolute;
  top: 0;
  left: 0;
  content: '';
}

.jp-SpinnerContent:after {
  background: var(--jp-layout-color0);
  width: 75%;
  height: 75%;
  border-radius: 50%;
  content: '';
  margin: auto;
  position: absolute;
  top: 0;
  left: 0;
  bottom: 0;
  right: 0;
}

@keyframes fadeIn {
  0% {
    opacity: 0;
  }
  100% {
    opacity: 1;
  }
}

@keyframes load3 {
  0% {
    transform: rotate(0deg);
  }
  100% {
    transform: rotate(360deg);
  }
}

/*-----------------------------------------------------------------------------
| Copyright (c) 2014-2017, Jupyter Development Team.
|
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

button.jp-mod-styled {
  font-size: var(--jp-ui-font-size1);
  color: var(--jp-ui-font-color0);
  border: none;
  box-sizing: border-box;
  text-align: center;
  line-height: 32px;
  height: 32px;
  padding: 0px 12px;
  letter-spacing: 0.8px;
  outline: none;
  appearance: none;
  -webkit-appearance: none;
  -moz-appearance: none;
}

input.jp-mod-styled {
  background: var(--jp-input-background);
  height: 28px;
  box-sizing: border-box;
  border: var(--jp-border-width) solid var(--jp-border-color1);
  padding-left: 7px;
  padding-right: 7px;
  font-size: var(--jp-ui-font-size2);
  color: var(--jp-ui-font-color0);
  outline: none;
  appearance: none;
  -webkit-appearance: none;
  -moz-appearance: none;
}

input.jp-mod-styled:focus {
  border: var(--jp-border-width) solid var(--md-blue-500);
  box-shadow: inset 0 0 4px var(--md-blue-300);
}

.jp-select-wrapper {
  display: flex;
  position: relative;
  flex-direction: column;
  padding: 1px;
  background-color: var(--jp-layout-color1);
  height: 28px;
  box-sizing: border-box;
  margin-bottom: 12px;
}

.jp-select-wrapper.jp-mod-focused select.jp-mod-styled {
  border: var(--jp-border-width) solid var(--jp-input-active-border-color);
  box-shadow: var(--jp-input-box-shadow);
  background-color: var(--jp-input-active-background);
}

select.jp-mod-styled:hover {
  background-color: var(--jp-layout-color1);
  cursor: pointer;
  color: var(--jp-ui-font-color0);
  background-color: var(--jp-input-hover-background);
  box-shadow: inset 0 0px 1px rgba(0, 0, 0, 0.5);
}

select.jp-mod-styled {
  flex: 1 1 auto;
  height: 32px;
  width: 100%;
  font-size: var(--jp-ui-font-size2);
  background: var(--jp-input-background);
  color: var(--jp-ui-font-color0);
  padding: 0 25px 0 8px;
  border: var(--jp-border-width) solid var(--jp-input-border-color);
  border-radius: 0px;
  outline: none;
  appearance: none;
  -webkit-appearance: none;
  -moz-appearance: none;
}

/*-----------------------------------------------------------------------------
| Copyright (c) 2014-2016, Jupyter Development Team.
|
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

:root {
  --jp-private-toolbar-height: calc(
    28px + var(--jp-border-width)
  ); /* leave 28px for content */
}

.jp-Toolbar {
  color: var(--jp-ui-font-color1);
  flex: 0 0 auto;
  display: flex;
  flex-direction: row;
  border-bottom: var(--jp-border-width) solid var(--jp-toolbar-border-color);
  box-shadow: var(--jp-toolbar-box-shadow);
  background: var(--jp-toolbar-background);
  min-height: var(--jp-toolbar-micro-height);
  padding: 2px;
  z-index: 1;
}

/* Toolbar items */

.jp-Toolbar > .jp-Toolbar-item.jp-Toolbar-spacer {
  flex-grow: 1;
  flex-shrink: 1;
}

.jp-Toolbar-item.jp-Toolbar-kernelStatus {
  display: inline-block;
  width: 32px;
  background-repeat: no-repeat;
  background-position: center;
  background-size: 16px;
}

.jp-Toolbar > .jp-Toolbar-item {
  flex: 0 0 auto;
  display: flex;
  padding-left: 1px;
  padding-right: 1px;
  font-size: var(--jp-ui-font-size1);
  line-height: var(--jp-private-toolbar-height);
  height: 100%;
}

/* Toolbar buttons */

/* This is the div we use to wrap the react component into a Widget */
div.jp-ToolbarButton {
  color: transparent;
  border: none;
  box-sizing: border-box;
  outline: none;
  appearance: none;
  -webkit-appearance: none;
  -moz-appearance: none;
  padding: 0px;
  margin: 0px;
}

button.jp-ToolbarButtonComponent {
  background: var(--jp-layout-color1);
  border: none;
  box-sizing: border-box;
  outline: none;
  appearance: none;
  -webkit-appearance: none;
  -moz-appearance: none;
  padding: 0px 6px;
  margin: 0px;
  height: 24px;
  border-radius: var(--jp-border-radius);
  display: flex;
  align-items: center;
  text-align: center;
  font-size: 14px;
  min-width: unset;
  min-height: unset;
}

button.jp-ToolbarButtonComponent:disabled {
  opacity: 0.4;
}

button.jp-ToolbarButtonComponent span {
  padding: 0px;
  flex: 0 0 auto;
}

button.jp-ToolbarButtonComponent .jp-ToolbarButtonComponent-label {
  font-size: var(--jp-ui-font-size1);
  line-height: 100%;
  padding-left: 2px;
  color: var(--jp-ui-font-color1);
}

/*-----------------------------------------------------------------------------
| Copyright (c) 2014-2017, Jupyter Development Team.
|
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

/* This file was auto-generated by ensurePackage() in @jupyterlab/buildutils */

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Copyright (c) 2014-2017, PhosphorJS Contributors
|
| Distributed under the terms of the BSD 3-Clause License.
|
| The full license is in the file LICENSE, distributed with this software.
|----------------------------------------------------------------------------*/


/* <DEPRECATED> */ body.p-mod-override-cursor *, /* </DEPRECATED> */
body.lm-mod-override-cursor * {
  cursor: inherit !important;
}

/*-----------------------------------------------------------------------------
| Copyright (c) 2014-2016, Jupyter Development Team.
|
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

.jp-JSONEditor {
  display: flex;
  flex-direction: column;
  width: 100%;
}

.jp-JSONEditor-host {
  flex: 1 1 auto;
  border: var(--jp-border-width) solid var(--jp-input-border-color);
  border-radius: 0px;
  background: var(--jp-layout-color0);
  min-height: 50px;
  padding: 1px;
}

.jp-JSONEditor.jp-mod-error .jp-JSONEditor-host {
  border-color: red;
  outline-color: red;
}

.jp-JSONEditor-header {
  display: flex;
  flex: 1 0 auto;
  padding: 0 0 0 12px;
}

.jp-JSONEditor-header label {
  flex: 0 0 auto;
}

.jp-JSONEditor-commitButton {
  height: 16px;
  width: 16px;
  background-size: 18px;
  background-repeat: no-repeat;
  background-position: center;
}

.jp-JSONEditor-host.jp-mod-focused {
  background-color: var(--jp-input-active-background);
  border: 1px solid var(--jp-input-active-border-color);
  box-shadow: var(--jp-input-box-shadow);
}

.jp-Editor.jp-mod-dropTarget {
  border: var(--jp-border-width) solid var(--jp-input-active-border-color);
  box-shadow: var(--jp-input-box-shadow);
}

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

/* This file was auto-generated by ensurePackage() in @jupyterlab/buildutils */

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

/* BASICS */

.CodeMirror {
  /* Set height, width, borders, and global font properties here */
  font-family: monospace;
  height: 300px;
  color: black;
  direction: ltr;
}

/* PADDING */

.CodeMirror-lines {
  padding: 4px 0; /* Vertical padding around content */
}
.CodeMirror pre.CodeMirror-line,
.CodeMirror pre.CodeMirror-line-like {
  padding: 0 4px; /* Horizontal padding of content */
}

.CodeMirror-scrollbar-filler, .CodeMirror-gutter-filler {
  background-color: white; /* The little square between H and V scrollbars */
}

/* GUTTER */

.CodeMirror-gutters {
  border-right: 1px solid #ddd;
  background-color: #f7f7f7;
  white-space: nowrap;
}
.CodeMirror-linenumbers {}
.CodeMirror-linenumber {
  padding: 0 3px 0 5px;
  min-width: 20px;
  text-align: right;
  color: #999;
  white-space: nowrap;
}

.CodeMirror-guttermarker { color: black; }
.CodeMirror-guttermarker-subtle { color: #999; }

/* CURSOR */

.CodeMirror-cursor {
  border-left: 1px solid black;
  border-right: none;
  width: 0;
}
/* Shown when moving in bi-directional text */
.CodeMirror div.CodeMirror-secondarycursor {
  border-left: 1px solid silver;
}
.cm-fat-cursor .CodeMirror-cursor {
  width: auto;
  border: 0 !important;
  background: #7e7;
}
.cm-fat-cursor div.CodeMirror-cursors {
  z-index: 1;
}
.cm-fat-cursor-mark {
  background-color: rgba(20, 255, 20, 0.5);
  -webkit-animation: blink 1.06s steps(1) infinite;
  -moz-animation: blink 1.06s steps(1) infinite;
  animation: blink 1.06s steps(1) infinite;
}
.cm-animate-fat-cursor {
  width: auto;
  border: 0;
  -webkit-animation: blink 1.06s steps(1) infinite;
  -moz-animation: blink 1.06s steps(1) infinite;
  animation: blink 1.06s steps(1) infinite;
  background-color: #7e7;
}
@-moz-keyframes blink {
  0% {}
  50% { background-color: transparent; }
  100% {}
}
@-webkit-keyframes blink {
  0% {}
  50% { background-color: transparent; }
  100% {}
}
@keyframes blink {
  0% {}
  50% { background-color: transparent; }
  100% {}
}

/* Can style cursor different in overwrite (non-insert) mode */
.CodeMirror-overwrite .CodeMirror-cursor {}

.cm-tab { display: inline-block; text-decoration: inherit; }

.CodeMirror-rulers {
  position: absolute;
  left: 0; right: 0; top: -50px; bottom: 0;
  overflow: hidden;
}
.CodeMirror-ruler {
  border-left: 1px solid #ccc;
  top: 0; bottom: 0;
  position: absolute;
}

/* DEFAULT THEME */

.cm-s-default .cm-header {color: blue;}
.cm-s-default .cm-quote {color: #090;}
.cm-negative {color: #d44;}
.cm-positive {color: #292;}
.cm-header, .cm-strong {font-weight: bold;}
.cm-em {font-style: italic;}
.cm-link {text-decoration: underline;}
.cm-strikethrough {text-decoration: line-through;}

.cm-s-default .cm-keyword {color: #708;}
.cm-s-default .cm-atom {color: #219;}
.cm-s-default .cm-number {color: #164;}
.cm-s-default .cm-def {color: #00f;}
.cm-s-default .cm-variable,
.cm-s-default .cm-punctuation,
.cm-s-default .cm-property,
.cm-s-default .cm-operator {}
.cm-s-default .cm-variable-2 {color: #05a;}
.cm-s-default .cm-variable-3, .cm-s-default .cm-type {color: #085;}
.cm-s-default .cm-comment {color: #a50;}
.cm-s-default .cm-string {color: #a11;}
.cm-s-default .cm-string-2 {color: #f50;}
.cm-s-default .cm-meta {color: #555;}
.cm-s-default .cm-qualifier {color: #555;}
.cm-s-default .cm-builtin {color: #30a;}
.cm-s-default .cm-bracket {color: #997;}
.cm-s-default .cm-tag {color: #170;}
.cm-s-default .cm-attribute {color: #00c;}
.cm-s-default .cm-hr {color: #999;}
.cm-s-default .cm-link {color: #00c;}

.cm-s-default .cm-error {color: #f00;}
.cm-invalidchar {color: #f00;}

.CodeMirror-composing { border-bottom: 2px solid; }

/* Default styles for common addons */

div.CodeMirror span.CodeMirror-matchingbracket {color: #0b0;}
div.CodeMirror span.CodeMirror-nonmatchingbracket {color: #a22;}
.CodeMirror-matchingtag { background: rgba(255, 150, 0, .3); }
.CodeMirror-activeline-background {background: #e8f2ff;}

/* STOP */

/* The rest of this file contains styles related to the mechanics of
   the editor. You probably shouldn't touch them. */

.CodeMirror {
  position: relative;
  overflow: hidden;
  background: white;
}

.CodeMirror-scroll {
  overflow: scroll !important; /* Things will break if this is overridden */
  /* 30px is the magic margin used to hide the element's real scrollbars */
  /* See overflow: hidden in .CodeMirror */
  margin-bottom: -30px; margin-right: -30px;
  padding-bottom: 30px;
  height: 100%;
  outline: none; /* Prevent dragging from highlighting the element */
  position: relative;
}
.CodeMirror-sizer {
  position: relative;
  border-right: 30px solid transparent;
}

/* The fake, visible scrollbars. Used to force redraw during scrolling
   before actual scrolling happens, thus preventing shaking and
   flickering artifacts. */
.CodeMirror-vscrollbar, .CodeMirror-hscrollbar, .CodeMirror-scrollbar-filler, .CodeMirror-gutter-filler {
  position: absolute;
  z-index: 6;
  display: none;
}
.CodeMirror-vscrollbar {
  right: 0; top: 0;
  overflow-x: hidden;
  overflow-y: scroll;
}
.CodeMirror-hscrollbar {
  bottom: 0; left: 0;
  overflow-y: hidden;
  overflow-x: scroll;
}
.CodeMirror-scrollbar-filler {
  right: 0; bottom: 0;
}
.CodeMirror-gutter-filler {
  left: 0; bottom: 0;
}

.CodeMirror-gutters {
  position: absolute; left: 0; top: 0;
  min-height: 100%;
  z-index: 3;
}
.CodeMirror-gutter {
  white-space: normal;
  height: 100%;
  display: inline-block;
  vertical-align: top;
  margin-bottom: -30px;
}
.CodeMirror-gutter-wrapper {
  position: absolute;
  z-index: 4;
  background: none !important;
  border: none !important;
}
.CodeMirror-gutter-background {
  position: absolute;
  top: 0; bottom: 0;
  z-index: 4;
}
.CodeMirror-gutter-elt {
  position: absolute;
  cursor: default;
  z-index: 4;
}
.CodeMirror-gutter-wrapper ::selection { background-color: transparent }
.CodeMirror-gutter-wrapper ::-moz-selection { background-color: transparent }

.CodeMirror-lines {
  cursor: text;
  min-height: 1px; /* prevents collapsing before first draw */
}
.CodeMirror pre.CodeMirror-line,
.CodeMirror pre.CodeMirror-line-like {
  /* Reset some styles that the rest of the page might have set */
  -moz-border-radius: 0; -webkit-border-radius: 0; border-radius: 0;
  border-width: 0;
  background: transparent;
  font-family: inherit;
  font-size: inherit;
  margin: 0;
  white-space: pre;
  word-wrap: normal;
  line-height: inherit;
  color: inherit;
  z-index: 2;
  position: relative;
  overflow: visible;
  -webkit-tap-highlight-color: transparent;
  -webkit-font-variant-ligatures: contextual;
  font-variant-ligatures: contextual;
}
.CodeMirror-wrap pre.CodeMirror-line,
.CodeMirror-wrap pre.CodeMirror-line-like {
  word-wrap: break-word;
  white-space: pre-wrap;
  word-break: normal;
}

.CodeMirror-linebackground {
  position: absolute;
  left: 0; right: 0; top: 0; bottom: 0;
  z-index: 0;
}

.CodeMirror-linewidget {
  position: relative;
  z-index: 2;
  padding: 0.1px; /* Force widget margins to stay inside of the container */
}

.CodeMirror-widget {}

.CodeMirror-rtl pre { direction: rtl; }

.CodeMirror-code {
  outline: none;
}

/* Force content-box sizing for the elements where we expect it */
.CodeMirror-scroll,
.CodeMirror-sizer,
.CodeMirror-gutter,
.CodeMirror-gutters,
.CodeMirror-linenumber {
  -moz-box-sizing: content-box;
  box-sizing: content-box;
}

.CodeMirror-measure {
  position: absolute;
  width: 100%;
  height: 0;
  overflow: hidden;
  visibility: hidden;
}

.CodeMirror-cursor {
  position: absolute;
  pointer-events: none;
}
.CodeMirror-measure pre { position: static; }

div.CodeMirror-cursors {
  visibility: hidden;
  position: relative;
  z-index: 3;
}
div.CodeMirror-dragcursors {
  visibility: visible;
}

.CodeMirror-focused div.CodeMirror-cursors {
  visibility: visible;
}

.CodeMirror-selected { background: #d9d9d9; }
.CodeMirror-focused .CodeMirror-selected { background: #d7d4f0; }
.CodeMirror-crosshair { cursor: crosshair; }
.CodeMirror-line::selection, .CodeMirror-line > span::selection, .CodeMirror-line > span > span::selection { background: #d7d4f0; }
.CodeMirror-line::-moz-selection, .CodeMirror-line > span::-moz-selection, .CodeMirror-line > span > span::-moz-selection { background: #d7d4f0; }

.cm-searching {
  background-color: #ffa;
  background-color: rgba(255, 255, 0, .4);
}

/* Used to force a border model for a node */
.cm-force-border { padding-right: .1px; }

@media print {
  /* Hide the cursor when printing */
  .CodeMirror div.CodeMirror-cursors {
    visibility: hidden;
  }
}

/* See issue #2901 */
.cm-tab-wrap-hack:after { content: ''; }

/* Help users use markselection to safely style text background */
span.CodeMirror-selectedtext { background: none; }

.CodeMirror-dialog {
  position: absolute;
  left: 0; right: 0;
  background: inherit;
  z-index: 15;
  padding: .1em .8em;
  overflow: hidden;
  color: inherit;
}

.CodeMirror-dialog-top {
  border-bottom: 1px solid #eee;
  top: 0;
}

.CodeMirror-dialog-bottom {
  border-top: 1px solid #eee;
  bottom: 0;
}

.CodeMirror-dialog input {
  border: none;
  outline: none;
  background: transparent;
  width: 20em;
  color: inherit;
  font-family: monospace;
}

.CodeMirror-dialog button {
  font-size: 70%;
}

.CodeMirror-foldmarker {
  color: blue;
  text-shadow: #b9f 1px 1px 2px, #b9f -1px -1px 2px, #b9f 1px -1px 2px, #b9f -1px 1px 2px;
  font-family: arial;
  line-height: .3;
  cursor: pointer;
}
.CodeMirror-foldgutter {
  width: .7em;
}
.CodeMirror-foldgutter-open,
.CodeMirror-foldgutter-folded {
  cursor: pointer;
}
.CodeMirror-foldgutter-open:after {
  content: "\25BE";
}
.CodeMirror-foldgutter-folded:after {
  content: "\25B8";
}

/*
  Name:       material
  Author:     Mattia Astorino (http://github.com/equinusocio)
  Website:    https://material-theme.site/
*/

.cm-s-material.CodeMirror {
  background-color: #263238;
  color: #EEFFFF;
}

.cm-s-material .CodeMirror-gutters {
  background: #263238;
  color: #546E7A;
  border: none;
}

.cm-s-material .CodeMirror-guttermarker,
.cm-s-material .CodeMirror-guttermarker-subtle,
.cm-s-material .CodeMirror-linenumber {
  color: #546E7A;
}

.cm-s-material .CodeMirror-cursor {
  border-left: 1px solid #FFCC00;
}

.cm-s-material div.CodeMirror-selected {
  background: rgba(128, 203, 196, 0.2);
}

.cm-s-material.CodeMirror-focused div.CodeMirror-selected {
  background: rgba(128, 203, 196, 0.2);
}

.cm-s-material .CodeMirror-line::selection,
.cm-s-material .CodeMirror-line>span::selection,
.cm-s-material .CodeMirror-line>span>span::selection {
  background: rgba(128, 203, 196, 0.2);
}

.cm-s-material .CodeMirror-line::-moz-selection,
.cm-s-material .CodeMirror-line>span::-moz-selection,
.cm-s-material .CodeMirror-line>span>span::-moz-selection {
  background: rgba(128, 203, 196, 0.2);
}

.cm-s-material .CodeMirror-activeline-background {
  background: rgba(0, 0, 0, 0.5);
}

.cm-s-material .cm-keyword {
  color: #C792EA;
}

.cm-s-material .cm-operator {
  color: #89DDFF;
}

.cm-s-material .cm-variable-2 {
  color: #EEFFFF;
}

.cm-s-material .cm-variable-3,
.cm-s-material .cm-type {
  color: #f07178;
}

.cm-s-material .cm-builtin {
  color: #FFCB6B;
}

.cm-s-material .cm-atom {
  color: #F78C6C;
}

.cm-s-material .cm-number {
  color: #FF5370;
}

.cm-s-material .cm-def {
  color: #82AAFF;
}

.cm-s-material .cm-string {
  color: #C3E88D;
}

.cm-s-material .cm-string-2 {
  color: #f07178;
}

.cm-s-material .cm-comment {
  color: #546E7A;
}

.cm-s-material .cm-variable {
  color: #f07178;
}

.cm-s-material .cm-tag {
  color: #FF5370;
}

.cm-s-material .cm-meta {
  color: #FFCB6B;
}

.cm-s-material .cm-attribute {
  color: #C792EA;
}

.cm-s-material .cm-property {
  color: #C792EA;
}

.cm-s-material .cm-qualifier {
  color: #DECB6B;
}

.cm-s-material .cm-variable-3,
.cm-s-material .cm-type {
  color: #DECB6B;
}


.cm-s-material .cm-error {
  color: rgba(255, 255, 255, 1.0);
  background-color: #FF5370;
}

.cm-s-material .CodeMirror-matchingbracket {
  text-decoration: underline;
  color: white !important;
}
/**
 * "
 *  Using Zenburn color palette from the Emacs Zenburn Theme
 *  https://github.com/bbatsov/zenburn-emacs/blob/master/zenburn-theme.el
 *
 *  Also using parts of https://github.com/xavi/coderay-lighttable-theme
 * "
 * From: https://github.com/wisenomad/zenburn-lighttable-theme/blob/master/zenburn.css
 */

.cm-s-zenburn .CodeMirror-gutters { background: #3f3f3f !important; }
.cm-s-zenburn .CodeMirror-foldgutter-open, .CodeMirror-foldgutter-folded { color: #999; }
.cm-s-zenburn .CodeMirror-cursor { border-left: 1px solid white; }
.cm-s-zenburn { background-color: #3f3f3f; color: #dcdccc; }
.cm-s-zenburn span.cm-builtin { color: #dcdccc; font-weight: bold; }
.cm-s-zenburn span.cm-comment { color: #7f9f7f; }
.cm-s-zenburn span.cm-keyword { color: #f0dfaf; font-weight: bold; }
.cm-s-zenburn span.cm-atom { color: #bfebbf; }
.cm-s-zenburn span.cm-def { color: #dcdccc; }
.cm-s-zenburn span.cm-variable { color: #dfaf8f; }
.cm-s-zenburn span.cm-variable-2 { color: #dcdccc; }
.cm-s-zenburn span.cm-string { color: #cc9393; }
.cm-s-zenburn span.cm-string-2 { color: #cc9393; }
.cm-s-zenburn span.cm-number { color: #dcdccc; }
.cm-s-zenburn span.cm-tag { color: #93e0e3; }
.cm-s-zenburn span.cm-property { color: #dfaf8f; }
.cm-s-zenburn span.cm-attribute { color: #dfaf8f; }
.cm-s-zenburn span.cm-qualifier { color: #7cb8bb; }
.cm-s-zenburn span.cm-meta { color: #f0dfaf; }
.cm-s-zenburn span.cm-header { color: #f0efd0; }
.cm-s-zenburn span.cm-operator { color: #f0efd0; }
.cm-s-zenburn span.CodeMirror-matchingbracket { box-sizing: border-box; background: transparent; border-bottom: 1px solid; }
.cm-s-zenburn span.CodeMirror-nonmatchingbracket { border-bottom: 1px solid; background: none; }
.cm-s-zenburn .CodeMirror-activeline { background: #000000; }
.cm-s-zenburn .CodeMirror-activeline-background { background: #000000; }
.cm-s-zenburn div.CodeMirror-selected { background: #545454; }
.cm-s-zenburn .CodeMirror-focused div.CodeMirror-selected { background: #4f4f4f; }

.cm-s-abcdef.CodeMirror { background: #0f0f0f; color: #defdef; }
.cm-s-abcdef div.CodeMirror-selected { background: #515151; }
.cm-s-abcdef .CodeMirror-line::selection, .cm-s-abcdef .CodeMirror-line > span::selection, .cm-s-abcdef .CodeMirror-line > span > span::selection { background: rgba(56, 56, 56, 0.99); }
.cm-s-abcdef .CodeMirror-line::-moz-selection, .cm-s-abcdef .CodeMirror-line > span::-moz-selection, .cm-s-abcdef .CodeMirror-line > span > span::-moz-selection { background: rgba(56, 56, 56, 0.99); }
.cm-s-abcdef .CodeMirror-gutters { background: #555; border-right: 2px solid #314151; }
.cm-s-abcdef .CodeMirror-guttermarker { color: #222; }
.cm-s-abcdef .CodeMirror-guttermarker-subtle { color: azure; }
.cm-s-abcdef .CodeMirror-linenumber { color: #FFFFFF; }
.cm-s-abcdef .CodeMirror-cursor { border-left: 1px solid #00FF00; }

.cm-s-abcdef span.cm-keyword { color: darkgoldenrod; font-weight: bold; }
.cm-s-abcdef span.cm-atom { color: #77F; }
.cm-s-abcdef span.cm-number { color: violet; }
.cm-s-abcdef span.cm-def { color: #fffabc; }
.cm-s-abcdef span.cm-variable { color: #abcdef; }
.cm-s-abcdef span.cm-variable-2 { color: #cacbcc; }
.cm-s-abcdef span.cm-variable-3, .cm-s-abcdef span.cm-type { color: #def; }
.cm-s-abcdef span.cm-property { color: #fedcba; }
.cm-s-abcdef span.cm-operator { color: #ff0; }
.cm-s-abcdef span.cm-comment { color: #7a7b7c; font-style: italic;}
.cm-s-abcdef span.cm-string { color: #2b4; }
.cm-s-abcdef span.cm-meta { color: #C9F; }
.cm-s-abcdef span.cm-qualifier { color: #FFF700; }
.cm-s-abcdef span.cm-builtin { color: #30aabc; }
.cm-s-abcdef span.cm-bracket { color: #8a8a8a; }
.cm-s-abcdef span.cm-tag { color: #FFDD44; }
.cm-s-abcdef span.cm-attribute { color: #DDFF00; }
.cm-s-abcdef span.cm-error { color: #FF0000; }
.cm-s-abcdef span.cm-header { color: aquamarine; font-weight: bold; }
.cm-s-abcdef span.cm-link { color: blueviolet; }

.cm-s-abcdef .CodeMirror-activeline-background { background: #314151; }

/*

    Name:       Base16 Default Light
    Author:     Chris Kempson (http://chriskempson.com)

    CodeMirror template by Jan T. Sott (https://github.com/idleberg/base16-codemirror)
    Original Base16 color scheme by Chris Kempson (https://github.com/chriskempson/base16)

*/

.cm-s-base16-light.CodeMirror { background: #f5f5f5; color: #202020; }
.cm-s-base16-light div.CodeMirror-selected { background: #e0e0e0; }
.cm-s-base16-light .CodeMirror-line::selection, .cm-s-base16-light .CodeMirror-line > span::selection, .cm-s-base16-light .CodeMirror-line > span > span::selection { background: #e0e0e0; }
.cm-s-base16-light .CodeMirror-line::-moz-selection, .cm-s-base16-light .CodeMirror-line > span::-moz-selection, .cm-s-base16-light .CodeMirror-line > span > span::-moz-selection { background: #e0e0e0; }
.cm-s-base16-light .CodeMirror-gutters { background: #f5f5f5; border-right: 0px; }
.cm-s-base16-light .CodeMirror-guttermarker { color: #ac4142; }
.cm-s-base16-light .CodeMirror-guttermarker-subtle { color: #b0b0b0; }
.cm-s-base16-light .CodeMirror-linenumber { color: #b0b0b0; }
.cm-s-base16-light .CodeMirror-cursor { border-left: 1px solid #505050; }

.cm-s-base16-light span.cm-comment { color: #8f5536; }
.cm-s-base16-light span.cm-atom { color: #aa759f; }
.cm-s-base16-light span.cm-number { color: #aa759f; }

.cm-s-base16-light span.cm-property, .cm-s-base16-light span.cm-attribute { color: #90a959; }
.cm-s-base16-light span.cm-keyword { color: #ac4142; }
.cm-s-base16-light span.cm-string { color: #f4bf75; }

.cm-s-base16-light span.cm-variable { color: #90a959; }
.cm-s-base16-light span.cm-variable-2 { color: #6a9fb5; }
.cm-s-base16-light span.cm-def { color: #d28445; }
.cm-s-base16-light span.cm-bracket { color: #202020; }
.cm-s-base16-light span.cm-tag { color: #ac4142; }
.cm-s-base16-light span.cm-link { color: #aa759f; }
.cm-s-base16-light span.cm-error { background: #ac4142; color: #505050; }

.cm-s-base16-light .CodeMirror-activeline-background { background: #DDDCDC; }
.cm-s-base16-light .CodeMirror-matchingbracket { color: #f5f5f5 !important; background-color: #6A9FB5 !important}

/*

    Name:       Base16 Default Dark
    Author:     Chris Kempson (http://chriskempson.com)

    CodeMirror template by Jan T. Sott (https://github.com/idleberg/base16-codemirror)
    Original Base16 color scheme by Chris Kempson (https://github.com/chriskempson/base16)

*/

.cm-s-base16-dark.CodeMirror { background: #151515; color: #e0e0e0; }
.cm-s-base16-dark div.CodeMirror-selected { background: #303030; }
.cm-s-base16-dark .CodeMirror-line::selection, .cm-s-base16-dark .CodeMirror-line > span::selection, .cm-s-base16-dark .CodeMirror-line > span > span::selection { background: rgba(48, 48, 48, .99); }
.cm-s-base16-dark .CodeMirror-line::-moz-selection, .cm-s-base16-dark .CodeMirror-line > span::-moz-selection, .cm-s-base16-dark .CodeMirror-line > span > span::-moz-selection { background: rgba(48, 48, 48, .99); }
.cm-s-base16-dark .CodeMirror-gutters { background: #151515; border-right: 0px; }
.cm-s-base16-dark .CodeMirror-guttermarker { color: #ac4142; }
.cm-s-base16-dark .CodeMirror-guttermarker-subtle { color: #505050; }
.cm-s-base16-dark .CodeMirror-linenumber { color: #505050; }
.cm-s-base16-dark .CodeMirror-cursor { border-left: 1px solid #b0b0b0; }

.cm-s-base16-dark span.cm-comment { color: #8f5536; }
.cm-s-base16-dark span.cm-atom { color: #aa759f; }
.cm-s-base16-dark span.cm-number { color: #aa759f; }

.cm-s-base16-dark span.cm-property, .cm-s-base16-dark span.cm-attribute { color: #90a959; }
.cm-s-base16-dark span.cm-keyword { color: #ac4142; }
.cm-s-base16-dark span.cm-string { color: #f4bf75; }

.cm-s-base16-dark span.cm-variable { color: #90a959; }
.cm-s-base16-dark span.cm-variable-2 { color: #6a9fb5; }
.cm-s-base16-dark span.cm-def { color: #d28445; }
.cm-s-base16-dark span.cm-bracket { color: #e0e0e0; }
.cm-s-base16-dark span.cm-tag { color: #ac4142; }
.cm-s-base16-dark span.cm-link { color: #aa759f; }
.cm-s-base16-dark span.cm-error { background: #ac4142; color: #b0b0b0; }

.cm-s-base16-dark .CodeMirror-activeline-background { background: #202020; }
.cm-s-base16-dark .CodeMirror-matchingbracket { text-decoration: underline; color: white !important; }

/*

    Name:       dracula
    Author:     Michael Kaminsky (http://github.com/mkaminsky11)

    Original dracula color scheme by Zeno Rocha (https://github.com/zenorocha/dracula-theme)

*/


.cm-s-dracula.CodeMirror, .cm-s-dracula .CodeMirror-gutters {
  background-color: #282a36 !important;
  color: #f8f8f2 !important;
  border: none;
}
.cm-s-dracula .CodeMirror-gutters { color: #282a36; }
.cm-s-dracula .CodeMirror-cursor { border-left: solid thin #f8f8f0; }
.cm-s-dracula .CodeMirror-linenumber { color: #6D8A88; }
.cm-s-dracula .CodeMirror-selected { background: rgba(255, 255, 255, 0.10); }
.cm-s-dracula .CodeMirror-line::selection, .cm-s-dracula .CodeMirror-line > span::selection, .cm-s-dracula .CodeMirror-line > span > span::selection { background: rgba(255, 255, 255, 0.10); }
.cm-s-dracula .CodeMirror-line::-moz-selection, .cm-s-dracula .CodeMirror-line > span::-moz-selection, .cm-s-dracula .CodeMirror-line > span > span::-moz-selection { background: rgba(255, 255, 255, 0.10); }
.cm-s-dracula span.cm-comment { color: #6272a4; }
.cm-s-dracula span.cm-string, .cm-s-dracula span.cm-string-2 { color: #f1fa8c; }
.cm-s-dracula span.cm-number { color: #bd93f9; }
.cm-s-dracula span.cm-variable { color: #50fa7b; }
.cm-s-dracula span.cm-variable-2 { color: white; }
.cm-s-dracula span.cm-def { color: #50fa7b; }
.cm-s-dracula span.cm-operator { color: #ff79c6; }
.cm-s-dracula span.cm-keyword { color: #ff79c6; }
.cm-s-dracula span.cm-atom { color: #bd93f9; }
.cm-s-dracula span.cm-meta { color: #f8f8f2; }
.cm-s-dracula span.cm-tag { color: #ff79c6; }
.cm-s-dracula span.cm-attribute { color: #50fa7b; }
.cm-s-dracula span.cm-qualifier { color: #50fa7b; }
.cm-s-dracula span.cm-property { color: #66d9ef; }
.cm-s-dracula span.cm-builtin { color: #50fa7b; }
.cm-s-dracula span.cm-variable-3, .cm-s-dracula span.cm-type { color: #ffb86c; }

.cm-s-dracula .CodeMirror-activeline-background { background: rgba(255,255,255,0.1); }
.cm-s-dracula .CodeMirror-matchingbracket { text-decoration: underline; color: white !important; }

/*

    Name:       Hopscotch
    Author:     Jan T. Sott

    CodeMirror template by Jan T. Sott (https://github.com/idleberg/base16-codemirror)
    Original Base16 color scheme by Chris Kempson (https://github.com/chriskempson/base16)

*/

.cm-s-hopscotch.CodeMirror {background: #322931; color: #d5d3d5;}
.cm-s-hopscotch div.CodeMirror-selected {background: #433b42 !important;}
.cm-s-hopscotch .CodeMirror-gutters {background: #322931; border-right: 0px;}
.cm-s-hopscotch .CodeMirror-linenumber {color: #797379;}
.cm-s-hopscotch .CodeMirror-cursor {border-left: 1px solid #989498 !important;}

.cm-s-hopscotch span.cm-comment {color: #b33508;}
.cm-s-hopscotch span.cm-atom {color: #c85e7c;}
.cm-s-hopscotch span.cm-number {color: #c85e7c;}

.cm-s-hopscotch span.cm-property, .cm-s-hopscotch span.cm-attribute {color: #8fc13e;}
.cm-s-hopscotch span.cm-keyword {color: #dd464c;}
.cm-s-hopscotch span.cm-string {color: #fdcc59;}

.cm-s-hopscotch span.cm-variable {color: #8fc13e;}
.cm-s-hopscotch span.cm-variable-2 {color: #1290bf;}
.cm-s-hopscotch span.cm-def {color: #fd8b19;}
.cm-s-hopscotch span.cm-error {background: #dd464c; color: #989498;}
.cm-s-hopscotch span.cm-bracket {color: #d5d3d5;}
.cm-s-hopscotch span.cm-tag {color: #dd464c;}
.cm-s-hopscotch span.cm-link {color: #c85e7c;}

.cm-s-hopscotch .CodeMirror-matchingbracket { text-decoration: underline; color: white !important;}
.cm-s-hopscotch .CodeMirror-activeline-background { background: #302020; }

/****************************************************************/
/*   Based on mbonaci's Brackets mbo theme                      */
/*   https://github.com/mbonaci/global/blob/master/Mbo.tmTheme  */
/*   Create your own: http://tmtheme-editor.herokuapp.com       */
/****************************************************************/

.cm-s-mbo.CodeMirror { background: #2c2c2c; color: #ffffec; }
.cm-s-mbo div.CodeMirror-selected { background: #716C62; }
.cm-s-mbo .CodeMirror-line::selection, .cm-s-mbo .CodeMirror-line > span::selection, .cm-s-mbo .CodeMirror-line > span > span::selection { background: rgba(113, 108, 98, .99); }
.cm-s-mbo .CodeMirror-line::-moz-selection, .cm-s-mbo .CodeMirror-line > span::-moz-selection, .cm-s-mbo .CodeMirror-line > span > span::-moz-selection { background: rgba(113, 108, 98, .99); }
.cm-s-mbo .CodeMirror-gutters { background: #4e4e4e; border-right: 0px; }
.cm-s-mbo .CodeMirror-guttermarker { color: white; }
.cm-s-mbo .CodeMirror-guttermarker-subtle { color: grey; }
.cm-s-mbo .CodeMirror-linenumber { color: #dadada; }
.cm-s-mbo .CodeMirror-cursor { border-left: 1px solid #ffffec; }

.cm-s-mbo span.cm-comment { color: #95958a; }
.cm-s-mbo span.cm-atom { color: #00a8c6; }
.cm-s-mbo span.cm-number { color: #00a8c6; }

.cm-s-mbo span.cm-property, .cm-s-mbo span.cm-attribute { color: #9ddfe9; }
.cm-s-mbo span.cm-keyword { color: #ffb928; }
.cm-s-mbo span.cm-string { color: #ffcf6c; }
.cm-s-mbo span.cm-string.cm-property { color: #ffffec; }

.cm-s-mbo span.cm-variable { color: #ffffec; }
.cm-s-mbo span.cm-variable-2 { color: #00a8c6; }
.cm-s-mbo span.cm-def { color: #ffffec; }
.cm-s-mbo span.cm-bracket { color: #fffffc; font-weight: bold; }
.cm-s-mbo span.cm-tag { color: #9ddfe9; }
.cm-s-mbo span.cm-link { color: #f54b07; }
.cm-s-mbo span.cm-error { border-bottom: #636363; color: #ffffec; }
.cm-s-mbo span.cm-qualifier { color: #ffffec; }

.cm-s-mbo .CodeMirror-activeline-background { background: #494b41; }
.cm-s-mbo .CodeMirror-matchingbracket { color: #ffb928 !important; }
.cm-s-mbo .CodeMirror-matchingtag { background: rgba(255, 255, 255, .37); }

/*
  MDN-LIKE Theme - Mozilla
  Ported to CodeMirror by Peter Kroon <plakroon@gmail.com>
  Report bugs/issues here: https://github.com/codemirror/CodeMirror/issues
  GitHub: @peterkroon

  The mdn-like theme is inspired on the displayed code examples at: https://developer.mozilla.org/en-US/docs/Web/CSS/animation

*/
.cm-s-mdn-like.CodeMirror { color: #999; background-color: #fff; }
.cm-s-mdn-like div.CodeMirror-selected { background: #cfc; }
.cm-s-mdn-like .CodeMirror-line::selection, .cm-s-mdn-like .CodeMirror-line > span::selection, .cm-s-mdn-like .CodeMirror-line > span > span::selection { background: #cfc; }
.cm-s-mdn-like .CodeMirror-line::-moz-selection, .cm-s-mdn-like .CodeMirror-line > span::-moz-selection, .cm-s-mdn-like .CodeMirror-line > span > span::-moz-selection { background: #cfc; }

.cm-s-mdn-like .CodeMirror-gutters { background: #f8f8f8; border-left: 6px solid rgba(0,83,159,0.65); color: #333; }
.cm-s-mdn-like .CodeMirror-linenumber { color: #aaa; padding-left: 8px; }
.cm-s-mdn-like .CodeMirror-cursor { border-left: 2px solid #222; }

.cm-s-mdn-like .cm-keyword { color: #6262FF; }
.cm-s-mdn-like .cm-atom { color: #F90; }
.cm-s-mdn-like .cm-number { color:  #ca7841; }
.cm-s-mdn-like .cm-def { color: #8DA6CE; }
.cm-s-mdn-like span.cm-variable-2, .cm-s-mdn-like span.cm-tag { color: #690; }
.cm-s-mdn-like span.cm-variable-3, .cm-s-mdn-like span.cm-def, .cm-s-mdn-like span.cm-type { color: #07a; }

.cm-s-mdn-like .cm-variable { color: #07a; }
.cm-s-mdn-like .cm-property { color: #905; }
.cm-s-mdn-like .cm-qualifier { color: #690; }

.cm-s-mdn-like .cm-operator { color: #cda869; }
.cm-s-mdn-like .cm-comment { color:#777; font-weight:normal; }
.cm-s-mdn-like .cm-string { color:#07a; font-style:italic; }
.cm-s-mdn-like .cm-string-2 { color:#bd6b18; } /*?*/
.cm-s-mdn-like .cm-meta { color: #000; } /*?*/
.cm-s-mdn-like .cm-builtin { color: #9B7536; } /*?*/
.cm-s-mdn-like .cm-tag { color: #997643; }
.cm-s-mdn-like .cm-attribute { color: #d6bb6d; } /*?*/
.cm-s-mdn-like .cm-header { color: #FF6400; }
.cm-s-mdn-like .cm-hr { color: #AEAEAE; }
.cm-s-mdn-like .cm-link { color:#ad9361; font-style:italic; text-decoration:none; }
.cm-s-mdn-like .cm-error { border-bottom: 1px solid red; }

div.cm-s-mdn-like .CodeMirror-activeline-background { background: #efefff; }
div.cm-s-mdn-like span.CodeMirror-matchingbracket { outline:1px solid grey; color: inherit; }

.cm-s-mdn-like.CodeMirror { background-image: url(data:image/png;base64,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); }

/*

    Name:       seti
    Author:     Michael Kaminsky (http://github.com/mkaminsky11)

    Original seti color scheme by Jesse Weed (https://github.com/jesseweed/seti-syntax)

*/


.cm-s-seti.CodeMirror {
  background-color: #151718 !important;
  color: #CFD2D1 !important;
  border: none;
}
.cm-s-seti .CodeMirror-gutters {
  color: #404b53;
  background-color: #0E1112;
  border: none;
}
.cm-s-seti .CodeMirror-cursor { border-left: solid thin #f8f8f0; }
.cm-s-seti .CodeMirror-linenumber { color: #6D8A88; }
.cm-s-seti.CodeMirror-focused div.CodeMirror-selected { background: rgba(255, 255, 255, 0.10); }
.cm-s-seti .CodeMirror-line::selection, .cm-s-seti .CodeMirror-line > span::selection, .cm-s-seti .CodeMirror-line > span > span::selection { background: rgba(255, 255, 255, 0.10); }
.cm-s-seti .CodeMirror-line::-moz-selection, .cm-s-seti .CodeMirror-line > span::-moz-selection, .cm-s-seti .CodeMirror-line > span > span::-moz-selection { background: rgba(255, 255, 255, 0.10); }
.cm-s-seti span.cm-comment { color: #41535b; }
.cm-s-seti span.cm-string, .cm-s-seti span.cm-string-2 { color: #55b5db; }
.cm-s-seti span.cm-number { color: #cd3f45; }
.cm-s-seti span.cm-variable { color: #55b5db; }
.cm-s-seti span.cm-variable-2 { color: #a074c4; }
.cm-s-seti span.cm-def { color: #55b5db; }
.cm-s-seti span.cm-keyword { color: #ff79c6; }
.cm-s-seti span.cm-operator { color: #9fca56; }
.cm-s-seti span.cm-keyword { color: #e6cd69; }
.cm-s-seti span.cm-atom { color: #cd3f45; }
.cm-s-seti span.cm-meta { color: #55b5db; }
.cm-s-seti span.cm-tag { color: #55b5db; }
.cm-s-seti span.cm-attribute { color: #9fca56; }
.cm-s-seti span.cm-qualifier { color: #9fca56; }
.cm-s-seti span.cm-property { color: #a074c4; }
.cm-s-seti span.cm-variable-3, .cm-s-seti span.cm-type { color: #9fca56; }
.cm-s-seti span.cm-builtin { color: #9fca56; }
.cm-s-seti .CodeMirror-activeline-background { background: #101213; }
.cm-s-seti .CodeMirror-matchingbracket { text-decoration: underline; color: white !important; }

/*
Solarized theme for code-mirror
http://ethanschoonover.com/solarized
*/

/*
Solarized color palette
http://ethanschoonover.com/solarized/img/solarized-palette.png
*/

.solarized.base03 { color: #002b36; }
.solarized.base02 { color: #073642; }
.solarized.base01 { color: #586e75; }
.solarized.base00 { color: #657b83; }
.solarized.base0 { color: #839496; }
.solarized.base1 { color: #93a1a1; }
.solarized.base2 { color: #eee8d5; }
.solarized.base3  { color: #fdf6e3; }
.solarized.solar-yellow  { color: #b58900; }
.solarized.solar-orange  { color: #cb4b16; }
.solarized.solar-red { color: #dc322f; }
.solarized.solar-magenta { color: #d33682; }
.solarized.solar-violet  { color: #6c71c4; }
.solarized.solar-blue { color: #268bd2; }
.solarized.solar-cyan { color: #2aa198; }
.solarized.solar-green { color: #859900; }

/* Color scheme for code-mirror */

.cm-s-solarized {
  line-height: 1.45em;
  color-profile: sRGB;
  rendering-intent: auto;
}
.cm-s-solarized.cm-s-dark {
  color: #839496;
  background-color: #002b36;
  text-shadow: #002b36 0 1px;
}
.cm-s-solarized.cm-s-light {
  background-color: #fdf6e3;
  color: #657b83;
  text-shadow: #eee8d5 0 1px;
}

.cm-s-solarized .CodeMirror-widget {
  text-shadow: none;
}

.cm-s-solarized .cm-header { color: #586e75; }
.cm-s-solarized .cm-quote { color: #93a1a1; }

.cm-s-solarized .cm-keyword { color: #cb4b16; }
.cm-s-solarized .cm-atom { color: #d33682; }
.cm-s-solarized .cm-number { color: #d33682; }
.cm-s-solarized .cm-def { color: #2aa198; }

.cm-s-solarized .cm-variable { color: #839496; }
.cm-s-solarized .cm-variable-2 { color: #b58900; }
.cm-s-solarized .cm-variable-3, .cm-s-solarized .cm-type { color: #6c71c4; }

.cm-s-solarized .cm-property { color: #2aa198; }
.cm-s-solarized .cm-operator { color: #6c71c4; }

.cm-s-solarized .cm-comment { color: #586e75; font-style:italic; }

.cm-s-solarized .cm-string { color: #859900; }
.cm-s-solarized .cm-string-2 { color: #b58900; }

.cm-s-solarized .cm-meta { color: #859900; }
.cm-s-solarized .cm-qualifier { color: #b58900; }
.cm-s-solarized .cm-builtin { color: #d33682; }
.cm-s-solarized .cm-bracket { color: #cb4b16; }
.cm-s-solarized .CodeMirror-matchingbracket { color: #859900; }
.cm-s-solarized .CodeMirror-nonmatchingbracket { color: #dc322f; }
.cm-s-solarized .cm-tag { color: #93a1a1; }
.cm-s-solarized .cm-attribute { color: #2aa198; }
.cm-s-solarized .cm-hr {
  color: transparent;
  border-top: 1px solid #586e75;
  display: block;
}
.cm-s-solarized .cm-link { color: #93a1a1; cursor: pointer; }
.cm-s-solarized .cm-special { color: #6c71c4; }
.cm-s-solarized .cm-em {
  color: #999;
  text-decoration: underline;
  text-decoration-style: dotted;
}
.cm-s-solarized .cm-error,
.cm-s-solarized .cm-invalidchar {
  color: #586e75;
  border-bottom: 1px dotted #dc322f;
}

.cm-s-solarized.cm-s-dark div.CodeMirror-selected { background: #073642; }
.cm-s-solarized.cm-s-dark.CodeMirror ::selection { background: rgba(7, 54, 66, 0.99); }
.cm-s-solarized.cm-s-dark .CodeMirror-line::-moz-selection, .cm-s-dark .CodeMirror-line > span::-moz-selection, .cm-s-dark .CodeMirror-line > span > span::-moz-selection { background: rgba(7, 54, 66, 0.99); }

.cm-s-solarized.cm-s-light div.CodeMirror-selected { background: #eee8d5; }
.cm-s-solarized.cm-s-light .CodeMirror-line::selection, .cm-s-light .CodeMirror-line > span::selection, .cm-s-light .CodeMirror-line > span > span::selection { background: #eee8d5; }
.cm-s-solarized.cm-s-light .CodeMirror-line::-moz-selection, .cm-s-ligh .CodeMirror-line > span::-moz-selection, .cm-s-ligh .CodeMirror-line > span > span::-moz-selection { background: #eee8d5; }

/* Editor styling */



/* Little shadow on the view-port of the buffer view */
.cm-s-solarized.CodeMirror {
  -moz-box-shadow: inset 7px 0 12px -6px #000;
  -webkit-box-shadow: inset 7px 0 12px -6px #000;
  box-shadow: inset 7px 0 12px -6px #000;
}

/* Remove gutter border */
.cm-s-solarized .CodeMirror-gutters {
  border-right: 0;
}

/* Gutter colors and line number styling based of color scheme (dark / light) */

/* Dark */
.cm-s-solarized.cm-s-dark .CodeMirror-gutters {
  background-color: #073642;
}

.cm-s-solarized.cm-s-dark .CodeMirror-linenumber {
  color: #586e75;
  text-shadow: #021014 0 -1px;
}

/* Light */
.cm-s-solarized.cm-s-light .CodeMirror-gutters {
  background-color: #eee8d5;
}

.cm-s-solarized.cm-s-light .CodeMirror-linenumber {
  color: #839496;
}

/* Common */
.cm-s-solarized .CodeMirror-linenumber {
  padding: 0 5px;
}
.cm-s-solarized .CodeMirror-guttermarker-subtle { color: #586e75; }
.cm-s-solarized.cm-s-dark .CodeMirror-guttermarker { color: #ddd; }
.cm-s-solarized.cm-s-light .CodeMirror-guttermarker { color: #cb4b16; }

.cm-s-solarized .CodeMirror-gutter .CodeMirror-gutter-text {
  color: #586e75;
}

/* Cursor */
.cm-s-solarized .CodeMirror-cursor { border-left: 1px solid #819090; }

/* Fat cursor */
.cm-s-solarized.cm-s-light.cm-fat-cursor .CodeMirror-cursor { background: #77ee77; }
.cm-s-solarized.cm-s-light .cm-animate-fat-cursor { background-color: #77ee77; }
.cm-s-solarized.cm-s-dark.cm-fat-cursor .CodeMirror-cursor { background: #586e75; }
.cm-s-solarized.cm-s-dark .cm-animate-fat-cursor { background-color: #586e75; }

/* Active line */
.cm-s-solarized.cm-s-dark .CodeMirror-activeline-background {
  background: rgba(255, 255, 255, 0.06);
}
.cm-s-solarized.cm-s-light .CodeMirror-activeline-background {
  background: rgba(0, 0, 0, 0.06);
}

.cm-s-the-matrix.CodeMirror { background: #000000; color: #00FF00; }
.cm-s-the-matrix div.CodeMirror-selected { background: #2D2D2D; }
.cm-s-the-matrix .CodeMirror-line::selection, .cm-s-the-matrix .CodeMirror-line > span::selection, .cm-s-the-matrix .CodeMirror-line > span > span::selection { background: rgba(45, 45, 45, 0.99); }
.cm-s-the-matrix .CodeMirror-line::-moz-selection, .cm-s-the-matrix .CodeMirror-line > span::-moz-selection, .cm-s-the-matrix .CodeMirror-line > span > span::-moz-selection { background: rgba(45, 45, 45, 0.99); }
.cm-s-the-matrix .CodeMirror-gutters { background: #060; border-right: 2px solid #00FF00; }
.cm-s-the-matrix .CodeMirror-guttermarker { color: #0f0; }
.cm-s-the-matrix .CodeMirror-guttermarker-subtle { color: white; }
.cm-s-the-matrix .CodeMirror-linenumber { color: #FFFFFF; }
.cm-s-the-matrix .CodeMirror-cursor { border-left: 1px solid #00FF00; }

.cm-s-the-matrix span.cm-keyword { color: #008803; font-weight: bold; }
.cm-s-the-matrix span.cm-atom { color: #3FF; }
.cm-s-the-matrix span.cm-number { color: #FFB94F; }
.cm-s-the-matrix span.cm-def { color: #99C; }
.cm-s-the-matrix span.cm-variable { color: #F6C; }
.cm-s-the-matrix span.cm-variable-2 { color: #C6F; }
.cm-s-the-matrix span.cm-variable-3, .cm-s-the-matrix span.cm-type { color: #96F; }
.cm-s-the-matrix span.cm-property { color: #62FFA0; }
.cm-s-the-matrix span.cm-operator { color: #999; }
.cm-s-the-matrix span.cm-comment { color: #CCCCCC; }
.cm-s-the-matrix span.cm-string { color: #39C; }
.cm-s-the-matrix span.cm-meta { color: #C9F; }
.cm-s-the-matrix span.cm-qualifier { color: #FFF700; }
.cm-s-the-matrix span.cm-builtin { color: #30a; }
.cm-s-the-matrix span.cm-bracket { color: #cc7; }
.cm-s-the-matrix span.cm-tag { color: #FFBD40; }
.cm-s-the-matrix span.cm-attribute { color: #FFF700; }
.cm-s-the-matrix span.cm-error { color: #FF0000; }

.cm-s-the-matrix .CodeMirror-activeline-background { background: #040; }

/*
Copyright (C) 2011 by MarkLogic Corporation
Author: Mike Brevoort <mike@brevoort.com>

Permission is hereby granted, free of charge, to any person obtaining a copy
of this software and associated documentation files (the "Software"), to deal
in the Software without restriction, including without limitation the rights
to use, copy, modify, merge, publish, distribute, sublicense, and/or sell
copies of the Software, and to permit persons to whom the Software is
furnished to do so, subject to the following conditions:

The above copyright notice and this permission notice shall be included in
all copies or substantial portions of the Software.

THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,
OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN
THE SOFTWARE.
*/
.cm-s-xq-light span.cm-keyword { line-height: 1em; font-weight: bold; color: #5A5CAD; }
.cm-s-xq-light span.cm-atom { color: #6C8CD5; }
.cm-s-xq-light span.cm-number { color: #164; }
.cm-s-xq-light span.cm-def { text-decoration:underline; }
.cm-s-xq-light span.cm-variable { color: black; }
.cm-s-xq-light span.cm-variable-2 { color:black; }
.cm-s-xq-light span.cm-variable-3, .cm-s-xq-light span.cm-type { color: black; }
.cm-s-xq-light span.cm-property {}
.cm-s-xq-light span.cm-operator {}
.cm-s-xq-light span.cm-comment { color: #0080FF; font-style: italic; }
.cm-s-xq-light span.cm-string { color: red; }
.cm-s-xq-light span.cm-meta { color: yellow; }
.cm-s-xq-light span.cm-qualifier { color: grey; }
.cm-s-xq-light span.cm-builtin { color: #7EA656; }
.cm-s-xq-light span.cm-bracket { color: #cc7; }
.cm-s-xq-light span.cm-tag { color: #3F7F7F; }
.cm-s-xq-light span.cm-attribute { color: #7F007F; }
.cm-s-xq-light span.cm-error { color: #f00; }

.cm-s-xq-light .CodeMirror-activeline-background { background: #e8f2ff; }
.cm-s-xq-light .CodeMirror-matchingbracket { outline:1px solid grey;color:black !important;background:yellow; }

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

.CodeMirror {
  line-height: var(--jp-code-line-height);
  font-size: var(--jp-code-font-size);
  font-family: var(--jp-code-font-family);
  border: 0;
  border-radius: 0;
  height: auto;
  /* Changed to auto to autogrow */
}

.CodeMirror pre {
  padding: 0 var(--jp-code-padding);
}

.jp-CodeMirrorEditor[data-type='inline'] .CodeMirror-dialog {
  background-color: var(--jp-layout-color0);
  color: var(--jp-content-font-color1);
}

/* This causes https://github.com/jupyter/jupyterlab/issues/522 */
/* May not cause it not because we changed it! */
.CodeMirror-lines {
  padding: var(--jp-code-padding) 0;
}

.CodeMirror-linenumber {
  padding: 0 8px;
}

.jp-CodeMirrorEditor-static {
  margin: var(--jp-code-padding);
}

.jp-CodeMirrorEditor,
.jp-CodeMirrorEditor-static {
  cursor: text;
}

.jp-CodeMirrorEditor[data-type='inline'] .CodeMirror-cursor {
  border-left: var(--jp-code-cursor-width0) solid var(--jp-editor-cursor-color);
}

/* When zoomed out 67% and 33% on a screen of 1440 width x 900 height */
@media screen and (min-width: 2138px) and (max-width: 4319px) {
  .jp-CodeMirrorEditor[data-type='inline'] .CodeMirror-cursor {
    border-left: var(--jp-code-cursor-width1) solid
      var(--jp-editor-cursor-color);
  }
}

/* When zoomed out less than 33% */
@media screen and (min-width: 4320px) {
  .jp-CodeMirrorEditor[data-type='inline'] .CodeMirror-cursor {
    border-left: var(--jp-code-cursor-width2) solid
      var(--jp-editor-cursor-color);
  }
}

.CodeMirror.jp-mod-readOnly .CodeMirror-cursor {
  display: none;
}

.CodeMirror-gutters {
  border-right: 1px solid var(--jp-border-color2);
  background-color: var(--jp-layout-color0);
}

.jp-CollaboratorCursor {
  border-left: 5px solid transparent;
  border-right: 5px solid transparent;
  border-top: none;
  border-bottom: 3px solid;
  background-clip: content-box;
  margin-left: -5px;
  margin-right: -5px;
}

.CodeMirror-selectedtext.cm-searching {
  background-color: var(--jp-search-selected-match-background-color) !important;
  color: var(--jp-search-selected-match-color) !important;
}

.cm-searching {
  background-color: var(
    --jp-search-unselected-match-background-color
  ) !important;
  color: var(--jp-search-unselected-match-color) !important;
}

.CodeMirror-focused .CodeMirror-selected {
  background-color: var(--jp-editor-selected-focused-background);
}

.CodeMirror-selected {
  background-color: var(--jp-editor-selected-background);
}

.jp-CollaboratorCursor-hover {
  position: absolute;
  z-index: 1;
  transform: translateX(-50%);
  color: white;
  border-radius: 3px;
  padding-left: 4px;
  padding-right: 4px;
  padding-top: 1px;
  padding-bottom: 1px;
  text-align: center;
  font-size: var(--jp-ui-font-size1);
  white-space: nowrap;
}

.jp-CodeMirror-ruler {
  border-left: 1px dashed var(--jp-border-color2);
}

/**
 * Here is our jupyter theme for CodeMirror syntax highlighting
 * This is used in our marked.js syntax highlighting and CodeMirror itself
 * The string "jupyter" is set in ../codemirror/widget.DEFAULT_CODEMIRROR_THEME
 * This came from the classic notebook, which came form highlight.js/GitHub
 */

/**
 * CodeMirror themes are handling the background/color in this way. This works
 * fine for CodeMirror editors outside the notebook, but the notebook styles
 * these things differently.
 */
.CodeMirror.cm-s-jupyter {
  background: var(--jp-layout-color0);
  color: var(--jp-content-font-color1);
}

/* In the notebook, we want this styling to be handled by its container */
.jp-CodeConsole .CodeMirror.cm-s-jupyter,
.jp-Notebook .CodeMirror.cm-s-jupyter {
  background: transparent;
}

.cm-s-jupyter .CodeMirror-cursor {
  border-left: var(--jp-code-cursor-width0) solid var(--jp-editor-cursor-color);
}
.cm-s-jupyter span.cm-keyword {
  color: var(--jp-mirror-editor-keyword-color);
  font-weight: bold;
}
.cm-s-jupyter span.cm-atom {
  color: var(--jp-mirror-editor-atom-color);
}
.cm-s-jupyter span.cm-number {
  color: var(--jp-mirror-editor-number-color);
}
.cm-s-jupyter span.cm-def {
  color: var(--jp-mirror-editor-def-color);
}
.cm-s-jupyter span.cm-variable {
  color: var(--jp-mirror-editor-variable-color);
}
.cm-s-jupyter span.cm-variable-2 {
  color: var(--jp-mirror-editor-variable-2-color);
}
.cm-s-jupyter span.cm-variable-3 {
  color: var(--jp-mirror-editor-variable-3-color);
}
.cm-s-jupyter span.cm-punctuation {
  color: var(--jp-mirror-editor-punctuation-color);
}
.cm-s-jupyter span.cm-property {
  color: var(--jp-mirror-editor-property-color);
}
.cm-s-jupyter span.cm-operator {
  color: var(--jp-mirror-editor-operator-color);
  font-weight: bold;
}
.cm-s-jupyter span.cm-comment {
  color: var(--jp-mirror-editor-comment-color);
  font-style: italic;
}
.cm-s-jupyter span.cm-string {
  color: var(--jp-mirror-editor-string-color);
}
.cm-s-jupyter span.cm-string-2 {
  color: var(--jp-mirror-editor-string-2-color);
}
.cm-s-jupyter span.cm-meta {
  color: var(--jp-mirror-editor-meta-color);
}
.cm-s-jupyter span.cm-qualifier {
  color: var(--jp-mirror-editor-qualifier-color);
}
.cm-s-jupyter span.cm-builtin {
  color: var(--jp-mirror-editor-builtin-color);
}
.cm-s-jupyter span.cm-bracket {
  color: var(--jp-mirror-editor-bracket-color);
}
.cm-s-jupyter span.cm-tag {
  color: var(--jp-mirror-editor-tag-color);
}
.cm-s-jupyter span.cm-attribute {
  color: var(--jp-mirror-editor-attribute-color);
}
.cm-s-jupyter span.cm-header {
  color: var(--jp-mirror-editor-header-color);
}
.cm-s-jupyter span.cm-quote {
  color: var(--jp-mirror-editor-quote-color);
}
.cm-s-jupyter span.cm-link {
  color: var(--jp-mirror-editor-link-color);
}
.cm-s-jupyter span.cm-error {
  color: var(--jp-mirror-editor-error-color);
}
.cm-s-jupyter span.cm-hr {
  color: #999;
}

.cm-s-jupyter span.cm-tab {
  background: url(data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAADAAAAAMCAYAAAAkuj5RAAAAAXNSR0IArs4c6QAAAGFJREFUSMft1LsRQFAQheHPowAKoACx3IgEKtaEHujDjORSgWTH/ZOdnZOcM/sgk/kFFWY0qV8foQwS4MKBCS3qR6ixBJvElOobYAtivseIE120FaowJPN75GMu8j/LfMwNjh4HUpwg4LUAAAAASUVORK5CYII=);
  background-position: right;
  background-repeat: no-repeat;
}

.cm-s-jupyter .CodeMirror-activeline-background,
.cm-s-jupyter .CodeMirror-gutter {
  background-color: var(--jp-layout-color2);
}

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

/* This file was auto-generated by ensurePackage() in @jupyterlab/buildutils */

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------
| RenderedText
|----------------------------------------------------------------------------*/

.jp-RenderedText {
  text-align: left;
  padding-left: var(--jp-code-padding);
  line-height: var(--jp-code-line-height);
  font-family: var(--jp-code-font-family);
}

.jp-RenderedText pre,
.jp-RenderedJavaScript pre,
.jp-RenderedHTMLCommon pre {
  color: var(--jp-content-font-color1);
  font-size: var(--jp-code-font-size);
  border: none;
  margin: 0px;
  padding: 0px;
  line-height: normal;
}

.jp-RenderedText pre a:link {
  text-decoration: none;
  color: var(--jp-content-link-color);
}
.jp-RenderedText pre a:hover {
  text-decoration: underline;
  color: var(--jp-content-link-color);
}
.jp-RenderedText pre a:visited {
  text-decoration: none;
  color: var(--jp-content-link-color);
}

/* console foregrounds and backgrounds */
.jp-RenderedText pre .ansi-black-fg {
  color: #3e424d;
}
.jp-RenderedText pre .ansi-red-fg {
  color: #e75c58;
}
.jp-RenderedText pre .ansi-green-fg {
  color: #00a250;
}
.jp-RenderedText pre .ansi-yellow-fg {
  color: #ddb62b;
}
.jp-RenderedText pre .ansi-blue-fg {
  color: #208ffb;
}
.jp-RenderedText pre .ansi-magenta-fg {
  color: #d160c4;
}
.jp-RenderedText pre .ansi-cyan-fg {
  color: #60c6c8;
}
.jp-RenderedText pre .ansi-white-fg {
  color: #c5c1b4;
}

.jp-RenderedText pre .ansi-black-bg {
  background-color: #3e424d;
}
.jp-RenderedText pre .ansi-red-bg {
  background-color: #e75c58;
}
.jp-RenderedText pre .ansi-green-bg {
  background-color: #00a250;
}
.jp-RenderedText pre .ansi-yellow-bg {
  background-color: #ddb62b;
}
.jp-RenderedText pre .ansi-blue-bg {
  background-color: #208ffb;
}
.jp-RenderedText pre .ansi-magenta-bg {
  background-color: #d160c4;
}
.jp-RenderedText pre .ansi-cyan-bg {
  background-color: #60c6c8;
}
.jp-RenderedText pre .ansi-white-bg {
  background-color: #c5c1b4;
}

.jp-RenderedText pre .ansi-black-intense-fg {
  color: #282c36;
}
.jp-RenderedText pre .ansi-red-intense-fg {
  color: #b22b31;
}
.jp-RenderedText pre .ansi-green-intense-fg {
  color: #007427;
}
.jp-RenderedText pre .ansi-yellow-intense-fg {
  color: #b27d12;
}
.jp-RenderedText pre .ansi-blue-intense-fg {
  color: #0065ca;
}
.jp-RenderedText pre .ansi-magenta-intense-fg {
  color: #a03196;
}
.jp-RenderedText pre .ansi-cyan-intense-fg {
  color: #258f8f;
}
.jp-RenderedText pre .ansi-white-intense-fg {
  color: #a1a6b2;
}

.jp-RenderedText pre .ansi-black-intense-bg {
  background-color: #282c36;
}
.jp-RenderedText pre .ansi-red-intense-bg {
  background-color: #b22b31;
}
.jp-RenderedText pre .ansi-green-intense-bg {
  background-color: #007427;
}
.jp-RenderedText pre .ansi-yellow-intense-bg {
  background-color: #b27d12;
}
.jp-RenderedText pre .ansi-blue-intense-bg {
  background-color: #0065ca;
}
.jp-RenderedText pre .ansi-magenta-intense-bg {
  background-color: #a03196;
}
.jp-RenderedText pre .ansi-cyan-intense-bg {
  background-color: #258f8f;
}
.jp-RenderedText pre .ansi-white-intense-bg {
  background-color: #a1a6b2;
}

.jp-RenderedText pre .ansi-default-inverse-fg {
  color: var(--jp-ui-inverse-font-color0);
}
.jp-RenderedText pre .ansi-default-inverse-bg {
  background-color: var(--jp-inverse-layout-color0);
}

.jp-RenderedText pre .ansi-bold {
  font-weight: bold;
}
.jp-RenderedText pre .ansi-underline {
  text-decoration: underline;
}

.jp-RenderedText[data-mime-type='application/vnd.jupyter.stderr'] {
  background: var(--jp-rendermime-error-background);
  padding-top: var(--jp-code-padding);
}

/*-----------------------------------------------------------------------------
| RenderedLatex
|----------------------------------------------------------------------------*/

.jp-RenderedLatex {
  color: var(--jp-content-font-color1);
  font-size: var(--jp-content-font-size1);
  line-height: var(--jp-content-line-height);
}

/* Left-justify outputs.*/
.jp-OutputArea-output.jp-RenderedLatex {
  padding: var(--jp-code-padding);
  text-align: left;
}

/*-----------------------------------------------------------------------------
| RenderedHTML
|----------------------------------------------------------------------------*/

.jp-RenderedHTMLCommon {
  color: var(--jp-content-font-color1);
  font-family: var(--jp-content-font-family);
  font-size: var(--jp-content-font-size1);
  line-height: var(--jp-content-line-height);
  /* Give a bit more R padding on Markdown text to keep line lengths reasonable */
  padding-right: 20px;
}

.jp-RenderedHTMLCommon em {
  font-style: italic;
}

.jp-RenderedHTMLCommon strong {
  font-weight: bold;
}

.jp-RenderedHTMLCommon u {
  text-decoration: underline;
}

.jp-RenderedHTMLCommon a:link {
  text-decoration: none;
  color: var(--jp-content-link-color);
}

.jp-RenderedHTMLCommon a:hover {
  text-decoration: underline;
  color: var(--jp-content-link-color);
}

.jp-RenderedHTMLCommon a:visited {
  text-decoration: none;
  color: var(--jp-content-link-color);
}

/* Headings */

.jp-RenderedHTMLCommon h1,
.jp-RenderedHTMLCommon h2,
.jp-RenderedHTMLCommon h3,
.jp-RenderedHTMLCommon h4,
.jp-RenderedHTMLCommon h5,
.jp-RenderedHTMLCommon h6 {
  line-height: var(--jp-content-heading-line-height);
  font-weight: var(--jp-content-heading-font-weight);
  font-style: normal;
  margin: var(--jp-content-heading-margin-top) 0
    var(--jp-content-heading-margin-bottom) 0;
}

.jp-RenderedHTMLCommon h1:first-child,
.jp-RenderedHTMLCommon h2:first-child,
.jp-RenderedHTMLCommon h3:first-child,
.jp-RenderedHTMLCommon h4:first-child,
.jp-RenderedHTMLCommon h5:first-child,
.jp-RenderedHTMLCommon h6:first-child {
  margin-top: calc(0.5 * var(--jp-content-heading-margin-top));
}

.jp-RenderedHTMLCommon h1:last-child,
.jp-RenderedHTMLCommon h2:last-child,
.jp-RenderedHTMLCommon h3:last-child,
.jp-RenderedHTMLCommon h4:last-child,
.jp-RenderedHTMLCommon h5:last-child,
.jp-RenderedHTMLCommon h6:last-child {
  margin-bottom: calc(0.5 * var(--jp-content-heading-margin-bottom));
}

.jp-RenderedHTMLCommon h1 {
  font-size: var(--jp-content-font-size5);
}

.jp-RenderedHTMLCommon h2 {
  font-size: var(--jp-content-font-size4);
}

.jp-RenderedHTMLCommon h3 {
  font-size: var(--jp-content-font-size3);
}

.jp-RenderedHTMLCommon h4 {
  font-size: var(--jp-content-font-size2);
}

.jp-RenderedHTMLCommon h5 {
  font-size: var(--jp-content-font-size1);
}

.jp-RenderedHTMLCommon h6 {
  font-size: var(--jp-content-font-size0);
}

/* Lists */

.jp-RenderedHTMLCommon ul:not(.list-inline),
.jp-RenderedHTMLCommon ol:not(.list-inline) {
  padding-left: 2em;
}

.jp-RenderedHTMLCommon ul {
  list-style: disc;
}

.jp-RenderedHTMLCommon ul ul {
  list-style: square;
}

.jp-RenderedHTMLCommon ul ul ul {
  list-style: circle;
}

.jp-RenderedHTMLCommon ol {
  list-style: decimal;
}

.jp-RenderedHTMLCommon ol ol {
  list-style: upper-alpha;
}

.jp-RenderedHTMLCommon ol ol ol {
  list-style: lower-alpha;
}

.jp-RenderedHTMLCommon ol ol ol ol {
  list-style: lower-roman;
}

.jp-RenderedHTMLCommon ol ol ol ol ol {
  list-style: decimal;
}

.jp-RenderedHTMLCommon ol,
.jp-RenderedHTMLCommon ul {
  margin-bottom: 1em;
}

.jp-RenderedHTMLCommon ul ul,
.jp-RenderedHTMLCommon ul ol,
.jp-RenderedHTMLCommon ol ul,
.jp-RenderedHTMLCommon ol ol {
  margin-bottom: 0em;
}

.jp-RenderedHTMLCommon hr {
  color: var(--jp-border-color2);
  background-color: var(--jp-border-color1);
  margin-top: 1em;
  margin-bottom: 1em;
}

.jp-RenderedHTMLCommon > pre {
  margin: 1.5em 2em;
}

.jp-RenderedHTMLCommon pre,
.jp-RenderedHTMLCommon code {
  border: 0;
  background-color: var(--jp-layout-color0);
  color: var(--jp-content-font-color1);
  font-family: var(--jp-code-font-family);
  font-size: inherit;
  line-height: var(--jp-code-line-height);
  padding: 0;
  white-space: pre-wrap;
}

.jp-RenderedHTMLCommon :not(pre) > code {
  background-color: var(--jp-layout-color2);
  padding: 1px 5px;
}

/* Tables */

.jp-RenderedHTMLCommon table {
  border-collapse: collapse;
  border-spacing: 0;
  border: none;
  color: var(--jp-ui-font-color1);
  font-size: 12px;
  table-layout: fixed;
  margin-left: auto;
  margin-right: auto;
}

.jp-RenderedHTMLCommon thead {
  border-bottom: var(--jp-border-width) solid var(--jp-border-color1);
  vertical-align: bottom;
}

.jp-RenderedHTMLCommon td,
.jp-RenderedHTMLCommon th,
.jp-RenderedHTMLCommon tr {
  vertical-align: middle;
  padding: 0.5em 0.5em;
  line-height: normal;
  white-space: normal;
  max-width: none;
  border: none;
}

.jp-RenderedMarkdown.jp-RenderedHTMLCommon td,
.jp-RenderedMarkdown.jp-RenderedHTMLCommon th {
  max-width: none;
}

:not(.jp-RenderedMarkdown).jp-RenderedHTMLCommon td,
:not(.jp-RenderedMarkdown).jp-RenderedHTMLCommon th,
:not(.jp-RenderedMarkdown).jp-RenderedHTMLCommon tr {
  text-align: right;
}

.jp-RenderedHTMLCommon th {
  font-weight: bold;
}

.jp-RenderedHTMLCommon tbody tr:nth-child(odd) {
  background: var(--jp-layout-color0);
}

.jp-RenderedHTMLCommon tbody tr:nth-child(even) {
  background: var(--jp-rendermime-table-row-background);
}

.jp-RenderedHTMLCommon tbody tr:hover {
  background: var(--jp-rendermime-table-row-hover-background);
}

.jp-RenderedHTMLCommon table {
  margin-bottom: 1em;
}

.jp-RenderedHTMLCommon p {
  text-align: left;
  margin: 0px;
}

.jp-RenderedHTMLCommon p {
  margin-bottom: 1em;
}

.jp-RenderedHTMLCommon img {
  -moz-force-broken-image-icon: 1;
}

/* Restrict to direct children as other images could be nested in other content. */
.jp-RenderedHTMLCommon > img {
  display: block;
  margin-left: 0;
  margin-right: 0;
  margin-bottom: 1em;
}

/* Change color behind transparent images if they need it... */
[data-jp-theme-light='false'] .jp-RenderedImage img.jp-needs-light-background {
  background-color: var(--jp-inverse-layout-color1);
}
[data-jp-theme-light='true'] .jp-RenderedImage img.jp-needs-dark-background {
  background-color: var(--jp-inverse-layout-color1);
}
/* ...or leave it untouched if they don't */
[data-jp-theme-light='false'] .jp-RenderedImage img.jp-needs-dark-background {
}
[data-jp-theme-light='true'] .jp-RenderedImage img.jp-needs-light-background {
}

.jp-RenderedHTMLCommon img,
.jp-RenderedImage img,
.jp-RenderedHTMLCommon svg,
.jp-RenderedSVG svg {
  max-width: 100%;
  height: auto;
}

.jp-RenderedHTMLCommon img.jp-mod-unconfined,
.jp-RenderedImage img.jp-mod-unconfined,
.jp-RenderedHTMLCommon svg.jp-mod-unconfined,
.jp-RenderedSVG svg.jp-mod-unconfined {
  max-width: none;
}

.jp-RenderedHTMLCommon .alert {
  padding: var(--jp-notebook-padding);
  border: var(--jp-border-width) solid transparent;
  border-radius: var(--jp-border-radius);
  margin-bottom: 1em;
}

.jp-RenderedHTMLCommon .alert-info {
  color: var(--jp-info-color0);
  background-color: var(--jp-info-color3);
  border-color: var(--jp-info-color2);
}
.jp-RenderedHTMLCommon .alert-info hr {
  border-color: var(--jp-info-color3);
}
.jp-RenderedHTMLCommon .alert-info > p:last-child,
.jp-RenderedHTMLCommon .alert-info > ul:last-child {
  margin-bottom: 0;
}

.jp-RenderedHTMLCommon .alert-warning {
  color: var(--jp-warn-color0);
  background-color: var(--jp-warn-color3);
  border-color: var(--jp-warn-color2);
}
.jp-RenderedHTMLCommon .alert-warning hr {
  border-color: var(--jp-warn-color3);
}
.jp-RenderedHTMLCommon .alert-warning > p:last-child,
.jp-RenderedHTMLCommon .alert-warning > ul:last-child {
  margin-bottom: 0;
}

.jp-RenderedHTMLCommon .alert-success {
  color: var(--jp-success-color0);
  background-color: var(--jp-success-color3);
  border-color: var(--jp-success-color2);
}
.jp-RenderedHTMLCommon .alert-success hr {
  border-color: var(--jp-success-color3);
}
.jp-RenderedHTMLCommon .alert-success > p:last-child,
.jp-RenderedHTMLCommon .alert-success > ul:last-child {
  margin-bottom: 0;
}

.jp-RenderedHTMLCommon .alert-danger {
  color: var(--jp-error-color0);
  background-color: var(--jp-error-color3);
  border-color: var(--jp-error-color2);
}
.jp-RenderedHTMLCommon .alert-danger hr {
  border-color: var(--jp-error-color3);
}
.jp-RenderedHTMLCommon .alert-danger > p:last-child,
.jp-RenderedHTMLCommon .alert-danger > ul:last-child {
  margin-bottom: 0;
}

.jp-RenderedHTMLCommon blockquote {
  margin: 1em 2em;
  padding: 0 1em;
  border-left: 5px solid var(--jp-border-color2);
}

a.jp-InternalAnchorLink {
  visibility: hidden;
  margin-left: 8px;
  color: var(--md-blue-800);
}

h1:hover .jp-InternalAnchorLink,
h2:hover .jp-InternalAnchorLink,
h3:hover .jp-InternalAnchorLink,
h4:hover .jp-InternalAnchorLink,
h5:hover .jp-InternalAnchorLink,
h6:hover .jp-InternalAnchorLink {
  visibility: visible;
}

.jp-RenderedHTMLCommon kbd {
  background-color: var(--jp-rendermime-table-row-background);
  border: 1px solid var(--jp-border-color0);
  border-bottom-color: var(--jp-border-color2);
  border-radius: 3px;
  box-shadow: inset 0 -1px 0 rgba(0, 0, 0, 0.25);
  display: inline-block;
  font-size: 0.8em;
  line-height: 1em;
  padding: 0.2em 0.5em;
}

/* Most direct children of .jp-RenderedHTMLCommon have a margin-bottom of 1.0.
 * At the bottom of cells this is a bit too much as there is also spacing
 * between cells. Going all the way to 0 gets too tight between markdown and
 * code cells.
 */
.jp-RenderedHTMLCommon > *:last-child {
  margin-bottom: 0.5em;
}

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

/* This file was auto-generated by ensurePackage() in @jupyterlab/buildutils */

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

.jp-MimeDocument {
  outline: none;
}

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

/* This file was auto-generated by ensurePackage() in @jupyterlab/buildutils */

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------
| Variables
|----------------------------------------------------------------------------*/

:root {
  --jp-private-filebrowser-button-height: 28px;
  --jp-private-filebrowser-button-width: 48px;
}

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

.jp-FileBrowser {
  display: flex;
  flex-direction: column;
  color: var(--jp-ui-font-color1);
  background: var(--jp-layout-color1);
  /* This is needed so that all font sizing of children done in ems is
   * relative to this base size */
  font-size: var(--jp-ui-font-size1);
}

.jp-FileBrowser-toolbar.jp-Toolbar {
  border-bottom: none;
  height: auto;
  margin: var(--jp-toolbar-header-margin);
  box-shadow: none;
}

.jp-BreadCrumbs {
  flex: 0 0 auto;
  margin: 4px 12px;
}

.jp-BreadCrumbs-item {
  margin: 0px 2px;
  padding: 0px 2px;
  border-radius: var(--jp-border-radius);
  cursor: pointer;
}

.jp-BreadCrumbs-item:hover {
  background-color: var(--jp-layout-color2);
}

.jp-BreadCrumbs-item:first-child {
  margin-left: 0px;
}

.jp-BreadCrumbs-item.jp-mod-dropTarget {
  background-color: var(--jp-brand-color2);
  opacity: 0.7;
}

/*-----------------------------------------------------------------------------
| Buttons
|----------------------------------------------------------------------------*/

.jp-FileBrowser-toolbar.jp-Toolbar {
  padding: 0px;
}

.jp-FileBrowser-toolbar.jp-Toolbar {
  justify-content: space-evenly;
}

.jp-FileBrowser-toolbar.jp-Toolbar .jp-Toolbar-item {
  flex: 1;
}

.jp-FileBrowser-toolbar.jp-Toolbar .jp-ToolbarButtonComponent {
  width: 100%;
}

/*-----------------------------------------------------------------------------
| DirListing
|----------------------------------------------------------------------------*/

.jp-DirListing {
  flex: 1 1 auto;
  display: flex;
  flex-direction: column;
  outline: 0;
}

.jp-DirListing-header {
  flex: 0 0 auto;
  display: flex;
  flex-direction: row;
  overflow: hidden;
  border-top: var(--jp-border-width) solid var(--jp-border-color2);
  border-bottom: var(--jp-border-width) solid var(--jp-border-color1);
  box-shadow: var(--jp-toolbar-box-shadow);
  z-index: 2;
}

.jp-DirListing-headerItem {
  padding: 4px 12px 2px 12px;
  font-weight: 500;
}

.jp-DirListing-headerItem:hover {
  background: var(--jp-layout-color2);
}

.jp-DirListing-headerItem.jp-id-name {
  flex: 1 0 84px;
}

.jp-DirListing-headerItem.jp-id-modified {
  flex: 0 0 112px;
  border-left: var(--jp-border-width) solid var(--jp-border-color2);
  text-align: right;
}

.jp-DirListing-narrow .jp-id-modified,
.jp-DirListing-narrow .jp-DirListing-itemModified {
  display: none;
}

.jp-DirListing-headerItem.jp-mod-selected {
  font-weight: 600;
}

/* increase specificity to override bundled default */
.jp-DirListing-content {
  flex: 1 1 auto;
  margin: 0;
  padding: 0;
  list-style-type: none;
  overflow: auto;
  background-color: var(--jp-layout-color1);
}

/* Style the directory listing content when a user drops a file to upload */
.jp-DirListing.jp-mod-native-drop .jp-DirListing-content {
  outline: 5px dashed rgba(128, 128, 128, 0.5);
  outline-offset: -10px;
  cursor: copy;
}

.jp-DirListing-item {
  display: flex;
  flex-direction: row;
  padding: 4px 12px;
  -webkit-user-select: none;
  -moz-user-select: none;
  -ms-user-select: none;
  user-select: none;
}

.jp-DirListing-item.jp-mod-selected {
  color: white;
  background: var(--jp-brand-color1);
}

.jp-DirListing-item.jp-mod-dropTarget {
  background: var(--jp-brand-color3);
}

.jp-DirListing-item:hover:not(.jp-mod-selected) {
  background: var(--jp-layout-color2);
}

.jp-DirListing-itemIcon {
  flex: 0 0 20px;
  margin-right: 4px;
}

.jp-DirListing-itemText {
  flex: 1 0 64px;
  white-space: nowrap;
  overflow: hidden;
  text-overflow: ellipsis;
  user-select: none;
}

.jp-DirListing-itemModified {
  flex: 0 0 125px;
  text-align: right;
}

.jp-DirListing-editor {
  flex: 1 0 64px;
  outline: none;
  border: none;
}

.jp-DirListing-item.jp-mod-running .jp-DirListing-itemIcon:before {
  color: limegreen;
  content: '\25CF';
  font-size: 8px;
  position: absolute;
  left: -8px;
}

.jp-DirListing-item.lm-mod-drag-image,
.jp-DirListing-item.jp-mod-selected.lm-mod-drag-image {
  font-size: var(--jp-ui-font-size1);
  padding-left: 4px;
  margin-left: 4px;
  width: 160px;
  background-color: var(--jp-ui-inverse-font-color2);
  box-shadow: var(--jp-elevation-z2);
  border-radius: 0px;
  color: var(--jp-ui-font-color1);
  transform: translateX(-40%) translateY(-58%);
}

.jp-DirListing-deadSpace {
  flex: 1 1 auto;
  margin: 0;
  padding: 0;
  list-style-type: none;
  overflow: auto;
  background-color: var(--jp-layout-color1);
}

.jp-Document {
  min-width: 120px;
  min-height: 120px;
  outline: none;
}

.jp-FileDialog.jp-mod-conflict input {
  color: red;
}

.jp-FileDialog .jp-new-name-title {
  margin-top: 12px;
}

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

/* This file was auto-generated by ensurePackage() in @jupyterlab/buildutils */

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------
| Private CSS variables
|----------------------------------------------------------------------------*/

:root {
}

/*-----------------------------------------------------------------------------
| Main OutputArea
| OutputArea has a list of Outputs
|----------------------------------------------------------------------------*/

.jp-OutputArea {
  overflow-y: auto;
}

.jp-OutputArea-child {
  display: flex;
  flex-direction: row;
}

.jp-OutputPrompt {
  flex: 0 0 var(--jp-cell-prompt-width);
  color: var(--jp-cell-outprompt-font-color);
  font-family: var(--jp-cell-prompt-font-family);
  padding: var(--jp-code-padding);
  letter-spacing: var(--jp-cell-prompt-letter-spacing);
  line-height: var(--jp-code-line-height);
  font-size: var(--jp-code-font-size);
  border: var(--jp-border-width) solid transparent;
  opacity: var(--jp-cell-prompt-opacity);
  /* Right align prompt text, don't wrap to handle large prompt numbers */
  text-align: right;
  white-space: nowrap;
  overflow: hidden;
  text-overflow: ellipsis;
  /* Disable text selection */
  -webkit-user-select: none;
  -moz-user-select: none;
  -ms-user-select: none;
  user-select: none;
}

.jp-OutputArea-output {
  height: auto;
  overflow: auto;
  user-select: text;
  -moz-user-select: text;
  -webkit-user-select: text;
  -ms-user-select: text;
}

.jp-OutputArea-child .jp-OutputArea-output {
  flex-grow: 1;
  flex-shrink: 1;
}

/**
 * Isolated output.
 */
.jp-OutputArea-output.jp-mod-isolated {
  width: 100%;
  display: block;
}

/*
When drag events occur, `p-mod-override-cursor` is added to the body.
Because iframes steal all cursor events, the following two rules are necessary
to suppress pointer events while resize drags are occurring. There may be a
better solution to this problem.
*/
body.lm-mod-override-cursor .jp-OutputArea-output.jp-mod-isolated {
  position: relative;
}

body.lm-mod-override-cursor .jp-OutputArea-output.jp-mod-isolated:before {
  content: '';
  position: absolute;
  top: 0;
  left: 0;
  right: 0;
  bottom: 0;
  background: transparent;
}

/* pre */

.jp-OutputArea-output pre {
  border: none;
  margin: 0px;
  padding: 0px;
  overflow-x: auto;
  overflow-y: auto;
  word-break: break-all;
  word-wrap: break-word;
  white-space: pre-wrap;
}

/* tables */

.jp-OutputArea-output.jp-RenderedHTMLCommon table {
  margin-left: 0;
  margin-right: 0;
}

/* description lists */

.jp-OutputArea-output dl,
.jp-OutputArea-output dt,
.jp-OutputArea-output dd {
  display: block;
}

.jp-OutputArea-output dl {
  width: 100%;
  overflow: hidden;
  padding: 0;
  margin: 0;
}

.jp-OutputArea-output dt {
  font-weight: bold;
  float: left;
  width: 20%;
  padding: 0;
  margin: 0;
}

.jp-OutputArea-output dd {
  float: left;
  width: 80%;
  padding: 0;
  margin: 0;
}

/* Hide the gutter in case of
 *  - nested output areas (e.g. in the case of output widgets)
 *  - mirrored output areas
 */
.jp-OutputArea .jp-OutputArea .jp-OutputArea-prompt {
  display: none;
}

/*-----------------------------------------------------------------------------
| executeResult is added to any Output-result for the display of the object
| returned by a cell
|----------------------------------------------------------------------------*/

.jp-OutputArea-output.jp-OutputArea-executeResult {
  margin-left: 0px;
  flex: 1 1 auto;
}

.jp-OutputArea-executeResult.jp-RenderedText {
  padding-top: var(--jp-code-padding);
}

/*-----------------------------------------------------------------------------
| The Stdin output
|----------------------------------------------------------------------------*/

.jp-OutputArea-stdin {
  line-height: var(--jp-code-line-height);
  padding-top: var(--jp-code-padding);
  display: flex;
}

.jp-Stdin-prompt {
  color: var(--jp-content-font-color0);
  padding-right: var(--jp-code-padding);
  vertical-align: baseline;
  flex: 0 0 auto;
}

.jp-Stdin-input {
  font-family: var(--jp-code-font-family);
  font-size: inherit;
  color: inherit;
  background-color: inherit;
  width: 42%;
  min-width: 200px;
  /* make sure input baseline aligns with prompt */
  vertical-align: baseline;
  /* padding + margin = 0.5em between prompt and cursor */
  padding: 0em 0.25em;
  margin: 0em 0.25em;
  flex: 0 0 70%;
}

.jp-Stdin-input:focus {
  box-shadow: none;
}

/*-----------------------------------------------------------------------------
| Output Area View
|----------------------------------------------------------------------------*/

.jp-LinkedOutputView .jp-OutputArea {
  height: 100%;
  display: block;
}

.jp-LinkedOutputView .jp-OutputArea-output:only-child {
  height: 100%;
}

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

/* This file was auto-generated by ensurePackage() in @jupyterlab/buildutils */

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

.jp-Collapser {
  flex: 0 0 var(--jp-cell-collapser-width);
  padding: 0px;
  margin: 0px;
  border: none;
  outline: none;
  background: transparent;
  border-radius: var(--jp-border-radius);
  opacity: 1;
}

.jp-Collapser-child {
  display: block;
  width: 100%;
  box-sizing: border-box;
  /* height: 100% doesn't work because the height of its parent is computed from content */
  position: absolute;
  top: 0px;
  bottom: 0px;
}

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------
| Header/Footer
|----------------------------------------------------------------------------*/

/* Hidden by zero height by default */
.jp-CellHeader,
.jp-CellFooter {
  height: 0px;
  width: 100%;
  padding: 0px;
  margin: 0px;
  border: none;
  outline: none;
  background: transparent;
}

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------
| Input
|----------------------------------------------------------------------------*/

/* All input areas */
.jp-InputArea {
  display: flex;
  flex-direction: row;
}

.jp-InputArea-editor {
  flex: 1 1 auto;
}

.jp-InputArea-editor {
  /* This is the non-active, default styling */
  border: var(--jp-border-width) solid var(--jp-cell-editor-border-color);
  border-radius: 0px;
  background: var(--jp-cell-editor-background);
}

.jp-InputPrompt {
  flex: 0 0 var(--jp-cell-prompt-width);
  color: var(--jp-cell-inprompt-font-color);
  font-family: var(--jp-cell-prompt-font-family);
  padding: var(--jp-code-padding);
  letter-spacing: var(--jp-cell-prompt-letter-spacing);
  opacity: var(--jp-cell-prompt-opacity);
  line-height: var(--jp-code-line-height);
  font-size: var(--jp-code-font-size);
  border: var(--jp-border-width) solid transparent;
  opacity: var(--jp-cell-prompt-opacity);
  /* Right align prompt text, don't wrap to handle large prompt numbers */
  text-align: right;
  white-space: nowrap;
  overflow: hidden;
  text-overflow: ellipsis;
  /* Disable text selection */
  -webkit-user-select: none;
  -moz-user-select: none;
  -ms-user-select: none;
  user-select: none;
}

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------
| Placeholder
|----------------------------------------------------------------------------*/

.jp-Placeholder {
  display: flex;
  flex-direction: row;
  flex: 1 1 auto;
}

.jp-Placeholder-prompt {
  box-sizing: border-box;
}

.jp-Placeholder-content {
  flex: 1 1 auto;
  border: none;
  background: transparent;
  height: 20px;
  box-sizing: border-box;
}

.jp-Placeholder-content .jp-MoreHorizIcon {
  width: 32px;
  height: 16px;
  border: 1px solid transparent;
  border-radius: var(--jp-border-radius);
}

.jp-Placeholder-content .jp-MoreHorizIcon:hover {
  border: 1px solid var(--jp-border-color1);
  box-shadow: 0px 0px 2px 0px rgba(0, 0, 0, 0.25);
  background-color: var(--jp-layout-color0);
}

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------
| Private CSS variables
|----------------------------------------------------------------------------*/

:root {
  --jp-private-cell-scrolling-output-offset: 5px;
}

/*-----------------------------------------------------------------------------
| Cell
|----------------------------------------------------------------------------*/

.jp-Cell {
  padding: var(--jp-cell-padding);
  margin: 0px;
  border: none;
  outline: none;
  background: transparent;
}

/*-----------------------------------------------------------------------------
| Common input/output
|----------------------------------------------------------------------------*/

.jp-Cell-inputWrapper,
.jp-Cell-outputWrapper {
  display: flex;
  flex-direction: row;
  padding: 0px;
  margin: 0px;
  /* Added to reveal the box-shadow on the input and output collapsers. */
  overflow: visible;
}

/* Only input/output areas inside cells */
.jp-Cell-inputArea,
.jp-Cell-outputArea {
  flex: 1 1 auto;
}

/*-----------------------------------------------------------------------------
| Collapser
|----------------------------------------------------------------------------*/

/* Make the output collapser disappear when there is not output, but do so
 * in a manner that leaves it in the layout and preserves its width.
 */
.jp-Cell.jp-mod-noOutputs .jp-Cell-outputCollapser {
  border: none !important;
  background: transparent !important;
}

.jp-Cell:not(.jp-mod-noOutputs) .jp-Cell-outputCollapser {
  min-height: var(--jp-cell-collapser-min-height);
}

/*-----------------------------------------------------------------------------
| Output
|----------------------------------------------------------------------------*/

/* Put a space between input and output when there IS output */
.jp-Cell:not(.jp-mod-noOutputs) .jp-Cell-outputWrapper {
  margin-top: 5px;
}

/* Text output with the Out[] prompt needs a top padding to match the
 * alignment of the Out[] prompt itself.
 */
.jp-OutputArea-executeResult .jp-RenderedText.jp-OutputArea-output {
  padding-top: var(--jp-code-padding);
}

.jp-CodeCell.jp-mod-outputsScrolled .jp-Cell-outputArea {
  overflow-y: auto;
  max-height: 200px;
  box-shadow: inset 0 0 6px 2px rgba(0, 0, 0, 0.3);
  margin-left: var(--jp-private-cell-scrolling-output-offset);
}

.jp-CodeCell.jp-mod-outputsScrolled .jp-OutputArea-prompt {
  flex: 0 0
    calc(
      var(--jp-cell-prompt-width) -
        var(--jp-private-cell-scrolling-output-offset)
    );
}

/*-----------------------------------------------------------------------------
| CodeCell
|----------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------
| MarkdownCell
|----------------------------------------------------------------------------*/

.jp-MarkdownOutput {
  flex: 1 1 auto;
  margin-top: 0;
  margin-bottom: 0;
  padding-left: var(--jp-code-padding);
}

.jp-MarkdownOutput.jp-RenderedHTMLCommon {
  overflow: auto;
}

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

/* This file was auto-generated by ensurePackage() in @jupyterlab/buildutils */

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------
| Variables
|----------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------

/*-----------------------------------------------------------------------------
| Styles
|----------------------------------------------------------------------------*/

.jp-NotebookPanel-toolbar {
  padding: 2px;
}

.jp-Toolbar-item.jp-Notebook-toolbarCellType .jp-select-wrapper.jp-mod-focused {
  border: none;
  box-shadow: none;
}

.jp-Notebook-toolbarCellTypeDropdown select {
  height: 24px;
  font-size: var(--jp-ui-font-size1);
  line-height: 14px;
  border-radius: 0;
  display: block;
}

.jp-Notebook-toolbarCellTypeDropdown span {
  top: 5px !important;
}

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------
| Private CSS variables
|----------------------------------------------------------------------------*/

:root {
  --jp-private-notebook-dragImage-width: 304px;
  --jp-private-notebook-dragImage-height: 36px;
  --jp-private-notebook-selected-color: var(--md-blue-400);
  --jp-private-notebook-active-color: var(--md-green-400);
}

/*-----------------------------------------------------------------------------
| Imports
|----------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------
| Notebook
|----------------------------------------------------------------------------*/

.jp-NotebookPanel {
  display: block;
  height: 100%;
}

.jp-NotebookPanel.jp-Document {
  min-width: 240px;
  min-height: 120px;
}

.jp-Notebook {
  padding: var(--jp-notebook-padding);
  outline: none;
  overflow: auto;
  background: var(--jp-layout-color0);
}

.jp-Notebook.jp-mod-scrollPastEnd::after {
  display: block;
  content: '';
  min-height: var(--jp-notebook-scroll-padding);
}

.jp-Notebook .jp-Cell {
  overflow: visible;
}

.jp-Notebook .jp-Cell .jp-InputPrompt {
  cursor: move;
}

/*-----------------------------------------------------------------------------
| Notebook state related styling
|
| The notebook and cells each have states, here are the possibilities:
|
| - Notebook
|   - Command
|   - Edit
| - Cell
|   - None
|   - Active (only one can be active)
|   - Selected (the cells actions are applied to)
|   - Multiselected (when multiple selected, the cursor)
|   - No outputs
|----------------------------------------------------------------------------*/

/* Command or edit modes */

.jp-Notebook .jp-Cell:not(.jp-mod-active) .jp-InputPrompt {
  opacity: var(--jp-cell-prompt-not-active-opacity);
  color: var(--jp-cell-prompt-not-active-font-color);
}

.jp-Notebook .jp-Cell:not(.jp-mod-active) .jp-OutputPrompt {
  opacity: var(--jp-cell-prompt-not-active-opacity);
  color: var(--jp-cell-prompt-not-active-font-color);
}

/* cell is active */
.jp-Notebook .jp-Cell.jp-mod-active .jp-Collapser {
  background: var(--jp-brand-color1);
}

/* collapser is hovered */
.jp-Notebook .jp-Cell .jp-Collapser:hover {
  box-shadow: var(--jp-elevation-z2);
  background: var(--jp-brand-color1);
  opacity: var(--jp-cell-collapser-not-active-hover-opacity);
}

/* cell is active and collapser is hovered */
.jp-Notebook .jp-Cell.jp-mod-active .jp-Collapser:hover {
  background: var(--jp-brand-color0);
  opacity: 1;
}

/* Command mode */

.jp-Notebook.jp-mod-commandMode .jp-Cell.jp-mod-selected {
  background: var(--jp-notebook-multiselected-color);
}

.jp-Notebook.jp-mod-commandMode
  .jp-Cell.jp-mod-active.jp-mod-selected:not(.jp-mod-multiSelected) {
  background: transparent;
}

/* Edit mode */

.jp-Notebook.jp-mod-editMode .jp-Cell.jp-mod-active .jp-InputArea-editor {
  border: var(--jp-border-width) solid var(--jp-cell-editor-active-border-color);
  box-shadow: var(--jp-input-box-shadow);
  background-color: var(--jp-cell-editor-active-background);
}

/*-----------------------------------------------------------------------------
| Notebook drag and drop
|----------------------------------------------------------------------------*/

.jp-Notebook-cell.jp-mod-dropSource {
  opacity: 0.5;
}

.jp-Notebook-cell.jp-mod-dropTarget,
.jp-Notebook.jp-mod-commandMode
  .jp-Notebook-cell.jp-mod-active.jp-mod-selected.jp-mod-dropTarget {
  border-top-color: var(--jp-private-notebook-selected-color);
  border-top-style: solid;
  border-top-width: 2px;
}

.jp-dragImage {
  display: flex;
  flex-direction: row;
  width: var(--jp-private-notebook-dragImage-width);
  height: var(--jp-private-notebook-dragImage-height);
  border: var(--jp-border-width) solid var(--jp-cell-editor-border-color);
  background: var(--jp-cell-editor-background);
  overflow: visible;
}

.jp-dragImage-singlePrompt {
  box-shadow: 2px 2px 4px 0px rgba(0, 0, 0, 0.12);
}

.jp-dragImage .jp-dragImage-content {
  flex: 1 1 auto;
  z-index: 2;
  font-size: var(--jp-code-font-size);
  font-family: var(--jp-code-font-family);
  line-height: var(--jp-code-line-height);
  padding: var(--jp-code-padding);
  border: var(--jp-border-width) solid var(--jp-cell-editor-border-color);
  background: var(--jp-cell-editor-background-color);
  color: var(--jp-content-font-color3);
  text-align: left;
  margin: 4px 4px 4px 0px;
}

.jp-dragImage .jp-dragImage-prompt {
  flex: 0 0 auto;
  min-width: 36px;
  color: var(--jp-cell-inprompt-font-color);
  padding: var(--jp-code-padding);
  padding-left: 12px;
  font-family: var(--jp-cell-prompt-font-family);
  letter-spacing: var(--jp-cell-prompt-letter-spacing);
  line-height: 1.9;
  font-size: var(--jp-code-font-size);
  border: var(--jp-border-width) solid transparent;
}

.jp-dragImage-multipleBack {
  z-index: -1;
  position: absolute;
  height: 32px;
  width: 300px;
  top: 8px;
  left: 8px;
  background: var(--jp-layout-color2);
  border: var(--jp-border-width) solid var(--jp-input-border-color);
  box-shadow: 2px 2px 4px 0px rgba(0, 0, 0, 0.12);
}

/*-----------------------------------------------------------------------------
| Cell toolbar
|----------------------------------------------------------------------------*/

.jp-NotebookTools {
  display: block;
  min-width: var(--jp-sidebar-min-width);
  color: var(--jp-ui-font-color1);
  background: var(--jp-layout-color1);
  /* This is needed so that all font sizing of children done in ems is
    * relative to this base size */
  font-size: var(--jp-ui-font-size1);
  overflow: auto;
}

.jp-NotebookTools-tool {
  padding: 0px 12px 0 12px;
}

.jp-ActiveCellTool {
  padding: 12px;
  background-color: var(--jp-layout-color1);
  border-top: none !important;
}

.jp-ActiveCellTool .jp-InputArea-prompt {
  flex: 0 0 auto;
  padding-left: 0px;
}

.jp-ActiveCellTool .jp-InputArea-editor {
  flex: 1 1 auto;
  background: var(--jp-cell-editor-background);
  border-color: var(--jp-cell-editor-border-color);
}

.jp-ActiveCellTool .jp-InputArea-editor .CodeMirror {
  background: transparent;
}

.jp-MetadataEditorTool {
  flex-direction: column;
  padding: 12px 0px 12px 0px;
}

.jp-RankedPanel > :not(:first-child) {
  margin-top: 12px;
}

.jp-KeySelector select.jp-mod-styled {
  font-size: var(--jp-ui-font-size1);
  color: var(--jp-ui-font-color0);
  border: var(--jp-border-width) solid var(--jp-border-color1);
}

.jp-KeySelector label,
.jp-MetadataEditorTool label {
  line-height: 1.4;
}

/*-----------------------------------------------------------------------------
| Presentation Mode (.jp-mod-presentationMode)
|----------------------------------------------------------------------------*/

.jp-mod-presentationMode .jp-Notebook {
  --jp-content-font-size1: var(--jp-content-presentation-font-size1);
  --jp-code-font-size: var(--jp-code-presentation-font-size);
}

.jp-mod-presentationMode .jp-Notebook .jp-Cell .jp-InputPrompt,
.jp-mod-presentationMode .jp-Notebook .jp-Cell .jp-OutputPrompt {
  flex: 0 0 110px;
}

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

/* This file was auto-generated by ensurePackage() in @jupyterlab/buildutils */

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

</style>

    <style type="text/css">
/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

/*
The following CSS variables define the main, public API for styling JupyterLab.
These variables should be used by all plugins wherever possible. In other
words, plugins should not define custom colors, sizes, etc unless absolutely
necessary. This enables users to change the visual theme of JupyterLab
by changing these variables.

Many variables appear in an ordered sequence (0,1,2,3). These sequences
are designed to work well together, so for example, `--jp-border-color1` should
be used with `--jp-layout-color1`. The numbers have the following meanings:

* 0: super-primary, reserved for special emphasis
* 1: primary, most important under normal situations
* 2: secondary, next most important under normal situations
* 3: tertiary, next most important under normal situations

Throughout JupyterLab, we are mostly following principles from Google's
Material Design when selecting colors. We are not, however, following
all of MD as it is not optimized for dense, information rich UIs.
*/

:root {
  /* Elevation
   *
   * We style box-shadows using Material Design's idea of elevation. These particular numbers are taken from here:
   *
   * https://github.com/material-components/material-components-web
   * https://material-components-web.appspot.com/elevation.html
   */

  --jp-shadow-base-lightness: 0;
  --jp-shadow-umbra-color: rgba(
    var(--jp-shadow-base-lightness),
    var(--jp-shadow-base-lightness),
    var(--jp-shadow-base-lightness),
    0.2
  );
  --jp-shadow-penumbra-color: rgba(
    var(--jp-shadow-base-lightness),
    var(--jp-shadow-base-lightness),
    var(--jp-shadow-base-lightness),
    0.14
  );
  --jp-shadow-ambient-color: rgba(
    var(--jp-shadow-base-lightness),
    var(--jp-shadow-base-lightness),
    var(--jp-shadow-base-lightness),
    0.12
  );
  --jp-elevation-z0: none;
  --jp-elevation-z1: 0px 2px 1px -1px var(--jp-shadow-umbra-color),
    0px 1px 1px 0px var(--jp-shadow-penumbra-color),
    0px 1px 3px 0px var(--jp-shadow-ambient-color);
  --jp-elevation-z2: 0px 3px 1px -2px var(--jp-shadow-umbra-color),
    0px 2px 2px 0px var(--jp-shadow-penumbra-color),
    0px 1px 5px 0px var(--jp-shadow-ambient-color);
  --jp-elevation-z4: 0px 2px 4px -1px var(--jp-shadow-umbra-color),
    0px 4px 5px 0px var(--jp-shadow-penumbra-color),
    0px 1px 10px 0px var(--jp-shadow-ambient-color);
  --jp-elevation-z6: 0px 3px 5px -1px var(--jp-shadow-umbra-color),
    0px 6px 10px 0px var(--jp-shadow-penumbra-color),
    0px 1px 18px 0px var(--jp-shadow-ambient-color);
  --jp-elevation-z8: 0px 5px 5px -3px var(--jp-shadow-umbra-color),
    0px 8px 10px 1px var(--jp-shadow-penumbra-color),
    0px 3px 14px 2px var(--jp-shadow-ambient-color);
  --jp-elevation-z12: 0px 7px 8px -4px var(--jp-shadow-umbra-color),
    0px 12px 17px 2px var(--jp-shadow-penumbra-color),
    0px 5px 22px 4px var(--jp-shadow-ambient-color);
  --jp-elevation-z16: 0px 8px 10px -5px var(--jp-shadow-umbra-color),
    0px 16px 24px 2px var(--jp-shadow-penumbra-color),
    0px 6px 30px 5px var(--jp-shadow-ambient-color);
  --jp-elevation-z20: 0px 10px 13px -6px var(--jp-shadow-umbra-color),
    0px 20px 31px 3px var(--jp-shadow-penumbra-color),
    0px 8px 38px 7px var(--jp-shadow-ambient-color);
  --jp-elevation-z24: 0px 11px 15px -7px var(--jp-shadow-umbra-color),
    0px 24px 38px 3px var(--jp-shadow-penumbra-color),
    0px 9px 46px 8px var(--jp-shadow-ambient-color);

  /* Borders
   *
   * The following variables, specify the visual styling of borders in JupyterLab.
   */

  --jp-border-width: 1px;
  --jp-border-color0: var(--md-grey-400);
  --jp-border-color1: var(--md-grey-400);
  --jp-border-color2: var(--md-grey-300);
  --jp-border-color3: var(--md-grey-200);
  --jp-border-radius: 2px;

  /* UI Fonts
   *
   * The UI font CSS variables are used for the typography all of the JupyterLab
   * user interface elements that are not directly user generated content.
   *
   * The font sizing here is done assuming that the body font size of --jp-ui-font-size1
   * is applied to a parent element. When children elements, such as headings, are sized
   * in em all things will be computed relative to that body size.
   */

  --jp-ui-font-scale-factor: 1.2;
  --jp-ui-font-size0: 0.83333em;
  --jp-ui-font-size1: 13px; /* Base font size */
  --jp-ui-font-size2: 1.2em;
  --jp-ui-font-size3: 1.44em;

  --jp-ui-font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Helvetica,
    Arial, sans-serif, 'Apple Color Emoji', 'Segoe UI Emoji', 'Segoe UI Symbol';

  /*
   * Use these font colors against the corresponding main layout colors.
   * In a light theme, these go from dark to light.
   */

  /* Defaults use Material Design specification */
  --jp-ui-font-color0: rgba(0, 0, 0, 1);
  --jp-ui-font-color1: rgba(0, 0, 0, 0.87);
  --jp-ui-font-color2: rgba(0, 0, 0, 0.54);
  --jp-ui-font-color3: rgba(0, 0, 0, 0.38);

  /*
   * Use these against the brand/accent/warn/error colors.
   * These will typically go from light to darker, in both a dark and light theme.
   */

  --jp-ui-inverse-font-color0: rgba(255, 255, 255, 1);
  --jp-ui-inverse-font-color1: rgba(255, 255, 255, 1);
  --jp-ui-inverse-font-color2: rgba(255, 255, 255, 0.7);
  --jp-ui-inverse-font-color3: rgba(255, 255, 255, 0.5);

  /* Content Fonts
   *
   * Content font variables are used for typography of user generated content.
   *
   * The font sizing here is done assuming that the body font size of --jp-content-font-size1
   * is applied to a parent element. When children elements, such as headings, are sized
   * in em all things will be computed relative to that body size.
   */

  --jp-content-line-height: 1.6;
  --jp-content-font-scale-factor: 1.2;
  --jp-content-font-size0: 0.83333em;
  --jp-content-font-size1: 14px; /* Base font size */
  --jp-content-font-size2: 1.2em;
  --jp-content-font-size3: 1.44em;
  --jp-content-font-size4: 1.728em;
  --jp-content-font-size5: 2.0736em;

  /* This gives a magnification of about 125% in presentation mode over normal. */
  --jp-content-presentation-font-size1: 17px;

  --jp-content-heading-line-height: 1;
  --jp-content-heading-margin-top: 1.2em;
  --jp-content-heading-margin-bottom: 0.8em;
  --jp-content-heading-font-weight: 500;

  /* Defaults use Material Design specification */
  --jp-content-font-color0: rgba(0, 0, 0, 1);
  --jp-content-font-color1: rgba(0, 0, 0, 0.87);
  --jp-content-font-color2: rgba(0, 0, 0, 0.54);
  --jp-content-font-color3: rgba(0, 0, 0, 0.38);

  --jp-content-link-color: var(--md-blue-700);

  --jp-content-font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI',
    Helvetica, Arial, sans-serif, 'Apple Color Emoji', 'Segoe UI Emoji',
    'Segoe UI Symbol';

  /*
   * Code Fonts
   *
   * Code font variables are used for typography of code and other monospaces content.
   */

  --jp-code-font-size: 13px;
  --jp-code-line-height: 1.3077; /* 17px for 13px base */
  --jp-code-padding: 5px; /* 5px for 13px base, codemirror highlighting needs integer px value */
  --jp-code-font-family-default: Menlo, Consolas, 'DejaVu Sans Mono', monospace;
  --jp-code-font-family: var(--jp-code-font-family-default);

  /* This gives a magnification of about 125% in presentation mode over normal. */
  --jp-code-presentation-font-size: 16px;

  /* may need to tweak cursor width if you change font size */
  --jp-code-cursor-width0: 1.4px;
  --jp-code-cursor-width1: 2px;
  --jp-code-cursor-width2: 4px;

  /* Layout
   *
   * The following are the main layout colors use in JupyterLab. In a light
   * theme these would go from light to dark.
   */

  --jp-layout-color0: white;
  --jp-layout-color1: white;
  --jp-layout-color2: var(--md-grey-200);
  --jp-layout-color3: var(--md-grey-400);
  --jp-layout-color4: var(--md-grey-600);

  /* Inverse Layout
   *
   * The following are the inverse layout colors use in JupyterLab. In a light
   * theme these would go from dark to light.
   */

  --jp-inverse-layout-color0: #111111;
  --jp-inverse-layout-color1: var(--md-grey-900);
  --jp-inverse-layout-color2: var(--md-grey-800);
  --jp-inverse-layout-color3: var(--md-grey-700);
  --jp-inverse-layout-color4: var(--md-grey-600);

  /* Brand/accent */

  --jp-brand-color0: var(--md-blue-700);
  --jp-brand-color1: var(--md-blue-500);
  --jp-brand-color2: var(--md-blue-300);
  --jp-brand-color3: var(--md-blue-100);
  --jp-brand-color4: var(--md-blue-50);

  --jp-accent-color0: var(--md-green-700);
  --jp-accent-color1: var(--md-green-500);
  --jp-accent-color2: var(--md-green-300);
  --jp-accent-color3: var(--md-green-100);

  /* State colors (warn, error, success, info) */

  --jp-warn-color0: var(--md-orange-700);
  --jp-warn-color1: var(--md-orange-500);
  --jp-warn-color2: var(--md-orange-300);
  --jp-warn-color3: var(--md-orange-100);

  --jp-error-color0: var(--md-red-700);
  --jp-error-color1: var(--md-red-500);
  --jp-error-color2: var(--md-red-300);
  --jp-error-color3: var(--md-red-100);

  --jp-success-color0: var(--md-green-700);
  --jp-success-color1: var(--md-green-500);
  --jp-success-color2: var(--md-green-300);
  --jp-success-color3: var(--md-green-100);

  --jp-info-color0: var(--md-cyan-700);
  --jp-info-color1: var(--md-cyan-500);
  --jp-info-color2: var(--md-cyan-300);
  --jp-info-color3: var(--md-cyan-100);

  /* Cell specific styles */

  --jp-cell-padding: 5px;

  --jp-cell-collapser-width: 8px;
  --jp-cell-collapser-min-height: 20px;
  --jp-cell-collapser-not-active-hover-opacity: 0.6;

  --jp-cell-editor-background: var(--md-grey-100);
  --jp-cell-editor-border-color: var(--md-grey-300);
  --jp-cell-editor-box-shadow: inset 0 0 2px var(--md-blue-300);
  --jp-cell-editor-active-background: var(--jp-layout-color0);
  --jp-cell-editor-active-border-color: var(--jp-brand-color1);

  --jp-cell-prompt-width: 64px;
  --jp-cell-prompt-font-family: 'Source Code Pro', monospace;
  --jp-cell-prompt-letter-spacing: 0px;
  --jp-cell-prompt-opacity: 1;
  --jp-cell-prompt-not-active-opacity: 0.5;
  --jp-cell-prompt-not-active-font-color: var(--md-grey-700);
  /* A custom blend of MD grey and blue 600
   * See https://meyerweb.com/eric/tools/color-blend/#546E7A:1E88E5:5:hex */
  --jp-cell-inprompt-font-color: #307fc1;
  /* A custom blend of MD grey and orange 600
   * https://meyerweb.com/eric/tools/color-blend/#546E7A:F4511E:5:hex */
  --jp-cell-outprompt-font-color: #bf5b3d;

  /* Notebook specific styles */

  --jp-notebook-padding: 10px;
  --jp-notebook-select-background: var(--jp-layout-color1);
  --jp-notebook-multiselected-color: var(--md-blue-50);

  /* The scroll padding is calculated to fill enough space at the bottom of the
  notebook to show one single-line cell (with appropriate padding) at the top
  when the notebook is scrolled all the way to the bottom. We also subtract one
  pixel so that no scrollbar appears if we have just one single-line cell in the
  notebook. This padding is to enable a 'scroll past end' feature in a notebook.
  */
  --jp-notebook-scroll-padding: calc(
    100% - var(--jp-code-font-size) * var(--jp-code-line-height) -
      var(--jp-code-padding) - var(--jp-cell-padding) - 1px
  );

  /* Rendermime styles */

  --jp-rendermime-error-background: #fdd;
  --jp-rendermime-table-row-background: var(--md-grey-100);
  --jp-rendermime-table-row-hover-background: var(--md-light-blue-50);

  /* Dialog specific styles */

  --jp-dialog-background: rgba(0, 0, 0, 0.25);

  /* Console specific styles */

  --jp-console-padding: 10px;

  /* Toolbar specific styles */

  --jp-toolbar-border-color: var(--jp-border-color1);
  --jp-toolbar-micro-height: 8px;
  --jp-toolbar-background: var(--jp-layout-color1);
  --jp-toolbar-box-shadow: 0px 0px 2px 0px rgba(0, 0, 0, 0.24);
  --jp-toolbar-header-margin: 4px 4px 0px 4px;
  --jp-toolbar-active-background: var(--md-grey-300);

  /* Input field styles */

  --jp-input-box-shadow: inset 0 0 2px var(--md-blue-300);
  --jp-input-active-background: var(--jp-layout-color1);
  --jp-input-hover-background: var(--jp-layout-color1);
  --jp-input-background: var(--md-grey-100);
  --jp-input-border-color: var(--jp-border-color1);
  --jp-input-active-border-color: var(--jp-brand-color1);
  --jp-input-active-box-shadow-color: rgba(19, 124, 189, 0.3);

  /* General editor styles */

  --jp-editor-selected-background: #d9d9d9;
  --jp-editor-selected-focused-background: #d7d4f0;
  --jp-editor-cursor-color: var(--jp-ui-font-color0);

  /* Code mirror specific styles */

  --jp-mirror-editor-keyword-color: #008000;
  --jp-mirror-editor-atom-color: #88f;
  --jp-mirror-editor-number-color: #080;
  --jp-mirror-editor-def-color: #00f;
  --jp-mirror-editor-variable-color: var(--md-grey-900);
  --jp-mirror-editor-variable-2-color: #05a;
  --jp-mirror-editor-variable-3-color: #085;
  --jp-mirror-editor-punctuation-color: #05a;
  --jp-mirror-editor-property-color: #05a;
  --jp-mirror-editor-operator-color: #aa22ff;
  --jp-mirror-editor-comment-color: #408080;
  --jp-mirror-editor-string-color: #ba2121;
  --jp-mirror-editor-string-2-color: #708;
  --jp-mirror-editor-meta-color: #aa22ff;
  --jp-mirror-editor-qualifier-color: #555;
  --jp-mirror-editor-builtin-color: #008000;
  --jp-mirror-editor-bracket-color: #997;
  --jp-mirror-editor-tag-color: #170;
  --jp-mirror-editor-attribute-color: #00c;
  --jp-mirror-editor-header-color: blue;
  --jp-mirror-editor-quote-color: #090;
  --jp-mirror-editor-link-color: #00c;
  --jp-mirror-editor-error-color: #f00;
  --jp-mirror-editor-hr-color: #999;

  /* Vega extension styles */

  --jp-vega-background: white;

  /* Sidebar-related styles */

  --jp-sidebar-min-width: 180px;

  /* Search-related styles */

  --jp-search-toggle-off-opacity: 0.5;
  --jp-search-toggle-hover-opacity: 0.8;
  --jp-search-toggle-on-opacity: 1;
  --jp-search-selected-match-background-color: rgb(245, 200, 0);
  --jp-search-selected-match-color: black;
  --jp-search-unselected-match-background-color: var(
    --jp-inverse-layout-color0
  );
  --jp-search-unselected-match-color: var(--jp-ui-inverse-font-color0);

  /* Icon colors that work well with light or dark backgrounds */
  --jp-icon-contrast-color0: var(--md-purple-600);
  --jp-icon-contrast-color1: var(--md-green-600);
  --jp-icon-contrast-color2: var(--md-pink-600);
  --jp-icon-contrast-color3: var(--md-blue-600);
}
</style>

<style type="text/css">
a.anchor-link {
   display: none;
}
.highlight  {
    margin: 0.4em;
}

/* Input area styling */
.jp-InputArea {
    overflow: hidden;
}

.jp-InputArea-editor {
    overflow: hidden;
}

@media print {
  body {
    margin: 0;
  }
}
</style>



<!-- Load mathjax -->
    <script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.7/latest.js?config=TeX-MML-AM_CHTML-full,Safe"> </script>
    <!-- MathJax configuration -->
    <script type="text/x-mathjax-config">
    init_mathjax = function() {
        if (window.MathJax) {
        // MathJax loaded
            MathJax.Hub.Config({
                TeX: {
                    equationNumbers: {
                    autoNumber: "AMS",
                    useLabelIds: true
                    }
                },
                tex2jax: {
                    inlineMath: [ ['$','$'], ["\\(","\\)"] ],
                    displayMath: [ ['$$','$$'], ["\\[","\\]"] ],
                    processEscapes: true,
                    processEnvironments: true
                },
                displayAlign: 'center',
                CommonHTML: {
                    linebreaks: { 
                    automatic: true 
                    }
                },
                "HTML-CSS": {
                    linebreaks: { 
                    automatic: true 
                    }
                }
            });
        
            MathJax.Hub.Queue(["Typeset", MathJax.Hub]);
        }
    }
    init_mathjax();
    </script>
    <!-- End of mathjax configuration --></head>
<body class="jp-Notebook" data-jp-theme-light="true" data-jp-theme-name="JupyterLab Light">

<div class="jp-Cell-inputWrapper"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput " data-mime-type="text/markdown">
<h1 id="Cercador-model-&#242;ptim-de-LSTM-i-GRU-de-dues-capes">Cercador model &#242;ptim de LSTM i GRU de dues capes<a class="anchor-link" href="#Cercador-model-&#242;ptim-de-LSTM-i-GRU-de-dues-capes">&#182;</a></h1>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell   ">
<div class="jp-Cell-inputWrapper">
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In&nbsp;[1]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
     <div class="CodeMirror cm-s-jupyter">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">tensorflow.compat.v2</span> <span class="k">as</span> <span class="nn">tf</span>
<span class="n">tf</span><span class="o">.</span><span class="n">enable_v2_behavior</span><span class="p">()</span>
<span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>
<span class="kn">from</span> <span class="nn">tensorflow</span> <span class="kn">import</span> <span class="n">keras</span>
<span class="kn">from</span> <span class="nn">sklearn.preprocessing</span> <span class="kn">import</span> <span class="n">StandardScaler</span>
<span class="kn">from</span> <span class="nn">sklearn.preprocessing</span> <span class="kn">import</span> <span class="n">RobustScaler</span>
<span class="kn">from</span> <span class="nn">sklearn.preprocessing</span> <span class="kn">import</span> <span class="n">MinMaxScaler</span>
<span class="kn">from</span> <span class="nn">matplotlib</span> <span class="kn">import</span> <span class="n">pyplot</span>
<span class="kn">import</span> <span class="nn">plotly.graph_objects</span> <span class="k">as</span> <span class="nn">go</span>
<span class="kn">import</span> <span class="nn">math</span>
<span class="kn">import</span> <span class="nn">seaborn</span> <span class="k">as</span> <span class="nn">sns</span>
<span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="kn">import</span> <span class="n">mean_squared_error</span>
<span class="kn">from</span> <span class="nn">time</span> <span class="kn">import</span> <span class="n">time</span>

<span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="mi">2</span><span class="p">)</span>
<span class="n">tf</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">set_seed</span><span class="p">(</span><span class="mi">2</span><span class="p">)</span>

<span class="kn">from</span> <span class="nn">tensorflow.keras.models</span> <span class="kn">import</span> <span class="n">Sequential</span>
<span class="kn">from</span> <span class="nn">tensorflow.keras.layers</span> <span class="kn">import</span> <span class="n">Dense</span><span class="p">,</span> <span class="n">LSTM</span><span class="p">,</span> <span class="n">GRU</span><span class="p">,</span> <span class="n">Dropout</span><span class="p">,</span> <span class="n">RepeatVector</span><span class="p">,</span> <span class="n">TimeDistributed</span>
<span class="kn">from</span> <span class="nn">tensorflow.keras</span> <span class="kn">import</span> <span class="n">backend</span>
</pre></div>

     </div>
</div>
</div>
</div>

<div class="jp-Cell-outputWrapper">


<div class="jp-OutputArea jp-Cell-outputArea">

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>C:\Users\dj_kr\anaconda3\lib\site-packages\statsmodels\tools\_testing.py:19: FutureWarning: pandas.util.testing is deprecated. Use the functions in the public API at pandas.testing instead.
  import pandas.util.testing as tm
</pre>
</div>
</div>

</div>

</div>

</div>
<div class="jp-Cell-inputWrapper"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput " data-mime-type="text/markdown">
<h2 id="C&#224;rrega-de-les-dades">C&#224;rrega de les dades<a class="anchor-link" href="#C&#224;rrega-de-les-dades">&#182;</a></h2>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell jp-mod-noOutputs  ">
<div class="jp-Cell-inputWrapper">
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In&nbsp;[2]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
     <div class="CodeMirror cm-s-jupyter">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s1">&#39;data/SentDATA.csv&#39;</span><span class="p">)</span>

<span class="n">df</span><span class="o">.</span><span class="n">reset_index</span><span class="p">(</span><span class="n">inplace</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">df</span><span class="p">[</span><span class="s1">&#39;Time&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">to_datetime</span><span class="p">(</span><span class="n">df</span><span class="p">[</span><span class="s1">&#39;Time&#39;</span><span class="p">])</span>
<span class="n">df</span> <span class="o">=</span> <span class="n">df</span><span class="o">.</span><span class="n">set_index</span><span class="p">(</span><span class="s1">&#39;Time&#39;</span><span class="p">)</span>
</pre></div>

     </div>
</div>
</div>
</div>

</div>
<div class="jp-Cell-inputWrapper"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput " data-mime-type="text/markdown">
<h2 id="Transformaci&#243;-de-dades">Transformaci&#243; de dades<a class="anchor-link" href="#Transformaci&#243;-de-dades">&#182;</a></h2>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell jp-mod-noOutputs  ">
<div class="jp-Cell-inputWrapper">
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In&nbsp;[6]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
     <div class="CodeMirror cm-s-jupyter">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">columns</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;PM1&#39;</span><span class="p">,</span><span class="s1">&#39;PM25&#39;</span><span class="p">,</span><span class="s1">&#39;PM10&#39;</span><span class="p">,</span><span class="s1">&#39;PM1ATM&#39;</span><span class="p">,</span><span class="s1">&#39;PM25ATM&#39;</span><span class="p">,</span><span class="s1">&#39;PM10ATM&#39;</span><span class="p">]</span>

<span class="n">df1</span> <span class="o">=</span> <span class="n">df</span><span class="o">.</span><span class="n">copy</span><span class="p">();</span>

<span class="n">df1</span> <span class="o">=</span> <span class="n">df1</span><span class="o">.</span><span class="n">rename</span><span class="p">(</span><span class="n">columns</span><span class="o">=</span><span class="p">{</span><span class="s2">&quot;PM 1&quot;</span><span class="p">:</span><span class="s2">&quot;PM1&quot;</span><span class="p">,</span><span class="s2">&quot;PM 2.5&quot;</span><span class="p">:</span><span class="s2">&quot;PM25&quot;</span><span class="p">,</span><span class="s2">&quot;PM 10&quot;</span><span class="p">:</span><span class="s2">&quot;PM10&quot;</span><span class="p">,</span><span class="s2">&quot;PM 1 ATM&quot;</span><span class="p">:</span><span class="s2">&quot;PM1ATM&quot;</span><span class="p">,</span><span class="s2">&quot;PM 2.5 ATM&quot;</span><span class="p">:</span><span class="s2">&quot;PM25ATM&quot;</span><span class="p">,</span><span class="s2">&quot;PM 10 ATM&quot;</span><span class="p">:</span><span class="s2">&quot;PM10ATM&quot;</span><span class="p">})</span>

<span class="n">df1</span><span class="p">[</span><span class="s1">&#39;PM1&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="s1">&#39;PM 1&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
<span class="n">df1</span><span class="p">[</span><span class="s1">&#39;PM25&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="s1">&#39;PM 2.5&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
<span class="n">df1</span><span class="p">[</span><span class="s1">&#39;PM10&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="s1">&#39;PM 10&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
<span class="n">df1</span><span class="p">[</span><span class="s1">&#39;PM1ATM&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="s1">&#39;PM 1 ATM&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
<span class="n">df1</span><span class="p">[</span><span class="s1">&#39;PM25ATM&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="s1">&#39;PM 2.5 ATM&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
<span class="n">df1</span><span class="p">[</span><span class="s1">&#39;PM10ATM&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="s1">&#39;PM 10 ATM&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
</pre></div>

     </div>
</div>
</div>
</div>

</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell jp-mod-noOutputs  ">
<div class="jp-Cell-inputWrapper">
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In&nbsp;[11]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
     <div class="CodeMirror cm-s-jupyter">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">df2</span> <span class="o">=</span> <span class="n">df1</span><span class="o">.</span><span class="n">copy</span><span class="p">()</span>
</pre></div>

     </div>
</div>
</div>
</div>

</div>
<div class="jp-Cell-inputWrapper"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput " data-mime-type="text/markdown">
<h2 id="Crear-dades-d'entrenament-i-de-test">Crear dades d'entrenament i de test<a class="anchor-link" href="#Crear-dades-d'entrenament-i-de-test">&#182;</a></h2>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell   ">
<div class="jp-Cell-inputWrapper">
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In&nbsp;[13]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
     <div class="CodeMirror cm-s-jupyter">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">train_size</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">df2</span><span class="p">)</span> <span class="o">*</span> <span class="mf">0.8</span><span class="p">)</span>
<span class="n">test_size</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">df2</span><span class="p">)</span> <span class="o">-</span> <span class="n">train_size</span>
<span class="n">train</span><span class="p">,</span> <span class="n">test</span> <span class="o">=</span> <span class="n">df2</span><span class="o">.</span><span class="n">iloc</span><span class="p">[</span><span class="mi">0</span><span class="p">:</span><span class="n">train_size</span><span class="p">],</span> <span class="n">df2</span><span class="o">.</span><span class="n">iloc</span><span class="p">[</span><span class="n">train_size</span><span class="p">:</span><span class="nb">len</span><span class="p">(</span><span class="n">df2</span><span class="p">)]</span>
<span class="n">train</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span> <span class="n">test</span><span class="o">.</span><span class="n">shape</span>
</pre></div>

     </div>
</div>
</div>
</div>

<div class="jp-Cell-outputWrapper">


<div class="jp-OutputArea jp-Cell-outputArea">

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt">Out[13]:</div>




<div class="jp-RenderedText jp-OutputArea-output jp-OutputArea-executeResult" data-mime-type="text/plain">
<pre>((3991, 7), (998, 7))</pre>
</div>

</div>

</div>

</div>

</div>
<div class="jp-Cell-inputWrapper"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput " data-mime-type="text/markdown">
<h2 id="Normalitzar-les-dades-d'entrenament">Normalitzar les dades d'entrenament<a class="anchor-link" href="#Normalitzar-les-dades-d'entrenament">&#182;</a></h2>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell   ">
<div class="jp-Cell-inputWrapper">
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In&nbsp;[14]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
     <div class="CodeMirror cm-s-jupyter">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1">#Standardize the data</span>
<span class="k">for</span> <span class="n">col</span> <span class="ow">in</span> <span class="n">columns</span><span class="p">:</span>
    <span class="n">scaler</span> <span class="o">=</span> <span class="n">StandardScaler</span><span class="p">()</span>
    <span class="n">train</span><span class="p">[</span><span class="n">col</span><span class="p">]</span> <span class="o">=</span> <span class="n">scaler</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">train</span><span class="p">[[</span><span class="n">col</span><span class="p">]])</span>
</pre></div>

     </div>
</div>
</div>
</div>

<div class="jp-Cell-outputWrapper">


<div class="jp-OutputArea jp-Cell-outputArea">

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>&lt;ipython-input-14-ad7c79e4e223&gt;:4: SettingWithCopyWarning:


A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy

&lt;ipython-input-14-ad7c79e4e223&gt;:4: SettingWithCopyWarning:


A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy

&lt;ipython-input-14-ad7c79e4e223&gt;:4: SettingWithCopyWarning:


A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy

&lt;ipython-input-14-ad7c79e4e223&gt;:4: SettingWithCopyWarning:


A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy

&lt;ipython-input-14-ad7c79e4e223&gt;:4: SettingWithCopyWarning:


A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy

&lt;ipython-input-14-ad7c79e4e223&gt;:4: SettingWithCopyWarning:


A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy

</pre>
</div>
</div>

</div>

</div>

</div>
<div class="jp-Cell-inputWrapper"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput " data-mime-type="text/markdown">
<h2 id="Crear-finestra-de-temps-PM-2.5">Crear finestra de temps PM 2.5<a class="anchor-link" href="#Crear-finestra-de-temps-PM-2.5">&#182;</a></h2>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell   ">
<div class="jp-Cell-inputWrapper">
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In&nbsp;[15]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
     <div class="CodeMirror cm-s-jupyter">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">TIME_STEPS</span><span class="o">=</span><span class="mi">144</span> <span class="c1">#6 registres hora x 24h x 3 --&gt; equival a una finestra d&#39;un dia</span>

<span class="k">def</span> <span class="nf">create_sequences</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">time_steps</span><span class="o">=</span><span class="n">TIME_STEPS</span><span class="p">):</span>
    <span class="n">Xs</span><span class="p">,</span> <span class="n">ys</span> <span class="o">=</span> <span class="p">[],</span> <span class="p">[]</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">X</span><span class="p">)</span><span class="o">-</span><span class="n">time_steps</span><span class="p">):</span>
        <span class="n">Xs</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">X</span><span class="o">.</span><span class="n">iloc</span><span class="p">[</span><span class="n">i</span><span class="p">:(</span><span class="n">i</span><span class="o">+</span><span class="n">time_steps</span><span class="p">)]</span><span class="o">.</span><span class="n">values</span><span class="p">)</span>
        <span class="n">ys</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">y</span><span class="o">.</span><span class="n">iloc</span><span class="p">[</span><span class="n">i</span><span class="o">+</span><span class="n">time_steps</span><span class="p">])</span>
    
    <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">Xs</span><span class="p">),</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">ys</span><span class="p">)</span>

<span class="n">X_train1h</span><span class="p">,</span> <span class="n">y_train1h</span> <span class="o">=</span> <span class="n">create_sequences</span><span class="p">(</span><span class="n">train</span><span class="p">[[</span><span class="n">columns</span><span class="p">[</span><span class="mi">1</span><span class="p">]]],</span> <span class="n">train</span><span class="p">[</span><span class="n">columns</span><span class="p">[</span><span class="mi">1</span><span class="p">]],</span> <span class="mi">6</span><span class="p">)</span> <span class="c1">#1 hour</span>

<span class="n">X_train3h</span><span class="p">,</span> <span class="n">y_train3h</span> <span class="o">=</span> <span class="n">create_sequences</span><span class="p">(</span><span class="n">train</span><span class="p">[[</span><span class="n">columns</span><span class="p">[</span><span class="mi">1</span><span class="p">]]],</span> <span class="n">train</span><span class="p">[</span><span class="n">columns</span><span class="p">[</span><span class="mi">1</span><span class="p">]],</span> <span class="mi">18</span><span class="p">)</span> <span class="c1">#3 hours</span>

<span class="n">X_train6h</span><span class="p">,</span> <span class="n">y_train6h</span> <span class="o">=</span> <span class="n">create_sequences</span><span class="p">(</span><span class="n">train</span><span class="p">[[</span><span class="n">columns</span><span class="p">[</span><span class="mi">1</span><span class="p">]]],</span> <span class="n">train</span><span class="p">[</span><span class="n">columns</span><span class="p">[</span><span class="mi">1</span><span class="p">]],</span> <span class="mi">36</span><span class="p">)</span> <span class="c1">#6 hours</span>

<span class="n">X_train12h</span><span class="p">,</span> <span class="n">y_train12h</span> <span class="o">=</span> <span class="n">create_sequences</span><span class="p">(</span><span class="n">train</span><span class="p">[[</span><span class="n">columns</span><span class="p">[</span><span class="mi">1</span><span class="p">]]],</span> <span class="n">train</span><span class="p">[</span><span class="n">columns</span><span class="p">[</span><span class="mi">1</span><span class="p">]],</span> <span class="mi">72</span><span class="p">)</span> <span class="c1">#12 hours</span>

<span class="n">X_train1d</span><span class="p">,</span> <span class="n">y_train1d</span> <span class="o">=</span> <span class="n">create_sequences</span><span class="p">(</span><span class="n">train</span><span class="p">[[</span><span class="n">columns</span><span class="p">[</span><span class="mi">1</span><span class="p">]]],</span> <span class="n">train</span><span class="p">[</span><span class="n">columns</span><span class="p">[</span><span class="mi">1</span><span class="p">]],</span> <span class="mi">144</span><span class="p">)</span> <span class="c1">#1 day</span>

<span class="n">X_train3d</span><span class="p">,</span> <span class="n">y_train3d</span> <span class="o">=</span> <span class="n">create_sequences</span><span class="p">(</span><span class="n">train</span><span class="p">[[</span><span class="n">columns</span><span class="p">[</span><span class="mi">1</span><span class="p">]]],</span> <span class="n">train</span><span class="p">[</span><span class="n">columns</span><span class="p">[</span><span class="mi">1</span><span class="p">]],</span> <span class="mi">432</span><span class="p">)</span> <span class="c1">#3 days</span>

<span class="n">X_train7d</span><span class="p">,</span> <span class="n">y_train7d</span> <span class="o">=</span> <span class="n">create_sequences</span><span class="p">(</span><span class="n">train</span><span class="p">[[</span><span class="n">columns</span><span class="p">[</span><span class="mi">1</span><span class="p">]]],</span> <span class="n">train</span><span class="p">[</span><span class="n">columns</span><span class="p">[</span><span class="mi">1</span><span class="p">]],</span> <span class="mi">1008</span><span class="p">)</span> <span class="c1">#7 days</span>
<span class="c1">#X_test, y_test = create_sequences(test[[columns[1]]], test[columns[1]])</span>

<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;X_train1h shape: </span><span class="si">{</span><span class="n">X_train1d</span><span class="o">.</span><span class="n">shape</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;X_train3d shape: </span><span class="si">{</span><span class="n">X_train3h</span><span class="o">.</span><span class="n">shape</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;X_train6h shape: </span><span class="si">{</span><span class="n">X_train6h</span><span class="o">.</span><span class="n">shape</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;X_train12h shape: </span><span class="si">{</span><span class="n">X_train12h</span><span class="o">.</span><span class="n">shape</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;X_train1d shape: </span><span class="si">{</span><span class="n">X_train1d</span><span class="o">.</span><span class="n">shape</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;X_train3d shape: </span><span class="si">{</span><span class="n">X_train3d</span><span class="o">.</span><span class="n">shape</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;X_train7d shape: </span><span class="si">{</span><span class="n">X_train7d</span><span class="o">.</span><span class="n">shape</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>
</pre></div>

     </div>
</div>
</div>
</div>

<div class="jp-Cell-outputWrapper">


<div class="jp-OutputArea jp-Cell-outputArea">

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>X_train1h shape: (3847, 144, 1)
X_train3d shape: (3973, 18, 1)
X_train6h shape: (3955, 36, 1)
X_train12h shape: (3919, 72, 1)
X_train1d shape: (3847, 144, 1)
X_train3d shape: (3559, 432, 1)
X_train7d shape: (2983, 1008, 1)
</pre>
</div>
</div>

</div>

</div>

</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell jp-mod-noOutputs  ">
<div class="jp-Cell-inputWrapper">
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In&nbsp;[16]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
     <div class="CodeMirror cm-s-jupyter">
<div class=" highlight hl-ipython3"><pre><span></span><span class="k">def</span> <span class="nf">evaluate_prediction</span><span class="p">(</span><span class="n">predictions</span><span class="p">,</span> <span class="n">actual</span><span class="p">,</span> <span class="n">model_name</span><span class="p">):</span>
    <span class="n">errors</span> <span class="o">=</span> <span class="n">predictions</span> <span class="o">-</span> <span class="n">actual</span>
    <span class="n">mse</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">square</span><span class="p">(</span><span class="n">errors</span><span class="p">)</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span>
    <span class="n">rmse</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">mse</span><span class="p">)</span>
    <span class="n">mae</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">abs</span><span class="p">(</span><span class="n">errors</span><span class="p">)</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span>

    <span class="nb">print</span><span class="p">(</span><span class="n">model_name</span> <span class="o">+</span> <span class="s1">&#39;:&#39;</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Mean Absolute Error: </span><span class="si">{:.4f}</span><span class="s1">&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">mae</span><span class="p">))</span>
    <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Root Mean Square Error: </span><span class="si">{:.4f}</span><span class="s1">&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">rmse</span><span class="p">))</span>
    <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Mean Square Error: </span><span class="si">{:.4f}</span><span class="s1">&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">mse</span><span class="p">))</span>
    <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;&#39;</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">mae</span><span class="p">,</span><span class="n">rmse</span><span class="p">,</span><span class="n">mse</span>
</pre></div>

     </div>
</div>
</div>
</div>

</div>
<div class="jp-Cell-inputWrapper"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput " data-mime-type="text/markdown">
<h2 id="Cerca-dels-models-&#242;ptims">Cerca dels models &#242;ptims<a class="anchor-link" href="#Cerca-dels-models-&#242;ptims">&#182;</a></h2>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell   ">
<div class="jp-Cell-inputWrapper">
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In&nbsp;[17]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
     <div class="CodeMirror cm-s-jupyter">
<div class=" highlight hl-ipython3"><pre><span></span><span class="k">def</span> <span class="nf">_model</span><span class="p">(</span><span class="n">cmodel</span><span class="p">,</span><span class="n">units</span><span class="p">,</span><span class="n">activationDense</span><span class="p">,</span><span class="n">dropout1</span><span class="p">,</span><span class="n">dropout2</span><span class="p">,</span><span class="n">optimizer</span><span class="p">):</span>
    <span class="n">model</span> <span class="o">=</span> <span class="n">Sequential</span><span class="p">()</span>
    <span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">cmodel</span><span class="p">(</span><span class="n">units</span> <span class="o">=</span> <span class="n">units</span><span class="p">,</span> <span class="n">return_sequences</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">input_shape</span><span class="o">=</span><span class="p">(</span><span class="n">X_train</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="n">X_train</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">2</span><span class="p">])))</span>
    <span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">Dropout</span><span class="p">(</span><span class="n">rate</span><span class="o">=</span><span class="n">dropout1</span><span class="p">))</span>
    <span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">cmodel</span><span class="p">(</span><span class="n">units</span> <span class="o">=</span> <span class="n">units</span><span class="p">,</span> <span class="n">return_sequences</span><span class="o">=</span><span class="kc">True</span><span class="p">))</span>
    <span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">Dropout</span><span class="p">(</span><span class="n">rate</span><span class="o">=</span><span class="n">dropout2</span><span class="p">))</span>
    <span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">TimeDistributed</span><span class="p">(</span><span class="n">Dense</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="n">kernel_initializer</span><span class="o">=</span><span class="s1">&#39;normal&#39;</span><span class="p">,</span><span class="n">activation</span><span class="o">=</span><span class="n">activationDense</span><span class="p">)))</span>
    <span class="n">model</span><span class="o">.</span><span class="n">compile</span><span class="p">(</span><span class="n">optimizer</span><span class="o">=</span><span class="n">optimizer</span><span class="p">,</span> <span class="n">loss</span><span class="o">=</span><span class="s1">&#39;mae&#39;</span><span class="p">)</span>
    <span class="n">model</span><span class="o">.</span><span class="n">summary</span><span class="p">()</span>
    
    <span class="k">return</span> <span class="n">model</span>

<span class="n">models</span> <span class="o">=</span> <span class="p">[</span><span class="n">LSTM</span><span class="p">,</span><span class="n">GRU</span><span class="p">]</span>
<span class="n">nmodels</span> <span class="o">=</span> <span class="p">[</span><span class="s2">&quot;LSTM&quot;</span><span class="p">,</span><span class="s2">&quot;GRU&quot;</span><span class="p">]</span>
<span class="n">sequences</span> <span class="o">=</span> <span class="p">[</span><span class="s2">&quot;1h&quot;</span><span class="p">,</span><span class="s2">&quot;3h&quot;</span><span class="p">,</span><span class="s2">&quot;6h&quot;</span><span class="p">,</span><span class="s2">&quot;12h&quot;</span><span class="p">,</span><span class="s2">&quot;1d&quot;</span><span class="p">,</span> <span class="s2">&quot;3d&quot;</span><span class="p">,</span> <span class="s2">&quot;7d&quot;</span><span class="p">]</span>
<span class="n">X_trains</span> <span class="o">=</span> <span class="p">[</span><span class="n">X_train1h</span><span class="p">,</span><span class="n">X_train3h</span><span class="p">,</span> <span class="n">X_train6h</span><span class="p">,</span> <span class="n">X_train12h</span><span class="p">,</span><span class="n">X_train1d</span><span class="p">,</span><span class="n">X_train3d</span><span class="p">,</span> <span class="n">X_train7d</span><span class="p">]</span>
<span class="n">y_trains</span><span class="o">=</span> <span class="p">[</span><span class="n">y_train1h</span><span class="p">,</span><span class="n">y_train3h</span><span class="p">,</span> <span class="n">y_train6h</span><span class="p">,</span><span class="n">y_train12h</span><span class="p">,</span><span class="n">y_train1d</span><span class="p">,</span><span class="n">y_train3d</span><span class="p">,</span> <span class="n">y_train7d</span><span class="p">]</span>
<span class="n">activations</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;relu&#39;</span><span class="p">]</span>
<span class="n">activationsDense</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;tanh&#39;</span><span class="p">,</span><span class="s1">&#39;sigmoid&#39;</span><span class="p">]</span>
<span class="n">optimizers</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;adam&#39;</span><span class="p">,</span><span class="s1">&#39;adadelta&#39;</span><span class="p">,</span><span class="s1">&#39;adamax&#39;</span><span class="p">]</span>
<span class="n">list_validationSplit</span> <span class="o">=</span> <span class="p">[</span><span class="mf">0.1</span><span class="p">,</span><span class="mf">0.2</span><span class="p">]</span>
<span class="n">list_dropout1</span> <span class="o">=</span>  <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">uniform</span><span class="p">(</span><span class="mf">0.1</span><span class="p">,</span><span class="mf">0.8</span><span class="p">,</span><span class="mi">5</span><span class="p">)</span>   
<span class="n">list_dropout2</span> <span class="o">=</span>  <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">uniform</span><span class="p">(</span><span class="mf">0.1</span><span class="p">,</span><span class="mf">0.8</span><span class="p">,</span><span class="mi">5</span><span class="p">)</span>   
<span class="n">list_units</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">randint</span><span class="p">(</span><span class="mi">6</span><span class="p">,</span><span class="n">high</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="mi">5</span><span class="p">)</span> 
<span class="n">list_epochs</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">randint</span><span class="p">(</span><span class="mi">5</span><span class="p">,</span><span class="n">high</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="mi">5</span><span class="p">)</span>  
<span class="n">list_batchsize</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">randint</span><span class="p">(</span><span class="mi">6</span><span class="p">,</span><span class="n">high</span><span class="o">=</span><span class="mi">64</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="mi">5</span><span class="p">)</span>    

<span class="n">list_results</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">()</span>

<span class="k">for</span> <span class="n">cmodel</span><span class="p">,</span><span class="n">nmodel</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">models</span><span class="p">,</span><span class="n">nmodels</span><span class="p">):</span>
    <span class="k">for</span> <span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span><span class="n">sequence</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">X_trains</span><span class="p">,</span><span class="n">y_trains</span><span class="p">,</span><span class="n">sequences</span><span class="p">):</span>
        <span class="k">for</span> <span class="n">optimizer</span> <span class="ow">in</span> <span class="n">optimizers</span><span class="p">:</span>
            <span class="c1">#for activation in activations:</span>
                <span class="k">for</span> <span class="n">activationDense</span> <span class="ow">in</span> <span class="n">activationsDense</span><span class="p">:</span>
                    <span class="k">for</span> <span class="n">units</span><span class="p">,</span><span class="n">epochs</span><span class="p">,</span><span class="n">batchsize</span><span class="p">,</span><span class="n">dropout1</span><span class="p">,</span><span class="n">dropout2</span><span class="p">,</span><span class="n">validationsplit</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">list_units</span><span class="p">,</span><span class="n">list_epochs</span><span class="p">,</span><span class="n">list_batchsize</span><span class="p">,</span><span class="n">list_dropout1</span><span class="p">,</span><span class="n">list_dropout2</span><span class="p">,</span><span class="n">list_validationSplit</span><span class="p">):</span> 
                        <span class="n">start</span> <span class="o">=</span> <span class="n">time</span><span class="p">()</span>
                        <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;###########################</span><span class="se">\n</span><span class="s2">&quot;</span><span class="p">)</span>
                        <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;MODEL: &quot;</span><span class="p">,</span> <span class="n">nmodel</span><span class="p">)</span>
                        <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;sequence: &#39;</span><span class="p">,</span><span class="n">sequence</span><span class="p">)</span>
                        <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;units: &#39;</span><span class="p">,</span><span class="n">units</span><span class="p">)</span>
                        <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;dropout1: &#39;</span><span class="p">,</span><span class="n">dropout1</span><span class="p">)</span>
                        <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;dropout2: &#39;</span><span class="p">,</span><span class="n">dropout2</span><span class="p">)</span>
                        <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;optimizer:&#39;</span><span class="p">,</span><span class="n">optimizer</span><span class="p">)</span>
                        <span class="c1">#print(&#39;activation:&#39;,activation)</span>
                        <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;activationDense:&#39;</span><span class="p">,</span><span class="n">activationDense</span><span class="p">)</span>
                        <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;epochs:&#39;</span><span class="p">,</span><span class="n">epochs</span><span class="p">)</span>
                        <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;batchsize:&#39;</span><span class="p">,</span><span class="n">batchsize</span><span class="p">)</span>
                        <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;validation_split:&#39;</span><span class="p">,</span><span class="n">validationsplit</span><span class="p">)</span>
                    
                        <span class="n">model</span> <span class="o">=</span> <span class="n">_model</span><span class="p">(</span><span class="n">cmodel</span><span class="p">,</span><span class="n">units</span><span class="p">,</span><span class="n">activationDense</span><span class="p">,</span><span class="n">dropout1</span><span class="p">,</span><span class="n">dropout2</span><span class="p">,</span><span class="n">optimizer</span><span class="p">)</span>
                        <span class="n">history</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">epochs</span><span class="o">=</span><span class="n">epochs</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="n">batchsize</span><span class="p">,</span> <span class="n">validation_split</span><span class="o">=</span><span class="n">validationsplit</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
                        <span class="n">end</span> <span class="o">=</span> <span class="n">time</span><span class="p">()</span>
                        <span class="n">totalTime</span> <span class="o">=</span> <span class="n">end</span><span class="o">-</span><span class="n">start</span>
                        <span class="nb">print</span> <span class="p">(</span><span class="s1">&#39;Execution time: &#39;</span><span class="p">,</span><span class="n">totalTime</span><span class="p">)</span>

                        <span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
                        <span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">history</span><span class="o">.</span><span class="n">history</span><span class="p">[</span><span class="s1">&#39;loss&#39;</span><span class="p">],</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;Training loss&#39;</span><span class="p">)</span>
                        <span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">history</span><span class="o">.</span><span class="n">history</span><span class="p">[</span><span class="s1">&#39;val_loss&#39;</span><span class="p">],</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;Validation loss&#39;</span><span class="p">)</span>
                        <span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">();</span>

                        <span class="n">X_train_pred</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
                        
                        <span class="n">mae</span><span class="p">,</span><span class="n">rmse</span><span class="p">,</span><span class="n">mse</span> <span class="o">=</span> <span class="n">evaluate_prediction</span><span class="p">(</span><span class="n">X_train_pred</span><span class="p">,</span> <span class="n">X_train</span><span class="p">,</span><span class="n">nmodel</span><span class="p">)</span>
                        
                        <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Train RMSE: </span><span class="si">%.3f</span><span class="s1">&#39;</span> <span class="o">%</span> <span class="n">rmse</span><span class="p">);</span>
                        <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Train MSE: </span><span class="si">%.3f</span><span class="s1">&#39;</span> <span class="o">%</span> <span class="n">mse</span><span class="p">);</span>
                        <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Train MAE: </span><span class="si">%.3f</span><span class="s1">&#39;</span> <span class="o">%</span> <span class="n">mae</span><span class="p">);</span>
                        
                        <span class="n">result</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">({</span>
                                               <span class="c1">#&#39;activation&#39;:[activation],</span>
                                               <span class="s1">&#39;model&#39;</span><span class="p">:[</span><span class="n">nmodel</span><span class="p">],</span>
                                               <span class="s1">&#39;sequence&#39;</span><span class="p">:[</span><span class="n">sequence</span><span class="p">],</span>
                                               <span class="s1">&#39;activationDense&#39;</span><span class="p">:[</span><span class="n">activationDense</span><span class="p">],</span>
                                               <span class="s1">&#39;optimizer&#39;</span><span class="p">:[</span><span class="n">optimizer</span><span class="p">],</span>
                                               <span class="s1">&#39;dropout1&#39;</span><span class="p">:[</span><span class="n">dropout1</span><span class="p">],</span>
                                               <span class="s1">&#39;dropout2&#39;</span><span class="p">:[</span><span class="n">dropout2</span><span class="p">],</span>
                                               <span class="s1">&#39;units&#39;</span><span class="p">:[</span><span class="n">units</span><span class="p">],</span>
                                               <span class="s1">&#39;epochs&#39;</span><span class="p">:[</span><span class="n">epochs</span><span class="p">],</span>
                                               <span class="s1">&#39;batchsize&#39;</span><span class="p">:[</span><span class="n">batchsize</span><span class="p">],</span>
                                               <span class="s1">&#39;validation_split&#39;</span><span class="p">:[</span><span class="n">validationsplit</span><span class="p">],</span>
                                               
                                               <span class="s1">&#39;RMSE&#39;</span><span class="p">:[</span><span class="n">rmse</span><span class="p">],</span>
                                               <span class="s1">&#39;MSE&#39;</span><span class="p">:[</span><span class="n">mse</span><span class="p">],</span>
                                               <span class="s1">&#39;MAE&#39;</span><span class="p">:[</span><span class="n">mae</span><span class="p">],</span>                            
                                               <span class="s1">&#39;Time&#39;</span><span class="p">:[</span><span class="n">totalTime</span><span class="p">]})</span>
                        <span class="n">list_results</span> <span class="o">=</span> <span class="n">list_results</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">result</span><span class="p">)</span> 
</pre></div>

     </div>
</div>
</div>
</div>

<div class="jp-Cell-outputWrapper">


<div class="jp-OutputArea jp-Cell-outputArea">

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>###########################

MODEL:  LSTM
sequence:  1h
units:  43
dropout1:  0.40519643149940265
dropout2:  0.3312343747027119
optimizer: adam
activationDense: tanh
epochs: 56
batchsize: 11
validation_split: 0.1
Model: &#34;sequential&#34;
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
lstm (LSTM)                  (None, 6, 43)             7740      
_________________________________________________________________
dropout (Dropout)            (None, 6, 43)             0         
_________________________________________________________________
lstm_1 (LSTM)                (None, 6, 43)             14964     
_________________________________________________________________
dropout_1 (Dropout)          (None, 6, 43)             0         
_________________________________________________________________
time_distributed (TimeDistri (None, 6, 1)              44        
=================================================================
Total params: 22,748
Trainable params: 22,748
Non-trainable params: 0
_________________________________________________________________
Epoch 1/56
326/326 [==============================] - 3s 10ms/step - loss: 0.4317 - val_loss: 0.3462
Epoch 2/56
326/326 [==============================] - 2s 5ms/step - loss: 0.3034 - val_loss: 0.2480
Epoch 3/56
326/326 [==============================] - 2s 5ms/step - loss: 0.2837 - val_loss: 0.2247
Epoch 4/56
326/326 [==============================] - 1s 5ms/step - loss: 0.2820 - val_loss: 0.2119
Epoch 5/56
326/326 [==============================] - 2s 5ms/step - loss: 0.2802 - val_loss: 0.2129
Epoch 6/56
326/326 [==============================] - 2s 5ms/step - loss: 0.2804 - val_loss: 0.2104
Epoch 7/56
326/326 [==============================] - 2s 5ms/step - loss: 0.2792 - val_loss: 0.2011
Epoch 8/56
326/326 [==============================] - 2s 5ms/step - loss: 0.2789 - val_loss: 0.2045
Epoch 9/56
326/326 [==============================] - 2s 5ms/step - loss: 0.2775 - val_loss: 0.1950
Epoch 10/56
326/326 [==============================] - 2s 5ms/step - loss: 0.2766 - val_loss: 0.1824
Epoch 11/56
326/326 [==============================] - 2s 5ms/step - loss: 0.2772 - val_loss: 0.1871
Epoch 12/56
326/326 [==============================] - 2s 5ms/step - loss: 0.2760 - val_loss: 0.1829
Epoch 13/56
326/326 [==============================] - 2s 5ms/step - loss: 0.2754 - val_loss: 0.1664
Epoch 14/56
326/326 [==============================] - 2s 5ms/step - loss: 0.2737 - val_loss: 0.1608
Epoch 15/56
326/326 [==============================] - 2s 5ms/step - loss: 0.2731 - val_loss: 0.1508
Epoch 16/56
326/326 [==============================] - 2s 5ms/step - loss: 0.2716 - val_loss: 0.1385
Epoch 17/56
326/326 [==============================] - 1s 4ms/step - loss: 0.2710 - val_loss: 0.1337
Epoch 18/56
326/326 [==============================] - 1s 4ms/step - loss: 0.2704 - val_loss: 0.1261
Epoch 19/56
326/326 [==============================] - 1s 4ms/step - loss: 0.2689 - val_loss: 0.1201
Epoch 20/56
326/326 [==============================] - 1s 4ms/step - loss: 0.2685 - val_loss: 0.1205
Epoch 21/56
326/326 [==============================] - 2s 5ms/step - loss: 0.2676 - val_loss: 0.1225
Epoch 22/56
326/326 [==============================] - 1s 5ms/step - loss: 0.2665 - val_loss: 0.1159
Epoch 23/56
326/326 [==============================] - 1s 4ms/step - loss: 0.2669 - val_loss: 0.1121
Epoch 24/56
326/326 [==============================] - 1s 4ms/step - loss: 0.2658 - val_loss: 0.1120
Epoch 25/56
326/326 [==============================] - 1s 5ms/step - loss: 0.2666 - val_loss: 0.1069
Epoch 26/56
326/326 [==============================] - 1s 4ms/step - loss: 0.2661 - val_loss: 0.1087
Epoch 27/56
326/326 [==============================] - 1s 5ms/step - loss: 0.2655 - val_loss: 0.1038
Epoch 28/56
326/326 [==============================] - 1s 4ms/step - loss: 0.2657 - val_loss: 0.1040
Epoch 29/56
326/326 [==============================] - 1s 4ms/step - loss: 0.2657 - val_loss: 0.1043
Epoch 30/56
326/326 [==============================] - 1s 5ms/step - loss: 0.2651 - val_loss: 0.1003
Epoch 31/56
326/326 [==============================] - 1s 5ms/step - loss: 0.2647 - val_loss: 0.1007
Epoch 32/56
326/326 [==============================] - 2s 5ms/step - loss: 0.2645 - val_loss: 0.0992
Epoch 33/56
326/326 [==============================] - 1s 4ms/step - loss: 0.2633 - val_loss: 0.1007
Epoch 34/56
326/326 [==============================] - 1s 4ms/step - loss: 0.2636 - val_loss: 0.0990
Epoch 35/56
326/326 [==============================] - 1s 4ms/step - loss: 0.2637 - val_loss: 0.0954
Epoch 36/56
326/326 [==============================] - 1s 5ms/step - loss: 0.2630 - val_loss: 0.0987
Epoch 37/56
326/326 [==============================] - 1s 5ms/step - loss: 0.2629 - val_loss: 0.0982
Epoch 38/56
326/326 [==============================] - 1s 4ms/step - loss: 0.2629 - val_loss: 0.0954
Epoch 39/56
326/326 [==============================] - 1s 4ms/step - loss: 0.2630 - val_loss: 0.0967
Epoch 40/56
326/326 [==============================] - 1s 4ms/step - loss: 0.2629 - val_loss: 0.0977
Epoch 41/56
326/326 [==============================] - 1s 4ms/step - loss: 0.2636 - val_loss: 0.1005
Epoch 42/56
326/326 [==============================] - 2s 5ms/step - loss: 0.2633 - val_loss: 0.0968
Epoch 43/56
326/326 [==============================] - 2s 5ms/step - loss: 0.2626 - val_loss: 0.0937
Epoch 44/56
326/326 [==============================] - 1s 5ms/step - loss: 0.2629 - val_loss: 0.0953
Epoch 45/56
326/326 [==============================] - 1s 4ms/step - loss: 0.2630 - val_loss: 0.0895
Epoch 46/56
326/326 [==============================] - 1s 4ms/step - loss: 0.2631 - val_loss: 0.0935
Epoch 47/56
326/326 [==============================] - 1s 4ms/step - loss: 0.2623 - val_loss: 0.0926
Epoch 48/56
326/326 [==============================] - 1s 4ms/step - loss: 0.2616 - val_loss: 0.0977
Epoch 49/56
326/326 [==============================] - 1s 4ms/step - loss: 0.2615 - val_loss: 0.0878
Epoch 50/56
326/326 [==============================] - 1s 5ms/step - loss: 0.2616 - val_loss: 0.0944
Epoch 51/56
326/326 [==============================] - 1s 4ms/step - loss: 0.2617 - val_loss: 0.0920
Epoch 52/56
326/326 [==============================] - 2s 5ms/step - loss: 0.2614 - val_loss: 0.0931
Epoch 53/56
326/326 [==============================] - 2s 5ms/step - loss: 0.2613 - val_loss: 0.0927
Epoch 54/56
326/326 [==============================] - 2s 5ms/step - loss: 0.2613 - val_loss: 0.0905
Epoch 55/56
326/326 [==============================] - 1s 4ms/step - loss: 0.2609 - val_loss: 0.0960
Epoch 56/56
326/326 [==============================] - 1s 4ms/step - loss: 0.2614 - val_loss: 0.0906
Execution time:  92.2193295955658
LSTM:
Mean Absolute Error: 0.1655
Root Mean Square Error: 0.5747
Mean Square Error: 0.3303

Train RMSE: 0.575
Train MSE: 0.330
Train MAE: 0.165
###########################

MODEL:  LSTM
sequence:  1h
units:  45
dropout1:  0.11814836227952394
dropout2:  0.24325404382648977
optimizer: adam
activationDense: tanh
epochs: 43
batchsize: 30
validation_split: 0.2
Model: &#34;sequential_1&#34;
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
lstm_2 (LSTM)                (None, 6, 45)             8460      
_________________________________________________________________
dropout_2 (Dropout)          (None, 6, 45)             0         
_________________________________________________________________
lstm_3 (LSTM)                (None, 6, 45)             16380     
_________________________________________________________________
dropout_3 (Dropout)          (None, 6, 45)             0         
_________________________________________________________________
time_distributed_1 (TimeDist (None, 6, 1)              46        
=================================================================
Total params: 24,886
Trainable params: 24,886
Non-trainable params: 0
_________________________________________________________________
Epoch 1/43
107/107 [==============================] - 2s 16ms/step - loss: 0.5278 - val_loss: 0.3699
Epoch 2/43
107/107 [==============================] - 1s 7ms/step - loss: 0.3832 - val_loss: 0.3112
Epoch 3/43
107/107 [==============================] - 1s 7ms/step - loss: 0.3322 - val_loss: 0.2638
Epoch 4/43
107/107 [==============================] - 1s 7ms/step - loss: 0.2965 - val_loss: 0.2365
Epoch 5/43
107/107 [==============================] - 1s 8ms/step - loss: 0.2806 - val_loss: 0.2270
Epoch 6/43
107/107 [==============================] - 1s 8ms/step - loss: 0.2749 - val_loss: 0.2234
Epoch 7/43
107/107 [==============================] - 1s 7ms/step - loss: 0.2741 - val_loss: 0.2225
Epoch 8/43
107/107 [==============================] - 1s 7ms/step - loss: 0.2723 - val_loss: 0.2210
Epoch 9/43
107/107 [==============================] - 1s 7ms/step - loss: 0.2724 - val_loss: 0.2208
Epoch 10/43
107/107 [==============================] - 1s 7ms/step - loss: 0.2712 - val_loss: 0.2180
Epoch 11/43
107/107 [==============================] - 1s 7ms/step - loss: 0.2714 - val_loss: 0.2181
Epoch 12/43
107/107 [==============================] - 1s 7ms/step - loss: 0.2714 - val_loss: 0.2195
Epoch 13/43
107/107 [==============================] - 1s 7ms/step - loss: 0.2705 - val_loss: 0.2168
Epoch 14/43
107/107 [==============================] - 1s 7ms/step - loss: 0.2706 - val_loss: 0.2163
Epoch 15/43
107/107 [==============================] - 1s 7ms/step - loss: 0.2696 - val_loss: 0.2140
Epoch 16/43
107/107 [==============================] - 1s 7ms/step - loss: 0.2695 - val_loss: 0.2140
Epoch 17/43
107/107 [==============================] - 1s 7ms/step - loss: 0.2685 - val_loss: 0.2105
Epoch 18/43
107/107 [==============================] - 1s 7ms/step - loss: 0.2686 - val_loss: 0.2069
Epoch 19/43
107/107 [==============================] - 1s 7ms/step - loss: 0.2677 - val_loss: 0.2038
Epoch 20/43
107/107 [==============================] - 1s 7ms/step - loss: 0.2677 - val_loss: 0.2034
Epoch 21/43
107/107 [==============================] - 1s 7ms/step - loss: 0.2664 - val_loss: 0.1996
Epoch 22/43
107/107 [==============================] - 1s 7ms/step - loss: 0.2667 - val_loss: 0.1969
Epoch 23/43
107/107 [==============================] - 1s 7ms/step - loss: 0.2667 - val_loss: 0.1970
Epoch 24/43
107/107 [==============================] - 1s 8ms/step - loss: 0.2656 - val_loss: 0.1941
Epoch 25/43
107/107 [==============================] - 1s 8ms/step - loss: 0.2653 - val_loss: 0.1905
Epoch 26/43
107/107 [==============================] - 1s 8ms/step - loss: 0.2646 - val_loss: 0.1919
Epoch 27/43
107/107 [==============================] - 1s 7ms/step - loss: 0.2649 - val_loss: 0.1902
Epoch 28/43
107/107 [==============================] - 1s 7ms/step - loss: 0.2648 - val_loss: 0.1889
Epoch 29/43
107/107 [==============================] - 1s 7ms/step - loss: 0.2645 - val_loss: 0.1886
Epoch 30/43
107/107 [==============================] - 1s 7ms/step - loss: 0.2632 - val_loss: 0.1878
Epoch 31/43
107/107 [==============================] - 1s 7ms/step - loss: 0.2625 - val_loss: 0.1878
Epoch 32/43
107/107 [==============================] - 1s 7ms/step - loss: 0.2627 - val_loss: 0.1858
Epoch 33/43
107/107 [==============================] - 1s 7ms/step - loss: 0.2625 - val_loss: 0.1826
Epoch 34/43
107/107 [==============================] - 1s 7ms/step - loss: 0.2626 - val_loss: 0.1832
Epoch 35/43
107/107 [==============================] - 1s 7ms/step - loss: 0.2620 - val_loss: 0.1823
Epoch 36/43
107/107 [==============================] - 1s 7ms/step - loss: 0.2627 - val_loss: 0.1816
Epoch 37/43
107/107 [==============================] - 1s 7ms/step - loss: 0.2619 - val_loss: 0.1821
Epoch 38/43
107/107 [==============================] - 1s 7ms/step - loss: 0.2614 - val_loss: 0.1826
Epoch 39/43
107/107 [==============================] - 1s 7ms/step - loss: 0.2614 - val_loss: 0.1812
Epoch 40/43
107/107 [==============================] - 1s 7ms/step - loss: 0.2615 - val_loss: 0.1802
Epoch 41/43
107/107 [==============================] - 1s 7ms/step - loss: 0.2600 - val_loss: 0.1814
Epoch 42/43
107/107 [==============================] - 1s 7ms/step - loss: 0.2601 - val_loss: 0.1800
Epoch 43/43
107/107 [==============================] - 1s 7ms/step - loss: 0.2607 - val_loss: 0.1804
Execution time:  40.12517833709717
LSTM:
Mean Absolute Error: 0.1552
Root Mean Square Error: 0.5734
Mean Square Error: 0.3288

Train RMSE: 0.573
Train MSE: 0.329
Train MAE: 0.155
###########################

MODEL:  LSTM
sequence:  1h
units:  43
dropout1:  0.40519643149940265
dropout2:  0.3312343747027119
optimizer: adam
activationDense: sigmoid
epochs: 56
batchsize: 11
validation_split: 0.1
Model: &#34;sequential_2&#34;
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
lstm_4 (LSTM)                (None, 6, 43)             7740      
_________________________________________________________________
dropout_4 (Dropout)          (None, 6, 43)             0         
_________________________________________________________________
lstm_5 (LSTM)                (None, 6, 43)             14964     
_________________________________________________________________
dropout_5 (Dropout)          (None, 6, 43)             0         
_________________________________________________________________
time_distributed_2 (TimeDist (None, 6, 1)              44        
=================================================================
Total params: 22,748
Trainable params: 22,748
Non-trainable params: 0
_________________________________________________________________
Epoch 1/56
326/326 [==============================] - 3s 8ms/step - loss: 0.6393 - val_loss: 0.8293
Epoch 2/56
326/326 [==============================] - 1s 4ms/step - loss: 0.5356 - val_loss: 0.8101
Epoch 3/56
326/326 [==============================] - 1s 4ms/step - loss: 0.5193 - val_loss: 0.8073
Epoch 4/56
326/326 [==============================] - 1s 4ms/step - loss: 0.5036 - val_loss: 0.8065
Epoch 5/56
326/326 [==============================] - 1s 4ms/step - loss: 0.5018 - val_loss: 0.8063
Epoch 6/56
326/326 [==============================] - 1s 5ms/step - loss: 0.5010 - val_loss: 0.8061
Epoch 7/56
326/326 [==============================] - 2s 5ms/step - loss: 0.5009 - val_loss: 0.8061
Epoch 8/56
326/326 [==============================] - 2s 5ms/step - loss: 0.5002 - val_loss: 0.8060
Epoch 9/56
326/326 [==============================] - 1s 4ms/step - loss: 0.5001 - val_loss: 0.8060
Epoch 10/56
326/326 [==============================] - 1s 4ms/step - loss: 0.5000 - val_loss: 0.8060
Epoch 11/56
326/326 [==============================] - 1s 4ms/step - loss: 0.4998 - val_loss: 0.8060
Epoch 12/56
326/326 [==============================] - 1s 4ms/step - loss: 0.4996 - val_loss: 0.8060
Epoch 13/56
326/326 [==============================] - 1s 4ms/step - loss: 0.4996 - val_loss: 0.8060
Epoch 14/56
326/326 [==============================] - 1s 4ms/step - loss: 0.4991 - val_loss: 0.8059
Epoch 15/56
326/326 [==============================] - 1s 4ms/step - loss: 0.4993 - val_loss: 0.8059
Epoch 16/56
326/326 [==============================] - 1s 4ms/step - loss: 0.4988 - val_loss: 0.8059
Epoch 17/56
326/326 [==============================] - 1s 4ms/step - loss: 0.4986 - val_loss: 0.8059
Epoch 18/56
326/326 [==============================] - 2s 5ms/step - loss: 0.4988 - val_loss: 0.8059
Epoch 19/56
326/326 [==============================] - 2s 5ms/step - loss: 0.4987 - val_loss: 0.8059
Epoch 20/56
326/326 [==============================] - 1s 4ms/step - loss: 0.4985 - val_loss: 0.8059
Epoch 21/56
326/326 [==============================] - 1s 4ms/step - loss: 0.4985 - val_loss: 0.8059
Epoch 22/56
326/326 [==============================] - 1s 4ms/step - loss: 0.4984 - val_loss: 0.8059
Epoch 23/56
326/326 [==============================] - 2s 5ms/step - loss: 0.4983 - val_loss: 0.8059
Epoch 24/56
326/326 [==============================] - 1s 5ms/step - loss: 0.4982 - val_loss: 0.8059
Epoch 25/56
326/326 [==============================] - 1s 4ms/step - loss: 0.4986 - val_loss: 0.8059
Epoch 26/56
326/326 [==============================] - 1s 4ms/step - loss: 0.4981 - val_loss: 0.8059
Epoch 27/56
326/326 [==============================] - 1s 4ms/step - loss: 0.4984 - val_loss: 0.8059
Epoch 28/56
326/326 [==============================] - 1s 4ms/step - loss: 0.4983 - val_loss: 0.8059
Epoch 29/56
326/326 [==============================] - 2s 5ms/step - loss: 0.4980 - val_loss: 0.8059
Epoch 30/56
326/326 [==============================] - 1s 5ms/step - loss: 0.4981 - val_loss: 0.8059
Epoch 31/56
326/326 [==============================] - 1s 4ms/step - loss: 0.4979 - val_loss: 0.8059
Epoch 32/56
326/326 [==============================] - 1s 4ms/step - loss: 0.4974 - val_loss: 0.8059
Epoch 33/56
326/326 [==============================] - 1s 4ms/step - loss: 0.4981 - val_loss: 0.8059
Epoch 34/56
326/326 [==============================] - 1s 4ms/step - loss: 0.4978 - val_loss: 0.8059
Epoch 35/56
326/326 [==============================] - 1s 4ms/step - loss: 0.4978 - val_loss: 0.8059
Epoch 36/56
326/326 [==============================] - 1s 5ms/step - loss: 0.4979 - val_loss: 0.8059
Epoch 37/56
326/326 [==============================] - 1s 4ms/step - loss: 0.4975 - val_loss: 0.8059
Epoch 38/56
326/326 [==============================] - 1s 4ms/step - loss: 0.4979 - val_loss: 0.8059
Epoch 39/56
326/326 [==============================] - 1s 5ms/step - loss: 0.4978 - val_loss: 0.8059
Epoch 40/56
326/326 [==============================] - 2s 5ms/step - loss: 0.4979 - val_loss: 0.8059
Epoch 41/56
326/326 [==============================] - 1s 4ms/step - loss: 0.4974 - val_loss: 0.8059
Epoch 42/56
326/326 [==============================] - 1s 4ms/step - loss: 0.4978 - val_loss: 0.8059
Epoch 43/56
326/326 [==============================] - 1s 4ms/step - loss: 0.4974 - val_loss: 0.8059
Epoch 44/56
326/326 [==============================] - 2s 5ms/step - loss: 0.4979 - val_loss: 0.8059
Epoch 45/56
326/326 [==============================] - 2s 5ms/step - loss: 0.4974 - val_loss: 0.8059
Epoch 46/56
326/326 [==============================] - 1s 5ms/step - loss: 0.4974 - val_loss: 0.8059
Epoch 47/56
326/326 [==============================] - 1s 5ms/step - loss: 0.4977 - val_loss: 0.8059
Epoch 48/56
326/326 [==============================] - 1s 4ms/step - loss: 0.4972 - val_loss: 0.8059
Epoch 49/56
326/326 [==============================] - 1s 4ms/step - loss: 0.4973 - val_loss: 0.8059
Epoch 50/56
326/326 [==============================] - 2s 5ms/step - loss: 0.4972 - val_loss: 0.8059
Epoch 51/56
326/326 [==============================] - 2s 5ms/step - loss: 0.4973 - val_loss: 0.8059
Epoch 52/56
326/326 [==============================] - 1s 4ms/step - loss: 0.4974 - val_loss: 0.8059
Epoch 53/56
326/326 [==============================] - 1s 4ms/step - loss: 0.4970 - val_loss: 0.8059
Epoch 54/56
326/326 [==============================] - 1s 5ms/step - loss: 0.4973 - val_loss: 0.8059
Epoch 55/56
326/326 [==============================] - 1s 4ms/step - loss: 0.4971 - val_loss: 0.8059
Epoch 56/56
326/326 [==============================] - 1s 4ms/step - loss: 0.4970 - val_loss: 0.8059
Execution time:  89.09990072250366
LSTM:
Mean Absolute Error: 0.4907
Root Mean Square Error: 0.7503
Mean Square Error: 0.5629

Train RMSE: 0.750
Train MSE: 0.563
Train MAE: 0.491
###########################

MODEL:  LSTM
sequence:  1h
units:  45
dropout1:  0.11814836227952394
dropout2:  0.24325404382648977
optimizer: adam
activationDense: sigmoid
epochs: 43
batchsize: 30
validation_split: 0.2
Model: &#34;sequential_3&#34;
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
lstm_6 (LSTM)                (None, 6, 45)             8460      
_________________________________________________________________
dropout_6 (Dropout)          (None, 6, 45)             0         
_________________________________________________________________
lstm_7 (LSTM)                (None, 6, 45)             16380     
_________________________________________________________________
dropout_7 (Dropout)          (None, 6, 45)             0         
_________________________________________________________________
time_distributed_3 (TimeDist (None, 6, 1)              46        
=================================================================
Total params: 24,886
Trainable params: 24,886
Non-trainable params: 0
_________________________________________________________________
Epoch 1/43
107/107 [==============================] - 2s 18ms/step - loss: 0.7585 - val_loss: 0.7674
Epoch 2/43
107/107 [==============================] - 1s 7ms/step - loss: 0.5761 - val_loss: 0.7114
Epoch 3/43
107/107 [==============================] - 1s 7ms/step - loss: 0.5480 - val_loss: 0.6899
Epoch 4/43
107/107 [==============================] - 1s 7ms/step - loss: 0.5353 - val_loss: 0.6780
Epoch 5/43
107/107 [==============================] - 1s 7ms/step - loss: 0.5275 - val_loss: 0.6707
Epoch 6/43
107/107 [==============================] - 1s 7ms/step - loss: 0.5188 - val_loss: 0.6681
Epoch 7/43
107/107 [==============================] - 1s 7ms/step - loss: 0.5035 - val_loss: 0.6648
Epoch 8/43
107/107 [==============================] - 1s 7ms/step - loss: 0.5001 - val_loss: 0.6639
Epoch 9/43
107/107 [==============================] - 1s 7ms/step - loss: 0.4991 - val_loss: 0.6634
Epoch 10/43
107/107 [==============================] - 1s 7ms/step - loss: 0.4983 - val_loss: 0.6630
Epoch 11/43
107/107 [==============================] - 1s 7ms/step - loss: 0.4979 - val_loss: 0.6631
Epoch 12/43
107/107 [==============================] - 1s 7ms/step - loss: 0.4974 - val_loss: 0.6631
Epoch 13/43
107/107 [==============================] - 1s 7ms/step - loss: 0.4970 - val_loss: 0.6629
Epoch 14/43
107/107 [==============================] - 1s 7ms/step - loss: 0.4967 - val_loss: 0.6628
Epoch 15/43
107/107 [==============================] - 1s 7ms/step - loss: 0.4966 - val_loss: 0.6627
Epoch 16/43
107/107 [==============================] - 1s 7ms/step - loss: 0.4966 - val_loss: 0.6627
Epoch 17/43
107/107 [==============================] - 1s 7ms/step - loss: 0.4962 - val_loss: 0.6628
Epoch 18/43
107/107 [==============================] - 1s 7ms/step - loss: 0.4958 - val_loss: 0.6628
Epoch 19/43
107/107 [==============================] - 1s 8ms/step - loss: 0.4958 - val_loss: 0.6624
Epoch 20/43
107/107 [==============================] - 1s 8ms/step - loss: 0.4956 - val_loss: 0.6626
Epoch 21/43
107/107 [==============================] - 1s 8ms/step - loss: 0.4954 - val_loss: 0.6627
Epoch 22/43
107/107 [==============================] - 1s 7ms/step - loss: 0.4952 - val_loss: 0.6625
Epoch 23/43
107/107 [==============================] - 1s 7ms/step - loss: 0.4958 - val_loss: 0.6625
Epoch 24/43
107/107 [==============================] - 1s 7ms/step - loss: 0.4952 - val_loss: 0.6627
Epoch 25/43
107/107 [==============================] - 1s 7ms/step - loss: 0.4952 - val_loss: 0.6623
Epoch 26/43
107/107 [==============================] - 1s 7ms/step - loss: 0.4952 - val_loss: 0.6624
Epoch 27/43
107/107 [==============================] - 1s 7ms/step - loss: 0.4949 - val_loss: 0.6627
Epoch 28/43
107/107 [==============================] - 1s 7ms/step - loss: 0.4950 - val_loss: 0.6629
Epoch 29/43
107/107 [==============================] - 1s 7ms/step - loss: 0.4951 - val_loss: 0.6624
Epoch 30/43
107/107 [==============================] - 1s 7ms/step - loss: 0.4947 - val_loss: 0.6623
Epoch 31/43
107/107 [==============================] - 1s 7ms/step - loss: 0.4949 - val_loss: 0.6623
Epoch 32/43
107/107 [==============================] - 1s 7ms/step - loss: 0.4947 - val_loss: 0.6627
Epoch 33/43
107/107 [==============================] - 1s 7ms/step - loss: 0.4948 - val_loss: 0.6624
Epoch 34/43
107/107 [==============================] - 1s 7ms/step - loss: 0.4946 - val_loss: 0.6624
Epoch 35/43
107/107 [==============================] - 1s 7ms/step - loss: 0.4946 - val_loss: 0.6627
Epoch 36/43
107/107 [==============================] - 1s 7ms/step - loss: 0.4947 - val_loss: 0.6624
Epoch 37/43
107/107 [==============================] - 1s 7ms/step - loss: 0.4945 - val_loss: 0.6627
Epoch 38/43
107/107 [==============================] - 1s 7ms/step - loss: 0.4948 - val_loss: 0.6625
Epoch 39/43
107/107 [==============================] - 1s 8ms/step - loss: 0.4945 - val_loss: 0.6620
Epoch 40/43
107/107 [==============================] - 1s 8ms/step - loss: 0.4943 - val_loss: 0.6625
Epoch 41/43
107/107 [==============================] - 1s 8ms/step - loss: 0.4943 - val_loss: 0.6622
Epoch 42/43
107/107 [==============================] - 1s 7ms/step - loss: 0.4942 - val_loss: 0.6622
Epoch 43/43
107/107 [==============================] - 1s 7ms/step - loss: 0.4945 - val_loss: 0.6622
Execution time:  41.00082015991211
LSTM:
Mean Absolute Error: 0.4926
Root Mean Square Error: 0.7513
Mean Square Error: 0.5645

Train RMSE: 0.751
Train MSE: 0.564
Train MAE: 0.493
###########################

MODEL:  LSTM
sequence:  1h
units:  43
dropout1:  0.40519643149940265
dropout2:  0.3312343747027119
optimizer: adadelta
activationDense: tanh
epochs: 56
batchsize: 11
validation_split: 0.1
Model: &#34;sequential_4&#34;
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
lstm_8 (LSTM)                (None, 6, 43)             7740      
_________________________________________________________________
dropout_8 (Dropout)          (None, 6, 43)             0         
_________________________________________________________________
lstm_9 (LSTM)                (None, 6, 43)             14964     
_________________________________________________________________
dropout_9 (Dropout)          (None, 6, 43)             0         
_________________________________________________________________
time_distributed_4 (TimeDist (None, 6, 1)              44        
=================================================================
Total params: 22,748
Trainable params: 22,748
Non-trainable params: 0
_________________________________________________________________
Epoch 1/56
326/326 [==============================] - 2s 8ms/step - loss: 0.7058 - val_loss: 0.8053
Epoch 2/56
326/326 [==============================] - 1s 4ms/step - loss: 0.7052 - val_loss: 0.8043
Epoch 3/56
326/326 [==============================] - 1s 4ms/step - loss: 0.7046 - val_loss: 0.8033
Epoch 4/56
326/326 [==============================] - 1s 4ms/step - loss: 0.7041 - val_loss: 0.8021
Epoch 5/56
326/326 [==============================] - 2s 5ms/step - loss: 0.7035 - val_loss: 0.8010
Epoch 6/56
326/326 [==============================] - 1s 4ms/step - loss: 0.7029 - val_loss: 0.7998
Epoch 7/56
326/326 [==============================] - 1s 4ms/step - loss: 0.7023 - val_loss: 0.7986
Epoch 8/56
326/326 [==============================] - 1s 4ms/step - loss: 0.7017 - val_loss: 0.7973
Epoch 9/56
326/326 [==============================] - 1s 4ms/step - loss: 0.7011 - val_loss: 0.7960
Epoch 10/56
326/326 [==============================] - 1s 4ms/step - loss: 0.7004 - val_loss: 0.7947
Epoch 11/56
326/326 [==============================] - 1s 4ms/step - loss: 0.6998 - val_loss: 0.7934
Epoch 12/56
326/326 [==============================] - 1s 4ms/step - loss: 0.6990 - val_loss: 0.7920
Epoch 13/56
326/326 [==============================] - 1s 4ms/step - loss: 0.6983 - val_loss: 0.7906
Epoch 14/56
326/326 [==============================] - 1s 4ms/step - loss: 0.6976 - val_loss: 0.7892
Epoch 15/56
326/326 [==============================] - 2s 5ms/step - loss: 0.6971 - val_loss: 0.7877
Epoch 16/56
326/326 [==============================] - 2s 5ms/step - loss: 0.6962 - val_loss: 0.7863
Epoch 17/56
326/326 [==============================] - 1s 4ms/step - loss: 0.6955 - val_loss: 0.7848
Epoch 18/56
326/326 [==============================] - 1s 4ms/step - loss: 0.6948 - val_loss: 0.7833
Epoch 19/56
326/326 [==============================] - 1s 4ms/step - loss: 0.6940 - val_loss: 0.7817
Epoch 20/56
326/326 [==============================] - 1s 4ms/step - loss: 0.6932 - val_loss: 0.7802
Epoch 21/56
326/326 [==============================] - 1s 4ms/step - loss: 0.6924 - val_loss: 0.7786
Epoch 22/56
326/326 [==============================] - 1s 4ms/step - loss: 0.6917 - val_loss: 0.7770
Epoch 23/56
326/326 [==============================] - 1s 4ms/step - loss: 0.6909 - val_loss: 0.7753
Epoch 24/56
326/326 [==============================] - 1s 4ms/step - loss: 0.6901 - val_loss: 0.7736
Epoch 25/56
326/326 [==============================] - 1s 4ms/step - loss: 0.6893 - val_loss: 0.7720
Epoch 26/56
326/326 [==============================] - 2s 5ms/step - loss: 0.6885 - val_loss: 0.7702
Epoch 27/56
326/326 [==============================] - 2s 5ms/step - loss: 0.6876 - val_loss: 0.7685
Epoch 28/56
326/326 [==============================] - 1s 4ms/step - loss: 0.6867 - val_loss: 0.7667
Epoch 29/56
326/326 [==============================] - 1s 4ms/step - loss: 0.6857 - val_loss: 0.7649
Epoch 30/56
326/326 [==============================] - 1s 4ms/step - loss: 0.6849 - val_loss: 0.7631
Epoch 31/56
326/326 [==============================] - 1s 4ms/step - loss: 0.6840 - val_loss: 0.7612
Epoch 32/56
326/326 [==============================] - 1s 4ms/step - loss: 0.6831 - val_loss: 0.7593
Epoch 33/56
326/326 [==============================] - 1s 4ms/step - loss: 0.6820 - val_loss: 0.7574
Epoch 34/56
326/326 [==============================] - 1s 5ms/step - loss: 0.6812 - val_loss: 0.7555
Epoch 35/56
326/326 [==============================] - 1s 4ms/step - loss: 0.6802 - val_loss: 0.7535
Epoch 36/56
326/326 [==============================] - 1s 4ms/step - loss: 0.6792 - val_loss: 0.7515
Epoch 37/56
326/326 [==============================] - 2s 5ms/step - loss: 0.6782 - val_loss: 0.7495
Epoch 38/56
326/326 [==============================] - 2s 5ms/step - loss: 0.6773 - val_loss: 0.7475
Epoch 39/56
326/326 [==============================] - 1s 4ms/step - loss: 0.6762 - val_loss: 0.7454
Epoch 40/56
326/326 [==============================] - 1s 4ms/step - loss: 0.6752 - val_loss: 0.7433
Epoch 41/56
326/326 [==============================] - 1s 4ms/step - loss: 0.6742 - val_loss: 0.7412
Epoch 42/56
326/326 [==============================] - 1s 4ms/step - loss: 0.6733 - val_loss: 0.7391
Epoch 43/56
326/326 [==============================] - 1s 4ms/step - loss: 0.6721 - val_loss: 0.7370
Epoch 44/56
326/326 [==============================] - 1s 4ms/step - loss: 0.6711 - val_loss: 0.7349
Epoch 45/56
326/326 [==============================] - 1s 4ms/step - loss: 0.6700 - val_loss: 0.7327
Epoch 46/56
326/326 [==============================] - 1s 4ms/step - loss: 0.6688 - val_loss: 0.7305
Epoch 47/56
326/326 [==============================] - 1s 4ms/step - loss: 0.6677 - val_loss: 0.7283
Epoch 48/56
326/326 [==============================] - 2s 5ms/step - loss: 0.6667 - val_loss: 0.7261
Epoch 49/56
326/326 [==============================] - 1s 5ms/step - loss: 0.6657 - val_loss: 0.7239
Epoch 50/56
326/326 [==============================] - 1s 4ms/step - loss: 0.6645 - val_loss: 0.7216
Epoch 51/56
326/326 [==============================] - 1s 4ms/step - loss: 0.6633 - val_loss: 0.7194
Epoch 52/56
326/326 [==============================] - 1s 4ms/step - loss: 0.6621 - val_loss: 0.7171
Epoch 53/56
326/326 [==============================] - 1s 4ms/step - loss: 0.6611 - val_loss: 0.7148
Epoch 54/56
326/326 [==============================] - 1s 4ms/step - loss: 0.6602 - val_loss: 0.7125
Epoch 55/56
326/326 [==============================] - 1s 4ms/step - loss: 0.6588 - val_loss: 0.7101
Epoch 56/56
326/326 [==============================] - 1s 4ms/step - loss: 0.6576 - val_loss: 0.7077
Execution time:  88.28747320175171
LSTM:
Mean Absolute Error: 0.6603
Root Mean Square Error: 0.9612
Mean Square Error: 0.9238

Train RMSE: 0.961
Train MSE: 0.924
Train MAE: 0.660
###########################

MODEL:  LSTM
sequence:  1h
units:  45
dropout1:  0.11814836227952394
dropout2:  0.24325404382648977
optimizer: adadelta
activationDense: tanh
epochs: 43
batchsize: 30
validation_split: 0.2
Model: &#34;sequential_5&#34;
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
lstm_10 (LSTM)               (None, 6, 45)             8460      
_________________________________________________________________
dropout_10 (Dropout)         (None, 6, 45)             0         
_________________________________________________________________
lstm_11 (LSTM)               (None, 6, 45)             16380     
_________________________________________________________________
dropout_11 (Dropout)         (None, 6, 45)             0         
_________________________________________________________________
time_distributed_5 (TimeDist (None, 6, 1)              46        
=================================================================
Total params: 24,886
Trainable params: 24,886
Non-trainable params: 0
_________________________________________________________________
Epoch 1/43
107/107 [==============================] - 2s 20ms/step - loss: 0.7196 - val_loss: 0.7078
Epoch 2/43
107/107 [==============================] - 1s 7ms/step - loss: 0.7195 - val_loss: 0.7075
Epoch 3/43
107/107 [==============================] - 1s 7ms/step - loss: 0.7192 - val_loss: 0.7072
Epoch 4/43
107/107 [==============================] - 1s 7ms/step - loss: 0.7189 - val_loss: 0.7068
Epoch 5/43
107/107 [==============================] - 1s 7ms/step - loss: 0.7187 - val_loss: 0.7064
Epoch 6/43
107/107 [==============================] - 1s 7ms/step - loss: 0.7183 - val_loss: 0.7061
Epoch 7/43
107/107 [==============================] - 1s 7ms/step - loss: 0.7182 - val_loss: 0.7057
Epoch 8/43
107/107 [==============================] - 1s 7ms/step - loss: 0.7179 - val_loss: 0.7054
Epoch 9/43
107/107 [==============================] - 1s 7ms/step - loss: 0.7176 - val_loss: 0.7050
Epoch 10/43
107/107 [==============================] - 1s 7ms/step - loss: 0.7174 - val_loss: 0.7046
Epoch 11/43
107/107 [==============================] - 1s 7ms/step - loss: 0.7171 - val_loss: 0.7042
Epoch 12/43
107/107 [==============================] - 1s 7ms/step - loss: 0.7168 - val_loss: 0.7039
Epoch 13/43
107/107 [==============================] - 1s 7ms/step - loss: 0.7165 - val_loss: 0.7035
Epoch 14/43
107/107 [==============================] - 1s 8ms/step - loss: 0.7163 - val_loss: 0.7031
Epoch 15/43
107/107 [==============================] - 1s 8ms/step - loss: 0.7160 - val_loss: 0.7027
Epoch 16/43
107/107 [==============================] - 1s 8ms/step - loss: 0.7157 - val_loss: 0.7023
Epoch 17/43
107/107 [==============================] - 1s 7ms/step - loss: 0.7155 - val_loss: 0.7019
Epoch 18/43
107/107 [==============================] - 1s 7ms/step - loss: 0.7152 - val_loss: 0.7015
Epoch 19/43
107/107 [==============================] - 1s 7ms/step - loss: 0.7149 - val_loss: 0.7011
Epoch 20/43
107/107 [==============================] - 1s 7ms/step - loss: 0.7146 - val_loss: 0.7008
Epoch 21/43
107/107 [==============================] - 1s 7ms/step - loss: 0.7144 - val_loss: 0.7004
Epoch 22/43
107/107 [==============================] - 1s 7ms/step - loss: 0.7141 - val_loss: 0.7000
Epoch 23/43
107/107 [==============================] - 1s 7ms/step - loss: 0.7138 - val_loss: 0.6996
Epoch 24/43
107/107 [==============================] - 1s 7ms/step - loss: 0.7136 - val_loss: 0.6992
Epoch 25/43
107/107 [==============================] - 1s 7ms/step - loss: 0.7132 - val_loss: 0.6988
Epoch 26/43
107/107 [==============================] - 1s 7ms/step - loss: 0.7130 - val_loss: 0.6983
Epoch 27/43
107/107 [==============================] - 1s 7ms/step - loss: 0.7127 - val_loss: 0.6979
Epoch 28/43
107/107 [==============================] - 1s 7ms/step - loss: 0.7125 - val_loss: 0.6975
Epoch 29/43
107/107 [==============================] - 1s 7ms/step - loss: 0.7122 - val_loss: 0.6971
Epoch 30/43
107/107 [==============================] - 1s 7ms/step - loss: 0.7119 - val_loss: 0.6967
Epoch 31/43
107/107 [==============================] - 1s 7ms/step - loss: 0.7116 - val_loss: 0.6963
Epoch 32/43
107/107 [==============================] - 1s 7ms/step - loss: 0.7114 - val_loss: 0.6959
Epoch 33/43
107/107 [==============================] - 1s 7ms/step - loss: 0.7110 - val_loss: 0.6955
Epoch 34/43
107/107 [==============================] - 1s 8ms/step - loss: 0.7107 - val_loss: 0.6951
Epoch 35/43
107/107 [==============================] - 1s 8ms/step - loss: 0.7105 - val_loss: 0.6946
Epoch 36/43
107/107 [==============================] - 1s 8ms/step - loss: 0.7102 - val_loss: 0.6942
Epoch 37/43
107/107 [==============================] - 1s 7ms/step - loss: 0.7099 - val_loss: 0.6938
Epoch 38/43
107/107 [==============================] - 1s 7ms/step - loss: 0.7096 - val_loss: 0.6934
Epoch 39/43
107/107 [==============================] - 1s 7ms/step - loss: 0.7094 - val_loss: 0.6930
Epoch 40/43
107/107 [==============================] - 1s 7ms/step - loss: 0.7091 - val_loss: 0.6925
Epoch 41/43
107/107 [==============================] - 1s 7ms/step - loss: 0.7088 - val_loss: 0.6921
Epoch 42/43
107/107 [==============================] - 1s 8ms/step - loss: 0.7085 - val_loss: 0.6917
Epoch 43/43
107/107 [==============================] - 1s 7ms/step - loss: 0.7082 - val_loss: 0.6913
Execution time:  41.589165687561035
LSTM:
Mean Absolute Error: 0.7041
Root Mean Square Error: 0.9905
Mean Square Error: 0.9810

Train RMSE: 0.990
Train MSE: 0.981
Train MAE: 0.704
###########################

MODEL:  LSTM
sequence:  1h
units:  43
dropout1:  0.40519643149940265
dropout2:  0.3312343747027119
optimizer: adadelta
activationDense: sigmoid
epochs: 56
batchsize: 11
validation_split: 0.1
Model: &#34;sequential_6&#34;
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
lstm_12 (LSTM)               (None, 6, 43)             7740      
_________________________________________________________________
dropout_12 (Dropout)         (None, 6, 43)             0         
_________________________________________________________________
lstm_13 (LSTM)               (None, 6, 43)             14964     
_________________________________________________________________
dropout_13 (Dropout)         (None, 6, 43)             0         
_________________________________________________________________
time_distributed_6 (TimeDist (None, 6, 1)              44        
=================================================================
Total params: 22,748
Trainable params: 22,748
Non-trainable params: 0
_________________________________________________________________
Epoch 1/56
326/326 [==============================] - 2s 7ms/step - loss: 0.8905 - val_loss: 1.3057
Epoch 2/56
326/326 [==============================] - 2s 5ms/step - loss: 0.8904 - val_loss: 1.3054
Epoch 3/56
326/326 [==============================] - 2s 5ms/step - loss: 0.8902 - val_loss: 1.3051
Epoch 4/56
326/326 [==============================] - 2s 5ms/step - loss: 0.8900 - val_loss: 1.3048
Epoch 5/56
326/326 [==============================] - 2s 5ms/step - loss: 0.8898 - val_loss: 1.3044
Epoch 6/56
326/326 [==============================] - 1s 5ms/step - loss: 0.8896 - val_loss: 1.3040
Epoch 7/56
326/326 [==============================] - 1s 5ms/step - loss: 0.8894 - val_loss: 1.3037
Epoch 8/56
326/326 [==============================] - 1s 5ms/step - loss: 0.8893 - val_loss: 1.3033
Epoch 9/56
326/326 [==============================] - 1s 5ms/step - loss: 0.8891 - val_loss: 1.3029
Epoch 10/56
326/326 [==============================] - 1s 5ms/step - loss: 0.8889 - val_loss: 1.3025
Epoch 11/56
326/326 [==============================] - 1s 5ms/step - loss: 0.8886 - val_loss: 1.3021
Epoch 12/56
326/326 [==============================] - 2s 5ms/step - loss: 0.8884 - val_loss: 1.3017
Epoch 13/56
326/326 [==============================] - 2s 5ms/step - loss: 0.8882 - val_loss: 1.3013
Epoch 14/56
326/326 [==============================] - 1s 5ms/step - loss: 0.8880 - val_loss: 1.3009
Epoch 15/56
326/326 [==============================] - 1s 5ms/step - loss: 0.8878 - val_loss: 1.3004
Epoch 16/56
326/326 [==============================] - 1s 5ms/step - loss: 0.8875 - val_loss: 1.3000
Epoch 17/56
326/326 [==============================] - 1s 5ms/step - loss: 0.8873 - val_loss: 1.2996
Epoch 18/56
326/326 [==============================] - 1s 4ms/step - loss: 0.8871 - val_loss: 1.2991
Epoch 19/56
326/326 [==============================] - 1s 5ms/step - loss: 0.8869 - val_loss: 1.2987
Epoch 20/56
326/326 [==============================] - 1s 5ms/step - loss: 0.8866 - val_loss: 1.2983
Epoch 21/56
326/326 [==============================] - 1s 5ms/step - loss: 0.8864 - val_loss: 1.2978
Epoch 22/56
326/326 [==============================] - 1s 5ms/step - loss: 0.8862 - val_loss: 1.2973
Epoch 23/56
326/326 [==============================] - 2s 5ms/step - loss: 0.8859 - val_loss: 1.2969
Epoch 24/56
326/326 [==============================] - 1s 5ms/step - loss: 0.8857 - val_loss: 1.2964
Epoch 25/56
326/326 [==============================] - 1s 5ms/step - loss: 0.8854 - val_loss: 1.2960
Epoch 26/56
326/326 [==============================] - 1s 5ms/step - loss: 0.8852 - val_loss: 1.2955
Epoch 27/56
326/326 [==============================] - 2s 5ms/step - loss: 0.8850 - val_loss: 1.2950
Epoch 28/56
326/326 [==============================] - 2s 5ms/step - loss: 0.8847 - val_loss: 1.2945
Epoch 29/56
326/326 [==============================] - 1s 5ms/step - loss: 0.8845 - val_loss: 1.2940
Epoch 30/56
326/326 [==============================] - 1s 5ms/step - loss: 0.8842 - val_loss: 1.2935
Epoch 31/56
326/326 [==============================] - 1s 5ms/step - loss: 0.8839 - val_loss: 1.2930
Epoch 32/56
326/326 [==============================] - 1s 5ms/step - loss: 0.8837 - val_loss: 1.2925
Epoch 33/56
326/326 [==============================] - 2s 5ms/step - loss: 0.8834 - val_loss: 1.2920
Epoch 34/56
326/326 [==============================] - 2s 5ms/step - loss: 0.8832 - val_loss: 1.2915
Epoch 35/56
326/326 [==============================] - 1s 5ms/step - loss: 0.8829 - val_loss: 1.2910
Epoch 36/56
326/326 [==============================] - 2s 5ms/step - loss: 0.8826 - val_loss: 1.2905
Epoch 37/56
326/326 [==============================] - 2s 5ms/step - loss: 0.8824 - val_loss: 1.2900
Epoch 38/56
326/326 [==============================] - 2s 5ms/step - loss: 0.8821 - val_loss: 1.2894
Epoch 39/56
326/326 [==============================] - 1s 5ms/step - loss: 0.8818 - val_loss: 1.2889
Epoch 40/56
326/326 [==============================] - 1s 5ms/step - loss: 0.8815 - val_loss: 1.2884
Epoch 41/56
326/326 [==============================] - 1s 5ms/step - loss: 0.8813 - val_loss: 1.2878
Epoch 42/56
326/326 [==============================] - 1s 5ms/step - loss: 0.8809 - val_loss: 1.2873
Epoch 43/56
326/326 [==============================] - 2s 5ms/step - loss: 0.8807 - val_loss: 1.2867
Epoch 44/56
326/326 [==============================] - 2s 5ms/step - loss: 0.8804 - val_loss: 1.2862
Epoch 45/56
326/326 [==============================] - 1s 5ms/step - loss: 0.8801 - val_loss: 1.2856
Epoch 46/56
326/326 [==============================] - 1s 5ms/step - loss: 0.8798 - val_loss: 1.2850
Epoch 47/56
326/326 [==============================] - 1s 5ms/step - loss: 0.8795 - val_loss: 1.2844
Epoch 48/56
326/326 [==============================] - 1s 5ms/step - loss: 0.8792 - val_loss: 1.2839
Epoch 49/56
326/326 [==============================] - 1s 5ms/step - loss: 0.8789 - val_loss: 1.2833
Epoch 50/56
326/326 [==============================] - 1s 5ms/step - loss: 0.8786 - val_loss: 1.2827
Epoch 51/56
326/326 [==============================] - 1s 5ms/step - loss: 0.8783 - val_loss: 1.2821
Epoch 52/56
326/326 [==============================] - 1s 5ms/step - loss: 0.8779 - val_loss: 1.2815
Epoch 53/56
326/326 [==============================] - 1s 5ms/step - loss: 0.8777 - val_loss: 1.2809
Epoch 54/56
326/326 [==============================] - 2s 5ms/step - loss: 0.8773 - val_loss: 1.2803
Epoch 55/56
326/326 [==============================] - 2s 5ms/step - loss: 0.8770 - val_loss: 1.2796
Epoch 56/56
326/326 [==============================] - 1s 5ms/step - loss: 0.8766 - val_loss: 1.2790
Execution time:  90.68845510482788
LSTM:
Mean Absolute Error: 0.9154
Root Mean Square Error: 1.1038
Mean Square Error: 1.2183

Train RMSE: 1.104
Train MSE: 1.218
Train MAE: 0.915
###########################

MODEL:  LSTM
sequence:  1h
units:  45
dropout1:  0.11814836227952394
dropout2:  0.24325404382648977
optimizer: adadelta
activationDense: sigmoid
epochs: 43
batchsize: 30
validation_split: 0.2
Model: &#34;sequential_7&#34;
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
lstm_14 (LSTM)               (None, 6, 45)             8460      
_________________________________________________________________
dropout_14 (Dropout)         (None, 6, 45)             0         
_________________________________________________________________
lstm_15 (LSTM)               (None, 6, 45)             16380     
_________________________________________________________________
dropout_15 (Dropout)         (None, 6, 45)             0         
_________________________________________________________________
time_distributed_7 (TimeDist (None, 6, 1)              46        
=================================================================
Total params: 24,886
Trainable params: 24,886
Non-trainable params: 0
_________________________________________________________________
Epoch 1/43
107/107 [==============================] - 2s 16ms/step - loss: 0.8784 - val_loss: 1.1381
Epoch 2/43
107/107 [==============================] - 1s 8ms/step - loss: 0.8783 - val_loss: 1.1380
Epoch 3/43
107/107 [==============================] - 1s 8ms/step - loss: 0.8782 - val_loss: 1.1380
Epoch 4/43
107/107 [==============================] - 1s 7ms/step - loss: 0.8782 - val_loss: 1.1379
Epoch 5/43
107/107 [==============================] - 1s 8ms/step - loss: 0.8781 - val_loss: 1.1378
Epoch 6/43
107/107 [==============================] - 1s 8ms/step - loss: 0.8781 - val_loss: 1.1377
Epoch 7/43
107/107 [==============================] - 1s 8ms/step - loss: 0.8780 - val_loss: 1.1376
Epoch 8/43
107/107 [==============================] - 1s 8ms/step - loss: 0.8780 - val_loss: 1.1375
Epoch 9/43
107/107 [==============================] - 1s 8ms/step - loss: 0.8779 - val_loss: 1.1374
Epoch 10/43
107/107 [==============================] - 1s 8ms/step - loss: 0.8779 - val_loss: 1.1373
Epoch 11/43
107/107 [==============================] - 1s 7ms/step - loss: 0.8778 - val_loss: 1.1372
Epoch 12/43
107/107 [==============================] - 1s 8ms/step - loss: 0.8778 - val_loss: 1.1371
Epoch 13/43
107/107 [==============================] - 1s 8ms/step - loss: 0.8777 - val_loss: 1.1370
Epoch 14/43
107/107 [==============================] - 1s 7ms/step - loss: 0.8776 - val_loss: 1.1370
Epoch 15/43
107/107 [==============================] - 1s 8ms/step - loss: 0.8776 - val_loss: 1.1369
Epoch 16/43
107/107 [==============================] - 1s 8ms/step - loss: 0.8775 - val_loss: 1.1368
Epoch 17/43
107/107 [==============================] - 1s 7ms/step - loss: 0.8775 - val_loss: 1.1366
Epoch 18/43
107/107 [==============================] - 1s 8ms/step - loss: 0.8774 - val_loss: 1.1365
Epoch 19/43
107/107 [==============================] - 1s 7ms/step - loss: 0.8773 - val_loss: 1.1364
Epoch 20/43
107/107 [==============================] - 1s 8ms/step - loss: 0.8773 - val_loss: 1.1363
Epoch 21/43
107/107 [==============================] - 1s 8ms/step - loss: 0.8772 - val_loss: 1.1362
Epoch 22/43
107/107 [==============================] - 1s 7ms/step - loss: 0.8772 - val_loss: 1.1361
Epoch 23/43
107/107 [==============================] - 1s 7ms/step - loss: 0.8771 - val_loss: 1.1360
Epoch 24/43
107/107 [==============================] - 1s 8ms/step - loss: 0.8770 - val_loss: 1.1359
Epoch 25/43
107/107 [==============================] - 1s 8ms/step - loss: 0.8770 - val_loss: 1.1358
Epoch 26/43
107/107 [==============================] - 1s 8ms/step - loss: 0.8769 - val_loss: 1.1357
Epoch 27/43
107/107 [==============================] - 1s 8ms/step - loss: 0.8768 - val_loss: 1.1356
Epoch 28/43
107/107 [==============================] - 1s 8ms/step - loss: 0.8768 - val_loss: 1.1355
Epoch 29/43
107/107 [==============================] - 1s 7ms/step - loss: 0.8767 - val_loss: 1.1354
Epoch 30/43
107/107 [==============================] - 1s 8ms/step - loss: 0.8766 - val_loss: 1.1353
Epoch 31/43
107/107 [==============================] - 1s 8ms/step - loss: 0.8766 - val_loss: 1.1352
Epoch 32/43
107/107 [==============================] - 1s 8ms/step - loss: 0.8765 - val_loss: 1.1350
Epoch 33/43
107/107 [==============================] - 1s 7ms/step - loss: 0.8765 - val_loss: 1.1349
Epoch 34/43
107/107 [==============================] - 1s 7ms/step - loss: 0.8764 - val_loss: 1.1348
Epoch 35/43
107/107 [==============================] - 1s 8ms/step - loss: 0.8763 - val_loss: 1.1347
Epoch 36/43
107/107 [==============================] - 1s 8ms/step - loss: 0.8763 - val_loss: 1.1346
Epoch 37/43
107/107 [==============================] - 1s 7ms/step - loss: 0.8762 - val_loss: 1.1345
Epoch 38/43
107/107 [==============================] - 1s 8ms/step - loss: 0.8761 - val_loss: 1.1344
Epoch 39/43
107/107 [==============================] - 1s 7ms/step - loss: 0.8761 - val_loss: 1.1342
Epoch 40/43
107/107 [==============================] - 1s 8ms/step - loss: 0.8760 - val_loss: 1.1341
Epoch 41/43
107/107 [==============================] - 1s 7ms/step - loss: 0.8759 - val_loss: 1.1340
Epoch 42/43
107/107 [==============================] - 1s 7ms/step - loss: 0.8758 - val_loss: 1.1339
Epoch 43/43
107/107 [==============================] - 1s 8ms/step - loss: 0.8758 - val_loss: 1.1338
Execution time:  41.50987648963928
LSTM:
Mean Absolute Error: 0.9261
Root Mean Square Error: 1.1132
Mean Square Error: 1.2392

Train RMSE: 1.113
Train MSE: 1.239
Train MAE: 0.926
###########################

MODEL:  LSTM
sequence:  1h
units:  43
dropout1:  0.40519643149940265
dropout2:  0.3312343747027119
optimizer: adamax
activationDense: tanh
epochs: 56
batchsize: 11
validation_split: 0.1
Model: &#34;sequential_8&#34;
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
lstm_16 (LSTM)               (None, 6, 43)             7740      
_________________________________________________________________
dropout_16 (Dropout)         (None, 6, 43)             0         
_________________________________________________________________
lstm_17 (LSTM)               (None, 6, 43)             14964     
_________________________________________________________________
dropout_17 (Dropout)         (None, 6, 43)             0         
_________________________________________________________________
time_distributed_8 (TimeDist (None, 6, 1)              44        
=================================================================
Total params: 22,748
Trainable params: 22,748
Non-trainable params: 0
_________________________________________________________________
Epoch 1/56
316/326 [============================&gt;.] - ETA: 0s - loss: 0.5068WARNING:tensorflow:Callbacks method `on_test_batch_end` is slow compared to the batch time (batch time: 0.0000s vs `on_test_batch_end` time: 0.0156s). Check your callbacks.
326/326 [==============================] - 2s 7ms/step - loss: 0.4995 - val_loss: 0.3910
Epoch 2/56
326/326 [==============================] - 1s 5ms/step - loss: 0.3673 - val_loss: 0.3296
Epoch 3/56
326/326 [==============================] - 2s 5ms/step - loss: 0.3179 - val_loss: 0.2528
Epoch 4/56
326/326 [==============================] - 1s 5ms/step - loss: 0.2976 - val_loss: 0.2183
Epoch 5/56
326/326 [==============================] - 1s 5ms/step - loss: 0.2872 - val_loss: 0.2027
Epoch 6/56
326/326 [==============================] - 1s 5ms/step - loss: 0.2824 - val_loss: 0.1945
Epoch 7/56
326/326 [==============================] - 2s 5ms/step - loss: 0.2796 - val_loss: 0.1887
Epoch 8/56
326/326 [==============================] - 2s 5ms/step - loss: 0.2784 - val_loss: 0.1862
Epoch 9/56
326/326 [==============================] - 2s 5ms/step - loss: 0.2772 - val_loss: 0.1860
Epoch 10/56
326/326 [==============================] - 2s 5ms/step - loss: 0.2768 - val_loss: 0.1803
Epoch 11/56
326/326 [==============================] - 2s 5ms/step - loss: 0.2769 - val_loss: 0.1778
Epoch 12/56
326/326 [==============================] - 2s 5ms/step - loss: 0.2767 - val_loss: 0.1791
Epoch 13/56
326/326 [==============================] - 2s 5ms/step - loss: 0.2760 - val_loss: 0.1796
Epoch 14/56
326/326 [==============================] - 2s 5ms/step - loss: 0.2752 - val_loss: 0.1764
Epoch 15/56
326/326 [==============================] - 2s 5ms/step - loss: 0.2751 - val_loss: 0.1720
Epoch 16/56
326/326 [==============================] - 2s 5ms/step - loss: 0.2747 - val_loss: 0.1726
Epoch 17/56
326/326 [==============================] - 2s 5ms/step - loss: 0.2748 - val_loss: 0.1729
Epoch 18/56
326/326 [==============================] - 2s 5ms/step - loss: 0.2745 - val_loss: 0.1706
Epoch 19/56
326/326 [==============================] - 2s 5ms/step - loss: 0.2743 - val_loss: 0.1711
Epoch 20/56
326/326 [==============================] - 2s 5ms/step - loss: 0.2737 - val_loss: 0.1672
Epoch 21/56
326/326 [==============================] - 1s 5ms/step - loss: 0.2729 - val_loss: 0.1709
Epoch 22/56
326/326 [==============================] - 1s 5ms/step - loss: 0.2729 - val_loss: 0.1665
Epoch 23/56
326/326 [==============================] - 2s 5ms/step - loss: 0.2732 - val_loss: 0.1663
Epoch 24/56
326/326 [==============================] - 2s 5ms/step - loss: 0.2726 - val_loss: 0.1668
Epoch 25/56
326/326 [==============================] - 2s 5ms/step - loss: 0.2724 - val_loss: 0.1609
Epoch 26/56
326/326 [==============================] - 2s 5ms/step - loss: 0.2726 - val_loss: 0.1647
Epoch 27/56
326/326 [==============================] - 2s 5ms/step - loss: 0.2718 - val_loss: 0.1609
Epoch 28/56
326/326 [==============================] - 2s 5ms/step - loss: 0.2723 - val_loss: 0.1577
Epoch 29/56
326/326 [==============================] - 2s 5ms/step - loss: 0.2722 - val_loss: 0.1599
Epoch 30/56
326/326 [==============================] - 2s 5ms/step - loss: 0.2719 - val_loss: 0.1590
Epoch 31/56
326/326 [==============================] - 2s 5ms/step - loss: 0.2715 - val_loss: 0.1546
Epoch 32/56
326/326 [==============================] - 2s 5ms/step - loss: 0.2707 - val_loss: 0.1535
Epoch 33/56
326/326 [==============================] - 2s 5ms/step - loss: 0.2703 - val_loss: 0.1531
Epoch 34/56
326/326 [==============================] - 2s 5ms/step - loss: 0.2706 - val_loss: 0.1499
Epoch 35/56
326/326 [==============================] - 2s 5ms/step - loss: 0.2702 - val_loss: 0.1448
Epoch 36/56
326/326 [==============================] - 2s 5ms/step - loss: 0.2703 - val_loss: 0.1472
Epoch 37/56
326/326 [==============================] - 2s 5ms/step - loss: 0.2696 - val_loss: 0.1424
Epoch 38/56
326/326 [==============================] - 2s 5ms/step - loss: 0.2698 - val_loss: 0.1403
Epoch 39/56
326/326 [==============================] - 2s 5ms/step - loss: 0.2694 - val_loss: 0.1400
Epoch 40/56
326/326 [==============================] - 2s 5ms/step - loss: 0.2696 - val_loss: 0.1374
Epoch 41/56
326/326 [==============================] - 1s 5ms/step - loss: 0.2688 - val_loss: 0.1348
Epoch 42/56
326/326 [==============================] - 2s 5ms/step - loss: 0.2685 - val_loss: 0.1377
Epoch 43/56
326/326 [==============================] - 2s 5ms/step - loss: 0.2681 - val_loss: 0.1319
Epoch 44/56
326/326 [==============================] - 2s 5ms/step - loss: 0.2679 - val_loss: 0.1277
Epoch 45/56
326/326 [==============================] - 2s 5ms/step - loss: 0.2678 - val_loss: 0.1287
Epoch 46/56
326/326 [==============================] - 2s 5ms/step - loss: 0.2678 - val_loss: 0.1270
Epoch 47/56
326/326 [==============================] - 2s 5ms/step - loss: 0.2673 - val_loss: 0.1242
Epoch 48/56
326/326 [==============================] - 1s 5ms/step - loss: 0.2670 - val_loss: 0.1256
Epoch 49/56
326/326 [==============================] - 2s 5ms/step - loss: 0.2664 - val_loss: 0.1215
Epoch 50/56
326/326 [==============================] - 2s 5ms/step - loss: 0.2664 - val_loss: 0.1204
Epoch 51/56
326/326 [==============================] - 2s 5ms/step - loss: 0.2655 - val_loss: 0.1191
Epoch 52/56
326/326 [==============================] - 1s 5ms/step - loss: 0.2658 - val_loss: 0.1186
Epoch 53/56
326/326 [==============================] - 1s 5ms/step - loss: 0.2659 - val_loss: 0.1149
Epoch 54/56
326/326 [==============================] - 1s 5ms/step - loss: 0.2652 - val_loss: 0.1169
Epoch 55/56
326/326 [==============================] - 2s 5ms/step - loss: 0.2650 - val_loss: 0.1155
Epoch 56/56
326/326 [==============================] - 2s 5ms/step - loss: 0.2648 - val_loss: 0.1142
Execution time:  91.40200185775757
LSTM:
Mean Absolute Error: 0.1623
Root Mean Square Error: 0.5744
Mean Square Error: 0.3299

Train RMSE: 0.574
Train MSE: 0.330
Train MAE: 0.162
###########################

MODEL:  LSTM
sequence:  1h
units:  45
dropout1:  0.11814836227952394
dropout2:  0.24325404382648977
optimizer: adamax
activationDense: tanh
epochs: 43
batchsize: 30
validation_split: 0.2
Model: &#34;sequential_9&#34;
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
lstm_18 (LSTM)               (None, 6, 45)             8460      
_________________________________________________________________
dropout_18 (Dropout)         (None, 6, 45)             0         
_________________________________________________________________
lstm_19 (LSTM)               (None, 6, 45)             16380     
_________________________________________________________________
dropout_19 (Dropout)         (None, 6, 45)             0         
_________________________________________________________________
time_distributed_9 (TimeDist (None, 6, 1)              46        
=================================================================
Total params: 24,886
Trainable params: 24,886
Non-trainable params: 0
_________________________________________________________________
Epoch 1/43
107/107 [==============================] - 2s 16ms/step - loss: 0.6122 - val_loss: 0.4047
Epoch 2/43
107/107 [==============================] - 1s 7ms/step - loss: 0.4330 - val_loss: 0.3774
Epoch 3/43
107/107 [==============================] - 1s 7ms/step - loss: 0.3977 - val_loss: 0.3483
Epoch 4/43
107/107 [==============================] - 1s 7ms/step - loss: 0.3723 - val_loss: 0.3157
Epoch 5/43
107/107 [==============================] - 1s 7ms/step - loss: 0.3472 - val_loss: 0.2860
Epoch 6/43
107/107 [==============================] - 1s 7ms/step - loss: 0.3248 - val_loss: 0.2635
Epoch 7/43
107/107 [==============================] - 1s 7ms/step - loss: 0.3082 - val_loss: 0.2505
Epoch 8/43
107/107 [==============================] - 1s 7ms/step - loss: 0.2981 - val_loss: 0.2411
Epoch 9/43
107/107 [==============================] - 1s 7ms/step - loss: 0.2905 - val_loss: 0.2339
Epoch 10/43
107/107 [==============================] - 1s 7ms/step - loss: 0.2833 - val_loss: 0.2277
Epoch 11/43
107/107 [==============================] - 1s 7ms/step - loss: 0.2795 - val_loss: 0.2230
Epoch 12/43
107/107 [==============================] - 1s 7ms/step - loss: 0.2759 - val_loss: 0.2199
Epoch 13/43
107/107 [==============================] - 1s 7ms/step - loss: 0.2738 - val_loss: 0.2176
Epoch 14/43
107/107 [==============================] - 1s 7ms/step - loss: 0.2731 - val_loss: 0.2163
Epoch 15/43
107/107 [==============================] - 1s 7ms/step - loss: 0.2719 - val_loss: 0.2155
Epoch 16/43
107/107 [==============================] - 1s 7ms/step - loss: 0.2715 - val_loss: 0.2151
Epoch 17/43
107/107 [==============================] - 1s 8ms/step - loss: 0.2710 - val_loss: 0.2144
Epoch 18/43
107/107 [==============================] - 1s 8ms/step - loss: 0.2705 - val_loss: 0.2140
Epoch 19/43
107/107 [==============================] - 1s 8ms/step - loss: 0.2703 - val_loss: 0.2133
Epoch 20/43
107/107 [==============================] - 1s 7ms/step - loss: 0.2708 - val_loss: 0.2127
Epoch 21/43
107/107 [==============================] - 1s 7ms/step - loss: 0.2702 - val_loss: 0.2127
Epoch 22/43
107/107 [==============================] - 1s 7ms/step - loss: 0.2701 - val_loss: 0.2122
Epoch 23/43
107/107 [==============================] - 1s 7ms/step - loss: 0.2704 - val_loss: 0.2123
Epoch 24/43
107/107 [==============================] - 1s 7ms/step - loss: 0.2699 - val_loss: 0.2120
Epoch 25/43
107/107 [==============================] - 1s 7ms/step - loss: 0.2700 - val_loss: 0.2114
Epoch 26/43
107/107 [==============================] - 1s 7ms/step - loss: 0.2695 - val_loss: 0.2110
Epoch 27/43
107/107 [==============================] - 1s 7ms/step - loss: 0.2695 - val_loss: 0.2111
Epoch 28/43
107/107 [==============================] - 1s 7ms/step - loss: 0.2694 - val_loss: 0.2111
Epoch 29/43
107/107 [==============================] - 1s 8ms/step - loss: 0.2694 - val_loss: 0.2107
Epoch 30/43
107/107 [==============================] - 1s 8ms/step - loss: 0.2690 - val_loss: 0.2106
Epoch 31/43
107/107 [==============================] - 1s 8ms/step - loss: 0.2690 - val_loss: 0.2099
Epoch 32/43
107/107 [==============================] - 1s 8ms/step - loss: 0.2689 - val_loss: 0.2097
Epoch 33/43
107/107 [==============================] - 1s 7ms/step - loss: 0.2688 - val_loss: 0.2096
Epoch 34/43
107/107 [==============================] - 1s 7ms/step - loss: 0.2681 - val_loss: 0.2088
Epoch 35/43
107/107 [==============================] - 1s 7ms/step - loss: 0.2681 - val_loss: 0.2090
Epoch 36/43
107/107 [==============================] - 1s 7ms/step - loss: 0.2687 - val_loss: 0.2087
Epoch 37/43
107/107 [==============================] - 1s 8ms/step - loss: 0.2679 - val_loss: 0.2083
Epoch 38/43
107/107 [==============================] - 1s 8ms/step - loss: 0.2681 - val_loss: 0.2078
Epoch 39/43
107/107 [==============================] - 1s 7ms/step - loss: 0.2682 - val_loss: 0.2076
Epoch 40/43
107/107 [==============================] - 1s 7ms/step - loss: 0.2679 - val_loss: 0.2074
Epoch 41/43
107/107 [==============================] - 1s 7ms/step - loss: 0.2675 - val_loss: 0.2067
Epoch 42/43
107/107 [==============================] - 1s 7ms/step - loss: 0.2674 - val_loss: 0.2070
Epoch 43/43
107/107 [==============================] - 1s 7ms/step - loss: 0.2671 - val_loss: 0.2068
Execution time:  41.7000367641449
LSTM:
Mean Absolute Error: 0.1639
Root Mean Square Error: 0.5757
Mean Square Error: 0.3314

Train RMSE: 0.576
Train MSE: 0.331
Train MAE: 0.164
###########################

MODEL:  LSTM
sequence:  1h
units:  43
dropout1:  0.40519643149940265
dropout2:  0.3312343747027119
optimizer: adamax
activationDense: sigmoid
epochs: 56
batchsize: 11
validation_split: 0.1
Model: &#34;sequential_10&#34;
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
lstm_20 (LSTM)               (None, 6, 43)             7740      
_________________________________________________________________
dropout_20 (Dropout)         (None, 6, 43)             0         
_________________________________________________________________
lstm_21 (LSTM)               (None, 6, 43)             14964     
_________________________________________________________________
dropout_21 (Dropout)         (None, 6, 43)             0         
_________________________________________________________________
time_distributed_10 (TimeDis (None, 6, 1)              44        
=================================================================
Total params: 22,748
Trainable params: 22,748
Non-trainable params: 0
_________________________________________________________________
Epoch 1/56
326/326 [==============================] - 2s 7ms/step - loss: 0.7347 - val_loss: 0.8898
Epoch 2/56
326/326 [==============================] - 1s 4ms/step - loss: 0.5789 - val_loss: 0.8460
Epoch 3/56
326/326 [==============================] - 2s 5ms/step - loss: 0.5517 - val_loss: 0.8259
Epoch 4/56
326/326 [==============================] - 2s 5ms/step - loss: 0.5392 - val_loss: 0.8158
Epoch 5/56
326/326 [==============================] - 1s 5ms/step - loss: 0.5320 - val_loss: 0.8107
Epoch 6/56
326/326 [==============================] - 1s 5ms/step - loss: 0.5280 - val_loss: 0.8083
Epoch 7/56
326/326 [==============================] - 2s 5ms/step - loss: 0.5257 - val_loss: 0.8073
Epoch 8/56
326/326 [==============================] - 1s 5ms/step - loss: 0.5244 - val_loss: 0.8067
Epoch 9/56
326/326 [==============================] - 1s 5ms/step - loss: 0.5235 - val_loss: 0.8065
Epoch 10/56
326/326 [==============================] - 1s 4ms/step - loss: 0.5230 - val_loss: 0.8063
Epoch 11/56
326/326 [==============================] - 1s 5ms/step - loss: 0.5227 - val_loss: 0.8062
Epoch 12/56
326/326 [==============================] - 1s 5ms/step - loss: 0.5226 - val_loss: 0.8061
Epoch 13/56
326/326 [==============================] - 1s 5ms/step - loss: 0.5224 - val_loss: 0.8061
Epoch 14/56
326/326 [==============================] - 2s 5ms/step - loss: 0.5222 - val_loss: 0.8060
Epoch 15/56
326/326 [==============================] - 2s 5ms/step - loss: 0.5222 - val_loss: 0.8060
Epoch 16/56
326/326 [==============================] - 1s 5ms/step - loss: 0.5221 - val_loss: 0.8060
Epoch 17/56
326/326 [==============================] - 1s 5ms/step - loss: 0.5215 - val_loss: 0.8060
Epoch 18/56
326/326 [==============================] - 1s 5ms/step - loss: 0.5209 - val_loss: 0.8060
Epoch 19/56
326/326 [==============================] - 1s 4ms/step - loss: 0.5203 - val_loss: 0.8060
Epoch 20/56
326/326 [==============================] - 2s 5ms/step - loss: 0.5190 - val_loss: 0.8060
Epoch 21/56
326/326 [==============================] - 2s 5ms/step - loss: 0.5176 - val_loss: 0.8060
Epoch 22/56
326/326 [==============================] - 1s 4ms/step - loss: 0.5159 - val_loss: 0.8060
Epoch 23/56
326/326 [==============================] - 1s 5ms/step - loss: 0.5124 - val_loss: 0.8060
Epoch 24/56
326/326 [==============================] - 2s 5ms/step - loss: 0.5093 - val_loss: 0.8060
Epoch 25/56
326/326 [==============================] - 2s 5ms/step - loss: 0.5076 - val_loss: 0.8060
Epoch 26/56
326/326 [==============================] - 2s 5ms/step - loss: 0.5058 - val_loss: 0.8060
Epoch 27/56
326/326 [==============================] - 1s 5ms/step - loss: 0.5044 - val_loss: 0.8060
Epoch 28/56
326/326 [==============================] - 1s 5ms/step - loss: 0.5031 - val_loss: 0.8060
Epoch 29/56
326/326 [==============================] - 1s 5ms/step - loss: 0.5020 - val_loss: 0.8060
Epoch 30/56
326/326 [==============================] - 1s 5ms/step - loss: 0.5015 - val_loss: 0.8060
Epoch 31/56
326/326 [==============================] - 1s 5ms/step - loss: 0.5012 - val_loss: 0.8060
Epoch 32/56
326/326 [==============================] - 1s 5ms/step - loss: 0.5008 - val_loss: 0.8060
Epoch 33/56
326/326 [==============================] - 1s 5ms/step - loss: 0.5006 - val_loss: 0.8060
Epoch 34/56
326/326 [==============================] - 1s 5ms/step - loss: 0.5003 - val_loss: 0.8060
Epoch 35/56
326/326 [==============================] - 2s 5ms/step - loss: 0.5002 - val_loss: 0.8060
Epoch 36/56
326/326 [==============================] - 2s 5ms/step - loss: 0.5002 - val_loss: 0.8060
Epoch 37/56
326/326 [==============================] - 1s 5ms/step - loss: 0.5001 - val_loss: 0.8060
Epoch 38/56
326/326 [==============================] - 1s 5ms/step - loss: 0.5000 - val_loss: 0.8060
Epoch 39/56
326/326 [==============================] - 1s 5ms/step - loss: 0.4995 - val_loss: 0.8060
Epoch 40/56
326/326 [==============================] - 1s 5ms/step - loss: 0.4998 - val_loss: 0.8060
Epoch 41/56
326/326 [==============================] - 1s 5ms/step - loss: 0.4997 - val_loss: 0.8060
Epoch 42/56
326/326 [==============================] - 2s 5ms/step - loss: 0.5000 - val_loss: 0.8060
Epoch 43/56
326/326 [==============================] - 1s 5ms/step - loss: 0.4996 - val_loss: 0.8060
Epoch 44/56
326/326 [==============================] - 1s 5ms/step - loss: 0.4996 - val_loss: 0.8060
Epoch 45/56
326/326 [==============================] - 2s 5ms/step - loss: 0.4993 - val_loss: 0.8060
Epoch 46/56
326/326 [==============================] - 2s 5ms/step - loss: 0.4995 - val_loss: 0.8060
Epoch 47/56
326/326 [==============================] - 1s 5ms/step - loss: 0.4993 - val_loss: 0.8060
Epoch 48/56
326/326 [==============================] - 1s 5ms/step - loss: 0.4993 - val_loss: 0.8060
Epoch 49/56
326/326 [==============================] - 2s 5ms/step - loss: 0.4992 - val_loss: 0.8060
Epoch 50/56
326/326 [==============================] - 1s 5ms/step - loss: 0.4992 - val_loss: 0.8060
Epoch 51/56
326/326 [==============================] - 1s 5ms/step - loss: 0.4988 - val_loss: 0.8060
Epoch 52/56
326/326 [==============================] - 1s 5ms/step - loss: 0.4991 - val_loss: 0.8060
Epoch 53/56
326/326 [==============================] - 1s 5ms/step - loss: 0.4990 - val_loss: 0.8059
Epoch 54/56
326/326 [==============================] - 1s 5ms/step - loss: 0.4992 - val_loss: 0.8059
Epoch 55/56
326/326 [==============================] - 1s 5ms/step - loss: 0.4991 - val_loss: 0.8059
Epoch 56/56
326/326 [==============================] - 2s 5ms/step - loss: 0.4984 - val_loss: 0.8059
Execution time:  90.45861434936523
LSTM:
Mean Absolute Error: 0.4900
Root Mean Square Error: 0.7484
Mean Square Error: 0.5601

Train RMSE: 0.748
Train MSE: 0.560
Train MAE: 0.490
###########################

MODEL:  LSTM
sequence:  1h
units:  45
dropout1:  0.11814836227952394
dropout2:  0.24325404382648977
optimizer: adamax
activationDense: sigmoid
epochs: 43
batchsize: 30
validation_split: 0.2
Model: &#34;sequential_11&#34;
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
lstm_22 (LSTM)               (None, 6, 45)             8460      
_________________________________________________________________
dropout_22 (Dropout)         (None, 6, 45)             0         
_________________________________________________________________
lstm_23 (LSTM)               (None, 6, 45)             16380     
_________________________________________________________________
dropout_23 (Dropout)         (None, 6, 45)             0         
_________________________________________________________________
time_distributed_11 (TimeDis (None, 6, 1)              46        
=================================================================
Total params: 24,886
Trainable params: 24,886
Non-trainable params: 0
_________________________________________________________________
Epoch 1/43
107/107 [==============================] - 2s 20ms/step - loss: 0.8385 - val_loss: 0.9584
Epoch 2/43
107/107 [==============================] - 1s 8ms/step - loss: 0.6544 - val_loss: 0.7762
Epoch 3/43
107/107 [==============================] - 1s 7ms/step - loss: 0.5960 - val_loss: 0.7405
Epoch 4/43
107/107 [==============================] - 1s 7ms/step - loss: 0.5746 - val_loss: 0.7223
Epoch 5/43
107/107 [==============================] - 1s 7ms/step - loss: 0.5613 - val_loss: 0.7098
Epoch 6/43
107/107 [==============================] - 1s 7ms/step - loss: 0.5522 - val_loss: 0.7003
Epoch 7/43
107/107 [==============================] - 1s 7ms/step - loss: 0.5454 - val_loss: 0.6927
Epoch 8/43
107/107 [==============================] - 1s 7ms/step - loss: 0.5401 - val_loss: 0.6867
Epoch 9/43
107/107 [==============================] - 1s 8ms/step - loss: 0.5357 - val_loss: 0.6819
Epoch 10/43
107/107 [==============================] - 1s 8ms/step - loss: 0.5322 - val_loss: 0.6783
Epoch 11/43
107/107 [==============================] - 1s 8ms/step - loss: 0.5296 - val_loss: 0.6757
Epoch 12/43
107/107 [==============================] - 1s 7ms/step - loss: 0.5278 - val_loss: 0.6738
Epoch 13/43
107/107 [==============================] - 1s 7ms/step - loss: 0.5263 - val_loss: 0.6723
Epoch 14/43
107/107 [==============================] - 1s 7ms/step - loss: 0.5251 - val_loss: 0.6712
Epoch 15/43
107/107 [==============================] - 1s 7ms/step - loss: 0.5243 - val_loss: 0.6703
Epoch 16/43
107/107 [==============================] - 1s 7ms/step - loss: 0.5235 - val_loss: 0.6696
Epoch 17/43
107/107 [==============================] - 1s 8ms/step - loss: 0.5229 - val_loss: 0.6690
Epoch 18/43
107/107 [==============================] - 1s 8ms/step - loss: 0.5224 - val_loss: 0.6685
Epoch 19/43
107/107 [==============================] - 1s 8ms/step - loss: 0.5219 - val_loss: 0.6679
Epoch 20/43
107/107 [==============================] - 1s 8ms/step - loss: 0.5212 - val_loss: 0.6673
Epoch 21/43
107/107 [==============================] - 1s 7ms/step - loss: 0.5203 - val_loss: 0.6668
Epoch 22/43
107/107 [==============================] - 1s 8ms/step - loss: 0.5195 - val_loss: 0.6663
Epoch 23/43
107/107 [==============================] - 1s 7ms/step - loss: 0.5186 - val_loss: 0.6658
Epoch 24/43
107/107 [==============================] - 1s 7ms/step - loss: 0.5170 - val_loss: 0.6653
Epoch 25/43
107/107 [==============================] - 1s 7ms/step - loss: 0.5153 - val_loss: 0.6647
Epoch 26/43
107/107 [==============================] - 1s 7ms/step - loss: 0.5127 - val_loss: 0.6639
Epoch 27/43
107/107 [==============================] - 1s 8ms/step - loss: 0.5090 - val_loss: 0.6632
Epoch 28/43
107/107 [==============================] - 1s 8ms/step - loss: 0.5052 - val_loss: 0.6622
Epoch 29/43
107/107 [==============================] - 1s 8ms/step - loss: 0.5022 - val_loss: 0.6623
Epoch 30/43
107/107 [==============================] - 1s 8ms/step - loss: 0.5003 - val_loss: 0.6623
Epoch 31/43
107/107 [==============================] - 1s 7ms/step - loss: 0.4993 - val_loss: 0.6624
Epoch 32/43
107/107 [==============================] - 1s 7ms/step - loss: 0.4988 - val_loss: 0.6624
Epoch 33/43
107/107 [==============================] - 1s 7ms/step - loss: 0.4982 - val_loss: 0.6624
Epoch 34/43
107/107 [==============================] - 1s 8ms/step - loss: 0.4980 - val_loss: 0.6623
Epoch 35/43
107/107 [==============================] - 1s 8ms/step - loss: 0.4982 - val_loss: 0.6623
Epoch 36/43
107/107 [==============================] - 1s 8ms/step - loss: 0.4978 - val_loss: 0.6623
Epoch 37/43
107/107 [==============================] - 1s 8ms/step - loss: 0.4974 - val_loss: 0.6623
Epoch 38/43
107/107 [==============================] - 1s 8ms/step - loss: 0.4973 - val_loss: 0.6624
Epoch 39/43
107/107 [==============================] - 1s 8ms/step - loss: 0.4971 - val_loss: 0.6624
Epoch 40/43
107/107 [==============================] - 1s 7ms/step - loss: 0.4971 - val_loss: 0.6622
Epoch 41/43
107/107 [==============================] - 1s 7ms/step - loss: 0.4969 - val_loss: 0.6624
Epoch 42/43
107/107 [==============================] - 1s 8ms/step - loss: 0.4968 - val_loss: 0.6623
Epoch 43/43
107/107 [==============================] - 1s 8ms/step - loss: 0.4970 - val_loss: 0.6623
Execution time:  41.39910626411438
LSTM:
Mean Absolute Error: 0.4909
Root Mean Square Error: 0.7490
Mean Square Error: 0.5610

Train RMSE: 0.749
Train MSE: 0.561
Train MAE: 0.491
###########################

MODEL:  LSTM
sequence:  3h
units:  43
dropout1:  0.40519643149940265
dropout2:  0.3312343747027119
optimizer: adam
activationDense: tanh
epochs: 56
batchsize: 11
validation_split: 0.1
Model: &#34;sequential_12&#34;
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
lstm_24 (LSTM)               (None, 18, 43)            7740      
_________________________________________________________________
dropout_24 (Dropout)         (None, 18, 43)            0         
_________________________________________________________________
lstm_25 (LSTM)               (None, 18, 43)            14964     
_________________________________________________________________
dropout_25 (Dropout)         (None, 18, 43)            0         
_________________________________________________________________
time_distributed_12 (TimeDis (None, 18, 1)             44        
=================================================================
Total params: 22,748
Trainable params: 22,748
Non-trainable params: 0
_________________________________________________________________
Epoch 1/56
325/325 [==============================] - 5s 15ms/step - loss: 0.4619 - val_loss: 0.3679
Epoch 2/56
325/325 [==============================] - 3s 10ms/step - loss: 0.3831 - val_loss: 0.2967
Epoch 3/56
325/325 [==============================] - 3s 10ms/step - loss: 0.3597 - val_loss: 0.2615
Epoch 4/56
325/325 [==============================] - 3s 10ms/step - loss: 0.3509 - val_loss: 0.2423
Epoch 5/56
325/325 [==============================] - 3s 10ms/step - loss: 0.3467 - val_loss: 0.2354
Epoch 6/56
325/325 [==============================] - 3s 10ms/step - loss: 0.3458 - val_loss: 0.2344
Epoch 7/56
325/325 [==============================] - 3s 10ms/step - loss: 0.3443 - val_loss: 0.2287
Epoch 8/56
325/325 [==============================] - 3s 10ms/step - loss: 0.3437 - val_loss: 0.2251
Epoch 9/56
325/325 [==============================] - 3s 10ms/step - loss: 0.3432 - val_loss: 0.2285
Epoch 10/56
325/325 [==============================] - 3s 10ms/step - loss: 0.3424 - val_loss: 0.2216
Epoch 11/56
325/325 [==============================] - 3s 10ms/step - loss: 0.3419 - val_loss: 0.2218
Epoch 12/56
325/325 [==============================] - 3s 10ms/step - loss: 0.3411 - val_loss: 0.2209
Epoch 13/56
325/325 [==============================] - 3s 10ms/step - loss: 0.3408 - val_loss: 0.2170
Epoch 14/56
325/325 [==============================] - 3s 10ms/step - loss: 0.3406 - val_loss: 0.2138
Epoch 15/56
325/325 [==============================] - 3s 10ms/step - loss: 0.3401 - val_loss: 0.2157
Epoch 16/56
325/325 [==============================] - 3s 10ms/step - loss: 0.3394 - val_loss: 0.2134
Epoch 17/56
325/325 [==============================] - 3s 10ms/step - loss: 0.3394 - val_loss: 0.2092
Epoch 18/56
325/325 [==============================] - 3s 10ms/step - loss: 0.3392 - val_loss: 0.2093
Epoch 19/56
325/325 [==============================] - 3s 10ms/step - loss: 0.3382 - val_loss: 0.2080
Epoch 20/56
325/325 [==============================] - 3s 10ms/step - loss: 0.3381 - val_loss: 0.2060
Epoch 21/56
325/325 [==============================] - 3s 10ms/step - loss: 0.3376 - val_loss: 0.2033
Epoch 22/56
325/325 [==============================] - 3s 10ms/step - loss: 0.3371 - val_loss: 0.2020
Epoch 23/56
325/325 [==============================] - 3s 10ms/step - loss: 0.3369 - val_loss: 0.2004
Epoch 24/56
325/325 [==============================] - 3s 10ms/step - loss: 0.3367 - val_loss: 0.2012
Epoch 25/56
325/325 [==============================] - 3s 10ms/step - loss: 0.3362 - val_loss: 0.1980
Epoch 26/56
325/325 [==============================] - 3s 10ms/step - loss: 0.3362 - val_loss: 0.1982
Epoch 27/56
325/325 [==============================] - 3s 10ms/step - loss: 0.3361 - val_loss: 0.1957
Epoch 28/56
325/325 [==============================] - 3s 10ms/step - loss: 0.3359 - val_loss: 0.1937
Epoch 29/56
325/325 [==============================] - 3s 10ms/step - loss: 0.3356 - val_loss: 0.1908
Epoch 30/56
325/325 [==============================] - 3s 10ms/step - loss: 0.3351 - val_loss: 0.1898
Epoch 31/56
325/325 [==============================] - 3s 10ms/step - loss: 0.3348 - val_loss: 0.1871
Epoch 32/56
325/325 [==============================] - 3s 10ms/step - loss: 0.3341 - val_loss: 0.1870
Epoch 33/56
325/325 [==============================] - 3s 10ms/step - loss: 0.3340 - val_loss: 0.1821
Epoch 34/56
325/325 [==============================] - 3s 10ms/step - loss: 0.3340 - val_loss: 0.1828
Epoch 35/56
325/325 [==============================] - 3s 10ms/step - loss: 0.3342 - val_loss: 0.1804
Epoch 36/56
325/325 [==============================] - 3s 10ms/step - loss: 0.3338 - val_loss: 0.1775
Epoch 37/56
325/325 [==============================] - 3s 10ms/step - loss: 0.3332 - val_loss: 0.1771
Epoch 38/56
325/325 [==============================] - 3s 10ms/step - loss: 0.3335 - val_loss: 0.1725
Epoch 39/56
325/325 [==============================] - 3s 10ms/step - loss: 0.3331 - val_loss: 0.1706
Epoch 40/56
325/325 [==============================] - 3s 10ms/step - loss: 0.3325 - val_loss: 0.1653
Epoch 41/56
325/325 [==============================] - 3s 10ms/step - loss: 0.3323 - val_loss: 0.1657
Epoch 42/56
325/325 [==============================] - 3s 10ms/step - loss: 0.3326 - val_loss: 0.1653
Epoch 43/56
325/325 [==============================] - 3s 10ms/step - loss: 0.3318 - val_loss: 0.1607
Epoch 44/56
325/325 [==============================] - 3s 10ms/step - loss: 0.3319 - val_loss: 0.1581
Epoch 45/56
325/325 [==============================] - 3s 10ms/step - loss: 0.3315 - val_loss: 0.1585
Epoch 46/56
325/325 [==============================] - 3s 10ms/step - loss: 0.3312 - val_loss: 0.1568
Epoch 47/56
325/325 [==============================] - 3s 10ms/step - loss: 0.3311 - val_loss: 0.1558
Epoch 48/56
325/325 [==============================] - 3s 10ms/step - loss: 0.3319 - val_loss: 0.1539
Epoch 49/56
325/325 [==============================] - 3s 10ms/step - loss: 0.3304 - val_loss: 0.1510
Epoch 50/56
325/325 [==============================] - 3s 10ms/step - loss: 0.3308 - val_loss: 0.1498
Epoch 51/56
325/325 [==============================] - 3s 10ms/step - loss: 0.3305 - val_loss: 0.1462
Epoch 52/56
325/325 [==============================] - 3s 10ms/step - loss: 0.3300 - val_loss: 0.1466
Epoch 53/56
325/325 [==============================] - 3s 10ms/step - loss: 0.3297 - val_loss: 0.1458
Epoch 54/56
325/325 [==============================] - 3s 10ms/step - loss: 0.3299 - val_loss: 0.1450
Epoch 55/56
325/325 [==============================] - 3s 10ms/step - loss: 0.3302 - val_loss: 0.1407
Epoch 56/56
325/325 [==============================] - 3s 10ms/step - loss: 0.3296 - val_loss: 0.1400
Execution time:  188.61861181259155
LSTM:
Mean Absolute Error: 0.1867
Root Mean Square Error: 0.6067
Mean Square Error: 0.3681

Train RMSE: 0.607
Train MSE: 0.368
Train MAE: 0.187
###########################

MODEL:  LSTM
sequence:  3h
units:  45
dropout1:  0.11814836227952394
dropout2:  0.24325404382648977
optimizer: adam
activationDense: tanh
epochs: 43
batchsize: 30
validation_split: 0.2
Model: &#34;sequential_13&#34;
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
lstm_26 (LSTM)               (None, 18, 45)            8460      
_________________________________________________________________
dropout_26 (Dropout)         (None, 18, 45)            0         
_________________________________________________________________
lstm_27 (LSTM)               (None, 18, 45)            16380     
_________________________________________________________________
dropout_27 (Dropout)         (None, 18, 45)            0         
_________________________________________________________________
time_distributed_13 (TimeDis (None, 18, 1)             46        
=================================================================
Total params: 24,886
Trainable params: 24,886
Non-trainable params: 0
_________________________________________________________________
Epoch 1/43
106/106 [==============================] - 3s 25ms/step - loss: 0.5234 - val_loss: 0.3605
Epoch 2/43
106/106 [==============================] - 2s 16ms/step - loss: 0.4143 - val_loss: 0.3246
Epoch 3/43
106/106 [==============================] - 2s 16ms/step - loss: 0.3827 - val_loss: 0.3031
Epoch 4/43
106/106 [==============================] - 2s 16ms/step - loss: 0.3670 - val_loss: 0.2908
Epoch 5/43
106/106 [==============================] - 2s 16ms/step - loss: 0.3581 - val_loss: 0.2822
Epoch 6/43
106/106 [==============================] - 2s 16ms/step - loss: 0.3508 - val_loss: 0.2765
Epoch 7/43
106/106 [==============================] - 2s 16ms/step - loss: 0.3463 - val_loss: 0.2722
Epoch 8/43
106/106 [==============================] - 2s 16ms/step - loss: 0.3427 - val_loss: 0.2687
Epoch 9/43
106/106 [==============================] - 2s 16ms/step - loss: 0.3392 - val_loss: 0.2663
Epoch 10/43
106/106 [==============================] - 2s 16ms/step - loss: 0.3372 - val_loss: 0.2651
Epoch 11/43
106/106 [==============================] - 2s 16ms/step - loss: 0.3357 - val_loss: 0.2646
Epoch 12/43
106/106 [==============================] - 2s 16ms/step - loss: 0.3350 - val_loss: 0.2636
Epoch 13/43
106/106 [==============================] - 2s 16ms/step - loss: 0.3343 - val_loss: 0.2622
Epoch 14/43
106/106 [==============================] - 2s 16ms/step - loss: 0.3335 - val_loss: 0.2622
Epoch 15/43
106/106 [==============================] - 2s 16ms/step - loss: 0.3334 - val_loss: 0.2617
Epoch 16/43
106/106 [==============================] - 2s 16ms/step - loss: 0.3331 - val_loss: 0.2615
Epoch 17/43
106/106 [==============================] - 2s 16ms/step - loss: 0.3333 - val_loss: 0.2610
Epoch 18/43
106/106 [==============================] - 2s 16ms/step - loss: 0.3329 - val_loss: 0.2613
Epoch 19/43
106/106 [==============================] - 2s 16ms/step - loss: 0.3324 - val_loss: 0.2613
Epoch 20/43
106/106 [==============================] - 2s 16ms/step - loss: 0.3322 - val_loss: 0.2603
Epoch 21/43
106/106 [==============================] - 2s 16ms/step - loss: 0.3322 - val_loss: 0.2606
Epoch 22/43
106/106 [==============================] - 2s 16ms/step - loss: 0.3323 - val_loss: 0.2605
Epoch 23/43
106/106 [==============================] - 2s 16ms/step - loss: 0.3320 - val_loss: 0.2599
Epoch 24/43
106/106 [==============================] - 2s 16ms/step - loss: 0.3320 - val_loss: 0.2603
Epoch 25/43
106/106 [==============================] - 2s 16ms/step - loss: 0.3314 - val_loss: 0.2605A: 0s - loss: 0
Epoch 26/43
106/106 [==============================] - 2s 16ms/step - loss: 0.3318 - val_loss: 0.2598
Epoch 27/43
106/106 [==============================] - 2s 15ms/step - loss: 0.3314 - val_loss: 0.2599
Epoch 28/43
106/106 [==============================] - 2s 18ms/step - loss: 0.3315 - val_loss: 0.2599
Epoch 29/43
106/106 [==============================] - 2s 16ms/step - loss: 0.3311 - val_loss: 0.2592
Epoch 30/43
106/106 [==============================] - 2s 16ms/step - loss: 0.3314 - val_loss: 0.2585
Epoch 31/43
106/106 [==============================] - 2s 16ms/step - loss: 0.3310 - val_loss: 0.2588
Epoch 32/43
106/106 [==============================] - 2s 16ms/step - loss: 0.3307 - val_loss: 0.2586
Epoch 33/43
106/106 [==============================] - 2s 16ms/step - loss: 0.3306 - val_loss: 0.2578
Epoch 34/43
106/106 [==============================] - 2s 16ms/step - loss: 0.3302 - val_loss: 0.2579
Epoch 35/43
106/106 [==============================] - 2s 16ms/step - loss: 0.3303 - val_loss: 0.2581
Epoch 36/43
106/106 [==============================] - 2s 16ms/step - loss: 0.3303 - val_loss: 0.2574: 
Epoch 37/43
106/106 [==============================] - 2s 17ms/step - loss: 0.3300 - val_loss: 0.2572
Epoch 38/43
106/106 [==============================] - 2s 16ms/step - loss: 0.3295 - val_loss: 0.2567
Epoch 39/43
106/106 [==============================] - 2s 16ms/step - loss: 0.3296 - val_loss: 0.2571
Epoch 40/43
106/106 [==============================] - 2s 16ms/step - loss: 0.3292 - val_loss: 0.2571
Epoch 41/43
106/106 [==============================] - 2s 16ms/step - loss: 0.3289 - val_loss: 0.2565
Epoch 42/43
106/106 [==============================] - 2s 16ms/step - loss: 0.3288 - val_loss: 0.2554
Epoch 43/43
106/106 [==============================] - 2s 16ms/step - loss: 0.3288 - val_loss: 0.2557: 0s - los
Execution time:  79.69973134994507
LSTM:
Mean Absolute Error: 0.1808
Root Mean Square Error: 0.5989
Mean Square Error: 0.3587

Train RMSE: 0.599
Train MSE: 0.359
Train MAE: 0.181
###########################

MODEL:  LSTM
sequence:  3h
units:  43
dropout1:  0.40519643149940265
dropout2:  0.3312343747027119
optimizer: adam
activationDense: sigmoid
epochs: 56
batchsize: 11
validation_split: 0.1
Model: &#34;sequential_14&#34;
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
lstm_28 (LSTM)               (None, 18, 43)            7740      
_________________________________________________________________
dropout_28 (Dropout)         (None, 18, 43)            0         
_________________________________________________________________
lstm_29 (LSTM)               (None, 18, 43)            14964     
_________________________________________________________________
dropout_29 (Dropout)         (None, 18, 43)            0         
_________________________________________________________________
time_distributed_14 (TimeDis (None, 18, 1)             44        
=================================================================
Total params: 22,748
Trainable params: 22,748
Non-trainable params: 0
_________________________________________________________________
Epoch 1/56
325/325 [==============================] - 4s 13ms/step - loss: 0.6606 - val_loss: 0.8320
Epoch 2/56
325/325 [==============================] - 3s 10ms/step - loss: 0.5871 - val_loss: 0.8173
Epoch 3/56
325/325 [==============================] - 3s 10ms/step - loss: 0.5587 - val_loss: 0.8104
Epoch 4/56
325/325 [==============================] - 3s 10ms/step - loss: 0.5498 - val_loss: 0.8077
Epoch 5/56
325/325 [==============================] - 3s 10ms/step - loss: 0.5449 - val_loss: 0.8066
Epoch 6/56
325/325 [==============================] - 3s 10ms/step - loss: 0.5425 - val_loss: 0.8061
Epoch 7/56
325/325 [==============================] - 3s 10ms/step - loss: 0.5412 - val_loss: 0.8059
Epoch 8/56
325/325 [==============================] - 3s 10ms/step - loss: 0.5404 - val_loss: 0.8058
Epoch 9/56
325/325 [==============================] - 3s 10ms/step - loss: 0.5401 - val_loss: 0.8057
Epoch 10/56
325/325 [==============================] - 3s 10ms/step - loss: 0.5399 - val_loss: 0.8057
Epoch 11/56
325/325 [==============================] - 3s 10ms/step - loss: 0.5396 - val_loss: 0.8057
Epoch 12/56
325/325 [==============================] - 3s 10ms/step - loss: 0.5392 - val_loss: 0.8057
Epoch 13/56
325/325 [==============================] - 3s 10ms/step - loss: 0.5393 - val_loss: 0.8056
Epoch 14/56
325/325 [==============================] - 3s 10ms/step - loss: 0.5390 - val_loss: 0.8056
Epoch 15/56
325/325 [==============================] - 3s 10ms/step - loss: 0.5389 - val_loss: 0.8056
Epoch 16/56
325/325 [==============================] - 3s 10ms/step - loss: 0.5386 - val_loss: 0.8056
Epoch 17/56
325/325 [==============================] - 3s 10ms/step - loss: 0.5386 - val_loss: 0.8056
Epoch 18/56
325/325 [==============================] - 3s 10ms/step - loss: 0.5382 - val_loss: 0.8056
Epoch 19/56
325/325 [==============================] - 3s 10ms/step - loss: 0.5380 - val_loss: 0.8056
Epoch 20/56
325/325 [==============================] - 3s 10ms/step - loss: 0.5379 - val_loss: 0.8056
Epoch 21/56
325/325 [==============================] - 3s 10ms/step - loss: 0.5381 - val_loss: 0.8056
Epoch 22/56
325/325 [==============================] - 3s 10ms/step - loss: 0.5375 - val_loss: 0.8056
Epoch 23/56
325/325 [==============================] - 3s 10ms/step - loss: 0.5373 - val_loss: 0.8056
Epoch 24/56
325/325 [==============================] - 3s 10ms/step - loss: 0.5372 - val_loss: 0.8056
Epoch 25/56
325/325 [==============================] - 3s 10ms/step - loss: 0.5373 - val_loss: 0.8056
Epoch 26/56
325/325 [==============================] - 3s 10ms/step - loss: 0.5365 - val_loss: 0.8056
Epoch 27/56
325/325 [==============================] - 3s 10ms/step - loss: 0.5365 - val_loss: 0.8056
Epoch 28/56
325/325 [==============================] - 3s 10ms/step - loss: 0.5363 - val_loss: 0.8056
Epoch 29/56
325/325 [==============================] - 3s 10ms/step - loss: 0.5358 - val_loss: 0.8056
Epoch 30/56
325/325 [==============================] - 3s 10ms/step - loss: 0.5353 - val_loss: 0.8056
Epoch 31/56
325/325 [==============================] - 3s 10ms/step - loss: 0.5355 - val_loss: 0.8056
Epoch 32/56
325/325 [==============================] - 3s 10ms/step - loss: 0.5357 - val_loss: 0.8056
Epoch 33/56
325/325 [==============================] - 3s 10ms/step - loss: 0.5353 - val_loss: 0.8056
Epoch 34/56
325/325 [==============================] - 3s 10ms/step - loss: 0.5354 - val_loss: 0.8056
Epoch 35/56
325/325 [==============================] - 3s 10ms/step - loss: 0.5352 - val_loss: 0.8056
Epoch 36/56
325/325 [==============================] - 3s 10ms/step - loss: 0.5350 - val_loss: 0.8056
Epoch 37/56
325/325 [==============================] - 3s 10ms/step - loss: 0.5349 - val_loss: 0.8056
Epoch 38/56
325/325 [==============================] - 3s 10ms/step - loss: 0.5352 - val_loss: 0.8056
Epoch 39/56
325/325 [==============================] - 3s 10ms/step - loss: 0.5347 - val_loss: 0.8056
Epoch 40/56
325/325 [==============================] - 3s 10ms/step - loss: 0.5348 - val_loss: 0.8056
Epoch 41/56
325/325 [==============================] - 3s 10ms/step - loss: 0.5344 - val_loss: 0.8056
Epoch 42/56
325/325 [==============================] - 3s 10ms/step - loss: 0.5343 - val_loss: 0.8056
Epoch 43/56
325/325 [==============================] - 3s 10ms/step - loss: 0.5342 - val_loss: 0.8056
Epoch 44/56
325/325 [==============================] - 3s 10ms/step - loss: 0.5343 - val_loss: 0.8056
Epoch 45/56
325/325 [==============================] - 3s 10ms/step - loss: 0.5340 - val_loss: 0.8056
Epoch 46/56
325/325 [==============================] - 3s 10ms/step - loss: 0.5337 - val_loss: 0.8056
Epoch 47/56
325/325 [==============================] - 3s 10ms/step - loss: 0.5336 - val_loss: 0.8056
Epoch 48/56
325/325 [==============================] - 3s 10ms/step - loss: 0.5337 - val_loss: 0.8056
Epoch 49/56
325/325 [==============================] - 3s 10ms/step - loss: 0.5332 - val_loss: 0.8056
Epoch 50/56
325/325 [==============================] - 3s 10ms/step - loss: 0.5335 - val_loss: 0.8056
Epoch 51/56
325/325 [==============================] - 3s 10ms/step - loss: 0.5335 - val_loss: 0.8056
Epoch 52/56
325/325 [==============================] - 3s 10ms/step - loss: 0.5330 - val_loss: 0.8056
Epoch 53/56
325/325 [==============================] - 3s 10ms/step - loss: 0.5332 - val_loss: 0.8056
Epoch 54/56
325/325 [==============================] - 3s 10ms/step - loss: 0.5327 - val_loss: 0.8056
Epoch 55/56
325/325 [==============================] - 3s 10ms/step - loss: 0.5327 - val_loss: 0.8056
Epoch 56/56
325/325 [==============================] - 3s 10ms/step - loss: 0.5324 - val_loss: 0.8056
Execution time:  185.33522510528564
LSTM:
Mean Absolute Error: 0.5096
Root Mean Square Error: 0.7691
Mean Square Error: 0.5915

Train RMSE: 0.769
Train MSE: 0.592
Train MAE: 0.510
###########################

MODEL:  LSTM
sequence:  3h
units:  45
dropout1:  0.11814836227952394
dropout2:  0.24325404382648977
optimizer: adam
activationDense: sigmoid
epochs: 43
batchsize: 30
validation_split: 0.2
Model: &#34;sequential_15&#34;
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
lstm_30 (LSTM)               (None, 18, 45)            8460      
_________________________________________________________________
dropout_30 (Dropout)         (None, 18, 45)            0         
_________________________________________________________________
lstm_31 (LSTM)               (None, 18, 45)            16380     
_________________________________________________________________
dropout_31 (Dropout)         (None, 18, 45)            0         
_________________________________________________________________
time_distributed_15 (TimeDis (None, 18, 1)             46        
=================================================================
Total params: 24,886
Trainable params: 24,886
Non-trainable params: 0
_________________________________________________________________
Epoch 1/43
106/106 [==============================] - 3s 31ms/step - loss: 0.7444 - val_loss: 0.7594
Epoch 2/43
106/106 [==============================] - 2s 16ms/step - loss: 0.6187 - val_loss: 0.7285
Epoch 3/43
106/106 [==============================] - 2s 16ms/step - loss: 0.5943 - val_loss: 0.7137
Epoch 4/43
106/106 [==============================] - 2s 16ms/step - loss: 0.5771 - val_loss: 0.7042
Epoch 5/43
106/106 [==============================] - 2s 16ms/step - loss: 0.5655 - val_loss: 0.6979
Epoch 6/43
106/106 [==============================] - 2s 16ms/step - loss: 0.5564 - val_loss: 0.6941
Epoch 7/43
106/106 [==============================] - 2s 16ms/step - loss: 0.5518 - val_loss: 0.6909
Epoch 8/43
106/106 [==============================] - 2s 16ms/step - loss: 0.5483 - val_loss: 0.6882
Epoch 9/43
106/106 [==============================] - 2s 17ms/step - loss: 0.5453 - val_loss: 0.6861
Epoch 10/43
106/106 [==============================] - 2s 16ms/step - loss: 0.5430 - val_loss: 0.6846
Epoch 11/43
106/106 [==============================] - 2s 17ms/step - loss: 0.5412 - val_loss: 0.6833
Epoch 12/43
106/106 [==============================] - 2s 16ms/step - loss: 0.5397 - val_loss: 0.6826
Epoch 13/43
106/106 [==============================] - 2s 16ms/step - loss: 0.5391 - val_loss: 0.6815
Epoch 14/43
106/106 [==============================] - 2s 16ms/step - loss: 0.5383 - val_loss: 0.6808
Epoch 15/43
106/106 [==============================] - 2s 16ms/step - loss: 0.5378 - val_loss: 0.6805
Epoch 16/43
106/106 [==============================] - 2s 16ms/step - loss: 0.5374 - val_loss: 0.6799s: 0
Epoch 17/43
106/106 [==============================] - 2s 16ms/step - loss: 0.5372 - val_loss: 0.6797
Epoch 18/43
106/106 [==============================] - 2s 16ms/step - loss: 0.5369 - val_loss: 0.6793
Epoch 19/43
106/106 [==============================] - 2s 16ms/step - loss: 0.5367 - val_loss: 0.6794
Epoch 20/43
106/106 [==============================] - 2s 16ms/step - loss: 0.5363 - val_loss: 0.6793
Epoch 21/43
106/106 [==============================] - 2s 16ms/step - loss: 0.5359 - val_loss: 0.6792
Epoch 22/43
106/106 [==============================] - 2s 16ms/step - loss: 0.5358 - val_loss: 0.6792
Epoch 23/43
106/106 [==============================] - 2s 16ms/step - loss: 0.5357 - val_loss: 0.6789
Epoch 24/43
106/106 [==============================] - 2s 16ms/step - loss: 0.5355 - val_loss: 0.6791
Epoch 25/43
106/106 [==============================] - 2s 16ms/step - loss: 0.5354 - val_loss: 0.6789
Epoch 26/43
106/106 [==============================] - 2s 16ms/step - loss: 0.5352 - val_loss: 0.6788
Epoch 27/43
106/106 [==============================] - 2s 16ms/step - loss: 0.5348 - val_loss: 0.6793
Epoch 28/43
106/106 [==============================] - 2s 16ms/step - loss: 0.5349 - val_loss: 0.6789
Epoch 29/43
106/106 [==============================] - 2s 17ms/step - loss: 0.5347 - val_loss: 0.6788
Epoch 30/43
106/106 [==============================] - 2s 16ms/step - loss: 0.5345 - val_loss: 0.6789
Epoch 31/43
106/106 [==============================] - 2s 16ms/step - loss: 0.5345 - val_loss: 0.6788
Epoch 32/43
106/106 [==============================] - 2s 16ms/step - loss: 0.5338 - val_loss: 0.6788
Epoch 33/43
106/106 [==============================] - 2s 16ms/step - loss: 0.5341 - val_loss: 0.6787
Epoch 34/43
106/106 [==============================] - 2s 16ms/step - loss: 0.5336 - val_loss: 0.6788
Epoch 35/43
106/106 [==============================] - 2s 16ms/step - loss: 0.5336 - val_loss: 0.6790
Epoch 36/43
106/106 [==============================] - 2s 16ms/step - loss: 0.5333 - val_loss: 0.6784
Epoch 37/43
106/106 [==============================] - 2s 16ms/step - loss: 0.5333 - val_loss: 0.6785
Epoch 38/43
106/106 [==============================] - 2s 17ms/step - loss: 0.5330 - val_loss: 0.6787
Epoch 39/43
106/106 [==============================] - 2s 16ms/step - loss: 0.5329 - val_loss: 0.6784
Epoch 40/43
106/106 [==============================] - 2s 16ms/step - loss: 0.5331 - val_loss: 0.6784
Epoch 41/43
106/106 [==============================] - 2s 16ms/step - loss: 0.5327 - val_loss: 0.6791
Epoch 42/43
106/106 [==============================] - 2s 16ms/step - loss: 0.5325 - val_loss: 0.6789
Epoch 43/43
106/106 [==============================] - 2s 16ms/step - loss: 0.5326 - val_loss: 0.6782
Execution time:  80.90086579322815
LSTM:
Mean Absolute Error: 0.5068
Root Mean Square Error: 0.7639
Mean Square Error: 0.5836

Train RMSE: 0.764
Train MSE: 0.584
Train MAE: 0.507
###########################

MODEL:  LSTM
sequence:  3h
units:  43
dropout1:  0.40519643149940265
dropout2:  0.3312343747027119
optimizer: adadelta
activationDense: tanh
epochs: 56
batchsize: 11
validation_split: 0.1
Model: &#34;sequential_16&#34;
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
lstm_32 (LSTM)               (None, 18, 43)            7740      
_________________________________________________________________
dropout_32 (Dropout)         (None, 18, 43)            0         
_________________________________________________________________
lstm_33 (LSTM)               (None, 18, 43)            14964     
_________________________________________________________________
dropout_33 (Dropout)         (None, 18, 43)            0         
_________________________________________________________________
time_distributed_16 (TimeDis (None, 18, 1)             44        
=================================================================
Total params: 22,748
Trainable params: 22,748
Non-trainable params: 0
_________________________________________________________________
Epoch 1/56
325/325 [==============================] - 4s 13ms/step - loss: 0.7128 - val_loss: 0.8092
Epoch 2/56
325/325 [==============================] - 3s 10ms/step - loss: 0.7110 - val_loss: 0.8062
Epoch 3/56
325/325 [==============================] - 3s 10ms/step - loss: 0.7094 - val_loss: 0.8031
Epoch 4/56
325/325 [==============================] - 3s 10ms/step - loss: 0.7077 - val_loss: 0.7999
Epoch 5/56
325/325 [==============================] - 3s 11ms/step - loss: 0.7060 - val_loss: 0.7967
Epoch 6/56
325/325 [==============================] - 3s 10ms/step - loss: 0.7042 - val_loss: 0.7934
Epoch 7/56
325/325 [==============================] - 3s 10ms/step - loss: 0.7024 - val_loss: 0.7900
Epoch 8/56
325/325 [==============================] - 3s 10ms/step - loss: 0.7006 - val_loss: 0.7865
Epoch 9/56
325/325 [==============================] - 3s 10ms/step - loss: 0.6988 - val_loss: 0.7830
Epoch 10/56
325/325 [==============================] - 3s 10ms/step - loss: 0.6968 - val_loss: 0.7794
Epoch 11/56
325/325 [==============================] - 3s 10ms/step - loss: 0.6950 - val_loss: 0.7756
Epoch 12/56
325/325 [==============================] - 3s 10ms/step - loss: 0.6930 - val_loss: 0.7718
Epoch 13/56
325/325 [==============================] - 3s 10ms/step - loss: 0.6911 - val_loss: 0.7679
Epoch 14/56
325/325 [==============================] - 3s 10ms/step - loss: 0.6891 - val_loss: 0.7639
Epoch 15/56
325/325 [==============================] - 3s 10ms/step - loss: 0.6869 - val_loss: 0.7598
Epoch 16/56
325/325 [==============================] - 3s 10ms/step - loss: 0.6848 - val_loss: 0.7556
Epoch 17/56
325/325 [==============================] - 3s 10ms/step - loss: 0.6827 - val_loss: 0.7513
Epoch 18/56
325/325 [==============================] - 3s 10ms/step - loss: 0.6805 - val_loss: 0.7469
Epoch 19/56
325/325 [==============================] - 3s 10ms/step - loss: 0.6784 - val_loss: 0.7424
Epoch 20/56
325/325 [==============================] - 3s 10ms/step - loss: 0.6760 - val_loss: 0.7378
Epoch 21/56
325/325 [==============================] - 3s 10ms/step - loss: 0.6738 - val_loss: 0.7331
Epoch 22/56
325/325 [==============================] - 3s 10ms/step - loss: 0.6714 - val_loss: 0.7284
Epoch 23/56
325/325 [==============================] - 3s 10ms/step - loss: 0.6690 - val_loss: 0.7235
Epoch 24/56
325/325 [==============================] - 3s 10ms/step - loss: 0.6666 - val_loss: 0.7185
Epoch 25/56
325/325 [==============================] - 3s 10ms/step - loss: 0.6641 - val_loss: 0.7134
Epoch 26/56
325/325 [==============================] - 3s 10ms/step - loss: 0.6615 - val_loss: 0.7081
Epoch 27/56
325/325 [==============================] - 3s 10ms/step - loss: 0.6587 - val_loss: 0.7027
Epoch 28/56
325/325 [==============================] - 3s 10ms/step - loss: 0.6563 - val_loss: 0.6972
Epoch 29/56
325/325 [==============================] - 3s 10ms/step - loss: 0.6534 - val_loss: 0.6915
Epoch 30/56
325/325 [==============================] - 3s 10ms/step - loss: 0.6507 - val_loss: 0.6857
Epoch 31/56
325/325 [==============================] - 3s 10ms/step - loss: 0.6480 - val_loss: 0.6797
Epoch 32/56
325/325 [==============================] - 3s 10ms/step - loss: 0.6448 - val_loss: 0.6735
Epoch 33/56
325/325 [==============================] - 3s 10ms/step - loss: 0.6417 - val_loss: 0.6672
Epoch 34/56
325/325 [==============================] - 3s 10ms/step - loss: 0.6387 - val_loss: 0.6607
Epoch 35/56
325/325 [==============================] - 3s 10ms/step - loss: 0.6354 - val_loss: 0.6540
Epoch 36/56
325/325 [==============================] - 3s 10ms/step - loss: 0.6323 - val_loss: 0.6472
Epoch 37/56
325/325 [==============================] - 3s 10ms/step - loss: 0.6288 - val_loss: 0.6402
Epoch 38/56
325/325 [==============================] - 3s 10ms/step - loss: 0.6254 - val_loss: 0.6331
Epoch 39/56
325/325 [==============================] - 3s 10ms/step - loss: 0.6215 - val_loss: 0.6257
Epoch 40/56
325/325 [==============================] - 3s 10ms/step - loss: 0.6183 - val_loss: 0.6183
Epoch 41/56
325/325 [==============================] - 3s 10ms/step - loss: 0.6144 - val_loss: 0.6107
Epoch 42/56
325/325 [==============================] - 3s 10ms/step - loss: 0.6105 - val_loss: 0.6030
Epoch 43/56
325/325 [==============================] - 3s 10ms/step - loss: 0.6069 - val_loss: 0.5952
Epoch 44/56
325/325 [==============================] - 3s 10ms/step - loss: 0.6032 - val_loss: 0.5874
Epoch 45/56
325/325 [==============================] - 3s 10ms/step - loss: 0.5997 - val_loss: 0.5796
Epoch 46/56
325/325 [==============================] - 3s 10ms/step - loss: 0.5958 - val_loss: 0.5717
Epoch 47/56
325/325 [==============================] - 3s 10ms/step - loss: 0.5918 - val_loss: 0.5639
Epoch 48/56
325/325 [==============================] - 3s 10ms/step - loss: 0.5882 - val_loss: 0.5562
Epoch 49/56
325/325 [==============================] - 3s 10ms/step - loss: 0.5843 - val_loss: 0.5486
Epoch 50/56
325/325 [==============================] - 3s 10ms/step - loss: 0.5808 - val_loss: 0.5410
Epoch 51/56
325/325 [==============================] - 3s 10ms/step - loss: 0.5773 - val_loss: 0.5335
Epoch 52/56
325/325 [==============================] - 3s 10ms/step - loss: 0.5739 - val_loss: 0.5261
Epoch 53/56
325/325 [==============================] - 3s 10ms/step - loss: 0.5703 - val_loss: 0.5189
Epoch 54/56
325/325 [==============================] - 3s 10ms/step - loss: 0.5670 - val_loss: 0.5117
Epoch 55/56
325/325 [==============================] - 3s 10ms/step - loss: 0.5637 - val_loss: 0.5046
Epoch 56/56
325/325 [==============================] - 3s 10ms/step - loss: 0.5607 - val_loss: 0.4977
Execution time:  187.65354013442993
LSTM:
Mean Absolute Error: 0.5354
Root Mean Square Error: 0.8736
Mean Square Error: 0.7632

Train RMSE: 0.874
Train MSE: 0.763
Train MAE: 0.535
###########################

MODEL:  LSTM
sequence:  3h
units:  45
dropout1:  0.11814836227952394
dropout2:  0.24325404382648977
optimizer: adadelta
activationDense: tanh
epochs: 43
batchsize: 30
validation_split: 0.2
Model: &#34;sequential_17&#34;
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
lstm_34 (LSTM)               (None, 18, 45)            8460      
_________________________________________________________________
dropout_34 (Dropout)         (None, 18, 45)            0         
_________________________________________________________________
lstm_35 (LSTM)               (None, 18, 45)            16380     
_________________________________________________________________
dropout_35 (Dropout)         (None, 18, 45)            0         
_________________________________________________________________
time_distributed_17 (TimeDis (None, 18, 1)             46        
=================================================================
Total params: 24,886
Trainable params: 24,886
Non-trainable params: 0
_________________________________________________________________
Epoch 1/43
106/106 [==============================] - 3s 27ms/step - loss: 0.7050 - val_loss: 0.6922
Epoch 2/43
106/106 [==============================] - 2s 16ms/step - loss: 0.7040 - val_loss: 0.6911
Epoch 3/43
106/106 [==============================] - 2s 16ms/step - loss: 0.7032 - val_loss: 0.6899
Epoch 4/43
106/106 [==============================] - 2s 16ms/step - loss: 0.7023 - val_loss: 0.6888
Epoch 5/43
106/106 [==============================] - 2s 16ms/step - loss: 0.7013 - val_loss: 0.6875
Epoch 6/43
106/106 [==============================] - 2s 16ms/step - loss: 0.7004 - val_loss: 0.6863
Epoch 7/43
106/106 [==============================] - 2s 16ms/step - loss: 0.6994 - val_loss: 0.6851
Epoch 8/43
106/106 [==============================] - 2s 16ms/step - loss: 0.6985 - val_loss: 0.6838
Epoch 9/43
106/106 [==============================] - 2s 18ms/step - loss: 0.6975 - val_loss: 0.6826
Epoch 10/43
106/106 [==============================] - 2s 18ms/step - loss: 0.6964 - val_loss: 0.6813
Epoch 11/43
106/106 [==============================] - 2s 17ms/step - loss: 0.6954 - val_loss: 0.6800
Epoch 12/43
106/106 [==============================] - 2s 16ms/step - loss: 0.6944 - val_loss: 0.6787
Epoch 13/43
106/106 [==============================] - 2s 16ms/step - loss: 0.6934 - val_loss: 0.6774
Epoch 14/43
106/106 [==============================] - 2s 16ms/step - loss: 0.6924 - val_loss: 0.6761
Epoch 15/43
106/106 [==============================] - 2s 16ms/step - loss: 0.6914 - val_loss: 0.6747
Epoch 16/43
106/106 [==============================] - 2s 16ms/step - loss: 0.6904 - val_loss: 0.6734
Epoch 17/43
106/106 [==============================] - 2s 16ms/step - loss: 0.6895 - val_loss: 0.6720
Epoch 18/43
106/106 [==============================] - 2s 16ms/step - loss: 0.6883 - val_loss: 0.6707
Epoch 19/43
106/106 [==============================] - 2s 17ms/step - loss: 0.6873 - val_loss: 0.6693
Epoch 20/43
106/106 [==============================] - 2s 17ms/step - loss: 0.6862 - val_loss: 0.6679
Epoch 21/43
106/106 [==============================] - 2s 16ms/step - loss: 0.6851 - val_loss: 0.6665
Epoch 22/43
106/106 [==============================] - 2s 16ms/step - loss: 0.6840 - val_loss: 0.6651
Epoch 23/43
106/106 [==============================] - 2s 16ms/step - loss: 0.6831 - val_loss: 0.6637
Epoch 24/43
106/106 [==============================] - 2s 16ms/step - loss: 0.6819 - val_loss: 0.6623
Epoch 25/43
106/106 [==============================] - 2s 16ms/step - loss: 0.6809 - val_loss: 0.6609
Epoch 26/43
106/106 [==============================] - 2s 16ms/step - loss: 0.6797 - val_loss: 0.6594
Epoch 27/43
106/106 [==============================] - 2s 16ms/step - loss: 0.6786 - val_loss: 0.6580
Epoch 28/43
106/106 [==============================] - 2s 16ms/step - loss: 0.6776 - val_loss: 0.6565
Epoch 29/43
106/106 [==============================] - 2s 17ms/step - loss: 0.6764 - val_loss: 0.6550
Epoch 30/43
106/106 [==============================] - 2s 16ms/step - loss: 0.6753 - val_loss: 0.6535
Epoch 31/43
106/106 [==============================] - 2s 16ms/step - loss: 0.6741 - val_loss: 0.6520
Epoch 32/43
106/106 [==============================] - 2s 16ms/step - loss: 0.6730 - val_loss: 0.6505
Epoch 33/43
106/106 [==============================] - 2s 16ms/step - loss: 0.6719 - val_loss: 0.6490
Epoch 34/43
106/106 [==============================] - 2s 16ms/step - loss: 0.6707 - val_loss: 0.6475
Epoch 35/43
106/106 [==============================] - 2s 16ms/step - loss: 0.6694 - val_loss: 0.6460
Epoch 36/43
106/106 [==============================] - 2s 16ms/step - loss: 0.6684 - val_loss: 0.6445
Epoch 37/43
106/106 [==============================] - 2s 16ms/step - loss: 0.6672 - val_loss: 0.6429
Epoch 38/43
106/106 [==============================] - 2s 17ms/step - loss: 0.6662 - val_loss: 0.6414
Epoch 39/43
106/106 [==============================] - 2s 16ms/step - loss: 0.6648 - val_loss: 0.6398
Epoch 40/43
106/106 [==============================] - 2s 16ms/step - loss: 0.6637 - val_loss: 0.6382
Epoch 41/43
106/106 [==============================] - 2s 16ms/step - loss: 0.6624 - val_loss: 0.6366
Epoch 42/43
106/106 [==============================] - 2s 16ms/step - loss: 0.6613 - val_loss: 0.6350
Epoch 43/43
106/106 [==============================] - 2s 16ms/step - loss: 0.6599 - val_loss: 0.6334
Execution time:  81.96568703651428
LSTM:
Mean Absolute Error: 0.6471
Root Mean Square Error: 0.9355
Mean Square Error: 0.8752

Train RMSE: 0.936
Train MSE: 0.875
Train MAE: 0.647
###########################

MODEL:  LSTM
sequence:  3h
units:  43
dropout1:  0.40519643149940265
dropout2:  0.3312343747027119
optimizer: adadelta
activationDense: sigmoid
epochs: 56
batchsize: 11
validation_split: 0.1
Model: &#34;sequential_18&#34;
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
lstm_36 (LSTM)               (None, 18, 43)            7740      
_________________________________________________________________
dropout_36 (Dropout)         (None, 18, 43)            0         
_________________________________________________________________
lstm_37 (LSTM)               (None, 18, 43)            14964     
_________________________________________________________________
dropout_37 (Dropout)         (None, 18, 43)            0         
_________________________________________________________________
time_distributed_18 (TimeDis (None, 18, 1)             44        
=================================================================
Total params: 22,748
Trainable params: 22,748
Non-trainable params: 0
_________________________________________________________________
Epoch 1/56
325/325 [==============================] - 4s 12ms/step - loss: 0.8954 - val_loss: 1.3100
Epoch 2/56
325/325 [==============================] - 3s 9ms/step - loss: 0.8950 - val_loss: 1.3091
Epoch 3/56
325/325 [==============================] - 3s 9ms/step - loss: 0.8945 - val_loss: 1.3083
Epoch 4/56
325/325 [==============================] - 3s 10ms/step - loss: 0.8940 - val_loss: 1.3074
Epoch 5/56
325/325 [==============================] - 3s 10ms/step - loss: 0.8935 - val_loss: 1.3065
Epoch 6/56
325/325 [==============================] - 3s 10ms/step - loss: 0.8930 - val_loss: 1.3055
Epoch 7/56
325/325 [==============================] - 3s 9ms/step - loss: 0.8926 - val_loss: 1.3046
Epoch 8/56
325/325 [==============================] - 3s 10ms/step - loss: 0.8920 - val_loss: 1.3036
Epoch 9/56
325/325 [==============================] - 3s 9ms/step - loss: 0.8915 - val_loss: 1.3027
Epoch 10/56
325/325 [==============================] - 3s 10ms/step - loss: 0.8909 - val_loss: 1.3017
Epoch 11/56
325/325 [==============================] - 3s 10ms/step - loss: 0.8904 - val_loss: 1.3007
Epoch 12/56
325/325 [==============================] - 3s 9ms/step - loss: 0.8898 - val_loss: 1.2996
Epoch 13/56
325/325 [==============================] - 3s 9ms/step - loss: 0.8892 - val_loss: 1.2986
Epoch 14/56
325/325 [==============================] - 3s 9ms/step - loss: 0.8887 - val_loss: 1.2975
Epoch 15/56
325/325 [==============================] - 3s 10ms/step - loss: 0.8881 - val_loss: 1.2965
Epoch 16/56
325/325 [==============================] - 3s 10ms/step - loss: 0.8875 - val_loss: 1.2954
Epoch 17/56
325/325 [==============================] - 3s 9ms/step - loss: 0.8870 - val_loss: 1.2943
Epoch 18/56
325/325 [==============================] - 3s 9ms/step - loss: 0.8864 - val_loss: 1.2932
Epoch 19/56
325/325 [==============================] - 3s 9ms/step - loss: 0.8858 - val_loss: 1.2921
Epoch 20/56
325/325 [==============================] - 3s 9ms/step - loss: 0.8851 - val_loss: 1.2909
Epoch 21/56
325/325 [==============================] - 3s 10ms/step - loss: 0.8845 - val_loss: 1.2898
Epoch 22/56
325/325 [==============================] - 3s 9ms/step - loss: 0.8839 - val_loss: 1.2886
Epoch 23/56
325/325 [==============================] - 3s 9ms/step - loss: 0.8833 - val_loss: 1.2874
Epoch 24/56
325/325 [==============================] - 3s 9ms/step - loss: 0.8826 - val_loss: 1.2862
Epoch 25/56
325/325 [==============================] - 3s 9ms/step - loss: 0.8819 - val_loss: 1.2850
Epoch 26/56
325/325 [==============================] - 3s 10ms/step - loss: 0.8812 - val_loss: 1.2837
Epoch 27/56
325/325 [==============================] - 3s 9ms/step - loss: 0.8806 - val_loss: 1.2824
Epoch 28/56
325/325 [==============================] - 3s 9ms/step - loss: 0.8799 - val_loss: 1.2811
Epoch 29/56
325/325 [==============================] - 3s 9ms/step - loss: 0.8792 - val_loss: 1.2798
Epoch 30/56
325/325 [==============================] - 3s 9ms/step - loss: 0.8784 - val_loss: 1.2785
Epoch 31/56
325/325 [==============================] - 3s 10ms/step - loss: 0.8777 - val_loss: 1.2771
Epoch 32/56
325/325 [==============================] - 3s 9ms/step - loss: 0.8769 - val_loss: 1.2757
Epoch 33/56
325/325 [==============================] - 3s 9ms/step - loss: 0.8761 - val_loss: 1.2743
Epoch 34/56
325/325 [==============================] - 3s 9ms/step - loss: 0.8754 - val_loss: 1.2729
Epoch 35/56
325/325 [==============================] - 3s 9ms/step - loss: 0.8745 - val_loss: 1.2714
Epoch 36/56
325/325 [==============================] - 3s 10ms/step - loss: 0.8737 - val_loss: 1.2699
Epoch 37/56
325/325 [==============================] - 3s 9ms/step - loss: 0.8729 - val_loss: 1.2683
Epoch 38/56
325/325 [==============================] - 3s 10ms/step - loss: 0.8721 - val_loss: 1.2668
Epoch 39/56
325/325 [==============================] - 3s 9ms/step - loss: 0.8712 - val_loss: 1.2652
Epoch 40/56
325/325 [==============================] - 3s 9ms/step - loss: 0.8703 - val_loss: 1.2636
Epoch 41/56
325/325 [==============================] - 3s 10ms/step - loss: 0.8694 - val_loss: 1.2619
Epoch 42/56
325/325 [==============================] - 3s 10ms/step - loss: 0.8684 - val_loss: 1.2602
Epoch 43/56
325/325 [==============================] - 3s 9ms/step - loss: 0.8675 - val_loss: 1.2585
Epoch 44/56
325/325 [==============================] - 3s 9ms/step - loss: 0.8666 - val_loss: 1.2567
Epoch 45/56
325/325 [==============================] - 3s 9ms/step - loss: 0.8656 - val_loss: 1.2549
Epoch 46/56
325/325 [==============================] - 3s 10ms/step - loss: 0.8645 - val_loss: 1.2530
Epoch 47/56
325/325 [==============================] - 3s 10ms/step - loss: 0.8634 - val_loss: 1.2512
Epoch 48/56
325/325 [==============================] - 3s 9ms/step - loss: 0.8623 - val_loss: 1.2493
Epoch 49/56
325/325 [==============================] - 3s 9ms/step - loss: 0.8613 - val_loss: 1.2473
Epoch 50/56
325/325 [==============================] - 3s 9ms/step - loss: 0.8602 - val_loss: 1.2453
Epoch 51/56
325/325 [==============================] - 3s 9ms/step - loss: 0.8590 - val_loss: 1.2433
Epoch 52/56
325/325 [==============================] - 3s 10ms/step - loss: 0.8579 - val_loss: 1.2413
Epoch 53/56
325/325 [==============================] - 3s 9ms/step - loss: 0.8567 - val_loss: 1.2392
Epoch 54/56
325/325 [==============================] - 3s 9ms/step - loss: 0.8555 - val_loss: 1.2370
Epoch 55/56
325/325 [==============================] - 3s 9ms/step - loss: 0.8543 - val_loss: 1.2349
Epoch 56/56
325/325 [==============================] - 3s 9ms/step - loss: 0.8530 - val_loss: 1.2327
Execution time:  179.52207684516907
LSTM:
Mean Absolute Error: 0.8846
Root Mean Square Error: 1.0744
Mean Square Error: 1.1544

Train RMSE: 1.074
Train MSE: 1.154
Train MAE: 0.885
###########################

MODEL:  LSTM
sequence:  3h
units:  45
dropout1:  0.11814836227952394
dropout2:  0.24325404382648977
optimizer: adadelta
activationDense: sigmoid
epochs: 43
batchsize: 30
validation_split: 0.2
Model: &#34;sequential_19&#34;
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
lstm_38 (LSTM)               (None, 18, 45)            8460      
_________________________________________________________________
dropout_38 (Dropout)         (None, 18, 45)            0         
_________________________________________________________________
lstm_39 (LSTM)               (None, 18, 45)            16380     
_________________________________________________________________
dropout_39 (Dropout)         (None, 18, 45)            0         
_________________________________________________________________
time_distributed_19 (TimeDis (None, 18, 1)             46        
=================================================================
Total params: 24,886
Trainable params: 24,886
Non-trainable params: 0
_________________________________________________________________
Epoch 1/43
106/106 [==============================] - 3s 25ms/step - loss: 0.8843 - val_loss: 1.1420
Epoch 2/43
106/106 [==============================] - 2s 16ms/step - loss: 0.8842 - val_loss: 1.1419
Epoch 3/43
106/106 [==============================] - 2s 16ms/step - loss: 0.8842 - val_loss: 1.1418
Epoch 4/43
106/106 [==============================] - 2s 16ms/step - loss: 0.8841 - val_loss: 1.1416
Epoch 5/43
106/106 [==============================] - 2s 16ms/step - loss: 0.8840 - val_loss: 1.1415
Epoch 6/43
106/106 [==============================] - 2s 16ms/step - loss: 0.8839 - val_loss: 1.1414
Epoch 7/43
106/106 [==============================] - 2s 16ms/step - loss: 0.8838 - val_loss: 1.1412
Epoch 8/43
106/106 [==============================] - 2s 16ms/step - loss: 0.8838 - val_loss: 1.1411
Epoch 9/43
106/106 [==============================] - 2s 16ms/step - loss: 0.8836 - val_loss: 1.1409
Epoch 10/43
106/106 [==============================] - 2s 16ms/step - loss: 0.8836 - val_loss: 1.1408
Epoch 11/43
106/106 [==============================] - 2s 16ms/step - loss: 0.8835 - val_loss: 1.1406
Epoch 12/43
106/106 [==============================] - 2s 16ms/step - loss: 0.8834 - val_loss: 1.1405
Epoch 13/43
106/106 [==============================] - 2s 16ms/step - loss: 0.8833 - val_loss: 1.1403
Epoch 14/43
106/106 [==============================] - 2s 16ms/step - loss: 0.8832 - val_loss: 1.1402
Epoch 15/43
106/106 [==============================] - 2s 16ms/step - loss: 0.8831 - val_loss: 1.1400
Epoch 16/43
106/106 [==============================] - 2s 16ms/step - loss: 0.8830 - val_loss: 1.1399
Epoch 17/43
106/106 [==============================] - 2s 16ms/step - loss: 0.8829 - val_loss: 1.1397
Epoch 18/43
106/106 [==============================] - 2s 16ms/step - loss: 0.8828 - val_loss: 1.1396
Epoch 19/43
106/106 [==============================] - 2s 16ms/step - loss: 0.8827 - val_loss: 1.1394
Epoch 20/43
106/106 [==============================] - 2s 16ms/step - loss: 0.8826 - val_loss: 1.1392
Epoch 21/43
106/106 [==============================] - 2s 16ms/step - loss: 0.8825 - val_loss: 1.1391
Epoch 22/43
106/106 [==============================] - 2s 16ms/step - loss: 0.8824 - val_loss: 1.1389
Epoch 23/43
106/106 [==============================] - 2s 16ms/step - loss: 0.8823 - val_loss: 1.1387
Epoch 24/43
106/106 [==============================] - 2s 16ms/step - loss: 0.8822 - val_loss: 1.1386
Epoch 25/43
106/106 [==============================] - 2s 16ms/step - loss: 0.8821 - val_loss: 1.1384
Epoch 26/43
106/106 [==============================] - 2s 16ms/step - loss: 0.8820 - val_loss: 1.1382
Epoch 27/43
106/106 [==============================] - 2s 16ms/step - loss: 0.8819 - val_loss: 1.1381
Epoch 28/43
106/106 [==============================] - 2s 16ms/step - loss: 0.8818 - val_loss: 1.1379
Epoch 29/43
106/106 [==============================] - 2s 16ms/step - loss: 0.8817 - val_loss: 1.1377
Epoch 30/43
106/106 [==============================] - 2s 16ms/step - loss: 0.8816 - val_loss: 1.1376
Epoch 31/43
106/106 [==============================] - 2s 16ms/step - loss: 0.8815 - val_loss: 1.1374
Epoch 32/43
106/106 [==============================] - 2s 16ms/step - loss: 0.8813 - val_loss: 1.1372
Epoch 33/43
106/106 [==============================] - 2s 16ms/step - loss: 0.8812 - val_loss: 1.1370
Epoch 34/43
106/106 [==============================] - 2s 16ms/step - loss: 0.8811 - val_loss: 1.1369
Epoch 35/43
106/106 [==============================] - 2s 16ms/step - loss: 0.8810 - val_loss: 1.1367
Epoch 36/43
106/106 [==============================] - 2s 16ms/step - loss: 0.8809 - val_loss: 1.1365
Epoch 37/43
106/106 [==============================] - 2s 16ms/step - loss: 0.8808 - val_loss: 1.1363
Epoch 38/43
106/106 [==============================] - 2s 16ms/step - loss: 0.8807 - val_loss: 1.1361
Epoch 39/43
106/106 [==============================] - 2s 16ms/step - loss: 0.8806 - val_loss: 1.1360
Epoch 40/43
106/106 [==============================] - 2s 16ms/step - loss: 0.8805 - val_loss: 1.1358
Epoch 41/43
106/106 [==============================] - 2s 16ms/step - loss: 0.8804 - val_loss: 1.1356 0s - loss: 
Epoch 42/43
106/106 [==============================] - 2s 16ms/step - loss: 0.8803 - val_loss: 1.1354
Epoch 43/43
106/106 [==============================] - 2s 16ms/step - loss: 0.8801 - val_loss: 1.1352
Execution time:  79.24483799934387
LSTM:
Mean Absolute Error: 0.9282
Root Mean Square Error: 1.1156
Mean Square Error: 1.2445

Train RMSE: 1.116
Train MSE: 1.245
Train MAE: 0.928
###########################

MODEL:  LSTM
sequence:  3h
units:  43
dropout1:  0.40519643149940265
dropout2:  0.3312343747027119
optimizer: adamax
activationDense: tanh
epochs: 56
batchsize: 11
validation_split: 0.1
Model: &#34;sequential_20&#34;
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
lstm_40 (LSTM)               (None, 18, 43)            7740      
_________________________________________________________________
dropout_40 (Dropout)         (None, 18, 43)            0         
_________________________________________________________________
lstm_41 (LSTM)               (None, 18, 43)            14964     
_________________________________________________________________
dropout_41 (Dropout)         (None, 18, 43)            0         
_________________________________________________________________
time_distributed_20 (TimeDis (None, 18, 1)             44        
=================================================================
Total params: 22,748
Trainable params: 22,748
Non-trainable params: 0
_________________________________________________________________
Epoch 1/56
325/325 [==============================] - 4s 12ms/step - loss: 0.4931 - val_loss: 0.3888
Epoch 2/56
325/325 [==============================] - 3s 10ms/step - loss: 0.4058 - val_loss: 0.3173
Epoch 3/56
325/325 [==============================] - 3s 10ms/step - loss: 0.3832 - val_loss: 0.2797
Epoch 4/56
325/325 [==============================] - 3s 10ms/step - loss: 0.3696 - val_loss: 0.2562
Epoch 5/56
325/325 [==============================] - 3s 10ms/step - loss: 0.3612 - val_loss: 0.2408
Epoch 6/56
325/325 [==============================] - 3s 10ms/step - loss: 0.3557 - val_loss: 0.2331
Epoch 7/56
325/325 [==============================] - 3s 10ms/step - loss: 0.3517 - val_loss: 0.2244
Epoch 8/56
325/325 [==============================] - 3s 10ms/step - loss: 0.3490 - val_loss: 0.2164
Epoch 9/56
325/325 [==============================] - 3s 10ms/step - loss: 0.3467 - val_loss: 0.2140
Epoch 10/56
325/325 [==============================] - 3s 10ms/step - loss: 0.3451 - val_loss: 0.2104
Epoch 11/56
325/325 [==============================] - 3s 10ms/step - loss: 0.3429 - val_loss: 0.2072
Epoch 12/56
325/325 [==============================] - 3s 10ms/step - loss: 0.3421 - val_loss: 0.2073
Epoch 13/56
325/325 [==============================] - 3s 10ms/step - loss: 0.3411 - val_loss: 0.2036
Epoch 14/56
325/325 [==============================] - 3s 10ms/step - loss: 0.3406 - val_loss: 0.2012
Epoch 15/56
325/325 [==============================] - 3s 10ms/step - loss: 0.3402 - val_loss: 0.1988
Epoch 16/56
325/325 [==============================] - 3s 10ms/step - loss: 0.3389 - val_loss: 0.1991
Epoch 17/56
325/325 [==============================] - 3s 10ms/step - loss: 0.3391 - val_loss: 0.1963
Epoch 18/56
325/325 [==============================] - 3s 10ms/step - loss: 0.3385 - val_loss: 0.1959
Epoch 19/56
325/325 [==============================] - 3s 10ms/step - loss: 0.3380 - val_loss: 0.1971
Epoch 20/56
325/325 [==============================] - 3s 10ms/step - loss: 0.3380 - val_loss: 0.1944
Epoch 21/56
325/325 [==============================] - 3s 10ms/step - loss: 0.3376 - val_loss: 0.1951
Epoch 22/56
325/325 [==============================] - 3s 10ms/step - loss: 0.3371 - val_loss: 0.1935
Epoch 23/56
325/325 [==============================] - 3s 10ms/step - loss: 0.3367 - val_loss: 0.1925
Epoch 24/56
325/325 [==============================] - 3s 10ms/step - loss: 0.3371 - val_loss: 0.1910
Epoch 25/56
325/325 [==============================] - 3s 10ms/step - loss: 0.3365 - val_loss: 0.1907
Epoch 26/56
325/325 [==============================] - 3s 10ms/step - loss: 0.3366 - val_loss: 0.1914
Epoch 27/56
325/325 [==============================] - 3s 10ms/step - loss: 0.3364 - val_loss: 0.1913
Epoch 28/56
325/325 [==============================] - 3s 10ms/step - loss: 0.3359 - val_loss: 0.1888
Epoch 29/56
325/325 [==============================] - 3s 10ms/step - loss: 0.3362 - val_loss: 0.1892
Epoch 30/56
325/325 [==============================] - 3s 10ms/step - loss: 0.3359 - val_loss: 0.1874
Epoch 31/56
325/325 [==============================] - 3s 10ms/step - loss: 0.3362 - val_loss: 0.1855
Epoch 32/56
325/325 [==============================] - 3s 10ms/step - loss: 0.3353 - val_loss: 0.1875
Epoch 33/56
325/325 [==============================] - 3s 10ms/step - loss: 0.3353 - val_loss: 0.1848
Epoch 34/56
325/325 [==============================] - 3s 10ms/step - loss: 0.3355 - val_loss: 0.1874
Epoch 35/56
325/325 [==============================] - 3s 10ms/step - loss: 0.3356 - val_loss: 0.1852
Epoch 36/56
325/325 [==============================] - 3s 10ms/step - loss: 0.3351 - val_loss: 0.1862
Epoch 37/56
325/325 [==============================] - 3s 10ms/step - loss: 0.3354 - val_loss: 0.1861
Epoch 38/56
325/325 [==============================] - 3s 10ms/step - loss: 0.3354 - val_loss: 0.1841
Epoch 39/56
325/325 [==============================] - 3s 10ms/step - loss: 0.3349 - val_loss: 0.1845
Epoch 40/56
325/325 [==============================] - 3s 10ms/step - loss: 0.3346 - val_loss: 0.1809
Epoch 41/56
325/325 [==============================] - 3s 10ms/step - loss: 0.3346 - val_loss: 0.1817
Epoch 42/56
325/325 [==============================] - 3s 10ms/step - loss: 0.3347 - val_loss: 0.1819
Epoch 43/56
325/325 [==============================] - 3s 10ms/step - loss: 0.3343 - val_loss: 0.1813
Epoch 44/56
325/325 [==============================] - 3s 10ms/step - loss: 0.3344 - val_loss: 0.1806
Epoch 45/56
325/325 [==============================] - 3s 10ms/step - loss: 0.3340 - val_loss: 0.1795
Epoch 46/56
325/325 [==============================] - 3s 10ms/step - loss: 0.3342 - val_loss: 0.1808
Epoch 47/56
325/325 [==============================] - 3s 10ms/step - loss: 0.3342 - val_loss: 0.1791
Epoch 48/56
325/325 [==============================] - 3s 10ms/step - loss: 0.3340 - val_loss: 0.1787
Epoch 49/56
325/325 [==============================] - 3s 10ms/step - loss: 0.3335 - val_loss: 0.1777
Epoch 50/56
325/325 [==============================] - 3s 10ms/step - loss: 0.3338 - val_loss: 0.1769
Epoch 51/56
325/325 [==============================] - 3s 10ms/step - loss: 0.3340 - val_loss: 0.1752
Epoch 52/56
325/325 [==============================] - 3s 10ms/step - loss: 0.3332 - val_loss: 0.1752
Epoch 53/56
325/325 [==============================] - 3s 10ms/step - loss: 0.3333 - val_loss: 0.1749
Epoch 54/56
325/325 [==============================] - 3s 10ms/step - loss: 0.3329 - val_loss: 0.1753
Epoch 55/56
325/325 [==============================] - 3s 10ms/step - loss: 0.3328 - val_loss: 0.1733
Epoch 56/56
325/325 [==============================] - 3s 10ms/step - loss: 0.3330 - val_loss: 0.1740
Execution time:  183.25079369544983
LSTM:
Mean Absolute Error: 0.1804
Root Mean Square Error: 0.5810
Mean Square Error: 0.3376

Train RMSE: 0.581
Train MSE: 0.338
Train MAE: 0.180
###########################

MODEL:  LSTM
sequence:  3h
units:  45
dropout1:  0.11814836227952394
dropout2:  0.24325404382648977
optimizer: adamax
activationDense: tanh
epochs: 43
batchsize: 30
validation_split: 0.2
Model: &#34;sequential_21&#34;
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
lstm_42 (LSTM)               (None, 18, 45)            8460      
_________________________________________________________________
dropout_42 (Dropout)         (None, 18, 45)            0         
_________________________________________________________________
lstm_43 (LSTM)               (None, 18, 45)            16380     
_________________________________________________________________
dropout_43 (Dropout)         (None, 18, 45)            0         
_________________________________________________________________
time_distributed_21 (TimeDis (None, 18, 1)             46        
=================================================================
Total params: 24,886
Trainable params: 24,886
Non-trainable params: 0
_________________________________________________________________
Epoch 1/43
106/106 [==============================] - 3s 25ms/step - loss: 0.5410 - val_loss: 0.3844
Epoch 2/43
106/106 [==============================] - 2s 16ms/step - loss: 0.4389 - val_loss: 0.3493
Epoch 3/43
106/106 [==============================] - 2s 16ms/step - loss: 0.4133 - val_loss: 0.3279
Epoch 4/43
106/106 [==============================] - 2s 16ms/step - loss: 0.3990 - val_loss: 0.3156
Epoch 5/43
106/106 [==============================] - 2s 16ms/step - loss: 0.3877 - val_loss: 0.3053
Epoch 6/43
106/106 [==============================] - 2s 16ms/step - loss: 0.3782 - val_loss: 0.2974
Epoch 7/43
106/106 [==============================] - 2s 16ms/step - loss: 0.3709 - val_loss: 0.2913
Epoch 8/43
106/106 [==============================] - 2s 16ms/step - loss: 0.3649 - val_loss: 0.2871
Epoch 9/43
106/106 [==============================] - 2s 16ms/step - loss: 0.3599 - val_loss: 0.2834
Epoch 10/43
106/106 [==============================] - 2s 16ms/step - loss: 0.3563 - val_loss: 0.2803
Epoch 11/43
106/106 [==============================] - 2s 16ms/step - loss: 0.3530 - val_loss: 0.2778
Epoch 12/43
106/106 [==============================] - 2s 16ms/step - loss: 0.3501 - val_loss: 0.2755 l
Epoch 13/43
106/106 [==============================] - 2s 16ms/step - loss: 0.3478 - val_loss: 0.2733
Epoch 14/43
106/106 [==============================] - 2s 16ms/step - loss: 0.3454 - val_loss: 0.2712
Epoch 15/43
106/106 [==============================] - 2s 16ms/step - loss: 0.3438 - val_loss: 0.2693
Epoch 16/43
106/106 [==============================] - 2s 16ms/step - loss: 0.3422 - val_loss: 0.2678
Epoch 17/43
106/106 [==============================] - 2s 16ms/step - loss: 0.3406 - val_loss: 0.2668
Epoch 18/43
106/106 [==============================] - 2s 16ms/step - loss: 0.3392 - val_loss: 0.2653
Epoch 19/43
106/106 [==============================] - 2s 17ms/step - loss: 0.3381 - val_loss: 0.2646
Epoch 20/43
106/106 [==============================] - 2s 16ms/step - loss: 0.3369 - val_loss: 0.2636
Epoch 21/43
106/106 [==============================] - 2s 16ms/step - loss: 0.3362 - val_loss: 0.2629
Epoch 22/43
106/106 [==============================] - 2s 16ms/step - loss: 0.3352 - val_loss: 0.2621
Epoch 23/43
106/106 [==============================] - 2s 16ms/step - loss: 0.3342 - val_loss: 0.2616
Epoch 24/43
106/106 [==============================] - 2s 16ms/step - loss: 0.3341 - val_loss: 0.2611
Epoch 25/43
106/106 [==============================] - 2s 16ms/step - loss: 0.3332 - val_loss: 0.2604
Epoch 26/43
106/106 [==============================] - 2s 16ms/step - loss: 0.3330 - val_loss: 0.2599
Epoch 27/43
106/106 [==============================] - 2s 16ms/step - loss: 0.3323 - val_loss: 0.2593
Epoch 28/43
106/106 [==============================] - 2s 17ms/step - loss: 0.3322 - val_loss: 0.2586
Epoch 29/43
106/106 [==============================] - 2s 16ms/step - loss: 0.3314 - val_loss: 0.2584
Epoch 30/43
106/106 [==============================] - 2s 16ms/step - loss: 0.3314 - val_loss: 0.2581
Epoch 31/43
106/106 [==============================] - 2s 17ms/step - loss: 0.3311 - val_loss: 0.2578
Epoch 32/43
106/106 [==============================] - 2s 15ms/step - loss: 0.3308 - val_loss: 0.2574
Epoch 33/43
106/106 [==============================] - 2s 16ms/step - loss: 0.3304 - val_loss: 0.2572
Epoch 34/43
106/106 [==============================] - 2s 16ms/step - loss: 0.3302 - val_loss: 0.2572
Epoch 35/43
106/106 [==============================] - 2s 16ms/step - loss: 0.3303 - val_loss: 0.2566
Epoch 36/43
106/106 [==============================] - 2s 16ms/step - loss: 0.3303 - val_loss: 0.2566
Epoch 37/43
106/106 [==============================] - 2s 16ms/step - loss: 0.3298 - val_loss: 0.2564
Epoch 38/43
106/106 [==============================] - 2s 16ms/step - loss: 0.3297 - val_loss: 0.2564
Epoch 39/43
106/106 [==============================] - 2s 16ms/step - loss: 0.3300 - val_loss: 0.2563
Epoch 40/43
106/106 [==============================] - 2s 16ms/step - loss: 0.3295 - val_loss: 0.2562
Epoch 41/43
106/106 [==============================] - 2s 16ms/step - loss: 0.3291 - val_loss: 0.2560
Epoch 42/43
106/106 [==============================] - 2s 16ms/step - loss: 0.3290 - val_loss: 0.2558
Epoch 43/43
106/106 [==============================] - 2s 16ms/step - loss: 0.3290 - val_loss: 0.2559
Execution time:  80.3897271156311
LSTM:
Mean Absolute Error: 0.1800
Root Mean Square Error: 0.5803
Mean Square Error: 0.3367

Train RMSE: 0.580
Train MSE: 0.337
Train MAE: 0.180
###########################

MODEL:  LSTM
sequence:  3h
units:  43
dropout1:  0.40519643149940265
dropout2:  0.3312343747027119
optimizer: adamax
activationDense: sigmoid
epochs: 56
batchsize: 11
validation_split: 0.1
Model: &#34;sequential_22&#34;
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
lstm_44 (LSTM)               (None, 18, 43)            7740      
_________________________________________________________________
dropout_44 (Dropout)         (None, 18, 43)            0         
_________________________________________________________________
lstm_45 (LSTM)               (None, 18, 43)            14964     
_________________________________________________________________
dropout_45 (Dropout)         (None, 18, 43)            0         
_________________________________________________________________
time_distributed_22 (TimeDis (None, 18, 1)             44        
=================================================================
Total params: 22,748
Trainable params: 22,748
Non-trainable params: 0
_________________________________________________________________
Epoch 1/56
325/325 [==============================] - 4s 13ms/step - loss: 0.7259 - val_loss: 0.8687
Epoch 2/56
325/325 [==============================] - 3s 10ms/step - loss: 0.6192 - val_loss: 0.8445
Epoch 3/56
325/325 [==============================] - 3s 10ms/step - loss: 0.6043 - val_loss: 0.8344
Epoch 4/56
325/325 [==============================] - 3s 10ms/step - loss: 0.5911 - val_loss: 0.8273
Epoch 5/56
325/325 [==============================] - 3s 10ms/step - loss: 0.5784 - val_loss: 0.8225
Epoch 6/56
325/325 [==============================] - 3s 10ms/step - loss: 0.5707 - val_loss: 0.8188
Epoch 7/56
325/325 [==============================] - 3s 10ms/step - loss: 0.5641 - val_loss: 0.8159
Epoch 8/56
325/325 [==============================] - 3s 10ms/step - loss: 0.5590 - val_loss: 0.8135
Epoch 9/56
325/325 [==============================] - 3s 10ms/step - loss: 0.5551 - val_loss: 0.8117
Epoch 10/56
325/325 [==============================] - 3s 10ms/step - loss: 0.5526 - val_loss: 0.8103
Epoch 11/56
325/325 [==============================] - 3s 10ms/step - loss: 0.5499 - val_loss: 0.8092
Epoch 12/56
325/325 [==============================] - 3s 10ms/step - loss: 0.5487 - val_loss: 0.8084
Epoch 13/56
325/325 [==============================] - 3s 10ms/step - loss: 0.5472 - val_loss: 0.8078
Epoch 14/56
325/325 [==============================] - 3s 10ms/step - loss: 0.5456 - val_loss: 0.8073
Epoch 15/56
325/325 [==============================] - 3s 10ms/step - loss: 0.5446 - val_loss: 0.8069
Epoch 16/56
325/325 [==============================] - 3s 10ms/step - loss: 0.5442 - val_loss: 0.8067
Epoch 17/56
325/325 [==============================] - 3s 10ms/step - loss: 0.5430 - val_loss: 0.8064
Epoch 18/56
325/325 [==============================] - 3s 10ms/step - loss: 0.5425 - val_loss: 0.8063
Epoch 19/56
325/325 [==============================] - 3s 10ms/step - loss: 0.5415 - val_loss: 0.8061
Epoch 20/56
325/325 [==============================] - 3s 10ms/step - loss: 0.5410 - val_loss: 0.8060
Epoch 21/56
325/325 [==============================] - 3s 10ms/step - loss: 0.5410 - val_loss: 0.8060
Epoch 22/56
325/325 [==============================] - 3s 10ms/step - loss: 0.5406 - val_loss: 0.8059
Epoch 23/56
325/325 [==============================] - 3s 10ms/step - loss: 0.5401 - val_loss: 0.8058
Epoch 24/56
325/325 [==============================] - 3s 10ms/step - loss: 0.5398 - val_loss: 0.8058
Epoch 25/56
325/325 [==============================] - 3s 10ms/step - loss: 0.5396 - val_loss: 0.8058
Epoch 26/56
325/325 [==============================] - 3s 10ms/step - loss: 0.5396 - val_loss: 0.8058
Epoch 27/56
325/325 [==============================] - 3s 10ms/step - loss: 0.5392 - val_loss: 0.8057
Epoch 28/56
325/325 [==============================] - 3s 10ms/step - loss: 0.5390 - val_loss: 0.8057
Epoch 29/56
325/325 [==============================] - 3s 10ms/step - loss: 0.5388 - val_loss: 0.8057
Epoch 30/56
325/325 [==============================] - 3s 10ms/step - loss: 0.5388 - val_loss: 0.8057
Epoch 31/56
325/325 [==============================] - 3s 10ms/step - loss: 0.5384 - val_loss: 0.8057
Epoch 32/56
325/325 [==============================] - 3s 10ms/step - loss: 0.5385 - val_loss: 0.8057
Epoch 33/56
325/325 [==============================] - 3s 10ms/step - loss: 0.5386 - val_loss: 0.8057
Epoch 34/56
325/325 [==============================] - 3s 10ms/step - loss: 0.5385 - val_loss: 0.8057
Epoch 35/56
325/325 [==============================] - 3s 10ms/step - loss: 0.5382 - val_loss: 0.8057
Epoch 36/56
325/325 [==============================] - 3s 10ms/step - loss: 0.5382 - val_loss: 0.8056
Epoch 37/56
325/325 [==============================] - 3s 10ms/step - loss: 0.5383 - val_loss: 0.8056
Epoch 38/56
325/325 [==============================] - 3s 10ms/step - loss: 0.5384 - val_loss: 0.8056
Epoch 39/56
325/325 [==============================] - 3s 10ms/step - loss: 0.5379 - val_loss: 0.8056
Epoch 40/56
325/325 [==============================] - 3s 10ms/step - loss: 0.5382 - val_loss: 0.8056
Epoch 41/56
325/325 [==============================] - 3s 10ms/step - loss: 0.5382 - val_loss: 0.8056
Epoch 42/56
325/325 [==============================] - 3s 10ms/step - loss: 0.5379 - val_loss: 0.8056
Epoch 43/56
325/325 [==============================] - 3s 10ms/step - loss: 0.5380 - val_loss: 0.8056
Epoch 44/56
325/325 [==============================] - 3s 10ms/step - loss: 0.5379 - val_loss: 0.8056
Epoch 45/56
325/325 [==============================] - 3s 10ms/step - loss: 0.5379 - val_loss: 0.8056
Epoch 46/56
325/325 [==============================] - 3s 10ms/step - loss: 0.5376 - val_loss: 0.8056
Epoch 47/56
325/325 [==============================] - 3s 10ms/step - loss: 0.5378 - val_loss: 0.8056
Epoch 48/56
325/325 [==============================] - 3s 10ms/step - loss: 0.5378 - val_loss: 0.8056
Epoch 49/56
325/325 [==============================] - 3s 10ms/step - loss: 0.5377 - val_loss: 0.8056
Epoch 50/56
325/325 [==============================] - 3s 10ms/step - loss: 0.5378 - val_loss: 0.8056
Epoch 51/56
325/325 [==============================] - 3s 10ms/step - loss: 0.5377 - val_loss: 0.8056
Epoch 52/56
325/325 [==============================] - 3s 10ms/step - loss: 0.5375 - val_loss: 0.8056
Epoch 53/56
325/325 [==============================] - 3s 10ms/step - loss: 0.5376 - val_loss: 0.8056
Epoch 54/56
325/325 [==============================] - 3s 10ms/step - loss: 0.5374 - val_loss: 0.8056
Epoch 55/56
325/325 [==============================] - 3s 10ms/step - loss: 0.5375 - val_loss: 0.8056
Epoch 56/56
325/325 [==============================] - 3s 10ms/step - loss: 0.5374 - val_loss: 0.8056
Execution time:  184.46612906455994
LSTM:
Mean Absolute Error: 0.5021
Root Mean Square Error: 0.7550
Mean Square Error: 0.5701

Train RMSE: 0.755
Train MSE: 0.570
Train MAE: 0.502
###########################

MODEL:  LSTM
sequence:  3h
units:  45
dropout1:  0.11814836227952394
dropout2:  0.24325404382648977
optimizer: adamax
activationDense: sigmoid
epochs: 43
batchsize: 30
validation_split: 0.2
Model: &#34;sequential_23&#34;
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
lstm_46 (LSTM)               (None, 18, 45)            8460      
_________________________________________________________________
dropout_46 (Dropout)         (None, 18, 45)            0         
_________________________________________________________________
lstm_47 (LSTM)               (None, 18, 45)            16380     
_________________________________________________________________
dropout_47 (Dropout)         (None, 18, 45)            0         
_________________________________________________________________
time_distributed_23 (TimeDis (None, 18, 1)             46        
=================================================================
Total params: 24,886
Trainable params: 24,886
Non-trainable params: 0
_________________________________________________________________
Epoch 1/43
106/106 [==============================] - 3s 24ms/step - loss: 0.8043 - val_loss: 0.8641
Epoch 2/43
106/106 [==============================] - 2s 16ms/step - loss: 0.6547 - val_loss: 0.7682
Epoch 3/43
106/106 [==============================] - 2s 16ms/step - loss: 0.6288 - val_loss: 0.7484
Epoch 4/43
106/106 [==============================] - 2s 16ms/step - loss: 0.6181 - val_loss: 0.7382
Epoch 5/43
106/106 [==============================] - 2s 16ms/step - loss: 0.6102 - val_loss: 0.7309
Epoch 6/43
106/106 [==============================] - 2s 16ms/step - loss: 0.6031 - val_loss: 0.7249
Epoch 7/43
106/106 [==============================] - 2s 16ms/step - loss: 0.5951 - val_loss: 0.7191
Epoch 8/43
106/106 [==============================] - 2s 16ms/step - loss: 0.5876 - val_loss: 0.7143
Epoch 9/43
106/106 [==============================] - 2s 16ms/step - loss: 0.5826 - val_loss: 0.7106
Epoch 10/43
106/106 [==============================] - 2s 16ms/step - loss: 0.5767 - val_loss: 0.7071
Epoch 11/43
106/106 [==============================] - 2s 16ms/step - loss: 0.5708 - val_loss: 0.7042
Epoch 12/43
106/106 [==============================] - 2s 16ms/step - loss: 0.5667 - val_loss: 0.7013
Epoch 13/43
106/106 [==============================] - 2s 16ms/step - loss: 0.5634 - val_loss: 0.6989
Epoch 14/43
106/106 [==============================] - 2s 16ms/step - loss: 0.5605 - val_loss: 0.6966
Epoch 15/43
106/106 [==============================] - 2s 17ms/step - loss: 0.5580 - val_loss: 0.6948
Epoch 16/43
106/106 [==============================] - 2s 15ms/step - loss: 0.5559 - val_loss: 0.6932
Epoch 17/43
106/106 [==============================] - 2s 16ms/step - loss: 0.5541 - val_loss: 0.6918
Epoch 18/43
106/106 [==============================] - 2s 16ms/step - loss: 0.5524 - val_loss: 0.6904
Epoch 19/43
106/106 [==============================] - 2s 16ms/step - loss: 0.5508 - val_loss: 0.6894
Epoch 20/43
106/106 [==============================] - 2s 16ms/step - loss: 0.5494 - val_loss: 0.6883
Epoch 21/43
106/106 [==============================] - 2s 16ms/step - loss: 0.5483 - val_loss: 0.6874
Epoch 22/43
106/106 [==============================] - 2s 16ms/step - loss: 0.5470 - val_loss: 0.6864
Epoch 23/43
106/106 [==============================] - 2s 16ms/step - loss: 0.5460 - val_loss: 0.6856
Epoch 24/43
106/106 [==============================] - 2s 16ms/step - loss: 0.5452 - val_loss: 0.6851
Epoch 25/43
106/106 [==============================] - 2s 16ms/step - loss: 0.5446 - val_loss: 0.6844
Epoch 26/43
106/106 [==============================] - 2s 16ms/step - loss: 0.5434 - val_loss: 0.6839
Epoch 27/43
106/106 [==============================] - 2s 16ms/step - loss: 0.5432 - val_loss: 0.6833
Epoch 28/43
106/106 [==============================] - 2s 16ms/step - loss: 0.5426 - val_loss: 0.6829
Epoch 29/43
106/106 [==============================] - 2s 16ms/step - loss: 0.5418 - val_loss: 0.6826
Epoch 30/43
106/106 [==============================] - 2s 16ms/step - loss: 0.5414 - val_loss: 0.6821
Epoch 31/43
106/106 [==============================] - 2s 16ms/step - loss: 0.5409 - val_loss: 0.6818
Epoch 32/43
106/106 [==============================] - 2s 16ms/step - loss: 0.5406 - val_loss: 0.6815
Epoch 33/43
106/106 [==============================] - 2s 16ms/step - loss: 0.5401 - val_loss: 0.6813
Epoch 34/43
106/106 [==============================] - 2s 16ms/step - loss: 0.5397 - val_loss: 0.6811
Epoch 35/43
106/106 [==============================] - 2s 16ms/step - loss: 0.5394 - val_loss: 0.6809
Epoch 36/43
106/106 [==============================] - 2s 16ms/step - loss: 0.5392 - val_loss: 0.6806
Epoch 37/43
106/106 [==============================] - 2s 16ms/step - loss: 0.5389 - val_loss: 0.6806
Epoch 38/43
106/106 [==============================] - 2s 16ms/step - loss: 0.5389 - val_loss: 0.6803
Epoch 39/43
106/106 [==============================] - 2s 16ms/step - loss: 0.5386 - val_loss: 0.6801
Epoch 40/43
106/106 [==============================] - 2s 16ms/step - loss: 0.5383 - val_loss: 0.6801
Epoch 41/43
106/106 [==============================] - 2s 16ms/step - loss: 0.5378 - val_loss: 0.6800
Epoch 42/43
106/106 [==============================] - 2s 16ms/step - loss: 0.5380 - val_loss: 0.6799
Epoch 43/43
106/106 [==============================] - 2s 16ms/step - loss: 0.5377 - val_loss: 0.6799
Execution time:  79.56351470947266
LSTM:
Mean Absolute Error: 0.5041
Root Mean Square Error: 0.7550
Mean Square Error: 0.5701

Train RMSE: 0.755
Train MSE: 0.570
Train MAE: 0.504
###########################

MODEL:  LSTM
sequence:  6h
units:  43
dropout1:  0.40519643149940265
dropout2:  0.3312343747027119
optimizer: adam
activationDense: tanh
epochs: 56
batchsize: 11
validation_split: 0.1
Model: &#34;sequential_24&#34;
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
lstm_48 (LSTM)               (None, 36, 43)            7740      
_________________________________________________________________
dropout_48 (Dropout)         (None, 36, 43)            0         
_________________________________________________________________
lstm_49 (LSTM)               (None, 36, 43)            14964     
_________________________________________________________________
dropout_49 (Dropout)         (None, 36, 43)            0         
_________________________________________________________________
time_distributed_24 (TimeDis (None, 36, 1)             44        
=================================================================
Total params: 22,748
Trainable params: 22,748
Non-trainable params: 0
_________________________________________________________________
Epoch 1/56
324/324 [==============================] - 9s 27ms/step - loss: 0.5046 - val_loss: 0.3819
Epoch 2/56
324/324 [==============================] - 8s 23ms/step - loss: 0.4459 - val_loss: 0.3214
Epoch 3/56
324/324 [==============================] - 8s 24ms/step - loss: 0.4292 - val_loss: 0.2924
Epoch 4/56
324/324 [==============================] - 8s 23ms/step - loss: 0.4216 - val_loss: 0.2774
Epoch 5/56
324/324 [==============================] - 8s 24ms/step - loss: 0.4174 - val_loss: 0.2698
Epoch 6/56
324/324 [==============================] - 8s 24ms/step - loss: 0.4150 - val_loss: 0.2635
Epoch 7/56
324/324 [==============================] - 8s 24ms/step - loss: 0.4134 - val_loss: 0.2591
Epoch 8/56
324/324 [==============================] - 8s 24ms/step - loss: 0.4123 - val_loss: 0.2584
Epoch 9/56
324/324 [==============================] - 8s 24ms/step - loss: 0.4113 - val_loss: 0.2556
Epoch 10/56
324/324 [==============================] - 8s 24ms/step - loss: 0.4116 - val_loss: 0.2541
Epoch 11/56
324/324 [==============================] - 8s 24ms/step - loss: 0.4114 - val_loss: 0.2548
Epoch 12/56
324/324 [==============================] - 8s 24ms/step - loss: 0.4109 - val_loss: 0.2544
Epoch 13/56
324/324 [==============================] - 8s 24ms/step - loss: 0.4106 - val_loss: 0.2552
Epoch 14/56
324/324 [==============================] - 8s 24ms/step - loss: 0.4103 - val_loss: 0.2540
Epoch 15/56
324/324 [==============================] - 8s 24ms/step - loss: 0.4097 - val_loss: 0.2549
Epoch 16/56
324/324 [==============================] - 8s 24ms/step - loss: 0.4103 - val_loss: 0.2498
Epoch 17/56
324/324 [==============================] - 8s 24ms/step - loss: 0.4087 - val_loss: 0.2479
Epoch 18/56
324/324 [==============================] - 8s 24ms/step - loss: 0.4094 - val_loss: 0.2499
Epoch 19/56
324/324 [==============================] - 8s 24ms/step - loss: 0.4083 - val_loss: 0.2470
Epoch 20/56
324/324 [==============================] - 8s 24ms/step - loss: 0.4079 - val_loss: 0.2473
Epoch 21/56
324/324 [==============================] - 8s 24ms/step - loss: 0.4079 - val_loss: 0.2465
Epoch 22/56
324/324 [==============================] - 8s 24ms/step - loss: 0.4074 - val_loss: 0.2455
Epoch 23/56
324/324 [==============================] - 8s 24ms/step - loss: 0.4073 - val_loss: 0.2469
Epoch 24/56
324/324 [==============================] - 8s 24ms/step - loss: 0.4070 - val_loss: 0.2452
Epoch 25/56
324/324 [==============================] - 8s 24ms/step - loss: 0.4063 - val_loss: 0.2452
Epoch 26/56
324/324 [==============================] - 8s 24ms/step - loss: 0.4058 - val_loss: 0.2441
Epoch 27/56
324/324 [==============================] - 8s 24ms/step - loss: 0.4052 - val_loss: 0.2428
Epoch 28/56
324/324 [==============================] - 8s 24ms/step - loss: 0.4051 - val_loss: 0.2449
Epoch 29/56
324/324 [==============================] - 8s 24ms/step - loss: 0.4048 - val_loss: 0.2459
Epoch 30/56
324/324 [==============================] - 8s 24ms/step - loss: 0.4047 - val_loss: 0.2426
Epoch 31/56
324/324 [==============================] - 8s 24ms/step - loss: 0.4037 - val_loss: 0.2426
Epoch 32/56
324/324 [==============================] - 8s 24ms/step - loss: 0.4038 - val_loss: 0.2418
Epoch 33/56
324/324 [==============================] - 8s 24ms/step - loss: 0.4038 - val_loss: 0.2428
Epoch 34/56
324/324 [==============================] - 8s 24ms/step - loss: 0.4034 - val_loss: 0.2399
Epoch 35/56
324/324 [==============================] - 8s 24ms/step - loss: 0.4029 - val_loss: 0.2403
Epoch 36/56
324/324 [==============================] - 8s 24ms/step - loss: 0.4022 - val_loss: 0.2403
Epoch 37/56
324/324 [==============================] - 8s 24ms/step - loss: 0.4024 - val_loss: 0.2404
Epoch 38/56
324/324 [==============================] - 8s 24ms/step - loss: 0.4013 - val_loss: 0.2383
Epoch 39/56
324/324 [==============================] - 8s 24ms/step - loss: 0.4026 - val_loss: 0.2399
Epoch 40/56
324/324 [==============================] - 8s 24ms/step - loss: 0.4007 - val_loss: 0.2377
Epoch 41/56
324/324 [==============================] - 8s 24ms/step - loss: 0.4008 - val_loss: 0.2358
Epoch 42/56
324/324 [==============================] - 8s 24ms/step - loss: 0.4012 - val_loss: 0.2368
Epoch 43/56
324/324 [==============================] - 8s 24ms/step - loss: 0.4010 - val_loss: 0.2391
Epoch 44/56
324/324 [==============================] - 8s 24ms/step - loss: 0.4007 - val_loss: 0.2379
Epoch 45/56
324/324 [==============================] - 8s 24ms/step - loss: 0.3989 - val_loss: 0.2394
Epoch 46/56
324/324 [==============================] - 8s 24ms/step - loss: 0.3991 - val_loss: 0.2369
Epoch 47/56
324/324 [==============================] - 8s 24ms/step - loss: 0.3987 - val_loss: 0.2344
Epoch 48/56
324/324 [==============================] - 8s 24ms/step - loss: 0.3987 - val_loss: 0.2365
Epoch 49/56
324/324 [==============================] - 8s 24ms/step - loss: 0.3986 - val_loss: 0.2365
Epoch 50/56
324/324 [==============================] - 8s 24ms/step - loss: 0.3983 - val_loss: 0.2386
Epoch 51/56
324/324 [==============================] - 8s 24ms/step - loss: 0.3975 - val_loss: 0.2339
Epoch 52/56
324/324 [==============================] - 8s 24ms/step - loss: 0.3976 - val_loss: 0.2359
Epoch 53/56
324/324 [==============================] - 8s 24ms/step - loss: 0.3972 - val_loss: 0.2373
Epoch 54/56
324/324 [==============================] - 8s 24ms/step - loss: 0.3970 - val_loss: 0.2366
Epoch 55/56
324/324 [==============================] - 8s 24ms/step - loss: 0.3971 - val_loss: 0.2365
Epoch 56/56
324/324 [==============================] - 8s 24ms/step - loss: 0.3968 - val_loss: 0.2355
Execution time:  442.22993898391724
LSTM:
Mean Absolute Error: 0.2268
Root Mean Square Error: 0.6344
Mean Square Error: 0.4025

Train RMSE: 0.634
Train MSE: 0.402
Train MAE: 0.227
###########################

MODEL:  LSTM
sequence:  6h
units:  45
dropout1:  0.11814836227952394
dropout2:  0.24325404382648977
optimizer: adam
activationDense: tanh
epochs: 43
batchsize: 30
validation_split: 0.2
Model: &#34;sequential_25&#34;
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
lstm_50 (LSTM)               (None, 36, 45)            8460      
_________________________________________________________________
dropout_50 (Dropout)         (None, 36, 45)            0         
_________________________________________________________________
lstm_51 (LSTM)               (None, 36, 45)            16380     
_________________________________________________________________
dropout_51 (Dropout)         (None, 36, 45)            0         
_________________________________________________________________
time_distributed_25 (TimeDis (None, 36, 1)             46        
=================================================================
Total params: 24,886
Trainable params: 24,886
Non-trainable params: 0
_________________________________________________________________
Epoch 1/43
106/106 [==============================] - 4s 36ms/step - loss: 0.5463 - val_loss: 0.3999
Epoch 2/43
106/106 [==============================] - 3s 28ms/step - loss: 0.4744 - val_loss: 0.3748
Epoch 3/43
106/106 [==============================] - 3s 29ms/step - loss: 0.4501 - val_loss: 0.3602
Epoch 4/43
106/106 [==============================] - 3s 28ms/step - loss: 0.4366 - val_loss: 0.3511
Epoch 5/43
106/106 [==============================] - 3s 28ms/step - loss: 0.4280 - val_loss: 0.3452
Epoch 6/43
106/106 [==============================] - 3s 28ms/step - loss: 0.4223 - val_loss: 0.3411
Epoch 7/43
106/106 [==============================] - 3s 28ms/step - loss: 0.4185 - val_loss: 0.3383
Epoch 8/43
106/106 [==============================] - 3s 29ms/step - loss: 0.4151 - val_loss: 0.3354
Epoch 9/43
106/106 [==============================] - 3s 28ms/step - loss: 0.4122 - val_loss: 0.3336
Epoch 10/43
106/106 [==============================] - 3s 28ms/step - loss: 0.4102 - val_loss: 0.3316
Epoch 11/43
106/106 [==============================] - 3s 28ms/step - loss: 0.4082 - val_loss: 0.3297
Epoch 12/43
106/106 [==============================] - 3s 27ms/step - loss: 0.4063 - val_loss: 0.3275
Epoch 13/43
106/106 [==============================] - 3s 28ms/step - loss: 0.4044 - val_loss: 0.3264
Epoch 14/43
106/106 [==============================] - 3s 28ms/step - loss: 0.4028 - val_loss: 0.3258
Epoch 15/43
106/106 [==============================] - 3s 27ms/step - loss: 0.4018 - val_loss: 0.3250
Epoch 16/43
106/106 [==============================] - 3s 27ms/step - loss: 0.4009 - val_loss: 0.3244
Epoch 17/43
106/106 [==============================] - 3s 27ms/step - loss: 0.4003 - val_loss: 0.3237
Epoch 18/43
106/106 [==============================] - 3s 27ms/step - loss: 0.3997 - val_loss: 0.3237
Epoch 19/43
106/106 [==============================] - 3s 29ms/step - loss: 0.3989 - val_loss: 0.3231
Epoch 20/43
106/106 [==============================] - 3s 27ms/step - loss: 0.3984 - val_loss: 0.3231
Epoch 21/43
106/106 [==============================] - 3s 27ms/step - loss: 0.3982 - val_loss: 0.3228
Epoch 22/43
106/106 [==============================] - 3s 27ms/step - loss: 0.3977 - val_loss: 0.3226
Epoch 23/43
106/106 [==============================] - 3s 27ms/step - loss: 0.3975 - val_loss: 0.3226
Epoch 24/43
106/106 [==============================] - 3s 29ms/step - loss: 0.3973 - val_loss: 0.3221
Epoch 25/43
106/106 [==============================] - 3s 27ms/step - loss: 0.3968 - val_loss: 0.3224
Epoch 26/43
106/106 [==============================] - 3s 27ms/step - loss: 0.3965 - val_loss: 0.3218
Epoch 27/43
106/106 [==============================] - 3s 27ms/step - loss: 0.3968 - val_loss: 0.3224
Epoch 28/43
106/106 [==============================] - 3s 27ms/step - loss: 0.3964 - val_loss: 0.3220
Epoch 29/43
106/106 [==============================] - 3s 29ms/step - loss: 0.3963 - val_loss: 0.3222
Epoch 30/43
106/106 [==============================] - 3s 28ms/step - loss: 0.3959 - val_loss: 0.3223
Epoch 31/43
106/106 [==============================] - 3s 27ms/step - loss: 0.3958 - val_loss: 0.3228
Epoch 32/43
106/106 [==============================] - 3s 27ms/step - loss: 0.3951 - val_loss: 0.3219
Epoch 33/43
106/106 [==============================] - 3s 27ms/step - loss: 0.3955 - val_loss: 0.3227
Epoch 34/43
106/106 [==============================] - 3s 28ms/step - loss: 0.3947 - val_loss: 0.3227
Epoch 35/43
106/106 [==============================] - 3s 29ms/step - loss: 0.3942 - val_loss: 0.3231
Epoch 36/43
106/106 [==============================] - 3s 27ms/step - loss: 0.3945 - val_loss: 0.3228
Epoch 37/43
106/106 [==============================] - 3s 27ms/step - loss: 0.3945 - val_loss: 0.3230
Epoch 38/43
106/106 [==============================] - 3s 27ms/step - loss: 0.3939 - val_loss: 0.3231
Epoch 39/43
106/106 [==============================] - 3s 27ms/step - loss: 0.3936 - val_loss: 0.3235
Epoch 40/43
106/106 [==============================] - 3s 29ms/step - loss: 0.3932 - val_loss: 0.3239
Epoch 41/43
106/106 [==============================] - 3s 28ms/step - loss: 0.3929 - val_loss: 0.3243
Epoch 42/43
106/106 [==============================] - 3s 27ms/step - loss: 0.3928 - val_loss: 0.3244
Epoch 43/43
106/106 [==============================] - 3s 27ms/step - loss: 0.3922 - val_loss: 0.3249
Execution time:  134.29966068267822
LSTM:
Mean Absolute Error: 0.2109
Root Mean Square Error: 0.6137
Mean Square Error: 0.3766

Train RMSE: 0.614
Train MSE: 0.377
Train MAE: 0.211
###########################

MODEL:  LSTM
sequence:  6h
units:  43
dropout1:  0.40519643149940265
dropout2:  0.3312343747027119
optimizer: adam
activationDense: sigmoid
epochs: 56
batchsize: 11
validation_split: 0.1
Model: &#34;sequential_26&#34;
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
lstm_52 (LSTM)               (None, 36, 43)            7740      
_________________________________________________________________
dropout_52 (Dropout)         (None, 36, 43)            0         
_________________________________________________________________
lstm_53 (LSTM)               (None, 36, 43)            14964     
_________________________________________________________________
dropout_53 (Dropout)         (None, 36, 43)            0         
_________________________________________________________________
time_distributed_26 (TimeDis (None, 36, 1)             44        
=================================================================
Total params: 22,748
Trainable params: 22,748
Non-trainable params: 0
_________________________________________________________________
Epoch 1/56
324/324 [==============================] - 8s 26ms/step - loss: 0.6805 - val_loss: 0.8273
Epoch 2/56
324/324 [==============================] - 8s 24ms/step - loss: 0.6181 - val_loss: 0.8170
Epoch 3/56
324/324 [==============================] - 8s 24ms/step - loss: 0.5999 - val_loss: 0.8119
Epoch 4/56
324/324 [==============================] - 8s 24ms/step - loss: 0.5936 - val_loss: 0.8091
Epoch 5/56
324/324 [==============================] - 8s 24ms/step - loss: 0.5890 - val_loss: 0.8074
Epoch 6/56
324/324 [==============================] - 8s 24ms/step - loss: 0.5865 - val_loss: 0.8064
Epoch 7/56
324/324 [==============================] - 8s 24ms/step - loss: 0.5842 - val_loss: 0.8058
Epoch 8/56
324/324 [==============================] - 8s 24ms/step - loss: 0.5830 - val_loss: 0.8055
Epoch 9/56
324/324 [==============================] - 8s 24ms/step - loss: 0.5822 - val_loss: 0.8053
Epoch 10/56
324/324 [==============================] - 8s 24ms/step - loss: 0.5815 - val_loss: 0.8052
Epoch 11/56
324/324 [==============================] - 8s 24ms/step - loss: 0.5812 - val_loss: 0.8051
Epoch 12/56
324/324 [==============================] - 8s 24ms/step - loss: 0.5806 - val_loss: 0.8051
Epoch 13/56
324/324 [==============================] - 8s 24ms/step - loss: 0.5803 - val_loss: 0.8050
Epoch 14/56
324/324 [==============================] - 8s 24ms/step - loss: 0.5801 - val_loss: 0.8050
Epoch 15/56
324/324 [==============================] - 8s 24ms/step - loss: 0.5799 - val_loss: 0.8050
Epoch 16/56
324/324 [==============================] - 8s 24ms/step - loss: 0.5793 - val_loss: 0.8050
Epoch 17/56
324/324 [==============================] - 8s 24ms/step - loss: 0.5789 - val_loss: 0.8050
Epoch 18/56
324/324 [==============================] - 8s 24ms/step - loss: 0.5787 - val_loss: 0.8050
Epoch 19/56
324/324 [==============================] - 8s 25ms/step - loss: 0.5782 - val_loss: 0.8049
Epoch 20/56
324/324 [==============================] - 8s 24ms/step - loss: 0.5778 - val_loss: 0.8049
Epoch 21/56
324/324 [==============================] - 8s 24ms/step - loss: 0.5776 - val_loss: 0.8049
Epoch 22/56
324/324 [==============================] - 8s 24ms/step - loss: 0.5769 - val_loss: 0.8049
Epoch 23/56
324/324 [==============================] - 8s 25ms/step - loss: 0.5761 - val_loss: 0.8049
Epoch 24/56
324/324 [==============================] - 8s 24ms/step - loss: 0.5761 - val_loss: 0.8049
Epoch 25/56
324/324 [==============================] - 8s 24ms/step - loss: 0.5755 - val_loss: 0.8049
Epoch 26/56
324/324 [==============================] - 8s 24ms/step - loss: 0.5747 - val_loss: 0.8049
Epoch 27/56
324/324 [==============================] - 8s 24ms/step - loss: 0.5754 - val_loss: 0.8049
Epoch 28/56
324/324 [==============================] - 8s 24ms/step - loss: 0.5755 - val_loss: 0.8049
Epoch 29/56
324/324 [==============================] - 8s 24ms/step - loss: 0.5737 - val_loss: 0.8049
Epoch 30/56
324/324 [==============================] - 8s 24ms/step - loss: 0.5736 - val_loss: 0.8049
Epoch 31/56
324/324 [==============================] - 8s 24ms/step - loss: 0.5732 - val_loss: 0.8049
Epoch 32/56
324/324 [==============================] - 8s 24ms/step - loss: 0.5726 - val_loss: 0.8049
Epoch 33/56
324/324 [==============================] - 8s 24ms/step - loss: 0.5717 - val_loss: 0.8049
Epoch 34/56
324/324 [==============================] - 8s 24ms/step - loss: 0.5713 - val_loss: 0.8049
Epoch 35/56
324/324 [==============================] - 8s 24ms/step - loss: 0.5715 - val_loss: 0.8049
Epoch 36/56
324/324 [==============================] - 8s 23ms/step - loss: 0.5708 - val_loss: 0.8049
Epoch 37/56
324/324 [==============================] - 8s 24ms/step - loss: 0.5713 - val_loss: 0.8049
Epoch 38/56
324/324 [==============================] - 8s 23ms/step - loss: 0.5705 - val_loss: 0.8049
Epoch 39/56
324/324 [==============================] - 8s 24ms/step - loss: 0.5700 - val_loss: 0.8049
Epoch 40/56
324/324 [==============================] - 8s 24ms/step - loss: 0.5698 - val_loss: 0.8049
Epoch 41/56
324/324 [==============================] - 8s 23ms/step - loss: 0.5688 - val_loss: 0.8049
Epoch 42/56
324/324 [==============================] - 8s 24ms/step - loss: 0.5693 - val_loss: 0.8049
Epoch 43/56
324/324 [==============================] - 8s 23ms/step - loss: 0.5683 - val_loss: 0.8049
Epoch 44/56
324/324 [==============================] - 8s 24ms/step - loss: 0.5685 - val_loss: 0.8049
Epoch 45/56
324/324 [==============================] - 8s 23ms/step - loss: 0.5671 - val_loss: 0.8049
Epoch 46/56
324/324 [==============================] - 8s 24ms/step - loss: 0.5668 - val_loss: 0.8049
Epoch 47/56
324/324 [==============================] - 8s 24ms/step - loss: 0.5675 - val_loss: 0.8049
Epoch 48/56
324/324 [==============================] - 8s 24ms/step - loss: 0.5662 - val_loss: 0.8049
Epoch 49/56
324/324 [==============================] - 8s 23ms/step - loss: 0.5671 - val_loss: 0.8049
Epoch 50/56
324/324 [==============================] - 8s 24ms/step - loss: 0.5677 - val_loss: 0.8049
Epoch 51/56
324/324 [==============================] - 8s 23ms/step - loss: 0.5662 - val_loss: 0.8049
Epoch 52/56
324/324 [==============================] - 8s 24ms/step - loss: 0.5661 - val_loss: 0.8049
Epoch 53/56
324/324 [==============================] - 8s 23ms/step - loss: 0.5653 - val_loss: 0.8049
Epoch 54/56
324/324 [==============================] - 8s 24ms/step - loss: 0.5651 - val_loss: 0.8049
Epoch 55/56
324/324 [==============================] - 8s 25ms/step - loss: 0.5655 - val_loss: 0.8049
Epoch 56/56
324/324 [==============================] - 8s 25ms/step - loss: 0.5645 - val_loss: 0.8049
Execution time:  440.38399744033813
LSTM:
Mean Absolute Error: 0.5417
Root Mean Square Error: 0.8082
Mean Square Error: 0.6531

Train RMSE: 0.808
Train MSE: 0.653
Train MAE: 0.542
###########################

MODEL:  LSTM
sequence:  6h
units:  45
dropout1:  0.11814836227952394
dropout2:  0.24325404382648977
optimizer: adam
activationDense: sigmoid
epochs: 43
batchsize: 30
validation_split: 0.2
Model: &#34;sequential_27&#34;
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
lstm_54 (LSTM)               (None, 36, 45)            8460      
_________________________________________________________________
dropout_54 (Dropout)         (None, 36, 45)            0         
_________________________________________________________________
lstm_55 (LSTM)               (None, 36, 45)            16380     
_________________________________________________________________
dropout_55 (Dropout)         (None, 36, 45)            0         
_________________________________________________________________
time_distributed_27 (TimeDis (None, 36, 1)             46        
=================================================================
Total params: 24,886
Trainable params: 24,886
Non-trainable params: 0
_________________________________________________________________
Epoch 1/43
106/106 [==============================] - 4s 39ms/step - loss: 0.7355 - val_loss: 0.7710
Epoch 2/43
106/106 [==============================] - 3s 28ms/step - loss: 0.6397 - val_loss: 0.7466
Epoch 3/43
106/106 [==============================] - 3s 28ms/step - loss: 0.6254 - val_loss: 0.7375
Epoch 4/43
106/106 [==============================] - 3s 28ms/step - loss: 0.6170 - val_loss: 0.7292
Epoch 5/43
106/106 [==============================] - 3s 28ms/step - loss: 0.6048 - val_loss: 0.7220
Epoch 6/43
106/106 [==============================] - 3s 28ms/step - loss: 0.5973 - val_loss: 0.7181
Epoch 7/43
106/106 [==============================] - 3s 29ms/step - loss: 0.5934 - val_loss: 0.7155
Epoch 8/43
106/106 [==============================] - 3s 27ms/step - loss: 0.5899 - val_loss: 0.7139
Epoch 9/43
106/106 [==============================] - 3s 28ms/step - loss: 0.5873 - val_loss: 0.7127
Epoch 10/43
106/106 [==============================] - 3s 28ms/step - loss: 0.5853 - val_loss: 0.7115
Epoch 11/43
106/106 [==============================] - 3s 27ms/step - loss: 0.5835 - val_loss: 0.7103
Epoch 12/43
106/106 [==============================] - 3s 29ms/step - loss: 0.5822 - val_loss: 0.7098
Epoch 13/43
106/106 [==============================] - 3s 28ms/step - loss: 0.5811 - val_loss: 0.7089
Epoch 14/43
106/106 [==============================] - 3s 28ms/step - loss: 0.5801 - val_loss: 0.7084
Epoch 15/43
106/106 [==============================] - 3s 28ms/step - loss: 0.5795 - val_loss: 0.7079
Epoch 16/43
106/106 [==============================] - 3s 28ms/step - loss: 0.5785 - val_loss: 0.7072
Epoch 17/43
106/106 [==============================] - 3s 28ms/step - loss: 0.5779 - val_loss: 0.7070
Epoch 18/43
106/106 [==============================] - 3s 28ms/step - loss: 0.5773 - val_loss: 0.7070
Epoch 19/43
106/106 [==============================] - 3s 28ms/step - loss: 0.5768 - val_loss: 0.7064
Epoch 20/43
106/106 [==============================] - 3s 28ms/step - loss: 0.5766 - val_loss: 0.7065
Epoch 21/43
106/106 [==============================] - 3s 28ms/step - loss: 0.5764 - val_loss: 0.7063
Epoch 22/43
106/106 [==============================] - 3s 28ms/step - loss: 0.5761 - val_loss: 0.7062
Epoch 23/43
106/106 [==============================] - 3s 29ms/step - loss: 0.5755 - val_loss: 0.7062
Epoch 24/43
106/106 [==============================] - 3s 28ms/step - loss: 0.5753 - val_loss: 0.7055
Epoch 25/43
106/106 [==============================] - 3s 28ms/step - loss: 0.5751 - val_loss: 0.7056
Epoch 26/43
106/106 [==============================] - 3s 28ms/step - loss: 0.5749 - val_loss: 0.7054
Epoch 27/43
106/106 [==============================] - 3s 28ms/step - loss: 0.5747 - val_loss: 0.7055
Epoch 28/43
106/106 [==============================] - 3s 29ms/step - loss: 0.5742 - val_loss: 0.7055
Epoch 29/43
106/106 [==============================] - 3s 28ms/step - loss: 0.5741 - val_loss: 0.7057
Epoch 30/43
106/106 [==============================] - 3s 28ms/step - loss: 0.5740 - val_loss: 0.7055
Epoch 31/43
106/106 [==============================] - 3s 28ms/step - loss: 0.5737 - val_loss: 0.7062
Epoch 32/43
106/106 [==============================] - 3s 28ms/step - loss: 0.5733 - val_loss: 0.7057
Epoch 33/43
106/106 [==============================] - 3s 29ms/step - loss: 0.5732 - val_loss: 0.7066
Epoch 34/43
106/106 [==============================] - 3s 29ms/step - loss: 0.5726 - val_loss: 0.7061
Epoch 35/43
106/106 [==============================] - 3s 28ms/step - loss: 0.5726 - val_loss: 0.7057
Epoch 36/43
106/106 [==============================] - 3s 28ms/step - loss: 0.5725 - val_loss: 0.7066
Epoch 37/43
106/106 [==============================] - 3s 28ms/step - loss: 0.5716 - val_loss: 0.7066
Epoch 38/43
106/106 [==============================] - 3s 28ms/step - loss: 0.5712 - val_loss: 0.7069
Epoch 39/43
106/106 [==============================] - 3s 29ms/step - loss: 0.5713 - val_loss: 0.7045
Epoch 40/43
106/106 [==============================] - 3s 28ms/step - loss: 0.5715 - val_loss: 0.7050
Epoch 41/43
106/106 [==============================] - 3s 28ms/step - loss: 0.5710 - val_loss: 0.7027
Epoch 42/43
106/106 [==============================] - 3s 28ms/step - loss: 0.5710 - val_loss: 0.7040
Epoch 43/43
106/106 [==============================] - 3s 28ms/step - loss: 0.5703 - val_loss: 0.7049
Execution time:  135.72730016708374
LSTM:
Mean Absolute Error: 0.5231
Root Mean Square Error: 0.7820
Mean Square Error: 0.6115

Train RMSE: 0.782
Train MSE: 0.612
Train MAE: 0.523
###########################

MODEL:  LSTM
sequence:  6h
units:  43
dropout1:  0.40519643149940265
dropout2:  0.3312343747027119
optimizer: adadelta
activationDense: tanh
epochs: 56
batchsize: 11
validation_split: 0.1
Model: &#34;sequential_28&#34;
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
lstm_56 (LSTM)               (None, 36, 43)            7740      
_________________________________________________________________
dropout_56 (Dropout)         (None, 36, 43)            0         
_________________________________________________________________
lstm_57 (LSTM)               (None, 36, 43)            14964     
_________________________________________________________________
dropout_57 (Dropout)         (None, 36, 43)            0         
_________________________________________________________________
time_distributed_28 (TimeDis (None, 36, 1)             44        
=================================================================
Total params: 22,748
Trainable params: 22,748
Non-trainable params: 0
_________________________________________________________________
Epoch 1/56
324/324 [==============================] - 8s 26ms/step - loss: 0.7094 - val_loss: 0.8032
Epoch 2/56
324/324 [==============================] - 8s 24ms/step - loss: 0.7072 - val_loss: 0.7989
Epoch 3/56
324/324 [==============================] - 8s 24ms/step - loss: 0.7051 - val_loss: 0.7945
Epoch 4/56
324/324 [==============================] - 8s 24ms/step - loss: 0.7027 - val_loss: 0.7899
Epoch 5/56
324/324 [==============================] - 8s 23ms/step - loss: 0.7004 - val_loss: 0.7851
Epoch 6/56
324/324 [==============================] - 8s 24ms/step - loss: 0.6980 - val_loss: 0.7802
Epoch 7/56
324/324 [==============================] - 8s 24ms/step - loss: 0.6955 - val_loss: 0.7752
Epoch 8/56
324/324 [==============================] - 8s 24ms/step - loss: 0.6930 - val_loss: 0.7700
Epoch 9/56
324/324 [==============================] - 8s 24ms/step - loss: 0.6903 - val_loss: 0.7646
Epoch 10/56
324/324 [==============================] - 8s 24ms/step - loss: 0.6876 - val_loss: 0.7591
Epoch 11/56
324/324 [==============================] - 8s 24ms/step - loss: 0.6848 - val_loss: 0.7533
Epoch 12/56
324/324 [==============================] - 8s 24ms/step - loss: 0.6821 - val_loss: 0.7473
Epoch 13/56
324/324 [==============================] - 8s 24ms/step - loss: 0.6790 - val_loss: 0.7411
Epoch 14/56
324/324 [==============================] - 8s 24ms/step - loss: 0.6760 - val_loss: 0.7347
Epoch 15/56
324/324 [==============================] - 8s 24ms/step - loss: 0.6730 - val_loss: 0.7280
Epoch 16/56
324/324 [==============================] - 8s 24ms/step - loss: 0.6696 - val_loss: 0.7211
Epoch 17/56
324/324 [==============================] - 8s 24ms/step - loss: 0.6663 - val_loss: 0.7140
Epoch 18/56
324/324 [==============================] - 8s 24ms/step - loss: 0.6628 - val_loss: 0.7066
Epoch 19/56
324/324 [==============================] - 8s 24ms/step - loss: 0.6593 - val_loss: 0.6989
Epoch 20/56
324/324 [==============================] - 8s 24ms/step - loss: 0.6555 - val_loss: 0.6910
Epoch 21/56
324/324 [==============================] - 8s 24ms/step - loss: 0.6518 - val_loss: 0.6827
Epoch 22/56
324/324 [==============================] - 8s 24ms/step - loss: 0.6478 - val_loss: 0.6741
Epoch 23/56
324/324 [==============================] - 8s 24ms/step - loss: 0.6439 - val_loss: 0.6652
Epoch 24/56
324/324 [==============================] - 8s 24ms/step - loss: 0.6395 - val_loss: 0.6558
Epoch 25/56
324/324 [==============================] - 8s 24ms/step - loss: 0.6351 - val_loss: 0.6461
Epoch 26/56
324/324 [==============================] - 8s 24ms/step - loss: 0.6303 - val_loss: 0.6360
Epoch 27/56
324/324 [==============================] - 8s 24ms/step - loss: 0.6255 - val_loss: 0.6256
Epoch 28/56
324/324 [==============================] - 8s 24ms/step - loss: 0.6205 - val_loss: 0.6147
Epoch 29/56
324/324 [==============================] - 8s 24ms/step - loss: 0.6152 - val_loss: 0.6036
Epoch 30/56
324/324 [==============================] - 8s 24ms/step - loss: 0.6102 - val_loss: 0.5921
Epoch 31/56
324/324 [==============================] - 8s 24ms/step - loss: 0.6047 - val_loss: 0.5804
Epoch 32/56
324/324 [==============================] - 8s 24ms/step - loss: 0.5992 - val_loss: 0.5685
Epoch 33/56
324/324 [==============================] - 8s 24ms/step - loss: 0.5939 - val_loss: 0.5566
Epoch 34/56
324/324 [==============================] - 8s 24ms/step - loss: 0.5885 - val_loss: 0.5449
Epoch 35/56
324/324 [==============================] - 8s 24ms/step - loss: 0.5835 - val_loss: 0.5334
Epoch 36/56
324/324 [==============================] - 8s 24ms/step - loss: 0.5782 - val_loss: 0.5221
Epoch 37/56
324/324 [==============================] - 8s 24ms/step - loss: 0.5734 - val_loss: 0.5111
Epoch 38/56
324/324 [==============================] - 8s 24ms/step - loss: 0.5688 - val_loss: 0.5004
Epoch 39/56
324/324 [==============================] - 8s 24ms/step - loss: 0.5643 - val_loss: 0.4900
Epoch 40/56
324/324 [==============================] - 8s 24ms/step - loss: 0.5600 - val_loss: 0.4800
Epoch 41/56
324/324 [==============================] - 8s 24ms/step - loss: 0.5563 - val_loss: 0.4703
Epoch 42/56
324/324 [==============================] - 8s 24ms/step - loss: 0.5525 - val_loss: 0.4609
Epoch 43/56
324/324 [==============================] - 8s 24ms/step - loss: 0.5491 - val_loss: 0.4517
Epoch 44/56
324/324 [==============================] - 8s 24ms/step - loss: 0.5454 - val_loss: 0.4428
Epoch 45/56
324/324 [==============================] - 8s 24ms/step - loss: 0.5423 - val_loss: 0.4342
Epoch 46/56
324/324 [==============================] - 8s 24ms/step - loss: 0.5391 - val_loss: 0.4259
Epoch 47/56
324/324 [==============================] - 8s 24ms/step - loss: 0.5364 - val_loss: 0.4178
Epoch 48/56
324/324 [==============================] - 8s 24ms/step - loss: 0.5335 - val_loss: 0.4101
Epoch 49/56
324/324 [==============================] - 8s 24ms/step - loss: 0.5309 - val_loss: 0.4027
Epoch 50/56
324/324 [==============================] - 8s 24ms/step - loss: 0.5283 - val_loss: 0.3959
Epoch 51/56
324/324 [==============================] - 8s 24ms/step - loss: 0.5263 - val_loss: 0.3896
Epoch 52/56
324/324 [==============================] - 8s 24ms/step - loss: 0.5248 - val_loss: 0.3839
Epoch 53/56
324/324 [==============================] - 8s 24ms/step - loss: 0.5225 - val_loss: 0.3787
Epoch 54/56
324/324 [==============================] - 8s 24ms/step - loss: 0.5208 - val_loss: 0.3741
Epoch 55/56
324/324 [==============================] - 8s 24ms/step - loss: 0.5198 - val_loss: 0.3699
Epoch 56/56
324/324 [==============================] - 8s 23ms/step - loss: 0.5181 - val_loss: 0.3661
Execution time:  441.71819138526917
LSTM:
Mean Absolute Error: 0.4465
Root Mean Square Error: 0.8062
Mean Square Error: 0.6500

Train RMSE: 0.806
Train MSE: 0.650
Train MAE: 0.447
###########################

MODEL:  LSTM
sequence:  6h
units:  45
dropout1:  0.11814836227952394
dropout2:  0.24325404382648977
optimizer: adadelta
activationDense: tanh
epochs: 43
batchsize: 30
validation_split: 0.2
Model: &#34;sequential_29&#34;
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
lstm_58 (LSTM)               (None, 36, 45)            8460      
_________________________________________________________________
dropout_58 (Dropout)         (None, 36, 45)            0         
_________________________________________________________________
lstm_59 (LSTM)               (None, 36, 45)            16380     
_________________________________________________________________
dropout_59 (Dropout)         (None, 36, 45)            0         
_________________________________________________________________
time_distributed_29 (TimeDis (None, 36, 1)             46        
=================================================================
Total params: 24,886
Trainable params: 24,886
Non-trainable params: 0
_________________________________________________________________
Epoch 1/43
106/106 [==============================] - 4s 36ms/step - loss: 0.7267 - val_loss: 0.7137
Epoch 2/43
106/106 [==============================] - 3s 28ms/step - loss: 0.7264 - val_loss: 0.7132
Epoch 3/43
106/106 [==============================] - 3s 27ms/step - loss: 0.7259 - val_loss: 0.7126
Epoch 4/43
106/106 [==============================] - 3s 27ms/step - loss: 0.7255 - val_loss: 0.7121
Epoch 5/43
106/106 [==============================] - 3s 27ms/step - loss: 0.7251 - val_loss: 0.7115
Epoch 6/43
106/106 [==============================] - 3s 28ms/step - loss: 0.7246 - val_loss: 0.7109
Epoch 7/43
106/106 [==============================] - 3s 27ms/step - loss: 0.7242 - val_loss: 0.7103
Epoch 8/43
106/106 [==============================] - 3s 28ms/step - loss: 0.7237 - val_loss: 0.7097
Epoch 9/43
106/106 [==============================] - 3s 27ms/step - loss: 0.7233 - val_loss: 0.7091
Epoch 10/43
106/106 [==============================] - 3s 27ms/step - loss: 0.7228 - val_loss: 0.7085
Epoch 11/43
106/106 [==============================] - 3s 29ms/step - loss: 0.7224 - val_loss: 0.7079
Epoch 12/43
106/106 [==============================] - 3s 27ms/step - loss: 0.7219 - val_loss: 0.7073
Epoch 13/43
106/106 [==============================] - 3s 27ms/step - loss: 0.7215 - val_loss: 0.7067
Epoch 14/43
106/106 [==============================] - 3s 27ms/step - loss: 0.7210 - val_loss: 0.7060
Epoch 15/43
106/106 [==============================] - 3s 27ms/step - loss: 0.7205 - val_loss: 0.7054
Epoch 16/43
106/106 [==============================] - 3s 28ms/step - loss: 0.7201 - val_loss: 0.7048
Epoch 17/43
106/106 [==============================] - 3s 28ms/step - loss: 0.7197 - val_loss: 0.7042
Epoch 18/43
106/106 [==============================] - 3s 29ms/step - loss: 0.7192 - val_loss: 0.7036
Epoch 19/43
106/106 [==============================] - 3s 28ms/step - loss: 0.7187 - val_loss: 0.7029
Epoch 20/43
106/106 [==============================] - 3s 27ms/step - loss: 0.7183 - val_loss: 0.7023
Epoch 21/43
106/106 [==============================] - 3s 27ms/step - loss: 0.7178 - val_loss: 0.7017
Epoch 22/43
106/106 [==============================] - 3s 28ms/step - loss: 0.7174 - val_loss: 0.7011
Epoch 23/43
106/106 [==============================] - 3s 27ms/step - loss: 0.7170 - val_loss: 0.7004
Epoch 24/43
106/106 [==============================] - 3s 27ms/step - loss: 0.7165 - val_loss: 0.6998
Epoch 25/43
106/106 [==============================] - 3s 27ms/step - loss: 0.7160 - val_loss: 0.6992
Epoch 26/43
106/106 [==============================] - 3s 27ms/step - loss: 0.7156 - val_loss: 0.6985
Epoch 27/43
106/106 [==============================] - 3s 28ms/step - loss: 0.7151 - val_loss: 0.6979
Epoch 28/43
106/106 [==============================] - 3s 28ms/step - loss: 0.7147 - val_loss: 0.6972
Epoch 29/43
106/106 [==============================] - 3s 27ms/step - loss: 0.7142 - val_loss: 0.6966
Epoch 30/43
106/106 [==============================] - 3s 27ms/step - loss: 0.7138 - val_loss: 0.6959
Epoch 31/43
106/106 [==============================] - 3s 27ms/step - loss: 0.7133 - val_loss: 0.6953
Epoch 32/43
106/106 [==============================] - 3s 27ms/step - loss: 0.7128 - val_loss: 0.6946
Epoch 33/43
106/106 [==============================] - 3s 28ms/step - loss: 0.7124 - val_loss: 0.6940
Epoch 34/43
106/106 [==============================] - 3s 27ms/step - loss: 0.7119 - val_loss: 0.6933
Epoch 35/43
106/106 [==============================] - 3s 27ms/step - loss: 0.7114 - val_loss: 0.6927
Epoch 36/43
106/106 [==============================] - 3s 27ms/step - loss: 0.7109 - val_loss: 0.6920
Epoch 37/43
106/106 [==============================] - 3s 27ms/step - loss: 0.7105 - val_loss: 0.6913
Epoch 38/43
106/106 [==============================] - 3s 29ms/step - loss: 0.7100 - val_loss: 0.6906
Epoch 39/43
106/106 [==============================] - 3s 28ms/step - loss: 0.7095 - val_loss: 0.6900
Epoch 40/43
106/106 [==============================] - 3s 27ms/step - loss: 0.7090 - val_loss: 0.6893
Epoch 41/43
106/106 [==============================] - 3s 27ms/step - loss: 0.7086 - val_loss: 0.6886
Epoch 42/43
106/106 [==============================] - 3s 27ms/step - loss: 0.7080 - val_loss: 0.6879
Epoch 43/43
106/106 [==============================] - 3s 28ms/step - loss: 0.7076 - val_loss: 0.6872
Execution time:  132.74413561820984
LSTM:
Mean Absolute Error: 0.6987
Root Mean Square Error: 0.9866
Mean Square Error: 0.9733

Train RMSE: 0.987
Train MSE: 0.973
Train MAE: 0.699
###########################

MODEL:  LSTM
sequence:  6h
units:  43
dropout1:  0.40519643149940265
dropout2:  0.3312343747027119
optimizer: adadelta
activationDense: sigmoid
epochs: 56
batchsize: 11
validation_split: 0.1
Model: &#34;sequential_30&#34;
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
lstm_60 (LSTM)               (None, 36, 43)            7740      
_________________________________________________________________
dropout_60 (Dropout)         (None, 36, 43)            0         
_________________________________________________________________
lstm_61 (LSTM)               (None, 36, 43)            14964     
_________________________________________________________________
dropout_61 (Dropout)         (None, 36, 43)            0         
_________________________________________________________________
time_distributed_30 (TimeDis (None, 36, 1)             44        
=================================================================
Total params: 22,748
Trainable params: 22,748
Non-trainable params: 0
_________________________________________________________________
Epoch 1/56
324/324 [==============================] - 9s 28ms/step - loss: 0.8979 - val_loss: 1.3064
Epoch 2/56
324/324 [==============================] - 8s 24ms/step - loss: 0.8975 - val_loss: 1.3056
Epoch 3/56
324/324 [==============================] - 8s 24ms/step - loss: 0.8971 - val_loss: 1.3047
Epoch 4/56
324/324 [==============================] - 8s 24ms/step - loss: 0.8967 - val_loss: 1.3038
Epoch 5/56
324/324 [==============================] - 8s 24ms/step - loss: 0.8962 - val_loss: 1.3029
Epoch 6/56
324/324 [==============================] - 8s 24ms/step - loss: 0.8958 - val_loss: 1.3020
Epoch 7/56
324/324 [==============================] - 8s 24ms/step - loss: 0.8952 - val_loss: 1.3010
Epoch 8/56
324/324 [==============================] - 8s 24ms/step - loss: 0.8948 - val_loss: 1.3000
Epoch 9/56
324/324 [==============================] - 8s 24ms/step - loss: 0.8943 - val_loss: 1.2990
Epoch 10/56
324/324 [==============================] - 8s 24ms/step - loss: 0.8938 - val_loss: 1.2979
Epoch 11/56
324/324 [==============================] - 8s 24ms/step - loss: 0.8932 - val_loss: 1.2969
Epoch 12/56
324/324 [==============================] - 8s 24ms/step - loss: 0.8927 - val_loss: 1.2958
Epoch 13/56
324/324 [==============================] - 8s 24ms/step - loss: 0.8922 - val_loss: 1.2947
Epoch 14/56
324/324 [==============================] - 8s 24ms/step - loss: 0.8916 - val_loss: 1.2935
Epoch 15/56
324/324 [==============================] - 8s 24ms/step - loss: 0.8910 - val_loss: 1.2924
Epoch 16/56
324/324 [==============================] - 8s 24ms/step - loss: 0.8905 - val_loss: 1.2912
Epoch 17/56
324/324 [==============================] - 8s 24ms/step - loss: 0.8898 - val_loss: 1.2900
Epoch 18/56
324/324 [==============================] - 8s 24ms/step - loss: 0.8892 - val_loss: 1.2887
Epoch 19/56
324/324 [==============================] - 8s 24ms/step - loss: 0.8886 - val_loss: 1.2875
Epoch 20/56
324/324 [==============================] - 8s 24ms/step - loss: 0.8880 - val_loss: 1.2862
Epoch 21/56
324/324 [==============================] - 8s 24ms/step - loss: 0.8873 - val_loss: 1.2849
Epoch 22/56
324/324 [==============================] - 8s 24ms/step - loss: 0.8866 - val_loss: 1.2835
Epoch 23/56
324/324 [==============================] - 8s 24ms/step - loss: 0.8860 - val_loss: 1.2822
Epoch 24/56
324/324 [==============================] - 8s 24ms/step - loss: 0.8852 - val_loss: 1.2808
Epoch 25/56
324/324 [==============================] - 8s 24ms/step - loss: 0.8846 - val_loss: 1.2793
Epoch 26/56
324/324 [==============================] - 8s 24ms/step - loss: 0.8838 - val_loss: 1.2778
Epoch 27/56
324/324 [==============================] - 8s 24ms/step - loss: 0.8830 - val_loss: 1.2763
Epoch 28/56
324/324 [==============================] - 8s 24ms/step - loss: 0.8823 - val_loss: 1.2748
Epoch 29/56
324/324 [==============================] - 8s 24ms/step - loss: 0.8815 - val_loss: 1.2732
Epoch 30/56
324/324 [==============================] - 8s 24ms/step - loss: 0.8806 - val_loss: 1.2716
Epoch 31/56
324/324 [==============================] - 8s 24ms/step - loss: 0.8798 - val_loss: 1.2699
Epoch 32/56
324/324 [==============================] - 8s 24ms/step - loss: 0.8789 - val_loss: 1.2682
Epoch 33/56
324/324 [==============================] - 8s 24ms/step - loss: 0.8780 - val_loss: 1.2665
Epoch 34/56
324/324 [==============================] - 8s 24ms/step - loss: 0.8771 - val_loss: 1.2647
Epoch 35/56
324/324 [==============================] - 8s 24ms/step - loss: 0.8763 - val_loss: 1.2628
Epoch 36/56
324/324 [==============================] - 8s 24ms/step - loss: 0.8752 - val_loss: 1.2609
Epoch 37/56
324/324 [==============================] - 8s 24ms/step - loss: 0.8743 - val_loss: 1.2590
Epoch 38/56
324/324 [==============================] - 8s 24ms/step - loss: 0.8732 - val_loss: 1.2570
Epoch 39/56
324/324 [==============================] - 8s 24ms/step - loss: 0.8722 - val_loss: 1.2550
Epoch 40/56
324/324 [==============================] - 8s 24ms/step - loss: 0.8710 - val_loss: 1.2529
Epoch 41/56
324/324 [==============================] - 8s 24ms/step - loss: 0.8700 - val_loss: 1.2508
Epoch 42/56
324/324 [==============================] - 8s 24ms/step - loss: 0.8688 - val_loss: 1.2486
Epoch 43/56
324/324 [==============================] - 8s 24ms/step - loss: 0.8676 - val_loss: 1.2464
Epoch 44/56
324/324 [==============================] - 8s 24ms/step - loss: 0.8664 - val_loss: 1.2441
Epoch 45/56
324/324 [==============================] - 8s 24ms/step - loss: 0.8652 - val_loss: 1.2418
Epoch 46/56
324/324 [==============================] - 8s 24ms/step - loss: 0.8639 - val_loss: 1.2394
Epoch 47/56
324/324 [==============================] - 8s 24ms/step - loss: 0.8627 - val_loss: 1.2369
Epoch 48/56
324/324 [==============================] - 8s 24ms/step - loss: 0.8613 - val_loss: 1.2344
Epoch 49/56
324/324 [==============================] - 8s 24ms/step - loss: 0.8600 - val_loss: 1.2319
Epoch 50/56
324/324 [==============================] - 8s 24ms/step - loss: 0.8585 - val_loss: 1.2293
Epoch 51/56
324/324 [==============================] - 8s 24ms/step - loss: 0.8571 - val_loss: 1.2266
Epoch 52/56
324/324 [==============================] - 8s 24ms/step - loss: 0.8557 - val_loss: 1.2239
Epoch 53/56
324/324 [==============================] - 8s 24ms/step - loss: 0.8542 - val_loss: 1.2212
Epoch 54/56
324/324 [==============================] - 8s 24ms/step - loss: 0.8525 - val_loss: 1.2183
Epoch 55/56
324/324 [==============================] - 8s 24ms/step - loss: 0.8510 - val_loss: 1.2154
Epoch 56/56
324/324 [==============================] - 8s 24ms/step - loss: 0.8494 - val_loss: 1.2125
Execution time:  443.73863768577576
LSTM:
Mean Absolute Error: 0.8735
Root Mean Square Error: 1.0650
Mean Square Error: 1.1343

Train RMSE: 1.065
Train MSE: 1.134
Train MAE: 0.873
###########################

MODEL:  LSTM
sequence:  6h
units:  45
dropout1:  0.11814836227952394
dropout2:  0.24325404382648977
optimizer: adadelta
activationDense: sigmoid
epochs: 43
batchsize: 30
validation_split: 0.2
Model: &#34;sequential_31&#34;
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
lstm_62 (LSTM)               (None, 36, 45)            8460      
_________________________________________________________________
dropout_62 (Dropout)         (None, 36, 45)            0         
_________________________________________________________________
lstm_63 (LSTM)               (None, 36, 45)            16380     
_________________________________________________________________
dropout_63 (Dropout)         (None, 36, 45)            0         
_________________________________________________________________
time_distributed_31 (TimeDis (None, 36, 1)             46        
=================================================================
Total params: 24,886
Trainable params: 24,886
Non-trainable params: 0
_________________________________________________________________
Epoch 1/43
106/106 [==============================] - 4s 36ms/step - loss: 0.8899 - val_loss: 1.1449
Epoch 2/43
106/106 [==============================] - 3s 28ms/step - loss: 0.8898 - val_loss: 1.1448
Epoch 3/43
106/106 [==============================] - 3s 28ms/step - loss: 0.8897 - val_loss: 1.1446
Epoch 4/43
106/106 [==============================] - 3s 29ms/step - loss: 0.8896 - val_loss: 1.1444
Epoch 5/43
106/106 [==============================] - 3s 28ms/step - loss: 0.8894 - val_loss: 1.1442
Epoch 6/43
106/106 [==============================] - 3s 28ms/step - loss: 0.8893 - val_loss: 1.1440
Epoch 7/43
106/106 [==============================] - 3s 28ms/step - loss: 0.8892 - val_loss: 1.1438
Epoch 8/43
106/106 [==============================] - 3s 28ms/step - loss: 0.8890 - val_loss: 1.1435
Epoch 9/43
106/106 [==============================] - 3s 29ms/step - loss: 0.8889 - val_loss: 1.1433
Epoch 10/43
106/106 [==============================] - 3s 28ms/step - loss: 0.8888 - val_loss: 1.1431
Epoch 11/43
106/106 [==============================] - 3s 28ms/step - loss: 0.8886 - val_loss: 1.1429
Epoch 12/43
106/106 [==============================] - 3s 28ms/step - loss: 0.8885 - val_loss: 1.1427
Epoch 13/43
106/106 [==============================] - 3s 28ms/step - loss: 0.8883 - val_loss: 1.1424
Epoch 14/43
106/106 [==============================] - 3s 29ms/step - loss: 0.8882 - val_loss: 1.1422
Epoch 15/43
106/106 [==============================] - 3s 29ms/step - loss: 0.8881 - val_loss: 1.1420
Epoch 16/43
106/106 [==============================] - 3s 28ms/step - loss: 0.8879 - val_loss: 1.1418
Epoch 17/43
106/106 [==============================] - 3s 28ms/step - loss: 0.8878 - val_loss: 1.1415
Epoch 18/43
106/106 [==============================] - 3s 28ms/step - loss: 0.8876 - val_loss: 1.1413
Epoch 19/43
106/106 [==============================] - 3s 28ms/step - loss: 0.8875 - val_loss: 1.1411
Epoch 20/43
106/106 [==============================] - 3s 29ms/step - loss: 0.8873 - val_loss: 1.1408
Epoch 21/43
106/106 [==============================] - 3s 28ms/step - loss: 0.8872 - val_loss: 1.1406
Epoch 22/43
106/106 [==============================] - 3s 28ms/step - loss: 0.8870 - val_loss: 1.1403
Epoch 23/43
106/106 [==============================] - 3s 28ms/step - loss: 0.8869 - val_loss: 1.1401
Epoch 24/43
106/106 [==============================] - 3s 28ms/step - loss: 0.8867 - val_loss: 1.1399
Epoch 25/43
106/106 [==============================] - 3s 29ms/step - loss: 0.8866 - val_loss: 1.1396
Epoch 26/43
106/106 [==============================] - 4s 34ms/step - loss: 0.8864 - val_loss: 1.1394
Epoch 27/43
106/106 [==============================] - 4s 38ms/step - loss: 0.8863 - val_loss: 1.1391
Epoch 28/43
106/106 [==============================] - 3s 32ms/step - loss: 0.8861 - val_loss: 1.1389
Epoch 29/43
106/106 [==============================] - 3s 28ms/step - loss: 0.8860 - val_loss: 1.1386
Epoch 30/43
106/106 [==============================] - 3s 33ms/step - loss: 0.8858 - val_loss: 1.1384
Epoch 31/43
106/106 [==============================] - 3s 28ms/step - loss: 0.8857 - val_loss: 1.1381
Epoch 32/43
106/106 [==============================] - 3s 27ms/step - loss: 0.8855 - val_loss: 1.1379
Epoch 33/43
106/106 [==============================] - 3s 27ms/step - loss: 0.8853 - val_loss: 1.1376
Epoch 34/43
106/106 [==============================] - 3s 28ms/step - loss: 0.8852 - val_loss: 1.1373
Epoch 35/43
106/106 [==============================] - 3s 31ms/step - loss: 0.8850 - val_loss: 1.1371
Epoch 36/43
106/106 [==============================] - 3s 27ms/step - loss: 0.8849 - val_loss: 1.1368
Epoch 37/43
106/106 [==============================] - 3s 27ms/step - loss: 0.8847 - val_loss: 1.1365
Epoch 38/43
106/106 [==============================] - 3s 27ms/step - loss: 0.8845 - val_loss: 1.1363
Epoch 39/43
106/106 [==============================] - 3s 27ms/step - loss: 0.8844 - val_loss: 1.1360
Epoch 40/43
106/106 [==============================] - 3s 28ms/step - loss: 0.8842 - val_loss: 1.1357
Epoch 41/43
106/106 [==============================] - 3s 28ms/step - loss: 0.8840 - val_loss: 1.1355
Epoch 42/43
106/106 [==============================] - 3s 27ms/step - loss: 0.8839 - val_loss: 1.1352
Epoch 43/43
106/106 [==============================] - 3s 28ms/step - loss: 0.8837 - val_loss: 1.1349
Execution time:  137.9662766456604
LSTM:
Mean Absolute Error: 0.9291
Root Mean Square Error: 1.1166
Mean Square Error: 1.2469

Train RMSE: 1.117
Train MSE: 1.247
Train MAE: 0.929
###########################

MODEL:  LSTM
sequence:  6h
units:  43
dropout1:  0.40519643149940265
dropout2:  0.3312343747027119
optimizer: adamax
activationDense: tanh
epochs: 56
batchsize: 11
validation_split: 0.1
Model: &#34;sequential_32&#34;
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
lstm_64 (LSTM)               (None, 36, 43)            7740      
_________________________________________________________________
dropout_64 (Dropout)         (None, 36, 43)            0         
_________________________________________________________________
lstm_65 (LSTM)               (None, 36, 43)            14964     
_________________________________________________________________
dropout_65 (Dropout)         (None, 36, 43)            0         
_________________________________________________________________
time_distributed_32 (TimeDis (None, 36, 1)             44        
=================================================================
Total params: 22,748
Trainable params: 22,748
Non-trainable params: 0
_________________________________________________________________
Epoch 1/56
324/324 [==============================] - 8s 25ms/step - loss: 0.5148 - val_loss: 0.3561
Epoch 2/56
324/324 [==============================] - 7s 22ms/step - loss: 0.4569 - val_loss: 0.3214
Epoch 3/56
324/324 [==============================] - 7s 23ms/step - loss: 0.4420 - val_loss: 0.2968
Epoch 4/56
324/324 [==============================] - 7s 22ms/step - loss: 0.4327 - val_loss: 0.2815
Epoch 5/56
324/324 [==============================] - 7s 23ms/step - loss: 0.4277 - val_loss: 0.2739
Epoch 6/56
324/324 [==============================] - 7s 22ms/step - loss: 0.4242 - val_loss: 0.2670
Epoch 7/56
324/324 [==============================] - 7s 23ms/step - loss: 0.4208 - val_loss: 0.2635
Epoch 8/56
324/324 [==============================] - 7s 22ms/step - loss: 0.4187 - val_loss: 0.2581
Epoch 9/56
324/324 [==============================] - 7s 23ms/step - loss: 0.4163 - val_loss: 0.2540
Epoch 10/56
324/324 [==============================] - 7s 22ms/step - loss: 0.4152 - val_loss: 0.2509
Epoch 11/56
324/324 [==============================] - 7s 23ms/step - loss: 0.4138 - val_loss: 0.2495
Epoch 12/56
324/324 [==============================] - 7s 22ms/step - loss: 0.4125 - val_loss: 0.2466
Epoch 13/56
324/324 [==============================] - 7s 22ms/step - loss: 0.4111 - val_loss: 0.2467
Epoch 14/56
324/324 [==============================] - 7s 22ms/step - loss: 0.4102 - val_loss: 0.2417
Epoch 15/56
324/324 [==============================] - 7s 22ms/step - loss: 0.4095 - val_loss: 0.2420
Epoch 16/56
324/324 [==============================] - 8s 24ms/step - loss: 0.4089 - val_loss: 0.2385
Epoch 17/56
324/324 [==============================] - 7s 22ms/step - loss: 0.4080 - val_loss: 0.2375
Epoch 18/56
324/324 [==============================] - 7s 23ms/step - loss: 0.4075 - val_loss: 0.2378
Epoch 19/56
324/324 [==============================] - 7s 22ms/step - loss: 0.4069 - val_loss: 0.2362
Epoch 20/56
324/324 [==============================] - 7s 23ms/step - loss: 0.4067 - val_loss: 0.2333
Epoch 21/56
324/324 [==============================] - 7s 22ms/step - loss: 0.4064 - val_loss: 0.2336
Epoch 22/56
324/324 [==============================] - 7s 23ms/step - loss: 0.4058 - val_loss: 0.2315
Epoch 23/56
324/324 [==============================] - 7s 22ms/step - loss: 0.4060 - val_loss: 0.2329
Epoch 24/56
324/324 [==============================] - 7s 22ms/step - loss: 0.4058 - val_loss: 0.2311
Epoch 25/56
324/324 [==============================] - 7s 22ms/step - loss: 0.4049 - val_loss: 0.2310
Epoch 26/56
324/324 [==============================] - 7s 22ms/step - loss: 0.4048 - val_loss: 0.2300
Epoch 27/56
324/324 [==============================] - 7s 23ms/step - loss: 0.4045 - val_loss: 0.2284
Epoch 28/56
324/324 [==============================] - 7s 22ms/step - loss: 0.4046 - val_loss: 0.2294
Epoch 29/56
324/324 [==============================] - 7s 23ms/step - loss: 0.4045 - val_loss: 0.2291
Epoch 30/56
324/324 [==============================] - 7s 22ms/step - loss: 0.4046 - val_loss: 0.2276
Epoch 31/56
324/324 [==============================] - 7s 23ms/step - loss: 0.4039 - val_loss: 0.2279
Epoch 32/56
324/324 [==============================] - 7s 22ms/step - loss: 0.4039 - val_loss: 0.2271
Epoch 33/56
324/324 [==============================] - 8s 24ms/step - loss: 0.4040 - val_loss: 0.2269
Epoch 34/56
324/324 [==============================] - 8s 25ms/step - loss: 0.4037 - val_loss: 0.2272
Epoch 35/56
324/324 [==============================] - 7s 23ms/step - loss: 0.4035 - val_loss: 0.2269
Epoch 36/56
324/324 [==============================] - 7s 23ms/step - loss: 0.4032 - val_loss: 0.2260
Epoch 37/56
324/324 [==============================] - 7s 22ms/step - loss: 0.4034 - val_loss: 0.2262
Epoch 38/56
324/324 [==============================] - 7s 22ms/step - loss: 0.4033 - val_loss: 0.2247
Epoch 39/56
324/324 [==============================] - 7s 22ms/step - loss: 0.4032 - val_loss: 0.2260
Epoch 40/56
324/324 [==============================] - 7s 23ms/step - loss: 0.4030 - val_loss: 0.2252
Epoch 41/56
324/324 [==============================] - 7s 22ms/step - loss: 0.4027 - val_loss: 0.2241
Epoch 42/56
324/324 [==============================] - 7s 23ms/step - loss: 0.4030 - val_loss: 0.2235
Epoch 43/56
324/324 [==============================] - 7s 22ms/step - loss: 0.4029 - val_loss: 0.2244
Epoch 44/56
324/324 [==============================] - 7s 23ms/step - loss: 0.4028 - val_loss: 0.2228
Epoch 45/56
324/324 [==============================] - 7s 22ms/step - loss: 0.4023 - val_loss: 0.2218
Epoch 46/56
324/324 [==============================] - 7s 23ms/step - loss: 0.4022 - val_loss: 0.2226
Epoch 47/56
324/324 [==============================] - 7s 22ms/step - loss: 0.4024 - val_loss: 0.2228
Epoch 48/56
324/324 [==============================] - 7s 22ms/step - loss: 0.4019 - val_loss: 0.2233
Epoch 49/56
324/324 [==============================] - 7s 22ms/step - loss: 0.4020 - val_loss: 0.2210
Epoch 50/56
324/324 [==============================] - 7s 22ms/step - loss: 0.4015 - val_loss: 0.2218
Epoch 51/56
324/324 [==============================] - 7s 23ms/step - loss: 0.4016 - val_loss: 0.2212
Epoch 52/56
324/324 [==============================] - 7s 22ms/step - loss: 0.4013 - val_loss: 0.2214
Epoch 53/56
324/324 [==============================] - 7s 23ms/step - loss: 0.4011 - val_loss: 0.2199
Epoch 54/56
324/324 [==============================] - 7s 22ms/step - loss: 0.4013 - val_loss: 0.2208
Epoch 55/56
324/324 [==============================] - 7s 23ms/step - loss: 0.4010 - val_loss: 0.2204
Epoch 56/56
324/324 [==============================] - 7s 22ms/step - loss: 0.4006 - val_loss: 0.2183
Execution time:  415.0670449733734
LSTM:
Mean Absolute Error: 0.2028
Root Mean Square Error: 0.6027
Mean Square Error: 0.3632

Train RMSE: 0.603
Train MSE: 0.363
Train MAE: 0.203
###########################

MODEL:  LSTM
sequence:  6h
units:  45
dropout1:  0.11814836227952394
dropout2:  0.24325404382648977
optimizer: adamax
activationDense: tanh
epochs: 43
batchsize: 30
validation_split: 0.2
Model: &#34;sequential_33&#34;
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
lstm_66 (LSTM)               (None, 36, 45)            8460      
_________________________________________________________________
dropout_66 (Dropout)         (None, 36, 45)            0         
_________________________________________________________________
lstm_67 (LSTM)               (None, 36, 45)            16380     
_________________________________________________________________
dropout_67 (Dropout)         (None, 36, 45)            0         
_________________________________________________________________
time_distributed_33 (TimeDis (None, 36, 1)             46        
=================================================================
Total params: 24,886
Trainable params: 24,886
Non-trainable params: 0
_________________________________________________________________
Epoch 1/43
106/106 [==============================] - 4s 35ms/step - loss: 0.5650 - val_loss: 0.4089
Epoch 2/43
106/106 [==============================] - 3s 26ms/step - loss: 0.4800 - val_loss: 0.3886
Epoch 3/43
106/106 [==============================] - 3s 26ms/step - loss: 0.4642 - val_loss: 0.3735
Epoch 4/43
106/106 [==============================] - 3s 26ms/step - loss: 0.4525 - val_loss: 0.3637
Epoch 5/43
106/106 [==============================] - 3s 27ms/step - loss: 0.4440 - val_loss: 0.3566
Epoch 6/43
106/106 [==============================] - 3s 26ms/step - loss: 0.4372 - val_loss: 0.3508
Epoch 7/43
106/106 [==============================] - 3s 26ms/step - loss: 0.4324 - val_loss: 0.3464
Epoch 8/43
106/106 [==============================] - 3s 26ms/step - loss: 0.4274 - val_loss: 0.3431
Epoch 9/43
106/106 [==============================] - 3s 26ms/step - loss: 0.4242 - val_loss: 0.3406
Epoch 10/43
106/106 [==============================] - 3s 26ms/step - loss: 0.4216 - val_loss: 0.3385
Epoch 11/43
106/106 [==============================] - 3s 26ms/step - loss: 0.4190 - val_loss: 0.3367
Epoch 12/43
106/106 [==============================] - 3s 26ms/step - loss: 0.4168 - val_loss: 0.3352
Epoch 13/43
106/106 [==============================] - 3s 26ms/step - loss: 0.4152 - val_loss: 0.3336
Epoch 14/43
106/106 [==============================] - 3s 26ms/step - loss: 0.4135 - val_loss: 0.3326
Epoch 15/43
106/106 [==============================] - 3s 26ms/step - loss: 0.4122 - val_loss: 0.3314
Epoch 16/43
106/106 [==============================] - 3s 27ms/step - loss: 0.4107 - val_loss: 0.3304
Epoch 17/43
106/106 [==============================] - 3s 26ms/step - loss: 0.4096 - val_loss: 0.3295
Epoch 18/43
106/106 [==============================] - 3s 26ms/step - loss: 0.4086 - val_loss: 0.3287
Epoch 19/43
106/106 [==============================] - 3s 26ms/step - loss: 0.4075 - val_loss: 0.3280
Epoch 20/43
106/106 [==============================] - 3s 26ms/step - loss: 0.4064 - val_loss: 0.3268
Epoch 21/43
106/106 [==============================] - 3s 26ms/step - loss: 0.4058 - val_loss: 0.3261
Epoch 22/43
106/106 [==============================] - 3s 27ms/step - loss: 0.4047 - val_loss: 0.3254
Epoch 23/43
106/106 [==============================] - 3s 26ms/step - loss: 0.4040 - val_loss: 0.3247
Epoch 24/43
106/106 [==============================] - 3s 26ms/step - loss: 0.4034 - val_loss: 0.3240
Epoch 25/43
106/106 [==============================] - 3s 27ms/step - loss: 0.4023 - val_loss: 0.3235
Epoch 26/43
106/106 [==============================] - 3s 26ms/step - loss: 0.4021 - val_loss: 0.3230
Epoch 27/43
106/106 [==============================] - 3s 26ms/step - loss: 0.4016 - val_loss: 0.3226
Epoch 28/43
106/106 [==============================] - 3s 27ms/step - loss: 0.4010 - val_loss: 0.3221
Epoch 29/43
106/106 [==============================] - 3s 26ms/step - loss: 0.4004 - val_loss: 0.3217
Epoch 30/43
106/106 [==============================] - 3s 27ms/step - loss: 0.4000 - val_loss: 0.3213
Epoch 31/43
106/106 [==============================] - 3s 26ms/step - loss: 0.3996 - val_loss: 0.3210
Epoch 32/43
106/106 [==============================] - 3s 26ms/step - loss: 0.3990 - val_loss: 0.3206
Epoch 33/43
106/106 [==============================] - 3s 26ms/step - loss: 0.3986 - val_loss: 0.3203
Epoch 34/43
106/106 [==============================] - 3s 26ms/step - loss: 0.3981 - val_loss: 0.3200
Epoch 35/43
106/106 [==============================] - 3s 26ms/step - loss: 0.3979 - val_loss: 0.3198
Epoch 36/43
106/106 [==============================] - 3s 26ms/step - loss: 0.3973 - val_loss: 0.3195
Epoch 37/43
106/106 [==============================] - 3s 26ms/step - loss: 0.3970 - val_loss: 0.3194
Epoch 38/43
106/106 [==============================] - 3s 26ms/step - loss: 0.3968 - val_loss: 0.3192
Epoch 39/43
106/106 [==============================] - 3s 27ms/step - loss: 0.3964 - val_loss: 0.3191
Epoch 40/43
106/106 [==============================] - 3s 26ms/step - loss: 0.3961 - val_loss: 0.3190
Epoch 41/43
106/106 [==============================] - 3s 26ms/step - loss: 0.3961 - val_loss: 0.3187
Epoch 42/43
106/106 [==============================] - 3s 26ms/step - loss: 0.3959 - val_loss: 0.3187
Epoch 43/43
106/106 [==============================] - 3s 27ms/step - loss: 0.3953 - val_loss: 0.3185
Execution time:  127.3875629901886
LSTM:
Mean Absolute Error: 0.2071
Root Mean Square Error: 0.5907
Mean Square Error: 0.3490

Train RMSE: 0.591
Train MSE: 0.349
Train MAE: 0.207
###########################

MODEL:  LSTM
sequence:  6h
units:  43
dropout1:  0.40519643149940265
dropout2:  0.3312343747027119
optimizer: adamax
activationDense: sigmoid
epochs: 56
batchsize: 11
validation_split: 0.1
Model: &#34;sequential_34&#34;
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
lstm_68 (LSTM)               (None, 36, 43)            7740      
_________________________________________________________________
dropout_68 (Dropout)         (None, 36, 43)            0         
_________________________________________________________________
lstm_69 (LSTM)               (None, 36, 43)            14964     
_________________________________________________________________
dropout_69 (Dropout)         (None, 36, 43)            0         
_________________________________________________________________
time_distributed_34 (TimeDis (None, 36, 1)             44        
=================================================================
Total params: 22,748
Trainable params: 22,748
Non-trainable params: 0
_________________________________________________________________
Epoch 1/56
324/324 [==============================] - 8s 25ms/step - loss: 0.7140 - val_loss: 0.8485
Epoch 2/56
324/324 [==============================] - 7s 23ms/step - loss: 0.6380 - val_loss: 0.8307
Epoch 3/56
324/324 [==============================] - 7s 22ms/step - loss: 0.6243 - val_loss: 0.8233
Epoch 4/56
324/324 [==============================] - 7s 23ms/step - loss: 0.6142 - val_loss: 0.8191
Epoch 5/56
324/324 [==============================] - 7s 22ms/step - loss: 0.6059 - val_loss: 0.8162
Epoch 6/56
324/324 [==============================] - 7s 23ms/step - loss: 0.6002 - val_loss: 0.8139
Epoch 7/56
324/324 [==============================] - 7s 23ms/step - loss: 0.5968 - val_loss: 0.8123
Epoch 8/56
324/324 [==============================] - 7s 22ms/step - loss: 0.5943 - val_loss: 0.8111
Epoch 9/56
324/324 [==============================] - 7s 23ms/step - loss: 0.5924 - val_loss: 0.8100
Epoch 10/56
324/324 [==============================] - 7s 22ms/step - loss: 0.5907 - val_loss: 0.8092
Epoch 11/56
324/324 [==============================] - 7s 23ms/step - loss: 0.5895 - val_loss: 0.8085
Epoch 12/56
324/324 [==============================] - 7s 22ms/step - loss: 0.5884 - val_loss: 0.8079
Epoch 13/56
324/324 [==============================] - 7s 23ms/step - loss: 0.5870 - val_loss: 0.8074
Epoch 14/56
324/324 [==============================] - 7s 22ms/step - loss: 0.5860 - val_loss: 0.8070
Epoch 15/56
324/324 [==============================] - 7s 23ms/step - loss: 0.5853 - val_loss: 0.8067
Epoch 16/56
324/324 [==============================] - 7s 22ms/step - loss: 0.5847 - val_loss: 0.8064
Epoch 17/56
324/324 [==============================] - 7s 23ms/step - loss: 0.5839 - val_loss: 0.8062
Epoch 18/56
324/324 [==============================] - 7s 22ms/step - loss: 0.5832 - val_loss: 0.8060
Epoch 19/56
324/324 [==============================] - 7s 22ms/step - loss: 0.5827 - val_loss: 0.8058
Epoch 20/56
324/324 [==============================] - 7s 23ms/step - loss: 0.5821 - val_loss: 0.8057
Epoch 21/56
324/324 [==============================] - 7s 22ms/step - loss: 0.5818 - val_loss: 0.8056
Epoch 22/56
324/324 [==============================] - 7s 23ms/step - loss: 0.5814 - val_loss: 0.8055
Epoch 23/56
324/324 [==============================] - 7s 22ms/step - loss: 0.5810 - val_loss: 0.8054
Epoch 24/56
324/324 [==============================] - 7s 23ms/step - loss: 0.5809 - val_loss: 0.8054
Epoch 25/56
324/324 [==============================] - 7s 22ms/step - loss: 0.5804 - val_loss: 0.8053
Epoch 26/56
324/324 [==============================] - 7s 23ms/step - loss: 0.5804 - val_loss: 0.8053
Epoch 27/56
324/324 [==============================] - 7s 22ms/step - loss: 0.5801 - val_loss: 0.8053
Epoch 28/56
324/324 [==============================] - 7s 22ms/step - loss: 0.5797 - val_loss: 0.8052
Epoch 29/56
324/324 [==============================] - 7s 22ms/step - loss: 0.5795 - val_loss: 0.8052
Epoch 30/56
324/324 [==============================] - 7s 22ms/step - loss: 0.5792 - val_loss: 0.8052
Epoch 31/56
324/324 [==============================] - 7s 23ms/step - loss: 0.5792 - val_loss: 0.8051
Epoch 32/56
324/324 [==============================] - 7s 22ms/step - loss: 0.5790 - val_loss: 0.8051
Epoch 33/56
324/324 [==============================] - 7s 23ms/step - loss: 0.5791 - val_loss: 0.8051
Epoch 34/56
324/324 [==============================] - 7s 22ms/step - loss: 0.5785 - val_loss: 0.8051
Epoch 35/56
324/324 [==============================] - 7s 22ms/step - loss: 0.5788 - val_loss: 0.8051
Epoch 36/56
324/324 [==============================] - 7s 22ms/step - loss: 0.5785 - val_loss: 0.8051
Epoch 37/56
324/324 [==============================] - 7s 23ms/step - loss: 0.5787 - val_loss: 0.8051
Epoch 38/56
324/324 [==============================] - 7s 22ms/step - loss: 0.5783 - val_loss: 0.8051
Epoch 39/56
324/324 [==============================] - 7s 22ms/step - loss: 0.5785 - val_loss: 0.8051
Epoch 40/56
324/324 [==============================] - 7s 22ms/step - loss: 0.5779 - val_loss: 0.8050
Epoch 41/56
324/324 [==============================] - 7s 22ms/step - loss: 0.5782 - val_loss: 0.8050
Epoch 42/56
324/324 [==============================] - 7s 23ms/step - loss: 0.5780 - val_loss: 0.8050
Epoch 43/56
324/324 [==============================] - 7s 22ms/step - loss: 0.5779 - val_loss: 0.8050
Epoch 44/56
324/324 [==============================] - 7s 23ms/step - loss: 0.5777 - val_loss: 0.8050
Epoch 45/56
324/324 [==============================] - 7s 22ms/step - loss: 0.5776 - val_loss: 0.8050
Epoch 46/56
324/324 [==============================] - 7s 22ms/step - loss: 0.5775 - val_loss: 0.8050
Epoch 47/56
324/324 [==============================] - 7s 22ms/step - loss: 0.5774 - val_loss: 0.8050
Epoch 48/56
324/324 [==============================] - 7s 23ms/step - loss: 0.5775 - val_loss: 0.8050
Epoch 49/56
324/324 [==============================] - 7s 22ms/step - loss: 0.5774 - val_loss: 0.8050
Epoch 50/56
324/324 [==============================] - 7s 22ms/step - loss: 0.5775 - val_loss: 0.8050
Epoch 51/56
324/324 [==============================] - 7s 22ms/step - loss: 0.5772 - val_loss: 0.8050
Epoch 52/56
324/324 [==============================] - 7s 22ms/step - loss: 0.5770 - val_loss: 0.8050
Epoch 53/56
324/324 [==============================] - 7s 23ms/step - loss: 0.5769 - val_loss: 0.8050
Epoch 54/56
324/324 [==============================] - 7s 22ms/step - loss: 0.5771 - val_loss: 0.8050
Epoch 55/56
324/324 [==============================] - 7s 23ms/step - loss: 0.5766 - val_loss: 0.8050
Epoch 56/56
324/324 [==============================] - 7s 22ms/step - loss: 0.5771 - val_loss: 0.8050
Execution time:  414.16626811027527
LSTM:
Mean Absolute Error: 0.5115
Root Mean Square Error: 0.7575
Mean Square Error: 0.5738

Train RMSE: 0.757
Train MSE: 0.574
Train MAE: 0.511
###########################

MODEL:  LSTM
sequence:  6h
units:  45
dropout1:  0.11814836227952394
dropout2:  0.24325404382648977
optimizer: adamax
activationDense: sigmoid
epochs: 43
batchsize: 30
validation_split: 0.2
Model: &#34;sequential_35&#34;
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
lstm_70 (LSTM)               (None, 36, 45)            8460      
_________________________________________________________________
dropout_70 (Dropout)         (None, 36, 45)            0         
_________________________________________________________________
lstm_71 (LSTM)               (None, 36, 45)            16380     
_________________________________________________________________
dropout_71 (Dropout)         (None, 36, 45)            0         
_________________________________________________________________
time_distributed_35 (TimeDis (None, 36, 1)             46        
=================================================================
Total params: 24,886
Trainable params: 24,886
Non-trainable params: 0
_________________________________________________________________
Epoch 1/43
106/106 [==============================] - 4s 35ms/step - loss: 0.7862 - val_loss: 0.8329
Epoch 2/43
106/106 [==============================] - 3s 26ms/step - loss: 0.6590 - val_loss: 0.7710
Epoch 3/43
106/106 [==============================] - 3s 26ms/step - loss: 0.6406 - val_loss: 0.7551
Epoch 4/43
106/106 [==============================] - 3s 26ms/step - loss: 0.6303 - val_loss: 0.7461
Epoch 5/43
106/106 [==============================] - 3s 27ms/step - loss: 0.6231 - val_loss: 0.7396
Epoch 6/43
106/106 [==============================] - 3s 27ms/step - loss: 0.6174 - val_loss: 0.7342
Epoch 7/43
106/106 [==============================] - 3s 27ms/step - loss: 0.6127 - val_loss: 0.7302
Epoch 8/43
106/106 [==============================] - 3s 26ms/step - loss: 0.6086 - val_loss: 0.7268
Epoch 9/43
106/106 [==============================] - 3s 26ms/step - loss: 0.6047 - val_loss: 0.7242
Epoch 10/43
106/106 [==============================] - 3s 27ms/step - loss: 0.6018 - val_loss: 0.7226
Epoch 11/43
106/106 [==============================] - 3s 26ms/step - loss: 0.5994 - val_loss: 0.7214
Epoch 12/43
106/106 [==============================] - 3s 27ms/step - loss: 0.5972 - val_loss: 0.7201
Epoch 13/43
106/106 [==============================] - 3s 27ms/step - loss: 0.5955 - val_loss: 0.7191
Epoch 14/43
106/106 [==============================] - 3s 27ms/step - loss: 0.5940 - val_loss: 0.7180
Epoch 15/43
106/106 [==============================] - 3s 27ms/step - loss: 0.5927 - val_loss: 0.7171
Epoch 16/43
106/106 [==============================] - 3s 27ms/step - loss: 0.5916 - val_loss: 0.7162
Epoch 17/43
106/106 [==============================] - 3s 26ms/step - loss: 0.5905 - val_loss: 0.7153
Epoch 18/43
106/106 [==============================] - 3s 25ms/step - loss: 0.5894 - val_loss: 0.7145
Epoch 19/43
106/106 [==============================] - 3s 26ms/step - loss: 0.5884 - val_loss: 0.7138
Epoch 20/43
106/106 [==============================] - 3s 25ms/step - loss: 0.5876 - val_loss: 0.7132
Epoch 21/43
106/106 [==============================] - 3s 25ms/step - loss: 0.5867 - val_loss: 0.7125
Epoch 22/43
106/106 [==============================] - 3s 27ms/step - loss: 0.5859 - val_loss: 0.7120
Epoch 23/43
106/106 [==============================] - 3s 25ms/step - loss: 0.5850 - val_loss: 0.7115
Epoch 24/43
106/106 [==============================] - 3s 26ms/step - loss: 0.5843 - val_loss: 0.7112
Epoch 25/43
106/106 [==============================] - 3s 25ms/step - loss: 0.5835 - val_loss: 0.7107
Epoch 26/43
106/106 [==============================] - 3s 25ms/step - loss: 0.5831 - val_loss: 0.7104
Epoch 27/43
106/106 [==============================] - 3s 26ms/step - loss: 0.5825 - val_loss: 0.7101
Epoch 28/43
106/106 [==============================] - 3s 27ms/step - loss: 0.5820 - val_loss: 0.7099
Epoch 29/43
106/106 [==============================] - 3s 26ms/step - loss: 0.5813 - val_loss: 0.7096
Epoch 30/43
106/106 [==============================] - 3s 25ms/step - loss: 0.5808 - val_loss: 0.7095
Epoch 31/43
106/106 [==============================] - 3s 25ms/step - loss: 0.5804 - val_loss: 0.7092
Epoch 32/43
106/106 [==============================] - 3s 25ms/step - loss: 0.5801 - val_loss: 0.7089
Epoch 33/43
106/106 [==============================] - 3s 26ms/step - loss: 0.5797 - val_loss: 0.7088
Epoch 34/43
106/106 [==============================] - 3s 27ms/step - loss: 0.5794 - val_loss: 0.7086
Epoch 35/43
106/106 [==============================] - 3s 25ms/step - loss: 0.5790 - val_loss: 0.7085
Epoch 36/43
106/106 [==============================] - 3s 25ms/step - loss: 0.5788 - val_loss: 0.7085
Epoch 37/43
106/106 [==============================] - 3s 26ms/step - loss: 0.5784 - val_loss: 0.7084
Epoch 38/43
106/106 [==============================] - 3s 25ms/step - loss: 0.5781 - val_loss: 0.7083
Epoch 39/43
106/106 [==============================] - 3s 26ms/step - loss: 0.5778 - val_loss: 0.7081
Epoch 40/43
106/106 [==============================] - 3s 26ms/step - loss: 0.5778 - val_loss: 0.7082
Epoch 41/43
106/106 [==============================] - 3s 25ms/step - loss: 0.5773 - val_loss: 0.7081
Epoch 42/43
106/106 [==============================] - 3s 25ms/step - loss: 0.5772 - val_loss: 0.7081
Epoch 43/43
106/106 [==============================] - 3s 25ms/step - loss: 0.5768 - val_loss: 0.7082
Execution time:  125.61718106269836
LSTM:
Mean Absolute Error: 0.5183
Root Mean Square Error: 0.7637
Mean Square Error: 0.5832

Train RMSE: 0.764
Train MSE: 0.583
Train MAE: 0.518
###########################

MODEL:  LSTM
sequence:  12h
units:  43
dropout1:  0.40519643149940265
dropout2:  0.3312343747027119
optimizer: adam
activationDense: tanh
epochs: 56
batchsize: 11
validation_split: 0.1
Model: &#34;sequential_36&#34;
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
lstm_72 (LSTM)               (None, 72, 43)            7740      
_________________________________________________________________
dropout_72 (Dropout)         (None, 72, 43)            0         
_________________________________________________________________
lstm_73 (LSTM)               (None, 72, 43)            14964     
_________________________________________________________________
dropout_73 (Dropout)         (None, 72, 43)            0         
_________________________________________________________________
time_distributed_36 (TimeDis (None, 72, 1)             44        
=================================================================
Total params: 22,748
Trainable params: 22,748
Non-trainable params: 0
_________________________________________________________________
Epoch 1/56
321/321 [==============================] - 14s 45ms/step - loss: 0.5693 - val_loss: 0.4496
Epoch 2/56
321/321 [==============================] - 13s 42ms/step - loss: 0.5296 - val_loss: 0.4230
Epoch 3/56
321/321 [==============================] - 14s 42ms/step - loss: 0.5202 - val_loss: 0.4180
Epoch 4/56
321/321 [==============================] - 14s 42ms/step - loss: 0.5142 - val_loss: 0.3974
Epoch 5/56
321/321 [==============================] - 14s 42ms/step - loss: 0.5106 - val_loss: 0.3823
Epoch 6/56
321/321 [==============================] - 14s 42ms/step - loss: 0.5073 - val_loss: 0.3790
Epoch 7/56
321/321 [==============================] - 14s 42ms/step - loss: 0.5040 - val_loss: 0.3645
Epoch 8/56
321/321 [==============================] - 14s 42ms/step - loss: 0.5029 - val_loss: 0.3697
Epoch 9/56
321/321 [==============================] - 14s 42ms/step - loss: 0.5013 - val_loss: 0.3606
Epoch 10/56
321/321 [==============================] - 14s 43ms/step - loss: 0.4996 - val_loss: 0.3532
Epoch 11/56
321/321 [==============================] - 14s 43ms/step - loss: 0.4982 - val_loss: 0.3593
Epoch 12/56
321/321 [==============================] - 14s 42ms/step - loss: 0.4953 - val_loss: 0.3480
Epoch 13/56
321/321 [==============================] - 14s 42ms/step - loss: 0.4939 - val_loss: 0.3409
Epoch 14/56
321/321 [==============================] - 14s 42ms/step - loss: 0.4925 - val_loss: 0.3344
Epoch 15/56
321/321 [==============================] - 13s 42ms/step - loss: 0.4851 - val_loss: 0.3296
Epoch 16/56
321/321 [==============================] - 14s 42ms/step - loss: 0.4830 - val_loss: 0.3098
Epoch 17/56
321/321 [==============================] - 15s 47ms/step - loss: 0.4783 - val_loss: 0.3115
Epoch 18/56
321/321 [==============================] - 15s 47ms/step - loss: 0.4775 - val_loss: 0.3188
Epoch 19/56
321/321 [==============================] - 14s 45ms/step - loss: 0.4808 - val_loss: 0.3091
Epoch 20/56
321/321 [==============================] - 14s 44ms/step - loss: 0.4752 - val_loss: 0.2994
Epoch 21/56
321/321 [==============================] - 14s 44ms/step - loss: 0.4730 - val_loss: 0.3182
Epoch 22/56
321/321 [==============================] - 14s 44ms/step - loss: 0.4730 - val_loss: 0.3009
Epoch 23/56
321/321 [==============================] - 14s 44ms/step - loss: 0.4714 - val_loss: 0.3139
Epoch 24/56
321/321 [==============================] - 14s 44ms/step - loss: 0.4676 - val_loss: 0.3065
Epoch 25/56
321/321 [==============================] - 14s 43ms/step - loss: 0.4707 - val_loss: 0.3129
Epoch 26/56
321/321 [==============================] - 14s 44ms/step - loss: 0.4672 - val_loss: 0.3158
Epoch 27/56
321/321 [==============================] - 14s 44ms/step - loss: 0.4697 - val_loss: 0.3111
Epoch 28/56
321/321 [==============================] - 14s 44ms/step - loss: 0.4654 - val_loss: 0.3096
Epoch 29/56
321/321 [==============================] - 14s 44ms/step - loss: 0.4654 - val_loss: 0.3089
Epoch 30/56
321/321 [==============================] - 14s 44ms/step - loss: 0.4656 - val_loss: 0.3051
Epoch 31/56
321/321 [==============================] - 14s 44ms/step - loss: 0.4636 - val_loss: 0.3137
Epoch 32/56
321/321 [==============================] - 14s 44ms/step - loss: 0.4618 - val_loss: 0.3170
Epoch 33/56
321/321 [==============================] - 14s 44ms/step - loss: 0.4667 - val_loss: 0.3018
Epoch 34/56
321/321 [==============================] - 14s 44ms/step - loss: 0.4590 - val_loss: 0.3116
Epoch 35/56
321/321 [==============================] - 14s 44ms/step - loss: 0.4585 - val_loss: 0.3003
Epoch 36/56
321/321 [==============================] - 14s 45ms/step - loss: 0.4586 - val_loss: 0.3009
Epoch 37/56
321/321 [==============================] - 14s 44ms/step - loss: 0.4591 - val_loss: 0.2975
Epoch 38/56
321/321 [==============================] - 14s 45ms/step - loss: 0.4576 - val_loss: 0.2971
Epoch 39/56
321/321 [==============================] - 14s 44ms/step - loss: 0.4546 - val_loss: 0.2969
Epoch 40/56
321/321 [==============================] - 14s 44ms/step - loss: 0.4577 - val_loss: 0.2987
Epoch 41/56
321/321 [==============================] - 14s 44ms/step - loss: 0.4540 - val_loss: 0.2972
Epoch 42/56
321/321 [==============================] - 14s 44ms/step - loss: 0.4545 - val_loss: 0.2979
Epoch 43/56
321/321 [==============================] - 14s 44ms/step - loss: 0.4501 - val_loss: 0.3020
Epoch 44/56
321/321 [==============================] - 14s 44ms/step - loss: 0.4535 - val_loss: 0.2990
Epoch 45/56
321/321 [==============================] - 14s 45ms/step - loss: 0.4591 - val_loss: 0.3042
Epoch 46/56
321/321 [==============================] - 14s 44ms/step - loss: 0.4496 - val_loss: 0.3002
Epoch 47/56
321/321 [==============================] - 14s 44ms/step - loss: 0.4542 - val_loss: 0.2999
Epoch 48/56
321/321 [==============================] - 14s 44ms/step - loss: 0.4506 - val_loss: 0.2947
Epoch 49/56
321/321 [==============================] - 14s 44ms/step - loss: 0.4490 - val_loss: 0.2946
Epoch 50/56
321/321 [==============================] - 14s 44ms/step - loss: 0.4459 - val_loss: 0.2995
Epoch 51/56
321/321 [==============================] - 14s 43ms/step - loss: 0.4440 - val_loss: 0.2970
Epoch 52/56
321/321 [==============================] - 14s 44ms/step - loss: 0.4469 - val_loss: 0.2975
Epoch 53/56
321/321 [==============================] - 14s 44ms/step - loss: 0.4449 - val_loss: 0.2930
Epoch 54/56
321/321 [==============================] - 15s 45ms/step - loss: 0.4386 - val_loss: 0.2952
Epoch 55/56
321/321 [==============================] - 15s 46ms/step - loss: 0.4418 - val_loss: 0.2940
Epoch 56/56
321/321 [==============================] - 14s 44ms/step - loss: 0.4375 - val_loss: 0.2947
Execution time:  794.231693983078
LSTM:
Mean Absolute Error: 0.3578
Root Mean Square Error: 0.8350
Mean Square Error: 0.6972

Train RMSE: 0.835
Train MSE: 0.697
Train MAE: 0.358
###########################

MODEL:  LSTM
sequence:  12h
units:  45
dropout1:  0.11814836227952394
dropout2:  0.24325404382648977
optimizer: adam
activationDense: tanh
epochs: 43
batchsize: 30
validation_split: 0.2
Model: &#34;sequential_37&#34;
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
lstm_74 (LSTM)               (None, 72, 45)            8460      
_________________________________________________________________
dropout_74 (Dropout)         (None, 72, 45)            0         
_________________________________________________________________
lstm_75 (LSTM)               (None, 72, 45)            16380     
_________________________________________________________________
dropout_75 (Dropout)         (None, 72, 45)            0         
_________________________________________________________________
time_distributed_37 (TimeDis (None, 72, 1)             46        
=================================================================
Total params: 24,886
Trainable params: 24,886
Non-trainable params: 0
_________________________________________________________________
Epoch 1/43
105/105 [==============================] - 6s 58ms/step - loss: 0.5885 - val_loss: 0.4277
Epoch 2/43
105/105 [==============================] - 5s 50ms/step - loss: 0.5383 - val_loss: 0.4212
Epoch 3/43
105/105 [==============================] - 5s 50ms/step - loss: 0.5256 - val_loss: 0.4156
Epoch 4/43
105/105 [==============================] - 5s 51ms/step - loss: 0.5191 - val_loss: 0.4117
Epoch 5/43
105/105 [==============================] - 5s 50ms/step - loss: 0.5139 - val_loss: 0.4092
Epoch 6/43
105/105 [==============================] - 5s 50ms/step - loss: 0.5094 - val_loss: 0.4080
Epoch 7/43
105/105 [==============================] - 5s 50ms/step - loss: 0.5054 - val_loss: 0.4075
Epoch 8/43
105/105 [==============================] - 5s 49ms/step - loss: 0.5020 - val_loss: 0.4067
Epoch 9/43
105/105 [==============================] - 5s 50ms/step - loss: 0.4975 - val_loss: 0.3967
Epoch 10/43
105/105 [==============================] - 5s 50ms/step - loss: 0.4921 - val_loss: 0.3939
Epoch 11/43
105/105 [==============================] - 5s 50ms/step - loss: 0.4965 - val_loss: 0.3974
Epoch 12/43
105/105 [==============================] - 5s 49ms/step - loss: 0.4861 - val_loss: 0.3959
Epoch 13/43
105/105 [==============================] - 5s 50ms/step - loss: 0.4821 - val_loss: 0.3939
Epoch 14/43
105/105 [==============================] - 5s 49ms/step - loss: 0.4795 - val_loss: 0.3956
Epoch 15/43
105/105 [==============================] - 5s 49ms/step - loss: 0.4751 - val_loss: 0.3913
Epoch 16/43
105/105 [==============================] - 5s 50ms/step - loss: 0.4936 - val_loss: 0.4167
Epoch 17/43
105/105 [==============================] - 5s 49ms/step - loss: 0.4882 - val_loss: 0.4048
Epoch 18/43
105/105 [==============================] - 5s 49ms/step - loss: 0.4779 - val_loss: 0.3914
Epoch 19/43
105/105 [==============================] - 5s 50ms/step - loss: 0.4853 - val_loss: 0.4115
Epoch 20/43
105/105 [==============================] - 5s 49ms/step - loss: 0.4893 - val_loss: 0.4117
Epoch 21/43
105/105 [==============================] - 5s 49ms/step - loss: 0.4859 - val_loss: 0.4133
Epoch 22/43
105/105 [==============================] - 5s 50ms/step - loss: 0.4825 - val_loss: 0.4060
Epoch 23/43
105/105 [==============================] - 5s 49ms/step - loss: 0.4794 - val_loss: 0.3957
Epoch 24/43
105/105 [==============================] - 5s 49ms/step - loss: 0.4748 - val_loss: 0.3950
Epoch 25/43
105/105 [==============================] - 5s 50ms/step - loss: 0.4928 - val_loss: 0.4124
Epoch 26/43
105/105 [==============================] - 5s 49ms/step - loss: 0.4763 - val_loss: 0.3965
Epoch 27/43
105/105 [==============================] - 5s 49ms/step - loss: 0.4715 - val_loss: 0.3937
Epoch 28/43
105/105 [==============================] - 5s 50ms/step - loss: 0.4645 - val_loss: 0.3938
Epoch 29/43
105/105 [==============================] - 5s 49ms/step - loss: 0.4604 - val_loss: 0.3939
Epoch 30/43
105/105 [==============================] - 5s 49ms/step - loss: 0.4596 - val_loss: 0.3957
Epoch 31/43
105/105 [==============================] - 5s 50ms/step - loss: 0.4702 - val_loss: 0.3961
Epoch 32/43
105/105 [==============================] - 5s 49ms/step - loss: 0.4580 - val_loss: 0.3930
Epoch 33/43
105/105 [==============================] - 5s 49ms/step - loss: 0.4584 - val_loss: 0.3952
Epoch 34/43
105/105 [==============================] - 5s 51ms/step - loss: 0.4782 - val_loss: 0.3939
Epoch 35/43
105/105 [==============================] - 5s 50ms/step - loss: 0.4537 - val_loss: 0.3967
Epoch 36/43
105/105 [==============================] - 5s 49ms/step - loss: 0.4509 - val_loss: 0.3983
Epoch 37/43
105/105 [==============================] - 5s 50ms/step - loss: 0.4574 - val_loss: 0.3980
Epoch 38/43
105/105 [==============================] - 5s 49ms/step - loss: 0.4534 - val_loss: 0.3992
Epoch 39/43
105/105 [==============================] - 5s 49ms/step - loss: 0.4504 - val_loss: 0.4007
Epoch 40/43
105/105 [==============================] - 5s 50ms/step - loss: 0.4483 - val_loss: 0.3969
Epoch 41/43
105/105 [==============================] - 5s 49ms/step - loss: 0.4469 - val_loss: 0.3986
Epoch 42/43
105/105 [==============================] - 5s 49ms/step - loss: 0.4448 - val_loss: 0.3990
Epoch 43/43
105/105 [==============================] - 5s 51ms/step - loss: 0.4440 - val_loss: 0.3998
Execution time:  231.65903115272522
LSTM:
Mean Absolute Error: 0.3556
Root Mean Square Error: 0.8537
Mean Square Error: 0.7288

Train RMSE: 0.854
Train MSE: 0.729
Train MAE: 0.356
###########################

MODEL:  LSTM
sequence:  12h
units:  43
dropout1:  0.40519643149940265
dropout2:  0.3312343747027119
optimizer: adam
activationDense: sigmoid
epochs: 56
batchsize: 11
validation_split: 0.1
Model: &#34;sequential_38&#34;
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
lstm_76 (LSTM)               (None, 72, 43)            7740      
_________________________________________________________________
dropout_76 (Dropout)         (None, 72, 43)            0         
_________________________________________________________________
lstm_77 (LSTM)               (None, 72, 43)            14964     
_________________________________________________________________
dropout_77 (Dropout)         (None, 72, 43)            0         
_________________________________________________________________
time_distributed_38 (TimeDis (None, 72, 1)             44        
=================================================================
Total params: 22,748
Trainable params: 22,748
Non-trainable params: 0
_________________________________________________________________
Epoch 1/56
321/321 [==============================] - 14s 45ms/step - loss: 0.7113 - val_loss: 0.8222
Epoch 2/56
321/321 [==============================] - 14s 42ms/step - loss: 0.6571 - val_loss: 0.8126
Epoch 3/56
321/321 [==============================] - 14s 44ms/step - loss: 0.6457 - val_loss: 0.8092
Epoch 4/56
321/321 [==============================] - 14s 43ms/step - loss: 0.6419 - val_loss: 0.8073
Epoch 5/56
321/321 [==============================] - 14s 44ms/step - loss: 0.6385 - val_loss: 0.8062
Epoch 6/56
321/321 [==============================] - 14s 43ms/step - loss: 0.6357 - val_loss: 0.8054
Epoch 7/56
321/321 [==============================] - 14s 43ms/step - loss: 0.6341 - val_loss: 0.8049
Epoch 8/56
321/321 [==============================] - 16s 48ms/step - loss: 0.6327 - val_loss: 0.8046
Epoch 9/56
321/321 [==============================] - 15s 46ms/step - loss: 0.6314 - val_loss: 0.8044
Epoch 10/56
321/321 [==============================] - 14s 44ms/step - loss: 0.6313 - val_loss: 0.8043
Epoch 11/56
321/321 [==============================] - 14s 45ms/step - loss: 0.6301 - val_loss: 0.8042
Epoch 12/56
321/321 [==============================] - 15s 46ms/step - loss: 0.6293 - val_loss: 0.8042
Epoch 13/56
321/321 [==============================] - 15s 47ms/step - loss: 0.6295 - val_loss: 0.8041
Epoch 14/56
321/321 [==============================] - 14s 44ms/step - loss: 0.6285 - val_loss: 0.8041
Epoch 15/56
321/321 [==============================] - 14s 44ms/step - loss: 0.6278 - val_loss: 0.8041
Epoch 16/56
321/321 [==============================] - 14s 44ms/step - loss: 0.6294 - val_loss: 0.8041
Epoch 17/56
321/321 [==============================] - 14s 44ms/step - loss: 0.6281 - val_loss: 0.8041
Epoch 18/56
321/321 [==============================] - 14s 44ms/step - loss: 0.6277 - val_loss: 0.8041
Epoch 19/56
321/321 [==============================] - 14s 44ms/step - loss: 0.6250 - val_loss: 0.8040
Epoch 20/56
321/321 [==============================] - 14s 44ms/step - loss: 0.6244 - val_loss: 0.8041
Epoch 21/56
321/321 [==============================] - 14s 43ms/step - loss: 0.6237 - val_loss: 0.8040
Epoch 22/56
321/321 [==============================] - 14s 44ms/step - loss: 0.6234 - val_loss: 0.8040
Epoch 23/56
321/321 [==============================] - 14s 44ms/step - loss: 0.6221 - val_loss: 0.8040
Epoch 24/56
321/321 [==============================] - 14s 43ms/step - loss: 0.6207 - val_loss: 0.8039
Epoch 25/56
321/321 [==============================] - 14s 43ms/step - loss: 0.6211 - val_loss: 0.8039
Epoch 26/56
321/321 [==============================] - 14s 43ms/step - loss: 0.6198 - val_loss: 0.8039
Epoch 27/56
321/321 [==============================] - 14s 44ms/step - loss: 0.6191 - val_loss: 0.8039
Epoch 28/56
321/321 [==============================] - 14s 43ms/step - loss: 0.6159 - val_loss: 0.8040
Epoch 29/56
321/321 [==============================] - 14s 44ms/step - loss: 0.6145 - val_loss: 0.8039
Epoch 30/56
321/321 [==============================] - 14s 44ms/step - loss: 0.6132 - val_loss: 0.8039
Epoch 31/56
321/321 [==============================] - 14s 44ms/step - loss: 0.6126 - val_loss: 0.8039
Epoch 32/56
321/321 [==============================] - 14s 43ms/step - loss: 0.6108 - val_loss: 0.8039
Epoch 33/56
321/321 [==============================] - 14s 44ms/step - loss: 0.6081 - val_loss: 0.8039
Epoch 34/56
321/321 [==============================] - 14s 43ms/step - loss: 0.6130 - val_loss: 0.8039
Epoch 35/56
321/321 [==============================] - 14s 43ms/step - loss: 0.6042 - val_loss: 0.8040
Epoch 36/56
321/321 [==============================] - 14s 43ms/step - loss: 0.6022 - val_loss: 0.8039
Epoch 37/56
321/321 [==============================] - 14s 43ms/step - loss: 0.6024 - val_loss: 0.8039
Epoch 38/56
321/321 [==============================] - 14s 44ms/step - loss: 0.5992 - val_loss: 0.8039
Epoch 39/56
321/321 [==============================] - 14s 44ms/step - loss: 0.6004 - val_loss: 0.8039
Epoch 40/56
321/321 [==============================] - 14s 43ms/step - loss: 0.5997 - val_loss: 0.8040
Epoch 41/56
321/321 [==============================] - 14s 44ms/step - loss: 0.6002 - val_loss: 0.8039
Epoch 42/56
321/321 [==============================] - 14s 44ms/step - loss: 0.6026 - val_loss: 0.8039
Epoch 43/56
321/321 [==============================] - 14s 44ms/step - loss: 0.5985 - val_loss: 0.8039
Epoch 44/56
321/321 [==============================] - 14s 44ms/step - loss: 0.5937 - val_loss: 0.8040
Epoch 45/56
321/321 [==============================] - 14s 44ms/step - loss: 0.5970 - val_loss: 0.8040
Epoch 46/56
321/321 [==============================] - 14s 44ms/step - loss: 0.5941 - val_loss: 0.8039
Epoch 47/56
321/321 [==============================] - 14s 44ms/step - loss: 0.5921 - val_loss: 0.8039
Epoch 48/56
321/321 [==============================] - 14s 43ms/step - loss: 0.5959 - val_loss: 0.8039
Epoch 49/56
321/321 [==============================] - 14s 43ms/step - loss: 0.5904 - val_loss: 0.8039
Epoch 50/56
321/321 [==============================] - 14s 44ms/step - loss: 0.5884 - val_loss: 0.8039
Epoch 51/56
321/321 [==============================] - 14s 44ms/step - loss: 0.5955 - val_loss: 0.8041
Epoch 52/56
321/321 [==============================] - 14s 44ms/step - loss: 0.5926 - val_loss: 0.8040
Epoch 53/56
321/321 [==============================] - 14s 44ms/step - loss: 0.5923 - val_loss: 0.8041
Epoch 54/56
321/321 [==============================] - 14s 44ms/step - loss: 0.5871 - val_loss: 0.8040
Epoch 55/56
321/321 [==============================] - 14s 44ms/step - loss: 0.5837 - val_loss: 0.8040
Epoch 56/56
321/321 [==============================] - 14s 44ms/step - loss: 0.5867 - val_loss: 0.8039
Execution time:  796.5217626094818
LSTM:
Mean Absolute Error: 0.5903
Root Mean Square Error: 0.8702
Mean Square Error: 0.7572

Train RMSE: 0.870
Train MSE: 0.757
Train MAE: 0.590
###########################

MODEL:  LSTM
sequence:  12h
units:  45
dropout1:  0.11814836227952394
dropout2:  0.24325404382648977
optimizer: adam
activationDense: sigmoid
epochs: 43
batchsize: 30
validation_split: 0.2
Model: &#34;sequential_39&#34;
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
lstm_78 (LSTM)               (None, 72, 45)            8460      
_________________________________________________________________
dropout_78 (Dropout)         (None, 72, 45)            0         
_________________________________________________________________
lstm_79 (LSTM)               (None, 72, 45)            16380     
_________________________________________________________________
dropout_79 (Dropout)         (None, 72, 45)            0         
_________________________________________________________________
time_distributed_39 (TimeDis (None, 72, 1)             46        
=================================================================
Total params: 24,886
Trainable params: 24,886
Non-trainable params: 0
_________________________________________________________________
Epoch 1/43
105/105 [==============================] - 7s 69ms/step - loss: 0.7470 - val_loss: 0.7683
Epoch 2/43
105/105 [==============================] - 6s 53ms/step - loss: 0.6739 - val_loss: 0.7506
Epoch 3/43
105/105 [==============================] - 5s 52ms/step - loss: 0.6659 - val_loss: 0.7513
Epoch 4/43
105/105 [==============================] - 6s 53ms/step - loss: 0.6521 - val_loss: 0.7459
Epoch 5/43
105/105 [==============================] - 5s 52ms/step - loss: 0.6449 - val_loss: 0.7437
Epoch 6/43
105/105 [==============================] - 5s 52ms/step - loss: 0.6411 - val_loss: 0.7404
Epoch 7/43
105/105 [==============================] - 6s 53ms/step - loss: 0.6381 - val_loss: 0.7390
Epoch 8/43
105/105 [==============================] - 5s 52ms/step - loss: 0.6361 - val_loss: 0.7379
Epoch 9/43
105/105 [==============================] - 5s 52ms/step - loss: 0.6349 - val_loss: 0.7371
Epoch 10/43
105/105 [==============================] - 6s 54ms/step - loss: 0.6340 - val_loss: 0.7363
Epoch 11/43
105/105 [==============================] - 5s 51ms/step - loss: 0.6333 - val_loss: 0.7350
Epoch 12/43
105/105 [==============================] - 5s 51ms/step - loss: 0.6320 - val_loss: 0.7346
Epoch 13/43
105/105 [==============================] - 6s 52ms/step - loss: 0.6319 - val_loss: 0.7315
Epoch 14/43
105/105 [==============================] - 5s 51ms/step - loss: 0.6291 - val_loss: 0.7299
Epoch 15/43
105/105 [==============================] - 5s 51ms/step - loss: 0.6273 - val_loss: 0.7286
Epoch 16/43
105/105 [==============================] - 5s 52ms/step - loss: 0.6260 - val_loss: 0.7278
Epoch 17/43
105/105 [==============================] - 5s 51ms/step - loss: 0.6257 - val_loss: 0.7285
Epoch 18/43
105/105 [==============================] - 5s 51ms/step - loss: 0.6240 - val_loss: 0.7283
Epoch 19/43
105/105 [==============================] - 6s 53ms/step - loss: 0.6272 - val_loss: 0.7268
Epoch 20/43
105/105 [==============================] - 5s 51ms/step - loss: 0.6281 - val_loss: 0.7289
Epoch 21/43
105/105 [==============================] - 5s 51ms/step - loss: 0.6217 - val_loss: 0.7266
Epoch 22/43
105/105 [==============================] - 5s 52ms/step - loss: 0.6264 - val_loss: 0.7276
Epoch 23/43
105/105 [==============================] - 5s 52ms/step - loss: 0.6209 - val_loss: 0.7266
Epoch 24/43
105/105 [==============================] - 5s 51ms/step - loss: 0.6253 - val_loss: 0.7277
Epoch 25/43
105/105 [==============================] - 5s 52ms/step - loss: 0.6195 - val_loss: 0.7268
Epoch 26/43
105/105 [==============================] - 5s 51ms/step - loss: 0.6207 - val_loss: 0.7262
Epoch 27/43
105/105 [==============================] - 5s 51ms/step - loss: 0.6222 - val_loss: 0.7258
Epoch 28/43
105/105 [==============================] - 5s 52ms/step - loss: 0.6177 - val_loss: 0.7259
Epoch 29/43
105/105 [==============================] - 5s 52ms/step - loss: 0.6154 - val_loss: 0.7257
Epoch 30/43
105/105 [==============================] - 5s 51ms/step - loss: 0.6164 - val_loss: 0.7260
Epoch 31/43
105/105 [==============================] - 6s 54ms/step - loss: 0.6138 - val_loss: 0.7249
Epoch 32/43
105/105 [==============================] - 5s 51ms/step - loss: 0.6220 - val_loss: 0.7237
Epoch 33/43
105/105 [==============================] - 5s 51ms/step - loss: 0.6142 - val_loss: 0.7248
Epoch 34/43
105/105 [==============================] - 5s 52ms/step - loss: 0.6115 - val_loss: 0.7230
Epoch 35/43
105/105 [==============================] - 5s 51ms/step - loss: 0.6115 - val_loss: 0.7239
Epoch 36/43
105/105 [==============================] - 5s 52ms/step - loss: 0.6114 - val_loss: 0.7230
Epoch 37/43
105/105 [==============================] - 5s 52ms/step - loss: 0.6094 - val_loss: 0.7225
Epoch 38/43
105/105 [==============================] - 5s 52ms/step - loss: 0.6089 - val_loss: 0.7267
Epoch 39/43
105/105 [==============================] - 5s 52ms/step - loss: 0.6139 - val_loss: 0.7236
Epoch 40/43
105/105 [==============================] - 6s 53ms/step - loss: 0.6076 - val_loss: 0.7206
Epoch 41/43
105/105 [==============================] - 5s 51ms/step - loss: 0.6069 - val_loss: 0.7216
Epoch 42/43
105/105 [==============================] - 6s 53ms/step - loss: 0.6064 - val_loss: 0.7202
Epoch 43/43
105/105 [==============================] - 5s 52ms/step - loss: 0.6044 - val_loss: 0.7201
Execution time:  243.15848755836487
LSTM:
Mean Absolute Error: 0.5676
Root Mean Square Error: 0.8397
Mean Square Error: 0.7052

Train RMSE: 0.840
Train MSE: 0.705
Train MAE: 0.568
###########################

MODEL:  LSTM
sequence:  12h
units:  43
dropout1:  0.40519643149940265
dropout2:  0.3312343747027119
optimizer: adadelta
activationDense: tanh
epochs: 56
batchsize: 11
validation_split: 0.1
Model: &#34;sequential_40&#34;
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
lstm_80 (LSTM)               (None, 72, 43)            7740      
_________________________________________________________________
dropout_80 (Dropout)         (None, 72, 43)            0         
_________________________________________________________________
lstm_81 (LSTM)               (None, 72, 43)            14964     
_________________________________________________________________
dropout_81 (Dropout)         (None, 72, 43)            0         
_________________________________________________________________
time_distributed_40 (TimeDis (None, 72, 1)             44        
=================================================================
Total params: 22,748
Trainable params: 22,748
Non-trainable params: 0
_________________________________________________________________
Epoch 1/56
321/321 [==============================] - 15s 47ms/step - loss: 0.6846 - val_loss: 0.7633
Epoch 2/56
321/321 [==============================] - 14s 44ms/step - loss: 0.6826 - val_loss: 0.7579
Epoch 3/56
321/321 [==============================] - 14s 44ms/step - loss: 0.6802 - val_loss: 0.7520
Epoch 4/56
321/321 [==============================] - 14s 45ms/step - loss: 0.6777 - val_loss: 0.7457
Epoch 5/56
321/321 [==============================] - 14s 44ms/step - loss: 0.6750 - val_loss: 0.7392
Epoch 6/56
321/321 [==============================] - 14s 45ms/step - loss: 0.6723 - val_loss: 0.7323
Epoch 7/56
321/321 [==============================] - 14s 45ms/step - loss: 0.6696 - val_loss: 0.7252
Epoch 8/56
321/321 [==============================] - 14s 44ms/step - loss: 0.6667 - val_loss: 0.7179
Epoch 9/56
321/321 [==============================] - 14s 44ms/step - loss: 0.6638 - val_loss: 0.7102
Epoch 10/56
321/321 [==============================] - 14s 44ms/step - loss: 0.6607 - val_loss: 0.7023
Epoch 11/56
321/321 [==============================] - 14s 44ms/step - loss: 0.6577 - val_loss: 0.6940
Epoch 12/56
321/321 [==============================] - 14s 44ms/step - loss: 0.6544 - val_loss: 0.6854
Epoch 13/56
321/321 [==============================] - 14s 44ms/step - loss: 0.6511 - val_loss: 0.6765
Epoch 14/56
321/321 [==============================] - 14s 44ms/step - loss: 0.6477 - val_loss: 0.6672
Epoch 15/56
321/321 [==============================] - 14s 44ms/step - loss: 0.6441 - val_loss: 0.6575
Epoch 16/56
321/321 [==============================] - 14s 44ms/step - loss: 0.6405 - val_loss: 0.6475
Epoch 17/56
321/321 [==============================] - 14s 44ms/step - loss: 0.6365 - val_loss: 0.6370
Epoch 18/56
321/321 [==============================] - 14s 44ms/step - loss: 0.6327 - val_loss: 0.6263
Epoch 19/56
321/321 [==============================] - 14s 44ms/step - loss: 0.6287 - val_loss: 0.6152
Epoch 20/56
321/321 [==============================] - 14s 44ms/step - loss: 0.6244 - val_loss: 0.6038
Epoch 21/56
321/321 [==============================] - 14s 44ms/step - loss: 0.6203 - val_loss: 0.5923
Epoch 22/56
321/321 [==============================] - 14s 44ms/step - loss: 0.6161 - val_loss: 0.5806
Epoch 23/56
321/321 [==============================] - 14s 45ms/step - loss: 0.6120 - val_loss: 0.5688
Epoch 24/56
321/321 [==============================] - 14s 44ms/step - loss: 0.6079 - val_loss: 0.5571
Epoch 25/56
321/321 [==============================] - 14s 44ms/step - loss: 0.6036 - val_loss: 0.5455
Epoch 26/56
321/321 [==============================] - 14s 44ms/step - loss: 0.5998 - val_loss: 0.5342
Epoch 27/56
321/321 [==============================] - 14s 43ms/step - loss: 0.5957 - val_loss: 0.5232
Epoch 28/56
321/321 [==============================] - 14s 44ms/step - loss: 0.5922 - val_loss: 0.5124
Epoch 29/56
321/321 [==============================] - 14s 44ms/step - loss: 0.5887 - val_loss: 0.5020
Epoch 30/56
321/321 [==============================] - 14s 44ms/step - loss: 0.5855 - val_loss: 0.4920
Epoch 31/56
321/321 [==============================] - 14s 44ms/step - loss: 0.5823 - val_loss: 0.4824
Epoch 32/56
321/321 [==============================] - 14s 44ms/step - loss: 0.5794 - val_loss: 0.4731
Epoch 33/56
321/321 [==============================] - 14s 44ms/step - loss: 0.5767 - val_loss: 0.4641
Epoch 34/56
321/321 [==============================] - 14s 44ms/step - loss: 0.5740 - val_loss: 0.4554
Epoch 35/56
321/321 [==============================] - 14s 43ms/step - loss: 0.5717 - val_loss: 0.4470
Epoch 36/56
321/321 [==============================] - 14s 43ms/step - loss: 0.5693 - val_loss: 0.4389
Epoch 37/56
321/321 [==============================] - 14s 44ms/step - loss: 0.5670 - val_loss: 0.4311
Epoch 38/56
321/321 [==============================] - 14s 44ms/step - loss: 0.5653 - val_loss: 0.4235
Epoch 39/56
321/321 [==============================] - 14s 44ms/step - loss: 0.5632 - val_loss: 0.4162
Epoch 40/56
321/321 [==============================] - 14s 44ms/step - loss: 0.5613 - val_loss: 0.4091
Epoch 41/56
321/321 [==============================] - 14s 44ms/step - loss: 0.5598 - val_loss: 0.4022
Epoch 42/56
321/321 [==============================] - 14s 44ms/step - loss: 0.5581 - val_loss: 0.3957
Epoch 43/56
321/321 [==============================] - 14s 44ms/step - loss: 0.5564 - val_loss: 0.3893
Epoch 44/56
321/321 [==============================] - 14s 43ms/step - loss: 0.5550 - val_loss: 0.3833
Epoch 45/56
321/321 [==============================] - 14s 44ms/step - loss: 0.5536 - val_loss: 0.3774
Epoch 46/56
321/321 [==============================] - 14s 44ms/step - loss: 0.5523 - val_loss: 0.3719
Epoch 47/56
321/321 [==============================] - 14s 44ms/step - loss: 0.5514 - val_loss: 0.3667
Epoch 48/56
321/321 [==============================] - 14s 44ms/step - loss: 0.5502 - val_loss: 0.3618
Epoch 49/56
321/321 [==============================] - 14s 44ms/step - loss: 0.5494 - val_loss: 0.3571
Epoch 50/56
321/321 [==============================] - 14s 44ms/step - loss: 0.5483 - val_loss: 0.3528
Epoch 51/56
321/321 [==============================] - 14s 44ms/step - loss: 0.5478 - val_loss: 0.3488
Epoch 52/56
321/321 [==============================] - 14s 44ms/step - loss: 0.5470 - val_loss: 0.3450
Epoch 53/56
321/321 [==============================] - 14s 43ms/step - loss: 0.5467 - val_loss: 0.3417
Epoch 54/56
321/321 [==============================] - 14s 44ms/step - loss: 0.5462 - val_loss: 0.3388
Epoch 55/56
321/321 [==============================] - 14s 44ms/step - loss: 0.5456 - val_loss: 0.3362
Epoch 56/56
321/321 [==============================] - 14s 44ms/step - loss: 0.5448 - val_loss: 0.3337
Execution time:  799.7367260456085
LSTM:
Mean Absolute Error: 0.4307
Root Mean Square Error: 0.7951
Mean Square Error: 0.6322

Train RMSE: 0.795
Train MSE: 0.632
Train MAE: 0.431
###########################

MODEL:  LSTM
sequence:  12h
units:  45
dropout1:  0.11814836227952394
dropout2:  0.24325404382648977
optimizer: adadelta
activationDense: tanh
epochs: 43
batchsize: 30
validation_split: 0.2
Model: &#34;sequential_41&#34;
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
lstm_82 (LSTM)               (None, 72, 45)            8460      
_________________________________________________________________
dropout_82 (Dropout)         (None, 72, 45)            0         
_________________________________________________________________
lstm_83 (LSTM)               (None, 72, 45)            16380     
_________________________________________________________________
dropout_83 (Dropout)         (None, 72, 45)            0         
_________________________________________________________________
time_distributed_41 (TimeDis (None, 72, 1)             46        
=================================================================
Total params: 24,886
Trainable params: 24,886
Non-trainable params: 0
_________________________________________________________________
Epoch 1/43
105/105 [==============================] - 6s 60ms/step - loss: 0.7171 - val_loss: 0.7112
Epoch 2/43
105/105 [==============================] - 6s 53ms/step - loss: 0.7165 - val_loss: 0.7104
Epoch 3/43
105/105 [==============================] - 6s 53ms/step - loss: 0.7159 - val_loss: 0.7096
Epoch 4/43
105/105 [==============================] - 6s 54ms/step - loss: 0.7153 - val_loss: 0.7087
Epoch 5/43
105/105 [==============================] - 5s 52ms/step - loss: 0.7146 - val_loss: 0.7078
Epoch 6/43
105/105 [==============================] - 6s 53ms/step - loss: 0.7139 - val_loss: 0.7068
Epoch 7/43
105/105 [==============================] - 5s 52ms/step - loss: 0.7133 - val_loss: 0.7059
Epoch 8/43
105/105 [==============================] - 5s 51ms/step - loss: 0.7126 - val_loss: 0.7049
Epoch 9/43
105/105 [==============================] - 6s 53ms/step - loss: 0.7119 - val_loss: 0.7039
Epoch 10/43
105/105 [==============================] - 5s 52ms/step - loss: 0.7111 - val_loss: 0.7029
Epoch 11/43
105/105 [==============================] - 5s 52ms/step - loss: 0.7103 - val_loss: 0.7019
Epoch 12/43
105/105 [==============================] - 6s 53ms/step - loss: 0.7096 - val_loss: 0.7008
Epoch 13/43
105/105 [==============================] - 5s 52ms/step - loss: 0.7089 - val_loss: 0.6998
Epoch 14/43
105/105 [==============================] - 6s 53ms/step - loss: 0.7081 - val_loss: 0.6987
Epoch 15/43
105/105 [==============================] - 6s 52ms/step - loss: 0.7074 - val_loss: 0.6977
Epoch 16/43
105/105 [==============================] - 5s 52ms/step - loss: 0.7066 - val_loss: 0.6966
Epoch 17/43
105/105 [==============================] - 6s 53ms/step - loss: 0.7058 - val_loss: 0.6955
Epoch 18/43
105/105 [==============================] - 5s 52ms/step - loss: 0.7050 - val_loss: 0.6944
Epoch 19/43
105/105 [==============================] - 5s 52ms/step - loss: 0.7043 - val_loss: 0.6933
Epoch 20/43
105/105 [==============================] - 6s 53ms/step - loss: 0.7035 - val_loss: 0.6921
Epoch 21/43
105/105 [==============================] - 5s 52ms/step - loss: 0.7027 - val_loss: 0.6910
Epoch 22/43
105/105 [==============================] - 5s 52ms/step - loss: 0.7019 - val_loss: 0.6898
Epoch 23/43
105/105 [==============================] - 6s 53ms/step - loss: 0.7010 - val_loss: 0.6887
Epoch 24/43
105/105 [==============================] - 5s 52ms/step - loss: 0.7002 - val_loss: 0.6875
Epoch 25/43
105/105 [==============================] - 5s 52ms/step - loss: 0.6994 - val_loss: 0.6863
Epoch 26/43
105/105 [==============================] - 6s 53ms/step - loss: 0.6986 - val_loss: 0.6850
Epoch 27/43
105/105 [==============================] - 5s 52ms/step - loss: 0.6977 - val_loss: 0.6838
Epoch 28/43
105/105 [==============================] - 5s 52ms/step - loss: 0.6968 - val_loss: 0.6826
Epoch 29/43
105/105 [==============================] - 6s 53ms/step - loss: 0.6959 - val_loss: 0.6813
Epoch 30/43
105/105 [==============================] - 5s 52ms/step - loss: 0.6951 - val_loss: 0.6800
Epoch 31/43
105/105 [==============================] - 5s 52ms/step - loss: 0.6942 - val_loss: 0.6787
Epoch 32/43
105/105 [==============================] - 6s 53ms/step - loss: 0.6933 - val_loss: 0.6774
Epoch 33/43
105/105 [==============================] - 5s 52ms/step - loss: 0.6924 - val_loss: 0.6761
Epoch 34/43
105/105 [==============================] - 5s 52ms/step - loss: 0.6913 - val_loss: 0.6747
Epoch 35/43
105/105 [==============================] - 6s 53ms/step - loss: 0.6904 - val_loss: 0.6734
Epoch 36/43
105/105 [==============================] - 5s 52ms/step - loss: 0.6895 - val_loss: 0.6720
Epoch 37/43
105/105 [==============================] - 6s 53ms/step - loss: 0.6886 - val_loss: 0.6706
Epoch 38/43
105/105 [==============================] - 6s 52ms/step - loss: 0.6876 - val_loss: 0.6692
Epoch 39/43
105/105 [==============================] - 5s 52ms/step - loss: 0.6866 - val_loss: 0.6678
Epoch 40/43
105/105 [==============================] - 6s 53ms/step - loss: 0.6857 - val_loss: 0.6663
Epoch 41/43
105/105 [==============================] - 6s 52ms/step - loss: 0.6846 - val_loss: 0.6649
Epoch 42/43
105/105 [==============================] - 5s 52ms/step - loss: 0.6836 - val_loss: 0.6634
Epoch 43/43
105/105 [==============================] - 6s 54ms/step - loss: 0.6827 - val_loss: 0.6620
Execution time:  245.54612040519714
LSTM:
Mean Absolute Error: 0.6699
Root Mean Square Error: 0.9645
Mean Square Error: 0.9303

Train RMSE: 0.965
Train MSE: 0.930
Train MAE: 0.670
###########################

MODEL:  LSTM
sequence:  12h
units:  43
dropout1:  0.40519643149940265
dropout2:  0.3312343747027119
optimizer: adadelta
activationDense: sigmoid
epochs: 56
batchsize: 11
validation_split: 0.1
Model: &#34;sequential_42&#34;
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
lstm_84 (LSTM)               (None, 72, 43)            7740      
_________________________________________________________________
dropout_84 (Dropout)         (None, 72, 43)            0         
_________________________________________________________________
lstm_85 (LSTM)               (None, 72, 43)            14964     
_________________________________________________________________
dropout_85 (Dropout)         (None, 72, 43)            0         
_________________________________________________________________
time_distributed_42 (TimeDis (None, 72, 1)             44        
=================================================================
Total params: 22,748
Trainable params: 22,748
Non-trainable params: 0
_________________________________________________________________
Epoch 1/56
321/321 [==============================] - 15s 48ms/step - loss: 0.8981 - val_loss: 1.3030
Epoch 2/56
321/321 [==============================] - 14s 45ms/step - loss: 0.8978 - val_loss: 1.3023
Epoch 3/56
321/321 [==============================] - 14s 44ms/step - loss: 0.8975 - val_loss: 1.3015
Epoch 4/56
321/321 [==============================] - 14s 44ms/step - loss: 0.8972 - val_loss: 1.3006
Epoch 5/56
321/321 [==============================] - 14s 44ms/step - loss: 0.8968 - val_loss: 1.2998
Epoch 6/56
321/321 [==============================] - 14s 44ms/step - loss: 0.8964 - val_loss: 1.2988
Epoch 7/56
321/321 [==============================] - 14s 44ms/step - loss: 0.8960 - val_loss: 1.2979
Epoch 8/56
321/321 [==============================] - 14s 44ms/step - loss: 0.8956 - val_loss: 1.2969
Epoch 9/56
321/321 [==============================] - 14s 44ms/step - loss: 0.8952 - val_loss: 1.2959
Epoch 10/56
321/321 [==============================] - 14s 44ms/step - loss: 0.8947 - val_loss: 1.2948
Epoch 11/56
321/321 [==============================] - 14s 44ms/step - loss: 0.8942 - val_loss: 1.2937
Epoch 12/56
321/321 [==============================] - 14s 44ms/step - loss: 0.8938 - val_loss: 1.2925
Epoch 13/56
321/321 [==============================] - 14s 44ms/step - loss: 0.8932 - val_loss: 1.2914
Epoch 14/56
321/321 [==============================] - 14s 44ms/step - loss: 0.8927 - val_loss: 1.2901
Epoch 15/56
321/321 [==============================] - 14s 43ms/step - loss: 0.8922 - val_loss: 1.2889
Epoch 16/56
321/321 [==============================] - 14s 44ms/step - loss: 0.8917 - val_loss: 1.2876
Epoch 17/56
321/321 [==============================] - 14s 44ms/step - loss: 0.8910 - val_loss: 1.2862
Epoch 18/56
321/321 [==============================] - 14s 44ms/step - loss: 0.8905 - val_loss: 1.2848
Epoch 19/56
321/321 [==============================] - 14s 44ms/step - loss: 0.8899 - val_loss: 1.2834
Epoch 20/56
321/321 [==============================] - 14s 44ms/step - loss: 0.8892 - val_loss: 1.2819
Epoch 21/56
321/321 [==============================] - 14s 43ms/step - loss: 0.8885 - val_loss: 1.2803
Epoch 22/56
321/321 [==============================] - 14s 44ms/step - loss: 0.8878 - val_loss: 1.2787
Epoch 23/56
321/321 [==============================] - 14s 43ms/step - loss: 0.8871 - val_loss: 1.2771
Epoch 24/56
321/321 [==============================] - 14s 44ms/step - loss: 0.8864 - val_loss: 1.2753
Epoch 25/56
321/321 [==============================] - 14s 44ms/step - loss: 0.8856 - val_loss: 1.2736
Epoch 26/56
321/321 [==============================] - 14s 44ms/step - loss: 0.8848 - val_loss: 1.2717
Epoch 27/56
321/321 [==============================] - 14s 44ms/step - loss: 0.8840 - val_loss: 1.2698
Epoch 28/56
321/321 [==============================] - 14s 44ms/step - loss: 0.8832 - val_loss: 1.2678
Epoch 29/56
321/321 [==============================] - 14s 44ms/step - loss: 0.8823 - val_loss: 1.2658
Epoch 30/56
321/321 [==============================] - 14s 44ms/step - loss: 0.8813 - val_loss: 1.2636
Epoch 31/56
321/321 [==============================] - 14s 43ms/step - loss: 0.8804 - val_loss: 1.2614
Epoch 32/56
321/321 [==============================] - 14s 44ms/step - loss: 0.8794 - val_loss: 1.2591
Epoch 33/56
321/321 [==============================] - 14s 44ms/step - loss: 0.8784 - val_loss: 1.2567
Epoch 34/56
321/321 [==============================] - 14s 44ms/step - loss: 0.8772 - val_loss: 1.2543
Epoch 35/56
321/321 [==============================] - 14s 44ms/step - loss: 0.8761 - val_loss: 1.2517
Epoch 36/56
321/321 [==============================] - 14s 44ms/step - loss: 0.8750 - val_loss: 1.2491
Epoch 37/56
321/321 [==============================] - 14s 44ms/step - loss: 0.8737 - val_loss: 1.2463
Epoch 38/56
321/321 [==============================] - 14s 44ms/step - loss: 0.8725 - val_loss: 1.2435
Epoch 39/56
321/321 [==============================] - 14s 44ms/step - loss: 0.8712 - val_loss: 1.2406
Epoch 40/56
321/321 [==============================] - 14s 43ms/step - loss: 0.8698 - val_loss: 1.2376
Epoch 41/56
321/321 [==============================] - 14s 44ms/step - loss: 0.8685 - val_loss: 1.2345
Epoch 42/56
321/321 [==============================] - 14s 44ms/step - loss: 0.8670 - val_loss: 1.2312
Epoch 43/56
321/321 [==============================] - 14s 44ms/step - loss: 0.8655 - val_loss: 1.2280
Epoch 44/56
321/321 [==============================] - 14s 44ms/step - loss: 0.8639 - val_loss: 1.2246
Epoch 45/56
321/321 [==============================] - 14s 44ms/step - loss: 0.8623 - val_loss: 1.2211
Epoch 46/56
321/321 [==============================] - 14s 44ms/step - loss: 0.8606 - val_loss: 1.2175
Epoch 47/56
321/321 [==============================] - 14s 44ms/step - loss: 0.8590 - val_loss: 1.2139
Epoch 48/56
321/321 [==============================] - 14s 44ms/step - loss: 0.8572 - val_loss: 1.2102
Epoch 49/56
321/321 [==============================] - 14s 44ms/step - loss: 0.8553 - val_loss: 1.2064
Epoch 50/56
321/321 [==============================] - 14s 44ms/step - loss: 0.8535 - val_loss: 1.2026
Epoch 51/56
321/321 [==============================] - 14s 44ms/step - loss: 0.8516 - val_loss: 1.1987
Epoch 52/56
321/321 [==============================] - 14s 45ms/step - loss: 0.8497 - val_loss: 1.1947
Epoch 53/56
321/321 [==============================] - 14s 44ms/step - loss: 0.8477 - val_loss: 1.1907
Epoch 54/56
321/321 [==============================] - 14s 44ms/step - loss: 0.8456 - val_loss: 1.1867
Epoch 55/56
321/321 [==============================] - 14s 44ms/step - loss: 0.8436 - val_loss: 1.1826
Epoch 56/56
321/321 [==============================] - 14s 44ms/step - loss: 0.8416 - val_loss: 1.1785
Execution time:  797.0529072284698
LSTM:
Mean Absolute Error: 0.8564
Root Mean Square Error: 1.0514
Mean Square Error: 1.1054

Train RMSE: 1.051
Train MSE: 1.105
Train MAE: 0.856
###########################

MODEL:  LSTM
sequence:  12h
units:  45
dropout1:  0.11814836227952394
dropout2:  0.24325404382648977
optimizer: adadelta
activationDense: sigmoid
epochs: 43
batchsize: 30
validation_split: 0.2
Model: &#34;sequential_43&#34;
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
lstm_86 (LSTM)               (None, 72, 45)            8460      
_________________________________________________________________
dropout_86 (Dropout)         (None, 72, 45)            0         
_________________________________________________________________
lstm_87 (LSTM)               (None, 72, 45)            16380     
_________________________________________________________________
dropout_87 (Dropout)         (None, 72, 45)            0         
_________________________________________________________________
time_distributed_43 (TimeDis (None, 72, 1)             46        
=================================================================
Total params: 24,886
Trainable params: 24,886
Non-trainable params: 0
_________________________________________________________________
Epoch 1/43
105/105 [==============================] - 6s 60ms/step - loss: 0.8886 - val_loss: 1.1423
Epoch 2/43
105/105 [==============================] - 5s 52ms/step - loss: 0.8885 - val_loss: 1.1420
Epoch 3/43
105/105 [==============================] - 5s 52ms/step - loss: 0.8884 - val_loss: 1.1418
Epoch 4/43
105/105 [==============================] - 6s 52ms/step - loss: 0.8882 - val_loss: 1.1416
Epoch 5/43
105/105 [==============================] - 5s 52ms/step - loss: 0.8881 - val_loss: 1.1413
Epoch 6/43
105/105 [==============================] - 5s 52ms/step - loss: 0.8879 - val_loss: 1.1410
Epoch 7/43
105/105 [==============================] - 6s 53ms/step - loss: 0.8877 - val_loss: 1.1407
Epoch 8/43
105/105 [==============================] - 6s 53ms/step - loss: 0.8876 - val_loss: 1.1405
Epoch 9/43
105/105 [==============================] - 5s 52ms/step - loss: 0.8874 - val_loss: 1.1402
Epoch 10/43
105/105 [==============================] - 6s 54ms/step - loss: 0.8872 - val_loss: 1.1399
Epoch 11/43
105/105 [==============================] - 5s 52ms/step - loss: 0.8870 - val_loss: 1.1396
Epoch 12/43
105/105 [==============================] - 5s 52ms/step - loss: 0.8868 - val_loss: 1.1393
Epoch 13/43
105/105 [==============================] - 6s 53ms/step - loss: 0.8867 - val_loss: 1.1390
Epoch 14/43
105/105 [==============================] - 5s 51ms/step - loss: 0.8865 - val_loss: 1.1387
Epoch 15/43
105/105 [==============================] - 5s 51ms/step - loss: 0.8863 - val_loss: 1.1384
Epoch 16/43
105/105 [==============================] - 5s 52ms/step - loss: 0.8861 - val_loss: 1.1381
Epoch 17/43
105/105 [==============================] - 5s 52ms/step - loss: 0.8859 - val_loss: 1.1377
Epoch 18/43
105/105 [==============================] - 5s 51ms/step - loss: 0.8857 - val_loss: 1.1374
Epoch 19/43
105/105 [==============================] - 6s 53ms/step - loss: 0.8855 - val_loss: 1.1371
Epoch 20/43
105/105 [==============================] - 5s 51ms/step - loss: 0.8853 - val_loss: 1.1368
Epoch 21/43
105/105 [==============================] - 5s 52ms/step - loss: 0.8851 - val_loss: 1.1364
Epoch 22/43
105/105 [==============================] - 6s 52ms/step - loss: 0.8849 - val_loss: 1.1361
Epoch 23/43
105/105 [==============================] - 5s 51ms/step - loss: 0.8847 - val_loss: 1.1358
Epoch 24/43
105/105 [==============================] - 5s 52ms/step - loss: 0.8845 - val_loss: 1.1354
Epoch 25/43
105/105 [==============================] - 6s 53ms/step - loss: 0.8843 - val_loss: 1.1351
Epoch 26/43
105/105 [==============================] - 5s 52ms/step - loss: 0.8841 - val_loss: 1.1347
Epoch 27/43
105/105 [==============================] - 6s 53ms/step - loss: 0.8839 - val_loss: 1.1344
Epoch 28/43
105/105 [==============================] - 6s 53ms/step - loss: 0.8837 - val_loss: 1.1340
Epoch 29/43
105/105 [==============================] - 5s 52ms/step - loss: 0.8834 - val_loss: 1.1336
Epoch 30/43
105/105 [==============================] - 6s 53ms/step - loss: 0.8832 - val_loss: 1.1333
Epoch 31/43
105/105 [==============================] - 5s 52ms/step - loss: 0.8830 - val_loss: 1.1329
Epoch 32/43
105/105 [==============================] - 5s 52ms/step - loss: 0.8828 - val_loss: 1.1325
Epoch 33/43
105/105 [==============================] - 6s 53ms/step - loss: 0.8825 - val_loss: 1.1322
Epoch 34/43
105/105 [==============================] - 5s 52ms/step - loss: 0.8823 - val_loss: 1.1318
Epoch 35/43
105/105 [==============================] - 5s 52ms/step - loss: 0.8821 - val_loss: 1.1314
Epoch 36/43
105/105 [==============================] - 6s 53ms/step - loss: 0.8819 - val_loss: 1.1310
Epoch 37/43
105/105 [==============================] - 5s 52ms/step - loss: 0.8816 - val_loss: 1.1306
Epoch 38/43
105/105 [==============================] - 5s 52ms/step - loss: 0.8814 - val_loss: 1.1302
Epoch 39/43
105/105 [==============================] - 6s 53ms/step - loss: 0.8812 - val_loss: 1.1299
Epoch 40/43
105/105 [==============================] - 5s 52ms/step - loss: 0.8809 - val_loss: 1.1295
Epoch 41/43
105/105 [==============================] - 5s 52ms/step - loss: 0.8807 - val_loss: 1.1290
Epoch 42/43
105/105 [==============================] - 6s 53ms/step - loss: 0.8804 - val_loss: 1.1286
Epoch 43/43
105/105 [==============================] - 5s 52ms/step - loss: 0.8802 - val_loss: 1.1282
Execution time:  244.50229263305664
LSTM:
Mean Absolute Error: 0.9229
Root Mean Square Error: 1.1109
Mean Square Error: 1.2341

Train RMSE: 1.111
Train MSE: 1.234
Train MAE: 0.923
###########################

MODEL:  LSTM
sequence:  12h
units:  43
dropout1:  0.40519643149940265
dropout2:  0.3312343747027119
optimizer: adamax
activationDense: tanh
epochs: 56
batchsize: 11
validation_split: 0.1
Model: &#34;sequential_44&#34;
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
lstm_88 (LSTM)               (None, 72, 43)            7740      
_________________________________________________________________
dropout_88 (Dropout)         (None, 72, 43)            0         
_________________________________________________________________
lstm_89 (LSTM)               (None, 72, 43)            14964     
_________________________________________________________________
dropout_89 (Dropout)         (None, 72, 43)            0         
_________________________________________________________________
time_distributed_44 (TimeDis (None, 72, 1)             44        
=================================================================
Total params: 22,748
Trainable params: 22,748
Non-trainable params: 0
_________________________________________________________________
Epoch 1/56
321/321 [==============================] - 15s 47ms/step - loss: 0.5649 - val_loss: 0.4087
Epoch 2/56
321/321 [==============================] - 14s 45ms/step - loss: 0.5301 - val_loss: 0.3877
Epoch 3/56
321/321 [==============================] - 15s 45ms/step - loss: 0.5221 - val_loss: 0.3750
Epoch 4/56
321/321 [==============================] - 14s 44ms/step - loss: 0.5170 - val_loss: 0.3650
Epoch 5/56
321/321 [==============================] - 14s 44ms/step - loss: 0.5117 - val_loss: 0.3480
Epoch 6/56
321/321 [==============================] - 14s 44ms/step - loss: 0.5056 - val_loss: 0.3259
Epoch 7/56
321/321 [==============================] - 14s 44ms/step - loss: 0.4999 - val_loss: 0.2993
Epoch 8/56
321/321 [==============================] - 14s 44ms/step - loss: 0.4955 - val_loss: 0.2917
Epoch 9/56
321/321 [==============================] - 14s 44ms/step - loss: 0.4921 - val_loss: 0.2906
Epoch 10/56
321/321 [==============================] - 14s 44ms/step - loss: 0.4889 - val_loss: 0.2811
Epoch 11/56
321/321 [==============================] - 14s 44ms/step - loss: 0.4867 - val_loss: 0.2694
Epoch 12/56
321/321 [==============================] - 14s 45ms/step - loss: 0.4834 - val_loss: 0.2694
Epoch 13/56
321/321 [==============================] - 14s 45ms/step - loss: 0.4824 - val_loss: 0.2673
Epoch 14/56
321/321 [==============================] - 14s 44ms/step - loss: 0.4804 - val_loss: 0.2701
Epoch 15/56
321/321 [==============================] - 14s 44ms/step - loss: 0.4801 - val_loss: 0.2637
Epoch 16/56
321/321 [==============================] - 14s 44ms/step - loss: 0.4785 - val_loss: 0.2637
Epoch 17/56
321/321 [==============================] - 14s 44ms/step - loss: 0.4780 - val_loss: 0.2626
Epoch 18/56
321/321 [==============================] - 14s 44ms/step - loss: 0.4763 - val_loss: 0.2656
Epoch 19/56
321/321 [==============================] - 14s 44ms/step - loss: 0.4760 - val_loss: 0.2615
Epoch 20/56
321/321 [==============================] - 14s 44ms/step - loss: 0.4750 - val_loss: 0.2630
Epoch 21/56
321/321 [==============================] - 14s 44ms/step - loss: 0.4744 - val_loss: 0.2641
Epoch 22/56
321/321 [==============================] - 14s 44ms/step - loss: 0.4741 - val_loss: 0.2669
Epoch 23/56
321/321 [==============================] - 14s 44ms/step - loss: 0.4736 - val_loss: 0.2611
Epoch 24/56
321/321 [==============================] - 14s 44ms/step - loss: 0.4709 - val_loss: 0.2587
Epoch 25/56
321/321 [==============================] - 14s 44ms/step - loss: 0.4702 - val_loss: 0.2602
Epoch 26/56
321/321 [==============================] - 14s 44ms/step - loss: 0.4712 - val_loss: 0.2595
Epoch 27/56
321/321 [==============================] - 14s 44ms/step - loss: 0.4696 - val_loss: 0.2605
Epoch 28/56
321/321 [==============================] - 14s 44ms/step - loss: 0.4694 - val_loss: 0.2564
Epoch 29/56
321/321 [==============================] - 14s 44ms/step - loss: 0.4680 - val_loss: 0.2574
Epoch 30/56
321/321 [==============================] - 14s 44ms/step - loss: 0.4676 - val_loss: 0.2545
Epoch 31/56
321/321 [==============================] - 14s 44ms/step - loss: 0.4660 - val_loss: 0.2524
Epoch 32/56
321/321 [==============================] - 14s 44ms/step - loss: 0.4657 - val_loss: 0.2553
Epoch 33/56
321/321 [==============================] - 14s 44ms/step - loss: 0.4653 - val_loss: 0.2545
Epoch 34/56
321/321 [==============================] - 14s 44ms/step - loss: 0.4654 - val_loss: 0.2559
Epoch 35/56
321/321 [==============================] - 14s 44ms/step - loss: 0.4647 - val_loss: 0.2557
Epoch 36/56
321/321 [==============================] - 14s 44ms/step - loss: 0.4629 - val_loss: 0.2550
Epoch 37/56
321/321 [==============================] - 15s 46ms/step - loss: 0.4619 - val_loss: 0.2541
Epoch 38/56
321/321 [==============================] - 14s 44ms/step - loss: 0.4607 - val_loss: 0.2542
Epoch 39/56
321/321 [==============================] - 14s 44ms/step - loss: 0.4598 - val_loss: 0.2528
Epoch 40/56
321/321 [==============================] - 14s 44ms/step - loss: 0.4575 - val_loss: 0.2559
Epoch 41/56
321/321 [==============================] - 14s 44ms/step - loss: 0.4584 - val_loss: 0.2549
Epoch 42/56
321/321 [==============================] - 14s 44ms/step - loss: 0.4569 - val_loss: 0.2493
Epoch 43/56
321/321 [==============================] - 14s 44ms/step - loss: 0.4528 - val_loss: 0.2511
Epoch 44/56
321/321 [==============================] - 14s 44ms/step - loss: 0.4528 - val_loss: 0.2523
Epoch 45/56
321/321 [==============================] - 14s 44ms/step - loss: 0.4520 - val_loss: 0.2507
Epoch 46/56
321/321 [==============================] - 14s 44ms/step - loss: 0.4511 - val_loss: 0.2496
Epoch 47/56
321/321 [==============================] - 14s 44ms/step - loss: 0.4491 - val_loss: 0.2487
Epoch 48/56
321/321 [==============================] - 14s 44ms/step - loss: 0.4485 - val_loss: 0.2515
Epoch 49/56
321/321 [==============================] - 14s 44ms/step - loss: 0.4485 - val_loss: 0.2446
Epoch 50/56
321/321 [==============================] - 14s 44ms/step - loss: 0.4469 - val_loss: 0.2486
Epoch 51/56
321/321 [==============================] - 14s 44ms/step - loss: 0.4463 - val_loss: 0.2487
Epoch 52/56
321/321 [==============================] - 14s 44ms/step - loss: 0.4440 - val_loss: 0.2503
Epoch 53/56
321/321 [==============================] - 14s 44ms/step - loss: 0.4461 - val_loss: 0.2493
Epoch 54/56
321/321 [==============================] - 14s 45ms/step - loss: 0.4438 - val_loss: 0.2494
Epoch 55/56
321/321 [==============================] - 14s 44ms/step - loss: 0.4434 - val_loss: 0.2486
Epoch 56/56
321/321 [==============================] - 14s 44ms/step - loss: 0.4417 - val_loss: 0.2452
Execution time:  803.3064453601837
LSTM:
Mean Absolute Error: 0.3466
Root Mean Square Error: 0.8337
Mean Square Error: 0.6950

Train RMSE: 0.834
Train MSE: 0.695
Train MAE: 0.347
###########################

MODEL:  LSTM
sequence:  12h
units:  45
dropout1:  0.11814836227952394
dropout2:  0.24325404382648977
optimizer: adamax
activationDense: tanh
epochs: 43
batchsize: 30
validation_split: 0.2
Model: &#34;sequential_45&#34;
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
lstm_90 (LSTM)               (None, 72, 45)            8460      
_________________________________________________________________
dropout_90 (Dropout)         (None, 72, 45)            0         
_________________________________________________________________
lstm_91 (LSTM)               (None, 72, 45)            16380     
_________________________________________________________________
dropout_91 (Dropout)         (None, 72, 45)            0         
_________________________________________________________________
time_distributed_45 (TimeDis (None, 72, 1)             46        
=================================================================
Total params: 24,886
Trainable params: 24,886
Non-trainable params: 0
_________________________________________________________________
Epoch 1/43
105/105 [==============================] - 6s 60ms/step - loss: 0.5907 - val_loss: 0.4297
Epoch 2/43
105/105 [==============================] - 6s 53ms/step - loss: 0.5322 - val_loss: 0.4223
Epoch 3/43
105/105 [==============================] - 5s 52ms/step - loss: 0.5243 - val_loss: 0.4158
Epoch 4/43
105/105 [==============================] - 5s 52ms/step - loss: 0.5193 - val_loss: 0.4109
Epoch 5/43
105/105 [==============================] - 6s 53ms/step - loss: 0.5155 - val_loss: 0.4074
Epoch 6/43
105/105 [==============================] - 5s 52ms/step - loss: 0.5122 - val_loss: 0.4045
Epoch 7/43
105/105 [==============================] - 5s 52ms/step - loss: 0.5097 - val_loss: 0.4020
Epoch 8/43
105/105 [==============================] - 6s 53ms/step - loss: 0.5075 - val_loss: 0.3998
Epoch 9/43
105/105 [==============================] - 5s 52ms/step - loss: 0.5049 - val_loss: 0.3978
Epoch 10/43
105/105 [==============================] - 5s 52ms/step - loss: 0.5026 - val_loss: 0.3959
Epoch 11/43
105/105 [==============================] - 6s 53ms/step - loss: 0.5005 - val_loss: 0.3942
Epoch 12/43
105/105 [==============================] - 6s 53ms/step - loss: 0.4985 - val_loss: 0.3923
Epoch 13/43
105/105 [==============================] - 6s 53ms/step - loss: 0.4969 - val_loss: 0.3907
Epoch 14/43
105/105 [==============================] - 6s 53ms/step - loss: 0.4952 - val_loss: 0.3893
Epoch 15/43
105/105 [==============================] - 5s 52ms/step - loss: 0.4938 - val_loss: 0.3878
Epoch 16/43
105/105 [==============================] - 6s 54ms/step - loss: 0.4927 - val_loss: 0.3860
Epoch 17/43
105/105 [==============================] - 5s 52ms/step - loss: 0.4916 - val_loss: 0.3846
Epoch 18/43
105/105 [==============================] - 5s 52ms/step - loss: 0.4902 - val_loss: 0.3834
Epoch 19/43
105/105 [==============================] - 6s 53ms/step - loss: 0.4887 - val_loss: 0.3820
Epoch 20/43
105/105 [==============================] - 5s 52ms/step - loss: 0.4875 - val_loss: 0.3809
Epoch 21/43
105/105 [==============================] - 5s 52ms/step - loss: 0.4853 - val_loss: 0.3796
Epoch 22/43
105/105 [==============================] - 6s 53ms/step - loss: 0.4839 - val_loss: 0.3787
Epoch 23/43
105/105 [==============================] - 6s 52ms/step - loss: 0.4813 - val_loss: 0.3776
Epoch 24/43
105/105 [==============================] - 6s 54ms/step - loss: 0.4819 - val_loss: 0.3774
Epoch 25/43
105/105 [==============================] - 6s 53ms/step - loss: 0.4759 - val_loss: 0.3759
Epoch 26/43
105/105 [==============================] - 5s 52ms/step - loss: 0.4772 - val_loss: 0.3754
Epoch 27/43
105/105 [==============================] - 5s 52ms/step - loss: 0.4739 - val_loss: 0.3747
Epoch 28/43
105/105 [==============================] - 6s 53ms/step - loss: 0.4722 - val_loss: 0.3741
Epoch 29/43
105/105 [==============================] - 6s 53ms/step - loss: 0.4710 - val_loss: 0.3739
Epoch 30/43
105/105 [==============================] - 5s 52ms/step - loss: 0.4703 - val_loss: 0.3737
Epoch 31/43
105/105 [==============================] - 6s 54ms/step - loss: 0.4693 - val_loss: 0.3736
Epoch 32/43
105/105 [==============================] - 5s 52ms/step - loss: 0.4680 - val_loss: 0.3737
Epoch 33/43
105/105 [==============================] - 6s 54ms/step - loss: 0.4669 - val_loss: 0.3739
Epoch 34/43
105/105 [==============================] - 6s 53ms/step - loss: 0.4658 - val_loss: 0.3742
Epoch 35/43
105/105 [==============================] - 5s 52ms/step - loss: 0.4646 - val_loss: 0.3746
Epoch 36/43
105/105 [==============================] - 6s 53ms/step - loss: 0.4632 - val_loss: 0.3750
Epoch 37/43
105/105 [==============================] - 5s 52ms/step - loss: 0.4617 - val_loss: 0.3754
Epoch 38/43
105/105 [==============================] - 5s 52ms/step - loss: 0.4603 - val_loss: 0.3757
Epoch 39/43
105/105 [==============================] - 6s 53ms/step - loss: 0.4587 - val_loss: 0.3761
Epoch 40/43
105/105 [==============================] - 5s 52ms/step - loss: 0.4583 - val_loss: 0.3765
Epoch 41/43
105/105 [==============================] - 5s 52ms/step - loss: 0.4590 - val_loss: 0.3769
Epoch 42/43
105/105 [==============================] - 6s 53ms/step - loss: 0.4563 - val_loss: 0.3771
Epoch 43/43
105/105 [==============================] - 5s 52ms/step - loss: 0.4542 - val_loss: 0.3774
Execution time:  246.59963583946228
LSTM:
Mean Absolute Error: 0.3159
Root Mean Square Error: 0.7866
Mean Square Error: 0.6188

Train RMSE: 0.787
Train MSE: 0.619
Train MAE: 0.316
###########################

MODEL:  LSTM
sequence:  12h
units:  43
dropout1:  0.40519643149940265
dropout2:  0.3312343747027119
optimizer: adamax
activationDense: sigmoid
epochs: 56
batchsize: 11
validation_split: 0.1
Model: &#34;sequential_46&#34;
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
lstm_92 (LSTM)               (None, 72, 43)            7740      
_________________________________________________________________
dropout_92 (Dropout)         (None, 72, 43)            0         
_________________________________________________________________
lstm_93 (LSTM)               (None, 72, 43)            14964     
_________________________________________________________________
dropout_93 (Dropout)         (None, 72, 43)            0         
_________________________________________________________________
time_distributed_46 (TimeDis (None, 72, 1)             44        
=================================================================
Total params: 22,748
Trainable params: 22,748
Non-trainable params: 0
_________________________________________________________________
Epoch 1/56
321/321 [==============================] - 15s 47ms/step - loss: 0.7319 - val_loss: 0.8397
Epoch 2/56
321/321 [==============================] - 14s 44ms/step - loss: 0.6669 - val_loss: 0.8247
Epoch 3/56
321/321 [==============================] - 14s 44ms/step - loss: 0.6545 - val_loss: 0.8184
Epoch 4/56
321/321 [==============================] - 14s 44ms/step - loss: 0.6492 - val_loss: 0.8150
Epoch 5/56
321/321 [==============================] - 14s 45ms/step - loss: 0.6455 - val_loss: 0.8129
Epoch 6/56
321/321 [==============================] - 14s 44ms/step - loss: 0.6419 - val_loss: 0.8114
Epoch 7/56
321/321 [==============================] - 14s 44ms/step - loss: 0.6400 - val_loss: 0.8104
Epoch 8/56
321/321 [==============================] - 14s 45ms/step - loss: 0.6385 - val_loss: 0.8096
Epoch 9/56
321/321 [==============================] - 14s 45ms/step - loss: 0.6373 - val_loss: 0.8090
Epoch 10/56
321/321 [==============================] - 14s 45ms/step - loss: 0.6363 - val_loss: 0.8084
Epoch 11/56
321/321 [==============================] - 14s 45ms/step - loss: 0.6355 - val_loss: 0.8079
Epoch 12/56
321/321 [==============================] - 14s 45ms/step - loss: 0.6350 - val_loss: 0.8075
Epoch 13/56
321/321 [==============================] - 14s 45ms/step - loss: 0.6340 - val_loss: 0.8072
Epoch 14/56
321/321 [==============================] - 14s 45ms/step - loss: 0.6333 - val_loss: 0.8068
Epoch 15/56
321/321 [==============================] - 14s 45ms/step - loss: 0.6329 - val_loss: 0.8066
Epoch 16/56
321/321 [==============================] - 14s 45ms/step - loss: 0.6321 - val_loss: 0.8063
Epoch 17/56
321/321 [==============================] - 14s 45ms/step - loss: 0.6315 - val_loss: 0.8061
Epoch 18/56
321/321 [==============================] - 14s 45ms/step - loss: 0.6307 - val_loss: 0.8059
Epoch 19/56
321/321 [==============================] - 14s 45ms/step - loss: 0.6298 - val_loss: 0.8057
Epoch 20/56
321/321 [==============================] - 14s 44ms/step - loss: 0.6280 - val_loss: 0.8056
Epoch 21/56
321/321 [==============================] - 14s 45ms/step - loss: 0.6277 - val_loss: 0.8055
Epoch 22/56
321/321 [==============================] - 14s 45ms/step - loss: 0.6266 - val_loss: 0.8053
Epoch 23/56
321/321 [==============================] - 14s 45ms/step - loss: 0.6258 - val_loss: 0.8053
Epoch 24/56
321/321 [==============================] - 14s 45ms/step - loss: 0.6257 - val_loss: 0.8052
Epoch 25/56
321/321 [==============================] - 14s 45ms/step - loss: 0.6248 - val_loss: 0.8051
Epoch 26/56
321/321 [==============================] - 15s 45ms/step - loss: 0.6243 - val_loss: 0.8050
Epoch 27/56
321/321 [==============================] - 14s 45ms/step - loss: 0.6231 - val_loss: 0.8049
Epoch 28/56
321/321 [==============================] - 14s 45ms/step - loss: 0.6230 - val_loss: 0.8049
Epoch 29/56
321/321 [==============================] - 14s 45ms/step - loss: 0.6222 - val_loss: 0.8048
Epoch 30/56
321/321 [==============================] - 14s 44ms/step - loss: 0.6220 - val_loss: 0.8048
Epoch 31/56
321/321 [==============================] - 14s 44ms/step - loss: 0.6212 - val_loss: 0.8047
Epoch 32/56
321/321 [==============================] - 14s 44ms/step - loss: 0.6208 - val_loss: 0.8047
Epoch 33/56
321/321 [==============================] - 14s 44ms/step - loss: 0.6203 - val_loss: 0.8046
Epoch 34/56
321/321 [==============================] - 14s 45ms/step - loss: 0.6196 - val_loss: 0.8046
Epoch 35/56
321/321 [==============================] - 14s 44ms/step - loss: 0.6191 - val_loss: 0.8045
Epoch 36/56
321/321 [==============================] - 14s 45ms/step - loss: 0.6185 - val_loss: 0.8045
Epoch 37/56
321/321 [==============================] - 14s 44ms/step - loss: 0.6182 - val_loss: 0.8045
Epoch 38/56
321/321 [==============================] - 14s 45ms/step - loss: 0.6176 - val_loss: 0.8045
Epoch 39/56
321/321 [==============================] - 14s 45ms/step - loss: 0.6162 - val_loss: 0.8044
Epoch 40/56
321/321 [==============================] - 14s 44ms/step - loss: 0.6160 - val_loss: 0.8044
Epoch 41/56
321/321 [==============================] - 14s 45ms/step - loss: 0.6153 - val_loss: 0.8044
Epoch 42/56
321/321 [==============================] - 14s 44ms/step - loss: 0.6147 - val_loss: 0.8043
Epoch 43/56
321/321 [==============================] - 14s 44ms/step - loss: 0.6136 - val_loss: 0.8043
Epoch 44/56
321/321 [==============================] - 14s 44ms/step - loss: 0.6126 - val_loss: 0.8043
Epoch 45/56
321/321 [==============================] - 14s 44ms/step - loss: 0.6125 - val_loss: 0.8043
Epoch 46/56
321/321 [==============================] - 14s 45ms/step - loss: 0.6114 - val_loss: 0.8043
Epoch 47/56
321/321 [==============================] - 14s 45ms/step - loss: 0.6105 - val_loss: 0.8043
Epoch 48/56
321/321 [==============================] - 14s 44ms/step - loss: 0.6096 - val_loss: 0.8043
Epoch 49/56
321/321 [==============================] - 14s 44ms/step - loss: 0.6089 - val_loss: 0.8042
Epoch 50/56
321/321 [==============================] - 14s 44ms/step - loss: 0.6091 - val_loss: 0.8042
Epoch 51/56
321/321 [==============================] - 14s 44ms/step - loss: 0.6082 - val_loss: 0.8042
Epoch 52/56
321/321 [==============================] - 14s 44ms/step - loss: 0.6083 - val_loss: 0.8042
Epoch 53/56
321/321 [==============================] - 14s 44ms/step - loss: 0.6068 - val_loss: 0.8042
Epoch 54/56
321/321 [==============================] - 14s 44ms/step - loss: 0.6058 - val_loss: 0.8042
Epoch 55/56
321/321 [==============================] - 15s 46ms/step - loss: 0.6048 - val_loss: 0.8042
Epoch 56/56
321/321 [==============================] - 14s 44ms/step - loss: 0.6048 - val_loss: 0.8042
Execution time:  809.4667508602142
LSTM:
Mean Absolute Error: 0.5721
Root Mean Square Error: 0.8523
Mean Square Error: 0.7263

Train RMSE: 0.852
Train MSE: 0.726
Train MAE: 0.572
###########################

MODEL:  LSTM
sequence:  12h
units:  45
dropout1:  0.11814836227952394
dropout2:  0.24325404382648977
optimizer: adamax
activationDense: sigmoid
epochs: 43
batchsize: 30
validation_split: 0.2
Model: &#34;sequential_47&#34;
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
lstm_94 (LSTM)               (None, 72, 45)            8460      
_________________________________________________________________
dropout_94 (Dropout)         (None, 72, 45)            0         
_________________________________________________________________
lstm_95 (LSTM)               (None, 72, 45)            16380     
_________________________________________________________________
dropout_95 (Dropout)         (None, 72, 45)            0         
_________________________________________________________________
time_distributed_47 (TimeDis (None, 72, 1)             46        
=================================================================
Total params: 24,886
Trainable params: 24,886
Non-trainable params: 0
_________________________________________________________________
Epoch 1/43
105/105 [==============================] - 6s 62ms/step - loss: 0.8041 - val_loss: 0.8534
Epoch 2/43
105/105 [==============================] - 5s 52ms/step - loss: 0.6852 - val_loss: 0.7840
Epoch 3/43
105/105 [==============================] - 5s 52ms/step - loss: 0.6667 - val_loss: 0.7691
Epoch 4/43
105/105 [==============================] - 6s 53ms/step - loss: 0.6586 - val_loss: 0.7611
Epoch 5/43
105/105 [==============================] - 5s 52ms/step - loss: 0.6532 - val_loss: 0.7567
Epoch 6/43
105/105 [==============================] - 5s 52ms/step - loss: 0.6503 - val_loss: 0.7534
Epoch 7/43
105/105 [==============================] - 6s 53ms/step - loss: 0.6479 - val_loss: 0.7510
Epoch 8/43
105/105 [==============================] - 5s 52ms/step - loss: 0.6464 - val_loss: 0.7491
Epoch 9/43
105/105 [==============================] - 5s 52ms/step - loss: 0.6446 - val_loss: 0.7477
Epoch 10/43
105/105 [==============================] - 6s 54ms/step - loss: 0.6435 - val_loss: 0.7461
Epoch 11/43
105/105 [==============================] - 5s 52ms/step - loss: 0.6420 - val_loss: 0.7449
Epoch 12/43
105/105 [==============================] - 6s 53ms/step - loss: 0.6406 - val_loss: 0.7439
Epoch 13/43
105/105 [==============================] - 6s 53ms/step - loss: 0.6394 - val_loss: 0.7429
Epoch 14/43
105/105 [==============================] - 6s 53ms/step - loss: 0.6384 - val_loss: 0.7420
Epoch 15/43
105/105 [==============================] - 6s 54ms/step - loss: 0.6377 - val_loss: 0.7411
Epoch 16/43
105/105 [==============================] - 6s 53ms/step - loss: 0.6369 - val_loss: 0.7401
Epoch 17/43
105/105 [==============================] - 5s 52ms/step - loss: 0.6361 - val_loss: 0.7392
Epoch 18/43
105/105 [==============================] - 6s 54ms/step - loss: 0.6352 - val_loss: 0.7384
Epoch 19/43
105/105 [==============================] - 5s 52ms/step - loss: 0.6345 - val_loss: 0.7377
Epoch 20/43
105/105 [==============================] - 5s 52ms/step - loss: 0.6338 - val_loss: 0.7370
Epoch 21/43
105/105 [==============================] - 6s 53ms/step - loss: 0.6331 - val_loss: 0.7363
Epoch 22/43
105/105 [==============================] - 5s 52ms/step - loss: 0.6326 - val_loss: 0.7357
Epoch 23/43
105/105 [==============================] - 5s 52ms/step - loss: 0.6320 - val_loss: 0.7352
Epoch 24/43
105/105 [==============================] - 6s 53ms/step - loss: 0.6313 - val_loss: 0.7345
Epoch 25/43
105/105 [==============================] - 6s 53ms/step - loss: 0.6309 - val_loss: 0.7344
Epoch 26/43
105/105 [==============================] - 5s 52ms/step - loss: 0.6304 - val_loss: 0.7337
Epoch 27/43
105/105 [==============================] - 6s 53ms/step - loss: 0.6298 - val_loss: 0.7335
Epoch 28/43
105/105 [==============================] - 5s 52ms/step - loss: 0.6294 - val_loss: 0.7335
Epoch 29/43
105/105 [==============================] - 6s 53ms/step - loss: 0.6287 - val_loss: 0.7337
Epoch 30/43
105/105 [==============================] - 6s 53ms/step - loss: 0.6283 - val_loss: 0.7330
Epoch 31/43
105/105 [==============================] - 5s 52ms/step - loss: 0.6278 - val_loss: 0.7334
Epoch 32/43
105/105 [==============================] - 6s 53ms/step - loss: 0.6276 - val_loss: 0.7325
Epoch 33/43
105/105 [==============================] - 6s 53ms/step - loss: 0.6269 - val_loss: 0.7330
Epoch 34/43
105/105 [==============================] - 6s 53ms/step - loss: 0.6273 - val_loss: 0.7321
Epoch 35/43
105/105 [==============================] - 6s 54ms/step - loss: 0.6270 - val_loss: 0.7332
Epoch 36/43
105/105 [==============================] - 6s 53ms/step - loss: 0.6268 - val_loss: 0.7323
Epoch 37/43
105/105 [==============================] - 6s 53ms/step - loss: 0.6259 - val_loss: 0.7330
Epoch 38/43
105/105 [==============================] - 6s 54ms/step - loss: 0.6263 - val_loss: 0.7324
Epoch 39/43
105/105 [==============================] - 5s 52ms/step - loss: 0.6257 - val_loss: 0.7321
Epoch 40/43
105/105 [==============================] - 6s 53ms/step - loss: 0.6252 - val_loss: 0.7330
Epoch 41/43
105/105 [==============================] - 6s 54ms/step - loss: 0.6260 - val_loss: 0.7320
Epoch 42/43
105/105 [==============================] - 6s 53ms/step - loss: 0.6253 - val_loss: 0.7322
Epoch 43/43
105/105 [==============================] - 5s 52ms/step - loss: 0.6247 - val_loss: 0.7320
Execution time:  247.14954662322998
LSTM:
Mean Absolute Error: 0.5647
Root Mean Square Error: 0.8230
Mean Square Error: 0.6773

Train RMSE: 0.823
Train MSE: 0.677
Train MAE: 0.565
###########################

MODEL:  LSTM
sequence:  1d
units:  43
dropout1:  0.40519643149940265
dropout2:  0.3312343747027119
optimizer: adam
activationDense: tanh
epochs: 56
batchsize: 11
validation_split: 0.1
Model: &#34;sequential_48&#34;
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
lstm_96 (LSTM)               (None, 144, 43)           7740      
_________________________________________________________________
dropout_96 (Dropout)         (None, 144, 43)           0         
_________________________________________________________________
lstm_97 (LSTM)               (None, 144, 43)           14964     
_________________________________________________________________
dropout_97 (Dropout)         (None, 144, 43)           0         
_________________________________________________________________
time_distributed_48 (TimeDis (None, 144, 1)            44        
=================================================================
Total params: 22,748
Trainable params: 22,748
Non-trainable params: 0
_________________________________________________________________
Epoch 1/56
315/315 [==============================] - 28s 90ms/step - loss: 0.6175 - val_loss: 0.4644
Epoch 2/56
315/315 [==============================] - 27s 86ms/step - loss: 0.5975 - val_loss: 0.4487
Epoch 3/56
315/315 [==============================] - 28s 87ms/step - loss: 0.5882 - val_loss: 0.4361
Epoch 4/56
315/315 [==============================] - 27s 87ms/step - loss: 0.5985 - val_loss: 0.4235
Epoch 5/56
315/315 [==============================] - 27s 86ms/step - loss: 0.5821 - val_loss: 0.3948
Epoch 6/56
315/315 [==============================] - 27s 86ms/step - loss: 0.5793 - val_loss: 0.3825
Epoch 7/56
315/315 [==============================] - 27s 86ms/step - loss: 0.5732 - val_loss: 0.4160
Epoch 8/56
315/315 [==============================] - 27s 87ms/step - loss: 0.5773 - val_loss: 0.4190
Epoch 9/56
315/315 [==============================] - 27s 86ms/step - loss: 0.5728 - val_loss: 0.3640
Epoch 10/56
315/315 [==============================] - 27s 87ms/step - loss: 0.5841 - val_loss: 0.4148
Epoch 11/56
315/315 [==============================] - 27s 87ms/step - loss: 0.5731 - val_loss: 0.3939
Epoch 12/56
315/315 [==============================] - 27s 87ms/step - loss: 0.5688 - val_loss: 0.3527
Epoch 13/56
315/315 [==============================] - 27s 87ms/step - loss: 0.5402 - val_loss: 0.3425
Epoch 14/56
315/315 [==============================] - 27s 87ms/step - loss: 0.5320 - val_loss: 0.3290
Epoch 15/56
315/315 [==============================] - 27s 87ms/step - loss: 0.5389 - val_loss: 0.3277
Epoch 16/56
315/315 [==============================] - 27s 86ms/step - loss: 0.5318 - val_loss: 0.3471
Epoch 17/56
315/315 [==============================] - 28s 87ms/step - loss: 0.5671 - val_loss: 0.4612
Epoch 18/56
315/315 [==============================] - 27s 87ms/step - loss: 0.5472 - val_loss: 0.3446
Epoch 19/56
315/315 [==============================] - 27s 86ms/step - loss: 0.5305 - val_loss: 0.3279
Epoch 20/56
315/315 [==============================] - 27s 87ms/step - loss: 0.5243 - val_loss: 0.3248
Epoch 21/56
315/315 [==============================] - 28s 87ms/step - loss: 0.5270 - val_loss: 0.3310
Epoch 22/56
315/315 [==============================] - 27s 87ms/step - loss: 0.5372 - val_loss: 0.3255
Epoch 23/56
315/315 [==============================] - 27s 87ms/step - loss: 0.5306 - val_loss: 0.3149
Epoch 24/56
315/315 [==============================] - 27s 87ms/step - loss: 0.5217 - val_loss: 0.3135
Epoch 25/56
315/315 [==============================] - 27s 87ms/step - loss: 0.5202 - val_loss: 0.3136
Epoch 26/56
315/315 [==============================] - 27s 86ms/step - loss: 0.5206 - val_loss: 0.3097
Epoch 27/56
315/315 [==============================] - 27s 87ms/step - loss: 0.5200 - val_loss: 0.3122
Epoch 28/56
315/315 [==============================] - 27s 87ms/step - loss: 0.5198 - val_loss: 0.3135
Epoch 29/56
315/315 [==============================] - 27s 87ms/step - loss: 0.5189 - val_loss: 0.3125TA: 0s - los
Epoch 30/56
315/315 [==============================] - 27s 87ms/step - loss: 0.5207 - val_loss: 0.3425
Epoch 31/56
315/315 [==============================] - 27s 87ms/step - loss: 0.5505 - val_loss: 0.3206
Epoch 32/56
315/315 [==============================] - 27s 87ms/step - loss: 0.5202 - val_loss: 0.3018
Epoch 33/56
315/315 [==============================] - 27s 86ms/step - loss: 0.5167 - val_loss: 0.2983
Epoch 34/56
315/315 [==============================] - 28s 87ms/step - loss: 0.5300 - val_loss: 0.3115
Epoch 35/56
315/315 [==============================] - 27s 87ms/step - loss: 0.5205 - val_loss: 0.3020
Epoch 36/56
315/315 [==============================] - 27s 87ms/step - loss: 0.5169 - val_loss: 0.3037
Epoch 37/56
315/315 [==============================] - 27s 86ms/step - loss: 0.5152 - val_loss: 0.3026
Epoch 38/56
315/315 [==============================] - 27s 87ms/step - loss: 0.5144 - val_loss: 0.3037
Epoch 39/56
315/315 [==============================] - 27s 87ms/step - loss: 0.5158 - val_loss: 0.3230
Epoch 40/56
315/315 [==============================] - 27s 86ms/step - loss: 0.5154 - val_loss: 0.3408
Epoch 41/56
315/315 [==============================] - 27s 87ms/step - loss: 0.5300 - val_loss: 0.3061
Epoch 42/56
315/315 [==============================] - 27s 87ms/step - loss: 0.5139 - val_loss: 0.3274
Epoch 43/56
315/315 [==============================] - 27s 87ms/step - loss: 0.5271 - val_loss: 0.3216
Epoch 44/56
315/315 [==============================] - 27s 86ms/step - loss: 0.5138 - val_loss: 0.3074
Epoch 45/56
315/315 [==============================] - 27s 87ms/step - loss: 0.5141 - val_loss: 0.2966
Epoch 46/56
315/315 [==============================] - 27s 87ms/step - loss: 0.5096 - val_loss: 0.3007
Epoch 47/56
315/315 [==============================] - 27s 87ms/step - loss: 0.5085 - val_loss: 0.3065
Epoch 48/56
315/315 [==============================] - 27s 87ms/step - loss: 0.5121 - val_loss: 0.4534
Epoch 49/56
315/315 [==============================] - 27s 87ms/step - loss: 0.5205 - val_loss: 0.3025
Epoch 50/56
315/315 [==============================] - 27s 86ms/step - loss: 0.5072 - val_loss: 0.3013
Epoch 51/56
315/315 [==============================] - 27s 87ms/step - loss: 0.5169 - val_loss: 0.3106
Epoch 52/56
315/315 [==============================] - 27s 87ms/step - loss: 0.5100 - val_loss: 0.3009
Epoch 53/56
315/315 [==============================] - 27s 87ms/step - loss: 0.5045 - val_loss: 0.3011
Epoch 54/56
315/315 [==============================] - 27s 86ms/step - loss: 0.5036 - val_loss: 0.2967
Epoch 55/56
315/315 [==============================] - 27s 86ms/step - loss: 0.5072 - val_loss: 0.2894
Epoch 56/56
315/315 [==============================] - 28s 88ms/step - loss: 0.5041 - val_loss: 0.2938
Execution time:  1539.680047750473
LSTM:
Mean Absolute Error: 0.4032
Root Mean Square Error: 0.8836
Mean Square Error: 0.7808

Train RMSE: 0.884
Train MSE: 0.781
Train MAE: 0.403
###########################

MODEL:  LSTM
sequence:  1d
units:  45
dropout1:  0.11814836227952394
dropout2:  0.24325404382648977
optimizer: adam
activationDense: tanh
epochs: 43
batchsize: 30
validation_split: 0.2
Model: &#34;sequential_49&#34;
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
lstm_98 (LSTM)               (None, 144, 45)           8460      
_________________________________________________________________
dropout_98 (Dropout)         (None, 144, 45)           0         
_________________________________________________________________
lstm_99 (LSTM)               (None, 144, 45)           16380     
_________________________________________________________________
dropout_99 (Dropout)         (None, 144, 45)           0         
_________________________________________________________________
time_distributed_49 (TimeDis (None, 144, 1)            46        
=================================================================
Total params: 24,886
Trainable params: 24,886
Non-trainable params: 0
_________________________________________________________________
Epoch 1/43
103/103 [==============================] - 12s 119ms/step - loss: 0.6229 - val_loss: 0.4201
Epoch 2/43
103/103 [==============================] - 11s 102ms/step - loss: 0.6059 - val_loss: 0.4252
Epoch 3/43
103/103 [==============================] - 10s 101ms/step - loss: 0.5935 - val_loss: 0.4267
Epoch 4/43
103/103 [==============================] - 11s 102ms/step - loss: 0.5887 - val_loss: 0.4271
Epoch 5/43
103/103 [==============================] - 10s 102ms/step - loss: 0.5832 - val_loss: 0.4254
Epoch 6/43
103/103 [==============================] - 10s 102ms/step - loss: 0.5807 - val_loss: 0.4240
Epoch 7/43
103/103 [==============================] - 11s 102ms/step - loss: 0.5854 - val_loss: 0.4209
Epoch 8/43
103/103 [==============================] - 11s 102ms/step - loss: 0.5749 - val_loss: 0.4175
Epoch 9/43
103/103 [==============================] - 11s 102ms/step - loss: 0.5771 - val_loss: 0.4071
Epoch 10/43
103/103 [==============================] - 11s 102ms/step - loss: 0.5906 - val_loss: 0.4235
Epoch 11/43
103/103 [==============================] - 11s 102ms/step - loss: 0.5669 - val_loss: 0.4199
Epoch 12/43
103/103 [==============================] - 10s 101ms/step - loss: 0.5556 - val_loss: 0.4841
Epoch 13/43
103/103 [==============================] - 11s 102ms/step - loss: 0.5688 - val_loss: 0.4404
Epoch 14/43
103/103 [==============================] - 11s 102ms/step - loss: 0.5450 - val_loss: 0.4102
Epoch 15/43
103/103 [==============================] - 10s 101ms/step - loss: 0.5582 - val_loss: 0.4046
Epoch 16/43
103/103 [==============================] - 10s 102ms/step - loss: 0.5485 - val_loss: 0.3990
Epoch 17/43
103/103 [==============================] - 11s 102ms/step - loss: 0.5422 - val_loss: 0.4017
Epoch 18/43
103/103 [==============================] - 10s 101ms/step - loss: 0.5396 - val_loss: 0.3969
Epoch 19/43
103/103 [==============================] - 10s 102ms/step - loss: 0.5516 - val_loss: 0.3973
Epoch 20/43
103/103 [==============================] - 11s 102ms/step - loss: 0.5361 - val_loss: 0.3975
Epoch 21/43
103/103 [==============================] - 10s 102ms/step - loss: 0.5275 - val_loss: 0.4071
Epoch 22/43
103/103 [==============================] - 11s 102ms/step - loss: 0.5280 - val_loss: 0.3954
Epoch 23/43
103/103 [==============================] - 11s 102ms/step - loss: 0.5374 - val_loss: 0.3948
Epoch 24/43
103/103 [==============================] - 10s 101ms/step - loss: 0.5346 - val_loss: 0.3959
Epoch 25/43
103/103 [==============================] - 11s 102ms/step - loss: 0.5347 - val_loss: 0.3957
Epoch 26/43
103/103 [==============================] - 10s 102ms/step - loss: 0.5209 - val_loss: 0.3943
Epoch 27/43
103/103 [==============================] - 10s 101ms/step - loss: 0.5435 - val_loss: 0.3938
Epoch 28/43
103/103 [==============================] - 11s 102ms/step - loss: 0.5187 - val_loss: 0.3961
Epoch 29/43
103/103 [==============================] - 11s 102ms/step - loss: 0.5277 - val_loss: 0.3967
Epoch 30/43
103/103 [==============================] - 10s 101ms/step - loss: 0.5336 - val_loss: 0.3970
Epoch 31/43
103/103 [==============================] - 11s 102ms/step - loss: 0.5169 - val_loss: 0.3966
Epoch 32/43
103/103 [==============================] - 11s 103ms/step - loss: 0.5208 - val_loss: 0.3993
Epoch 33/43
103/103 [==============================] - 10s 101ms/step - loss: 0.5402 - val_loss: 0.4019
Epoch 34/43
103/103 [==============================] - 11s 102ms/step - loss: 0.5157 - val_loss: 0.4003
Epoch 35/43
103/103 [==============================] - 11s 102ms/step - loss: 0.5184 - val_loss: 0.4016
Epoch 36/43
103/103 [==============================] - 10s 101ms/step - loss: 0.5209 - val_loss: 0.4006
Epoch 37/43
103/103 [==============================] - 11s 103ms/step - loss: 0.5323 - val_loss: 0.4044
Epoch 38/43
103/103 [==============================] - 11s 102ms/step - loss: 0.5146 - val_loss: 0.4008
Epoch 39/43
103/103 [==============================] - 10s 101ms/step - loss: 0.5132 - val_loss: 0.3999
Epoch 40/43
103/103 [==============================] - 11s 102ms/step - loss: 0.5113 - val_loss: 0.4070
Epoch 41/43
103/103 [==============================] - 11s 103ms/step - loss: 0.5138 - val_loss: 0.4001
Epoch 42/43
103/103 [==============================] - 10s 101ms/step - loss: 0.5117 - val_loss: 0.4029
Epoch 43/43
103/103 [==============================] - 11s 103ms/step - loss: 0.5093 - val_loss: 0.4046
Execution time:  461.9719235897064
LSTM:
Mean Absolute Error: 0.4015
Root Mean Square Error: 0.8768
Mean Square Error: 0.7688

Train RMSE: 0.877
Train MSE: 0.769
Train MAE: 0.402
###########################

MODEL:  LSTM
sequence:  1d
units:  43
dropout1:  0.40519643149940265
dropout2:  0.3312343747027119
optimizer: adam
activationDense: sigmoid
epochs: 56
batchsize: 11
validation_split: 0.1
Model: &#34;sequential_50&#34;
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
lstm_100 (LSTM)              (None, 144, 43)           7740      
_________________________________________________________________
dropout_100 (Dropout)        (None, 144, 43)           0         
_________________________________________________________________
lstm_101 (LSTM)              (None, 144, 43)           14964     
_________________________________________________________________
dropout_101 (Dropout)        (None, 144, 43)           0         
_________________________________________________________________
time_distributed_50 (TimeDis (None, 144, 1)            44        
=================================================================
Total params: 22,748
Trainable params: 22,748
Non-trainable params: 0
_________________________________________________________________
Epoch 1/56
315/315 [==============================] - 29s 91ms/step - loss: 0.7486 - val_loss: 0.8179
Epoch 2/56
315/315 [==============================] - 27s 87ms/step - loss: 0.7232 - val_loss: 0.8102
Epoch 3/56
315/315 [==============================] - 28s 87ms/step - loss: 0.7203 - val_loss: 0.8077
Epoch 4/56
315/315 [==============================] - 27s 87ms/step - loss: 0.7159 - val_loss: 0.8062
Epoch 5/56
315/315 [==============================] - 28s 87ms/step - loss: 0.7135 - val_loss: 0.8051
Epoch 6/56
315/315 [==============================] - 27s 87ms/step - loss: 0.7116 - val_loss: 0.8044
Epoch 7/56
315/315 [==============================] - 27s 87ms/step - loss: 0.7108 - val_loss: 0.8038
Epoch 8/56
315/315 [==============================] - 27s 87ms/step - loss: 0.7103 - val_loss: 0.8053
Epoch 9/56
315/315 [==============================] - 28s 88ms/step - loss: 0.7104 - val_loss: 0.8048
Epoch 10/56
315/315 [==============================] - 27s 87ms/step - loss: 0.7083 - val_loss: 0.8045
Epoch 11/56
315/315 [==============================] - 27s 87ms/step - loss: 0.7078 - val_loss: 0.8033
Epoch 12/56
315/315 [==============================] - 27s 87ms/step - loss: 0.7119 - val_loss: 0.8047
Epoch 13/56
315/315 [==============================] - 27s 87ms/step - loss: 0.7101 - val_loss: 0.8044
Epoch 14/56
315/315 [==============================] - 28s 88ms/step - loss: 0.7081 - val_loss: 0.8034
Epoch 15/56
315/315 [==============================] - 27s 87ms/step - loss: 0.7055 - val_loss: 0.8033
Epoch 16/56
315/315 [==============================] - 28s 88ms/step - loss: 0.7051 - val_loss: 0.8031
Epoch 17/56
315/315 [==============================] - 28s 88ms/step - loss: 0.7047 - val_loss: 0.8030
Epoch 18/56
315/315 [==============================] - 28s 87ms/step - loss: 0.7043 - val_loss: 0.8029
Epoch 19/56
315/315 [==============================] - 27s 87ms/step - loss: 0.7041 - val_loss: 0.8028
Epoch 20/56
315/315 [==============================] - 27s 87ms/step - loss: 0.7039 - val_loss: 0.8028
Epoch 21/56
315/315 [==============================] - 27s 87ms/step - loss: 0.7035 - val_loss: 0.8021
Epoch 22/56
315/315 [==============================] - 27s 87ms/step - loss: 0.7035 - val_loss: 0.8020
Epoch 23/56
315/315 [==============================] - 27s 86ms/step - loss: 0.7036 - val_loss: 0.8020
Epoch 24/56
315/315 [==============================] - 27s 86ms/step - loss: 0.7034 - val_loss: 0.8020
Epoch 25/56
315/315 [==============================] - 27s 86ms/step - loss: 0.7043 - val_loss: 0.8025
Epoch 26/56
315/315 [==============================] - 27s 86ms/step - loss: 0.7031 - val_loss: 0.8025
Epoch 27/56
315/315 [==============================] - 27s 87ms/step - loss: 0.7018 - val_loss: 0.8013
Epoch 28/56
315/315 [==============================] - 27s 86ms/step - loss: 0.7055 - val_loss: 0.8013
Epoch 29/56
315/315 [==============================] - 27s 86ms/step - loss: 0.7052 - val_loss: 0.8013
Epoch 30/56
315/315 [==============================] - 27s 86ms/step - loss: 0.7050 - val_loss: 0.8014
Epoch 31/56
315/315 [==============================] - 27s 87ms/step - loss: 0.7045 - val_loss: 0.8014
Epoch 32/56
315/315 [==============================] - 27s 86ms/step - loss: 0.7041 - val_loss: 0.8014
Epoch 33/56
315/315 [==============================] - 27s 86ms/step - loss: 0.7032 - val_loss: 0.8014
Epoch 34/56
315/315 [==============================] - 27s 86ms/step - loss: 0.7009 - val_loss: 0.8015
Epoch 35/56
315/315 [==============================] - 27s 87ms/step - loss: 0.7048 - val_loss: 0.8014
Epoch 36/56
315/315 [==============================] - 27s 86ms/step - loss: 0.7065 - val_loss: 0.8014
Epoch 37/56
315/315 [==============================] - 27s 86ms/step - loss: 0.7020 - val_loss: 0.8013
Epoch 38/56
315/315 [==============================] - 27s 86ms/step - loss: 0.7006 - val_loss: 0.8014
Epoch 39/56
315/315 [==============================] - 27s 86ms/step - loss: 0.7003 - val_loss: 0.8014
Epoch 40/56
315/315 [==============================] - 27s 86ms/step - loss: 0.7001 - val_loss: 0.8014
Epoch 41/56
315/315 [==============================] - 27s 86ms/step - loss: 0.6999 - val_loss: 0.8014
Epoch 42/56
315/315 [==============================] - 27s 86ms/step - loss: 0.6999 - val_loss: 0.8014
Epoch 43/56
315/315 [==============================] - 27s 86ms/step - loss: 0.6997 - val_loss: 0.8013
Epoch 44/56
315/315 [==============================] - 27s 87ms/step - loss: 0.6998 - val_loss: 0.8013
Epoch 45/56
315/315 [==============================] - 27s 87ms/step - loss: 0.6997 - val_loss: 0.8014
Epoch 46/56
315/315 [==============================] - 27s 86ms/step - loss: 0.6997 - val_loss: 0.8013
Epoch 47/56
315/315 [==============================] - 27s 87ms/step - loss: 0.6998 - val_loss: 0.8014
Epoch 48/56
315/315 [==============================] - 27s 87ms/step - loss: 0.6996 - val_loss: 0.8014
Epoch 49/56
315/315 [==============================] - 27s 87ms/step - loss: 0.6999 - val_loss: 0.8013
Epoch 50/56
315/315 [==============================] - 27s 86ms/step - loss: 0.6998 - val_loss: 0.8014
Epoch 51/56
315/315 [==============================] - 27s 87ms/step - loss: 0.6997 - val_loss: 0.8013
Epoch 52/56
315/315 [==============================] - 27s 86ms/step - loss: 0.7003 - val_loss: 0.8013
Epoch 53/56
315/315 [==============================] - 27s 87ms/step - loss: 0.7003 - val_loss: 0.8013
Epoch 54/56
315/315 [==============================] - 27s 87ms/step - loss: 0.7015 - val_loss: 0.8013
Epoch 55/56
315/315 [==============================] - 27s 86ms/step - loss: 0.7008 - val_loss: 0.8013
Epoch 56/56
315/315 [==============================] - 27s 86ms/step - loss: 0.7006 - val_loss: 0.8013
Execution time:  1539.5536215305328
LSTM:
Mean Absolute Error: 0.7134
Root Mean Square Error: 1.0049
Mean Square Error: 1.0098

Train RMSE: 1.005
Train MSE: 1.010
Train MAE: 0.713
###########################

MODEL:  LSTM
sequence:  1d
units:  45
dropout1:  0.11814836227952394
dropout2:  0.24325404382648977
optimizer: adam
activationDense: sigmoid
epochs: 43
batchsize: 30
validation_split: 0.2
Model: &#34;sequential_51&#34;
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
lstm_102 (LSTM)              (None, 144, 45)           8460      
_________________________________________________________________
dropout_102 (Dropout)        (None, 144, 45)           0         
_________________________________________________________________
lstm_103 (LSTM)              (None, 144, 45)           16380     
_________________________________________________________________
dropout_103 (Dropout)        (None, 144, 45)           0         
_________________________________________________________________
time_distributed_51 (TimeDis (None, 144, 1)            46        
=================================================================
Total params: 24,886
Trainable params: 24,886
Non-trainable params: 0
_________________________________________________________________
Epoch 1/43
103/103 [==============================] - 11s 108ms/step - loss: 0.7662 - val_loss: 0.7593
Epoch 2/43
103/103 [==============================] - 10s 101ms/step - loss: 0.7073 - val_loss: 0.7394
Epoch 3/43
103/103 [==============================] - 10s 101ms/step - loss: 0.7178 - val_loss: 0.7360
Epoch 4/43
103/103 [==============================] - 10s 102ms/step - loss: 0.7095 - val_loss: 0.7336
Epoch 5/43
103/103 [==============================] - 10s 100ms/step - loss: 0.7088 - val_loss: 0.7322
Epoch 6/43
103/103 [==============================] - 10s 101ms/step - loss: 0.7083 - val_loss: 0.7311
Epoch 7/43
103/103 [==============================] - 10s 102ms/step - loss: 0.7079 - val_loss: 0.7303
Epoch 8/43
103/103 [==============================] - 10s 100ms/step - loss: 0.7074 - val_loss: 0.7297
Epoch 9/43
103/103 [==============================] - 10s 101ms/step - loss: 0.7062 - val_loss: 0.7290
Epoch 10/43
103/103 [==============================] - 10s 102ms/step - loss: 0.7049 - val_loss: 0.7284
Epoch 11/43
103/103 [==============================] - 10s 101ms/step - loss: 0.7005 - val_loss: 0.7291
Epoch 12/43
103/103 [==============================] - 11s 102ms/step - loss: 0.7202 - val_loss: 0.7551
Epoch 13/43
103/103 [==============================] - 10s 102ms/step - loss: 0.7269 - val_loss: 0.7523
Epoch 14/43
103/103 [==============================] - 10s 101ms/step - loss: 0.7236 - val_loss: 0.7510
Epoch 15/43
103/103 [==============================] - 10s 102ms/step - loss: 0.7225 - val_loss: 0.7493
Epoch 16/43
103/103 [==============================] - 10s 102ms/step - loss: 0.7212 - val_loss: 0.7479
Epoch 17/43
103/103 [==============================] - 10s 100ms/step - loss: 0.7202 - val_loss: 0.7465
Epoch 18/43
103/103 [==============================] - 10s 101ms/step - loss: 0.7191 - val_loss: 0.7445
Epoch 19/43
103/103 [==============================] - 10s 101ms/step - loss: 0.7178 - val_loss: 0.7428
Epoch 20/43
103/103 [==============================] - 10s 101ms/step - loss: 0.7168 - val_loss: 0.7410
Epoch 21/43
103/103 [==============================] - 10s 102ms/step - loss: 0.7158 - val_loss: 0.7391
Epoch 22/43
103/103 [==============================] - 10s 101ms/step - loss: 0.7148 - val_loss: 0.7373
Epoch 23/43
103/103 [==============================] - 10s 101ms/step - loss: 0.7139 - val_loss: 0.7357
Epoch 24/43
103/103 [==============================] - 11s 103ms/step - loss: 0.7132 - val_loss: 0.7345
Epoch 25/43
103/103 [==============================] - 10s 101ms/step - loss: 0.7128 - val_loss: 0.7334
Epoch 26/43
103/103 [==============================] - 10s 101ms/step - loss: 0.7124 - val_loss: 0.7323
Epoch 27/43
103/103 [==============================] - 10s 101ms/step - loss: 0.7118 - val_loss: 0.7314
Epoch 28/43
103/103 [==============================] - 10s 101ms/step - loss: 0.7115 - val_loss: 0.7306
Epoch 29/43
103/103 [==============================] - 10s 101ms/step - loss: 0.7113 - val_loss: 0.7300
Epoch 30/43
103/103 [==============================] - 10s 102ms/step - loss: 0.7112 - val_loss: 0.7292
Epoch 31/43
103/103 [==============================] - 10s 101ms/step - loss: 0.7108 - val_loss: 0.7284
Epoch 32/43
103/103 [==============================] - 10s 101ms/step - loss: 0.7104 - val_loss: 0.7271
Epoch 33/43
103/103 [==============================] - 10s 102ms/step - loss: 0.7098 - val_loss: 0.7242
Epoch 34/43
103/103 [==============================] - 10s 101ms/step - loss: 0.7089 - val_loss: 0.7200
Epoch 35/43
103/103 [==============================] - 11s 102ms/step - loss: 0.7017 - val_loss: 0.7196
Epoch 36/43
103/103 [==============================] - 10s 101ms/step - loss: 0.7148 - val_loss: 0.7199
Epoch 37/43
103/103 [==============================] - 10s 101ms/step - loss: 0.6993 - val_loss: 0.7207
Epoch 38/43
103/103 [==============================] - 10s 102ms/step - loss: 0.6955 - val_loss: 0.7218
Epoch 39/43
103/103 [==============================] - 10s 101ms/step - loss: 0.6931 - val_loss: 0.7219
Epoch 40/43
103/103 [==============================] - 10s 101ms/step - loss: 0.6961 - val_loss: 0.7217
Epoch 41/43
103/103 [==============================] - 10s 101ms/step - loss: 0.6913 - val_loss: 0.7222
Epoch 42/43
103/103 [==============================] - 10s 101ms/step - loss: 0.7077 - val_loss: 0.7491
Epoch 43/43
103/103 [==============================] - 10s 100ms/step - loss: 0.7239 - val_loss: 0.7453
Execution time:  457.72136425971985
LSTM:
Mean Absolute Error: 0.6864
Root Mean Square Error: 0.9548
Mean Square Error: 0.9117

Train RMSE: 0.955
Train MSE: 0.912
Train MAE: 0.686
###########################

MODEL:  LSTM
sequence:  1d
units:  43
dropout1:  0.40519643149940265
dropout2:  0.3312343747027119
optimizer: adadelta
activationDense: tanh
epochs: 56
batchsize: 11
validation_split: 0.1
Model: &#34;sequential_52&#34;
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
lstm_104 (LSTM)              (None, 144, 43)           7740      
_________________________________________________________________
dropout_104 (Dropout)        (None, 144, 43)           0         
_________________________________________________________________
lstm_105 (LSTM)              (None, 144, 43)           14964     
_________________________________________________________________
dropout_105 (Dropout)        (None, 144, 43)           0         
_________________________________________________________________
time_distributed_52 (TimeDis (None, 144, 1)            44        
=================================================================
Total params: 22,748
Trainable params: 22,748
Non-trainable params: 0
_________________________________________________________________
Epoch 1/56
315/315 [==============================] - 29s 91ms/step - loss: 0.6954 - val_loss: 0.7855
Epoch 2/56
315/315 [==============================] - 27s 87ms/step - loss: 0.6945 - val_loss: 0.7824
Epoch 3/56
315/315 [==============================] - 27s 87ms/step - loss: 0.6934 - val_loss: 0.7790
Epoch 4/56
315/315 [==============================] - 28s 87ms/step - loss: 0.6922 - val_loss: 0.7755
Epoch 5/56
315/315 [==============================] - 27s 87ms/step - loss: 0.6910 - val_loss: 0.7717
Epoch 6/56
315/315 [==============================] - 28s 88ms/step - loss: 0.6897 - val_loss: 0.7678
Epoch 7/56
315/315 [==============================] - 27s 87ms/step - loss: 0.6883 - val_loss: 0.7637
Epoch 8/56
315/315 [==============================] - 27s 87ms/step - loss: 0.6869 - val_loss: 0.7594
Epoch 9/56
315/315 [==============================] - 28s 88ms/step - loss: 0.6855 - val_loss: 0.7550
Epoch 10/56
315/315 [==============================] - 27s 87ms/step - loss: 0.6840 - val_loss: 0.7504
Epoch 11/56
315/315 [==============================] - 28s 88ms/step - loss: 0.6824 - val_loss: 0.7456
Epoch 12/56
315/315 [==============================] - 27s 87ms/step - loss: 0.6808 - val_loss: 0.7407
Epoch 13/56
315/315 [==============================] - 27s 87ms/step - loss: 0.6791 - val_loss: 0.7357
Epoch 14/56
315/315 [==============================] - 28s 87ms/step - loss: 0.6776 - val_loss: 0.7305
Epoch 15/56
315/315 [==============================] - 28s 87ms/step - loss: 0.6758 - val_loss: 0.7252
Epoch 16/56
315/315 [==============================] - 27s 87ms/step - loss: 0.6742 - val_loss: 0.7197
Epoch 17/56
315/315 [==============================] - 27s 87ms/step - loss: 0.6724 - val_loss: 0.7141
Epoch 18/56
315/315 [==============================] - 27s 87ms/step - loss: 0.6707 - val_loss: 0.7083
Epoch 19/56
315/315 [==============================] - 28s 88ms/step - loss: 0.6689 - val_loss: 0.7023
Epoch 20/56
315/315 [==============================] - 27s 87ms/step - loss: 0.6671 - val_loss: 0.6961
Epoch 21/56
315/315 [==============================] - 27s 87ms/step - loss: 0.6651 - val_loss: 0.6897
Epoch 22/56
315/315 [==============================] - 27s 87ms/step - loss: 0.6632 - val_loss: 0.6831
Epoch 23/56
315/315 [==============================] - 28s 87ms/step - loss: 0.6612 - val_loss: 0.6762
Epoch 24/56
315/315 [==============================] - 27s 87ms/step - loss: 0.6590 - val_loss: 0.6691
Epoch 25/56
315/315 [==============================] - 28s 88ms/step - loss: 0.6569 - val_loss: 0.6617
Epoch 26/56
315/315 [==============================] - 27s 87ms/step - loss: 0.6546 - val_loss: 0.6540
Epoch 27/56
315/315 [==============================] - 27s 87ms/step - loss: 0.6523 - val_loss: 0.6461
Epoch 28/56
315/315 [==============================] - 27s 87ms/step - loss: 0.6499 - val_loss: 0.6378
Epoch 29/56
315/315 [==============================] - 27s 87ms/step - loss: 0.6475 - val_loss: 0.6294
Epoch 30/56
315/315 [==============================] - 27s 87ms/step - loss: 0.6450 - val_loss: 0.6207
Epoch 31/56
315/315 [==============================] - 27s 86ms/step - loss: 0.6424 - val_loss: 0.6118
Epoch 32/56
315/315 [==============================] - 28s 88ms/step - loss: 0.6398 - val_loss: 0.6027
Epoch 33/56
315/315 [==============================] - 27s 87ms/step - loss: 0.6370 - val_loss: 0.5934
Epoch 34/56
315/315 [==============================] - 27s 87ms/step - loss: 0.6344 - val_loss: 0.5840
Epoch 35/56
315/315 [==============================] - 27s 87ms/step - loss: 0.6316 - val_loss: 0.5745
Epoch 36/56
315/315 [==============================] - 28s 88ms/step - loss: 0.6291 - val_loss: 0.5649
Epoch 37/56
315/315 [==============================] - 27s 87ms/step - loss: 0.6263 - val_loss: 0.5553
Epoch 38/56
315/315 [==============================] - 27s 86ms/step - loss: 0.6238 - val_loss: 0.5457
Epoch 39/56
315/315 [==============================] - 27s 87ms/step - loss: 0.6212 - val_loss: 0.5362
Epoch 40/56
315/315 [==============================] - 27s 87ms/step - loss: 0.6186 - val_loss: 0.5268
Epoch 41/56
315/315 [==============================] - 28s 87ms/step - loss: 0.6162 - val_loss: 0.5177
Epoch 42/56
315/315 [==============================] - 27s 87ms/step - loss: 0.6139 - val_loss: 0.5088
Epoch 43/56
315/315 [==============================] - 27s 87ms/step - loss: 0.6117 - val_loss: 0.5001
Epoch 44/56
315/315 [==============================] - 27s 87ms/step - loss: 0.6096 - val_loss: 0.4918
Epoch 45/56
315/315 [==============================] - 27s 87ms/step - loss: 0.6078 - val_loss: 0.4836
Epoch 46/56
315/315 [==============================] - 27s 87ms/step - loss: 0.6059 - val_loss: 0.4758
Epoch 47/56
315/315 [==============================] - 27s 87ms/step - loss: 0.6042 - val_loss: 0.4683
Epoch 48/56
315/315 [==============================] - 27s 87ms/step - loss: 0.6025 - val_loss: 0.4610
Epoch 49/56
315/315 [==============================] - 27s 87ms/step - loss: 0.6012 - val_loss: 0.4539
Epoch 50/56
315/315 [==============================] - 27s 87ms/step - loss: 0.5996 - val_loss: 0.4472
Epoch 51/56
315/315 [==============================] - 27s 87ms/step - loss: 0.5985 - val_loss: 0.4406
Epoch 52/56
315/315 [==============================] - 27s 86ms/step - loss: 0.5972 - val_loss: 0.4343
Epoch 53/56
315/315 [==============================] - 27s 87ms/step - loss: 0.5960 - val_loss: 0.4282
Epoch 54/56
315/315 [==============================] - 28s 87ms/step - loss: 0.5949 - val_loss: 0.4223
Epoch 55/56
315/315 [==============================] - 27s 87ms/step - loss: 0.5939 - val_loss: 0.4166
Epoch 56/56
315/315 [==============================] - 27s 86ms/step - loss: 0.5930 - val_loss: 0.4111
Execution time:  1547.029044866562
LSTM:
Mean Absolute Error: 0.4910
Root Mean Square Error: 0.8566
Mean Square Error: 0.7337

Train RMSE: 0.857
Train MSE: 0.734
Train MAE: 0.491
###########################

MODEL:  LSTM
sequence:  1d
units:  45
dropout1:  0.11814836227952394
dropout2:  0.24325404382648977
optimizer: adadelta
activationDense: tanh
epochs: 43
batchsize: 30
validation_split: 0.2
Model: &#34;sequential_53&#34;
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
lstm_106 (LSTM)              (None, 144, 45)           8460      
_________________________________________________________________
dropout_106 (Dropout)        (None, 144, 45)           0         
_________________________________________________________________
lstm_107 (LSTM)              (None, 144, 45)           16380     
_________________________________________________________________
dropout_107 (Dropout)        (None, 144, 45)           0         
_________________________________________________________________
time_distributed_53 (TimeDis (None, 144, 1)            46        
=================================================================
Total params: 24,886
Trainable params: 24,886
Non-trainable params: 0
_________________________________________________________________
Epoch 1/43
103/103 [==============================] - 11s 107ms/step - loss: 0.7097 - val_loss: 0.7075
Epoch 2/43
103/103 [==============================] - 10s 101ms/step - loss: 0.7093 - val_loss: 0.7069
Epoch 3/43
103/103 [==============================] - 11s 103ms/step - loss: 0.7089 - val_loss: 0.7062
Epoch 4/43
103/103 [==============================] - 11s 103ms/step - loss: 0.7085 - val_loss: 0.7055
Epoch 5/43
103/103 [==============================] - 10s 102ms/step - loss: 0.7081 - val_loss: 0.7048
Epoch 6/43
103/103 [==============================] - 10s 101ms/step - loss: 0.7076 - val_loss: 0.7040
Epoch 7/43
103/103 [==============================] - 10s 102ms/step - loss: 0.7072 - val_loss: 0.7033
Epoch 8/43
103/103 [==============================] - 10s 101ms/step - loss: 0.7067 - val_loss: 0.7025
Epoch 9/43
103/103 [==============================] - 10s 102ms/step - loss: 0.7063 - val_loss: 0.7017
Epoch 10/43
103/103 [==============================] - 11s 104ms/step - loss: 0.7059 - val_loss: 0.7009
Epoch 11/43
103/103 [==============================] - 10s 101ms/step - loss: 0.7053 - val_loss: 0.7001
Epoch 12/43
103/103 [==============================] - 10s 102ms/step - loss: 0.7049 - val_loss: 0.6993
Epoch 13/43
103/103 [==============================] - 10s 101ms/step - loss: 0.7044 - val_loss: 0.6984
Epoch 14/43
103/103 [==============================] - 10s 102ms/step - loss: 0.7038 - val_loss: 0.6976
Epoch 15/43
103/103 [==============================] - 11s 102ms/step - loss: 0.7034 - val_loss: 0.6967
Epoch 16/43
103/103 [==============================] - 10s 101ms/step - loss: 0.7029 - val_loss: 0.6958
Epoch 17/43
103/103 [==============================] - 10s 102ms/step - loss: 0.7024 - val_loss: 0.6950
Epoch 18/43
103/103 [==============================] - 11s 102ms/step - loss: 0.7019 - val_loss: 0.6941
Epoch 19/43
103/103 [==============================] - 10s 101ms/step - loss: 0.7014 - val_loss: 0.6932
Epoch 20/43
103/103 [==============================] - 10s 102ms/step - loss: 0.7009 - val_loss: 0.6923
Epoch 21/43
103/103 [==============================] - 10s 102ms/step - loss: 0.7003 - val_loss: 0.6913
Epoch 22/43
103/103 [==============================] - 10s 101ms/step - loss: 0.6998 - val_loss: 0.6904
Epoch 23/43
103/103 [==============================] - 11s 102ms/step - loss: 0.6993 - val_loss: 0.6895
Epoch 24/43
103/103 [==============================] - 10s 102ms/step - loss: 0.6987 - val_loss: 0.6885
Epoch 25/43
103/103 [==============================] - 10s 101ms/step - loss: 0.6982 - val_loss: 0.6876
Epoch 26/43
103/103 [==============================] - 11s 103ms/step - loss: 0.6976 - val_loss: 0.6866
Epoch 27/43
103/103 [==============================] - 11s 107ms/step - loss: 0.6971 - val_loss: 0.6856
Epoch 28/43
103/103 [==============================] - 10s 101ms/step - loss: 0.6966 - val_loss: 0.6846
Epoch 29/43
103/103 [==============================] - 10s 102ms/step - loss: 0.6960 - val_loss: 0.6836
Epoch 30/43
103/103 [==============================] - 11s 102ms/step - loss: 0.6954 - val_loss: 0.6826
Epoch 31/43
103/103 [==============================] - 10s 101ms/step - loss: 0.6949 - val_loss: 0.6816
Epoch 32/43
103/103 [==============================] - 10s 102ms/step - loss: 0.6943 - val_loss: 0.6806
Epoch 33/43
103/103 [==============================] - 11s 104ms/step - loss: 0.6938 - val_loss: 0.6795
Epoch 34/43
103/103 [==============================] - 10s 101ms/step - loss: 0.6931 - val_loss: 0.6785
Epoch 35/43
103/103 [==============================] - 11s 102ms/step - loss: 0.6925 - val_loss: 0.6775
Epoch 36/43
103/103 [==============================] - 11s 102ms/step - loss: 0.6920 - val_loss: 0.6764
Epoch 37/43
103/103 [==============================] - 10s 102ms/step - loss: 0.6914 - val_loss: 0.6753
Epoch 38/43
103/103 [==============================] - 11s 102ms/step - loss: 0.6908 - val_loss: 0.6743
Epoch 39/43
103/103 [==============================] - 11s 102ms/step - loss: 0.6902 - val_loss: 0.6732
Epoch 40/43
103/103 [==============================] - 10s 101ms/step - loss: 0.6896 - val_loss: 0.6721
Epoch 41/43
103/103 [==============================] - 10s 102ms/step - loss: 0.6890 - val_loss: 0.6710
Epoch 42/43
103/103 [==============================] - 10s 101ms/step - loss: 0.6884 - val_loss: 0.6699
Epoch 43/43
103/103 [==============================] - 10s 101ms/step - loss: 0.6879 - val_loss: 0.6689
Execution time:  460.52639174461365
LSTM:
Mean Absolute Error: 0.6743
Root Mean Square Error: 0.9756
Mean Square Error: 0.9519

Train RMSE: 0.976
Train MSE: 0.952
Train MAE: 0.674
###########################

MODEL:  LSTM
sequence:  1d
units:  43
dropout1:  0.40519643149940265
dropout2:  0.3312343747027119
optimizer: adadelta
activationDense: sigmoid
epochs: 56
batchsize: 11
validation_split: 0.1
Model: &#34;sequential_54&#34;
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
lstm_108 (LSTM)              (None, 144, 43)           7740      
_________________________________________________________________
dropout_108 (Dropout)        (None, 144, 43)           0         
_________________________________________________________________
lstm_109 (LSTM)              (None, 144, 43)           14964     
_________________________________________________________________
dropout_109 (Dropout)        (None, 144, 43)           0         
_________________________________________________________________
time_distributed_54 (TimeDis (None, 144, 1)            44        
=================================================================
Total params: 22,748
Trainable params: 22,748
Non-trainable params: 0
_________________________________________________________________
Epoch 1/56
315/315 [==============================] - 28s 90ms/step - loss: 0.9077 - val_loss: 1.2945
Epoch 2/56
315/315 [==============================] - 27s 87ms/step - loss: 0.9074 - val_loss: 1.2939
Epoch 3/56
315/315 [==============================] - 27s 87ms/step - loss: 0.9072 - val_loss: 1.2932
Epoch 4/56
315/315 [==============================] - 28s 87ms/step - loss: 0.9069 - val_loss: 1.2925
Epoch 5/56
315/315 [==============================] - 28s 87ms/step - loss: 0.9066 - val_loss: 1.2917
Epoch 6/56
315/315 [==============================] - 27s 87ms/step - loss: 0.9063 - val_loss: 1.2909
Epoch 7/56
315/315 [==============================] - 27s 87ms/step - loss: 0.9059 - val_loss: 1.2901
Epoch 8/56
315/315 [==============================] - 27s 86ms/step - loss: 0.9056 - val_loss: 1.2892
Epoch 9/56
315/315 [==============================] - 27s 86ms/step - loss: 0.9053 - val_loss: 1.2883
Epoch 10/56
315/315 [==============================] - 27s 86ms/step - loss: 0.9049 - val_loss: 1.2874
Epoch 11/56
315/315 [==============================] - 27s 87ms/step - loss: 0.9045 - val_loss: 1.2864
Epoch 12/56
315/315 [==============================] - 27s 86ms/step - loss: 0.9041 - val_loss: 1.2854
Epoch 13/56
315/315 [==============================] - 27s 86ms/step - loss: 0.9037 - val_loss: 1.2844
Epoch 14/56
315/315 [==============================] - 27s 86ms/step - loss: 0.9032 - val_loss: 1.2833
Epoch 15/56
315/315 [==============================] - 27s 87ms/step - loss: 0.9028 - val_loss: 1.2822
Epoch 16/56
315/315 [==============================] - 27s 86ms/step - loss: 0.9023 - val_loss: 1.2810
Epoch 17/56
315/315 [==============================] - 27s 86ms/step - loss: 0.9018 - val_loss: 1.2799
Epoch 18/56
315/315 [==============================] - 27s 87ms/step - loss: 0.9013 - val_loss: 1.2787
Epoch 19/56
315/315 [==============================] - 27s 86ms/step - loss: 0.9008 - val_loss: 1.2774
Epoch 20/56
315/315 [==============================] - 27s 87ms/step - loss: 0.9003 - val_loss: 1.2761
Epoch 21/56
315/315 [==============================] - 27s 86ms/step - loss: 0.8997 - val_loss: 1.2748
Epoch 22/56
315/315 [==============================] - 27s 86ms/step - loss: 0.8991 - val_loss: 1.2734
Epoch 23/56
315/315 [==============================] - 27s 86ms/step - loss: 0.8985 - val_loss: 1.2720
Epoch 24/56
315/315 [==============================] - 27s 87ms/step - loss: 0.8979 - val_loss: 1.2705
Epoch 25/56
315/315 [==============================] - 27s 87ms/step - loss: 0.8973 - val_loss: 1.2690
Epoch 26/56
315/315 [==============================] - 27s 86ms/step - loss: 0.8967 - val_loss: 1.2674
Epoch 27/56
315/315 [==============================] - 27s 86ms/step - loss: 0.8960 - val_loss: 1.2658
Epoch 28/56
315/315 [==============================] - 27s 87ms/step - loss: 0.8953 - val_loss: 1.2641
Epoch 29/56
315/315 [==============================] - 27s 87ms/step - loss: 0.8946 - val_loss: 1.2624
Epoch 30/56
315/315 [==============================] - 27s 86ms/step - loss: 0.8938 - val_loss: 1.2607
Epoch 31/56
315/315 [==============================] - 27s 86ms/step - loss: 0.8931 - val_loss: 1.2588
Epoch 32/56
315/315 [==============================] - 27s 86ms/step - loss: 0.8923 - val_loss: 1.2570
Epoch 33/56
315/315 [==============================] - 27s 87ms/step - loss: 0.8915 - val_loss: 1.2550
Epoch 34/56
315/315 [==============================] - 28s 88ms/step - loss: 0.8906 - val_loss: 1.2531
Epoch 35/56
315/315 [==============================] - 27s 87ms/step - loss: 0.8898 - val_loss: 1.2510
Epoch 36/56
315/315 [==============================] - 27s 87ms/step - loss: 0.8889 - val_loss: 1.2489
Epoch 37/56
315/315 [==============================] - 27s 87ms/step - loss: 0.8880 - val_loss: 1.2467
Epoch 38/56
315/315 [==============================] - 27s 87ms/step - loss: 0.8870 - val_loss: 1.2445
Epoch 39/56
315/315 [==============================] - 27s 87ms/step - loss: 0.8860 - val_loss: 1.2422
Epoch 40/56
315/315 [==============================] - 27s 87ms/step - loss: 0.8850 - val_loss: 1.2398
Epoch 41/56
315/315 [==============================] - 27s 87ms/step - loss: 0.8840 - val_loss: 1.2374
Epoch 42/56
315/315 [==============================] - 28s 87ms/step - loss: 0.8829 - val_loss: 1.2349
Epoch 43/56
315/315 [==============================] - 27s 87ms/step - loss: 0.8818 - val_loss: 1.2324
Epoch 44/56
315/315 [==============================] - 27s 86ms/step - loss: 0.8807 - val_loss: 1.2298
Epoch 45/56
315/315 [==============================] - 27s 87ms/step - loss: 0.8795 - val_loss: 1.2271
Epoch 46/56
315/315 [==============================] - 28s 88ms/step - loss: 0.8783 - val_loss: 1.2244
Epoch 47/56
315/315 [==============================] - 27s 87ms/step - loss: 0.8771 - val_loss: 1.2216
Epoch 48/56
315/315 [==============================] - 27s 87ms/step - loss: 0.8758 - val_loss: 1.2187
Epoch 49/56
315/315 [==============================] - 27s 87ms/step - loss: 0.8746 - val_loss: 1.2158
Epoch 50/56
315/315 [==============================] - 28s 87ms/step - loss: 0.8733 - val_loss: 1.2128
Epoch 51/56
315/315 [==============================] - 27s 87ms/step - loss: 0.8719 - val_loss: 1.2097
Epoch 52/56
315/315 [==============================] - 27s 87ms/step - loss: 0.8705 - val_loss: 1.2066
Epoch 53/56
315/315 [==============================] - 27s 87ms/step - loss: 0.8692 - val_loss: 1.2034
Epoch 54/56
315/315 [==============================] - 27s 87ms/step - loss: 0.8677 - val_loss: 1.2002
Epoch 55/56
315/315 [==============================] - 27s 87ms/step - loss: 0.8663 - val_loss: 1.1969
Epoch 56/56
315/315 [==============================] - 27s 87ms/step - loss: 0.8647 - val_loss: 1.1935
Execution time:  1541.8392975330353
LSTM:
Mean Absolute Error: 0.8662
Root Mean Square Error: 1.0608
Mean Square Error: 1.1252

Train RMSE: 1.061
Train MSE: 1.125
Train MAE: 0.866
###########################

MODEL:  LSTM
sequence:  1d
units:  45
dropout1:  0.11814836227952394
dropout2:  0.24325404382648977
optimizer: adadelta
activationDense: sigmoid
epochs: 43
batchsize: 30
validation_split: 0.2
Model: &#34;sequential_55&#34;
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
lstm_110 (LSTM)              (None, 144, 45)           8460      
_________________________________________________________________
dropout_110 (Dropout)        (None, 144, 45)           0         
_________________________________________________________________
lstm_111 (LSTM)              (None, 144, 45)           16380     
_________________________________________________________________
dropout_111 (Dropout)        (None, 144, 45)           0         
_________________________________________________________________
time_distributed_55 (TimeDis (None, 144, 1)            46        
=================================================================
Total params: 24,886
Trainable params: 24,886
Non-trainable params: 0
_________________________________________________________________
Epoch 1/43
103/103 [==============================] - 11s 106ms/step - loss: 0.8993 - val_loss: 1.1415
Epoch 2/43
103/103 [==============================] - 10s 102ms/step - loss: 0.8992 - val_loss: 1.1413
Epoch 3/43
103/103 [==============================] - 10s 102ms/step - loss: 0.8991 - val_loss: 1.1411
Epoch 4/43
103/103 [==============================] - 10s 101ms/step - loss: 0.8990 - val_loss: 1.1409
Epoch 5/43
103/103 [==============================] - 10s 102ms/step - loss: 0.8989 - val_loss: 1.1407
Epoch 6/43
103/103 [==============================] - 11s 103ms/step - loss: 0.8987 - val_loss: 1.1404
Epoch 7/43
103/103 [==============================] - 10s 102ms/step - loss: 0.8986 - val_loss: 1.1402
Epoch 8/43
103/103 [==============================] - 10s 102ms/step - loss: 0.8985 - val_loss: 1.1399
Epoch 9/43
103/103 [==============================] - 11s 102ms/step - loss: 0.8983 - val_loss: 1.1397
Epoch 10/43
103/103 [==============================] - 10s 101ms/step - loss: 0.8982 - val_loss: 1.1394
Epoch 11/43
103/103 [==============================] - 11s 102ms/step - loss: 0.8980 - val_loss: 1.1392
Epoch 12/43
103/103 [==============================] - 11s 102ms/step - loss: 0.8979 - val_loss: 1.1389
Epoch 13/43
103/103 [==============================] - 10s 101ms/step - loss: 0.8978 - val_loss: 1.1386
Epoch 14/43
103/103 [==============================] - 10s 102ms/step - loss: 0.8976 - val_loss: 1.1383
Epoch 15/43
103/103 [==============================] - 10s 102ms/step - loss: 0.8974 - val_loss: 1.1381
Epoch 16/43
103/103 [==============================] - 10s 102ms/step - loss: 0.8973 - val_loss: 1.1378
Epoch 17/43
103/103 [==============================] - 11s 103ms/step - loss: 0.8971 - val_loss: 1.1375
Epoch 18/43
103/103 [==============================] - 11s 102ms/step - loss: 0.8970 - val_loss: 1.1372
Epoch 19/43
103/103 [==============================] - 10s 102ms/step - loss: 0.8968 - val_loss: 1.1369
Epoch 20/43
103/103 [==============================] - 11s 102ms/step - loss: 0.8967 - val_loss: 1.1366
Epoch 21/43
103/103 [==============================] - 10s 101ms/step - loss: 0.8965 - val_loss: 1.1363
Epoch 22/43
103/103 [==============================] - 10s 102ms/step - loss: 0.8963 - val_loss: 1.1360
Epoch 23/43
103/103 [==============================] - 10s 102ms/step - loss: 0.8962 - val_loss: 1.1357
Epoch 24/43
103/103 [==============================] - 10s 101ms/step - loss: 0.8960 - val_loss: 1.1354
Epoch 25/43
103/103 [==============================] - 11s 103ms/step - loss: 0.8958 - val_loss: 1.1351
Epoch 26/43
103/103 [==============================] - 11s 102ms/step - loss: 0.8956 - val_loss: 1.1348
Epoch 27/43
103/103 [==============================] - 11s 102ms/step - loss: 0.8955 - val_loss: 1.1344
Epoch 28/43
103/103 [==============================] - 11s 102ms/step - loss: 0.8953 - val_loss: 1.1341
Epoch 29/43
103/103 [==============================] - 11s 102ms/step - loss: 0.8951 - val_loss: 1.1338
Epoch 30/43
103/103 [==============================] - 10s 101ms/step - loss: 0.8949 - val_loss: 1.1334
Epoch 31/43
103/103 [==============================] - 10s 102ms/step - loss: 0.8947 - val_loss: 1.1331
Epoch 32/43
103/103 [==============================] - 10s 102ms/step - loss: 0.8946 - val_loss: 1.1328
Epoch 33/43
103/103 [==============================] - 10s 101ms/step - loss: 0.8944 - val_loss: 1.1324
Epoch 34/43
103/103 [==============================] - 10s 102ms/step - loss: 0.8942 - val_loss: 1.1321
Epoch 35/43
103/103 [==============================] - 11s 102ms/step - loss: 0.8940 - val_loss: 1.1317
Epoch 36/43
103/103 [==============================] - 10s 101ms/step - loss: 0.8938 - val_loss: 1.1314
Epoch 37/43
103/103 [==============================] - 11s 102ms/step - loss: 0.8936 - val_loss: 1.1310
Epoch 38/43
103/103 [==============================] - 10s 102ms/step - loss: 0.8934 - val_loss: 1.1307
Epoch 39/43
103/103 [==============================] - 10s 101ms/step - loss: 0.8932 - val_loss: 1.1303
Epoch 40/43
103/103 [==============================] - 11s 103ms/step - loss: 0.8930 - val_loss: 1.1299
Epoch 41/43
103/103 [==============================] - 11s 102ms/step - loss: 0.8928 - val_loss: 1.1296
Epoch 42/43
103/103 [==============================] - 10s 101ms/step - loss: 0.8926 - val_loss: 1.1292
Epoch 43/43
103/103 [==============================] - 10s 102ms/step - loss: 0.8924 - val_loss: 1.1288
Execution time:  460.13913679122925
LSTM:
Mean Absolute Error: 0.9210
Root Mean Square Error: 1.1098
Mean Square Error: 1.2316

Train RMSE: 1.110
Train MSE: 1.232
Train MAE: 0.921
###########################

MODEL:  LSTM
sequence:  1d
units:  43
dropout1:  0.40519643149940265
dropout2:  0.3312343747027119
optimizer: adamax
activationDense: tanh
epochs: 56
batchsize: 11
validation_split: 0.1
Model: &#34;sequential_56&#34;
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
lstm_112 (LSTM)              (None, 144, 43)           7740      
_________________________________________________________________
dropout_112 (Dropout)        (None, 144, 43)           0         
_________________________________________________________________
lstm_113 (LSTM)              (None, 144, 43)           14964     
_________________________________________________________________
dropout_113 (Dropout)        (None, 144, 43)           0         
_________________________________________________________________
time_distributed_56 (TimeDis (None, 144, 1)            44        
=================================================================
Total params: 22,748
Trainable params: 22,748
Non-trainable params: 0
_________________________________________________________________
Epoch 1/56
315/315 [==============================] - 28s 90ms/step - loss: 0.6131 - val_loss: 0.4485
Epoch 2/56
315/315 [==============================] - 28s 88ms/step - loss: 0.5945 - val_loss: 0.4233
Epoch 3/56
315/315 [==============================] - 28s 88ms/step - loss: 0.5902 - val_loss: 0.3996
Epoch 4/56
315/315 [==============================] - 27s 87ms/step - loss: 0.5858 - val_loss: 0.3735
Epoch 5/56
315/315 [==============================] - 27s 87ms/step - loss: 0.5816 - val_loss: 0.3393
Epoch 6/56
315/315 [==============================] - 28s 88ms/step - loss: 0.5718 - val_loss: 0.3219
Epoch 7/56
315/315 [==============================] - 28s 88ms/step - loss: 0.5486 - val_loss: 0.3066
Epoch 8/56
315/315 [==============================] - 28s 87ms/step - loss: 0.5404 - val_loss: 0.2958
Epoch 9/56
315/315 [==============================] - 27s 87ms/step - loss: 0.5382 - val_loss: 0.2847
Epoch 10/56
315/315 [==============================] - 28s 88ms/step - loss: 0.5318 - val_loss: 0.2847
Epoch 11/56
315/315 [==============================] - 27s 87ms/step - loss: 0.5301 - val_loss: 0.2852
Epoch 12/56
315/315 [==============================] - 28s 87ms/step - loss: 0.5304 - val_loss: 0.2862
Epoch 13/56
315/315 [==============================] - 27s 87ms/step - loss: 0.5305 - val_loss: 0.2853
Epoch 14/56
315/315 [==============================] - 27s 87ms/step - loss: 0.5317 - val_loss: 0.2847
Epoch 15/56
315/315 [==============================] - 27s 87ms/step - loss: 0.5303 - val_loss: 0.2873
Epoch 16/56
315/315 [==============================] - 27s 87ms/step - loss: 0.5280 - val_loss: 0.2732
Epoch 17/56
315/315 [==============================] - 27s 87ms/step - loss: 0.5220 - val_loss: 0.2720
Epoch 18/56
315/315 [==============================] - 27s 87ms/step - loss: 0.5212 - val_loss: 0.2726
Epoch 19/56
315/315 [==============================] - 27s 87ms/step - loss: 0.5214 - val_loss: 0.2709
Epoch 20/56
315/315 [==============================] - 27s 87ms/step - loss: 0.5231 - val_loss: 0.2708
Epoch 21/56
315/315 [==============================] - 28s 88ms/step - loss: 0.5204 - val_loss: 0.2726
Epoch 22/56
315/315 [==============================] - 27s 87ms/step - loss: 0.5229 - val_loss: 0.2678
Epoch 23/56
315/315 [==============================] - 27s 86ms/step - loss: 0.5192 - val_loss: 0.2685
Epoch 24/56
315/315 [==============================] - 27s 87ms/step - loss: 0.5192 - val_loss: 0.2700
Epoch 25/56
315/315 [==============================] - 28s 88ms/step - loss: 0.5201 - val_loss: 0.2705
Epoch 26/56
315/315 [==============================] - 27s 86ms/step - loss: 0.5198 - val_loss: 0.2683
Epoch 27/56
315/315 [==============================] - 28s 88ms/step - loss: 0.5205 - val_loss: 0.2649
Epoch 28/56
315/315 [==============================] - 27s 87ms/step - loss: 0.5178 - val_loss: 0.2661
Epoch 29/56
315/315 [==============================] - 28s 87ms/step - loss: 0.5173 - val_loss: 0.2678
Epoch 30/56
315/315 [==============================] - 27s 87ms/step - loss: 0.5185 - val_loss: 0.2686
Epoch 31/56
315/315 [==============================] - 27s 87ms/step - loss: 0.5173 - val_loss: 0.2674
Epoch 32/56
315/315 [==============================] - 27s 87ms/step - loss: 0.5168 - val_loss: 0.2608
Epoch 33/56
315/315 [==============================] - 27s 86ms/step - loss: 0.5127 - val_loss: 0.2592
Epoch 34/56
315/315 [==============================] - 28s 87ms/step - loss: 0.5118 - val_loss: 0.2595
Epoch 35/56
315/315 [==============================] - 27s 87ms/step - loss: 0.5118 - val_loss: 0.2589
Epoch 36/56
315/315 [==============================] - 27s 87ms/step - loss: 0.5124 - val_loss: 0.2589
Epoch 37/56
315/315 [==============================] - 27s 87ms/step - loss: 0.5122 - val_loss: 0.2603
Epoch 38/56
315/315 [==============================] - 28s 88ms/step - loss: 0.5132 - val_loss: 0.2605
Epoch 39/56
315/315 [==============================] - 27s 87ms/step - loss: 0.5124 - val_loss: 0.2612
Epoch 40/56
315/315 [==============================] - 28s 88ms/step - loss: 0.5135 - val_loss: 0.2624
Epoch 41/56
315/315 [==============================] - 27s 86ms/step - loss: 0.5134 - val_loss: 0.2629
Epoch 42/56
315/315 [==============================] - 28s 89ms/step - loss: 0.5132 - val_loss: 0.2623
Epoch 43/56
315/315 [==============================] - 27s 87ms/step - loss: 0.5134 - val_loss: 0.2652
Epoch 44/56
315/315 [==============================] - 27s 86ms/step - loss: 0.5143 - val_loss: 0.2633
Epoch 45/56
315/315 [==============================] - 27s 87ms/step - loss: 0.5121 - val_loss: 0.2628
Epoch 46/56
315/315 [==============================] - 27s 87ms/step - loss: 0.5124 - val_loss: 0.2599
Epoch 47/56
315/315 [==============================] - 28s 87ms/step - loss: 0.5113 - val_loss: 0.2599
Epoch 48/56
315/315 [==============================] - 27s 86ms/step - loss: 0.5117 - val_loss: 0.2614
Epoch 49/56
315/315 [==============================] - 27s 87ms/step - loss: 0.5103 - val_loss: 0.2622
Epoch 50/56
315/315 [==============================] - 27s 87ms/step - loss: 0.5125 - val_loss: 0.2618
Epoch 51/56
315/315 [==============================] - 27s 87ms/step - loss: 0.5114 - val_loss: 0.2657
Epoch 52/56
315/315 [==============================] - 27s 87ms/step - loss: 0.5127 - val_loss: 0.2684
Epoch 53/56
315/315 [==============================] - 27s 87ms/step - loss: 0.5135 - val_loss: 0.2616
Epoch 54/56
315/315 [==============================] - 27s 87ms/step - loss: 0.5107 - val_loss: 0.2652
Epoch 55/56
315/315 [==============================] - 27s 87ms/step - loss: 0.5122 - val_loss: 0.2620
Epoch 56/56
315/315 [==============================] - 27s 87ms/step - loss: 0.5105 - val_loss: 0.2678
Execution time:  1547.7490448951721
LSTM:
Mean Absolute Error: 0.4062
Root Mean Square Error: 0.8761
Mean Square Error: 0.7676

Train RMSE: 0.876
Train MSE: 0.768
Train MAE: 0.406
###########################

MODEL:  LSTM
sequence:  1d
units:  45
dropout1:  0.11814836227952394
dropout2:  0.24325404382648977
optimizer: adamax
activationDense: tanh
epochs: 43
batchsize: 30
validation_split: 0.2
Model: &#34;sequential_57&#34;
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
lstm_114 (LSTM)              (None, 144, 45)           8460      
_________________________________________________________________
dropout_114 (Dropout)        (None, 144, 45)           0         
_________________________________________________________________
lstm_115 (LSTM)              (None, 144, 45)           16380     
_________________________________________________________________
dropout_115 (Dropout)        (None, 144, 45)           0         
_________________________________________________________________
time_distributed_57 (TimeDis (None, 144, 1)            46        
=================================================================
Total params: 24,886
Trainable params: 24,886
Non-trainable params: 0
_________________________________________________________________
Epoch 1/43
103/103 [==============================] - 11s 106ms/step - loss: 0.6192 - val_loss: 0.4303
Epoch 2/43
103/103 [==============================] - 10s 102ms/step - loss: 0.5957 - val_loss: 0.4323
Epoch 3/43
103/103 [==============================] - 11s 102ms/step - loss: 0.5898 - val_loss: 0.4331
Epoch 4/43
103/103 [==============================] - 10s 101ms/step - loss: 0.5849 - val_loss: 0.4329
Epoch 5/43
103/103 [==============================] - 11s 102ms/step - loss: 0.5809 - val_loss: 0.4331
Epoch 6/43
103/103 [==============================] - 11s 102ms/step - loss: 0.5777 - val_loss: 0.4336
Epoch 7/43
103/103 [==============================] - 10s 101ms/step - loss: 0.5730 - val_loss: 0.4344
Epoch 8/43
103/103 [==============================] - 11s 104ms/step - loss: 0.5685 - val_loss: 0.4324
Epoch 9/43
103/103 [==============================] - 11s 103ms/step - loss: 0.5639 - val_loss: 0.4301
Epoch 10/43
103/103 [==============================] - 10s 101ms/step - loss: 0.5536 - val_loss: 0.4224
Epoch 11/43
103/103 [==============================] - 11s 102ms/step - loss: 0.5512 - val_loss: 0.4187
Epoch 12/43
103/103 [==============================] - 11s 102ms/step - loss: 0.5486 - val_loss: 0.4141
Epoch 13/43
103/103 [==============================] - 10s 101ms/step - loss: 0.5438 - val_loss: 0.4085
Epoch 14/43
103/103 [==============================] - 11s 102ms/step - loss: 0.5447 - val_loss: 0.4071
Epoch 15/43
103/103 [==============================] - 11s 102ms/step - loss: 0.5386 - val_loss: 0.4038
Epoch 16/43
103/103 [==============================] - 10s 101ms/step - loss: 0.5419 - val_loss: 0.4032
Epoch 17/43
103/103 [==============================] - 10s 102ms/step - loss: 0.5349 - val_loss: 0.4016
Epoch 18/43
103/103 [==============================] - 11s 102ms/step - loss: 0.5349 - val_loss: 0.4003
Epoch 19/43
103/103 [==============================] - 10s 101ms/step - loss: 0.5346 - val_loss: 0.3991
Epoch 20/43
103/103 [==============================] - 11s 103ms/step - loss: 0.5347 - val_loss: 0.3984
Epoch 21/43
103/103 [==============================] - 10s 101ms/step - loss: 0.5349 - val_loss: 0.3981
Epoch 22/43
103/103 [==============================] - 10s 102ms/step - loss: 0.5358 - val_loss: 0.3983
Epoch 23/43
103/103 [==============================] - 10s 102ms/step - loss: 0.5324 - val_loss: 0.3976
Epoch 24/43
103/103 [==============================] - 10s 101ms/step - loss: 0.5330 - val_loss: 0.3971
Epoch 25/43
103/103 [==============================] - 10s 101ms/step - loss: 0.5336 - val_loss: 0.3970
Epoch 26/43
103/103 [==============================] - 10s 102ms/step - loss: 0.5328 - val_loss: 0.3967
Epoch 27/43
103/103 [==============================] - 10s 101ms/step - loss: 0.5322 - val_loss: 0.3969
Epoch 28/43
103/103 [==============================] - 11s 102ms/step - loss: 0.5330 - val_loss: 0.3973
Epoch 29/43
103/103 [==============================] - 10s 102ms/step - loss: 0.5297 - val_loss: 0.3963
Epoch 30/43
103/103 [==============================] - 10s 101ms/step - loss: 0.5302 - val_loss: 0.3962
Epoch 31/43
103/103 [==============================] - 11s 103ms/step - loss: 0.5305 - val_loss: 0.3962
Epoch 32/43
103/103 [==============================] - 11s 102ms/step - loss: 0.5294 - val_loss: 0.3966
Epoch 33/43
103/103 [==============================] - 10s 101ms/step - loss: 0.5275 - val_loss: 0.3960
Epoch 34/43
103/103 [==============================] - 10s 101ms/step - loss: 0.5281 - val_loss: 0.3963
Epoch 35/43
103/103 [==============================] - 10s 101ms/step - loss: 0.5282 - val_loss: 0.3961
Epoch 36/43
103/103 [==============================] - 10s 101ms/step - loss: 0.5270 - val_loss: 0.3966
Epoch 37/43
103/103 [==============================] - 11s 102ms/step - loss: 0.5255 - val_loss: 0.3953
Epoch 38/43
103/103 [==============================] - 10s 102ms/step - loss: 0.5232 - val_loss: 0.3958
Epoch 39/43
103/103 [==============================] - 10s 101ms/step - loss: 0.5225 - val_loss: 0.3958
Epoch 40/43
103/103 [==============================] - 10s 102ms/step - loss: 0.5228 - val_loss: 0.3971
Epoch 41/43
103/103 [==============================] - 10s 102ms/step - loss: 0.5209 - val_loss: 0.4003
Epoch 42/43
103/103 [==============================] - 10s 102ms/step - loss: 0.5149 - val_loss: 0.3963
Epoch 43/43
103/103 [==============================] - 11s 103ms/step - loss: 0.5161 - val_loss: 0.3960
Execution time:  460.0937395095825
LSTM:
Mean Absolute Error: 0.4009
Root Mean Square Error: 0.8676
Mean Square Error: 0.7528

Train RMSE: 0.868
Train MSE: 0.753
Train MAE: 0.401
###########################

MODEL:  LSTM
sequence:  1d
units:  43
dropout1:  0.40519643149940265
dropout2:  0.3312343747027119
optimizer: adamax
activationDense: sigmoid
epochs: 56
batchsize: 11
validation_split: 0.1
Model: &#34;sequential_58&#34;
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
lstm_116 (LSTM)              (None, 144, 43)           7740      
_________________________________________________________________
dropout_116 (Dropout)        (None, 144, 43)           0         
_________________________________________________________________
lstm_117 (LSTM)              (None, 144, 43)           14964     
_________________________________________________________________
dropout_117 (Dropout)        (None, 144, 43)           0         
_________________________________________________________________
time_distributed_58 (TimeDis (None, 144, 1)            44        
=================================================================
Total params: 22,748
Trainable params: 22,748
Non-trainable params: 0
_________________________________________________________________
Epoch 1/56
315/315 [==============================] - 28s 90ms/step - loss: 0.7418 - val_loss: 0.8301
Epoch 2/56
315/315 [==============================] - 27s 86ms/step - loss: 0.6948 - val_loss: 0.8182
Epoch 3/56
315/315 [==============================] - 27s 86ms/step - loss: 0.6911 - val_loss: 0.8143
Epoch 4/56
315/315 [==============================] - 27s 86ms/step - loss: 0.6896 - val_loss: 0.8123
Epoch 5/56
315/315 [==============================] - 27s 86ms/step - loss: 0.6891 - val_loss: 0.8111
Epoch 6/56
315/315 [==============================] - 27s 86ms/step - loss: 0.6883 - val_loss: 0.8101
Epoch 7/56
315/315 [==============================] - 27s 86ms/step - loss: 0.6879 - val_loss: 0.8093
Epoch 8/56
315/315 [==============================] - 27s 86ms/step - loss: 0.6870 - val_loss: 0.8088
Epoch 9/56
315/315 [==============================] - 27s 86ms/step - loss: 0.6865 - val_loss: 0.8083
Epoch 10/56
315/315 [==============================] - 27s 86ms/step - loss: 0.6915 - val_loss: 0.8080
Epoch 11/56
315/315 [==============================] - 27s 85ms/step - loss: 0.6873 - val_loss: 0.8078
Epoch 12/56
315/315 [==============================] - 27s 86ms/step - loss: 0.6852 - val_loss: 0.8075
Epoch 13/56
315/315 [==============================] - 27s 87ms/step - loss: 0.6849 - val_loss: 0.8072
Epoch 14/56
315/315 [==============================] - 27s 86ms/step - loss: 0.6851 - val_loss: 0.8070
Epoch 15/56
315/315 [==============================] - 27s 86ms/step - loss: 0.6853 - val_loss: 0.8067
Epoch 16/56
315/315 [==============================] - 27s 86ms/step - loss: 0.6853 - val_loss: 0.8065
Epoch 17/56
315/315 [==============================] - 27s 87ms/step - loss: 0.6849 - val_loss: 0.8063
Epoch 18/56
315/315 [==============================] - 27s 86ms/step - loss: 0.6845 - val_loss: 0.8061
Epoch 19/56
315/315 [==============================] - 27s 87ms/step - loss: 0.6846 - val_loss: 0.8059
Epoch 20/56
315/315 [==============================] - 27s 86ms/step - loss: 0.6851 - val_loss: 0.8057
Epoch 21/56
315/315 [==============================] - 27s 86ms/step - loss: 0.6851 - val_loss: 0.8056
Epoch 22/56
315/315 [==============================] - 27s 87ms/step - loss: 0.6835 - val_loss: 0.8054
Epoch 23/56
315/315 [==============================] - 27s 86ms/step - loss: 0.6826 - val_loss: 0.8052
Epoch 24/56
315/315 [==============================] - 27s 86ms/step - loss: 0.6814 - val_loss: 0.8051
Epoch 25/56
315/315 [==============================] - 27s 86ms/step - loss: 0.6807 - val_loss: 0.8050
Epoch 26/56
315/315 [==============================] - 27s 87ms/step - loss: 0.6799 - val_loss: 0.8049
Epoch 27/56
315/315 [==============================] - 27s 86ms/step - loss: 0.6798 - val_loss: 0.8048
Epoch 28/56
315/315 [==============================] - 27s 85ms/step - loss: 0.6799 - val_loss: 0.8047
Epoch 29/56
315/315 [==============================] - 27s 86ms/step - loss: 0.6796 - val_loss: 0.8046
Epoch 30/56
315/315 [==============================] - 27s 86ms/step - loss: 0.6795 - val_loss: 0.8046
Epoch 31/56
315/315 [==============================] - 27s 86ms/step - loss: 0.6794 - val_loss: 0.8045
Epoch 32/56
315/315 [==============================] - 27s 86ms/step - loss: 0.6790 - val_loss: 0.8044
Epoch 33/56
315/315 [==============================] - 27s 86ms/step - loss: 0.6819 - val_loss: 0.8044
Epoch 34/56
315/315 [==============================] - 27s 87ms/step - loss: 0.6765 - val_loss: 0.8044
Epoch 35/56
315/315 [==============================] - 27s 86ms/step - loss: 0.6761 - val_loss: 0.8043
Epoch 36/56
315/315 [==============================] - 27s 86ms/step - loss: 0.6758 - val_loss: 0.8042
Epoch 37/56
315/315 [==============================] - 27s 86ms/step - loss: 0.6754 - val_loss: 0.8042
Epoch 38/56
315/315 [==============================] - 27s 86ms/step - loss: 0.6752 - val_loss: 0.8041
Epoch 39/56
315/315 [==============================] - 27s 86ms/step - loss: 0.6751 - val_loss: 0.8041
Epoch 40/56
315/315 [==============================] - 27s 86ms/step - loss: 0.6752 - val_loss: 0.8040
Epoch 41/56
315/315 [==============================] - 27s 85ms/step - loss: 0.6751 - val_loss: 0.8039
Epoch 42/56
315/315 [==============================] - 27s 86ms/step - loss: 0.6750 - val_loss: 0.8039
Epoch 43/56
315/315 [==============================] - 27s 86ms/step - loss: 0.6779 - val_loss: 0.8039
Epoch 44/56
315/315 [==============================] - 27s 86ms/step - loss: 0.6718 - val_loss: 0.8038
Epoch 45/56
315/315 [==============================] - 27s 86ms/step - loss: 0.6759 - val_loss: 0.8038
Epoch 46/56
315/315 [==============================] - 27s 86ms/step - loss: 0.6765 - val_loss: 0.8038
Epoch 47/56
315/315 [==============================] - 27s 86ms/step - loss: 0.6722 - val_loss: 0.8037
Epoch 48/56
315/315 [==============================] - 27s 86ms/step - loss: 0.6773 - val_loss: 0.8037
Epoch 49/56
315/315 [==============================] - 27s 86ms/step - loss: 0.6701 - val_loss: 0.8036
Epoch 50/56
315/315 [==============================] - 27s 86ms/step - loss: 0.6700 - val_loss: 0.8036
Epoch 51/56
315/315 [==============================] - 27s 86ms/step - loss: 0.6715 - val_loss: 0.8036
Epoch 52/56
315/315 [==============================] - 27s 86ms/step - loss: 0.6765 - val_loss: 0.8035
Epoch 53/56
315/315 [==============================] - 28s 88ms/step - loss: 0.6705 - val_loss: 0.8035
Epoch 54/56
315/315 [==============================] - 27s 86ms/step - loss: 0.6786 - val_loss: 0.8035
Epoch 55/56
315/315 [==============================] - 27s 86ms/step - loss: 0.6760 - val_loss: 0.8035
Epoch 56/56
315/315 [==============================] - 27s 86ms/step - loss: 0.6751 - val_loss: 0.8034
Execution time:  1528.9490535259247
LSTM:
Mean Absolute Error: 0.6673
Root Mean Square Error: 0.9594
Mean Square Error: 0.9205

Train RMSE: 0.959
Train MSE: 0.921
Train MAE: 0.667
###########################

MODEL:  LSTM
sequence:  1d
units:  45
dropout1:  0.11814836227952394
dropout2:  0.24325404382648977
optimizer: adamax
activationDense: sigmoid
epochs: 43
batchsize: 30
validation_split: 0.2
Model: &#34;sequential_59&#34;
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
lstm_118 (LSTM)              (None, 144, 45)           8460      
_________________________________________________________________
dropout_118 (Dropout)        (None, 144, 45)           0         
_________________________________________________________________
lstm_119 (LSTM)              (None, 144, 45)           16380     
_________________________________________________________________
dropout_119 (Dropout)        (None, 144, 45)           0         
_________________________________________________________________
time_distributed_59 (TimeDis (None, 144, 1)            46        
=================================================================
Total params: 24,886
Trainable params: 24,886
Non-trainable params: 0
_________________________________________________________________
Epoch 1/43
103/103 [==============================] - 11s 106ms/step - loss: 0.8274 - val_loss: 0.8520
Epoch 2/43
103/103 [==============================] - 11s 103ms/step - loss: 0.7189 - val_loss: 0.7815
Epoch 3/43
103/103 [==============================] - 10s 101ms/step - loss: 0.7023 - val_loss: 0.7692
Epoch 4/43
103/103 [==============================] - 10s 101ms/step - loss: 0.6947 - val_loss: 0.7633
Epoch 5/43
103/103 [==============================] - 10s 102ms/step - loss: 0.6903 - val_loss: 0.7595
Epoch 6/43
103/103 [==============================] - 11s 102ms/step - loss: 0.6884 - val_loss: 0.7569
Epoch 7/43
103/103 [==============================] - 10s 101ms/step - loss: 0.6869 - val_loss: 0.7550
Epoch 8/43
103/103 [==============================] - 10s 102ms/step - loss: 0.6856 - val_loss: 0.7535
Epoch 9/43
103/103 [==============================] - 11s 102ms/step - loss: 0.6845 - val_loss: 0.7521
Epoch 10/43
103/103 [==============================] - 10s 101ms/step - loss: 0.6833 - val_loss: 0.7509
Epoch 11/43
103/103 [==============================] - 11s 102ms/step - loss: 0.6821 - val_loss: 0.7496
Epoch 12/43
103/103 [==============================] - 11s 103ms/step - loss: 0.6806 - val_loss: 0.7484
Epoch 13/43
103/103 [==============================] - 10s 101ms/step - loss: 0.6790 - val_loss: 0.7472
Epoch 14/43
103/103 [==============================] - 11s 102ms/step - loss: 0.6773 - val_loss: 0.7457
Epoch 15/43
103/103 [==============================] - 10s 102ms/step - loss: 0.6757 - val_loss: 0.7439
Epoch 16/43
103/103 [==============================] - 10s 102ms/step - loss: 0.6738 - val_loss: 0.7416
Epoch 17/43
103/103 [==============================] - 11s 102ms/step - loss: 0.6717 - val_loss: 0.7385
Epoch 18/43
103/103 [==============================] - 10s 101ms/step - loss: 0.6690 - val_loss: 0.7336
Epoch 19/43
103/103 [==============================] - 10s 101ms/step - loss: 0.6695 - val_loss: 0.7311
Epoch 20/43
103/103 [==============================] - 10s 101ms/step - loss: 0.6680 - val_loss: 0.7297
Epoch 21/43
103/103 [==============================] - 10s 101ms/step - loss: 0.6674 - val_loss: 0.7285
Epoch 22/43
103/103 [==============================] - 10s 102ms/step - loss: 0.6665 - val_loss: 0.7271
Epoch 23/43
103/103 [==============================] - 11s 102ms/step - loss: 0.6655 - val_loss: 0.7259
Epoch 24/43
103/103 [==============================] - 10s 101ms/step - loss: 0.6642 - val_loss: 0.7244
Epoch 25/43
103/103 [==============================] - 10s 102ms/step - loss: 0.6630 - val_loss: 0.7236
Epoch 26/43
103/103 [==============================] - 11s 102ms/step - loss: 0.6607 - val_loss: 0.7222
Epoch 27/43
103/103 [==============================] - 10s 102ms/step - loss: 0.6577 - val_loss: 0.7219
Epoch 28/43
103/103 [==============================] - 11s 102ms/step - loss: 0.6543 - val_loss: 0.7211
Epoch 29/43
103/103 [==============================] - 10s 102ms/step - loss: 0.6525 - val_loss: 0.7198
Epoch 30/43
103/103 [==============================] - 10s 101ms/step - loss: 0.6538 - val_loss: 0.7193
Epoch 31/43
103/103 [==============================] - 10s 101ms/step - loss: 0.6541 - val_loss: 0.7195
Epoch 32/43
103/103 [==============================] - 10s 102ms/step - loss: 0.6503 - val_loss: 0.7191
Epoch 33/43
103/103 [==============================] - 10s 101ms/step - loss: 0.6499 - val_loss: 0.7187
Epoch 34/43
103/103 [==============================] - 11s 102ms/step - loss: 0.6499 - val_loss: 0.7185
Epoch 35/43
103/103 [==============================] - 11s 103ms/step - loss: 0.6495 - val_loss: 0.7184
Epoch 36/43
103/103 [==============================] - 10s 101ms/step - loss: 0.6495 - val_loss: 0.7182
Epoch 37/43
103/103 [==============================] - 11s 102ms/step - loss: 0.6491 - val_loss: 0.7180
Epoch 38/43
103/103 [==============================] - 10s 102ms/step - loss: 0.6495 - val_loss: 0.7177
Epoch 39/43
103/103 [==============================] - 10s 101ms/step - loss: 0.6490 - val_loss: 0.7178
Epoch 40/43
103/103 [==============================] - 10s 102ms/step - loss: 0.6483 - val_loss: 0.7177
Epoch 41/43
103/103 [==============================] - 10s 102ms/step - loss: 0.6483 - val_loss: 0.7175
Epoch 42/43
103/103 [==============================] - 10s 101ms/step - loss: 0.6488 - val_loss: 0.7173
Epoch 43/43
103/103 [==============================] - 11s 102ms/step - loss: 0.6516 - val_loss: 0.7173
Execution time:  459.6406066417694
LSTM:
Mean Absolute Error: 0.6252
Root Mean Square Error: 0.9181
Mean Square Error: 0.8428

Train RMSE: 0.918
Train MSE: 0.843
Train MAE: 0.625
###########################

MODEL:  LSTM
sequence:  3d
units:  43
dropout1:  0.40519643149940265
dropout2:  0.3312343747027119
optimizer: adam
activationDense: tanh
epochs: 56
batchsize: 11
validation_split: 0.1
Model: &#34;sequential_60&#34;
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
lstm_120 (LSTM)              (None, 432, 43)           7740      
_________________________________________________________________
dropout_120 (Dropout)        (None, 432, 43)           0         
_________________________________________________________________
lstm_121 (LSTM)              (None, 432, 43)           14964     
_________________________________________________________________
dropout_121 (Dropout)        (None, 432, 43)           0         
_________________________________________________________________
time_distributed_60 (TimeDis (None, 432, 1)            44        
=================================================================
Total params: 22,748
Trainable params: 22,748
Non-trainable params: 0
_________________________________________________________________
Epoch 1/56
292/292 [==============================] - 75s 255ms/step - loss: 0.6448 - val_loss: 0.4795
Epoch 2/56
292/292 [==============================] - 75s 256ms/step - loss: 0.6592 - val_loss: 0.3918
Epoch 3/56
292/292 [==============================] - 75s 256ms/step - loss: 0.6601 - val_loss: 0.4769
Epoch 4/56
292/292 [==============================] - 75s 255ms/step - loss: 0.6436 - val_loss: 0.3876
Epoch 5/56
292/292 [==============================] - 75s 255ms/step - loss: 0.6300 - val_loss: 0.4009
Epoch 6/56
292/292 [==============================] - 75s 256ms/step - loss: 0.6254 - val_loss: 0.4102
Epoch 7/56
292/292 [==============================] - 75s 256ms/step - loss: 0.6225 - val_loss: 0.4165
Epoch 8/56
292/292 [==============================] - 75s 255ms/step - loss: 0.6207 - val_loss: 0.4200
Epoch 9/56
292/292 [==============================] - 75s 256ms/step - loss: 0.6193 - val_loss: 0.4218
Epoch 10/56
292/292 [==============================] - 75s 257ms/step - loss: 0.6184 - val_loss: 0.4233
Epoch 11/56
292/292 [==============================] - 75s 256ms/step - loss: 0.6178 - val_loss: 0.4246
Epoch 12/56
292/292 [==============================] - 75s 256ms/step - loss: 0.6171 - val_loss: 0.4251
Epoch 13/56
292/292 [==============================] - 74s 255ms/step - loss: 0.6166 - val_loss: 0.4254
Epoch 14/56
292/292 [==============================] - 75s 256ms/step - loss: 0.6160 - val_loss: 0.4260
Epoch 15/56
292/292 [==============================] - 75s 256ms/step - loss: 0.6156 - val_loss: 0.4271
Epoch 16/56
292/292 [==============================] - 74s 255ms/step - loss: 0.6152 - val_loss: 0.4277
Epoch 17/56
292/292 [==============================] - 75s 256ms/step - loss: 0.6151 - val_loss: 0.4323
Epoch 18/56
292/292 [==============================] - 75s 256ms/step - loss: 0.6145 - val_loss: 0.4401
Epoch 19/56
292/292 [==============================] - 74s 255ms/step - loss: 0.6131 - val_loss: 0.4514
Epoch 20/56
292/292 [==============================] - 75s 255ms/step - loss: 0.6105 - val_loss: 0.4611
Epoch 21/56
292/292 [==============================] - 75s 255ms/step - loss: 0.6082 - val_loss: 0.4649
Epoch 22/56
292/292 [==============================] - 75s 255ms/step - loss: 0.6072 - val_loss: 0.4677
Epoch 23/56
292/292 [==============================] - 75s 255ms/step - loss: 0.6067 - val_loss: 0.4692
Epoch 24/56
292/292 [==============================] - 75s 255ms/step - loss: 0.6064 - val_loss: 0.4701
Epoch 25/56
292/292 [==============================] - 75s 255ms/step - loss: 0.6063 - val_loss: 0.4712
Epoch 26/56
292/292 [==============================] - 75s 256ms/step - loss: 0.6061 - val_loss: 0.4715
Epoch 27/56
292/292 [==============================] - 74s 255ms/step - loss: 0.6061 - val_loss: 0.4719
Epoch 28/56
292/292 [==============================] - 75s 256ms/step - loss: 0.6060 - val_loss: 0.4714
Epoch 29/56
292/292 [==============================] - 75s 255ms/step - loss: 0.6061 - val_loss: 0.4718
Epoch 30/56
292/292 [==============================] - 75s 256ms/step - loss: 0.6060 - val_loss: 0.4719
Epoch 31/56
292/292 [==============================] - 75s 256ms/step - loss: 0.6060 - val_loss: 0.4719
Epoch 32/56
292/292 [==============================] - 74s 255ms/step - loss: 0.6060 - val_loss: 0.4720
Epoch 33/56
292/292 [==============================] - 75s 255ms/step - loss: 0.6060 - val_loss: 0.4719
Epoch 34/56
292/292 [==============================] - 75s 256ms/step - loss: 0.6060 - val_loss: 0.4720
Epoch 35/56
292/292 [==============================] - 74s 255ms/step - loss: 0.6060 - val_loss: 0.4720
Epoch 36/56
292/292 [==============================] - 75s 256ms/step - loss: 0.6060 - val_loss: 0.4720
Epoch 37/56
292/292 [==============================] - 75s 255ms/step - loss: 0.6060 - val_loss: 0.4720
Epoch 38/56
292/292 [==============================] - 75s 256ms/step - loss: 0.6059 - val_loss: 0.4707
Epoch 39/56
292/292 [==============================] - 75s 256ms/step - loss: 0.6060 - val_loss: 0.4712
Epoch 40/56
292/292 [==============================] - 74s 255ms/step - loss: 0.6060 - val_loss: 0.4716
Epoch 41/56
292/292 [==============================] - 75s 256ms/step - loss: 0.6060 - val_loss: 0.4720
Epoch 42/56
292/292 [==============================] - 75s 256ms/step - loss: 0.6059 - val_loss: 0.4706
Epoch 43/56
292/292 [==============================] - 75s 255ms/step - loss: 0.6060 - val_loss: 0.4710
Epoch 44/56
292/292 [==============================] - 75s 255ms/step - loss: 0.6060 - val_loss: 0.4715
Epoch 45/56
292/292 [==============================] - 74s 255ms/step - loss: 0.6060 - val_loss: 0.4719
Epoch 46/56
292/292 [==============================] - 75s 256ms/step - loss: 0.6060 - val_loss: 0.4720
Epoch 47/56
292/292 [==============================] - 75s 255ms/step - loss: 0.6060 - val_loss: 0.4720
Epoch 48/56
292/292 [==============================] - 75s 255ms/step - loss: 0.6059 - val_loss: 0.4713
Epoch 49/56
292/292 [==============================] - 75s 256ms/step - loss: 0.6060 - val_loss: 0.4717
Epoch 50/56
292/292 [==============================] - 75s 256ms/step - loss: 0.6060 - val_loss: 0.4722
Epoch 51/56
292/292 [==============================] - 75s 255ms/step - loss: 0.6059 - val_loss: 0.4714
Epoch 52/56
292/292 [==============================] - 75s 256ms/step - loss: 0.6060 - val_loss: 0.4719
Epoch 53/56
292/292 [==============================] - 75s 256ms/step - loss: 0.6060 - val_loss: 0.4720
Epoch 54/56
292/292 [==============================] - 75s 256ms/step - loss: 0.6060 - val_loss: 0.4721
Epoch 55/56
292/292 [==============================] - 75s 256ms/step - loss: 0.6059 - val_loss: 0.4713
Epoch 56/56
292/292 [==============================] - 75s 256ms/step - loss: 0.6060 - val_loss: 0.4718
Execution time:  4198.491082668304
LSTM:
Mean Absolute Error: 0.6161
Root Mean Square Error: 1.0443
Mean Square Error: 1.0905

Train RMSE: 1.044
Train MSE: 1.091
Train MAE: 0.616
###########################

MODEL:  LSTM
sequence:  3d
units:  45
dropout1:  0.11814836227952394
dropout2:  0.24325404382648977
optimizer: adam
activationDense: tanh
epochs: 43
batchsize: 30
validation_split: 0.2
Model: &#34;sequential_61&#34;
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
lstm_122 (LSTM)              (None, 432, 45)           8460      
_________________________________________________________________
dropout_122 (Dropout)        (None, 432, 45)           0         
_________________________________________________________________
lstm_123 (LSTM)              (None, 432, 45)           16380     
_________________________________________________________________
dropout_123 (Dropout)        (None, 432, 45)           0         
_________________________________________________________________
time_distributed_61 (TimeDis (None, 432, 1)            46        
=================================================================
Total params: 24,886
Trainable params: 24,886
Non-trainable params: 0
_________________________________________________________________
Epoch 1/43
95/95 [==============================] - 30s 315ms/step - loss: 0.6934 - val_loss: 0.3609
Epoch 2/43
95/95 [==============================] - 29s 303ms/step - loss: 0.6768 - val_loss: 0.3008
Epoch 3/43
95/95 [==============================] - 29s 302ms/step - loss: 0.6743 - val_loss: 0.3198
Epoch 4/43
95/95 [==============================] - 29s 302ms/step - loss: 0.6687 - val_loss: 0.3328
Epoch 5/43
95/95 [==============================] - 29s 303ms/step - loss: 0.6637 - val_loss: 0.3347
Epoch 6/43
95/95 [==============================] - 29s 303ms/step - loss: 0.6618 - val_loss: 0.3346
Epoch 7/43
95/95 [==============================] - 29s 301ms/step - loss: 0.6606 - val_loss: 0.3345
Epoch 8/43
95/95 [==============================] - 29s 300ms/step - loss: 0.6590 - val_loss: 0.3354
Epoch 9/43
95/95 [==============================] - 29s 301ms/step - loss: 0.6576 - val_loss: 0.3360
Epoch 10/43
95/95 [==============================] - 28s 300ms/step - loss: 0.6566 - val_loss: 0.3362
Epoch 11/43
95/95 [==============================] - 29s 302ms/step - loss: 0.6560 - val_loss: 0.3356
Epoch 12/43
95/95 [==============================] - 29s 302ms/step - loss: 0.6550 - val_loss: 0.3350
Epoch 13/43
95/95 [==============================] - 29s 303ms/step - loss: 0.6543 - val_loss: 0.3353
Epoch 14/43
95/95 [==============================] - 28s 300ms/step - loss: 0.6528 - val_loss: 0.3328
Epoch 15/43
95/95 [==============================] - 29s 302ms/step - loss: 0.6522 - val_loss: 0.3355
Epoch 16/43
95/95 [==============================] - 29s 302ms/step - loss: 0.6506 - val_loss: 0.3368
Epoch 17/43
95/95 [==============================] - 29s 304ms/step - loss: 0.6454 - val_loss: 0.3249
Epoch 18/43
95/95 [==============================] - 29s 301ms/step - loss: 0.6402 - val_loss: 0.3639
Epoch 19/43
95/95 [==============================] - 29s 304ms/step - loss: 0.6396 - val_loss: 0.3600
Epoch 20/43
95/95 [==============================] - 29s 302ms/step - loss: 0.6376 - val_loss: 0.3689
Epoch 21/43
95/95 [==============================] - 29s 302ms/step - loss: 0.6339 - val_loss: 0.3789
Epoch 22/43
95/95 [==============================] - 29s 302ms/step - loss: 0.6316 - val_loss: 0.3799
Epoch 23/43
95/95 [==============================] - 29s 303ms/step - loss: 0.6305 - val_loss: 0.3800
Epoch 24/43
95/95 [==============================] - 29s 302ms/step - loss: 0.6302 - val_loss: 0.3786
Epoch 25/43
95/95 [==============================] - 29s 304ms/step - loss: 0.6310 - val_loss: 0.3730
Epoch 26/43
95/95 [==============================] - 29s 303ms/step - loss: 0.6317 - val_loss: 0.3799
Epoch 27/43
95/95 [==============================] - 29s 303ms/step - loss: 0.6300 - val_loss: 0.3806
Epoch 28/43
95/95 [==============================] - 29s 302ms/step - loss: 0.6295 - val_loss: 0.3808
Epoch 29/43
95/95 [==============================] - 29s 301ms/step - loss: 0.6298 - val_loss: 0.3786
Epoch 30/43
95/95 [==============================] - 29s 304ms/step - loss: 0.6303 - val_loss: 0.3788
Epoch 31/43
95/95 [==============================] - 28s 299ms/step - loss: 0.6307 - val_loss: 0.3680
Epoch 32/43
95/95 [==============================] - 29s 304ms/step - loss: 0.6306 - val_loss: 0.3781
Epoch 33/43
95/95 [==============================] - 29s 303ms/step - loss: 0.6291 - val_loss: 0.3792
Epoch 34/43
95/95 [==============================] - 29s 301ms/step - loss: 0.6287 - val_loss: 0.3799
Epoch 35/43
95/95 [==============================] - 29s 302ms/step - loss: 0.6285 - val_loss: 0.3796
Epoch 36/43
95/95 [==============================] - 28s 299ms/step - loss: 0.6293 - val_loss: 0.3743
Epoch 37/43
95/95 [==============================] - 29s 300ms/step - loss: 0.6294 - val_loss: 0.3691
Epoch 38/43
95/95 [==============================] - 29s 304ms/step - loss: 0.6293 - val_loss: 0.3754
Epoch 39/43
95/95 [==============================] - 29s 302ms/step - loss: 0.6282 - val_loss: 0.3757
Epoch 40/43
95/95 [==============================] - 29s 301ms/step - loss: 0.6411 - val_loss: 0.3614
Epoch 41/43
95/95 [==============================] - 29s 301ms/step - loss: 0.6349 - val_loss: 0.3690
Epoch 42/43
95/95 [==============================] - 29s 303ms/step - loss: 0.6303 - val_loss: 0.3446
Epoch 43/43
95/95 [==============================] - 29s 304ms/step - loss: 0.6314 - val_loss: 0.3763
Execution time:  1254.0413279533386
LSTM:
Mean Absolute Error: 0.5610
Root Mean Square Error: 1.0127
Mean Square Error: 1.0257

Train RMSE: 1.013
Train MSE: 1.026
Train MAE: 0.561
###########################

MODEL:  LSTM
sequence:  3d
units:  43
dropout1:  0.40519643149940265
dropout2:  0.3312343747027119
optimizer: adam
activationDense: sigmoid
epochs: 56
batchsize: 11
validation_split: 0.1
Model: &#34;sequential_62&#34;
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
lstm_124 (LSTM)              (None, 432, 43)           7740      
_________________________________________________________________
dropout_124 (Dropout)        (None, 432, 43)           0         
_________________________________________________________________
lstm_125 (LSTM)              (None, 432, 43)           14964     
_________________________________________________________________
dropout_125 (Dropout)        (None, 432, 43)           0         
_________________________________________________________________
time_distributed_62 (TimeDis (None, 432, 1)            44        
=================================================================
Total params: 22,748
Trainable params: 22,748
Non-trainable params: 0
_________________________________________________________________
Epoch 1/56
292/292 [==============================] - 74s 254ms/step - loss: 0.7419 - val_loss: 0.8070
Epoch 2/56
292/292 [==============================] - 74s 254ms/step - loss: 0.6795 - val_loss: 0.7981
Epoch 3/56
292/292 [==============================] - 75s 256ms/step - loss: 0.6777 - val_loss: 0.7962
Epoch 4/56
292/292 [==============================] - 75s 257ms/step - loss: 0.6771 - val_loss: 0.7953
Epoch 5/56
292/292 [==============================] - 75s 258ms/step - loss: 0.6768 - val_loss: 0.7947
Epoch 6/56
292/292 [==============================] - 75s 258ms/step - loss: 0.6766 - val_loss: 0.7943
Epoch 7/56
292/292 [==============================] - 75s 258ms/step - loss: 0.6764 - val_loss: 0.7941
Epoch 8/56
292/292 [==============================] - 75s 258ms/step - loss: 0.6763 - val_loss: 0.7938
Epoch 9/56
292/292 [==============================] - 75s 258ms/step - loss: 0.6762 - val_loss: 0.7936
Epoch 10/56
292/292 [==============================] - 75s 258ms/step - loss: 0.6761 - val_loss: 0.7935
Epoch 11/56
292/292 [==============================] - 75s 258ms/step - loss: 0.6761 - val_loss: 0.7934
Epoch 12/56
292/292 [==============================] - 75s 258ms/step - loss: 0.6760 - val_loss: 0.7933
Epoch 13/56
292/292 [==============================] - 76s 259ms/step - loss: 0.6760 - val_loss: 0.7931
Epoch 14/56
292/292 [==============================] - 75s 258ms/step - loss: 0.6759 - val_loss: 0.7931
Epoch 15/56
292/292 [==============================] - 75s 257ms/step - loss: 0.6759 - val_loss: 0.7930
Epoch 16/56
292/292 [==============================] - 76s 259ms/step - loss: 0.6758 - val_loss: 0.7929
Epoch 17/56
292/292 [==============================] - 75s 258ms/step - loss: 0.6758 - val_loss: 0.7929
Epoch 18/56
292/292 [==============================] - 75s 258ms/step - loss: 0.6758 - val_loss: 0.7928
Epoch 19/56
292/292 [==============================] - 76s 259ms/step - loss: 0.6758 - val_loss: 0.7928
Epoch 20/56
292/292 [==============================] - 76s 259ms/step - loss: 0.6758 - val_loss: 0.7928
Epoch 21/56
292/292 [==============================] - 76s 259ms/step - loss: 0.6758 - val_loss: 0.7928
Epoch 22/56
292/292 [==============================] - 76s 259ms/step - loss: 0.6758 - val_loss: 0.7928
Epoch 23/56
292/292 [==============================] - 76s 259ms/step - loss: 0.6758 - val_loss: 0.7928
Epoch 24/56
292/292 [==============================] - 76s 259ms/step - loss: 0.6758 - val_loss: 0.7928
Epoch 25/56
292/292 [==============================] - 76s 259ms/step - loss: 0.6758 - val_loss: 0.7927
Epoch 26/56
292/292 [==============================] - 75s 259ms/step - loss: 0.6758 - val_loss: 0.7927
Epoch 27/56
292/292 [==============================] - 76s 259ms/step - loss: 0.6758 - val_loss: 0.7927
Epoch 28/56
292/292 [==============================] - 76s 260ms/step - loss: 0.6758 - val_loss: 0.7927
Epoch 29/56
292/292 [==============================] - 76s 259ms/step - loss: 0.6758 - val_loss: 0.7927
Epoch 30/56
292/292 [==============================] - 76s 259ms/step - loss: 0.6757 - val_loss: 0.7927
Epoch 31/56
292/292 [==============================] - 76s 259ms/step - loss: 0.6757 - val_loss: 0.7927
Epoch 32/56
292/292 [==============================] - 76s 259ms/step - loss: 0.6757 - val_loss: 0.7927
Epoch 33/56
292/292 [==============================] - 76s 259ms/step - loss: 0.6757 - val_loss: 0.7927
Epoch 34/56
292/292 [==============================] - 75s 258ms/step - loss: 0.6757 - val_loss: 0.7927
Epoch 35/56
292/292 [==============================] - 76s 259ms/step - loss: 0.6757 - val_loss: 0.7927
Epoch 36/56
292/292 [==============================] - 76s 260ms/step - loss: 0.6757 - val_loss: 0.7927
Epoch 37/56
292/292 [==============================] - 76s 259ms/step - loss: 0.6757 - val_loss: 0.7927
Epoch 38/56
292/292 [==============================] - 76s 259ms/step - loss: 0.6757 - val_loss: 0.7927
Epoch 39/56
292/292 [==============================] - 76s 259ms/step - loss: 0.6757 - val_loss: 0.7927
Epoch 40/56
292/292 [==============================] - 76s 259ms/step - loss: 0.6757 - val_loss: 0.7927
Epoch 41/56
292/292 [==============================] - 76s 259ms/step - loss: 0.6757 - val_loss: 0.7927
Epoch 42/56
292/292 [==============================] - 75s 259ms/step - loss: 0.6757 - val_loss: 0.7927
Epoch 43/56
292/292 [==============================] - 76s 259ms/step - loss: 0.6757 - val_loss: 0.7927
Epoch 44/56
292/292 [==============================] - 76s 259ms/step - loss: 0.6757 - val_loss: 0.7927
Epoch 45/56
292/292 [==============================] - 75s 258ms/step - loss: 0.6757 - val_loss: 0.7927
Epoch 46/56
292/292 [==============================] - 76s 259ms/step - loss: 0.6757 - val_loss: 0.7927
Epoch 47/56
292/292 [==============================] - 76s 259ms/step - loss: 0.6757 - val_loss: 0.7927
Epoch 48/56
292/292 [==============================] - 76s 259ms/step - loss: 0.6757 - val_loss: 0.7927
Epoch 49/56
292/292 [==============================] - 76s 259ms/step - loss: 0.6757 - val_loss: 0.7927
Epoch 50/56
292/292 [==============================] - 76s 259ms/step - loss: 0.6757 - val_loss: 0.7927
Epoch 51/56
292/292 [==============================] - 76s 259ms/step - loss: 0.6757 - val_loss: 0.7927
Epoch 52/56
292/292 [==============================] - 76s 259ms/step - loss: 0.6757 - val_loss: 0.7927
Epoch 53/56
292/292 [==============================] - 75s 258ms/step - loss: 0.6757 - val_loss: 0.7927
Epoch 54/56
292/292 [==============================] - 76s 259ms/step - loss: 0.6757 - val_loss: 0.7927
Epoch 55/56
292/292 [==============================] - 76s 259ms/step - loss: 0.6757 - val_loss: 0.7927
Epoch 56/56
292/292 [==============================] - 76s 259ms/step - loss: 0.6757 - val_loss: 0.7927
Execution time:  4246.793601036072
LSTM:
Mean Absolute Error: 0.6930
Root Mean Square Error: 0.9952
Mean Square Error: 0.9904

Train RMSE: 0.995
Train MSE: 0.990
Train MAE: 0.693
###########################

MODEL:  LSTM
sequence:  3d
units:  45
dropout1:  0.11814836227952394
dropout2:  0.24325404382648977
optimizer: adam
activationDense: sigmoid
epochs: 43
batchsize: 30
validation_split: 0.2
Model: &#34;sequential_63&#34;
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
lstm_126 (LSTM)              (None, 432, 45)           8460      
_________________________________________________________________
dropout_126 (Dropout)        (None, 432, 45)           0         
_________________________________________________________________
lstm_127 (LSTM)              (None, 432, 45)           16380     
_________________________________________________________________
dropout_127 (Dropout)        (None, 432, 45)           0         
_________________________________________________________________
time_distributed_63 (TimeDis (None, 432, 1)            46        
=================================================================
Total params: 24,886
Trainable params: 24,886
Non-trainable params: 0
_________________________________________________________________
Epoch 1/43
95/95 [==============================] - 30s 320ms/step - loss: 0.8742 - val_loss: 0.7188
Epoch 2/43
95/95 [==============================] - 29s 308ms/step - loss: 0.7187 - val_loss: 0.6367
Epoch 3/43
95/95 [==============================] - 29s 307ms/step - loss: 0.7102 - val_loss: 0.6293
Epoch 4/43
95/95 [==============================] - 29s 307ms/step - loss: 0.7084 - val_loss: 0.6262
Epoch 5/43
95/95 [==============================] - 29s 306ms/step - loss: 0.7075 - val_loss: 0.6244
Epoch 6/43
95/95 [==============================] - 29s 305ms/step - loss: 0.7069 - val_loss: 0.6233
Epoch 7/43
95/95 [==============================] - 29s 305ms/step - loss: 0.7066 - val_loss: 0.6226
Epoch 8/43
95/95 [==============================] - 29s 305ms/step - loss: 0.7063 - val_loss: 0.6220
Epoch 9/43
95/95 [==============================] - 29s 305ms/step - loss: 0.7061 - val_loss: 0.6216
Epoch 10/43
95/95 [==============================] - 29s 307ms/step - loss: 0.7060 - val_loss: 0.6212
Epoch 11/43
95/95 [==============================] - 29s 308ms/step - loss: 0.7058 - val_loss: 0.6209
Epoch 12/43
95/95 [==============================] - 29s 305ms/step - loss: 0.7057 - val_loss: 0.6207
Epoch 13/43
95/95 [==============================] - 29s 308ms/step - loss: 0.7056 - val_loss: 0.6205
Epoch 14/43
95/95 [==============================] - 29s 307ms/step - loss: 0.7056 - val_loss: 0.6203
Epoch 15/43
95/95 [==============================] - 29s 304ms/step - loss: 0.7055 - val_loss: 0.6201
Epoch 16/43
95/95 [==============================] - 29s 305ms/step - loss: 0.7054 - val_loss: 0.6200
Epoch 17/43
95/95 [==============================] - 29s 304ms/step - loss: 0.7054 - val_loss: 0.6198
Epoch 18/43
95/95 [==============================] - 29s 306ms/step - loss: 0.7053 - val_loss: 0.6197
Epoch 19/43
95/95 [==============================] - 29s 306ms/step - loss: 0.7053 - val_loss: 0.6196
Epoch 20/43
95/95 [==============================] - 29s 306ms/step - loss: 0.7052 - val_loss: 0.6195
Epoch 21/43
95/95 [==============================] - 29s 303ms/step - loss: 0.7052 - val_loss: 0.6194
Epoch 22/43
95/95 [==============================] - 29s 304ms/step - loss: 0.7052 - val_loss: 0.6193
Epoch 23/43
95/95 [==============================] - 29s 302ms/step - loss: 0.7051 - val_loss: 0.6192
Epoch 24/43
95/95 [==============================] - 29s 304ms/step - loss: 0.7051 - val_loss: 0.6192
Epoch 25/43
95/95 [==============================] - 29s 306ms/step - loss: 0.7051 - val_loss: 0.6191
Epoch 26/43
95/95 [==============================] - 29s 307ms/step - loss: 0.7051 - val_loss: 0.6190
Epoch 27/43
95/95 [==============================] - 29s 304ms/step - loss: 0.7050 - val_loss: 0.6190
Epoch 28/43
95/95 [==============================] - 29s 305ms/step - loss: 0.7050 - val_loss: 0.6189
Epoch 29/43
95/95 [==============================] - 29s 304ms/step - loss: 0.7050 - val_loss: 0.6189
Epoch 30/43
95/95 [==============================] - 29s 305ms/step - loss: 0.7050 - val_loss: 0.6188
Epoch 31/43
95/95 [==============================] - 29s 308ms/step - loss: 0.7049 - val_loss: 0.6188
Epoch 32/43
95/95 [==============================] - 29s 304ms/step - loss: 0.7049 - val_loss: 0.6187
Epoch 33/43
95/95 [==============================] - 29s 305ms/step - loss: 0.7049 - val_loss: 0.6187
Epoch 34/43
95/95 [==============================] - 29s 305ms/step - loss: 0.7049 - val_loss: 0.6187
Epoch 35/43
95/95 [==============================] - 29s 304ms/step - loss: 0.7049 - val_loss: 0.6186
Epoch 36/43
95/95 [==============================] - 29s 303ms/step - loss: 0.7049 - val_loss: 0.6186
Epoch 37/43
95/95 [==============================] - 30s 312ms/step - loss: 0.7049 - val_loss: 0.6186
Epoch 38/43
95/95 [==============================] - 29s 303ms/step - loss: 0.7049 - val_loss: 0.6185
Epoch 39/43
95/95 [==============================] - 29s 302ms/step - loss: 0.7048 - val_loss: 0.6185
Epoch 40/43
95/95 [==============================] - 29s 304ms/step - loss: 0.7048 - val_loss: 0.6185
Epoch 41/43
95/95 [==============================] - 29s 302ms/step - loss: 0.7048 - val_loss: 0.6185
Epoch 42/43
95/95 [==============================] - 29s 306ms/step - loss: 0.7048 - val_loss: 0.6184
Epoch 43/43
95/95 [==============================] - 29s 306ms/step - loss: 0.7048 - val_loss: 0.6184
Execution time:  1267.4651937484741
LSTM:
Mean Absolute Error: 0.6930
Root Mean Square Error: 0.9952
Mean Square Error: 0.9904

Train RMSE: 0.995
Train MSE: 0.990
Train MAE: 0.693
###########################

MODEL:  LSTM
sequence:  3d
units:  43
dropout1:  0.40519643149940265
dropout2:  0.3312343747027119
optimizer: adadelta
activationDense: tanh
epochs: 56
batchsize: 11
validation_split: 0.1
Model: &#34;sequential_64&#34;
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
lstm_128 (LSTM)              (None, 432, 43)           7740      
_________________________________________________________________
dropout_128 (Dropout)        (None, 432, 43)           0         
_________________________________________________________________
lstm_129 (LSTM)              (None, 432, 43)           14964     
_________________________________________________________________
dropout_129 (Dropout)        (None, 432, 43)           0         
_________________________________________________________________
time_distributed_64 (TimeDis (None, 432, 1)            44        
=================================================================
Total params: 22,748
Trainable params: 22,748
Non-trainable params: 0
_________________________________________________________________
Epoch 1/56
292/292 [==============================] - 75s 256ms/step - loss: 0.6770 - val_loss: 0.7994
Epoch 2/56
292/292 [==============================] - 75s 258ms/step - loss: 0.6761 - val_loss: 0.7959
Epoch 3/56
292/292 [==============================] - 76s 259ms/step - loss: 0.6752 - val_loss: 0.7923
Epoch 4/56
292/292 [==============================] - 75s 258ms/step - loss: 0.6741 - val_loss: 0.7885
Epoch 5/56
292/292 [==============================] - 75s 257ms/step - loss: 0.6731 - val_loss: 0.7846
Epoch 6/56
292/292 [==============================] - 75s 257ms/step - loss: 0.6719 - val_loss: 0.7805
Epoch 7/56
292/292 [==============================] - 75s 257ms/step - loss: 0.6707 - val_loss: 0.7764
Epoch 8/56
292/292 [==============================] - 75s 257ms/step - loss: 0.6695 - val_loss: 0.7720
Epoch 9/56
292/292 [==============================] - 75s 258ms/step - loss: 0.6683 - val_loss: 0.7675
Epoch 10/56
292/292 [==============================] - 75s 257ms/step - loss: 0.6670 - val_loss: 0.7628
Epoch 11/56
292/292 [==============================] - 75s 258ms/step - loss: 0.6656 - val_loss: 0.7580
Epoch 12/56
292/292 [==============================] - 75s 257ms/step - loss: 0.6642 - val_loss: 0.7531
Epoch 13/56
292/292 [==============================] - 75s 257ms/step - loss: 0.6628 - val_loss: 0.7480
Epoch 14/56
292/292 [==============================] - 75s 258ms/step - loss: 0.6614 - val_loss: 0.7430
Epoch 15/56
292/292 [==============================] - 75s 258ms/step - loss: 0.6601 - val_loss: 0.7379
Epoch 16/56
292/292 [==============================] - 75s 257ms/step - loss: 0.6587 - val_loss: 0.7328
Epoch 17/56
292/292 [==============================] - 75s 258ms/step - loss: 0.6574 - val_loss: 0.7277
Epoch 18/56
292/292 [==============================] - 75s 257ms/step - loss: 0.6561 - val_loss: 0.7226
Epoch 19/56
292/292 [==============================] - 75s 257ms/step - loss: 0.6549 - val_loss: 0.7174
Epoch 20/56
292/292 [==============================] - 75s 258ms/step - loss: 0.6536 - val_loss: 0.7121
Epoch 21/56
292/292 [==============================] - 75s 257ms/step - loss: 0.6524 - val_loss: 0.7068
Epoch 22/56
292/292 [==============================] - 75s 257ms/step - loss: 0.6511 - val_loss: 0.7014
Epoch 23/56
292/292 [==============================] - 75s 258ms/step - loss: 0.6498 - val_loss: 0.6958
Epoch 24/56
292/292 [==============================] - 75s 257ms/step - loss: 0.6485 - val_loss: 0.6901
Epoch 25/56
292/292 [==============================] - 75s 257ms/step - loss: 0.6471 - val_loss: 0.6842
Epoch 26/56
292/292 [==============================] - 75s 257ms/step - loss: 0.6458 - val_loss: 0.6782
Epoch 27/56
292/292 [==============================] - 75s 258ms/step - loss: 0.6444 - val_loss: 0.6721
Epoch 28/56
292/292 [==============================] - 75s 258ms/step - loss: 0.6430 - val_loss: 0.6658
Epoch 29/56
292/292 [==============================] - 75s 257ms/step - loss: 0.6415 - val_loss: 0.6595
Epoch 30/56
292/292 [==============================] - 75s 257ms/step - loss: 0.6401 - val_loss: 0.6530
Epoch 31/56
292/292 [==============================] - 75s 257ms/step - loss: 0.6387 - val_loss: 0.6465
Epoch 32/56
292/292 [==============================] - 75s 257ms/step - loss: 0.6372 - val_loss: 0.6399
Epoch 33/56
292/292 [==============================] - 75s 258ms/step - loss: 0.6358 - val_loss: 0.6333
Epoch 34/56
292/292 [==============================] - 75s 257ms/step - loss: 0.6344 - val_loss: 0.6267
Epoch 35/56
292/292 [==============================] - 75s 258ms/step - loss: 0.6331 - val_loss: 0.6202
Epoch 36/56
292/292 [==============================] - 75s 257ms/step - loss: 0.6317 - val_loss: 0.6136
Epoch 37/56
292/292 [==============================] - 75s 257ms/step - loss: 0.6304 - val_loss: 0.6071
Epoch 38/56
292/292 [==============================] - 75s 257ms/step - loss: 0.6291 - val_loss: 0.6006
Epoch 39/56
292/292 [==============================] - 75s 258ms/step - loss: 0.6277 - val_loss: 0.5941
Epoch 40/56
292/292 [==============================] - 75s 257ms/step - loss: 0.6265 - val_loss: 0.5877
Epoch 41/56
292/292 [==============================] - 75s 258ms/step - loss: 0.6253 - val_loss: 0.5814
Epoch 42/56
292/292 [==============================] - 75s 257ms/step - loss: 0.6241 - val_loss: 0.5752
Epoch 43/56
292/292 [==============================] - 75s 257ms/step - loss: 0.6230 - val_loss: 0.5690
Epoch 44/56
292/292 [==============================] - 75s 257ms/step - loss: 0.6220 - val_loss: 0.5631
Epoch 45/56
292/292 [==============================] - 75s 257ms/step - loss: 0.6209 - val_loss: 0.5572
Epoch 46/56
292/292 [==============================] - 75s 258ms/step - loss: 0.6200 - val_loss: 0.5516
Epoch 47/56
292/292 [==============================] - 75s 258ms/step - loss: 0.6191 - val_loss: 0.5461
Epoch 48/56
292/292 [==============================] - 75s 257ms/step - loss: 0.6182 - val_loss: 0.5409
Epoch 49/56
292/292 [==============================] - 75s 258ms/step - loss: 0.6174 - val_loss: 0.5359
Epoch 50/56
292/292 [==============================] - 75s 257ms/step - loss: 0.6166 - val_loss: 0.5311
Epoch 51/56
292/292 [==============================] - 75s 257ms/step - loss: 0.6159 - val_loss: 0.5266
Epoch 52/56
292/292 [==============================] - 76s 259ms/step - loss: 0.6153 - val_loss: 0.5223
Epoch 53/56
292/292 [==============================] - 75s 258ms/step - loss: 0.6148 - val_loss: 0.5181
Epoch 54/56
292/292 [==============================] - 75s 258ms/step - loss: 0.6142 - val_loss: 0.5142
Epoch 55/56
292/292 [==============================] - 75s 258ms/step - loss: 0.6137 - val_loss: 0.5105
Epoch 56/56
292/292 [==============================] - 75s 257ms/step - loss: 0.6131 - val_loss: 0.5069
Execution time:  4229.341509580612
LSTM:
Mean Absolute Error: 0.5534
Root Mean Square Error: 0.9417
Mean Square Error: 0.8867

Train RMSE: 0.942
Train MSE: 0.887
Train MAE: 0.553
###########################

MODEL:  LSTM
sequence:  3d
units:  45
dropout1:  0.11814836227952394
dropout2:  0.24325404382648977
optimizer: adadelta
activationDense: tanh
epochs: 43
batchsize: 30
validation_split: 0.2
Model: &#34;sequential_65&#34;
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
lstm_130 (LSTM)              (None, 432, 45)           8460      
_________________________________________________________________
dropout_130 (Dropout)        (None, 432, 45)           0         
_________________________________________________________________
lstm_131 (LSTM)              (None, 432, 45)           16380     
_________________________________________________________________
dropout_131 (Dropout)        (None, 432, 45)           0         
_________________________________________________________________
time_distributed_65 (TimeDis (None, 432, 1)            46        
=================================================================
Total params: 24,886
Trainable params: 24,886
Non-trainable params: 0
_________________________________________________________________
Epoch 1/43
95/95 [==============================] - 30s 319ms/step - loss: 0.7009 - val_loss: 0.6011
Epoch 2/43
95/95 [==============================] - 30s 312ms/step - loss: 0.7008 - val_loss: 0.6008
Epoch 3/43
95/95 [==============================] - 29s 310ms/step - loss: 0.7007 - val_loss: 0.6004
Epoch 4/43
95/95 [==============================] - 29s 310ms/step - loss: 0.7006 - val_loss: 0.6001
Epoch 5/43
95/95 [==============================] - 30s 311ms/step - loss: 0.7005 - val_loss: 0.5997
Epoch 6/43
95/95 [==============================] - 30s 313ms/step - loss: 0.7004 - val_loss: 0.5993
Epoch 7/43
95/95 [==============================] - 30s 313ms/step - loss: 0.7002 - val_loss: 0.5989
Epoch 8/43
95/95 [==============================] - 30s 313ms/step - loss: 0.7001 - val_loss: 0.5985
Epoch 9/43
95/95 [==============================] - 30s 311ms/step - loss: 0.7000 - val_loss: 0.5981
Epoch 10/43
95/95 [==============================] - 30s 311ms/step - loss: 0.6999 - val_loss: 0.5977
Epoch 11/43
95/95 [==============================] - 29s 310ms/step - loss: 0.6998 - val_loss: 0.5972
Epoch 12/43
95/95 [==============================] - 30s 313ms/step - loss: 0.6996 - val_loss: 0.5968
Epoch 13/43
95/95 [==============================] - 30s 312ms/step - loss: 0.6995 - val_loss: 0.5964
Epoch 14/43
95/95 [==============================] - 30s 312ms/step - loss: 0.6994 - val_loss: 0.5959
Epoch 15/43
95/95 [==============================] - 30s 313ms/step - loss: 0.6992 - val_loss: 0.5955
Epoch 16/43
95/95 [==============================] - 30s 314ms/step - loss: 0.6991 - val_loss: 0.5950
Epoch 17/43
95/95 [==============================] - 29s 310ms/step - loss: 0.6990 - val_loss: 0.5945
Epoch 18/43
95/95 [==============================] - 29s 310ms/step - loss: 0.6988 - val_loss: 0.5941
Epoch 19/43
95/95 [==============================] - 29s 309ms/step - loss: 0.6987 - val_loss: 0.5936
Epoch 20/43
95/95 [==============================] - 30s 311ms/step - loss: 0.6985 - val_loss: 0.5931
Epoch 21/43
95/95 [==============================] - 30s 312ms/step - loss: 0.6984 - val_loss: 0.5926
Epoch 22/43
95/95 [==============================] - 30s 311ms/step - loss: 0.6983 - val_loss: 0.5921
Epoch 23/43
95/95 [==============================] - 30s 313ms/step - loss: 0.6981 - val_loss: 0.5916
Epoch 24/43
95/95 [==============================] - 29s 310ms/step - loss: 0.6980 - val_loss: 0.5911
Epoch 25/43
95/95 [==============================] - 30s 312ms/step - loss: 0.6978 - val_loss: 0.5906
Epoch 26/43
95/95 [==============================] - 30s 312ms/step - loss: 0.6977 - val_loss: 0.5901
Epoch 27/43
95/95 [==============================] - 29s 310ms/step - loss: 0.6975 - val_loss: 0.5896
Epoch 28/43
95/95 [==============================] - 30s 311ms/step - loss: 0.6974 - val_loss: 0.5891
Epoch 29/43
95/95 [==============================] - 30s 311ms/step - loss: 0.6972 - val_loss: 0.5886
Epoch 30/43
95/95 [==============================] - 30s 313ms/step - loss: 0.6971 - val_loss: 0.5881
Epoch 31/43
95/95 [==============================] - 30s 312ms/step - loss: 0.6969 - val_loss: 0.5876
Epoch 32/43
95/95 [==============================] - 29s 310ms/step - loss: 0.6968 - val_loss: 0.5870
Epoch 33/43
95/95 [==============================] - 29s 310ms/step - loss: 0.6966 - val_loss: 0.5865
Epoch 34/43
95/95 [==============================] - 30s 311ms/step - loss: 0.6965 - val_loss: 0.5860
Epoch 35/43
95/95 [==============================] - 29s 310ms/step - loss: 0.6963 - val_loss: 0.5855
Epoch 36/43
95/95 [==============================] - 30s 311ms/step - loss: 0.6962 - val_loss: 0.5849
Epoch 37/43
95/95 [==============================] - 29s 310ms/step - loss: 0.6960 - val_loss: 0.5844
Epoch 38/43
95/95 [==============================] - 30s 312ms/step - loss: 0.6959 - val_loss: 0.5839
Epoch 39/43
95/95 [==============================] - 29s 309ms/step - loss: 0.6957 - val_loss: 0.5833
Epoch 40/43
95/95 [==============================] - 29s 310ms/step - loss: 0.6956 - val_loss: 0.5828
Epoch 41/43
95/95 [==============================] - 30s 311ms/step - loss: 0.6954 - val_loss: 0.5822
Epoch 42/43
95/95 [==============================] - 29s 310ms/step - loss: 0.6953 - val_loss: 0.5817
Epoch 43/43
95/95 [==============================] - 30s 311ms/step - loss: 0.6951 - val_loss: 0.5812
Execution time:  1289.9682788848877
LSTM:
Mean Absolute Error: 0.6476
Root Mean Square Error: 0.9533
Mean Square Error: 0.9089

Train RMSE: 0.953
Train MSE: 0.909
Train MAE: 0.648
###########################

MODEL:  LSTM
sequence:  3d
units:  43
dropout1:  0.40519643149940265
dropout2:  0.3312343747027119
optimizer: adadelta
activationDense: sigmoid
epochs: 56
batchsize: 11
validation_split: 0.1
Model: &#34;sequential_66&#34;
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
lstm_132 (LSTM)              (None, 432, 43)           7740      
_________________________________________________________________
dropout_132 (Dropout)        (None, 432, 43)           0         
_________________________________________________________________
lstm_133 (LSTM)              (None, 432, 43)           14964     
_________________________________________________________________
dropout_133 (Dropout)        (None, 432, 43)           0         
_________________________________________________________________
time_distributed_66 (TimeDis (None, 432, 1)            44        
=================================================================
Total params: 22,748
Trainable params: 22,748
Non-trainable params: 0
_________________________________________________________________
Epoch 1/56
292/292 [==============================] - 76s 260ms/step - loss: 0.9076 - val_loss: 1.2918
Epoch 2/56
292/292 [==============================] - 76s 260ms/step - loss: 0.9074 - val_loss: 1.2913
Epoch 3/56
292/292 [==============================] - 76s 260ms/step - loss: 0.9071 - val_loss: 1.2908
Epoch 4/56
292/292 [==============================] - 76s 260ms/step - loss: 0.9069 - val_loss: 1.2902
Epoch 5/56
292/292 [==============================] - 76s 260ms/step - loss: 0.9066 - val_loss: 1.2896
Epoch 6/56
292/292 [==============================] - 76s 260ms/step - loss: 0.9063 - val_loss: 1.2889
Epoch 7/56
292/292 [==============================] - 76s 260ms/step - loss: 0.9060 - val_loss: 1.2882
Epoch 8/56
292/292 [==============================] - 76s 260ms/step - loss: 0.9057 - val_loss: 1.2875
Epoch 9/56
292/292 [==============================] - 76s 260ms/step - loss: 0.9054 - val_loss: 1.2868
Epoch 10/56
292/292 [==============================] - 76s 260ms/step - loss: 0.9050 - val_loss: 1.2860
Epoch 11/56
292/292 [==============================] - 76s 259ms/step - loss: 0.9047 - val_loss: 1.2852
Epoch 12/56
292/292 [==============================] - 76s 260ms/step - loss: 0.9043 - val_loss: 1.2844
Epoch 13/56
292/292 [==============================] - 76s 260ms/step - loss: 0.9039 - val_loss: 1.2835
Epoch 14/56
292/292 [==============================] - 75s 256ms/step - loss: 0.9035 - val_loss: 1.2826
Epoch 15/56
292/292 [==============================] - 75s 257ms/step - loss: 0.9031 - val_loss: 1.2817
Epoch 16/56
292/292 [==============================] - 75s 257ms/step - loss: 0.9026 - val_loss: 1.2807
Epoch 17/56
292/292 [==============================] - 75s 257ms/step - loss: 0.9022 - val_loss: 1.2798
Epoch 18/56
292/292 [==============================] - 75s 257ms/step - loss: 0.9017 - val_loss: 1.2787
Epoch 19/56
292/292 [==============================] - 75s 257ms/step - loss: 0.9012 - val_loss: 1.2777
Epoch 20/56
292/292 [==============================] - 75s 258ms/step - loss: 0.9007 - val_loss: 1.2766
Epoch 21/56
292/292 [==============================] - 75s 257ms/step - loss: 0.9002 - val_loss: 1.2755
Epoch 22/56
292/292 [==============================] - 75s 257ms/step - loss: 0.8997 - val_loss: 1.2744
Epoch 23/56
292/292 [==============================] - 75s 257ms/step - loss: 0.8991 - val_loss: 1.2732
Epoch 24/56
292/292 [==============================] - 75s 257ms/step - loss: 0.8986 - val_loss: 1.2719
Epoch 25/56
292/292 [==============================] - 75s 257ms/step - loss: 0.8980 - val_loss: 1.2707
Epoch 26/56
292/292 [==============================] - 75s 257ms/step - loss: 0.8974 - val_loss: 1.2693
Epoch 27/56
292/292 [==============================] - 75s 257ms/step - loss: 0.8967 - val_loss: 1.2680
Epoch 28/56
292/292 [==============================] - 75s 258ms/step - loss: 0.8961 - val_loss: 1.2665
Epoch 29/56
292/292 [==============================] - 75s 257ms/step - loss: 0.8954 - val_loss: 1.2651
Epoch 30/56
292/292 [==============================] - 75s 257ms/step - loss: 0.8947 - val_loss: 1.2635
Epoch 31/56
292/292 [==============================] - 75s 257ms/step - loss: 0.8940 - val_loss: 1.2619
Epoch 32/56
292/292 [==============================] - 75s 256ms/step - loss: 0.8932 - val_loss: 1.2603
Epoch 33/56
292/292 [==============================] - 75s 258ms/step - loss: 0.8924 - val_loss: 1.2585
Epoch 34/56
292/292 [==============================] - 75s 257ms/step - loss: 0.8916 - val_loss: 1.2567
Epoch 35/56
292/292 [==============================] - 75s 256ms/step - loss: 0.8907 - val_loss: 1.2548
Epoch 36/56
292/292 [==============================] - 75s 257ms/step - loss: 0.8898 - val_loss: 1.2529
Epoch 37/56
292/292 [==============================] - 75s 257ms/step - loss: 0.8889 - val_loss: 1.2508
Epoch 38/56
292/292 [==============================] - 75s 256ms/step - loss: 0.8879 - val_loss: 1.2487
Epoch 39/56
292/292 [==============================] - 75s 257ms/step - loss: 0.8868 - val_loss: 1.2465
Epoch 40/56
292/292 [==============================] - 75s 256ms/step - loss: 0.8858 - val_loss: 1.2441
Epoch 41/56
292/292 [==============================] - 75s 257ms/step - loss: 0.8847 - val_loss: 1.2417
Epoch 42/56
292/292 [==============================] - 75s 257ms/step - loss: 0.8835 - val_loss: 1.2391
Epoch 43/56
292/292 [==============================] - 75s 257ms/step - loss: 0.8823 - val_loss: 1.2365
Epoch 44/56
292/292 [==============================] - 75s 257ms/step - loss: 0.8810 - val_loss: 1.2337
Epoch 45/56
292/292 [==============================] - 75s 257ms/step - loss: 0.8796 - val_loss: 1.2308
Epoch 46/56
292/292 [==============================] - 75s 257ms/step - loss: 0.8782 - val_loss: 1.2277
Epoch 47/56
292/292 [==============================] - 75s 257ms/step - loss: 0.8768 - val_loss: 1.2245
Epoch 48/56
292/292 [==============================] - 75s 256ms/step - loss: 0.8753 - val_loss: 1.2212
Epoch 49/56
292/292 [==============================] - 75s 257ms/step - loss: 0.8736 - val_loss: 1.2177
Epoch 50/56
292/292 [==============================] - 75s 257ms/step - loss: 0.8720 - val_loss: 1.2140
Epoch 51/56
292/292 [==============================] - 75s 256ms/step - loss: 0.8702 - val_loss: 1.2102
Epoch 52/56
292/292 [==============================] - 75s 257ms/step - loss: 0.8684 - val_loss: 1.2061
Epoch 53/56
292/292 [==============================] - 75s 257ms/step - loss: 0.8664 - val_loss: 1.2019
Epoch 54/56
292/292 [==============================] - 75s 256ms/step - loss: 0.8644 - val_loss: 1.1975
Epoch 55/56
292/292 [==============================] - 75s 257ms/step - loss: 0.8623 - val_loss: 1.1929
Epoch 56/56
292/292 [==============================] - 75s 257ms/step - loss: 0.8600 - val_loss: 1.1881
Execution time:  4233.551719427109
LSTM:
Mean Absolute Error: 0.8593
Root Mean Square Error: 1.0605
Mean Square Error: 1.1246

Train RMSE: 1.060
Train MSE: 1.125
Train MAE: 0.859
###########################

MODEL:  LSTM
sequence:  3d
units:  45
dropout1:  0.11814836227952394
dropout2:  0.24325404382648977
optimizer: adadelta
activationDense: sigmoid
epochs: 43
batchsize: 30
validation_split: 0.2
Model: &#34;sequential_67&#34;
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
lstm_134 (LSTM)              (None, 432, 45)           8460      
_________________________________________________________________
dropout_134 (Dropout)        (None, 432, 45)           0         
_________________________________________________________________
lstm_135 (LSTM)              (None, 432, 45)           16380     
_________________________________________________________________
dropout_135 (Dropout)        (None, 432, 45)           0         
_________________________________________________________________
time_distributed_67 (TimeDis (None, 432, 1)            46        
=================================================================
Total params: 24,886
Trainable params: 24,886
Non-trainable params: 0
_________________________________________________________________
Epoch 1/43
95/95 [==============================] - 30s 315ms/step - loss: 0.9068 - val_loss: 1.0968
Epoch 2/43
95/95 [==============================] - 29s 303ms/step - loss: 0.9067 - val_loss: 1.0967
Epoch 3/43
95/95 [==============================] - 29s 302ms/step - loss: 0.9067 - val_loss: 1.0966
Epoch 4/43
95/95 [==============================] - 29s 302ms/step - loss: 0.9067 - val_loss: 1.0965
Epoch 5/43
95/95 [==============================] - 29s 301ms/step - loss: 0.9066 - val_loss: 1.0964
Epoch 6/43
95/95 [==============================] - 29s 302ms/step - loss: 0.9066 - val_loss: 1.0963
Epoch 7/43
95/95 [==============================] - 29s 301ms/step - loss: 0.9065 - val_loss: 1.0962
Epoch 8/43
95/95 [==============================] - 29s 305ms/step - loss: 0.9065 - val_loss: 1.0961
Epoch 9/43
95/95 [==============================] - 29s 304ms/step - loss: 0.9064 - val_loss: 1.0959
Epoch 10/43
95/95 [==============================] - 29s 303ms/step - loss: 0.9064 - val_loss: 1.0958
Epoch 11/43
95/95 [==============================] - 29s 305ms/step - loss: 0.9063 - val_loss: 1.0957
Epoch 12/43
95/95 [==============================] - 29s 305ms/step - loss: 0.9063 - val_loss: 1.0956
Epoch 13/43
95/95 [==============================] - 29s 302ms/step - loss: 0.9062 - val_loss: 1.0955
Epoch 14/43
95/95 [==============================] - 29s 306ms/step - loss: 0.9061 - val_loss: 1.0953
Epoch 15/43
95/95 [==============================] - 29s 305ms/step - loss: 0.9061 - val_loss: 1.0952
Epoch 16/43
95/95 [==============================] - 29s 305ms/step - loss: 0.9060 - val_loss: 1.0951
Epoch 17/43
95/95 [==============================] - 29s 304ms/step - loss: 0.9060 - val_loss: 1.0949
Epoch 18/43
95/95 [==============================] - 29s 304ms/step - loss: 0.9059 - val_loss: 1.0948
Epoch 19/43
95/95 [==============================] - 29s 302ms/step - loss: 0.9058 - val_loss: 1.0947
Epoch 20/43
95/95 [==============================] - 29s 307ms/step - loss: 0.9058 - val_loss: 1.0945
Epoch 21/43
95/95 [==============================] - 29s 306ms/step - loss: 0.9057 - val_loss: 1.0944
Epoch 22/43
95/95 [==============================] - 29s 305ms/step - loss: 0.9057 - val_loss: 1.0943
Epoch 23/43
95/95 [==============================] - 29s 305ms/step - loss: 0.9056 - val_loss: 1.0941
Epoch 24/43
95/95 [==============================] - 29s 304ms/step - loss: 0.9055 - val_loss: 1.0940
Epoch 25/43
95/95 [==============================] - 29s 303ms/step - loss: 0.9055 - val_loss: 1.0938
Epoch 26/43
95/95 [==============================] - 29s 307ms/step - loss: 0.9054 - val_loss: 1.0937
Epoch 27/43
95/95 [==============================] - 29s 304ms/step - loss: 0.9053 - val_loss: 1.0935
Epoch 28/43
95/95 [==============================] - 29s 305ms/step - loss: 0.9053 - val_loss: 1.0934
Epoch 29/43
95/95 [==============================] - 29s 304ms/step - loss: 0.9052 - val_loss: 1.0932
Epoch 30/43
95/95 [==============================] - 29s 304ms/step - loss: 0.9051 - val_loss: 1.0931
Epoch 31/43
95/95 [==============================] - 29s 305ms/step - loss: 0.9050 - val_loss: 1.0929
Epoch 32/43
95/95 [==============================] - 29s 308ms/step - loss: 0.9050 - val_loss: 1.0928
Epoch 33/43
95/95 [==============================] - 29s 303ms/step - loss: 0.9049 - val_loss: 1.0926
Epoch 34/43
95/95 [==============================] - 29s 303ms/step - loss: 0.9048 - val_loss: 1.0925
Epoch 35/43
95/95 [==============================] - 29s 304ms/step - loss: 0.9048 - val_loss: 1.0923
Epoch 36/43
95/95 [==============================] - 29s 304ms/step - loss: 0.9047 - val_loss: 1.0922
Epoch 37/43
95/95 [==============================] - 29s 307ms/step - loss: 0.9046 - val_loss: 1.0920
Epoch 38/43
95/95 [==============================] - 29s 305ms/step - loss: 0.9045 - val_loss: 1.0918
Epoch 39/43
95/95 [==============================] - 29s 304ms/step - loss: 0.9045 - val_loss: 1.0917
Epoch 40/43
95/95 [==============================] - 29s 303ms/step - loss: 0.9044 - val_loss: 1.0915
Epoch 41/43
95/95 [==============================] - 29s 303ms/step - loss: 0.9043 - val_loss: 1.0913
Epoch 42/43
95/95 [==============================] - 29s 305ms/step - loss: 0.9042 - val_loss: 1.0912
Epoch 43/43
95/95 [==============================] - 29s 304ms/step - loss: 0.9042 - val_loss: 1.0910
Execution time:  1260.0782957077026
LSTM:
Mean Absolute Error: 0.9163
Root Mean Square Error: 1.1086
Mean Square Error: 1.2290

Train RMSE: 1.109
Train MSE: 1.229
Train MAE: 0.916
###########################

MODEL:  LSTM
sequence:  3d
units:  43
dropout1:  0.40519643149940265
dropout2:  0.3312343747027119
optimizer: adamax
activationDense: tanh
epochs: 56
batchsize: 11
validation_split: 0.1
Model: &#34;sequential_68&#34;
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
lstm_136 (LSTM)              (None, 432, 43)           7740      
_________________________________________________________________
dropout_136 (Dropout)        (None, 432, 43)           0         
_________________________________________________________________
lstm_137 (LSTM)              (None, 432, 43)           14964     
_________________________________________________________________
dropout_137 (Dropout)        (None, 432, 43)           0         
_________________________________________________________________
time_distributed_68 (TimeDis (None, 432, 1)            44        
=================================================================
Total params: 22,748
Trainable params: 22,748
Non-trainable params: 0
_________________________________________________________________
Epoch 1/56
292/292 [==============================] - 75s 256ms/step - loss: 0.6342 - val_loss: 0.4774
Epoch 2/56
292/292 [==============================] - 75s 257ms/step - loss: 0.6232 - val_loss: 0.3874
Epoch 3/56
292/292 [==============================] - 75s 256ms/step - loss: 0.6203 - val_loss: 0.3613
Epoch 4/56
292/292 [==============================] - 75s 258ms/step - loss: 0.6194 - val_loss: 0.3549
Epoch 5/56
292/292 [==============================] - 75s 258ms/step - loss: 0.6184 - val_loss: 0.3581
Epoch 6/56
292/292 [==============================] - 75s 258ms/step - loss: 0.6174 - val_loss: 0.3636
Epoch 7/56
292/292 [==============================] - 76s 260ms/step - loss: 0.6162 - val_loss: 0.3682
Epoch 8/56
292/292 [==============================] - 75s 258ms/step - loss: 0.6153 - val_loss: 0.3718
Epoch 9/56
292/292 [==============================] - 75s 258ms/step - loss: 0.6145 - val_loss: 0.3720
Epoch 10/56
292/292 [==============================] - 75s 258ms/step - loss: 0.6137 - val_loss: 0.3740
Epoch 11/56
292/292 [==============================] - 74s 255ms/step - loss: 0.6128 - val_loss: 0.3762
Epoch 12/56
292/292 [==============================] - 75s 256ms/step - loss: 0.6121 - val_loss: 0.3761
Epoch 13/56
292/292 [==============================] - 74s 255ms/step - loss: 0.6116 - val_loss: 0.3770
Epoch 14/56
292/292 [==============================] - 75s 256ms/step - loss: 0.6110 - val_loss: 0.3726
Epoch 15/56
292/292 [==============================] - 75s 255ms/step - loss: 0.6105 - val_loss: 0.3730
Epoch 16/56
292/292 [==============================] - 74s 255ms/step - loss: 0.6097 - val_loss: 0.3719
Epoch 17/56
292/292 [==============================] - 75s 256ms/step - loss: 0.6099 - val_loss: 0.3627
Epoch 18/56
292/292 [==============================] - 74s 255ms/step - loss: 0.6051 - val_loss: 0.3869
Epoch 19/56
292/292 [==============================] - 74s 255ms/step - loss: 0.6001 - val_loss: 0.3940
Epoch 20/56
292/292 [==============================] - 75s 256ms/step - loss: 0.6038 - val_loss: 0.3829
Epoch 21/56
292/292 [==============================] - 75s 255ms/step - loss: 0.5983 - val_loss: 0.4378
Epoch 22/56
292/292 [==============================] - 75s 256ms/step - loss: 0.5931 - val_loss: 0.4536
Epoch 23/56
292/292 [==============================] - 75s 256ms/step - loss: 0.5921 - val_loss: 0.4591
Epoch 24/56
292/292 [==============================] - 75s 255ms/step - loss: 0.5913 - val_loss: 0.4615
Epoch 25/56
292/292 [==============================] - 75s 256ms/step - loss: 0.5911 - val_loss: 0.4623
Epoch 26/56
292/292 [==============================] - 75s 256ms/step - loss: 0.5907 - val_loss: 0.4626
Epoch 27/56
292/292 [==============================] - 75s 255ms/step - loss: 0.5905 - val_loss: 0.4633
Epoch 28/56
292/292 [==============================] - 75s 256ms/step - loss: 0.5896 - val_loss: 0.4625
Epoch 29/56
292/292 [==============================] - 75s 255ms/step - loss: 0.5893 - val_loss: 0.4642
Epoch 30/56
292/292 [==============================] - 75s 256ms/step - loss: 0.5890 - val_loss: 0.4644
Epoch 31/56
292/292 [==============================] - 75s 256ms/step - loss: 0.5880 - val_loss: 0.4646
Epoch 32/56
292/292 [==============================] - 75s 256ms/step - loss: 0.5880 - val_loss: 0.4627
Epoch 33/56
292/292 [==============================] - 75s 256ms/step - loss: 0.5880 - val_loss: 0.4651
Epoch 34/56
292/292 [==============================] - 75s 256ms/step - loss: 0.5882 - val_loss: 0.4649
Epoch 35/56
292/292 [==============================] - 75s 256ms/step - loss: 0.5875 - val_loss: 0.4658
Epoch 36/56
292/292 [==============================] - 75s 257ms/step - loss: 0.5870 - val_loss: 0.4614
Epoch 37/56
292/292 [==============================] - 75s 255ms/step - loss: 0.5851 - val_loss: 0.4615
Epoch 38/56
292/292 [==============================] - 75s 256ms/step - loss: 0.5849 - val_loss: 0.4617
Epoch 39/56
292/292 [==============================] - 75s 256ms/step - loss: 0.5801 - val_loss: 0.4647
Epoch 40/56
292/292 [==============================] - 75s 256ms/step - loss: 0.5784 - val_loss: 0.4658
Epoch 41/56
292/292 [==============================] - 75s 256ms/step - loss: 0.5754 - val_loss: 0.4668
Epoch 42/56
292/292 [==============================] - 75s 256ms/step - loss: 0.5819 - val_loss: 0.4682
Epoch 43/56
292/292 [==============================] - 75s 255ms/step - loss: 0.5810 - val_loss: 0.4701
Epoch 44/56
292/292 [==============================] - 75s 256ms/step - loss: 0.5800 - val_loss: 0.4656
Epoch 45/56
292/292 [==============================] - 75s 256ms/step - loss: 0.5763 - val_loss: 0.4668
Epoch 46/56
292/292 [==============================] - 75s 256ms/step - loss: 0.5728 - val_loss: 0.4669
Epoch 47/56
292/292 [==============================] - 75s 256ms/step - loss: 0.5665 - val_loss: 0.4675
Epoch 48/56
292/292 [==============================] - 75s 256ms/step - loss: 0.5627 - val_loss: 0.4660
Epoch 49/56
292/292 [==============================] - 75s 256ms/step - loss: 0.5622 - val_loss: 0.4662
Epoch 50/56
292/292 [==============================] - 75s 256ms/step - loss: 0.5636 - val_loss: 0.4640
Epoch 51/56
292/292 [==============================] - 75s 256ms/step - loss: 0.5762 - val_loss: 0.4623
Epoch 52/56
292/292 [==============================] - 75s 256ms/step - loss: 0.5509 - val_loss: 0.4640
Epoch 53/56
292/292 [==============================] - 79s 271ms/step - loss: 0.5584 - val_loss: 0.4637
Epoch 54/56
292/292 [==============================] - 75s 256ms/step - loss: 0.5435 - val_loss: 0.4631
Epoch 55/56
292/292 [==============================] - 75s 256ms/step - loss: 0.5365 - val_loss: 0.4612
Epoch 56/56
292/292 [==============================] - 75s 256ms/step - loss: 0.5264 - val_loss: 0.4592
Execution time:  4212.094009399414
LSTM:
Mean Absolute Error: 0.5534
Root Mean Square Error: 1.0070
Mean Square Error: 1.0141

Train RMSE: 1.007
Train MSE: 1.014
Train MAE: 0.553
###########################

MODEL:  LSTM
sequence:  3d
units:  45
dropout1:  0.11814836227952394
dropout2:  0.24325404382648977
optimizer: adamax
activationDense: tanh
epochs: 43
batchsize: 30
validation_split: 0.2
Model: &#34;sequential_69&#34;
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
lstm_138 (LSTM)              (None, 432, 45)           8460      
_________________________________________________________________
dropout_138 (Dropout)        (None, 432, 45)           0         
_________________________________________________________________
lstm_139 (LSTM)              (None, 432, 45)           16380     
_________________________________________________________________
dropout_139 (Dropout)        (None, 432, 45)           0         
_________________________________________________________________
time_distributed_69 (TimeDis (None, 432, 1)            46        
=================================================================
Total params: 24,886
Trainable params: 24,886
Non-trainable params: 0
_________________________________________________________________
Epoch 1/43
95/95 [==============================] - 30s 317ms/step - loss: 0.6908 - val_loss: 0.4069
Epoch 2/43
95/95 [==============================] - 29s 306ms/step - loss: 0.6616 - val_loss: 0.3135
Epoch 3/43
95/95 [==============================] - 29s 304ms/step - loss: 0.6696 - val_loss: 0.3270
Epoch 4/43
95/95 [==============================] - 28s 300ms/step - loss: 0.6639 - val_loss: 0.3286
Epoch 5/43
95/95 [==============================] - 29s 301ms/step - loss: 0.6616 - val_loss: 0.3290
Epoch 6/43
95/95 [==============================] - 29s 303ms/step - loss: 0.6601 - val_loss: 0.3299
Epoch 7/43
95/95 [==============================] - 29s 302ms/step - loss: 0.6587 - val_loss: 0.3306
Epoch 8/43
95/95 [==============================] - 28s 298ms/step - loss: 0.6578 - val_loss: 0.3311
Epoch 9/43
95/95 [==============================] - 28s 298ms/step - loss: 0.6569 - val_loss: 0.3320
Epoch 10/43
95/95 [==============================] - 29s 302ms/step - loss: 0.6560 - val_loss: 0.3326
Epoch 11/43
95/95 [==============================] - 29s 305ms/step - loss: 0.6553 - val_loss: 0.3333
Epoch 12/43
95/95 [==============================] - 29s 301ms/step - loss: 0.6546 - val_loss: 0.3337
Epoch 13/43
95/95 [==============================] - 29s 302ms/step - loss: 0.6541 - val_loss: 0.3342
Epoch 14/43
95/95 [==============================] - 29s 302ms/step - loss: 0.6536 - val_loss: 0.3345
Epoch 15/43
95/95 [==============================] - 29s 302ms/step - loss: 0.6530 - val_loss: 0.3349
Epoch 16/43
95/95 [==============================] - 29s 302ms/step - loss: 0.6525 - val_loss: 0.3352
Epoch 17/43
95/95 [==============================] - 29s 304ms/step - loss: 0.6519 - val_loss: 0.3353
Epoch 18/43
95/95 [==============================] - 29s 302ms/step - loss: 0.6516 - val_loss: 0.3354
Epoch 19/43
95/95 [==============================] - 29s 303ms/step - loss: 0.6510 - val_loss: 0.3354
Epoch 20/43
95/95 [==============================] - 29s 302ms/step - loss: 0.6508 - val_loss: 0.3351
Epoch 21/43
95/95 [==============================] - 29s 303ms/step - loss: 0.6501 - val_loss: 0.3353
Epoch 22/43
95/95 [==============================] - 29s 307ms/step - loss: 0.6496 - val_loss: 0.3348
Epoch 23/43
95/95 [==============================] - 29s 305ms/step - loss: 0.6490 - val_loss: 0.3346
Epoch 24/43
95/95 [==============================] - 29s 303ms/step - loss: 0.6484 - val_loss: 0.3340
Epoch 25/43
95/95 [==============================] - 29s 303ms/step - loss: 0.6476 - val_loss: 0.3334
Epoch 26/43
95/95 [==============================] - 29s 303ms/step - loss: 0.6467 - val_loss: 0.3300
Epoch 27/43
95/95 [==============================] - 29s 304ms/step - loss: 0.6426 - val_loss: 0.3385
Epoch 28/43
95/95 [==============================] - 29s 307ms/step - loss: 0.6337 - val_loss: 0.3554
Epoch 29/43
95/95 [==============================] - 29s 302ms/step - loss: 0.6300 - val_loss: 0.3612
Epoch 30/43
95/95 [==============================] - 29s 303ms/step - loss: 0.6296 - val_loss: 0.3705
Epoch 31/43
95/95 [==============================] - 29s 303ms/step - loss: 0.6280 - val_loss: 0.3695
Epoch 32/43
95/95 [==============================] - 29s 302ms/step - loss: 0.6259 - val_loss: 0.3771
Epoch 33/43
95/95 [==============================] - 29s 305ms/step - loss: 0.6244 - val_loss: 0.3775
Epoch 34/43
95/95 [==============================] - 29s 307ms/step - loss: 0.6245 - val_loss: 0.3796
Epoch 35/43
95/95 [==============================] - 29s 304ms/step - loss: 0.6241 - val_loss: 0.3798
Epoch 36/43
95/95 [==============================] - 29s 304ms/step - loss: 0.6240 - val_loss: 0.3804
Epoch 37/43
95/95 [==============================] - 29s 304ms/step - loss: 0.6239 - val_loss: 0.3805
Epoch 38/43
95/95 [==============================] - 29s 304ms/step - loss: 0.6238 - val_loss: 0.3808
Epoch 39/43
95/95 [==============================] - 29s 306ms/step - loss: 0.6237 - val_loss: 0.3808
Epoch 40/43
95/95 [==============================] - 29s 306ms/step - loss: 0.6237 - val_loss: 0.3813
Epoch 41/43
95/95 [==============================] - 29s 304ms/step - loss: 0.6235 - val_loss: 0.3811
Epoch 42/43
95/95 [==============================] - 29s 303ms/step - loss: 0.6235 - val_loss: 0.3816
Epoch 43/43
95/95 [==============================] - 29s 304ms/step - loss: 0.6233 - val_loss: 0.3815
Execution time:  1258.6436741352081
LSTM:
Mean Absolute Error: 0.5478
Root Mean Square Error: 0.9963
Mean Square Error: 0.9926

Train RMSE: 0.996
Train MSE: 0.993
Train MAE: 0.548
###########################

MODEL:  LSTM
sequence:  3d
units:  43
dropout1:  0.40519643149940265
dropout2:  0.3312343747027119
optimizer: adamax
activationDense: sigmoid
epochs: 56
batchsize: 11
validation_split: 0.1
Model: &#34;sequential_70&#34;
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
lstm_140 (LSTM)              (None, 432, 43)           7740      
_________________________________________________________________
dropout_140 (Dropout)        (None, 432, 43)           0         
_________________________________________________________________
lstm_141 (LSTM)              (None, 432, 43)           14964     
_________________________________________________________________
dropout_141 (Dropout)        (None, 432, 43)           0         
_________________________________________________________________
time_distributed_70 (TimeDis (None, 432, 1)            44        
=================================================================
Total params: 22,748
Trainable params: 22,748
Non-trainable params: 0
_________________________________________________________________
Epoch 1/56
292/292 [==============================] - 74s 255ms/step - loss: 0.7984 - val_loss: 0.8214
Epoch 2/56
292/292 [==============================] - 74s 253ms/step - loss: 0.6836 - val_loss: 0.8033
Epoch 3/56
292/292 [==============================] - 74s 253ms/step - loss: 0.6797 - val_loss: 0.7995
Epoch 4/56
292/292 [==============================] - 75s 255ms/step - loss: 0.6784 - val_loss: 0.7976
Epoch 5/56
292/292 [==============================] - 74s 255ms/step - loss: 0.6777 - val_loss: 0.7965
Epoch 6/56
292/292 [==============================] - 75s 256ms/step - loss: 0.6773 - val_loss: 0.7958
Epoch 7/56
292/292 [==============================] - 75s 256ms/step - loss: 0.6770 - val_loss: 0.7952
Epoch 8/56
292/292 [==============================] - 75s 256ms/step - loss: 0.6768 - val_loss: 0.7948
Epoch 9/56
292/292 [==============================] - 75s 256ms/step - loss: 0.6766 - val_loss: 0.7944
Epoch 10/56
292/292 [==============================] - 75s 256ms/step - loss: 0.6764 - val_loss: 0.7942
Epoch 11/56
292/292 [==============================] - 75s 256ms/step - loss: 0.6763 - val_loss: 0.7939
Epoch 12/56
292/292 [==============================] - 75s 256ms/step - loss: 0.6762 - val_loss: 0.7937
Epoch 13/56
292/292 [==============================] - 75s 256ms/step - loss: 0.6761 - val_loss: 0.7935
Epoch 14/56
292/292 [==============================] - 75s 256ms/step - loss: 0.6761 - val_loss: 0.7934
Epoch 15/56
292/292 [==============================] - 75s 256ms/step - loss: 0.6760 - val_loss: 0.7933
Epoch 16/56
292/292 [==============================] - 75s 256ms/step - loss: 0.6759 - val_loss: 0.7931
Epoch 17/56
292/292 [==============================] - 75s 256ms/step - loss: 0.6759 - val_loss: 0.7931
Epoch 18/56
292/292 [==============================] - 75s 256ms/step - loss: 0.6759 - val_loss: 0.7930
Epoch 19/56
292/292 [==============================] - 75s 257ms/step - loss: 0.6758 - val_loss: 0.7929
Epoch 20/56
292/292 [==============================] - 75s 256ms/step - loss: 0.6758 - val_loss: 0.7928
Epoch 21/56
292/292 [==============================] - 75s 256ms/step - loss: 0.6758 - val_loss: 0.7928
Epoch 22/56
292/292 [==============================] - 75s 256ms/step - loss: 0.6758 - val_loss: 0.7928
Epoch 23/56
292/292 [==============================] - 75s 256ms/step - loss: 0.6758 - val_loss: 0.7928
Epoch 24/56
292/292 [==============================] - 75s 256ms/step - loss: 0.6758 - val_loss: 0.7928
Epoch 25/56
292/292 [==============================] - 75s 256ms/step - loss: 0.6758 - val_loss: 0.7927
Epoch 26/56
292/292 [==============================] - 75s 256ms/step - loss: 0.6757 - val_loss: 0.7927
Epoch 27/56
292/292 [==============================] - 75s 256ms/step - loss: 0.6757 - val_loss: 0.7927
Epoch 28/56
292/292 [==============================] - 75s 259ms/step - loss: 0.6757 - val_loss: 0.7927
Epoch 29/56
292/292 [==============================] - 75s 256ms/step - loss: 0.6757 - val_loss: 0.7927
Epoch 30/56
292/292 [==============================] - 75s 256ms/step - loss: 0.6757 - val_loss: 0.7927
Epoch 31/56
292/292 [==============================] - 75s 256ms/step - loss: 0.6757 - val_loss: 0.7927
Epoch 32/56
292/292 [==============================] - 75s 256ms/step - loss: 0.6757 - val_loss: 0.7927
Epoch 33/56
292/292 [==============================] - 75s 256ms/step - loss: 0.6757 - val_loss: 0.7927
Epoch 34/56
292/292 [==============================] - 75s 256ms/step - loss: 0.6757 - val_loss: 0.7927
Epoch 35/56
292/292 [==============================] - 75s 257ms/step - loss: 0.6757 - val_loss: 0.7927
Epoch 36/56
292/292 [==============================] - 75s 256ms/step - loss: 0.6757 - val_loss: 0.7927
Epoch 37/56
292/292 [==============================] - 75s 256ms/step - loss: 0.6757 - val_loss: 0.7927
Epoch 38/56
292/292 [==============================] - 75s 256ms/step - loss: 0.6757 - val_loss: 0.7927
Epoch 39/56
292/292 [==============================] - 75s 256ms/step - loss: 0.6757 - val_loss: 0.7927
Epoch 40/56
292/292 [==============================] - 75s 256ms/step - loss: 0.6757 - val_loss: 0.7927
Epoch 41/56
292/292 [==============================] - 75s 256ms/step - loss: 0.6757 - val_loss: 0.7927
Epoch 42/56
292/292 [==============================] - 75s 256ms/step - loss: 0.6757 - val_loss: 0.7927
Epoch 43/56
292/292 [==============================] - 75s 256ms/step - loss: 0.6757 - val_loss: 0.7927
Epoch 44/56
292/292 [==============================] - 75s 256ms/step - loss: 0.6757 - val_loss: 0.7927
Epoch 45/56
292/292 [==============================] - 75s 256ms/step - loss: 0.6757 - val_loss: 0.7927
Epoch 46/56
292/292 [==============================] - 75s 255ms/step - loss: 0.6757 - val_loss: 0.7927
Epoch 47/56
292/292 [==============================] - 75s 256ms/step - loss: 0.6757 - val_loss: 0.7927
Epoch 48/56
292/292 [==============================] - 75s 256ms/step - loss: 0.6757 - val_loss: 0.7927
Epoch 49/56
292/292 [==============================] - 75s 256ms/step - loss: 0.6757 - val_loss: 0.7927
Epoch 50/56
292/292 [==============================] - 75s 256ms/step - loss: 0.6757 - val_loss: 0.7927
Epoch 51/56
292/292 [==============================] - 75s 256ms/step - loss: 0.6757 - val_loss: 0.7927
Epoch 52/56
292/292 [==============================] - 75s 256ms/step - loss: 0.6757 - val_loss: 0.7927
Epoch 53/56
292/292 [==============================] - 75s 256ms/step - loss: 0.6757 - val_loss: 0.7927
Epoch 54/56
292/292 [==============================] - 75s 256ms/step - loss: 0.6757 - val_loss: 0.7927
Epoch 55/56
292/292 [==============================] - 75s 255ms/step - loss: 0.6757 - val_loss: 0.7927
Epoch 56/56
292/292 [==============================] - 75s 256ms/step - loss: 0.6757 - val_loss: 0.7927
Execution time:  4201.5671553611755
LSTM:
Mean Absolute Error: 0.6930
Root Mean Square Error: 0.9952
Mean Square Error: 0.9904

Train RMSE: 0.995
Train MSE: 0.990
Train MAE: 0.693
###########################

MODEL:  LSTM
sequence:  3d
units:  45
dropout1:  0.11814836227952394
dropout2:  0.24325404382648977
optimizer: adamax
activationDense: sigmoid
epochs: 43
batchsize: 30
validation_split: 0.2
Model: &#34;sequential_71&#34;
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
lstm_142 (LSTM)              (None, 432, 45)           8460      
_________________________________________________________________
dropout_142 (Dropout)        (None, 432, 45)           0         
_________________________________________________________________
lstm_143 (LSTM)              (None, 432, 45)           16380     
_________________________________________________________________
dropout_143 (Dropout)        (None, 432, 45)           0         
_________________________________________________________________
time_distributed_71 (TimeDis (None, 432, 1)            46        
=================================================================
Total params: 24,886
Trainable params: 24,886
Non-trainable params: 0
_________________________________________________________________
Epoch 1/43
95/95 [==============================] - 31s 326ms/step - loss: 0.8892 - val_loss: 0.9085
Epoch 2/43
95/95 [==============================] - 29s 306ms/step - loss: 0.7595 - val_loss: 0.6766
Epoch 3/43
95/95 [==============================] - 29s 304ms/step - loss: 0.7190 - val_loss: 0.6468
Epoch 4/43
95/95 [==============================] - 29s 305ms/step - loss: 0.7135 - val_loss: 0.6381
Epoch 5/43
95/95 [==============================] - 29s 307ms/step - loss: 0.7112 - val_loss: 0.6335
Epoch 6/43
95/95 [==============================] - 29s 304ms/step - loss: 0.7099 - val_loss: 0.6307
Epoch 7/43
95/95 [==============================] - 29s 305ms/step - loss: 0.7091 - val_loss: 0.6288
Epoch 8/43
95/95 [==============================] - 29s 305ms/step - loss: 0.7085 - val_loss: 0.6273
Epoch 9/43
95/95 [==============================] - 29s 309ms/step - loss: 0.7080 - val_loss: 0.6262
Epoch 10/43
95/95 [==============================] - 29s 307ms/step - loss: 0.7076 - val_loss: 0.6253
Epoch 11/43
95/95 [==============================] - 29s 304ms/step - loss: 0.7073 - val_loss: 0.6246
Epoch 12/43
95/95 [==============================] - 29s 304ms/step - loss: 0.7071 - val_loss: 0.6240
Epoch 13/43
95/95 [==============================] - 29s 303ms/step - loss: 0.7068 - val_loss: 0.6235
Epoch 14/43
95/95 [==============================] - 29s 304ms/step - loss: 0.7067 - val_loss: 0.6230
Epoch 15/43
95/95 [==============================] - 29s 305ms/step - loss: 0.7065 - val_loss: 0.6226
Epoch 16/43
95/95 [==============================] - 29s 304ms/step - loss: 0.7064 - val_loss: 0.6223
Epoch 17/43
95/95 [==============================] - 29s 304ms/step - loss: 0.7062 - val_loss: 0.6220
Epoch 18/43
95/95 [==============================] - 29s 305ms/step - loss: 0.7061 - val_loss: 0.6217
Epoch 19/43
95/95 [==============================] - 29s 303ms/step - loss: 0.7060 - val_loss: 0.6214
Epoch 20/43
95/95 [==============================] - 29s 303ms/step - loss: 0.7059 - val_loss: 0.6212
Epoch 21/43
95/95 [==============================] - 29s 304ms/step - loss: 0.7058 - val_loss: 0.6210
Epoch 22/43
95/95 [==============================] - 29s 306ms/step - loss: 0.7058 - val_loss: 0.6208
Epoch 23/43
95/95 [==============================] - 29s 304ms/step - loss: 0.7057 - val_loss: 0.6206
Epoch 24/43
95/95 [==============================] - 29s 305ms/step - loss: 0.7056 - val_loss: 0.6205
Epoch 25/43
95/95 [==============================] - 29s 306ms/step - loss: 0.7056 - val_loss: 0.6203
Epoch 26/43
95/95 [==============================] - 29s 302ms/step - loss: 0.7055 - val_loss: 0.6202
Epoch 27/43
95/95 [==============================] - 29s 307ms/step - loss: 0.7054 - val_loss: 0.6200
Epoch 28/43
95/95 [==============================] - 29s 305ms/step - loss: 0.7054 - val_loss: 0.6199
Epoch 29/43
95/95 [==============================] - 29s 302ms/step - loss: 0.7053 - val_loss: 0.6198
Epoch 30/43
95/95 [==============================] - 29s 305ms/step - loss: 0.7053 - val_loss: 0.6197
Epoch 31/43
95/95 [==============================] - 29s 304ms/step - loss: 0.7053 - val_loss: 0.6196
Epoch 32/43
95/95 [==============================] - 29s 305ms/step - loss: 0.7052 - val_loss: 0.6195
Epoch 33/43
95/95 [==============================] - 29s 307ms/step - loss: 0.7052 - val_loss: 0.6194
Epoch 34/43
95/95 [==============================] - 29s 305ms/step - loss: 0.7052 - val_loss: 0.6193
Epoch 35/43
95/95 [==============================] - 29s 306ms/step - loss: 0.7051 - val_loss: 0.6192
Epoch 36/43
95/95 [==============================] - 29s 305ms/step - loss: 0.7051 - val_loss: 0.6192
Epoch 37/43
95/95 [==============================] - 29s 307ms/step - loss: 0.7051 - val_loss: 0.6191
Epoch 38/43
95/95 [==============================] - 29s 304ms/step - loss: 0.7050 - val_loss: 0.6190
Epoch 39/43
95/95 [==============================] - 29s 309ms/step - loss: 0.7050 - val_loss: 0.6190
Epoch 40/43
95/95 [==============================] - 29s 305ms/step - loss: 0.7050 - val_loss: 0.6189
Epoch 41/43
95/95 [==============================] - 29s 303ms/step - loss: 0.7050 - val_loss: 0.6188
Epoch 42/43
95/95 [==============================] - 29s 308ms/step - loss: 0.7049 - val_loss: 0.6188
Epoch 43/43
95/95 [==============================] - 29s 306ms/step - loss: 0.7049 - val_loss: 0.6187
Execution time:  1265.280571937561
LSTM:
Mean Absolute Error: 0.6932
Root Mean Square Error: 0.9952
Mean Square Error: 0.9905

Train RMSE: 0.995
Train MSE: 0.990
Train MAE: 0.693
###########################

MODEL:  LSTM
sequence:  7d
units:  43
dropout1:  0.40519643149940265
dropout2:  0.3312343747027119
optimizer: adam
activationDense: tanh
epochs: 56
batchsize: 11
validation_split: 0.1
Model: &#34;sequential_72&#34;
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
lstm_144 (LSTM)              (None, 1008, 43)          7740      
_________________________________________________________________
dropout_144 (Dropout)        (None, 1008, 43)          0         
_________________________________________________________________
lstm_145 (LSTM)              (None, 1008, 43)          14964     
_________________________________________________________________
dropout_145 (Dropout)        (None, 1008, 43)          0         
_________________________________________________________________
time_distributed_72 (TimeDis (None, 1008, 1)           44        
=================================================================
Total params: 22,748
Trainable params: 22,748
Non-trainable params: 0
_________________________________________________________________
Epoch 1/56
244/244 [==============================] - 117s 480ms/step - loss: 0.5957 - val_loss: 0.2276
Epoch 2/56
244/244 [==============================] - 116s 475ms/step - loss: 0.5751 - val_loss: 0.4579
Epoch 3/56
244/244 [==============================] - 116s 474ms/step - loss: 0.5607 - val_loss: 0.4157
Epoch 4/56
244/244 [==============================] - 116s 476ms/step - loss: 0.5674 - val_loss: 0.5167
Epoch 5/56
244/244 [==============================] - 116s 474ms/step - loss: 0.5651 - val_loss: 0.4912
Epoch 6/56
244/244 [==============================] - 116s 475ms/step - loss: 0.5655 - val_loss: 0.3717
Epoch 7/56
244/244 [==============================] - 116s 476ms/step - loss: 0.5633 - val_loss: 0.4060
Epoch 8/56
244/244 [==============================] - 117s 478ms/step - loss: 0.5623 - val_loss: 0.4283
Epoch 9/56
244/244 [==============================] - 116s 477ms/step - loss: 0.5666 - val_loss: 0.4018
Epoch 10/56
244/244 [==============================] - 116s 476ms/step - loss: 0.5675 - val_loss: 0.3887
Epoch 11/56
244/244 [==============================] - 116s 475ms/step - loss: 0.5625 - val_loss: 0.3851
Epoch 12/56
244/244 [==============================] - 116s 475ms/step - loss: 0.5613 - val_loss: 0.3887
Epoch 13/56
244/244 [==============================] - 116s 475ms/step - loss: 0.5607 - val_loss: 0.3923
Epoch 14/56
244/244 [==============================] - 116s 474ms/step - loss: 0.5588 - val_loss: 0.3909
Epoch 15/56
244/244 [==============================] - 116s 475ms/step - loss: 0.5573 - val_loss: 0.3896
Epoch 16/56
244/244 [==============================] - 116s 476ms/step - loss: 0.5561 - val_loss: 0.3874
Epoch 17/56
244/244 [==============================] - 117s 478ms/step - loss: 0.5562 - val_loss: 0.3921
Epoch 18/56
244/244 [==============================] - 117s 478ms/step - loss: 0.5538 - val_loss: 0.4256
Epoch 19/56
244/244 [==============================] - 116s 477ms/step - loss: 0.5506 - val_loss: 0.4503
Epoch 20/56
244/244 [==============================] - 117s 478ms/step - loss: 0.5478 - val_loss: 0.4735
Epoch 21/56
244/244 [==============================] - 116s 477ms/step - loss: 0.5453 - val_loss: 0.4885
Epoch 22/56
244/244 [==============================] - 116s 475ms/step - loss: 0.5483 - val_loss: 0.4876
Epoch 23/56
244/244 [==============================] - 118s 482ms/step - loss: 0.5519 - val_loss: 0.4565
Epoch 24/56
244/244 [==============================] - 116s 474ms/step - loss: 0.5548 - val_loss: 0.4324
Epoch 25/56
244/244 [==============================] - 116s 475ms/step - loss: 0.5536 - val_loss: 0.4191
Epoch 26/56
244/244 [==============================] - 116s 476ms/step - loss: 0.5518 - val_loss: 0.4189
Epoch 27/56
244/244 [==============================] - 116s 477ms/step - loss: 0.5478 - val_loss: 0.4448
Epoch 28/56
244/244 [==============================] - 117s 480ms/step - loss: 0.5457 - val_loss: 0.4700
Epoch 29/56
244/244 [==============================] - 117s 478ms/step - loss: 0.5436 - val_loss: 0.4859
Epoch 30/56
244/244 [==============================] - 117s 481ms/step - loss: 0.5439 - val_loss: 0.4954
Epoch 31/56
244/244 [==============================] - 117s 479ms/step - loss: 0.5423 - val_loss: 0.5016
Epoch 32/56
244/244 [==============================] - 117s 479ms/step - loss: 0.5389 - val_loss: 0.5069
Epoch 33/56
244/244 [==============================] - 117s 479ms/step - loss: 0.5402 - val_loss: 0.5090
Epoch 34/56
244/244 [==============================] - 117s 481ms/step - loss: 0.5398 - val_loss: 0.5111
Epoch 35/56
244/244 [==============================] - 117s 479ms/step - loss: 0.5399 - val_loss: 0.5133
Epoch 36/56
244/244 [==============================] - 117s 480ms/step - loss: 0.5409 - val_loss: 0.5147
Epoch 37/56
244/244 [==============================] - 117s 480ms/step - loss: 0.5401 - val_loss: 0.5167
Epoch 38/56
244/244 [==============================] - 118s 482ms/step - loss: 0.5388 - val_loss: 0.5182
Epoch 39/56
244/244 [==============================] - 118s 482ms/step - loss: 0.5395 - val_loss: 0.5199
Epoch 40/56
244/244 [==============================] - 117s 480ms/step - loss: 0.5424 - val_loss: 0.5169
Epoch 41/56
244/244 [==============================] - 117s 480ms/step - loss: 0.5392 - val_loss: 0.5188
Epoch 42/56
244/244 [==============================] - 117s 481ms/step - loss: 0.5388 - val_loss: 0.5214
Epoch 43/56
244/244 [==============================] - 118s 482ms/step - loss: 0.5395 - val_loss: 0.5218
Epoch 44/56
244/244 [==============================] - 118s 482ms/step - loss: 0.5447 - val_loss: 0.5137
Epoch 45/56
244/244 [==============================] - 118s 483ms/step - loss: 0.5435 - val_loss: 0.5081
Epoch 46/56
244/244 [==============================] - 118s 482ms/step - loss: 0.5431 - val_loss: 0.5036
Epoch 47/56
244/244 [==============================] - 118s 482ms/step - loss: 0.5416 - val_loss: 0.5023
Epoch 48/56
244/244 [==============================] - 117s 480ms/step - loss: 0.5407 - val_loss: 0.5019
Epoch 49/56
244/244 [==============================] - 117s 480ms/step - loss: 0.5404 - val_loss: 0.5047
Epoch 50/56
244/244 [==============================] - 118s 482ms/step - loss: 0.5384 - val_loss: 0.5075
Epoch 51/56
244/244 [==============================] - 117s 479ms/step - loss: 0.5403 - val_loss: 0.5082
Epoch 52/56
244/244 [==============================] - 117s 481ms/step - loss: 0.5346 - val_loss: 0.5141
Epoch 53/56
244/244 [==============================] - 117s 481ms/step - loss: 0.5394 - val_loss: 0.5159
Epoch 54/56
244/244 [==============================] - 116s 477ms/step - loss: 0.5398 - val_loss: 0.5176
Epoch 55/56
244/244 [==============================] - 117s 479ms/step - loss: 0.5388 - val_loss: 0.5188
Epoch 56/56
244/244 [==============================] - 117s 479ms/step - loss: 0.5421 - val_loss: 0.5160
Execution time:  6566.312698364258
LSTM:
Mean Absolute Error: 0.6330
Root Mean Square Error: 1.1150
Mean Square Error: 1.2431

Train RMSE: 1.115
Train MSE: 1.243
Train MAE: 0.633
###########################

MODEL:  LSTM
sequence:  7d
units:  45
dropout1:  0.11814836227952394
dropout2:  0.24325404382648977
optimizer: adam
activationDense: tanh
epochs: 43
batchsize: 30
validation_split: 0.2
Model: &#34;sequential_73&#34;
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
lstm_146 (LSTM)              (None, 1008, 45)          8460      
_________________________________________________________________
dropout_146 (Dropout)        (None, 1008, 45)          0         
_________________________________________________________________
lstm_147 (LSTM)              (None, 1008, 45)          16380     
_________________________________________________________________
dropout_147 (Dropout)        (None, 1008, 45)          0         
_________________________________________________________________
time_distributed_73 (TimeDis (None, 1008, 1)           46        
=================================================================
Total params: 24,886
Trainable params: 24,886
Non-trainable params: 0
_________________________________________________________________
Epoch 1/43
80/80 [==============================] - 61s 762ms/step - loss: 0.6789 - val_loss: 0.5106
Epoch 2/43
80/80 [==============================] - 62s 772ms/step - loss: 0.6402 - val_loss: 0.5063
Epoch 3/43
80/80 [==============================] - 62s 778ms/step - loss: 0.6216 - val_loss: 0.4433
Epoch 4/43
80/80 [==============================] - 62s 778ms/step - loss: 0.6105 - val_loss: 0.4128
Epoch 5/43
80/80 [==============================] - 62s 779ms/step - loss: 0.6063 - val_loss: 0.3903
Epoch 6/43
80/80 [==============================] - 62s 777ms/step - loss: 0.6026 - val_loss: 0.3895
Epoch 7/43
80/80 [==============================] - 62s 778ms/step - loss: 0.6018 - val_loss: 0.3771
Epoch 8/43
80/80 [==============================] - 62s 779ms/step - loss: 0.5985 - val_loss: 0.3843
Epoch 9/43
80/80 [==============================] - 62s 773ms/step - loss: 0.5984 - val_loss: 0.3817
Epoch 10/43
80/80 [==============================] - 62s 779ms/step - loss: 0.5956 - val_loss: 0.3607
Epoch 11/43
80/80 [==============================] - 62s 778ms/step - loss: 0.5940 - val_loss: 0.3822
Epoch 12/43
80/80 [==============================] - 63s 783ms/step - loss: 0.5933 - val_loss: 0.3775
Epoch 13/43
80/80 [==============================] - 62s 775ms/step - loss: 0.5934 - val_loss: 0.3823
Epoch 14/43
80/80 [==============================] - 62s 777ms/step - loss: 0.5904 - val_loss: 0.3285
Epoch 15/43
80/80 [==============================] - 62s 777ms/step - loss: 0.6004 - val_loss: 0.3473
Epoch 16/43
80/80 [==============================] - 62s 775ms/step - loss: 0.5849 - val_loss: 0.3486
Epoch 17/43
80/80 [==============================] - 62s 774ms/step - loss: 0.5821 - val_loss: 0.3581
Epoch 18/43
80/80 [==============================] - 62s 773ms/step - loss: 0.5786 - val_loss: 0.3673
Epoch 19/43
80/80 [==============================] - 62s 778ms/step - loss: 0.5761 - val_loss: 0.3756
Epoch 20/43
80/80 [==============================] - 62s 776ms/step - loss: 0.5945 - val_loss: 0.3434
Epoch 21/43
80/80 [==============================] - 62s 777ms/step - loss: 0.5806 - val_loss: 0.3734
Epoch 22/43
80/80 [==============================] - 62s 774ms/step - loss: 0.5937 - val_loss: 0.3916
Epoch 23/43
80/80 [==============================] - 62s 779ms/step - loss: 0.5908 - val_loss: 0.3902
Epoch 24/43
80/80 [==============================] - 62s 777ms/step - loss: 0.5903 - val_loss: 0.3902
Epoch 25/43
80/80 [==============================] - 62s 779ms/step - loss: 0.5895 - val_loss: 0.3903
Epoch 26/43
80/80 [==============================] - 62s 776ms/step - loss: 0.5890 - val_loss: 0.3904
Epoch 27/43
80/80 [==============================] - 63s 783ms/step - loss: 0.5885 - val_loss: 0.3905
Epoch 28/43
80/80 [==============================] - 62s 771ms/step - loss: 0.5881 - val_loss: 0.3908
Epoch 29/43
80/80 [==============================] - 62s 779ms/step - loss: 0.5877 - val_loss: 0.3910
Epoch 30/43
80/80 [==============================] - 62s 774ms/step - loss: 0.5874 - val_loss: 0.3913
Epoch 31/43
80/80 [==============================] - 62s 779ms/step - loss: 0.5872 - val_loss: 0.3916
Epoch 32/43
80/80 [==============================] - 62s 779ms/step - loss: 0.5870 - val_loss: 0.3920
Epoch 33/43
80/80 [==============================] - 62s 779ms/step - loss: 0.5867 - val_loss: 0.3925
Epoch 34/43
80/80 [==============================] - 62s 773ms/step - loss: 0.5865 - val_loss: 0.3929
Epoch 35/43
80/80 [==============================] - 62s 777ms/step - loss: 0.5863 - val_loss: 0.3934
Epoch 36/43
80/80 [==============================] - 62s 779ms/step - loss: 0.5861 - val_loss: 0.3939
Epoch 37/43
80/80 [==============================] - 62s 776ms/step - loss: 0.5859 - val_loss: 0.3944
Epoch 38/43
80/80 [==============================] - 62s 774ms/step - loss: 0.5857 - val_loss: 0.3950
Epoch 39/43
80/80 [==============================] - 62s 776ms/step - loss: 0.5855 - val_loss: 0.3959
Epoch 40/43
80/80 [==============================] - 62s 779ms/step - loss: 0.5853 - val_loss: 0.3967
Epoch 41/43
80/80 [==============================] - 62s 781ms/step - loss: 0.5852 - val_loss: 0.3975
Epoch 42/43
80/80 [==============================] - 62s 776ms/step - loss: 0.5852 - val_loss: 0.3982
Epoch 43/43
80/80 [==============================] - 62s 778ms/step - loss: 0.5850 - val_loss: 0.3992
Execution time:  2708.8113062381744
LSTM:
Mean Absolute Error: 0.6724
Root Mean Square Error: 1.1562
Mean Square Error: 1.3368

Train RMSE: 1.156
Train MSE: 1.337
Train MAE: 0.672
###########################

MODEL:  LSTM
sequence:  7d
units:  43
dropout1:  0.40519643149940265
dropout2:  0.3312343747027119
optimizer: adam
activationDense: sigmoid
epochs: 56
batchsize: 11
validation_split: 0.1
Model: &#34;sequential_74&#34;
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
lstm_148 (LSTM)              (None, 1008, 43)          7740      
_________________________________________________________________
dropout_148 (Dropout)        (None, 1008, 43)          0         
_________________________________________________________________
lstm_149 (LSTM)              (None, 1008, 43)          14964     
_________________________________________________________________
dropout_149 (Dropout)        (None, 1008, 43)          0         
_________________________________________________________________
time_distributed_74 (TimeDis (None, 1008, 1)           44        
=================================================================
Total params: 22,748
Trainable params: 22,748
Non-trainable params: 0
_________________________________________________________________
Epoch 1/56
244/244 [==============================] - 119s 488ms/step - loss: 0.7568 - val_loss: 0.8411
Epoch 2/56
244/244 [==============================] - 118s 482ms/step - loss: 0.6814 - val_loss: 0.8373
Epoch 3/56
244/244 [==============================] - 117s 482ms/step - loss: 0.6801 - val_loss: 0.8362
Epoch 4/56
244/244 [==============================] - 118s 484ms/step - loss: 0.6796 - val_loss: 0.8357
Epoch 5/56
244/244 [==============================] - 118s 482ms/step - loss: 0.6793 - val_loss: 0.8353
Epoch 6/56
244/244 [==============================] - 118s 482ms/step - loss: 0.6791 - val_loss: 0.8351
Epoch 7/56
244/244 [==============================] - 118s 483ms/step - loss: 0.6790 - val_loss: 0.8349
Epoch 8/56
244/244 [==============================] - 118s 483ms/step - loss: 0.6789 - val_loss: 0.8348
Epoch 9/56
244/244 [==============================] - 117s 481ms/step - loss: 0.6788 - val_loss: 0.8347
Epoch 10/56
244/244 [==============================] - 118s 482ms/step - loss: 0.6788 - val_loss: 0.8346
Epoch 11/56
244/244 [==============================] - 117s 481ms/step - loss: 0.6787 - val_loss: 0.8345
Epoch 12/56
244/244 [==============================] - 118s 483ms/step - loss: 0.6787 - val_loss: 0.8345
Epoch 13/56
244/244 [==============================] - 118s 482ms/step - loss: 0.6786 - val_loss: 0.8344
Epoch 14/56
244/244 [==============================] - 118s 483ms/step - loss: 0.6786 - val_loss: 0.8344
Epoch 15/56
244/244 [==============================] - 118s 482ms/step - loss: 0.6786 - val_loss: 0.8343
Epoch 16/56
244/244 [==============================] - 118s 482ms/step - loss: 0.6786 - val_loss: 0.8343
Epoch 17/56
244/244 [==============================] - 118s 483ms/step - loss: 0.6785 - val_loss: 0.8343
Epoch 18/56
244/244 [==============================] - 118s 482ms/step - loss: 0.6785 - val_loss: 0.8342
Epoch 19/56
244/244 [==============================] - 118s 483ms/step - loss: 0.6785 - val_loss: 0.8342
Epoch 20/56
244/244 [==============================] - 118s 483ms/step - loss: 0.6785 - val_loss: 0.8342
Epoch 21/56
244/244 [==============================] - 118s 482ms/step - loss: 0.6785 - val_loss: 0.8342
Epoch 22/56
244/244 [==============================] - 117s 481ms/step - loss: 0.6785 - val_loss: 0.8342
Epoch 23/56
244/244 [==============================] - 118s 482ms/step - loss: 0.6785 - val_loss: 0.8341
Epoch 24/56
244/244 [==============================] - 118s 483ms/step - loss: 0.6785 - val_loss: 0.8341
Epoch 25/56
244/244 [==============================] - 118s 482ms/step - loss: 0.6785 - val_loss: 0.8341
Epoch 26/56
244/244 [==============================] - 118s 482ms/step - loss: 0.6785 - val_loss: 0.8341
Epoch 27/56
244/244 [==============================] - 118s 484ms/step - loss: 0.6785 - val_loss: 0.8341
Epoch 28/56
244/244 [==============================] - 118s 482ms/step - loss: 0.6785 - val_loss: 0.8341
Epoch 29/56
244/244 [==============================] - 118s 482ms/step - loss: 0.6785 - val_loss: 0.8341
Epoch 30/56
244/244 [==============================] - 117s 481ms/step - loss: 0.6785 - val_loss: 0.8341
Epoch 31/56
244/244 [==============================] - 118s 482ms/step - loss: 0.6785 - val_loss: 0.8341
Epoch 32/56
244/244 [==============================] - 117s 481ms/step - loss: 0.6785 - val_loss: 0.8341
Epoch 33/56
244/244 [==============================] - 117s 481ms/step - loss: 0.6785 - val_loss: 0.8341
Epoch 34/56
244/244 [==============================] - 117s 481ms/step - loss: 0.6785 - val_loss: 0.8341
Epoch 35/56
244/244 [==============================] - 118s 483ms/step - loss: 0.6785 - val_loss: 0.8341
Epoch 36/56
244/244 [==============================] - 117s 482ms/step - loss: 0.6785 - val_loss: 0.8341
Epoch 37/56
244/244 [==============================] - 118s 483ms/step - loss: 0.6785 - val_loss: 0.8341
Epoch 38/56
244/244 [==============================] - 118s 482ms/step - loss: 0.6785 - val_loss: 0.8341
Epoch 39/56
244/244 [==============================] - 118s 483ms/step - loss: 0.6785 - val_loss: 0.8341
Epoch 40/56
244/244 [==============================] - 118s 482ms/step - loss: 0.6785 - val_loss: 0.8341
Epoch 41/56
244/244 [==============================] - 117s 481ms/step - loss: 0.6785 - val_loss: 0.8341
Epoch 42/56
244/244 [==============================] - 117s 481ms/step - loss: 0.6785 - val_loss: 0.8341
Epoch 43/56
244/244 [==============================] - 118s 484ms/step - loss: 0.6785 - val_loss: 0.8341
Epoch 44/56
244/244 [==============================] - 118s 483ms/step - loss: 0.6785 - val_loss: 0.8341
Epoch 45/56
244/244 [==============================] - 118s 483ms/step - loss: 0.6785 - val_loss: 0.8341
Epoch 46/56
244/244 [==============================] - 118s 483ms/step - loss: 0.6785 - val_loss: 0.8341
Epoch 47/56
244/244 [==============================] - 117s 481ms/step - loss: 0.6785 - val_loss: 0.8341
Epoch 48/56
244/244 [==============================] - 118s 482ms/step - loss: 0.6785 - val_loss: 0.8341
Epoch 49/56
244/244 [==============================] - 118s 482ms/step - loss: 0.6785 - val_loss: 0.8341
Epoch 50/56
244/244 [==============================] - 118s 483ms/step - loss: 0.6785 - val_loss: 0.8341
Epoch 51/56
244/244 [==============================] - 118s 482ms/step - loss: 0.6785 - val_loss: 0.8341
Epoch 52/56
244/244 [==============================] - 118s 483ms/step - loss: 0.6785 - val_loss: 0.8341
Epoch 53/56
244/244 [==============================] - 117s 481ms/step - loss: 0.6785 - val_loss: 0.8341
Epoch 54/56
244/244 [==============================] - 117s 481ms/step - loss: 0.6785 - val_loss: 0.8341
Epoch 55/56
244/244 [==============================] - 118s 483ms/step - loss: 0.6785 - val_loss: 0.8341
Epoch 56/56
244/244 [==============================] - 118s 482ms/step - loss: 0.6785 - val_loss: 0.8341
Execution time:  6620.891446590424
LSTM:
Mean Absolute Error: 0.6954
Root Mean Square Error: 1.0192
Mean Square Error: 1.0387

Train RMSE: 1.019
Train MSE: 1.039
Train MAE: 0.695
###########################

MODEL:  LSTM
sequence:  7d
units:  45
dropout1:  0.11814836227952394
dropout2:  0.24325404382648977
optimizer: adam
activationDense: sigmoid
epochs: 43
batchsize: 30
validation_split: 0.2
Model: &#34;sequential_75&#34;
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
lstm_150 (LSTM)              (None, 1008, 45)          8460      
_________________________________________________________________
dropout_150 (Dropout)        (None, 1008, 45)          0         
_________________________________________________________________
lstm_151 (LSTM)              (None, 1008, 45)          16380     
_________________________________________________________________
dropout_151 (Dropout)        (None, 1008, 45)          0         
_________________________________________________________________
time_distributed_75 (TimeDis (None, 1008, 1)           46        
=================================================================
Total params: 24,886
Trainable params: 24,886
Non-trainable params: 0
_________________________________________________________________
Epoch 1/43
80/80 [==============================] - 60s 753ms/step - loss: 0.9045 - val_loss: 0.7174
Epoch 2/43
80/80 [==============================] - 60s 752ms/step - loss: 0.7109 - val_loss: 0.6773
Epoch 3/43
80/80 [==============================] - 60s 754ms/step - loss: 0.7052 - val_loss: 0.6735
Epoch 4/43
80/80 [==============================] - 60s 748ms/step - loss: 0.7039 - val_loss: 0.6718
Epoch 5/43
80/80 [==============================] - 60s 749ms/step - loss: 0.7032 - val_loss: 0.6708
Epoch 6/43
80/80 [==============================] - 61s 760ms/step - loss: 0.7027 - val_loss: 0.6702
Epoch 7/43
80/80 [==============================] - 60s 756ms/step - loss: 0.7024 - val_loss: 0.6698
Epoch 8/43
80/80 [==============================] - 61s 760ms/step - loss: 0.7022 - val_loss: 0.6694
Epoch 9/43
80/80 [==============================] - 60s 754ms/step - loss: 0.7021 - val_loss: 0.6692
Epoch 10/43
80/80 [==============================] - 60s 755ms/step - loss: 0.7019 - val_loss: 0.6690
Epoch 11/43
80/80 [==============================] - 60s 753ms/step - loss: 0.7018 - val_loss: 0.6688
Epoch 12/43
80/80 [==============================] - 61s 757ms/step - loss: 0.7017 - val_loss: 0.6687
Epoch 13/43
80/80 [==============================] - 60s 756ms/step - loss: 0.7017 - val_loss: 0.6685
Epoch 14/43
80/80 [==============================] - 61s 757ms/step - loss: 0.7016 - val_loss: 0.6684
Epoch 15/43
80/80 [==============================] - 60s 755ms/step - loss: 0.7016 - val_loss: 0.6683
Epoch 16/43
80/80 [==============================] - 60s 756ms/step - loss: 0.7015 - val_loss: 0.6683
Epoch 17/43
80/80 [==============================] - 60s 755ms/step - loss: 0.7015 - val_loss: 0.6682
Epoch 18/43
80/80 [==============================] - 61s 761ms/step - loss: 0.7014 - val_loss: 0.6681
Epoch 19/43
80/80 [==============================] - 60s 755ms/step - loss: 0.7014 - val_loss: 0.6680
Epoch 20/43
80/80 [==============================] - 61s 757ms/step - loss: 0.7013 - val_loss: 0.6680
Epoch 21/43
80/80 [==============================] - 60s 756ms/step - loss: 0.7013 - val_loss: 0.6679
Epoch 22/43
80/80 [==============================] - 60s 755ms/step - loss: 0.7013 - val_loss: 0.6679
Epoch 23/43
80/80 [==============================] - 60s 755ms/step - loss: 0.7013 - val_loss: 0.6679
Epoch 24/43
80/80 [==============================] - 61s 757ms/step - loss: 0.7012 - val_loss: 0.6678
Epoch 25/43
80/80 [==============================] - 61s 767ms/step - loss: 0.7012 - val_loss: 0.6678
Epoch 26/43
80/80 [==============================] - 60s 755ms/step - loss: 0.7012 - val_loss: 0.6677
Epoch 27/43
80/80 [==============================] - 61s 758ms/step - loss: 0.7012 - val_loss: 0.6677
Epoch 28/43
80/80 [==============================] - 61s 757ms/step - loss: 0.7012 - val_loss: 0.6677
Epoch 29/43
80/80 [==============================] - 60s 756ms/step - loss: 0.7011 - val_loss: 0.6676
Epoch 30/43
80/80 [==============================] - 61s 757ms/step - loss: 0.7011 - val_loss: 0.6676
Epoch 31/43
80/80 [==============================] - 61s 757ms/step - loss: 0.7011 - val_loss: 0.6676
Epoch 32/43
80/80 [==============================] - 61s 757ms/step - loss: 0.7011 - val_loss: 0.6675
Epoch 33/43
80/80 [==============================] - 61s 760ms/step - loss: 0.7011 - val_loss: 0.6675
Epoch 34/43
80/80 [==============================] - 61s 757ms/step - loss: 0.7011 - val_loss: 0.6675
Epoch 35/43
80/80 [==============================] - 61s 758ms/step - loss: 0.7011 - val_loss: 0.6675
Epoch 36/43
80/80 [==============================] - 61s 757ms/step - loss: 0.7011 - val_loss: 0.6675
Epoch 37/43
80/80 [==============================] - 61s 760ms/step - loss: 0.7010 - val_loss: 0.6674
Epoch 38/43
80/80 [==============================] - 62s 774ms/step - loss: 0.7010 - val_loss: 0.6674
Epoch 39/43
80/80 [==============================] - 61s 760ms/step - loss: 0.7010 - val_loss: 0.6674
Epoch 40/43
80/80 [==============================] - 60s 754ms/step - loss: 0.7010 - val_loss: 0.6674
Epoch 41/43
80/80 [==============================] - 61s 759ms/step - loss: 0.7010 - val_loss: 0.6674
Epoch 42/43
80/80 [==============================] - 60s 755ms/step - loss: 0.7010 - val_loss: 0.6673
Epoch 43/43
80/80 [==============================] - 61s 759ms/step - loss: 0.7010 - val_loss: 0.6673
Execution time:  2639.207366466522
LSTM:
Mean Absolute Error: 0.6956
Root Mean Square Error: 1.0192
Mean Square Error: 1.0389

Train RMSE: 1.019
Train MSE: 1.039
Train MAE: 0.696
###########################

MODEL:  LSTM
sequence:  7d
units:  43
dropout1:  0.40519643149940265
dropout2:  0.3312343747027119
optimizer: adadelta
activationDense: tanh
epochs: 56
batchsize: 11
validation_split: 0.1
Model: &#34;sequential_76&#34;
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
lstm_152 (LSTM)              (None, 1008, 43)          7740      
_________________________________________________________________
dropout_152 (Dropout)        (None, 1008, 43)          0         
_________________________________________________________________
lstm_153 (LSTM)              (None, 1008, 43)          14964     
_________________________________________________________________
dropout_153 (Dropout)        (None, 1008, 43)          0         
_________________________________________________________________
time_distributed_76 (TimeDis (None, 1008, 1)           44        
=================================================================
Total params: 22,748
Trainable params: 22,748
Non-trainable params: 0
_________________________________________________________________
Epoch 1/56
244/244 [==============================] - 118s 485ms/step - loss: 0.6767 - val_loss: 0.8466
Epoch 2/56
244/244 [==============================] - 117s 480ms/step - loss: 0.6761 - val_loss: 0.8453
Epoch 3/56
244/244 [==============================] - 117s 480ms/step - loss: 0.6754 - val_loss: 0.8439
Epoch 4/56
244/244 [==============================] - 117s 479ms/step - loss: 0.6747 - val_loss: 0.8425
Epoch 5/56
244/244 [==============================] - 117s 480ms/step - loss: 0.6739 - val_loss: 0.8409
Epoch 6/56
244/244 [==============================] - 117s 480ms/step - loss: 0.6730 - val_loss: 0.8392
Epoch 7/56
244/244 [==============================] - 117s 479ms/step - loss: 0.6721 - val_loss: 0.8374
Epoch 8/56
244/244 [==============================] - 117s 480ms/step - loss: 0.6711 - val_loss: 0.8355
Epoch 9/56
244/244 [==============================] - 117s 479ms/step - loss: 0.6702 - val_loss: 0.8335
Epoch 10/56
244/244 [==============================] - 117s 480ms/step - loss: 0.6691 - val_loss: 0.8314
Epoch 11/56
244/244 [==============================] - 117s 480ms/step - loss: 0.6680 - val_loss: 0.8292
Epoch 12/56
244/244 [==============================] - 117s 479ms/step - loss: 0.6669 - val_loss: 0.8268
Epoch 13/56
244/244 [==============================] - 117s 479ms/step - loss: 0.6657 - val_loss: 0.8244
Epoch 14/56
244/244 [==============================] - 117s 479ms/step - loss: 0.6644 - val_loss: 0.8218
Epoch 15/56
244/244 [==============================] - 117s 479ms/step - loss: 0.6631 - val_loss: 0.8191
Epoch 16/56
244/244 [==============================] - 117s 479ms/step - loss: 0.6617 - val_loss: 0.8163
Epoch 17/56
244/244 [==============================] - 117s 480ms/step - loss: 0.6603 - val_loss: 0.8132
Epoch 18/56
244/244 [==============================] - 117s 481ms/step - loss: 0.6587 - val_loss: 0.8100
Epoch 19/56
244/244 [==============================] - 117s 479ms/step - loss: 0.6572 - val_loss: 0.8067
Epoch 20/56
244/244 [==============================] - 117s 479ms/step - loss: 0.6554 - val_loss: 0.8031
Epoch 21/56
244/244 [==============================] - 117s 479ms/step - loss: 0.6537 - val_loss: 0.7993
Epoch 22/56
244/244 [==============================] - 117s 479ms/step - loss: 0.6518 - val_loss: 0.7953
Epoch 23/56
244/244 [==============================] - 117s 480ms/step - loss: 0.6499 - val_loss: 0.7911
Epoch 24/56
244/244 [==============================] - 117s 479ms/step - loss: 0.6479 - val_loss: 0.7867
Epoch 25/56
244/244 [==============================] - 117s 478ms/step - loss: 0.6459 - val_loss: 0.7822
Epoch 26/56
244/244 [==============================] - 117s 479ms/step - loss: 0.6437 - val_loss: 0.7774
Epoch 27/56
244/244 [==============================] - 117s 480ms/step - loss: 0.6415 - val_loss: 0.7725
Epoch 28/56
244/244 [==============================] - 117s 479ms/step - loss: 0.6393 - val_loss: 0.7674
Epoch 29/56
244/244 [==============================] - 117s 480ms/step - loss: 0.6370 - val_loss: 0.7620
Epoch 30/56
244/244 [==============================] - 117s 479ms/step - loss: 0.6346 - val_loss: 0.7562
Epoch 31/56
244/244 [==============================] - 117s 479ms/step - loss: 0.6320 - val_loss: 0.7502
Epoch 32/56
244/244 [==============================] - 117s 479ms/step - loss: 0.6293 - val_loss: 0.7436
Epoch 33/56
244/244 [==============================] - 117s 481ms/step - loss: 0.6265 - val_loss: 0.7367
Epoch 34/56
244/244 [==============================] - 118s 482ms/step - loss: 0.6234 - val_loss: 0.7291
Epoch 35/56
244/244 [==============================] - 117s 480ms/step - loss: 0.6200 - val_loss: 0.7209
Epoch 36/56
244/244 [==============================] - 119s 487ms/step - loss: 0.6166 - val_loss: 0.7120
Epoch 37/56
244/244 [==============================] - 117s 479ms/step - loss: 0.6128 - val_loss: 0.7024
Epoch 38/56
244/244 [==============================] - 121s 495ms/step - loss: 0.6088 - val_loss: 0.6920
Epoch 39/56
244/244 [==============================] - 119s 489ms/step - loss: 0.6047 - val_loss: 0.6808
Epoch 40/56
244/244 [==============================] - 117s 481ms/step - loss: 0.6003 - val_loss: 0.6691
Epoch 41/56
244/244 [==============================] - 118s 482ms/step - loss: 0.5959 - val_loss: 0.6569
Epoch 42/56
244/244 [==============================] - 117s 479ms/step - loss: 0.5915 - val_loss: 0.6441
Epoch 43/56
244/244 [==============================] - 117s 481ms/step - loss: 0.5871 - val_loss: 0.6309
Epoch 44/56
244/244 [==============================] - 117s 479ms/step - loss: 0.5827 - val_loss: 0.6172
Epoch 45/56
244/244 [==============================] - 117s 480ms/step - loss: 0.5783 - val_loss: 0.6031
Epoch 46/56
244/244 [==============================] - 117s 480ms/step - loss: 0.5742 - val_loss: 0.5889
Epoch 47/56
244/244 [==============================] - 118s 482ms/step - loss: 0.5703 - val_loss: 0.5753
Epoch 48/56
244/244 [==============================] - 118s 483ms/step - loss: 0.5668 - val_loss: 0.5625
Epoch 49/56
244/244 [==============================] - 117s 481ms/step - loss: 0.5641 - val_loss: 0.5510
Epoch 50/56
244/244 [==============================] - 117s 481ms/step - loss: 0.5618 - val_loss: 0.5407
Epoch 51/56
244/244 [==============================] - 118s 482ms/step - loss: 0.5600 - val_loss: 0.5315
Epoch 52/56
244/244 [==============================] - 118s 482ms/step - loss: 0.5585 - val_loss: 0.5234
Epoch 53/56
244/244 [==============================] - 118s 482ms/step - loss: 0.5572 - val_loss: 0.5162
Epoch 54/56
244/244 [==============================] - 118s 482ms/step - loss: 0.5561 - val_loss: 0.5096
Epoch 55/56
244/244 [==============================] - 118s 483ms/step - loss: 0.5553 - val_loss: 0.5035
Epoch 56/56
244/244 [==============================] - 118s 484ms/step - loss: 0.5544 - val_loss: 0.4980
Execution time:  6600.593079566956
LSTM:
Mean Absolute Error: 0.6403
Root Mean Square Error: 1.1032
Mean Square Error: 1.2171

Train RMSE: 1.103
Train MSE: 1.217
Train MAE: 0.640
###########################

MODEL:  LSTM
sequence:  7d
units:  45
dropout1:  0.11814836227952394
dropout2:  0.24325404382648977
optimizer: adadelta
activationDense: tanh
epochs: 43
batchsize: 30
validation_split: 0.2
Model: &#34;sequential_77&#34;
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
lstm_154 (LSTM)              (None, 1008, 45)          8460      
_________________________________________________________________
dropout_154 (Dropout)        (None, 1008, 45)          0         
_________________________________________________________________
lstm_155 (LSTM)              (None, 1008, 45)          16380     
_________________________________________________________________
dropout_155 (Dropout)        (None, 1008, 45)          0         
_________________________________________________________________
time_distributed_77 (TimeDis (None, 1008, 1)           46        
=================================================================
Total params: 24,886
Trainable params: 24,886
Non-trainable params: 0
_________________________________________________________________
Epoch 1/43
80/80 [==============================] - 60s 751ms/step - loss: 0.7025 - val_loss: 0.6602
Epoch 2/43
80/80 [==============================] - 61s 759ms/step - loss: 0.7024 - val_loss: 0.6600
Epoch 3/43
80/80 [==============================] - 61s 768ms/step - loss: 0.7022 - val_loss: 0.6598
Epoch 4/43
80/80 [==============================] - 61s 763ms/step - loss: 0.7020 - val_loss: 0.6595
Epoch 5/43
80/80 [==============================] - 62s 774ms/step - loss: 0.7019 - val_loss: 0.6593
Epoch 6/43
80/80 [==============================] - 62s 771ms/step - loss: 0.7017 - val_loss: 0.6591
Epoch 7/43
80/80 [==============================] - 62s 774ms/step - loss: 0.7015 - val_loss: 0.6588
Epoch 8/43
80/80 [==============================] - 62s 773ms/step - loss: 0.7013 - val_loss: 0.6585
Epoch 9/43
80/80 [==============================] - 62s 774ms/step - loss: 0.7012 - val_loss: 0.6583
Epoch 10/43
80/80 [==============================] - 62s 769ms/step - loss: 0.7010 - val_loss: 0.6580
Epoch 11/43
80/80 [==============================] - 62s 772ms/step - loss: 0.7008 - val_loss: 0.6577
Epoch 12/43
80/80 [==============================] - 61s 769ms/step - loss: 0.7005 - val_loss: 0.6574
Epoch 13/43
80/80 [==============================] - 62s 773ms/step - loss: 0.7003 - val_loss: 0.6571
Epoch 14/43
80/80 [==============================] - 62s 772ms/step - loss: 0.7001 - val_loss: 0.6568
Epoch 15/43
80/80 [==============================] - 62s 776ms/step - loss: 0.6999 - val_loss: 0.6564
Epoch 16/43
80/80 [==============================] - 62s 770ms/step - loss: 0.6997 - val_loss: 0.6561
Epoch 17/43
80/80 [==============================] - 62s 771ms/step - loss: 0.6995 - val_loss: 0.6558
Epoch 18/43
80/80 [==============================] - 62s 773ms/step - loss: 0.6992 - val_loss: 0.6554
Epoch 19/43
80/80 [==============================] - 62s 772ms/step - loss: 0.6990 - val_loss: 0.6551
Epoch 20/43
80/80 [==============================] - 61s 764ms/step - loss: 0.6988 - val_loss: 0.6547
Epoch 21/43
80/80 [==============================] - 61s 761ms/step - loss: 0.6986 - val_loss: 0.6544
Epoch 22/43
80/80 [==============================] - 61s 767ms/step - loss: 0.6983 - val_loss: 0.6540
Epoch 23/43
80/80 [==============================] - 62s 771ms/step - loss: 0.6981 - val_loss: 0.6536
Epoch 24/43
80/80 [==============================] - 61s 768ms/step - loss: 0.6978 - val_loss: 0.6533
Epoch 25/43
80/80 [==============================] - 61s 765ms/step - loss: 0.6976 - val_loss: 0.6529
Epoch 26/43
80/80 [==============================] - 61s 766ms/step - loss: 0.6974 - val_loss: 0.6525
Epoch 27/43
80/80 [==============================] - 61s 763ms/step - loss: 0.6971 - val_loss: 0.6521
Epoch 28/43
80/80 [==============================] - 62s 770ms/step - loss: 0.6969 - val_loss: 0.6517
Epoch 29/43
80/80 [==============================] - 61s 763ms/step - loss: 0.6966 - val_loss: 0.6513
Epoch 30/43
80/80 [==============================] - 61s 765ms/step - loss: 0.6963 - val_loss: 0.6509
Epoch 31/43
80/80 [==============================] - 61s 763ms/step - loss: 0.6961 - val_loss: 0.6505
Epoch 32/43
80/80 [==============================] - 61s 769ms/step - loss: 0.6959 - val_loss: 0.6501
Epoch 33/43
80/80 [==============================] - 61s 765ms/step - loss: 0.6956 - val_loss: 0.6497
Epoch 34/43
80/80 [==============================] - 61s 766ms/step - loss: 0.6953 - val_loss: 0.6493
Epoch 35/43
80/80 [==============================] - 61s 764ms/step - loss: 0.6951 - val_loss: 0.6489
Epoch 36/43
80/80 [==============================] - 61s 765ms/step - loss: 0.6948 - val_loss: 0.6484
Epoch 37/43
80/80 [==============================] - 61s 764ms/step - loss: 0.6945 - val_loss: 0.6480
Epoch 38/43
80/80 [==============================] - 61s 764ms/step - loss: 0.6943 - val_loss: 0.6476
Epoch 39/43
80/80 [==============================] - 62s 770ms/step - loss: 0.6940 - val_loss: 0.6471
Epoch 40/43
80/80 [==============================] - 62s 774ms/step - loss: 0.6937 - val_loss: 0.6467
Epoch 41/43
80/80 [==============================] - 62s 771ms/step - loss: 0.6935 - val_loss: 0.6462
Epoch 42/43
80/80 [==============================] - 62s 773ms/step - loss: 0.6932 - val_loss: 0.6458
Epoch 43/43
80/80 [==============================] - 62s 775ms/step - loss: 0.6929 - val_loss: 0.6453
Execution time:  2678.760439157486
LSTM:
Mean Absolute Error: 0.6816
Root Mean Square Error: 1.0115
Mean Square Error: 1.0231

Train RMSE: 1.011
Train MSE: 1.023
Train MAE: 0.682
###########################

MODEL:  LSTM
sequence:  7d
units:  43
dropout1:  0.40519643149940265
dropout2:  0.3312343747027119
optimizer: adadelta
activationDense: sigmoid
epochs: 56
batchsize: 11
validation_split: 0.1
Model: &#34;sequential_78&#34;
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
lstm_156 (LSTM)              (None, 1008, 43)          7740      
_________________________________________________________________
dropout_156 (Dropout)        (None, 1008, 43)          0         
_________________________________________________________________
lstm_157 (LSTM)              (None, 1008, 43)          14964     
_________________________________________________________________
dropout_157 (Dropout)        (None, 1008, 43)          0         
_________________________________________________________________
time_distributed_78 (TimeDis (None, 1008, 1)           44        
=================================================================
Total params: 22,748
Trainable params: 22,748
Non-trainable params: 0
_________________________________________________________________
Epoch 1/56
244/244 [==============================] - 122s 498ms/step - loss: 0.9812 - val_loss: 1.3328
Epoch 2/56
244/244 [==============================] - 122s 498ms/step - loss: 0.9810 - val_loss: 1.3324
Epoch 3/56
244/244 [==============================] - 121s 496ms/step - loss: 0.9807 - val_loss: 1.3321
Epoch 4/56
244/244 [==============================] - 121s 496ms/step - loss: 0.9804 - val_loss: 1.3316
Epoch 5/56
244/244 [==============================] - 121s 497ms/step - loss: 0.9801 - val_loss: 1.3312
Epoch 6/56
244/244 [==============================] - 121s 496ms/step - loss: 0.9798 - val_loss: 1.3307
Epoch 7/56
244/244 [==============================] - 121s 498ms/step - loss: 0.9794 - val_loss: 1.3302
Epoch 8/56
244/244 [==============================] - 121s 496ms/step - loss: 0.9790 - val_loss: 1.3297
Epoch 9/56
244/244 [==============================] - 121s 497ms/step - loss: 0.9786 - val_loss: 1.3291
Epoch 10/56
244/244 [==============================] - 121s 496ms/step - loss: 0.9782 - val_loss: 1.3285
Epoch 11/56
244/244 [==============================] - 121s 498ms/step - loss: 0.9778 - val_loss: 1.3279
Epoch 12/56
244/244 [==============================] - 121s 496ms/step - loss: 0.9774 - val_loss: 1.3272
Epoch 13/56
244/244 [==============================] - 121s 497ms/step - loss: 0.9769 - val_loss: 1.3266
Epoch 14/56
244/244 [==============================] - 121s 496ms/step - loss: 0.9764 - val_loss: 1.3259
Epoch 15/56
244/244 [==============================] - 121s 498ms/step - loss: 0.9759 - val_loss: 1.3251
Epoch 16/56
244/244 [==============================] - 121s 496ms/step - loss: 0.9754 - val_loss: 1.3244
Epoch 17/56
244/244 [==============================] - 121s 496ms/step - loss: 0.9748 - val_loss: 1.3236
Epoch 18/56
244/244 [==============================] - 121s 496ms/step - loss: 0.9743 - val_loss: 1.3228
Epoch 19/56
244/244 [==============================] - 121s 496ms/step - loss: 0.9737 - val_loss: 1.3219
Epoch 20/56
244/244 [==============================] - 121s 497ms/step - loss: 0.9731 - val_loss: 1.3210
Epoch 21/56
244/244 [==============================] - 121s 497ms/step - loss: 0.9725 - val_loss: 1.3200
Epoch 22/56
244/244 [==============================] - 121s 498ms/step - loss: 0.9718 - val_loss: 1.3191
Epoch 23/56
244/244 [==============================] - 121s 496ms/step - loss: 0.9711 - val_loss: 1.3180
Epoch 24/56
244/244 [==============================] - 121s 496ms/step - loss: 0.9704 - val_loss: 1.3169
Epoch 25/56
244/244 [==============================] - 121s 497ms/step - loss: 0.9696 - val_loss: 1.3158
Epoch 26/56
244/244 [==============================] - 121s 496ms/step - loss: 0.9688 - val_loss: 1.3146
Epoch 27/56
244/244 [==============================] - 121s 498ms/step - loss: 0.9680 - val_loss: 1.3134
Epoch 28/56
244/244 [==============================] - 121s 496ms/step - loss: 0.9671 - val_loss: 1.3121
Epoch 29/56
244/244 [==============================] - 121s 497ms/step - loss: 0.9662 - val_loss: 1.3107
Epoch 30/56
244/244 [==============================] - 122s 499ms/step - loss: 0.9652 - val_loss: 1.3092
Epoch 31/56
244/244 [==============================] - 122s 501ms/step - loss: 0.9642 - val_loss: 1.3076
Epoch 32/56
244/244 [==============================] - 121s 496ms/step - loss: 0.9631 - val_loss: 1.3060
Epoch 33/56
244/244 [==============================] - 121s 497ms/step - loss: 0.9620 - val_loss: 1.3042
Epoch 34/56
244/244 [==============================] - 121s 496ms/step - loss: 0.9608 - val_loss: 1.3024
Epoch 35/56
244/244 [==============================] - 121s 496ms/step - loss: 0.9595 - val_loss: 1.3004
Epoch 36/56
244/244 [==============================] - 121s 497ms/step - loss: 0.9581 - val_loss: 1.2982
Epoch 37/56
244/244 [==============================] - 121s 498ms/step - loss: 0.9566 - val_loss: 1.2960
Epoch 38/56
244/244 [==============================] - 121s 497ms/step - loss: 0.9550 - val_loss: 1.2935
Epoch 39/56
244/244 [==============================] - 121s 497ms/step - loss: 0.9533 - val_loss: 1.2909
Epoch 40/56
244/244 [==============================] - 121s 497ms/step - loss: 0.9515 - val_loss: 1.2880
Epoch 41/56
244/244 [==============================] - 121s 498ms/step - loss: 0.9496 - val_loss: 1.2850
Epoch 42/56
244/244 [==============================] - 121s 497ms/step - loss: 0.9475 - val_loss: 1.2816
Epoch 43/56
244/244 [==============================] - 122s 498ms/step - loss: 0.9452 - val_loss: 1.2781
Epoch 44/56
244/244 [==============================] - 122s 499ms/step - loss: 0.9428 - val_loss: 1.2742
Epoch 45/56
244/244 [==============================] - 121s 497ms/step - loss: 0.9402 - val_loss: 1.2699
Epoch 46/56
244/244 [==============================] - 121s 498ms/step - loss: 0.9373 - val_loss: 1.2653
Epoch 47/56
244/244 [==============================] - 121s 497ms/step - loss: 0.9343 - val_loss: 1.2603
Epoch 48/56
244/244 [==============================] - 121s 496ms/step - loss: 0.9308 - val_loss: 1.2548
Epoch 49/56
244/244 [==============================] - 121s 497ms/step - loss: 0.9272 - val_loss: 1.2487
Epoch 50/56
244/244 [==============================] - 121s 497ms/step - loss: 0.9231 - val_loss: 1.2421
Epoch 51/56
244/244 [==============================] - 121s 497ms/step - loss: 0.9187 - val_loss: 1.2349
Epoch 52/56
244/244 [==============================] - 122s 500ms/step - loss: 0.9139 - val_loss: 1.2271
Epoch 53/56
244/244 [==============================] - 121s 498ms/step - loss: 0.9086 - val_loss: 1.2186
Epoch 54/56
244/244 [==============================] - 121s 497ms/step - loss: 0.9029 - val_loss: 1.2094
Epoch 55/56
244/244 [==============================] - 121s 497ms/step - loss: 0.8968 - val_loss: 1.1996
Epoch 56/56
244/244 [==============================] - 121s 496ms/step - loss: 0.8904 - val_loss: 1.1893
Execution time:  6823.556005239487
LSTM:
Mean Absolute Error: 0.8446
Root Mean Square Error: 1.0735
Mean Square Error: 1.1525

Train RMSE: 1.074
Train MSE: 1.152
Train MAE: 0.845
###########################

MODEL:  LSTM
sequence:  7d
units:  45
dropout1:  0.11814836227952394
dropout2:  0.24325404382648977
optimizer: adadelta
activationDense: sigmoid
epochs: 43
batchsize: 30
validation_split: 0.2
Model: &#34;sequential_79&#34;
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
lstm_158 (LSTM)              (None, 1008, 45)          8460      
_________________________________________________________________
dropout_158 (Dropout)        (None, 1008, 45)          0         
_________________________________________________________________
lstm_159 (LSTM)              (None, 1008, 45)          16380     
_________________________________________________________________
dropout_159 (Dropout)        (None, 1008, 45)          0         
_________________________________________________________________
time_distributed_79 (TimeDis (None, 1008, 1)           46        
=================================================================
Total params: 24,886
Trainable params: 24,886
Non-trainable params: 0
_________________________________________________________________
Epoch 1/43
80/80 [==============================] - 64s 804ms/step - loss: 0.9813 - val_loss: 1.1627
Epoch 2/43
80/80 [==============================] - 63s 794ms/step - loss: 0.9813 - val_loss: 1.1626
Epoch 3/43
80/80 [==============================] - 64s 799ms/step - loss: 0.9812 - val_loss: 1.1625
Epoch 4/43
80/80 [==============================] - 64s 801ms/step - loss: 0.9812 - val_loss: 1.1625
Epoch 5/43
80/80 [==============================] - 64s 803ms/step - loss: 0.9811 - val_loss: 1.1624
Epoch 6/43
80/80 [==============================] - 64s 801ms/step - loss: 0.9811 - val_loss: 1.1623
Epoch 7/43
80/80 [==============================] - 64s 803ms/step - loss: 0.9810 - val_loss: 1.1622
Epoch 8/43
80/80 [==============================] - 64s 802ms/step - loss: 0.9809 - val_loss: 1.1621
Epoch 9/43
80/80 [==============================] - 64s 800ms/step - loss: 0.9808 - val_loss: 1.1620
Epoch 10/43
80/80 [==============================] - 64s 796ms/step - loss: 0.9808 - val_loss: 1.1619
Epoch 11/43
80/80 [==============================] - 64s 800ms/step - loss: 0.9807 - val_loss: 1.1618
Epoch 12/43
80/80 [==============================] - 64s 798ms/step - loss: 0.9806 - val_loss: 1.1617
Epoch 13/43
80/80 [==============================] - 64s 798ms/step - loss: 0.9805 - val_loss: 1.1616
Epoch 14/43
80/80 [==============================] - 64s 801ms/step - loss: 0.9804 - val_loss: 1.1615
Epoch 15/43
80/80 [==============================] - 64s 799ms/step - loss: 0.9804 - val_loss: 1.1613
Epoch 16/43
80/80 [==============================] - 64s 800ms/step - loss: 0.9803 - val_loss: 1.1612
Epoch 17/43
80/80 [==============================] - 64s 806ms/step - loss: 0.9802 - val_loss: 1.1611
Epoch 18/43
80/80 [==============================] - 64s 799ms/step - loss: 0.9801 - val_loss: 1.1610
Epoch 19/43
80/80 [==============================] - 64s 802ms/step - loss: 0.9800 - val_loss: 1.1609
Epoch 20/43
80/80 [==============================] - 64s 801ms/step - loss: 0.9799 - val_loss: 1.1607
Epoch 21/43
80/80 [==============================] - 64s 801ms/step - loss: 0.9798 - val_loss: 1.1606
Epoch 22/43
80/80 [==============================] - 64s 804ms/step - loss: 0.9797 - val_loss: 1.1605
Epoch 23/43
80/80 [==============================] - 64s 801ms/step - loss: 0.9796 - val_loss: 1.1603
Epoch 24/43
80/80 [==============================] - 64s 802ms/step - loss: 0.9795 - val_loss: 1.1602
Epoch 25/43
80/80 [==============================] - 64s 800ms/step - loss: 0.9794 - val_loss: 1.1601
Epoch 26/43
80/80 [==============================] - 64s 803ms/step - loss: 0.9793 - val_loss: 1.1599
Epoch 27/43
80/80 [==============================] - 64s 798ms/step - loss: 0.9792 - val_loss: 1.1598
Epoch 28/43
80/80 [==============================] - 64s 803ms/step - loss: 0.9791 - val_loss: 1.1597
Epoch 29/43
80/80 [==============================] - 64s 801ms/step - loss: 0.9790 - val_loss: 1.1595
Epoch 30/43
80/80 [==============================] - 64s 799ms/step - loss: 0.9789 - val_loss: 1.1594
Epoch 31/43
80/80 [==============================] - 64s 798ms/step - loss: 0.9788 - val_loss: 1.1592
Epoch 32/43
80/80 [==============================] - 64s 796ms/step - loss: 0.9787 - val_loss: 1.1591
Epoch 33/43
80/80 [==============================] - 64s 799ms/step - loss: 0.9786 - val_loss: 1.1589
Epoch 34/43
80/80 [==============================] - 63s 793ms/step - loss: 0.9785 - val_loss: 1.1588
Epoch 35/43
80/80 [==============================] - 63s 791ms/step - loss: 0.9784 - val_loss: 1.1586
Epoch 36/43
80/80 [==============================] - 63s 793ms/step - loss: 0.9783 - val_loss: 1.1585
Epoch 37/43
80/80 [==============================] - 63s 791ms/step - loss: 0.9782 - val_loss: 1.1583
Epoch 38/43
80/80 [==============================] - 63s 787ms/step - loss: 0.9781 - val_loss: 1.1582
Epoch 39/43
80/80 [==============================] - 64s 795ms/step - loss: 0.9780 - val_loss: 1.1580
Epoch 40/43
80/80 [==============================] - 63s 790ms/step - loss: 0.9778 - val_loss: 1.1579
Epoch 41/43
80/80 [==============================] - 63s 790ms/step - loss: 0.9777 - val_loss: 1.1577
Epoch 42/43
80/80 [==============================] - 63s 788ms/step - loss: 0.9776 - val_loss: 1.1575
Epoch 43/43
80/80 [==============================] - 63s 790ms/step - loss: 0.9775 - val_loss: 1.1574
Execution time:  2782.560327529907
LSTM:
Mean Absolute Error: 0.9241
Root Mean Square Error: 1.1337
Mean Square Error: 1.2854

Train RMSE: 1.134
Train MSE: 1.285
Train MAE: 0.924
###########################

MODEL:  LSTM
sequence:  7d
units:  43
dropout1:  0.40519643149940265
dropout2:  0.3312343747027119
optimizer: adamax
activationDense: tanh
epochs: 56
batchsize: 11
validation_split: 0.1
Model: &#34;sequential_80&#34;
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
lstm_160 (LSTM)              (None, 1008, 43)          7740      
_________________________________________________________________
dropout_160 (Dropout)        (None, 1008, 43)          0         
_________________________________________________________________
lstm_161 (LSTM)              (None, 1008, 43)          14964     
_________________________________________________________________
dropout_161 (Dropout)        (None, 1008, 43)          0         
_________________________________________________________________
time_distributed_80 (TimeDis (None, 1008, 1)           44        
=================================================================
Total params: 22,748
Trainable params: 22,748
Non-trainable params: 0
_________________________________________________________________
Epoch 1/56
244/244 [==============================] - 119s 487ms/step - loss: 0.6233 - val_loss: 0.4743
Epoch 2/56
244/244 [==============================] - 119s 486ms/step - loss: 0.5706 - val_loss: 0.4328
Epoch 3/56
244/244 [==============================] - 119s 486ms/step - loss: 0.5667 - val_loss: 0.4242
Epoch 4/56
244/244 [==============================] - 118s 482ms/step - loss: 0.5658 - val_loss: 0.3915
Epoch 5/56
244/244 [==============================] - 117s 482ms/step - loss: 0.5631 - val_loss: 0.3928
Epoch 6/56
244/244 [==============================] - 118s 483ms/step - loss: 0.5620 - val_loss: 0.3986
Epoch 7/56
244/244 [==============================] - 118s 482ms/step - loss: 0.5612 - val_loss: 0.3950
Epoch 8/56
244/244 [==============================] - 118s 483ms/step - loss: 0.5604 - val_loss: 0.3913
Epoch 9/56
244/244 [==============================] - 118s 482ms/step - loss: 0.5600 - val_loss: 0.3907
Epoch 10/56
244/244 [==============================] - 118s 483ms/step - loss: 0.5598 - val_loss: 0.3907
Epoch 11/56
244/244 [==============================] - 118s 483ms/step - loss: 0.5595 - val_loss: 0.3899
Epoch 12/56
244/244 [==============================] - 118s 482ms/step - loss: 0.5593 - val_loss: 0.3894
Epoch 13/56
244/244 [==============================] - 118s 482ms/step - loss: 0.5590 - val_loss: 0.3876
Epoch 14/56
244/244 [==============================] - 118s 483ms/step - loss: 0.5592 - val_loss: 0.3870
Epoch 15/56
244/244 [==============================] - 118s 482ms/step - loss: 0.5584 - val_loss: 0.4021
Epoch 16/56
244/244 [==============================] - 118s 483ms/step - loss: 0.5575 - val_loss: 0.4223
Epoch 17/56
244/244 [==============================] - 118s 483ms/step - loss: 0.5557 - val_loss: 0.4439
Epoch 18/56
244/244 [==============================] - 118s 485ms/step - loss: 0.5559 - val_loss: 0.4726
Epoch 19/56
244/244 [==============================] - 118s 483ms/step - loss: 0.5569 - val_loss: 0.4131
Epoch 20/56
244/244 [==============================] - 118s 483ms/step - loss: 0.5572 - val_loss: 0.4115
Epoch 21/56
244/244 [==============================] - 118s 483ms/step - loss: 0.5569 - val_loss: 0.4157
Epoch 22/56
244/244 [==============================] - 118s 482ms/step - loss: 0.5566 - val_loss: 0.4233
Epoch 23/56
244/244 [==============================] - 118s 483ms/step - loss: 0.5569 - val_loss: 0.4176
Epoch 24/56
244/244 [==============================] - 118s 483ms/step - loss: 0.5563 - val_loss: 0.4194
Epoch 25/56
244/244 [==============================] - 118s 484ms/step - loss: 0.5559 - val_loss: 0.4305
Epoch 26/56
244/244 [==============================] - 118s 484ms/step - loss: 0.5554 - val_loss: 0.4220
Epoch 27/56
244/244 [==============================] - 117s 481ms/step - loss: 0.5437 - val_loss: 0.4384
Epoch 28/56
244/244 [==============================] - 118s 483ms/step - loss: 0.5519 - val_loss: 0.4304
Epoch 29/56
244/244 [==============================] - 118s 483ms/step - loss: 0.5429 - val_loss: 0.4421
Epoch 30/56
244/244 [==============================] - 118s 482ms/step - loss: 0.5418 - val_loss: 0.4468
Epoch 31/56
244/244 [==============================] - 118s 483ms/step - loss: 0.5408 - val_loss: 0.4518
Epoch 32/56
244/244 [==============================] - 118s 482ms/step - loss: 0.5401 - val_loss: 0.4774
Epoch 33/56
244/244 [==============================] - 118s 484ms/step - loss: 0.5399 - val_loss: 0.4744
Epoch 34/56
244/244 [==============================] - 118s 483ms/step - loss: 0.5385 - val_loss: 0.4747
Epoch 35/56
244/244 [==============================] - 118s 482ms/step - loss: 0.5383 - val_loss: 0.4806
Epoch 36/56
244/244 [==============================] - 118s 482ms/step - loss: 0.5380 - val_loss: 0.4727
Epoch 37/56
244/244 [==============================] - 118s 482ms/step - loss: 0.5377 - val_loss: 0.4762
Epoch 38/56
244/244 [==============================] - 118s 482ms/step - loss: 0.5389 - val_loss: 0.4916
Epoch 39/56
244/244 [==============================] - 118s 482ms/step - loss: 0.5365 - val_loss: 0.5512
Epoch 40/56
244/244 [==============================] - 118s 484ms/step - loss: 0.5370 - val_loss: 0.4822
Epoch 41/56
244/244 [==============================] - 118s 484ms/step - loss: 0.5363 - val_loss: 0.4850
Epoch 42/56
244/244 [==============================] - 118s 483ms/step - loss: 0.5361 - val_loss: 0.4883
Epoch 43/56
244/244 [==============================] - 118s 482ms/step - loss: 0.5360 - val_loss: 0.4915
Epoch 44/56
244/244 [==============================] - 118s 482ms/step - loss: 0.5358 - val_loss: 0.5002
Epoch 45/56
244/244 [==============================] - 117s 481ms/step - loss: 0.5353 - val_loss: 0.5688
Epoch 46/56
244/244 [==============================] - 118s 483ms/step - loss: 0.5377 - val_loss: 0.4888
Epoch 47/56
244/244 [==============================] - 118s 483ms/step - loss: 0.5357 - val_loss: 0.4891
Epoch 48/56
244/244 [==============================] - 117s 482ms/step - loss: 0.5354 - val_loss: 0.4997
Epoch 49/56
244/244 [==============================] - 118s 483ms/step - loss: 0.5369 - val_loss: 0.5068
Epoch 50/56
244/244 [==============================] - 118s 483ms/step - loss: 0.5348 - val_loss: 0.5664
Epoch 51/56
244/244 [==============================] - 118s 482ms/step - loss: 0.5371 - val_loss: 0.4872
Epoch 52/56
244/244 [==============================] - 118s 483ms/step - loss: 0.5351 - val_loss: 0.4910
Epoch 53/56
244/244 [==============================] - 118s 483ms/step - loss: 0.5345 - val_loss: 0.5041
Epoch 54/56
244/244 [==============================] - 118s 482ms/step - loss: 0.5377 - val_loss: 0.5591
Epoch 55/56
244/244 [==============================] - 118s 483ms/step - loss: 0.5357 - val_loss: 0.4888
Epoch 56/56
244/244 [==============================] - 118s 484ms/step - loss: 0.5343 - val_loss: 0.4936
Execution time:  6629.472941875458
LSTM:
Mean Absolute Error: 0.6667
Root Mean Square Error: 1.1497
Mean Square Error: 1.3219

Train RMSE: 1.150
Train MSE: 1.322
Train MAE: 0.667
###########################

MODEL:  LSTM
sequence:  7d
units:  45
dropout1:  0.11814836227952394
dropout2:  0.24325404382648977
optimizer: adamax
activationDense: tanh
epochs: 43
batchsize: 30
validation_split: 0.2
Model: &#34;sequential_81&#34;
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
lstm_162 (LSTM)              (None, 1008, 45)          8460      
_________________________________________________________________
dropout_162 (Dropout)        (None, 1008, 45)          0         
_________________________________________________________________
lstm_163 (LSTM)              (None, 1008, 45)          16380     
_________________________________________________________________
dropout_163 (Dropout)        (None, 1008, 45)          0         
_________________________________________________________________
time_distributed_81 (TimeDis (None, 1008, 1)           46        
=================================================================
Total params: 24,886
Trainable params: 24,886
Non-trainable params: 0
_________________________________________________________________
Epoch 1/43
80/80 [==============================] - 61s 765ms/step - loss: 0.6795 - val_loss: 0.5521
Epoch 2/43
80/80 [==============================] - 61s 766ms/step - loss: 0.6238 - val_loss: 0.4537
Epoch 3/43
80/80 [==============================] - 61s 768ms/step - loss: 0.6120 - val_loss: 0.4243
Epoch 4/43
80/80 [==============================] - 62s 771ms/step - loss: 0.6069 - val_loss: 0.4063
Epoch 5/43
80/80 [==============================] - 62s 773ms/step - loss: 0.6039 - val_loss: 0.3977
Epoch 6/43
80/80 [==============================] - 64s 794ms/step - loss: 0.6015 - val_loss: 0.3937
Epoch 7/43
80/80 [==============================] - 62s 773ms/step - loss: 0.5998 - val_loss: 0.3901
Epoch 8/43
80/80 [==============================] - 62s 773ms/step - loss: 0.5983 - val_loss: 0.3883
Epoch 9/43
80/80 [==============================] - 63s 782ms/step - loss: 0.5973 - val_loss: 0.3859
Epoch 10/43
80/80 [==============================] - 62s 778ms/step - loss: 0.5960 - val_loss: 0.3857
Epoch 11/43
80/80 [==============================] - 62s 776ms/step - loss: 0.5951 - val_loss: 0.3843
Epoch 12/43
80/80 [==============================] - 62s 770ms/step - loss: 0.5927 - val_loss: 0.3589
Epoch 13/43
80/80 [==============================] - 62s 777ms/step - loss: 0.5834 - val_loss: 0.3623
Epoch 14/43
80/80 [==============================] - 63s 782ms/step - loss: 0.5809 - val_loss: 0.3533
Epoch 15/43
80/80 [==============================] - 62s 773ms/step - loss: 0.5763 - val_loss: 0.3646
Epoch 16/43
80/80 [==============================] - 62s 776ms/step - loss: 0.5737 - val_loss: 0.3749
Epoch 17/43
80/80 [==============================] - 62s 771ms/step - loss: 0.5718 - val_loss: 0.3830
Epoch 18/43
80/80 [==============================] - 62s 774ms/step - loss: 0.5705 - val_loss: 0.3915
Epoch 19/43
80/80 [==============================] - 62s 776ms/step - loss: 0.5694 - val_loss: 0.3994
Epoch 20/43
80/80 [==============================] - 62s 770ms/step - loss: 0.5686 - val_loss: 0.4057
Epoch 21/43
80/80 [==============================] - 62s 776ms/step - loss: 0.5681 - val_loss: 0.4117
Epoch 22/43
80/80 [==============================] - 62s 775ms/step - loss: 0.5675 - val_loss: 0.4162
Epoch 23/43
80/80 [==============================] - 62s 776ms/step - loss: 0.5671 - val_loss: 0.4201
Epoch 24/43
80/80 [==============================] - 62s 777ms/step - loss: 0.5665 - val_loss: 0.4250
Epoch 25/43
80/80 [==============================] - 62s 780ms/step - loss: 0.5656 - val_loss: 0.4284
Epoch 26/43
80/80 [==============================] - 62s 772ms/step - loss: 0.5647 - val_loss: 0.4334
Epoch 27/43
80/80 [==============================] - 62s 775ms/step - loss: 0.5643 - val_loss: 0.4387
Epoch 28/43
80/80 [==============================] - 62s 776ms/step - loss: 0.5639 - val_loss: 0.4426
Epoch 29/43
80/80 [==============================] - 62s 775ms/step - loss: 0.5636 - val_loss: 0.4465
Epoch 30/43
80/80 [==============================] - 62s 775ms/step - loss: 0.5632 - val_loss: 0.4505
Epoch 31/43
80/80 [==============================] - 62s 773ms/step - loss: 0.5633 - val_loss: 0.4541
Epoch 32/43
80/80 [==============================] - 62s 771ms/step - loss: 0.5632 - val_loss: 0.4590
Epoch 33/43
80/80 [==============================] - 62s 776ms/step - loss: 0.5625 - val_loss: 0.4585
Epoch 34/43
80/80 [==============================] - 62s 777ms/step - loss: 0.5623 - val_loss: 0.4621
Epoch 35/43
80/80 [==============================] - 62s 774ms/step - loss: 0.5615 - val_loss: 0.4629
Epoch 36/43
80/80 [==============================] - 62s 772ms/step - loss: 0.5605 - val_loss: 0.4642
Epoch 37/43
80/80 [==============================] - 62s 775ms/step - loss: 0.5594 - val_loss: 0.4684
Epoch 38/43
80/80 [==============================] - 62s 776ms/step - loss: 0.5593 - val_loss: 0.4711
Epoch 39/43
80/80 [==============================] - 63s 782ms/step - loss: 0.5591 - val_loss: 0.4734
Epoch 40/43
80/80 [==============================] - 62s 775ms/step - loss: 0.5589 - val_loss: 0.4751
Epoch 41/43
80/80 [==============================] - 62s 775ms/step - loss: 0.5584 - val_loss: 0.4757
Epoch 42/43
80/80 [==============================] - 62s 774ms/step - loss: 0.5584 - val_loss: 0.4771
Epoch 43/43
80/80 [==============================] - 62s 773ms/step - loss: 0.5585 - val_loss: 0.4797
Execution time:  2701.564010620117
LSTM:
Mean Absolute Error: 0.7249
Root Mean Square Error: 1.1887
Mean Square Error: 1.4131

Train RMSE: 1.189
Train MSE: 1.413
Train MAE: 0.725
###########################

MODEL:  LSTM
sequence:  7d
units:  43
dropout1:  0.40519643149940265
dropout2:  0.3312343747027119
optimizer: adamax
activationDense: sigmoid
epochs: 56
batchsize: 11
validation_split: 0.1
Model: &#34;sequential_82&#34;
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
lstm_164 (LSTM)              (None, 1008, 43)          7740      
_________________________________________________________________
dropout_164 (Dropout)        (None, 1008, 43)          0         
_________________________________________________________________
lstm_165 (LSTM)              (None, 1008, 43)          14964     
_________________________________________________________________
dropout_165 (Dropout)        (None, 1008, 43)          0         
_________________________________________________________________
time_distributed_82 (TimeDis (None, 1008, 1)           44        
=================================================================
Total params: 22,748
Trainable params: 22,748
Non-trainable params: 0
_________________________________________________________________
Epoch 1/56
244/244 [==============================] - 120s 493ms/step - loss: 0.8057 - val_loss: 0.8555
Epoch 2/56
244/244 [==============================] - 119s 488ms/step - loss: 0.6867 - val_loss: 0.8432
Epoch 3/56
244/244 [==============================] - 119s 487ms/step - loss: 0.6829 - val_loss: 0.8398
Epoch 4/56
244/244 [==============================] - 118s 486ms/step - loss: 0.6815 - val_loss: 0.8382
Epoch 5/56
244/244 [==============================] - 119s 487ms/step - loss: 0.6807 - val_loss: 0.8372
Epoch 6/56
244/244 [==============================] - 119s 486ms/step - loss: 0.6802 - val_loss: 0.8366
Epoch 7/56
244/244 [==============================] - 118s 485ms/step - loss: 0.6798 - val_loss: 0.8361
Epoch 8/56
244/244 [==============================] - 118s 484ms/step - loss: 0.6796 - val_loss: 0.8357
Epoch 9/56
244/244 [==============================] - 118s 484ms/step - loss: 0.6794 - val_loss: 0.8355
Epoch 10/56
244/244 [==============================] - 118s 484ms/step - loss: 0.6792 - val_loss: 0.8352
Epoch 11/56
244/244 [==============================] - 118s 484ms/step - loss: 0.6791 - val_loss: 0.8350
Epoch 12/56
244/244 [==============================] - 118s 485ms/step - loss: 0.6790 - val_loss: 0.8349
Epoch 13/56
244/244 [==============================] - 118s 484ms/step - loss: 0.6789 - val_loss: 0.8348
Epoch 14/56
244/244 [==============================] - 118s 483ms/step - loss: 0.6788 - val_loss: 0.8346
Epoch 15/56
244/244 [==============================] - 118s 485ms/step - loss: 0.6787 - val_loss: 0.8345
Epoch 16/56
244/244 [==============================] - 118s 483ms/step - loss: 0.6787 - val_loss: 0.8345
Epoch 17/56
244/244 [==============================] - 118s 483ms/step - loss: 0.6786 - val_loss: 0.8344
Epoch 18/56
244/244 [==============================] - 118s 482ms/step - loss: 0.6786 - val_loss: 0.8343
Epoch 19/56
244/244 [==============================] - 118s 482ms/step - loss: 0.6786 - val_loss: 0.8343
Epoch 20/56
244/244 [==============================] - 118s 483ms/step - loss: 0.6785 - val_loss: 0.8343
Epoch 21/56
244/244 [==============================] - 118s 482ms/step - loss: 0.6785 - val_loss: 0.8342
Epoch 22/56
244/244 [==============================] - 118s 485ms/step - loss: 0.6785 - val_loss: 0.8342
Epoch 23/56
244/244 [==============================] - 117s 481ms/step - loss: 0.6785 - val_loss: 0.8342
Epoch 24/56
244/244 [==============================] - 117s 481ms/step - loss: 0.6785 - val_loss: 0.8341
Epoch 25/56
244/244 [==============================] - 118s 483ms/step - loss: 0.6785 - val_loss: 0.8341
Epoch 26/56
244/244 [==============================] - 118s 482ms/step - loss: 0.6785 - val_loss: 0.8341
Epoch 27/56
244/244 [==============================] - 117s 481ms/step - loss: 0.6785 - val_loss: 0.8341
Epoch 28/56
244/244 [==============================] - 117s 481ms/step - loss: 0.6785 - val_loss: 0.8341
Epoch 29/56
244/244 [==============================] - 117s 480ms/step - loss: 0.6785 - val_loss: 0.8341
Epoch 30/56
244/244 [==============================] - 118s 484ms/step - loss: 0.6785 - val_loss: 0.8341
Epoch 31/56
244/244 [==============================] - 117s 480ms/step - loss: 0.6785 - val_loss: 0.8341
Epoch 32/56
244/244 [==============================] - 117s 481ms/step - loss: 0.6785 - val_loss: 0.8341
Epoch 33/56
244/244 [==============================] - 118s 482ms/step - loss: 0.6785 - val_loss: 0.8341
Epoch 34/56
244/244 [==============================] - 117s 480ms/step - loss: 0.6785 - val_loss: 0.8341
Epoch 35/56
244/244 [==============================] - 117s 479ms/step - loss: 0.6785 - val_loss: 0.8341
Epoch 36/56
244/244 [==============================] - 117s 480ms/step - loss: 0.6785 - val_loss: 0.8341
Epoch 37/56
244/244 [==============================] - 117s 480ms/step - loss: 0.6785 - val_loss: 0.8341
Epoch 38/56
244/244 [==============================] - 117s 481ms/step - loss: 0.6785 - val_loss: 0.8341
Epoch 39/56
244/244 [==============================] - 117s 479ms/step - loss: 0.6785 - val_loss: 0.8341
Epoch 40/56
244/244 [==============================] - 117s 480ms/step - loss: 0.6785 - val_loss: 0.8341
Epoch 41/56
244/244 [==============================] - 117s 480ms/step - loss: 0.6785 - val_loss: 0.8341
Epoch 42/56
244/244 [==============================] - 117s 479ms/step - loss: 0.6785 - val_loss: 0.8341
Epoch 43/56
244/244 [==============================] - 117s 479ms/step - loss: 0.6785 - val_loss: 0.8341
Epoch 44/56
244/244 [==============================] - 117s 480ms/step - loss: 0.6785 - val_loss: 0.8341
Epoch 45/56
244/244 [==============================] - 117s 481ms/step - loss: 0.6785 - val_loss: 0.8341
Epoch 46/56
244/244 [==============================] - 117s 480ms/step - loss: 0.6785 - val_loss: 0.8341
Epoch 47/56
244/244 [==============================] - 117s 479ms/step - loss: 0.6785 - val_loss: 0.8341
Epoch 48/56
244/244 [==============================] - 118s 483ms/step - loss: 0.6785 - val_loss: 0.8341
Epoch 49/56
244/244 [==============================] - 117s 479ms/step - loss: 0.6785 - val_loss: 0.8341
Epoch 50/56
244/244 [==============================] - 117s 481ms/step - loss: 0.6785 - val_loss: 0.8341
Epoch 51/56
244/244 [==============================] - 117s 479ms/step - loss: 0.6785 - val_loss: 0.8341
Epoch 52/56
244/244 [==============================] - 117s 480ms/step - loss: 0.6785 - val_loss: 0.8341
Epoch 53/56
244/244 [==============================] - 117s 481ms/step - loss: 0.6785 - val_loss: 0.8341
Epoch 54/56
244/244 [==============================] - 117s 480ms/step - loss: 0.6785 - val_loss: 0.8341
Epoch 55/56
244/244 [==============================] - 117s 479ms/step - loss: 0.6785 - val_loss: 0.8341
Epoch 56/56
244/244 [==============================] - 117s 480ms/step - loss: 0.6785 - val_loss: 0.8341
Execution time:  6619.18386220932
LSTM:
Mean Absolute Error: 0.6954
Root Mean Square Error: 1.0192
Mean Square Error: 1.0387

Train RMSE: 1.019
Train MSE: 1.039
Train MAE: 0.695
###########################

MODEL:  LSTM
sequence:  7d
units:  45
dropout1:  0.11814836227952394
dropout2:  0.24325404382648977
optimizer: adamax
activationDense: sigmoid
epochs: 43
batchsize: 30
validation_split: 0.2
Model: &#34;sequential_83&#34;
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
lstm_166 (LSTM)              (None, 1008, 45)          8460      
_________________________________________________________________
dropout_166 (Dropout)        (None, 1008, 45)          0         
_________________________________________________________________
lstm_167 (LSTM)              (None, 1008, 45)          16380     
_________________________________________________________________
dropout_167 (Dropout)        (None, 1008, 45)          0         
_________________________________________________________________
time_distributed_83 (TimeDis (None, 1008, 1)           46        
=================================================================
Total params: 24,886
Trainable params: 24,886
Non-trainable params: 0
_________________________________________________________________
Epoch 1/43
80/80 [==============================] - 59s 734ms/step - loss: 0.9438 - val_loss: 0.9019
Epoch 2/43
80/80 [==============================] - 60s 744ms/step - loss: 0.7569 - val_loss: 0.7071
Epoch 3/43
80/80 [==============================] - 59s 742ms/step - loss: 0.7156 - val_loss: 0.6876
Epoch 4/43
80/80 [==============================] - 60s 744ms/step - loss: 0.7101 - val_loss: 0.6814
Epoch 5/43
80/80 [==============================] - 59s 742ms/step - loss: 0.7077 - val_loss: 0.6782
Epoch 6/43
80/80 [==============================] - 60s 749ms/step - loss: 0.7063 - val_loss: 0.6761
Epoch 7/43
80/80 [==============================] - 60s 747ms/step - loss: 0.7054 - val_loss: 0.6747
Epoch 8/43
80/80 [==============================] - 60s 749ms/step - loss: 0.7047 - val_loss: 0.6736
Epoch 9/43
80/80 [==============================] - 60s 754ms/step - loss: 0.7042 - val_loss: 0.6728
Epoch 10/43
80/80 [==============================] - 60s 752ms/step - loss: 0.7038 - val_loss: 0.6722
Epoch 11/43
80/80 [==============================] - 60s 750ms/step - loss: 0.7035 - val_loss: 0.6716
Epoch 12/43
80/80 [==============================] - 60s 749ms/step - loss: 0.7033 - val_loss: 0.6712
Epoch 13/43
80/80 [==============================] - 60s 748ms/step - loss: 0.7030 - val_loss: 0.6708
Epoch 14/43
80/80 [==============================] - 60s 751ms/step - loss: 0.7028 - val_loss: 0.6705
Epoch 15/43
80/80 [==============================] - 60s 750ms/step - loss: 0.7027 - val_loss: 0.6702
Epoch 16/43
80/80 [==============================] - 60s 750ms/step - loss: 0.7025 - val_loss: 0.6700
Epoch 17/43
80/80 [==============================] - 60s 749ms/step - loss: 0.7024 - val_loss: 0.6697
Epoch 18/43
80/80 [==============================] - 60s 751ms/step - loss: 0.7023 - val_loss: 0.6696
Epoch 19/43
80/80 [==============================] - 60s 749ms/step - loss: 0.7022 - val_loss: 0.6694
Epoch 20/43
80/80 [==============================] - 60s 753ms/step - loss: 0.7021 - val_loss: 0.6692
Epoch 21/43
80/80 [==============================] - 60s 747ms/step - loss: 0.7020 - val_loss: 0.6691
Epoch 22/43
80/80 [==============================] - 60s 751ms/step - loss: 0.7019 - val_loss: 0.6689
Epoch 23/43
80/80 [==============================] - 59s 742ms/step - loss: 0.7018 - val_loss: 0.6688
Epoch 24/43
80/80 [==============================] - 60s 746ms/step - loss: 0.7018 - val_loss: 0.6687
Epoch 25/43
80/80 [==============================] - 59s 743ms/step - loss: 0.7017 - val_loss: 0.6686
Epoch 26/43
80/80 [==============================] - 60s 744ms/step - loss: 0.7016 - val_loss: 0.6685
Epoch 27/43
80/80 [==============================] - 60s 746ms/step - loss: 0.7016 - val_loss: 0.6684
Epoch 28/43
80/80 [==============================] - 60s 749ms/step - loss: 0.7015 - val_loss: 0.6683
Epoch 29/43
80/80 [==============================] - 60s 749ms/step - loss: 0.7015 - val_loss: 0.6683
Epoch 30/43
80/80 [==============================] - 60s 754ms/step - loss: 0.7015 - val_loss: 0.6682
Epoch 31/43
80/80 [==============================] - 60s 752ms/step - loss: 0.7014 - val_loss: 0.6681
Epoch 32/43
80/80 [==============================] - 60s 749ms/step - loss: 0.7014 - val_loss: 0.6680
Epoch 33/43
80/80 [==============================] - 60s 753ms/step - loss: 0.7013 - val_loss: 0.6680
Epoch 34/43
80/80 [==============================] - 60s 754ms/step - loss: 0.7013 - val_loss: 0.6679
Epoch 35/43
80/80 [==============================] - 60s 752ms/step - loss: 0.7013 - val_loss: 0.6679
Epoch 36/43
80/80 [==============================] - 60s 752ms/step - loss: 0.7012 - val_loss: 0.6678
Epoch 37/43
80/80 [==============================] - 60s 751ms/step - loss: 0.7012 - val_loss: 0.6678
Epoch 38/43
80/80 [==============================] - 60s 756ms/step - loss: 0.7012 - val_loss: 0.6677
Epoch 39/43
80/80 [==============================] - 60s 753ms/step - loss: 0.7012 - val_loss: 0.6677
Epoch 40/43
80/80 [==============================] - 60s 756ms/step - loss: 0.7011 - val_loss: 0.6676
Epoch 41/43
80/80 [==============================] - 60s 750ms/step - loss: 0.7011 - val_loss: 0.6676
Epoch 42/43
80/80 [==============================] - 60s 751ms/step - loss: 0.7011 - val_loss: 0.6675
Epoch 43/43
80/80 [==============================] - 60s 748ms/step - loss: 0.7011 - val_loss: 0.6675
Execution time:  2611.783912420273
LSTM:
Mean Absolute Error: 0.6956
Root Mean Square Error: 1.0193
Mean Square Error: 1.0389

Train RMSE: 1.019
Train MSE: 1.039
Train MAE: 0.696
###########################

MODEL:  GRU
sequence:  1h
units:  43
dropout1:  0.40519643149940265
dropout2:  0.3312343747027119
optimizer: adam
activationDense: tanh
epochs: 56
batchsize: 11
validation_split: 0.1
Model: &#34;sequential_84&#34;
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
gru (GRU)                    (None, 6, 43)             5934      
_________________________________________________________________
dropout_168 (Dropout)        (None, 6, 43)             0         
_________________________________________________________________
gru_1 (GRU)                  (None, 6, 43)             11352     
_________________________________________________________________
dropout_169 (Dropout)        (None, 6, 43)             0         
_________________________________________________________________
time_distributed_84 (TimeDis (None, 6, 1)              44        
=================================================================
Total params: 17,330
Trainable params: 17,330
Non-trainable params: 0
_________________________________________________________________
Epoch 1/56
326/326 [==============================] - 2s 7ms/step - loss: 0.3738 - val_loss: 0.1992
Epoch 2/56
326/326 [==============================] - 1s 4ms/step - loss: 0.2903 - val_loss: 0.2041
Epoch 3/56
326/326 [==============================] - 1s 4ms/step - loss: 0.2838 - val_loss: 0.2156
Epoch 4/56
326/326 [==============================] - 1s 4ms/step - loss: 0.2825 - val_loss: 0.2119
Epoch 5/56
326/326 [==============================] - 1s 4ms/step - loss: 0.2813 - val_loss: 0.2220
Epoch 6/56
326/326 [==============================] - 1s 4ms/step - loss: 0.2817 - val_loss: 0.2226
Epoch 7/56
326/326 [==============================] - 1s 5ms/step - loss: 0.2800 - val_loss: 0.2111
Epoch 8/56
326/326 [==============================] - 1s 4ms/step - loss: 0.2803 - val_loss: 0.2223
Epoch 9/56
326/326 [==============================] - 1s 4ms/step - loss: 0.2790 - val_loss: 0.2113
Epoch 10/56
326/326 [==============================] - 1s 4ms/step - loss: 0.2783 - val_loss: 0.2045
Epoch 11/56
326/326 [==============================] - 1s 4ms/step - loss: 0.2778 - val_loss: 0.2080
Epoch 12/56
326/326 [==============================] - 1s 4ms/step - loss: 0.2776 - val_loss: 0.2050
Epoch 13/56
326/326 [==============================] - 1s 4ms/step - loss: 0.2767 - val_loss: 0.2054
Epoch 14/56
326/326 [==============================] - 1s 4ms/step - loss: 0.2748 - val_loss: 0.1950
Epoch 15/56
326/326 [==============================] - 1s 4ms/step - loss: 0.2755 - val_loss: 0.1929
Epoch 16/56
326/326 [==============================] - 1s 4ms/step - loss: 0.2730 - val_loss: 0.1800
Epoch 17/56
326/326 [==============================] - 1s 4ms/step - loss: 0.2729 - val_loss: 0.1783
Epoch 18/56
326/326 [==============================] - 1s 5ms/step - loss: 0.2723 - val_loss: 0.1718
Epoch 19/56
326/326 [==============================] - 1s 4ms/step - loss: 0.2719 - val_loss: 0.1673
Epoch 20/56
326/326 [==============================] - 1s 4ms/step - loss: 0.2715 - val_loss: 0.1676
Epoch 21/56
326/326 [==============================] - 1s 4ms/step - loss: 0.2704 - val_loss: 0.1591
Epoch 22/56
326/326 [==============================] - 1s 4ms/step - loss: 0.2705 - val_loss: 0.1572
Epoch 23/56
326/326 [==============================] - 1s 4ms/step - loss: 0.2698 - val_loss: 0.1522
Epoch 24/56
326/326 [==============================] - 1s 4ms/step - loss: 0.2687 - val_loss: 0.1458
Epoch 25/56
326/326 [==============================] - 1s 4ms/step - loss: 0.2688 - val_loss: 0.1392
Epoch 26/56
326/326 [==============================] - 1s 4ms/step - loss: 0.2694 - val_loss: 0.1459
Epoch 27/56
326/326 [==============================] - 1s 4ms/step - loss: 0.2674 - val_loss: 0.1350
Epoch 28/56
326/326 [==============================] - 1s 4ms/step - loss: 0.2678 - val_loss: 0.1292
Epoch 29/56
326/326 [==============================] - 1s 4ms/step - loss: 0.2678 - val_loss: 0.1291
Epoch 30/56
326/326 [==============================] - 1s 5ms/step - loss: 0.2676 - val_loss: 0.1205
Epoch 31/56
326/326 [==============================] - 1s 4ms/step - loss: 0.2670 - val_loss: 0.1206
Epoch 32/56
326/326 [==============================] - 1s 4ms/step - loss: 0.2664 - val_loss: 0.1192
Epoch 33/56
326/326 [==============================] - 1s 4ms/step - loss: 0.2657 - val_loss: 0.1228
Epoch 34/56
326/326 [==============================] - 1s 4ms/step - loss: 0.2658 - val_loss: 0.1196
Epoch 35/56
326/326 [==============================] - 1s 4ms/step - loss: 0.2649 - val_loss: 0.1152
Epoch 36/56
326/326 [==============================] - 1s 4ms/step - loss: 0.2658 - val_loss: 0.1111
Epoch 37/56
326/326 [==============================] - 1s 4ms/step - loss: 0.2649 - val_loss: 0.1097
Epoch 38/56
326/326 [==============================] - 1s 4ms/step - loss: 0.2648 - val_loss: 0.1110
Epoch 39/56
326/326 [==============================] - 1s 4ms/step - loss: 0.2643 - val_loss: 0.1109
Epoch 40/56
326/326 [==============================] - 1s 4ms/step - loss: 0.2655 - val_loss: 0.1059
Epoch 41/56
326/326 [==============================] - 2s 5ms/step - loss: 0.2647 - val_loss: 0.1059
Epoch 42/56
326/326 [==============================] - 1s 4ms/step - loss: 0.2645 - val_loss: 0.1054
Epoch 43/56
326/326 [==============================] - 1s 4ms/step - loss: 0.2638 - val_loss: 0.0986
Epoch 44/56
326/326 [==============================] - 1s 4ms/step - loss: 0.2638 - val_loss: 0.1023
Epoch 45/56
326/326 [==============================] - 1s 4ms/step - loss: 0.2644 - val_loss: 0.0985
Epoch 46/56
326/326 [==============================] - 1s 4ms/step - loss: 0.2643 - val_loss: 0.1003
Epoch 47/56
326/326 [==============================] - 1s 4ms/step - loss: 0.2636 - val_loss: 0.0985
Epoch 48/56
326/326 [==============================] - 1s 4ms/step - loss: 0.2636 - val_loss: 0.0985
Epoch 49/56
326/326 [==============================] - 1s 4ms/step - loss: 0.2628 - val_loss: 0.0918
Epoch 50/56
326/326 [==============================] - 1s 4ms/step - loss: 0.2627 - val_loss: 0.1016
Epoch 51/56
326/326 [==============================] - 1s 4ms/step - loss: 0.2630 - val_loss: 0.0954
Epoch 52/56
326/326 [==============================] - 1s 4ms/step - loss: 0.2629 - val_loss: 0.0940
Epoch 53/56
326/326 [==============================] - 1s 5ms/step - loss: 0.2628 - val_loss: 0.0957
Epoch 54/56
326/326 [==============================] - 1s 4ms/step - loss: 0.2625 - val_loss: 0.0958
Epoch 55/56
326/326 [==============================] - 1s 4ms/step - loss: 0.2623 - val_loss: 0.0986
Epoch 56/56
326/326 [==============================] - 1s 4ms/step - loss: 0.2627 - val_loss: 0.0943
Execution time:  84.43638944625854
GRU:
Mean Absolute Error: 0.1696
Root Mean Square Error: 0.5747
Mean Square Error: 0.3303

Train RMSE: 0.575
Train MSE: 0.330
Train MAE: 0.170
###########################

MODEL:  GRU
sequence:  1h
units:  45
dropout1:  0.11814836227952394
dropout2:  0.24325404382648977
optimizer: adam
activationDense: tanh
epochs: 43
batchsize: 30
validation_split: 0.2
Model: &#34;sequential_85&#34;
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
gru_2 (GRU)                  (None, 6, 45)             6480      
_________________________________________________________________
dropout_170 (Dropout)        (None, 6, 45)             0         
_________________________________________________________________
gru_3 (GRU)                  (None, 6, 45)             12420     
_________________________________________________________________
dropout_171 (Dropout)        (None, 6, 45)             0         
_________________________________________________________________
time_distributed_85 (TimeDis (None, 6, 1)              46        
=================================================================
Total params: 18,946
Trainable params: 18,946
Non-trainable params: 0
_________________________________________________________________
Epoch 1/43
107/107 [==============================] - 2s 16ms/step - loss: 0.4752 - val_loss: 0.2880
Epoch 2/43
107/107 [==============================] - 1s 8ms/step - loss: 0.3125 - val_loss: 0.2340
Epoch 3/43
107/107 [==============================] - 1s 8ms/step - loss: 0.2844 - val_loss: 0.2182
Epoch 4/43
107/107 [==============================] - 1s 8ms/step - loss: 0.2763 - val_loss: 0.2164
Epoch 5/43
107/107 [==============================] - 1s 9ms/step - loss: 0.2740 - val_loss: 0.2154
Epoch 6/43
107/107 [==============================] - 1s 8ms/step - loss: 0.2724 - val_loss: 0.2128
Epoch 7/43
107/107 [==============================] - 1s 8ms/step - loss: 0.2728 - val_loss: 0.2138
Epoch 8/43
107/107 [==============================] - 1s 8ms/step - loss: 0.2719 - val_loss: 0.2147
Epoch 9/43
107/107 [==============================] - 1s 8ms/step - loss: 0.2713 - val_loss: 0.2134
Epoch 10/43
107/107 [==============================] - 1s 8ms/step - loss: 0.2711 - val_loss: 0.2137
Epoch 11/43
107/107 [==============================] - 1s 8ms/step - loss: 0.2712 - val_loss: 0.2119
Epoch 12/43
107/107 [==============================] - 1s 8ms/step - loss: 0.2727 - val_loss: 0.2153
Epoch 13/43
107/107 [==============================] - 1s 8ms/step - loss: 0.2704 - val_loss: 0.2128
Epoch 14/43
107/107 [==============================] - 1s 8ms/step - loss: 0.2712 - val_loss: 0.2144
Epoch 15/43
107/107 [==============================] - 1s 8ms/step - loss: 0.2703 - val_loss: 0.2110
Epoch 16/43
107/107 [==============================] - 1s 8ms/step - loss: 0.2704 - val_loss: 0.2111
Epoch 17/43
107/107 [==============================] - 1s 8ms/step - loss: 0.2695 - val_loss: 0.2103
Epoch 18/43
107/107 [==============================] - 1s 8ms/step - loss: 0.2694 - val_loss: 0.2081
Epoch 19/43
107/107 [==============================] - 1s 8ms/step - loss: 0.2699 - val_loss: 0.2087
Epoch 20/43
107/107 [==============================] - 1s 8ms/step - loss: 0.2699 - val_loss: 0.2094
Epoch 21/43
107/107 [==============================] - 1s 8ms/step - loss: 0.2685 - val_loss: 0.2085
Epoch 22/43
107/107 [==============================] - 1s 8ms/step - loss: 0.2693 - val_loss: 0.2100
Epoch 23/43
107/107 [==============================] - 1s 9ms/step - loss: 0.2690 - val_loss: 0.2098
Epoch 24/43
107/107 [==============================] - 1s 8ms/step - loss: 0.2681 - val_loss: 0.2086
Epoch 25/43
107/107 [==============================] - 1s 9ms/step - loss: 0.2681 - val_loss: 0.2053
Epoch 26/43
107/107 [==============================] - 1s 8ms/step - loss: 0.2672 - val_loss: 0.2039
Epoch 27/43
107/107 [==============================] - 1s 8ms/step - loss: 0.2670 - val_loss: 0.2047
Epoch 28/43
107/107 [==============================] - 1s 8ms/step - loss: 0.2670 - val_loss: 0.2031
Epoch 29/43
107/107 [==============================] - 1s 8ms/step - loss: 0.2670 - val_loss: 0.2015
Epoch 30/43
107/107 [==============================] - 1s 8ms/step - loss: 0.2663 - val_loss: 0.2015
Epoch 31/43
107/107 [==============================] - 1s 8ms/step - loss: 0.2666 - val_loss: 0.2012
Epoch 32/43
107/107 [==============================] - 1s 8ms/step - loss: 0.2654 - val_loss: 0.1976
Epoch 33/43
107/107 [==============================] - 1s 8ms/step - loss: 0.2652 - val_loss: 0.1957
Epoch 34/43
107/107 [==============================] - 1s 8ms/step - loss: 0.2659 - val_loss: 0.1974
Epoch 35/43
107/107 [==============================] - 1s 8ms/step - loss: 0.2651 - val_loss: 0.1948
Epoch 36/43
107/107 [==============================] - 1s 8ms/step - loss: 0.2660 - val_loss: 0.1950
Epoch 37/43
107/107 [==============================] - 1s 8ms/step - loss: 0.2657 - val_loss: 0.1973
Epoch 38/43
107/107 [==============================] - 1s 8ms/step - loss: 0.2637 - val_loss: 0.1926
Epoch 39/43
107/107 [==============================] - 1s 8ms/step - loss: 0.2653 - val_loss: 0.1934
Epoch 40/43
107/107 [==============================] - 1s 8ms/step - loss: 0.2655 - val_loss: 0.1932
Epoch 41/43
107/107 [==============================] - 1s 9ms/step - loss: 0.2636 - val_loss: 0.1912
Epoch 42/43
107/107 [==============================] - 1s 9ms/step - loss: 0.2634 - val_loss: 0.1916
Epoch 43/43
107/107 [==============================] - 1s 8ms/step - loss: 0.2636 - val_loss: 0.1872
Execution time:  43.191447257995605
GRU:
Mean Absolute Error: 0.1574
Root Mean Square Error: 0.5736
Mean Square Error: 0.3290

Train RMSE: 0.574
Train MSE: 0.329
Train MAE: 0.157
###########################

MODEL:  GRU
sequence:  1h
units:  43
dropout1:  0.40519643149940265
dropout2:  0.3312343747027119
optimizer: adam
activationDense: sigmoid
epochs: 56
batchsize: 11
validation_split: 0.1
Model: &#34;sequential_86&#34;
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
gru_4 (GRU)                  (None, 6, 43)             5934      
_________________________________________________________________
dropout_172 (Dropout)        (None, 6, 43)             0         
_________________________________________________________________
gru_5 (GRU)                  (None, 6, 43)             11352     
_________________________________________________________________
dropout_173 (Dropout)        (None, 6, 43)             0         
_________________________________________________________________
time_distributed_86 (TimeDis (None, 6, 1)              44        
=================================================================
Total params: 17,330
Trainable params: 17,330
Non-trainable params: 0
_________________________________________________________________
Epoch 1/56
  1/326 [..............................] - ETA: 0s - loss: 0.1185WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0000s vs `on_train_batch_end` time: 0.0111s). Check your callbacks.
326/326 [==============================] - 2s 7ms/step - loss: 0.5953 - val_loss: 0.8097
Epoch 2/56
326/326 [==============================] - 1s 4ms/step - loss: 0.5135 - val_loss: 0.8066
Epoch 3/56
326/326 [==============================] - 1s 4ms/step - loss: 0.5029 - val_loss: 0.8062
Epoch 4/56
326/326 [==============================] - 1s 4ms/step - loss: 0.5021 - val_loss: 0.8061
Epoch 5/56
326/326 [==============================] - 1s 4ms/step - loss: 0.5018 - val_loss: 0.8061
Epoch 6/56
326/326 [==============================] - 1s 4ms/step - loss: 0.5014 - val_loss: 0.8060
Epoch 7/56
326/326 [==============================] - 2s 5ms/step - loss: 0.5014 - val_loss: 0.8060
Epoch 8/56
326/326 [==============================] - 1s 4ms/step - loss: 0.5008 - val_loss: 0.8060
Epoch 9/56
326/326 [==============================] - 1s 4ms/step - loss: 0.5011 - val_loss: 0.8060
Epoch 10/56
326/326 [==============================] - 1s 4ms/step - loss: 0.5008 - val_loss: 0.8060
Epoch 11/56
326/326 [==============================] - 1s 4ms/step - loss: 0.5005 - val_loss: 0.8060
Epoch 12/56
326/326 [==============================] - 1s 4ms/step - loss: 0.5009 - val_loss: 0.8060
Epoch 13/56
326/326 [==============================] - 1s 4ms/step - loss: 0.5005 - val_loss: 0.8059
Epoch 14/56
326/326 [==============================] - 1s 4ms/step - loss: 0.5001 - val_loss: 0.8059
Epoch 15/56
326/326 [==============================] - 1s 4ms/step - loss: 0.5001 - val_loss: 0.8059
Epoch 16/56
326/326 [==============================] - 1s 4ms/step - loss: 0.4998 - val_loss: 0.8059
Epoch 17/56
326/326 [==============================] - 1s 4ms/step - loss: 0.5000 - val_loss: 0.8059
Epoch 18/56
326/326 [==============================] - 1s 5ms/step - loss: 0.4997 - val_loss: 0.8059
Epoch 19/56
326/326 [==============================] - 1s 4ms/step - loss: 0.5000 - val_loss: 0.8059
Epoch 20/56
326/326 [==============================] - 1s 4ms/step - loss: 0.4995 - val_loss: 0.8059
Epoch 21/56
326/326 [==============================] - 1s 4ms/step - loss: 0.4996 - val_loss: 0.8059
Epoch 22/56
326/326 [==============================] - 1s 4ms/step - loss: 0.4993 - val_loss: 0.8059
Epoch 23/56
326/326 [==============================] - 1s 4ms/step - loss: 0.4992 - val_loss: 0.8059
Epoch 24/56
326/326 [==============================] - 1s 4ms/step - loss: 0.4991 - val_loss: 0.8059
Epoch 25/56
326/326 [==============================] - 1s 4ms/step - loss: 0.4990 - val_loss: 0.8059
Epoch 26/56
326/326 [==============================] - 1s 4ms/step - loss: 0.4986 - val_loss: 0.8059
Epoch 27/56
326/326 [==============================] - 1s 4ms/step - loss: 0.4988 - val_loss: 0.8059
Epoch 28/56
326/326 [==============================] - 1s 4ms/step - loss: 0.4986 - val_loss: 0.8059
Epoch 29/56
326/326 [==============================] - 1s 4ms/step - loss: 0.4989 - val_loss: 0.8059
Epoch 30/56
326/326 [==============================] - 1s 5ms/step - loss: 0.4988 - val_loss: 0.8059
Epoch 31/56
326/326 [==============================] - 1s 4ms/step - loss: 0.4985 - val_loss: 0.8059
Epoch 32/56
326/326 [==============================] - 1s 4ms/step - loss: 0.4982 - val_loss: 0.8059
Epoch 33/56
326/326 [==============================] - 1s 4ms/step - loss: 0.4982 - val_loss: 0.8059
Epoch 34/56
326/326 [==============================] - 1s 4ms/step - loss: 0.4980 - val_loss: 0.8059
Epoch 35/56
326/326 [==============================] - 1s 4ms/step - loss: 0.4977 - val_loss: 0.8059
Epoch 36/56
326/326 [==============================] - 1s 4ms/step - loss: 0.4981 - val_loss: 0.8059
Epoch 37/56
326/326 [==============================] - 1s 4ms/step - loss: 0.4981 - val_loss: 0.8059
Epoch 38/56
326/326 [==============================] - 1s 4ms/step - loss: 0.4980 - val_loss: 0.8059
Epoch 39/56
326/326 [==============================] - 1s 4ms/step - loss: 0.4980 - val_loss: 0.8059
Epoch 40/56
326/326 [==============================] - 1s 4ms/step - loss: 0.4979 - val_loss: 0.8059
Epoch 41/56
326/326 [==============================] - 1s 5ms/step - loss: 0.4978 - val_loss: 0.8059
Epoch 42/56
326/326 [==============================] - 1s 4ms/step - loss: 0.4980 - val_loss: 0.8059
Epoch 43/56
326/326 [==============================] - 1s 4ms/step - loss: 0.4980 - val_loss: 0.8059
Epoch 44/56
326/326 [==============================] - 1s 4ms/step - loss: 0.4979 - val_loss: 0.8059
Epoch 45/56
326/326 [==============================] - 1s 4ms/step - loss: 0.4973 - val_loss: 0.8059
Epoch 46/56
326/326 [==============================] - 1s 4ms/step - loss: 0.4979 - val_loss: 0.8059
Epoch 47/56
326/326 [==============================] - 1s 4ms/step - loss: 0.4976 - val_loss: 0.8059
Epoch 48/56
326/326 [==============================] - 1s 4ms/step - loss: 0.4974 - val_loss: 0.8059
Epoch 49/56
326/326 [==============================] - 1s 4ms/step - loss: 0.4975 - val_loss: 0.8059
Epoch 50/56
326/326 [==============================] - 1s 4ms/step - loss: 0.4974 - val_loss: 0.8059
Epoch 51/56
326/326 [==============================] - 1s 4ms/step - loss: 0.4973 - val_loss: 0.8059
Epoch 52/56
326/326 [==============================] - 1s 4ms/step - loss: 0.4975 - val_loss: 0.8059
Epoch 53/56
326/326 [==============================] - 1s 5ms/step - loss: 0.4972 - val_loss: 0.8059
Epoch 54/56
326/326 [==============================] - 1s 4ms/step - loss: 0.4973 - val_loss: 0.8059
Epoch 55/56
326/326 [==============================] - 1s 4ms/step - loss: 0.4977 - val_loss: 0.8059
Epoch 56/56
326/326 [==============================] - 1s 4ms/step - loss: 0.4971 - val_loss: 0.8059
Execution time:  82.23852682113647
GRU:
Mean Absolute Error: 0.4937
Root Mean Square Error: 0.7565
Mean Square Error: 0.5723

Train RMSE: 0.756
Train MSE: 0.572
Train MAE: 0.494
###########################

MODEL:  GRU
sequence:  1h
units:  45
dropout1:  0.11814836227952394
dropout2:  0.24325404382648977
optimizer: adam
activationDense: sigmoid
epochs: 43
batchsize: 30
validation_split: 0.2
Model: &#34;sequential_87&#34;
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
gru_6 (GRU)                  (None, 6, 45)             6480      
_________________________________________________________________
dropout_174 (Dropout)        (None, 6, 45)             0         
_________________________________________________________________
gru_7 (GRU)                  (None, 6, 45)             12420     
_________________________________________________________________
dropout_175 (Dropout)        (None, 6, 45)             0         
_________________________________________________________________
time_distributed_87 (TimeDis (None, 6, 1)              46        
=================================================================
Total params: 18,946
Trainable params: 18,946
Non-trainable params: 0
_________________________________________________________________
Epoch 1/43
107/107 [==============================] - 2s 16ms/step - loss: 0.7047 - val_loss: 0.7135
Epoch 2/43
107/107 [==============================] - 1s 8ms/step - loss: 0.5393 - val_loss: 0.6789
Epoch 3/43
107/107 [==============================] - 1s 9ms/step - loss: 0.5181 - val_loss: 0.6690
Epoch 4/43
107/107 [==============================] - 1s 8ms/step - loss: 0.5035 - val_loss: 0.6650
Epoch 5/43
107/107 [==============================] - 1s 8ms/step - loss: 0.5000 - val_loss: 0.6635
Epoch 6/43
107/107 [==============================] - 1s 8ms/step - loss: 0.4990 - val_loss: 0.6631
Epoch 7/43
107/107 [==============================] - 1s 8ms/step - loss: 0.4984 - val_loss: 0.6625
Epoch 8/43
107/107 [==============================] - 1s 8ms/step - loss: 0.4984 - val_loss: 0.6623
Epoch 9/43
107/107 [==============================] - 1s 8ms/step - loss: 0.4982 - val_loss: 0.6620
Epoch 10/43
107/107 [==============================] - 1s 8ms/step - loss: 0.4979 - val_loss: 0.6620
Epoch 11/43
107/107 [==============================] - 1s 8ms/step - loss: 0.4977 - val_loss: 0.6617
Epoch 12/43
107/107 [==============================] - 1s 8ms/step - loss: 0.4976 - val_loss: 0.6617
Epoch 13/43
107/107 [==============================] - 1s 8ms/step - loss: 0.4974 - val_loss: 0.6619
Epoch 14/43
107/107 [==============================] - 1s 8ms/step - loss: 0.4974 - val_loss: 0.6622
Epoch 15/43
107/107 [==============================] - 1s 8ms/step - loss: 0.4973 - val_loss: 0.6621
Epoch 16/43
107/107 [==============================] - 1s 8ms/step - loss: 0.4971 - val_loss: 0.6620
Epoch 17/43
107/107 [==============================] - 1s 8ms/step - loss: 0.4968 - val_loss: 0.6620
Epoch 18/43
107/107 [==============================] - 1s 8ms/step - loss: 0.4969 - val_loss: 0.6623
Epoch 19/43
107/107 [==============================] - 1s 8ms/step - loss: 0.4967 - val_loss: 0.6622
Epoch 20/43
107/107 [==============================] - 1s 8ms/step - loss: 0.4967 - val_loss: 0.6623
Epoch 21/43
107/107 [==============================] - 1s 9ms/step - loss: 0.4965 - val_loss: 0.6624
Epoch 22/43
107/107 [==============================] - 1s 8ms/step - loss: 0.4965 - val_loss: 0.6625
Epoch 23/43
107/107 [==============================] - 1s 8ms/step - loss: 0.4966 - val_loss: 0.6622
Epoch 24/43
107/107 [==============================] - 1s 8ms/step - loss: 0.4962 - val_loss: 0.6619
Epoch 25/43
107/107 [==============================] - 1s 8ms/step - loss: 0.4961 - val_loss: 0.6625
Epoch 26/43
107/107 [==============================] - 1s 8ms/step - loss: 0.4962 - val_loss: 0.6624
Epoch 27/43
107/107 [==============================] - 1s 8ms/step - loss: 0.4960 - val_loss: 0.6622
Epoch 28/43
107/107 [==============================] - 1s 8ms/step - loss: 0.4958 - val_loss: 0.6624
Epoch 29/43
107/107 [==============================] - 1s 8ms/step - loss: 0.4960 - val_loss: 0.6625
Epoch 30/43
107/107 [==============================] - 1s 8ms/step - loss: 0.4953 - val_loss: 0.6625
Epoch 31/43
107/107 [==============================] - 1s 8ms/step - loss: 0.4956 - val_loss: 0.6623
Epoch 32/43
107/107 [==============================] - 1s 8ms/step - loss: 0.4952 - val_loss: 0.6623
Epoch 33/43
107/107 [==============================] - 1s 8ms/step - loss: 0.4953 - val_loss: 0.6622
Epoch 34/43
107/107 [==============================] - 1s 8ms/step - loss: 0.4951 - val_loss: 0.6625
Epoch 35/43
107/107 [==============================] - 1s 8ms/step - loss: 0.4951 - val_loss: 0.6623
Epoch 36/43
107/107 [==============================] - 1s 8ms/step - loss: 0.4950 - val_loss: 0.6621
Epoch 37/43
107/107 [==============================] - 1s 8ms/step - loss: 0.4949 - val_loss: 0.6622
Epoch 38/43
107/107 [==============================] - 1s 8ms/step - loss: 0.4949 - val_loss: 0.6621
Epoch 39/43
107/107 [==============================] - 1s 8ms/step - loss: 0.4946 - val_loss: 0.6622
Epoch 40/43
107/107 [==============================] - 1s 9ms/step - loss: 0.4949 - val_loss: 0.6620
Epoch 41/43
107/107 [==============================] - 1s 8ms/step - loss: 0.4947 - val_loss: 0.6621
Epoch 42/43
107/107 [==============================] - 1s 8ms/step - loss: 0.4945 - val_loss: 0.6621
Epoch 43/43
107/107 [==============================] - 1s 8ms/step - loss: 0.4950 - val_loss: 0.6620
Execution time:  45.2899649143219
GRU:
Mean Absolute Error: 0.4938
Root Mean Square Error: 0.7567
Mean Square Error: 0.5726

Train RMSE: 0.757
Train MSE: 0.573
Train MAE: 0.494
###########################

MODEL:  GRU
sequence:  1h
units:  43
dropout1:  0.40519643149940265
dropout2:  0.3312343747027119
optimizer: adadelta
activationDense: tanh
epochs: 56
batchsize: 11
validation_split: 0.1
Model: &#34;sequential_88&#34;
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
gru_8 (GRU)                  (None, 6, 43)             5934      
_________________________________________________________________
dropout_176 (Dropout)        (None, 6, 43)             0         
_________________________________________________________________
gru_9 (GRU)                  (None, 6, 43)             11352     
_________________________________________________________________
dropout_177 (Dropout)        (None, 6, 43)             0         
_________________________________________________________________
time_distributed_88 (TimeDis (None, 6, 1)              44        
=================================================================
Total params: 17,330
Trainable params: 17,330
Non-trainable params: 0
_________________________________________________________________
Epoch 1/56
  1/326 [..............................] - ETA: 0s - loss: 0.4802WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0000s vs `on_train_batch_end` time: 0.0054s). Check your callbacks.
326/326 [==============================] - 2s 7ms/step - loss: 0.7157 - val_loss: 0.8169
Epoch 2/56
326/326 [==============================] - 1s 4ms/step - loss: 0.7138 - val_loss: 0.8139
Epoch 3/56
326/326 [==============================] - 1s 4ms/step - loss: 0.7119 - val_loss: 0.8109
Epoch 4/56
326/326 [==============================] - 1s 4ms/step - loss: 0.7098 - val_loss: 0.8079
Epoch 5/56
326/326 [==============================] - 1s 4ms/step - loss: 0.7080 - val_loss: 0.8048
Epoch 6/56
326/326 [==============================] - 1s 4ms/step - loss: 0.7063 - val_loss: 0.8016
Epoch 7/56
326/326 [==============================] - 1s 4ms/step - loss: 0.7043 - val_loss: 0.7984
Epoch 8/56
326/326 [==============================] - 1s 4ms/step - loss: 0.7023 - val_loss: 0.7951
Epoch 9/56
326/326 [==============================] - 1s 4ms/step - loss: 0.7004 - val_loss: 0.7918
Epoch 10/56
326/326 [==============================] - 1s 4ms/step - loss: 0.6981 - val_loss: 0.7885
Epoch 11/56
326/326 [==============================] - 1s 4ms/step - loss: 0.6964 - val_loss: 0.7850
Epoch 12/56
326/326 [==============================] - 1s 4ms/step - loss: 0.6947 - val_loss: 0.7816
Epoch 13/56
326/326 [==============================] - 1s 4ms/step - loss: 0.6924 - val_loss: 0.7781
Epoch 14/56
326/326 [==============================] - 1s 4ms/step - loss: 0.6903 - val_loss: 0.7746
Epoch 15/56
326/326 [==============================] - 1s 4ms/step - loss: 0.6882 - val_loss: 0.7710
Epoch 16/56
326/326 [==============================] - 1s 4ms/step - loss: 0.6859 - val_loss: 0.7674
Epoch 17/56
326/326 [==============================] - 1s 4ms/step - loss: 0.6842 - val_loss: 0.7637
Epoch 18/56
326/326 [==============================] - 1s 4ms/step - loss: 0.6819 - val_loss: 0.7600
Epoch 19/56
326/326 [==============================] - 1s 4ms/step - loss: 0.6798 - val_loss: 0.7562
Epoch 20/56
326/326 [==============================] - 1s 4ms/step - loss: 0.6775 - val_loss: 0.7523
Epoch 21/56
326/326 [==============================] - 1s 4ms/step - loss: 0.6751 - val_loss: 0.7485
Epoch 22/56
326/326 [==============================] - 1s 4ms/step - loss: 0.6731 - val_loss: 0.7445
Epoch 23/56
326/326 [==============================] - 1s 4ms/step - loss: 0.6706 - val_loss: 0.7405
Epoch 24/56
326/326 [==============================] - 1s 4ms/step - loss: 0.6685 - val_loss: 0.7365
Epoch 25/56
326/326 [==============================] - 1s 4ms/step - loss: 0.6663 - val_loss: 0.7324
Epoch 26/56
326/326 [==============================] - 1s 4ms/step - loss: 0.6639 - val_loss: 0.7283
Epoch 27/56
326/326 [==============================] - 1s 4ms/step - loss: 0.6616 - val_loss: 0.7242
Epoch 28/56
326/326 [==============================] - 1s 4ms/step - loss: 0.6590 - val_loss: 0.7200
Epoch 29/56
326/326 [==============================] - 1s 4ms/step - loss: 0.6566 - val_loss: 0.7158
Epoch 30/56
326/326 [==============================] - 1s 4ms/step - loss: 0.6544 - val_loss: 0.7116
Epoch 31/56
326/326 [==============================] - 1s 4ms/step - loss: 0.6518 - val_loss: 0.7074
Epoch 32/56
326/326 [==============================] - 1s 4ms/step - loss: 0.6492 - val_loss: 0.7031
Epoch 33/56
326/326 [==============================] - 1s 4ms/step - loss: 0.6470 - val_loss: 0.6987
Epoch 34/56
326/326 [==============================] - 1s 4ms/step - loss: 0.6445 - val_loss: 0.6943
Epoch 35/56
326/326 [==============================] - 1s 4ms/step - loss: 0.6420 - val_loss: 0.6899
Epoch 36/56
326/326 [==============================] - 1s 4ms/step - loss: 0.6397 - val_loss: 0.6854
Epoch 37/56
326/326 [==============================] - 1s 4ms/step - loss: 0.6371 - val_loss: 0.6809
Epoch 38/56
326/326 [==============================] - 1s 4ms/step - loss: 0.6344 - val_loss: 0.6763
Epoch 39/56
326/326 [==============================] - 1s 4ms/step - loss: 0.6317 - val_loss: 0.6717
Epoch 40/56
326/326 [==============================] - 1s 4ms/step - loss: 0.6290 - val_loss: 0.6669
Epoch 41/56
326/326 [==============================] - 1s 4ms/step - loss: 0.6261 - val_loss: 0.6621
Epoch 42/56
326/326 [==============================] - 1s 4ms/step - loss: 0.6233 - val_loss: 0.6572
Epoch 43/56
326/326 [==============================] - 1s 4ms/step - loss: 0.6206 - val_loss: 0.6522
Epoch 44/56
326/326 [==============================] - 1s 4ms/step - loss: 0.6175 - val_loss: 0.6471
Epoch 45/56
326/326 [==============================] - 1s 4ms/step - loss: 0.6152 - val_loss: 0.6420
Epoch 46/56
326/326 [==============================] - 1s 4ms/step - loss: 0.6119 - val_loss: 0.6368
Epoch 47/56
326/326 [==============================] - 1s 4ms/step - loss: 0.6086 - val_loss: 0.6314
Epoch 48/56
326/326 [==============================] - 1s 4ms/step - loss: 0.6057 - val_loss: 0.6260
Epoch 49/56
326/326 [==============================] - 1s 4ms/step - loss: 0.6025 - val_loss: 0.6205
Epoch 50/56
326/326 [==============================] - 1s 4ms/step - loss: 0.5991 - val_loss: 0.6148
Epoch 51/56
326/326 [==============================] - 1s 4ms/step - loss: 0.5958 - val_loss: 0.6091
Epoch 52/56
326/326 [==============================] - 1s 4ms/step - loss: 0.5923 - val_loss: 0.6033
Epoch 53/56
326/326 [==============================] - 2s 5ms/step - loss: 0.5893 - val_loss: 0.5974
Epoch 54/56
326/326 [==============================] - 1s 4ms/step - loss: 0.5862 - val_loss: 0.5915
Epoch 55/56
326/326 [==============================] - 1s 4ms/step - loss: 0.5825 - val_loss: 0.5854
Epoch 56/56
326/326 [==============================] - 1s 4ms/step - loss: 0.5787 - val_loss: 0.5793
Execution time:  80.02521181106567
GRU:
Mean Absolute Error: 0.5707
Root Mean Square Error: 0.8778
Mean Square Error: 0.7705

Train RMSE: 0.878
Train MSE: 0.771
Train MAE: 0.571
###########################

MODEL:  GRU
sequence:  1h
units:  45
dropout1:  0.11814836227952394
dropout2:  0.24325404382648977
optimizer: adadelta
activationDense: tanh
epochs: 43
batchsize: 30
validation_split: 0.2
Model: &#34;sequential_89&#34;
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
gru_10 (GRU)                 (None, 6, 45)             6480      
_________________________________________________________________
dropout_178 (Dropout)        (None, 6, 45)             0         
_________________________________________________________________
gru_11 (GRU)                 (None, 6, 45)             12420     
_________________________________________________________________
dropout_179 (Dropout)        (None, 6, 45)             0         
_________________________________________________________________
time_distributed_89 (TimeDis (None, 6, 1)              46        
=================================================================
Total params: 18,946
Trainable params: 18,946
Non-trainable params: 0
_________________________________________________________________
Epoch 1/43
107/107 [==============================] - 2s 16ms/step - loss: 0.6999 - val_loss: 0.6865
Epoch 2/43
107/107 [==============================] - 1s 8ms/step - loss: 0.6992 - val_loss: 0.6856
Epoch 3/43
107/107 [==============================] - 1s 8ms/step - loss: 0.6983 - val_loss: 0.6847
Epoch 4/43
107/107 [==============================] - 1s 8ms/step - loss: 0.6977 - val_loss: 0.6837
Epoch 5/43
107/107 [==============================] - 1s 8ms/step - loss: 0.6969 - val_loss: 0.6828
Epoch 6/43
107/107 [==============================] - 1s 8ms/step - loss: 0.6962 - val_loss: 0.6818
Epoch 7/43
107/107 [==============================] - 1s 9ms/step - loss: 0.6953 - val_loss: 0.6808
Epoch 8/43
107/107 [==============================] - 1s 8ms/step - loss: 0.6947 - val_loss: 0.6799
Epoch 9/43
107/107 [==============================] - 1s 8ms/step - loss: 0.6939 - val_loss: 0.6789
Epoch 10/43
107/107 [==============================] - 1s 8ms/step - loss: 0.6931 - val_loss: 0.6779
Epoch 11/43
107/107 [==============================] - 1s 8ms/step - loss: 0.6923 - val_loss: 0.6769
Epoch 12/43
107/107 [==============================] - 1s 8ms/step - loss: 0.6915 - val_loss: 0.6758
Epoch 13/43
107/107 [==============================] - 1s 8ms/step - loss: 0.6907 - val_loss: 0.6748
Epoch 14/43
107/107 [==============================] - 1s 8ms/step - loss: 0.6899 - val_loss: 0.6738
Epoch 15/43
107/107 [==============================] - 1s 8ms/step - loss: 0.6889 - val_loss: 0.6727
Epoch 16/43
107/107 [==============================] - 1s 8ms/step - loss: 0.6883 - val_loss: 0.6717
Epoch 17/43
107/107 [==============================] - 1s 8ms/step - loss: 0.6874 - val_loss: 0.6706
Epoch 18/43
107/107 [==============================] - 1s 8ms/step - loss: 0.6868 - val_loss: 0.6696
Epoch 19/43
107/107 [==============================] - 1s 8ms/step - loss: 0.6858 - val_loss: 0.6685
Epoch 20/43
107/107 [==============================] - 1s 8ms/step - loss: 0.6851 - val_loss: 0.6674
Epoch 21/43
107/107 [==============================] - 1s 8ms/step - loss: 0.6842 - val_loss: 0.6664
Epoch 22/43
107/107 [==============================] - 1s 8ms/step - loss: 0.6834 - val_loss: 0.6653
Epoch 23/43
107/107 [==============================] - 1s 8ms/step - loss: 0.6823 - val_loss: 0.6642
Epoch 24/43
107/107 [==============================] - 1s 8ms/step - loss: 0.6818 - val_loss: 0.6631
Epoch 25/43
107/107 [==============================] - 1s 8ms/step - loss: 0.6809 - val_loss: 0.6620
Epoch 26/43
107/107 [==============================] - 1s 8ms/step - loss: 0.6800 - val_loss: 0.6608
Epoch 27/43
107/107 [==============================] - 1s 8ms/step - loss: 0.6792 - val_loss: 0.6597
Epoch 28/43
107/107 [==============================] - 1s 8ms/step - loss: 0.6783 - val_loss: 0.6586
Epoch 29/43
107/107 [==============================] - 1s 8ms/step - loss: 0.6775 - val_loss: 0.6574
Epoch 30/43
107/107 [==============================] - 1s 8ms/step - loss: 0.6765 - val_loss: 0.6563
Epoch 31/43
107/107 [==============================] - 1s 8ms/step - loss: 0.6758 - val_loss: 0.6551
Epoch 32/43
107/107 [==============================] - 1s 8ms/step - loss: 0.6748 - val_loss: 0.6540
Epoch 33/43
107/107 [==============================] - 1s 8ms/step - loss: 0.6740 - val_loss: 0.6528
Epoch 34/43
107/107 [==============================] - 1s 8ms/step - loss: 0.6731 - val_loss: 0.6516
Epoch 35/43
107/107 [==============================] - 1s 8ms/step - loss: 0.6722 - val_loss: 0.6504
Epoch 36/43
107/107 [==============================] - 1s 8ms/step - loss: 0.6715 - val_loss: 0.6492
Epoch 37/43
107/107 [==============================] - 1s 8ms/step - loss: 0.6705 - val_loss: 0.6480
Epoch 38/43
107/107 [==============================] - 1s 8ms/step - loss: 0.6696 - val_loss: 0.6468
Epoch 39/43
107/107 [==============================] - 1s 8ms/step - loss: 0.6687 - val_loss: 0.6456
Epoch 40/43
107/107 [==============================] - 1s 8ms/step - loss: 0.6677 - val_loss: 0.6444
Epoch 41/43
107/107 [==============================] - 1s 8ms/step - loss: 0.6669 - val_loss: 0.6431
Epoch 42/43
107/107 [==============================] - 1s 8ms/step - loss: 0.6660 - val_loss: 0.6419
Epoch 43/43
107/107 [==============================] - 1s 8ms/step - loss: 0.6651 - val_loss: 0.6407
Execution time:  42.630512952804565
GRU:
Mean Absolute Error: 0.6572
Root Mean Square Error: 0.9417
Mean Square Error: 0.8868

Train RMSE: 0.942
Train MSE: 0.887
Train MAE: 0.657
###########################

MODEL:  GRU
sequence:  1h
units:  43
dropout1:  0.40519643149940265
dropout2:  0.3312343747027119
optimizer: adadelta
activationDense: sigmoid
epochs: 56
batchsize: 11
validation_split: 0.1
Model: &#34;sequential_90&#34;
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
gru_12 (GRU)                 (None, 6, 43)             5934      
_________________________________________________________________
dropout_180 (Dropout)        (None, 6, 43)             0         
_________________________________________________________________
gru_13 (GRU)                 (None, 6, 43)             11352     
_________________________________________________________________
dropout_181 (Dropout)        (None, 6, 43)             0         
_________________________________________________________________
time_distributed_90 (TimeDis (None, 6, 1)              44        
=================================================================
Total params: 17,330
Trainable params: 17,330
Non-trainable params: 0
_________________________________________________________________
Epoch 1/56
326/326 [==============================] - 2s 7ms/step - loss: 0.8897 - val_loss: 1.3045
Epoch 2/56
326/326 [==============================] - 1s 4ms/step - loss: 0.8892 - val_loss: 1.3036
Epoch 3/56
326/326 [==============================] - 1s 4ms/step - loss: 0.8887 - val_loss: 1.3028
Epoch 4/56
326/326 [==============================] - 1s 4ms/step - loss: 0.8883 - val_loss: 1.3019
Epoch 5/56
326/326 [==============================] - 1s 4ms/step - loss: 0.8877 - val_loss: 1.3010
Epoch 6/56
326/326 [==============================] - 1s 4ms/step - loss: 0.8872 - val_loss: 1.3001
Epoch 7/56
326/326 [==============================] - 1s 4ms/step - loss: 0.8867 - val_loss: 1.2992
Epoch 8/56
326/326 [==============================] - 1s 4ms/step - loss: 0.8861 - val_loss: 1.2982
Epoch 9/56
326/326 [==============================] - 1s 4ms/step - loss: 0.8855 - val_loss: 1.2972
Epoch 10/56
326/326 [==============================] - 1s 4ms/step - loss: 0.8850 - val_loss: 1.2962
Epoch 11/56
326/326 [==============================] - 1s 4ms/step - loss: 0.8844 - val_loss: 1.2951
Epoch 12/56
326/326 [==============================] - 1s 4ms/step - loss: 0.8838 - val_loss: 1.2940
Epoch 13/56
326/326 [==============================] - 1s 4ms/step - loss: 0.8832 - val_loss: 1.2930
Epoch 14/56
326/326 [==============================] - 1s 4ms/step - loss: 0.8826 - val_loss: 1.2919
Epoch 15/56
326/326 [==============================] - 1s 4ms/step - loss: 0.8820 - val_loss: 1.2907
Epoch 16/56
326/326 [==============================] - 1s 4ms/step - loss: 0.8813 - val_loss: 1.2896
Epoch 17/56
326/326 [==============================] - 1s 4ms/step - loss: 0.8806 - val_loss: 1.2884
Epoch 18/56
326/326 [==============================] - 1s 4ms/step - loss: 0.8800 - val_loss: 1.2872
Epoch 19/56
326/326 [==============================] - 1s 4ms/step - loss: 0.8793 - val_loss: 1.2860
Epoch 20/56
326/326 [==============================] - 1s 4ms/step - loss: 0.8787 - val_loss: 1.2848
Epoch 21/56
326/326 [==============================] - 1s 4ms/step - loss: 0.8780 - val_loss: 1.2836
Epoch 22/56
326/326 [==============================] - 1s 4ms/step - loss: 0.8772 - val_loss: 1.2823
Epoch 23/56
326/326 [==============================] - 1s 4ms/step - loss: 0.8765 - val_loss: 1.2810
Epoch 24/56
326/326 [==============================] - 1s 4ms/step - loss: 0.8757 - val_loss: 1.2797
Epoch 25/56
326/326 [==============================] - 1s 4ms/step - loss: 0.8750 - val_loss: 1.2784
Epoch 26/56
326/326 [==============================] - 1s 4ms/step - loss: 0.8743 - val_loss: 1.2770
Epoch 27/56
326/326 [==============================] - 1s 4ms/step - loss: 0.8736 - val_loss: 1.2756
Epoch 28/56
326/326 [==============================] - 1s 4ms/step - loss: 0.8728 - val_loss: 1.2742
Epoch 29/56
326/326 [==============================] - 1s 4ms/step - loss: 0.8720 - val_loss: 1.2728
Epoch 30/56
326/326 [==============================] - 1s 4ms/step - loss: 0.8712 - val_loss: 1.2714
Epoch 31/56
326/326 [==============================] - 1s 4ms/step - loss: 0.8704 - val_loss: 1.2699
Epoch 32/56
326/326 [==============================] - 1s 4ms/step - loss: 0.8695 - val_loss: 1.2684
Epoch 33/56
326/326 [==============================] - 1s 4ms/step - loss: 0.8687 - val_loss: 1.2669
Epoch 34/56
326/326 [==============================] - 1s 4ms/step - loss: 0.8678 - val_loss: 1.2654
Epoch 35/56
326/326 [==============================] - 1s 4ms/step - loss: 0.8670 - val_loss: 1.2638
Epoch 36/56
326/326 [==============================] - 1s 4ms/step - loss: 0.8661 - val_loss: 1.2622
Epoch 37/56
326/326 [==============================] - 1s 4ms/step - loss: 0.8652 - val_loss: 1.2606
Epoch 38/56
326/326 [==============================] - 1s 4ms/step - loss: 0.8643 - val_loss: 1.2590
Epoch 39/56
326/326 [==============================] - 1s 4ms/step - loss: 0.8634 - val_loss: 1.2573
Epoch 40/56
326/326 [==============================] - 1s 4ms/step - loss: 0.8624 - val_loss: 1.2556
Epoch 41/56
326/326 [==============================] - 1s 4ms/step - loss: 0.8613 - val_loss: 1.2539
Epoch 42/56
326/326 [==============================] - 1s 4ms/step - loss: 0.8604 - val_loss: 1.2521
Epoch 43/56
326/326 [==============================] - 1s 4ms/step - loss: 0.8594 - val_loss: 1.2503
Epoch 44/56
326/326 [==============================] - 1s 4ms/step - loss: 0.8585 - val_loss: 1.2485
Epoch 45/56
326/326 [==============================] - 1s 4ms/step - loss: 0.8574 - val_loss: 1.2467
Epoch 46/56
326/326 [==============================] - 1s 4ms/step - loss: 0.8564 - val_loss: 1.2448
Epoch 47/56
326/326 [==============================] - 1s 4ms/step - loss: 0.8553 - val_loss: 1.2429
Epoch 48/56
326/326 [==============================] - 1s 4ms/step - loss: 0.8542 - val_loss: 1.2410
Epoch 49/56
326/326 [==============================] - 1s 4ms/step - loss: 0.8531 - val_loss: 1.2390
Epoch 50/56
326/326 [==============================] - 1s 4ms/step - loss: 0.8519 - val_loss: 1.2370
Epoch 51/56
326/326 [==============================] - 1s 4ms/step - loss: 0.8508 - val_loss: 1.2350
Epoch 52/56
326/326 [==============================] - 1s 4ms/step - loss: 0.8496 - val_loss: 1.2329
Epoch 53/56
326/326 [==============================] - 1s 4ms/step - loss: 0.8487 - val_loss: 1.2309
Epoch 54/56
326/326 [==============================] - 1s 4ms/step - loss: 0.8474 - val_loss: 1.2287
Epoch 55/56
326/326 [==============================] - 1s 4ms/step - loss: 0.8462 - val_loss: 1.2266
Epoch 56/56
326/326 [==============================] - 1s 4ms/step - loss: 0.8449 - val_loss: 1.2244
Execution time:  80.19839143753052
GRU:
Mean Absolute Error: 0.8798
Root Mean Square Error: 1.0685
Mean Square Error: 1.1416

Train RMSE: 1.068
Train MSE: 1.142
Train MAE: 0.880
###########################

MODEL:  GRU
sequence:  1h
units:  45
dropout1:  0.11814836227952394
dropout2:  0.24325404382648977
optimizer: adadelta
activationDense: sigmoid
epochs: 43
batchsize: 30
validation_split: 0.2
Model: &#34;sequential_91&#34;
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
gru_14 (GRU)                 (None, 6, 45)             6480      
_________________________________________________________________
dropout_182 (Dropout)        (None, 6, 45)             0         
_________________________________________________________________
gru_15 (GRU)                 (None, 6, 45)             12420     
_________________________________________________________________
dropout_183 (Dropout)        (None, 6, 45)             0         
_________________________________________________________________
time_distributed_91 (TimeDis (None, 6, 1)              46        
=================================================================
Total params: 18,946
Trainable params: 18,946
Non-trainable params: 0
_________________________________________________________________
Epoch 1/43
107/107 [==============================] - 2s 16ms/step - loss: 0.8823 - val_loss: 1.1427
Epoch 2/43
107/107 [==============================] - 1s 8ms/step - loss: 0.8823 - val_loss: 1.1425
Epoch 3/43
107/107 [==============================] - 1s 8ms/step - loss: 0.8821 - val_loss: 1.1424
Epoch 4/43
107/107 [==============================] - 1s 8ms/step - loss: 0.8820 - val_loss: 1.1422
Epoch 5/43
107/107 [==============================] - 1s 8ms/step - loss: 0.8819 - val_loss: 1.1420
Epoch 6/43
107/107 [==============================] - 1s 8ms/step - loss: 0.8818 - val_loss: 1.1418
Epoch 7/43
107/107 [==============================] - 1s 8ms/step - loss: 0.8816 - val_loss: 1.1416
Epoch 8/43
107/107 [==============================] - 1s 8ms/step - loss: 0.8815 - val_loss: 1.1414
Epoch 9/43
107/107 [==============================] - 1s 8ms/step - loss: 0.8813 - val_loss: 1.1412
Epoch 10/43
107/107 [==============================] - 1s 8ms/step - loss: 0.8812 - val_loss: 1.1410
Epoch 11/43
107/107 [==============================] - 1s 8ms/step - loss: 0.8811 - val_loss: 1.1408
Epoch 12/43
107/107 [==============================] - 1s 8ms/step - loss: 0.8809 - val_loss: 1.1406
Epoch 13/43
107/107 [==============================] - 1s 8ms/step - loss: 0.8808 - val_loss: 1.1404
Epoch 14/43
107/107 [==============================] - 1s 8ms/step - loss: 0.8807 - val_loss: 1.1402
Epoch 15/43
107/107 [==============================] - 1s 8ms/step - loss: 0.8806 - val_loss: 1.1400
Epoch 16/43
107/107 [==============================] - 1s 8ms/step - loss: 0.8804 - val_loss: 1.1398
Epoch 17/43
107/107 [==============================] - 1s 8ms/step - loss: 0.8803 - val_loss: 1.1396
Epoch 18/43
107/107 [==============================] - 1s 8ms/step - loss: 0.8801 - val_loss: 1.1394
Epoch 19/43
107/107 [==============================] - 1s 8ms/step - loss: 0.8800 - val_loss: 1.1392
Epoch 20/43
107/107 [==============================] - 1s 8ms/step - loss: 0.8798 - val_loss: 1.1389
Epoch 21/43
107/107 [==============================] - 1s 8ms/step - loss: 0.8797 - val_loss: 1.1387
Epoch 22/43
107/107 [==============================] - 1s 8ms/step - loss: 0.8796 - val_loss: 1.1385
Epoch 23/43
107/107 [==============================] - 1s 8ms/step - loss: 0.8794 - val_loss: 1.1383
Epoch 24/43
107/107 [==============================] - 1s 8ms/step - loss: 0.8793 - val_loss: 1.1381
Epoch 25/43
107/107 [==============================] - 1s 9ms/step - loss: 0.8791 - val_loss: 1.1379
Epoch 26/43
107/107 [==============================] - 1s 8ms/step - loss: 0.8790 - val_loss: 1.1377
Epoch 27/43
107/107 [==============================] - 1s 8ms/step - loss: 0.8789 - val_loss: 1.1375
Epoch 28/43
107/107 [==============================] - 1s 8ms/step - loss: 0.8787 - val_loss: 1.1372
Epoch 29/43
107/107 [==============================] - 1s 8ms/step - loss: 0.8786 - val_loss: 1.1370
Epoch 30/43
107/107 [==============================] - 1s 8ms/step - loss: 0.8784 - val_loss: 1.1368
Epoch 31/43
107/107 [==============================] - 1s 8ms/step - loss: 0.8783 - val_loss: 1.1366
Epoch 32/43
107/107 [==============================] - 1s 8ms/step - loss: 0.8782 - val_loss: 1.1364
Epoch 33/43
107/107 [==============================] - 1s 8ms/step - loss: 0.8780 - val_loss: 1.1361
Epoch 34/43
107/107 [==============================] - 1s 8ms/step - loss: 0.8778 - val_loss: 1.1359
Epoch 35/43
107/107 [==============================] - 1s 8ms/step - loss: 0.8777 - val_loss: 1.1357
Epoch 36/43
107/107 [==============================] - 1s 8ms/step - loss: 0.8776 - val_loss: 1.1355
Epoch 37/43
107/107 [==============================] - 1s 8ms/step - loss: 0.8774 - val_loss: 1.1353
Epoch 38/43
107/107 [==============================] - 1s 8ms/step - loss: 0.8773 - val_loss: 1.1350
Epoch 39/43
107/107 [==============================] - 1s 8ms/step - loss: 0.8771 - val_loss: 1.1348
Epoch 40/43
107/107 [==============================] - 1s 8ms/step - loss: 0.8770 - val_loss: 1.1346
Epoch 41/43
107/107 [==============================] - 1s 8ms/step - loss: 0.8768 - val_loss: 1.1344
Epoch 42/43
107/107 [==============================] - 1s 8ms/step - loss: 0.8767 - val_loss: 1.1341
Epoch 43/43
107/107 [==============================] - 1s 8ms/step - loss: 0.8765 - val_loss: 1.1339
Execution time:  44.818156480789185
GRU:
Mean Absolute Error: 0.9267
Root Mean Square Error: 1.1143
Mean Square Error: 1.2416

Train RMSE: 1.114
Train MSE: 1.242
Train MAE: 0.927
###########################

MODEL:  GRU
sequence:  1h
units:  43
dropout1:  0.40519643149940265
dropout2:  0.3312343747027119
optimizer: adamax
activationDense: tanh
epochs: 56
batchsize: 11
validation_split: 0.1
Model: &#34;sequential_92&#34;
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
gru_16 (GRU)                 (None, 6, 43)             5934      
_________________________________________________________________
dropout_184 (Dropout)        (None, 6, 43)             0         
_________________________________________________________________
gru_17 (GRU)                 (None, 6, 43)             11352     
_________________________________________________________________
dropout_185 (Dropout)        (None, 6, 43)             0         
_________________________________________________________________
time_distributed_92 (TimeDis (None, 6, 1)              44        
=================================================================
Total params: 17,330
Trainable params: 17,330
Non-trainable params: 0
_________________________________________________________________
Epoch 1/56
326/326 [==============================] - 2s 7ms/step - loss: 0.4307 - val_loss: 0.2706
Epoch 2/56
326/326 [==============================] - 1s 4ms/step - loss: 0.3096 - val_loss: 0.1970
Epoch 3/56
326/326 [==============================] - 1s 4ms/step - loss: 0.2883 - val_loss: 0.1874
Epoch 4/56
326/326 [==============================] - 1s 4ms/step - loss: 0.2826 - val_loss: 0.1775
Epoch 5/56
326/326 [==============================] - 1s 4ms/step - loss: 0.2805 - val_loss: 0.1843
Epoch 6/56
326/326 [==============================] - 1s 4ms/step - loss: 0.2801 - val_loss: 0.1911
Epoch 7/56
326/326 [==============================] - 1s 4ms/step - loss: 0.2790 - val_loss: 0.1891
Epoch 8/56
326/326 [==============================] - 1s 5ms/step - loss: 0.2785 - val_loss: 0.1911
Epoch 9/56
326/326 [==============================] - 1s 4ms/step - loss: 0.2775 - val_loss: 0.1922
Epoch 10/56
326/326 [==============================] - 1s 4ms/step - loss: 0.2775 - val_loss: 0.1874
Epoch 11/56
326/326 [==============================] - 1s 4ms/step - loss: 0.2774 - val_loss: 0.1909
Epoch 12/56
326/326 [==============================] - 1s 4ms/step - loss: 0.2773 - val_loss: 0.1884
Epoch 13/56
326/326 [==============================] - 1s 4ms/step - loss: 0.2766 - val_loss: 0.1941
Epoch 14/56
326/326 [==============================] - 1s 4ms/step - loss: 0.2754 - val_loss: 0.1908
Epoch 15/56
326/326 [==============================] - 1s 4ms/step - loss: 0.2756 - val_loss: 0.1879
Epoch 16/56
326/326 [==============================] - 1s 4ms/step - loss: 0.2750 - val_loss: 0.1861
Epoch 17/56
326/326 [==============================] - 1s 4ms/step - loss: 0.2752 - val_loss: 0.1862
Epoch 18/56
326/326 [==============================] - 1s 4ms/step - loss: 0.2748 - val_loss: 0.1845
Epoch 19/56
326/326 [==============================] - 1s 4ms/step - loss: 0.2749 - val_loss: 0.1860
Epoch 20/56
326/326 [==============================] - 1s 5ms/step - loss: 0.2743 - val_loss: 0.1826
Epoch 21/56
326/326 [==============================] - 1s 4ms/step - loss: 0.2739 - val_loss: 0.1870
Epoch 22/56
326/326 [==============================] - 1s 4ms/step - loss: 0.2737 - val_loss: 0.1832
Epoch 23/56
326/326 [==============================] - 1s 4ms/step - loss: 0.2737 - val_loss: 0.1810
Epoch 24/56
326/326 [==============================] - 1s 4ms/step - loss: 0.2732 - val_loss: 0.1844
Epoch 25/56
326/326 [==============================] - 1s 4ms/step - loss: 0.2731 - val_loss: 0.1760
Epoch 26/56
326/326 [==============================] - 1s 4ms/step - loss: 0.2733 - val_loss: 0.1807
Epoch 27/56
326/326 [==============================] - 1s 4ms/step - loss: 0.2727 - val_loss: 0.1798
Epoch 28/56
326/326 [==============================] - 1s 4ms/step - loss: 0.2729 - val_loss: 0.1767
Epoch 29/56
326/326 [==============================] - 1s 4ms/step - loss: 0.2733 - val_loss: 0.1770
Epoch 30/56
326/326 [==============================] - 1s 4ms/step - loss: 0.2735 - val_loss: 0.1771
Epoch 31/56
326/326 [==============================] - 1s 4ms/step - loss: 0.2724 - val_loss: 0.1728
Epoch 32/56
326/326 [==============================] - 1s 4ms/step - loss: 0.2725 - val_loss: 0.1717
Epoch 33/56
326/326 [==============================] - 1s 4ms/step - loss: 0.2714 - val_loss: 0.1718
Epoch 34/56
326/326 [==============================] - 1s 4ms/step - loss: 0.2716 - val_loss: 0.1727
Epoch 35/56
326/326 [==============================] - 1s 4ms/step - loss: 0.2717 - val_loss: 0.1697
Epoch 36/56
326/326 [==============================] - 1s 4ms/step - loss: 0.2717 - val_loss: 0.1717
Epoch 37/56
326/326 [==============================] - 1s 4ms/step - loss: 0.2714 - val_loss: 0.1693
Epoch 38/56
326/326 [==============================] - 1s 4ms/step - loss: 0.2714 - val_loss: 0.1676
Epoch 39/56
326/326 [==============================] - 1s 4ms/step - loss: 0.2710 - val_loss: 0.1680
Epoch 40/56
326/326 [==============================] - 1s 4ms/step - loss: 0.2714 - val_loss: 0.1689
Epoch 41/56
326/326 [==============================] - 1s 4ms/step - loss: 0.2715 - val_loss: 0.1667
Epoch 42/56
326/326 [==============================] - 1s 4ms/step - loss: 0.2709 - val_loss: 0.1703
Epoch 43/56
326/326 [==============================] - 1s 5ms/step - loss: 0.2704 - val_loss: 0.1647
Epoch 44/56
326/326 [==============================] - 1s 4ms/step - loss: 0.2703 - val_loss: 0.1656
Epoch 45/56
326/326 [==============================] - 1s 4ms/step - loss: 0.2700 - val_loss: 0.1622
Epoch 46/56
326/326 [==============================] - 1s 4ms/step - loss: 0.2703 - val_loss: 0.1675
Epoch 47/56
326/326 [==============================] - 1s 4ms/step - loss: 0.2699 - val_loss: 0.1627
Epoch 48/56
326/326 [==============================] - 1s 4ms/step - loss: 0.2696 - val_loss: 0.1651
Epoch 49/56
326/326 [==============================] - 1s 4ms/step - loss: 0.2689 - val_loss: 0.1637
Epoch 50/56
326/326 [==============================] - 1s 4ms/step - loss: 0.2694 - val_loss: 0.1615
Epoch 51/56
326/326 [==============================] - 1s 4ms/step - loss: 0.2684 - val_loss: 0.1632
Epoch 52/56
326/326 [==============================] - 1s 4ms/step - loss: 0.2692 - val_loss: 0.1589
Epoch 53/56
326/326 [==============================] - 1s 4ms/step - loss: 0.2686 - val_loss: 0.1583
Epoch 54/56
326/326 [==============================] - 1s 4ms/step - loss: 0.2688 - val_loss: 0.1606
Epoch 55/56
326/326 [==============================] - 1s 4ms/step - loss: 0.2684 - val_loss: 0.1609
Epoch 56/56
326/326 [==============================] - 1s 4ms/step - loss: 0.2679 - val_loss: 0.1587
Execution time:  81.51253342628479
GRU:
Mean Absolute Error: 0.1761
Root Mean Square Error: 0.5767
Mean Square Error: 0.3326

Train RMSE: 0.577
Train MSE: 0.333
Train MAE: 0.176
###########################

MODEL:  GRU
sequence:  1h
units:  45
dropout1:  0.11814836227952394
dropout2:  0.24325404382648977
optimizer: adamax
activationDense: tanh
epochs: 43
batchsize: 30
validation_split: 0.2
Model: &#34;sequential_93&#34;
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
gru_18 (GRU)                 (None, 6, 45)             6480      
_________________________________________________________________
dropout_186 (Dropout)        (None, 6, 45)             0         
_________________________________________________________________
gru_19 (GRU)                 (None, 6, 45)             12420     
_________________________________________________________________
dropout_187 (Dropout)        (None, 6, 45)             0         
_________________________________________________________________
time_distributed_93 (TimeDis (None, 6, 1)              46        
=================================================================
Total params: 18,946
Trainable params: 18,946
Non-trainable params: 0
_________________________________________________________________
Epoch 1/43
107/107 [==============================] - 2s 16ms/step - loss: 0.5053 - val_loss: 0.3227
Epoch 2/43
107/107 [==============================] - 1s 8ms/step - loss: 0.3511 - val_loss: 0.2736
Epoch 3/43
107/107 [==============================] - 1s 8ms/step - loss: 0.3126 - val_loss: 0.2395
Epoch 4/43
107/107 [==============================] - 1s 8ms/step - loss: 0.2944 - val_loss: 0.2265
Epoch 5/43
107/107 [==============================] - 1s 8ms/step - loss: 0.2858 - val_loss: 0.2182
Epoch 6/43
107/107 [==============================] - 1s 8ms/step - loss: 0.2793 - val_loss: 0.2130
Epoch 7/43
107/107 [==============================] - 1s 8ms/step - loss: 0.2762 - val_loss: 0.2117
Epoch 8/43
107/107 [==============================] - 1s 9ms/step - loss: 0.2738 - val_loss: 0.2110
Epoch 9/43
107/107 [==============================] - 1s 8ms/step - loss: 0.2733 - val_loss: 0.2112
Epoch 10/43
107/107 [==============================] - 1s 8ms/step - loss: 0.2724 - val_loss: 0.2112
Epoch 11/43
107/107 [==============================] - 1s 8ms/step - loss: 0.2729 - val_loss: 0.2115
Epoch 12/43
107/107 [==============================] - 1s 8ms/step - loss: 0.2726 - val_loss: 0.2115
Epoch 13/43
107/107 [==============================] - 1s 8ms/step - loss: 0.2721 - val_loss: 0.2115
Epoch 14/43
107/107 [==============================] - 1s 8ms/step - loss: 0.2724 - val_loss: 0.2114
Epoch 15/43
107/107 [==============================] - 1s 8ms/step - loss: 0.2715 - val_loss: 0.2116
Epoch 16/43
107/107 [==============================] - 1s 8ms/step - loss: 0.2713 - val_loss: 0.2118
Epoch 17/43
107/107 [==============================] - 1s 8ms/step - loss: 0.2711 - val_loss: 0.2116
Epoch 18/43
107/107 [==============================] - 1s 8ms/step - loss: 0.2706 - val_loss: 0.2113
Epoch 19/43
107/107 [==============================] - 1s 8ms/step - loss: 0.2706 - val_loss: 0.2109
Epoch 20/43
107/107 [==============================] - 1s 8ms/step - loss: 0.2711 - val_loss: 0.2106
Epoch 21/43
107/107 [==============================] - 1s 8ms/step - loss: 0.2703 - val_loss: 0.2109
Epoch 22/43
107/107 [==============================] - 1s 8ms/step - loss: 0.2705 - val_loss: 0.2107
Epoch 23/43
107/107 [==============================] - 1s 8ms/step - loss: 0.2707 - val_loss: 0.2107
Epoch 24/43
107/107 [==============================] - 1s 8ms/step - loss: 0.2704 - val_loss: 0.2102
Epoch 25/43
107/107 [==============================] - 1s 8ms/step - loss: 0.2703 - val_loss: 0.2100
Epoch 26/43
107/107 [==============================] - 1s 8ms/step - loss: 0.2698 - val_loss: 0.2098
Epoch 27/43
107/107 [==============================] - 1s 9ms/step - loss: 0.2699 - val_loss: 0.2098
Epoch 28/43
107/107 [==============================] - 1s 8ms/step - loss: 0.2699 - val_loss: 0.2097
Epoch 29/43
107/107 [==============================] - 1s 8ms/step - loss: 0.2699 - val_loss: 0.2093
Epoch 30/43
107/107 [==============================] - 1s 8ms/step - loss: 0.2694 - val_loss: 0.2091
Epoch 31/43
107/107 [==============================] - 1s 8ms/step - loss: 0.2692 - val_loss: 0.2088
Epoch 32/43
107/107 [==============================] - 1s 8ms/step - loss: 0.2692 - val_loss: 0.2084
Epoch 33/43
107/107 [==============================] - 1s 8ms/step - loss: 0.2687 - val_loss: 0.2085
Epoch 34/43
107/107 [==============================] - 1s 8ms/step - loss: 0.2687 - val_loss: 0.2077
Epoch 35/43
107/107 [==============================] - 1s 8ms/step - loss: 0.2686 - val_loss: 0.2080
Epoch 36/43
107/107 [==============================] - 1s 8ms/step - loss: 0.2691 - val_loss: 0.2078
Epoch 37/43
107/107 [==============================] - 1s 8ms/step - loss: 0.2684 - val_loss: 0.2077
Epoch 38/43
107/107 [==============================] - 1s 8ms/step - loss: 0.2688 - val_loss: 0.2073
Epoch 39/43
107/107 [==============================] - 1s 8ms/step - loss: 0.2688 - val_loss: 0.2071
Epoch 40/43
107/107 [==============================] - 1s 8ms/step - loss: 0.2687 - val_loss: 0.2076
Epoch 41/43
107/107 [==============================] - 1s 8ms/step - loss: 0.2684 - val_loss: 0.2066
Epoch 42/43
107/107 [==============================] - 1s 8ms/step - loss: 0.2682 - val_loss: 0.2069
Epoch 43/43
107/107 [==============================] - 1s 8ms/step - loss: 0.2680 - val_loss: 0.2063
Execution time:  42.36288595199585
GRU:
Mean Absolute Error: 0.1638
Root Mean Square Error: 0.5750
Mean Square Error: 0.3306

Train RMSE: 0.575
Train MSE: 0.331
Train MAE: 0.164
###########################

MODEL:  GRU
sequence:  1h
units:  43
dropout1:  0.40519643149940265
dropout2:  0.3312343747027119
optimizer: adamax
activationDense: sigmoid
epochs: 56
batchsize: 11
validation_split: 0.1
Model: &#34;sequential_94&#34;
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
gru_20 (GRU)                 (None, 6, 43)             5934      
_________________________________________________________________
dropout_188 (Dropout)        (None, 6, 43)             0         
_________________________________________________________________
gru_21 (GRU)                 (None, 6, 43)             11352     
_________________________________________________________________
dropout_189 (Dropout)        (None, 6, 43)             0         
_________________________________________________________________
time_distributed_94 (TimeDis (None, 6, 1)              44        
=================================================================
Total params: 17,330
Trainable params: 17,330
Non-trainable params: 0
_________________________________________________________________
Epoch 1/56
326/326 [==============================] - 2s 7ms/step - loss: 0.6643 - val_loss: 0.8404
Epoch 2/56
326/326 [==============================] - 1s 4ms/step - loss: 0.5384 - val_loss: 0.8157
Epoch 3/56
326/326 [==============================] - 1s 4ms/step - loss: 0.5248 - val_loss: 0.8096
Epoch 4/56
326/326 [==============================] - 1s 4ms/step - loss: 0.5186 - val_loss: 0.8077
Epoch 5/56
326/326 [==============================] - 1s 4ms/step - loss: 0.5129 - val_loss: 0.8070
Epoch 6/56
326/326 [==============================] - 1s 4ms/step - loss: 0.5072 - val_loss: 0.8066
Epoch 7/56
326/326 [==============================] - 1s 4ms/step - loss: 0.5039 - val_loss: 0.8064
Epoch 8/56
326/326 [==============================] - 1s 4ms/step - loss: 0.5022 - val_loss: 0.8063
Epoch 9/56
326/326 [==============================] - 1s 4ms/step - loss: 0.5016 - val_loss: 0.8062
Epoch 10/56
326/326 [==============================] - 1s 4ms/step - loss: 0.5016 - val_loss: 0.8061
Epoch 11/56
326/326 [==============================] - 1s 4ms/step - loss: 0.5010 - val_loss: 0.8061
Epoch 12/56
326/326 [==============================] - 1s 4ms/step - loss: 0.5013 - val_loss: 0.8061
Epoch 13/56
326/326 [==============================] - 1s 4ms/step - loss: 0.5011 - val_loss: 0.8061
Epoch 14/56
326/326 [==============================] - 1s 4ms/step - loss: 0.5008 - val_loss: 0.8060
Epoch 15/56
326/326 [==============================] - 1s 4ms/step - loss: 0.5009 - val_loss: 0.8060
Epoch 16/56
326/326 [==============================] - 1s 4ms/step - loss: 0.5008 - val_loss: 0.8060
Epoch 17/56
326/326 [==============================] - 1s 4ms/step - loss: 0.5007 - val_loss: 0.8060
Epoch 18/56
326/326 [==============================] - 1s 4ms/step - loss: 0.5007 - val_loss: 0.8060
Epoch 19/56
326/326 [==============================] - 1s 4ms/step - loss: 0.5007 - val_loss: 0.8060
Epoch 20/56
326/326 [==============================] - 1s 4ms/step - loss: 0.5007 - val_loss: 0.8060
Epoch 21/56
326/326 [==============================] - 1s 4ms/step - loss: 0.5006 - val_loss: 0.8060
Epoch 22/56
326/326 [==============================] - 1s 4ms/step - loss: 0.5005 - val_loss: 0.8060
Epoch 23/56
326/326 [==============================] - 1s 4ms/step - loss: 0.5003 - val_loss: 0.8060
Epoch 24/56
326/326 [==============================] - 1s 4ms/step - loss: 0.5006 - val_loss: 0.8060
Epoch 25/56
326/326 [==============================] - 1s 4ms/step - loss: 0.5004 - val_loss: 0.8060
Epoch 26/56
326/326 [==============================] - 1s 4ms/step - loss: 0.5005 - val_loss: 0.8060
Epoch 27/56
326/326 [==============================] - 1s 4ms/step - loss: 0.5003 - val_loss: 0.8060
Epoch 28/56
326/326 [==============================] - 1s 4ms/step - loss: 0.5005 - val_loss: 0.8060
Epoch 29/56
326/326 [==============================] - 1s 4ms/step - loss: 0.5006 - val_loss: 0.8060
Epoch 30/56
326/326 [==============================] - 1s 4ms/step - loss: 0.5006 - val_loss: 0.8060
Epoch 31/56
326/326 [==============================] - 1s 4ms/step - loss: 0.5004 - val_loss: 0.8060
Epoch 32/56
326/326 [==============================] - 1s 4ms/step - loss: 0.5001 - val_loss: 0.8060
Epoch 33/56
326/326 [==============================] - 1s 5ms/step - loss: 0.5003 - val_loss: 0.8060
Epoch 34/56
326/326 [==============================] - 1s 4ms/step - loss: 0.4999 - val_loss: 0.8060
Epoch 35/56
326/326 [==============================] - 1s 4ms/step - loss: 0.5001 - val_loss: 0.8060
Epoch 36/56
326/326 [==============================] - 1s 4ms/step - loss: 0.5000 - val_loss: 0.8060
Epoch 37/56
326/326 [==============================] - 1s 4ms/step - loss: 0.5001 - val_loss: 0.8060
Epoch 38/56
326/326 [==============================] - 1s 4ms/step - loss: 0.5003 - val_loss: 0.8060
Epoch 39/56
326/326 [==============================] - 1s 4ms/step - loss: 0.4999 - val_loss: 0.8060
Epoch 40/56
326/326 [==============================] - 1s 4ms/step - loss: 0.5002 - val_loss: 0.8060
Epoch 41/56
326/326 [==============================] - 1s 4ms/step - loss: 0.5003 - val_loss: 0.8060
Epoch 42/56
326/326 [==============================] - 1s 4ms/step - loss: 0.5001 - val_loss: 0.8060
Epoch 43/56
326/326 [==============================] - 1s 4ms/step - loss: 0.5002 - val_loss: 0.8060
Epoch 44/56
326/326 [==============================] - 1s 4ms/step - loss: 0.5002 - val_loss: 0.8060
Epoch 45/56
326/326 [==============================] - 1s 5ms/step - loss: 0.4999 - val_loss: 0.8060
Epoch 46/56
326/326 [==============================] - 1s 4ms/step - loss: 0.4999 - val_loss: 0.8060
Epoch 47/56
326/326 [==============================] - 1s 4ms/step - loss: 0.4999 - val_loss: 0.8060
Epoch 48/56
326/326 [==============================] - 1s 4ms/step - loss: 0.4999 - val_loss: 0.8060
Epoch 49/56
326/326 [==============================] - 1s 4ms/step - loss: 0.4999 - val_loss: 0.8060
Epoch 50/56
326/326 [==============================] - 1s 4ms/step - loss: 0.4998 - val_loss: 0.8060
Epoch 51/56
326/326 [==============================] - 1s 4ms/step - loss: 0.4997 - val_loss: 0.8060
Epoch 52/56
326/326 [==============================] - 1s 4ms/step - loss: 0.4999 - val_loss: 0.8060
Epoch 53/56
326/326 [==============================] - 1s 4ms/step - loss: 0.4996 - val_loss: 0.8060
Epoch 54/56
326/326 [==============================] - 1s 4ms/step - loss: 0.4998 - val_loss: 0.8060
Epoch 55/56
326/326 [==============================] - 1s 4ms/step - loss: 0.4998 - val_loss: 0.8060
Epoch 56/56
326/326 [==============================] - 1s 5ms/step - loss: 0.4995 - val_loss: 0.8060
Execution time:  81.205246925354
GRU:
Mean Absolute Error: 0.4932
Root Mean Square Error: 0.7504
Mean Square Error: 0.5631

Train RMSE: 0.750
Train MSE: 0.563
Train MAE: 0.493
###########################

MODEL:  GRU
sequence:  1h
units:  45
dropout1:  0.11814836227952394
dropout2:  0.24325404382648977
optimizer: adamax
activationDense: sigmoid
epochs: 43
batchsize: 30
validation_split: 0.2
Model: &#34;sequential_95&#34;
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
gru_22 (GRU)                 (None, 6, 45)             6480      
_________________________________________________________________
dropout_190 (Dropout)        (None, 6, 45)             0         
_________________________________________________________________
gru_23 (GRU)                 (None, 6, 45)             12420     
_________________________________________________________________
dropout_191 (Dropout)        (None, 6, 45)             0         
_________________________________________________________________
time_distributed_95 (TimeDis (None, 6, 1)              46        
=================================================================
Total params: 18,946
Trainable params: 18,946
Non-trainable params: 0
_________________________________________________________________
Epoch 1/43
107/107 [==============================] - 2s 16ms/step - loss: 0.8027 - val_loss: 0.8321
Epoch 2/43
107/107 [==============================] - 1s 8ms/step - loss: 0.5870 - val_loss: 0.7217
Epoch 3/43
107/107 [==============================] - 1s 8ms/step - loss: 0.5517 - val_loss: 0.6978
Epoch 4/43
107/107 [==============================] - 1s 8ms/step - loss: 0.5381 - val_loss: 0.6854
Epoch 5/43
107/107 [==============================] - 1s 8ms/step - loss: 0.5295 - val_loss: 0.6780
Epoch 6/43
107/107 [==============================] - 1s 8ms/step - loss: 0.5233 - val_loss: 0.6733
Epoch 7/43
107/107 [==============================] - 1s 8ms/step - loss: 0.5183 - val_loss: 0.6701
Epoch 8/43
107/107 [==============================] - 1s 8ms/step - loss: 0.5134 - val_loss: 0.6676
Epoch 9/43
107/107 [==============================] - 1s 8ms/step - loss: 0.5085 - val_loss: 0.6663
Epoch 10/43
107/107 [==============================] - 1s 8ms/step - loss: 0.5044 - val_loss: 0.6652
Epoch 11/43
107/107 [==============================] - 1s 8ms/step - loss: 0.5023 - val_loss: 0.6644
Epoch 12/43
107/107 [==============================] - 1s 8ms/step - loss: 0.5005 - val_loss: 0.6638
Epoch 13/43
107/107 [==============================] - 1s 8ms/step - loss: 0.4996 - val_loss: 0.6634
Epoch 14/43
107/107 [==============================] - 1s 8ms/step - loss: 0.4990 - val_loss: 0.6630
Epoch 15/43
107/107 [==============================] - 1s 8ms/step - loss: 0.4990 - val_loss: 0.6628
Epoch 16/43
107/107 [==============================] - 1s 8ms/step - loss: 0.4986 - val_loss: 0.6627
Epoch 17/43
107/107 [==============================] - 1s 8ms/step - loss: 0.4984 - val_loss: 0.6627
Epoch 18/43
107/107 [==============================] - 1s 8ms/step - loss: 0.4983 - val_loss: 0.6625
Epoch 19/43
107/107 [==============================] - 1s 8ms/step - loss: 0.4981 - val_loss: 0.6624
Epoch 20/43
107/107 [==============================] - 1s 8ms/step - loss: 0.4982 - val_loss: 0.6624
Epoch 21/43
107/107 [==============================] - 1s 8ms/step - loss: 0.4979 - val_loss: 0.6623
Epoch 22/43
107/107 [==============================] - 1s 8ms/step - loss: 0.4978 - val_loss: 0.6624
Epoch 23/43
107/107 [==============================] - 1s 8ms/step - loss: 0.4980 - val_loss: 0.6623
Epoch 24/43
107/107 [==============================] - 1s 8ms/step - loss: 0.4979 - val_loss: 0.6622
Epoch 25/43
107/107 [==============================] - 1s 8ms/step - loss: 0.4977 - val_loss: 0.6622
Epoch 26/43
107/107 [==============================] - 1s 8ms/step - loss: 0.4977 - val_loss: 0.6622
Epoch 27/43
107/107 [==============================] - 1s 9ms/step - loss: 0.4976 - val_loss: 0.6622
Epoch 28/43
107/107 [==============================] - 1s 8ms/step - loss: 0.4978 - val_loss: 0.6622
Epoch 29/43
107/107 [==============================] - 1s 8ms/step - loss: 0.4977 - val_loss: 0.6623
Epoch 30/43
107/107 [==============================] - 1s 8ms/step - loss: 0.4975 - val_loss: 0.6622
Epoch 31/43
107/107 [==============================] - 1s 8ms/step - loss: 0.4975 - val_loss: 0.6622
Epoch 32/43
107/107 [==============================] - 1s 8ms/step - loss: 0.4976 - val_loss: 0.6621
Epoch 33/43
107/107 [==============================] - 1s 8ms/step - loss: 0.4974 - val_loss: 0.6621
Epoch 34/43
107/107 [==============================] - 1s 8ms/step - loss: 0.4972 - val_loss: 0.6621
Epoch 35/43
107/107 [==============================] - 1s 8ms/step - loss: 0.4973 - val_loss: 0.6621
Epoch 36/43
107/107 [==============================] - 1s 8ms/step - loss: 0.4974 - val_loss: 0.6622
Epoch 37/43
107/107 [==============================] - 1s 8ms/step - loss: 0.4973 - val_loss: 0.6621
Epoch 38/43
107/107 [==============================] - 1s 8ms/step - loss: 0.4972 - val_loss: 0.6622
Epoch 39/43
107/107 [==============================] - 1s 8ms/step - loss: 0.4972 - val_loss: 0.6621
Epoch 40/43
107/107 [==============================] - 1s 8ms/step - loss: 0.4971 - val_loss: 0.6621
Epoch 41/43
107/107 [==============================] - 1s 8ms/step - loss: 0.4971 - val_loss: 0.6621
Epoch 42/43
107/107 [==============================] - 1s 8ms/step - loss: 0.4972 - val_loss: 0.6622
Epoch 43/43
107/107 [==============================] - 1s 8ms/step - loss: 0.4973 - val_loss: 0.6622
Execution time:  44.59614324569702
GRU:
Mean Absolute Error: 0.4928
Root Mean Square Error: 0.7502
Mean Square Error: 0.5627

Train RMSE: 0.750
Train MSE: 0.563
Train MAE: 0.493
###########################

MODEL:  GRU
sequence:  3h
units:  43
dropout1:  0.40519643149940265
dropout2:  0.3312343747027119
optimizer: adam
activationDense: tanh
epochs: 56
batchsize: 11
validation_split: 0.1
Model: &#34;sequential_96&#34;
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
gru_24 (GRU)                 (None, 18, 43)            5934      
_________________________________________________________________
dropout_192 (Dropout)        (None, 18, 43)            0         
_________________________________________________________________
gru_25 (GRU)                 (None, 18, 43)            11352     
_________________________________________________________________
dropout_193 (Dropout)        (None, 18, 43)            0         
_________________________________________________________________
time_distributed_96 (TimeDis (None, 18, 1)             44        
=================================================================
Total params: 17,330
Trainable params: 17,330
Non-trainable params: 0
_________________________________________________________________
Epoch 1/56
325/325 [==============================] - 4s 11ms/step - loss: 0.4178 - val_loss: 0.2499
Epoch 2/56
325/325 [==============================] - 3s 8ms/step - loss: 0.3618 - val_loss: 0.2365
Epoch 3/56
325/325 [==============================] - 3s 8ms/step - loss: 0.3530 - val_loss: 0.2373
Epoch 4/56
325/325 [==============================] - 3s 8ms/step - loss: 0.3495 - val_loss: 0.2446
Epoch 5/56
325/325 [==============================] - 3s 9ms/step - loss: 0.3482 - val_loss: 0.2438
Epoch 6/56
325/325 [==============================] - 3s 8ms/step - loss: 0.3472 - val_loss: 0.2446
Epoch 7/56
325/325 [==============================] - 3s 8ms/step - loss: 0.3462 - val_loss: 0.2407
Epoch 8/56
325/325 [==============================] - 3s 8ms/step - loss: 0.3460 - val_loss: 0.2377
Epoch 9/56
325/325 [==============================] - 3s 8ms/step - loss: 0.3454 - val_loss: 0.2378
Epoch 10/56
325/325 [==============================] - 3s 9ms/step - loss: 0.3448 - val_loss: 0.2324
Epoch 11/56
325/325 [==============================] - 3s 9ms/step - loss: 0.3437 - val_loss: 0.2324
Epoch 12/56
325/325 [==============================] - 3s 8ms/step - loss: 0.3440 - val_loss: 0.2336
Epoch 13/56
325/325 [==============================] - 3s 8ms/step - loss: 0.3429 - val_loss: 0.2326
Epoch 14/56
325/325 [==============================] - 3s 8ms/step - loss: 0.3432 - val_loss: 0.2245
Epoch 15/56
325/325 [==============================] - 3s 8ms/step - loss: 0.3427 - val_loss: 0.2265
Epoch 16/56
325/325 [==============================] - 3s 8ms/step - loss: 0.3415 - val_loss: 0.2213
Epoch 17/56
325/325 [==============================] - 3s 9ms/step - loss: 0.3411 - val_loss: 0.2161
Epoch 18/56
325/325 [==============================] - 3s 8ms/step - loss: 0.3411 - val_loss: 0.2161
Epoch 19/56
325/325 [==============================] - 3s 8ms/step - loss: 0.3403 - val_loss: 0.2117
Epoch 20/56
325/325 [==============================] - 3s 8ms/step - loss: 0.3396 - val_loss: 0.2071
Epoch 21/56
325/325 [==============================] - 3s 8ms/step - loss: 0.3390 - val_loss: 0.2042
Epoch 22/56
325/325 [==============================] - 3s 9ms/step - loss: 0.3380 - val_loss: 0.2019
Epoch 23/56
325/325 [==============================] - 3s 9ms/step - loss: 0.3381 - val_loss: 0.2013
Epoch 24/56
325/325 [==============================] - 3s 8ms/step - loss: 0.3376 - val_loss: 0.1984
Epoch 25/56
325/325 [==============================] - 3s 8ms/step - loss: 0.3372 - val_loss: 0.1945
Epoch 26/56
325/325 [==============================] - 3s 8ms/step - loss: 0.3374 - val_loss: 0.1954
Epoch 27/56
325/325 [==============================] - 3s 8ms/step - loss: 0.3371 - val_loss: 0.1937
Epoch 28/56
325/325 [==============================] - 3s 9ms/step - loss: 0.3362 - val_loss: 0.1919
Epoch 29/56
325/325 [==============================] - 3s 8ms/step - loss: 0.3362 - val_loss: 0.1914
Epoch 30/56
325/325 [==============================] - 3s 8ms/step - loss: 0.3360 - val_loss: 0.1864
Epoch 31/56
325/325 [==============================] - 3s 8ms/step - loss: 0.3354 - val_loss: 0.1847
Epoch 32/56
325/325 [==============================] - 3s 8ms/step - loss: 0.3347 - val_loss: 0.1819
Epoch 33/56
325/325 [==============================] - 3s 8ms/step - loss: 0.3348 - val_loss: 0.1820
Epoch 34/56
325/325 [==============================] - 3s 9ms/step - loss: 0.3349 - val_loss: 0.1798
Epoch 35/56
325/325 [==============================] - 3s 8ms/step - loss: 0.3351 - val_loss: 0.1788
Epoch 36/56
325/325 [==============================] - 3s 8ms/step - loss: 0.3342 - val_loss: 0.1764
Epoch 37/56
325/325 [==============================] - 3s 8ms/step - loss: 0.3342 - val_loss: 0.1751
Epoch 38/56
325/325 [==============================] - 3s 8ms/step - loss: 0.3340 - val_loss: 0.1713
Epoch 39/56
325/325 [==============================] - 3s 8ms/step - loss: 0.3332 - val_loss: 0.1690
Epoch 40/56
325/325 [==============================] - 3s 9ms/step - loss: 0.3327 - val_loss: 0.1672
Epoch 41/56
325/325 [==============================] - 3s 8ms/step - loss: 0.3327 - val_loss: 0.1655
Epoch 42/56
325/325 [==============================] - 3s 8ms/step - loss: 0.3330 - val_loss: 0.1636
Epoch 43/56
325/325 [==============================] - 3s 8ms/step - loss: 0.3321 - val_loss: 0.1609
Epoch 44/56
325/325 [==============================] - 3s 8ms/step - loss: 0.3325 - val_loss: 0.1576
Epoch 45/56
325/325 [==============================] - 3s 8ms/step - loss: 0.3316 - val_loss: 0.1549
Epoch 46/56
325/325 [==============================] - 3s 9ms/step - loss: 0.3317 - val_loss: 0.1555
Epoch 47/56
325/325 [==============================] - 3s 8ms/step - loss: 0.3315 - val_loss: 0.1531
Epoch 48/56
325/325 [==============================] - 3s 8ms/step - loss: 0.3310 - val_loss: 0.1524
Epoch 49/56
325/325 [==============================] - 3s 8ms/step - loss: 0.3308 - val_loss: 0.1473
Epoch 50/56
325/325 [==============================] - 3s 8ms/step - loss: 0.3308 - val_loss: 0.1503
Epoch 51/56
325/325 [==============================] - 3s 8ms/step - loss: 0.3303 - val_loss: 0.1437
Epoch 52/56
325/325 [==============================] - 3s 9ms/step - loss: 0.3302 - val_loss: 0.1438
Epoch 53/56
325/325 [==============================] - 3s 8ms/step - loss: 0.3296 - val_loss: 0.1430
Epoch 54/56
325/325 [==============================] - 3s 8ms/step - loss: 0.3290 - val_loss: 0.1384
Epoch 55/56
325/325 [==============================] - 3s 8ms/step - loss: 0.3292 - val_loss: 0.1385
Epoch 56/56
325/325 [==============================] - 3s 8ms/step - loss: 0.3289 - val_loss: 0.1374
Execution time:  157.61947011947632
GRU:
Mean Absolute Error: 0.1921
Root Mean Square Error: 0.6040
Mean Square Error: 0.3648

Train RMSE: 0.604
Train MSE: 0.365
Train MAE: 0.192
###########################

MODEL:  GRU
sequence:  3h
units:  45
dropout1:  0.11814836227952394
dropout2:  0.24325404382648977
optimizer: adam
activationDense: tanh
epochs: 43
batchsize: 30
validation_split: 0.2
Model: &#34;sequential_97&#34;
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
gru_26 (GRU)                 (None, 18, 45)            6480      
_________________________________________________________________
dropout_194 (Dropout)        (None, 18, 45)            0         
_________________________________________________________________
gru_27 (GRU)                 (None, 18, 45)            12420     
_________________________________________________________________
dropout_195 (Dropout)        (None, 18, 45)            0         
_________________________________________________________________
time_distributed_97 (TimeDis (None, 18, 1)             46        
=================================================================
Total params: 18,946
Trainable params: 18,946
Non-trainable params: 0
_________________________________________________________________
Epoch 1/43
106/106 [==============================] - 3s 25ms/step - loss: 0.4674 - val_loss: 0.2937
Epoch 2/43
106/106 [==============================] - 2s 17ms/step - loss: 0.3695 - val_loss: 0.2766
Epoch 3/43
106/106 [==============================] - 2s 17ms/step - loss: 0.3559 - val_loss: 0.2687
Epoch 4/43
106/106 [==============================] - 2s 17ms/step - loss: 0.3486 - val_loss: 0.2619
Epoch 5/43
106/106 [==============================] - 2s 17ms/step - loss: 0.3442 - val_loss: 0.2592
Epoch 6/43
106/106 [==============================] - 2s 16ms/step - loss: 0.3413 - val_loss: 0.2577
Epoch 7/43
106/106 [==============================] - 2s 18ms/step - loss: 0.3403 - val_loss: 0.2564
Epoch 8/43
106/106 [==============================] - 2s 17ms/step - loss: 0.3398 - val_loss: 0.2562
Epoch 9/43
106/106 [==============================] - 2s 16ms/step - loss: 0.3386 - val_loss: 0.2561
Epoch 10/43
106/106 [==============================] - 2s 16ms/step - loss: 0.3387 - val_loss: 0.2560
Epoch 11/43
106/106 [==============================] - 2s 17ms/step - loss: 0.3379 - val_loss: 0.2563
Epoch 12/43
106/106 [==============================] - 2s 16ms/step - loss: 0.3377 - val_loss: 0.2558
Epoch 13/43
106/106 [==============================] - 2s 16ms/step - loss: 0.3376 - val_loss: 0.2559
Epoch 14/43
106/106 [==============================] - 2s 16ms/step - loss: 0.3369 - val_loss: 0.2561
Epoch 15/43
106/106 [==============================] - 2s 16ms/step - loss: 0.3367 - val_loss: 0.2556
Epoch 16/43
106/106 [==============================] - 2s 17ms/step - loss: 0.3372 - val_loss: 0.2556
Epoch 17/43
106/106 [==============================] - 2s 16ms/step - loss: 0.3366 - val_loss: 0.2558
Epoch 18/43
106/106 [==============================] - 2s 16ms/step - loss: 0.3366 - val_loss: 0.2551
Epoch 19/43
106/106 [==============================] - 2s 16ms/step - loss: 0.3360 - val_loss: 0.2554
Epoch 20/43
106/106 [==============================] - 2s 16ms/step - loss: 0.3353 - val_loss: 0.2546
Epoch 21/43
106/106 [==============================] - 2s 16ms/step - loss: 0.3350 - val_loss: 0.2543
Epoch 22/43
106/106 [==============================] - 2s 16ms/step - loss: 0.3350 - val_loss: 0.2543
Epoch 23/43
106/106 [==============================] - 2s 16ms/step - loss: 0.3339 - val_loss: 0.2548
Epoch 24/43
106/106 [==============================] - 2s 16ms/step - loss: 0.3339 - val_loss: 0.2547
Epoch 25/43
106/106 [==============================] - 2s 18ms/step - loss: 0.3335 - val_loss: 0.2565
Epoch 26/43
106/106 [==============================] - 2s 17ms/step - loss: 0.3338 - val_loss: 0.2533
Epoch 27/43
106/106 [==============================] - 2s 16ms/step - loss: 0.3328 - val_loss: 0.2552
Epoch 28/43
106/106 [==============================] - 2s 16ms/step - loss: 0.3331 - val_loss: 0.2547
Epoch 29/43
106/106 [==============================] - 2s 16ms/step - loss: 0.3321 - val_loss: 0.2541
Epoch 30/43
106/106 [==============================] - 2s 16ms/step - loss: 0.3321 - val_loss: 0.2544
Epoch 31/43
106/106 [==============================] - 2s 16ms/step - loss: 0.3322 - val_loss: 0.2539
Epoch 32/43
106/106 [==============================] - 2s 16ms/step - loss: 0.3320 - val_loss: 0.2546
Epoch 33/43
106/106 [==============================] - 2s 16ms/step - loss: 0.3317 - val_loss: 0.2528
Epoch 34/43
106/106 [==============================] - 2s 17ms/step - loss: 0.3309 - val_loss: 0.2545
Epoch 35/43
106/106 [==============================] - 2s 17ms/step - loss: 0.3314 - val_loss: 0.2537
Epoch 36/43
106/106 [==============================] - 2s 17ms/step - loss: 0.3310 - val_loss: 0.2529
Epoch 37/43
106/106 [==============================] - 2s 16ms/step - loss: 0.3305 - val_loss: 0.2540- ET
Epoch 38/43
106/106 [==============================] - 2s 16ms/step - loss: 0.3302 - val_loss: 0.2537
Epoch 39/43
106/106 [==============================] - 2s 16ms/step - loss: 0.3307 - val_loss: 0.2524
Epoch 40/43
106/106 [==============================] - 2s 16ms/step - loss: 0.3300 - val_loss: 0.2535
Epoch 41/43
106/106 [==============================] - 2s 16ms/step - loss: 0.3297 - val_loss: 0.2533
Epoch 42/43
106/106 [==============================] - 2s 17ms/step - loss: 0.3297 - val_loss: 0.2522
Epoch 43/43
106/106 [==============================] - 2s 18ms/step - loss: 0.3294 - val_loss: 0.2529
Execution time:  82.41637229919434
GRU:
Mean Absolute Error: 0.1850
Root Mean Square Error: 0.5977
Mean Square Error: 0.3573

Train RMSE: 0.598
Train MSE: 0.357
Train MAE: 0.185
###########################

MODEL:  GRU
sequence:  3h
units:  43
dropout1:  0.40519643149940265
dropout2:  0.3312343747027119
optimizer: adam
activationDense: sigmoid
epochs: 56
batchsize: 11
validation_split: 0.1
Model: &#34;sequential_98&#34;
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
gru_28 (GRU)                 (None, 18, 43)            5934      
_________________________________________________________________
dropout_196 (Dropout)        (None, 18, 43)            0         
_________________________________________________________________
gru_29 (GRU)                 (None, 18, 43)            11352     
_________________________________________________________________
dropout_197 (Dropout)        (None, 18, 43)            0         
_________________________________________________________________
time_distributed_98 (TimeDis (None, 18, 1)             44        
=================================================================
Total params: 17,330
Trainable params: 17,330
Non-trainable params: 0
_________________________________________________________________
Epoch 1/56
325/325 [==============================] - 4s 11ms/step - loss: 0.6180 - val_loss: 0.8139
Epoch 2/56
325/325 [==============================] - 3s 8ms/step - loss: 0.5505 - val_loss: 0.8071
Epoch 3/56
325/325 [==============================] - 3s 8ms/step - loss: 0.5438 - val_loss: 0.8061
Epoch 4/56
325/325 [==============================] - 3s 9ms/step - loss: 0.5421 - val_loss: 0.8059
Epoch 5/56
325/325 [==============================] - 3s 8ms/step - loss: 0.5411 - val_loss: 0.8057
Epoch 6/56
325/325 [==============================] - 3s 8ms/step - loss: 0.5408 - val_loss: 0.8057
Epoch 7/56
325/325 [==============================] - 3s 8ms/step - loss: 0.5403 - val_loss: 0.8057
Epoch 8/56
325/325 [==============================] - 3s 8ms/step - loss: 0.5399 - val_loss: 0.8056
Epoch 9/56
325/325 [==============================] - 3s 8ms/step - loss: 0.5398 - val_loss: 0.8056
Epoch 10/56
325/325 [==============================] - 3s 9ms/step - loss: 0.5398 - val_loss: 0.8056
Epoch 11/56
325/325 [==============================] - 3s 8ms/step - loss: 0.5394 - val_loss: 0.8056
Epoch 12/56
325/325 [==============================] - 3s 8ms/step - loss: 0.5392 - val_loss: 0.8056
Epoch 13/56
325/325 [==============================] - 3s 8ms/step - loss: 0.5390 - val_loss: 0.8056
Epoch 14/56
325/325 [==============================] - 3s 8ms/step - loss: 0.5390 - val_loss: 0.8056
Epoch 15/56
325/325 [==============================] - 3s 8ms/step - loss: 0.5390 - val_loss: 0.8056
Epoch 16/56
325/325 [==============================] - 3s 9ms/step - loss: 0.5391 - val_loss: 0.8056
Epoch 17/56
325/325 [==============================] - 3s 8ms/step - loss: 0.5387 - val_loss: 0.8056
Epoch 18/56
325/325 [==============================] - 3s 8ms/step - loss: 0.5387 - val_loss: 0.8056
Epoch 19/56
325/325 [==============================] - 3s 8ms/step - loss: 0.5385 - val_loss: 0.8056
Epoch 20/56
325/325 [==============================] - 3s 8ms/step - loss: 0.5383 - val_loss: 0.8056
Epoch 21/56
325/325 [==============================] - 3s 9ms/step - loss: 0.5386 - val_loss: 0.8056
Epoch 22/56
325/325 [==============================] - 3s 9ms/step - loss: 0.5385 - val_loss: 0.8056
Epoch 23/56
325/325 [==============================] - 3s 8ms/step - loss: 0.5384 - val_loss: 0.8056
Epoch 24/56
325/325 [==============================] - 3s 8ms/step - loss: 0.5383 - val_loss: 0.8056
Epoch 25/56
325/325 [==============================] - 3s 8ms/step - loss: 0.5382 - val_loss: 0.8056
Epoch 26/56
325/325 [==============================] - 3s 8ms/step - loss: 0.5381 - val_loss: 0.8056
Epoch 27/56
325/325 [==============================] - 3s 9ms/step - loss: 0.5383 - val_loss: 0.8056
Epoch 28/56
325/325 [==============================] - 3s 8ms/step - loss: 0.5379 - val_loss: 0.8056
Epoch 29/56
325/325 [==============================] - 3s 8ms/step - loss: 0.5378 - val_loss: 0.8056
Epoch 30/56
325/325 [==============================] - 3s 8ms/step - loss: 0.5376 - val_loss: 0.8056
Epoch 31/56
325/325 [==============================] - 3s 8ms/step - loss: 0.5376 - val_loss: 0.8056
Epoch 32/56
325/325 [==============================] - 3s 8ms/step - loss: 0.5374 - val_loss: 0.8056
Epoch 33/56
325/325 [==============================] - 3s 9ms/step - loss: 0.5373 - val_loss: 0.8056
Epoch 34/56
325/325 [==============================] - 3s 8ms/step - loss: 0.5372 - val_loss: 0.8056
Epoch 35/56
325/325 [==============================] - 3s 8ms/step - loss: 0.5372 - val_loss: 0.8056
Epoch 36/56
325/325 [==============================] - 3s 8ms/step - loss: 0.5372 - val_loss: 0.8056
Epoch 37/56
325/325 [==============================] - 3s 8ms/step - loss: 0.5369 - val_loss: 0.8056
Epoch 38/56
325/325 [==============================] - 3s 8ms/step - loss: 0.5371 - val_loss: 0.8056
Epoch 39/56
325/325 [==============================] - 3s 9ms/step - loss: 0.5369 - val_loss: 0.8056
Epoch 40/56
325/325 [==============================] - 3s 8ms/step - loss: 0.5368 - val_loss: 0.8056
Epoch 41/56
325/325 [==============================] - 3s 8ms/step - loss: 0.5369 - val_loss: 0.8056
Epoch 42/56
325/325 [==============================] - 3s 8ms/step - loss: 0.5368 - val_loss: 0.8056
Epoch 43/56
325/325 [==============================] - 3s 8ms/step - loss: 0.5367 - val_loss: 0.8056
Epoch 44/56
325/325 [==============================] - 3s 8ms/step - loss: 0.5365 - val_loss: 0.8056
Epoch 45/56
325/325 [==============================] - 3s 9ms/step - loss: 0.5367 - val_loss: 0.8056
Epoch 46/56
325/325 [==============================] - 3s 8ms/step - loss: 0.5366 - val_loss: 0.8056
Epoch 47/56
325/325 [==============================] - 3s 8ms/step - loss: 0.5363 - val_loss: 0.8056
Epoch 48/56
325/325 [==============================] - 3s 8ms/step - loss: 0.5364 - val_loss: 0.8056
Epoch 49/56
325/325 [==============================] - 3s 8ms/step - loss: 0.5363 - val_loss: 0.8056
Epoch 50/56
325/325 [==============================] - 3s 9ms/step - loss: 0.5363 - val_loss: 0.8056
Epoch 51/56
325/325 [==============================] - 3s 9ms/step - loss: 0.5363 - val_loss: 0.8056
Epoch 52/56
325/325 [==============================] - 3s 8ms/step - loss: 0.5360 - val_loss: 0.8056
Epoch 53/56
325/325 [==============================] - 3s 8ms/step - loss: 0.5361 - val_loss: 0.8056
Epoch 54/56
325/325 [==============================] - 3s 8ms/step - loss: 0.5359 - val_loss: 0.8056
Epoch 55/56
325/325 [==============================] - 3s 8ms/step - loss: 0.5359 - val_loss: 0.8056
Epoch 56/56
325/325 [==============================] - 3s 9ms/step - loss: 0.5358 - val_loss: 0.8056
Execution time:  158.30796456336975
GRU:
Mean Absolute Error: 0.5075
Root Mean Square Error: 0.7646
Mean Square Error: 0.5847

Train RMSE: 0.765
Train MSE: 0.585
Train MAE: 0.507
###########################

MODEL:  GRU
sequence:  3h
units:  45
dropout1:  0.11814836227952394
dropout2:  0.24325404382648977
optimizer: adam
activationDense: sigmoid
epochs: 43
batchsize: 30
validation_split: 0.2
Model: &#34;sequential_99&#34;
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
gru_30 (GRU)                 (None, 18, 45)            6480      
_________________________________________________________________
dropout_198 (Dropout)        (None, 18, 45)            0         
_________________________________________________________________
gru_31 (GRU)                 (None, 18, 45)            12420     
_________________________________________________________________
dropout_199 (Dropout)        (None, 18, 45)            0         
_________________________________________________________________
time_distributed_99 (TimeDis (None, 18, 1)             46        
=================================================================
Total params: 18,946
Trainable params: 18,946
Non-trainable params: 0
_________________________________________________________________
Epoch 1/43
106/106 [==============================] - 3s 25ms/step - loss: 0.6912 - val_loss: 0.7204
Epoch 2/43
106/106 [==============================] - 2s 16ms/step - loss: 0.5772 - val_loss: 0.6978
Epoch 3/43
106/106 [==============================] - 2s 16ms/step - loss: 0.5552 - val_loss: 0.6884
Epoch 4/43
106/106 [==============================] - 2s 18ms/step - loss: 0.5475 - val_loss: 0.6839
Epoch 5/43
106/106 [==============================] - 2s 17ms/step - loss: 0.5433 - val_loss: 0.6819
Epoch 6/43
106/106 [==============================] - 2s 16ms/step - loss: 0.5408 - val_loss: 0.6808
Epoch 7/43
106/106 [==============================] - 2s 17ms/step - loss: 0.5393 - val_loss: 0.6803
Epoch 8/43
106/106 [==============================] - 2s 17ms/step - loss: 0.5385 - val_loss: 0.6799
Epoch 9/43
106/106 [==============================] - 2s 16ms/step - loss: 0.5378 - val_loss: 0.6796
Epoch 10/43
106/106 [==============================] - 2s 16ms/step - loss: 0.5372 - val_loss: 0.6795
Epoch 11/43
106/106 [==============================] - 2s 16ms/step - loss: 0.5370 - val_loss: 0.6792
Epoch 12/43
106/106 [==============================] - 2s 16ms/step - loss: 0.5366 - val_loss: 0.6792
Epoch 13/43
106/106 [==============================] - 2s 18ms/step - loss: 0.5366 - val_loss: 0.6790
Epoch 14/43
106/106 [==============================] - 2s 16ms/step - loss: 0.5364 - val_loss: 0.6788
Epoch 15/43
106/106 [==============================] - 2s 16ms/step - loss: 0.5362 - val_loss: 0.6788
Epoch 16/43
106/106 [==============================] - 2s 16ms/step - loss: 0.5361 - val_loss: 0.6788
Epoch 17/43
106/106 [==============================] - 2s 16ms/step - loss: 0.5361 - val_loss: 0.6791
Epoch 18/43
106/106 [==============================] - 2s 16ms/step - loss: 0.5360 - val_loss: 0.6787
Epoch 19/43
106/106 [==============================] - 2s 16ms/step - loss: 0.5359 - val_loss: 0.6788
Epoch 20/43
106/106 [==============================] - 2s 16ms/step - loss: 0.5358 - val_loss: 0.6786
Epoch 21/43
106/106 [==============================] - 2s 16ms/step - loss: 0.5356 - val_loss: 0.6790
Epoch 22/43
106/106 [==============================] - 2s 18ms/step - loss: 0.5357 - val_loss: 0.6786
Epoch 23/43
106/106 [==============================] - 2s 16ms/step - loss: 0.5356 - val_loss: 0.6786
Epoch 24/43
106/106 [==============================] - 2s 16ms/step - loss: 0.5357 - val_loss: 0.6785
Epoch 25/43
106/106 [==============================] - 2s 16ms/step - loss: 0.5354 - val_loss: 0.6785
Epoch 26/43
106/106 [==============================] - 2s 16ms/step - loss: 0.5354 - val_loss: 0.6782
Epoch 27/43
106/106 [==============================] - 2s 16ms/step - loss: 0.5354 - val_loss: 0.6785
Epoch 28/43
106/106 [==============================] - 2s 16ms/step - loss: 0.5354 - val_loss: 0.6783
Epoch 29/43
106/106 [==============================] - 2s 16ms/step - loss: 0.5352 - val_loss: 0.6783
Epoch 30/43
106/106 [==============================] - 2s 16ms/step - loss: 0.5352 - val_loss: 0.6781
Epoch 31/43
106/106 [==============================] - 2s 17ms/step - loss: 0.5351 - val_loss: 0.6782
Epoch 32/43
106/106 [==============================] - 2s 17ms/step - loss: 0.5351 - val_loss: 0.6784
Epoch 33/43
106/106 [==============================] - 2s 16ms/step - loss: 0.5348 - val_loss: 0.6785: 0s - loss: 
Epoch 34/43
106/106 [==============================] - 2s 16ms/step - loss: 0.5349 - val_loss: 0.6784
Epoch 35/43
106/106 [==============================] - 2s 16ms/step - loss: 0.5348 - val_loss: 0.6784
Epoch 36/43
106/106 [==============================] - 2s 16ms/step - loss: 0.5347 - val_loss: 0.6784
Epoch 37/43
106/106 [==============================] - 2s 16ms/step - loss: 0.5347 - val_loss: 0.6786
Epoch 38/43
106/106 [==============================] - 2s 16ms/step - loss: 0.5346 - val_loss: 0.6785
Epoch 39/43
106/106 [==============================] - 2s 16ms/step - loss: 0.5346 - val_loss: 0.6785
Epoch 40/43
106/106 [==============================] - 2s 17ms/step - loss: 0.5343 - val_loss: 0.6786
Epoch 41/43
106/106 [==============================] - 2s 17ms/step - loss: 0.5342 - val_loss: 0.6788
Epoch 42/43
106/106 [==============================] - 2s 16ms/step - loss: 0.5344 - val_loss: 0.6789
Epoch 43/43
106/106 [==============================] - 2s 16ms/step - loss: 0.5344 - val_loss: 0.6787
Execution time:  84.3237042427063
GRU:
Mean Absolute Error: 0.5063
Root Mean Square Error: 0.7668
Mean Square Error: 0.5879

Train RMSE: 0.767
Train MSE: 0.588
Train MAE: 0.506
###########################

MODEL:  GRU
sequence:  3h
units:  43
dropout1:  0.40519643149940265
dropout2:  0.3312343747027119
optimizer: adadelta
activationDense: tanh
epochs: 56
batchsize: 11
validation_split: 0.1
Model: &#34;sequential_100&#34;
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
gru_32 (GRU)                 (None, 18, 43)            5934      
_________________________________________________________________
dropout_200 (Dropout)        (None, 18, 43)            0         
_________________________________________________________________
gru_33 (GRU)                 (None, 18, 43)            11352     
_________________________________________________________________
dropout_201 (Dropout)        (None, 18, 43)            0         
_________________________________________________________________
time_distributed_100 (TimeDi (None, 18, 1)             44        
=================================================================
Total params: 17,330
Trainable params: 17,330
Non-trainable params: 0
_________________________________________________________________
Epoch 1/56
325/325 [==============================] - 3s 11ms/step - loss: 0.7082 - val_loss: 0.8058
Epoch 2/56
325/325 [==============================] - 3s 9ms/step - loss: 0.7053 - val_loss: 0.8011
Epoch 3/56
325/325 [==============================] - 3s 8ms/step - loss: 0.7023 - val_loss: 0.7964
Epoch 4/56
325/325 [==============================] - 3s 8ms/step - loss: 0.6998 - val_loss: 0.7916
Epoch 5/56
325/325 [==============================] - 3s 8ms/step - loss: 0.6970 - val_loss: 0.7868
Epoch 6/56
325/325 [==============================] - 3s 8ms/step - loss: 0.6940 - val_loss: 0.7818
Epoch 7/56
325/325 [==============================] - 3s 8ms/step - loss: 0.6914 - val_loss: 0.7768
Epoch 8/56
325/325 [==============================] - 3s 9ms/step - loss: 0.6883 - val_loss: 0.7716
Epoch 9/56
325/325 [==============================] - 3s 8ms/step - loss: 0.6856 - val_loss: 0.7664
Epoch 10/56
325/325 [==============================] - 3s 8ms/step - loss: 0.6828 - val_loss: 0.7610
Epoch 11/56
325/325 [==============================] - 3s 8ms/step - loss: 0.6796 - val_loss: 0.7556
Epoch 12/56
325/325 [==============================] - 3s 8ms/step - loss: 0.6767 - val_loss: 0.7500
Epoch 13/56
325/325 [==============================] - 3s 8ms/step - loss: 0.6736 - val_loss: 0.7444
Epoch 14/56
325/325 [==============================] - 3s 9ms/step - loss: 0.6703 - val_loss: 0.7386
Epoch 15/56
325/325 [==============================] - 3s 8ms/step - loss: 0.6673 - val_loss: 0.7328
Epoch 16/56
325/325 [==============================] - 3s 8ms/step - loss: 0.6638 - val_loss: 0.7268
Epoch 17/56
325/325 [==============================] - 3s 8ms/step - loss: 0.6608 - val_loss: 0.7208
Epoch 18/56
325/325 [==============================] - 3s 8ms/step - loss: 0.6578 - val_loss: 0.7147
Epoch 19/56
325/325 [==============================] - 3s 9ms/step - loss: 0.6541 - val_loss: 0.7085
Epoch 20/56
325/325 [==============================] - 3s 9ms/step - loss: 0.6509 - val_loss: 0.7022
Epoch 21/56
325/325 [==============================] - 3s 8ms/step - loss: 0.6475 - val_loss: 0.6958
Epoch 22/56
325/325 [==============================] - 3s 8ms/step - loss: 0.6441 - val_loss: 0.6893
Epoch 23/56
325/325 [==============================] - 3s 8ms/step - loss: 0.6406 - val_loss: 0.6828
Epoch 24/56
325/325 [==============================] - 3s 8ms/step - loss: 0.6373 - val_loss: 0.6761
Epoch 25/56
325/325 [==============================] - 3s 9ms/step - loss: 0.6336 - val_loss: 0.6693
Epoch 26/56
325/325 [==============================] - 3s 8ms/step - loss: 0.6302 - val_loss: 0.6624
Epoch 27/56
325/325 [==============================] - 3s 8ms/step - loss: 0.6266 - val_loss: 0.6553
Epoch 28/56
325/325 [==============================] - 3s 8ms/step - loss: 0.6227 - val_loss: 0.6480
Epoch 29/56
325/325 [==============================] - 3s 8ms/step - loss: 0.6189 - val_loss: 0.6406
Epoch 30/56
325/325 [==============================] - 3s 8ms/step - loss: 0.6150 - val_loss: 0.6330
Epoch 31/56
325/325 [==============================] - 3s 9ms/step - loss: 0.6111 - val_loss: 0.6252
Epoch 32/56
325/325 [==============================] - 3s 8ms/step - loss: 0.6068 - val_loss: 0.6172
Epoch 33/56
325/325 [==============================] - 3s 8ms/step - loss: 0.6025 - val_loss: 0.6090
Epoch 34/56
325/325 [==============================] - 3s 8ms/step - loss: 0.5981 - val_loss: 0.6007
Epoch 35/56
325/325 [==============================] - 3s 8ms/step - loss: 0.5940 - val_loss: 0.5921
Epoch 36/56
325/325 [==============================] - 3s 8ms/step - loss: 0.5893 - val_loss: 0.5833
Epoch 37/56
325/325 [==============================] - 3s 9ms/step - loss: 0.5850 - val_loss: 0.5743
Epoch 38/56
325/325 [==============================] - 3s 8ms/step - loss: 0.5802 - val_loss: 0.5651
Epoch 39/56
325/325 [==============================] - 3s 8ms/step - loss: 0.5753 - val_loss: 0.5557
Epoch 40/56
325/325 [==============================] - 3s 8ms/step - loss: 0.5707 - val_loss: 0.5461
Epoch 41/56
325/325 [==============================] - 3s 8ms/step - loss: 0.5656 - val_loss: 0.5364
Epoch 42/56
325/325 [==============================] - 3s 8ms/step - loss: 0.5609 - val_loss: 0.5266
Epoch 43/56
325/325 [==============================] - 3s 9ms/step - loss: 0.5560 - val_loss: 0.5167
Epoch 44/56
325/325 [==============================] - 3s 8ms/step - loss: 0.5510 - val_loss: 0.5067
Epoch 45/56
325/325 [==============================] - 3s 8ms/step - loss: 0.5462 - val_loss: 0.4967
Epoch 46/56
325/325 [==============================] - 3s 8ms/step - loss: 0.5410 - val_loss: 0.4867
Epoch 47/56
325/325 [==============================] - 3s 8ms/step - loss: 0.5361 - val_loss: 0.4768
Epoch 48/56
325/325 [==============================] - 3s 8ms/step - loss: 0.5309 - val_loss: 0.4669
Epoch 49/56
325/325 [==============================] - 3s 9ms/step - loss: 0.5262 - val_loss: 0.4571
Epoch 50/56
325/325 [==============================] - 3s 8ms/step - loss: 0.5211 - val_loss: 0.4474
Epoch 51/56
325/325 [==============================] - 3s 8ms/step - loss: 0.5165 - val_loss: 0.4378
Epoch 52/56
325/325 [==============================] - 3s 8ms/step - loss: 0.5124 - val_loss: 0.4281
Epoch 53/56
325/325 [==============================] - 3s 8ms/step - loss: 0.5073 - val_loss: 0.4187
Epoch 54/56
325/325 [==============================] - 3s 9ms/step - loss: 0.5030 - val_loss: 0.4092
Epoch 55/56
325/325 [==============================] - 3s 9ms/step - loss: 0.4984 - val_loss: 0.3999
Epoch 56/56
325/325 [==============================] - 3s 8ms/step - loss: 0.4946 - val_loss: 0.3908
Execution time:  157.76559209823608
GRU:
Mean Absolute Error: 0.4463
Root Mean Square Error: 0.7825
Mean Square Error: 0.6124

Train RMSE: 0.783
Train MSE: 0.612
Train MAE: 0.446
###########################

MODEL:  GRU
sequence:  3h
units:  45
dropout1:  0.11814836227952394
dropout2:  0.24325404382648977
optimizer: adadelta
activationDense: tanh
epochs: 43
batchsize: 30
validation_split: 0.2
Model: &#34;sequential_101&#34;
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
gru_34 (GRU)                 (None, 18, 45)            6480      
_________________________________________________________________
dropout_202 (Dropout)        (None, 18, 45)            0         
_________________________________________________________________
gru_35 (GRU)                 (None, 18, 45)            12420     
_________________________________________________________________
dropout_203 (Dropout)        (None, 18, 45)            0         
_________________________________________________________________
time_distributed_101 (TimeDi (None, 18, 1)             46        
=================================================================
Total params: 18,946
Trainable params: 18,946
Non-trainable params: 0
_________________________________________________________________
Epoch 1/43
106/106 [==============================] - 3s 25ms/step - loss: 0.7116 - val_loss: 0.6981
Epoch 2/43
106/106 [==============================] - 2s 17ms/step - loss: 0.7105 - val_loss: 0.6969
Epoch 3/43
106/106 [==============================] - 2s 17ms/step - loss: 0.7097 - val_loss: 0.6957
Epoch 4/43
106/106 [==============================] - 2s 16ms/step - loss: 0.7088 - val_loss: 0.6944
Epoch 5/43
106/106 [==============================] - 2s 16ms/step - loss: 0.7078 - val_loss: 0.6932
Epoch 6/43
106/106 [==============================] - 2s 16ms/step - loss: 0.7070 - val_loss: 0.6919
Epoch 7/43
106/106 [==============================] - 2s 17ms/step - loss: 0.7060 - val_loss: 0.6907
Epoch 8/43
106/106 [==============================] - 2s 16ms/step - loss: 0.7050 - val_loss: 0.6894
Epoch 9/43
106/106 [==============================] - 2s 16ms/step - loss: 0.7039 - val_loss: 0.6881
Epoch 10/43
106/106 [==============================] - 2s 16ms/step - loss: 0.7029 - val_loss: 0.6868
Epoch 11/43
106/106 [==============================] - 2s 17ms/step - loss: 0.7020 - val_loss: 0.6855
Epoch 12/43
106/106 [==============================] - 2s 19ms/step - loss: 0.7010 - val_loss: 0.6841
Epoch 13/43
106/106 [==============================] - 2s 16ms/step - loss: 0.7000 - val_loss: 0.6828
Epoch 14/43
106/106 [==============================] - 2s 16ms/step - loss: 0.6990 - val_loss: 0.6815
Epoch 15/43
106/106 [==============================] - 2s 16ms/step - loss: 0.6979 - val_loss: 0.6801
Epoch 16/43
106/106 [==============================] - 2s 16ms/step - loss: 0.6968 - val_loss: 0.6787
Epoch 17/43
106/106 [==============================] - 2s 16ms/step - loss: 0.6959 - val_loss: 0.6774
Epoch 18/43
106/106 [==============================] - 2s 16ms/step - loss: 0.6949 - val_loss: 0.6760
Epoch 19/43
106/106 [==============================] - 2s 16ms/step - loss: 0.6939 - val_loss: 0.6746
Epoch 20/43
106/106 [==============================] - 2s 17ms/step - loss: 0.6928 - val_loss: 0.6732
Epoch 21/43
106/106 [==============================] - 2s 17ms/step - loss: 0.6919 - val_loss: 0.6718
Epoch 22/43
106/106 [==============================] - 2s 16ms/step - loss: 0.6908 - val_loss: 0.6703
Epoch 23/43
106/106 [==============================] - 2s 17ms/step - loss: 0.6897 - val_loss: 0.6689
Epoch 24/43
106/106 [==============================] - 2s 16ms/step - loss: 0.6887 - val_loss: 0.6675
Epoch 25/43
106/106 [==============================] - 2s 16ms/step - loss: 0.6877 - val_loss: 0.6660
Epoch 26/43
106/106 [==============================] - 2s 16ms/step - loss: 0.6865 - val_loss: 0.6646
Epoch 27/43
106/106 [==============================] - 2s 16ms/step - loss: 0.6856 - val_loss: 0.6631
Epoch 28/43
106/106 [==============================] - 2s 16ms/step - loss: 0.6844 - val_loss: 0.6616
Epoch 29/43
106/106 [==============================] - 2s 17ms/step - loss: 0.6834 - val_loss: 0.6601
Epoch 30/43
106/106 [==============================] - 2s 18ms/step - loss: 0.6822 - val_loss: 0.6586
Epoch 31/43
106/106 [==============================] - 2s 17ms/step - loss: 0.6813 - val_loss: 0.6571
Epoch 32/43
106/106 [==============================] - 2s 17ms/step - loss: 0.6800 - val_loss: 0.6556
Epoch 33/43
106/106 [==============================] - 2s 16ms/step - loss: 0.6790 - val_loss: 0.6540
Epoch 34/43
106/106 [==============================] - 2s 16ms/step - loss: 0.6778 - val_loss: 0.6525
Epoch 35/43
106/106 [==============================] - 2s 16ms/step - loss: 0.6767 - val_loss: 0.6509
Epoch 36/43
106/106 [==============================] - 2s 16ms/step - loss: 0.6756 - val_loss: 0.6494
Epoch 37/43
106/106 [==============================] - 2s 16ms/step - loss: 0.6746 - val_loss: 0.6478
Epoch 38/43
106/106 [==============================] - 2s 17ms/step - loss: 0.6735 - val_loss: 0.6462
Epoch 39/43
106/106 [==============================] - 2s 17ms/step - loss: 0.6724 - val_loss: 0.6447
Epoch 40/43
106/106 [==============================] - 2s 16ms/step - loss: 0.6712 - val_loss: 0.6431
Epoch 41/43
106/106 [==============================] - 2s 16ms/step - loss: 0.6699 - val_loss: 0.6415
Epoch 42/43
106/106 [==============================] - 2s 16ms/step - loss: 0.6688 - val_loss: 0.6399
Epoch 43/43
106/106 [==============================] - 2s 16ms/step - loss: 0.6676 - val_loss: 0.6383
Execution time:  81.83752202987671
GRU:
Mean Absolute Error: 0.6547
Root Mean Square Error: 0.9428
Mean Square Error: 0.8889

Train RMSE: 0.943
Train MSE: 0.889
Train MAE: 0.655
###########################

MODEL:  GRU
sequence:  3h
units:  43
dropout1:  0.40519643149940265
dropout2:  0.3312343747027119
optimizer: adadelta
activationDense: sigmoid
epochs: 56
batchsize: 11
validation_split: 0.1
Model: &#34;sequential_102&#34;
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
gru_36 (GRU)                 (None, 18, 43)            5934      
_________________________________________________________________
dropout_204 (Dropout)        (None, 18, 43)            0         
_________________________________________________________________
gru_37 (GRU)                 (None, 18, 43)            11352     
_________________________________________________________________
dropout_205 (Dropout)        (None, 18, 43)            0         
_________________________________________________________________
time_distributed_102 (TimeDi (None, 18, 1)             44        
=================================================================
Total params: 17,330
Trainable params: 17,330
Non-trainable params: 0
_________________________________________________________________
Epoch 1/56
325/325 [==============================] - 4s 12ms/step - loss: 0.8921 - val_loss: 1.3036
Epoch 2/56
325/325 [==============================] - 3s 8ms/step - loss: 0.8916 - val_loss: 1.3027
Epoch 3/56
325/325 [==============================] - 3s 8ms/step - loss: 0.8911 - val_loss: 1.3017
Epoch 4/56
325/325 [==============================] - 3s 8ms/step - loss: 0.8906 - val_loss: 1.3007
Epoch 5/56
325/325 [==============================] - 3s 9ms/step - loss: 0.8900 - val_loss: 1.2997
Epoch 6/56
325/325 [==============================] - 3s 8ms/step - loss: 0.8894 - val_loss: 1.2986
Epoch 7/56
325/325 [==============================] - 3s 9ms/step - loss: 0.8888 - val_loss: 1.2975
Epoch 8/56
325/325 [==============================] - 3s 8ms/step - loss: 0.8882 - val_loss: 1.2963
Epoch 9/56
325/325 [==============================] - 3s 8ms/step - loss: 0.8876 - val_loss: 1.2952
Epoch 10/56
325/325 [==============================] - 3s 8ms/step - loss: 0.8870 - val_loss: 1.2940
Epoch 11/56
325/325 [==============================] - 3s 8ms/step - loss: 0.8863 - val_loss: 1.2927
Epoch 12/56
325/325 [==============================] - 3s 8ms/step - loss: 0.8856 - val_loss: 1.2915
Epoch 13/56
325/325 [==============================] - 3s 9ms/step - loss: 0.8850 - val_loss: 1.2902
Epoch 14/56
325/325 [==============================] - 3s 8ms/step - loss: 0.8842 - val_loss: 1.2888
Epoch 15/56
325/325 [==============================] - 3s 8ms/step - loss: 0.8835 - val_loss: 1.2874
Epoch 16/56
325/325 [==============================] - 3s 8ms/step - loss: 0.8828 - val_loss: 1.2860
Epoch 17/56
325/325 [==============================] - 3s 8ms/step - loss: 0.8820 - val_loss: 1.2846
Epoch 18/56
325/325 [==============================] - 3s 9ms/step - loss: 0.8812 - val_loss: 1.2831
Epoch 19/56
325/325 [==============================] - 3s 9ms/step - loss: 0.8805 - val_loss: 1.2816
Epoch 20/56
325/325 [==============================] - 3s 8ms/step - loss: 0.8796 - val_loss: 1.2801
Epoch 21/56
325/325 [==============================] - 3s 8ms/step - loss: 0.8788 - val_loss: 1.2785
Epoch 22/56
325/325 [==============================] - 3s 8ms/step - loss: 0.8779 - val_loss: 1.2769
Epoch 23/56
325/325 [==============================] - 3s 8ms/step - loss: 0.8771 - val_loss: 1.2752
Epoch 24/56
325/325 [==============================] - 3s 9ms/step - loss: 0.8762 - val_loss: 1.2735
Epoch 25/56
325/325 [==============================] - 3s 9ms/step - loss: 0.8753 - val_loss: 1.2718
Epoch 26/56
325/325 [==============================] - 3s 8ms/step - loss: 0.8744 - val_loss: 1.2700
Epoch 27/56
325/325 [==============================] - 3s 8ms/step - loss: 0.8734 - val_loss: 1.2682
Epoch 28/56
325/325 [==============================] - 3s 8ms/step - loss: 0.8725 - val_loss: 1.2663
Epoch 29/56
325/325 [==============================] - 3s 8ms/step - loss: 0.8714 - val_loss: 1.2644
Epoch 30/56
325/325 [==============================] - 3s 9ms/step - loss: 0.8703 - val_loss: 1.2625
Epoch 31/56
325/325 [==============================] - 3s 8ms/step - loss: 0.8694 - val_loss: 1.2605
Epoch 32/56
325/325 [==============================] - 3s 8ms/step - loss: 0.8682 - val_loss: 1.2584
Epoch 33/56
325/325 [==============================] - 3s 8ms/step - loss: 0.8671 - val_loss: 1.2563
Epoch 34/56
325/325 [==============================] - 3s 8ms/step - loss: 0.8659 - val_loss: 1.2541
Epoch 35/56
325/325 [==============================] - 3s 8ms/step - loss: 0.8648 - val_loss: 1.2519
Epoch 36/56
325/325 [==============================] - 3s 9ms/step - loss: 0.8636 - val_loss: 1.2497
Epoch 37/56
325/325 [==============================] - 3s 8ms/step - loss: 0.8624 - val_loss: 1.2474
Epoch 38/56
325/325 [==============================] - 3s 8ms/step - loss: 0.8611 - val_loss: 1.2450
Epoch 39/56
325/325 [==============================] - 3s 8ms/step - loss: 0.8598 - val_loss: 1.2426
Epoch 40/56
325/325 [==============================] - 3s 8ms/step - loss: 0.8586 - val_loss: 1.2401
Epoch 41/56
325/325 [==============================] - 3s 8ms/step - loss: 0.8572 - val_loss: 1.2376
Epoch 42/56
325/325 [==============================] - 3s 9ms/step - loss: 0.8558 - val_loss: 1.2350
Epoch 43/56
325/325 [==============================] - 3s 8ms/step - loss: 0.8544 - val_loss: 1.2323
Epoch 44/56
325/325 [==============================] - 3s 8ms/step - loss: 0.8530 - val_loss: 1.2296
Epoch 45/56
325/325 [==============================] - 3s 8ms/step - loss: 0.8516 - val_loss: 1.2268
Epoch 46/56
325/325 [==============================] - 3s 8ms/step - loss: 0.8501 - val_loss: 1.2240
Epoch 47/56
325/325 [==============================] - 3s 8ms/step - loss: 0.8485 - val_loss: 1.2211
Epoch 48/56
325/325 [==============================] - 3s 9ms/step - loss: 0.8470 - val_loss: 1.2181
Epoch 49/56
325/325 [==============================] - 3s 8ms/step - loss: 0.8453 - val_loss: 1.2151
Epoch 50/56
325/325 [==============================] - 3s 8ms/step - loss: 0.8437 - val_loss: 1.2120
Epoch 51/56
325/325 [==============================] - 3s 8ms/step - loss: 0.8420 - val_loss: 1.2089
Epoch 52/56
325/325 [==============================] - 3s 8ms/step - loss: 0.8403 - val_loss: 1.2057
Epoch 53/56
325/325 [==============================] - 3s 8ms/step - loss: 0.8384 - val_loss: 1.2024
Epoch 54/56
325/325 [==============================] - 3s 9ms/step - loss: 0.8368 - val_loss: 1.1991
Epoch 55/56
325/325 [==============================] - 3s 8ms/step - loss: 0.8350 - val_loss: 1.1957
Epoch 56/56
325/325 [==============================] - 3s 8ms/step - loss: 0.8330 - val_loss: 1.1922
Execution time:  158.44966626167297
GRU:
Mean Absolute Error: 0.8605
Root Mean Square Error: 1.0508
Mean Square Error: 1.1042

Train RMSE: 1.051
Train MSE: 1.104
Train MAE: 0.860
###########################

MODEL:  GRU
sequence:  3h
units:  45
dropout1:  0.11814836227952394
dropout2:  0.24325404382648977
optimizer: adadelta
activationDense: sigmoid
epochs: 43
batchsize: 30
validation_split: 0.2
Model: &#34;sequential_103&#34;
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
gru_38 (GRU)                 (None, 18, 45)            6480      
_________________________________________________________________
dropout_206 (Dropout)        (None, 18, 45)            0         
_________________________________________________________________
gru_39 (GRU)                 (None, 18, 45)            12420     
_________________________________________________________________
dropout_207 (Dropout)        (None, 18, 45)            0         
_________________________________________________________________
time_distributed_103 (TimeDi (None, 18, 1)             46        
=================================================================
Total params: 18,946
Trainable params: 18,946
Non-trainable params: 0
_________________________________________________________________
Epoch 1/43
106/106 [==============================] - 3s 25ms/step - loss: 0.8812 - val_loss: 1.1381
Epoch 2/43
106/106 [==============================] - 2s 17ms/step - loss: 0.8810 - val_loss: 1.1379
Epoch 3/43
106/106 [==============================] - 2s 17ms/step - loss: 0.8809 - val_loss: 1.1376
Epoch 4/43
106/106 [==============================] - 2s 16ms/step - loss: 0.8807 - val_loss: 1.1373
Epoch 5/43
106/106 [==============================] - 2s 17ms/step - loss: 0.8805 - val_loss: 1.1370
Epoch 6/43
106/106 [==============================] - 2s 16ms/step - loss: 0.8803 - val_loss: 1.1367
Epoch 7/43
106/106 [==============================] - 2s 16ms/step - loss: 0.8801 - val_loss: 1.1364
Epoch 8/43
106/106 [==============================] - 2s 17ms/step - loss: 0.8799 - val_loss: 1.1361
Epoch 9/43
106/106 [==============================] - 2s 18ms/step - loss: 0.8797 - val_loss: 1.1358
Epoch 10/43
106/106 [==============================] - 2s 17ms/step - loss: 0.8795 - val_loss: 1.1355
Epoch 11/43
106/106 [==============================] - 2s 16ms/step - loss: 0.8793 - val_loss: 1.1352
Epoch 12/43
106/106 [==============================] - 2s 16ms/step - loss: 0.8791 - val_loss: 1.1349
Epoch 13/43
106/106 [==============================] - 2s 16ms/step - loss: 0.8789 - val_loss: 1.1346
Epoch 14/43
106/106 [==============================] - 2s 16ms/step - loss: 0.8787 - val_loss: 1.1342
Epoch 15/43
106/106 [==============================] - 2s 17ms/step - loss: 0.8785 - val_loss: 1.1339
Epoch 16/43
106/106 [==============================] - 2s 16ms/step - loss: 0.8783 - val_loss: 1.1336
Epoch 17/43
106/106 [==============================] - 2s 17ms/step - loss: 0.8781 - val_loss: 1.1332
Epoch 18/43
106/106 [==============================] - 2s 17ms/step - loss: 0.8779 - val_loss: 1.1329
Epoch 19/43
106/106 [==============================] - 2s 16ms/step - loss: 0.8777 - val_loss: 1.1326
Epoch 20/43
106/106 [==============================] - 2s 16ms/step - loss: 0.8775 - val_loss: 1.1322
Epoch 21/43
106/106 [==============================] - 2s 16ms/step - loss: 0.8772 - val_loss: 1.1319
Epoch 22/43
106/106 [==============================] - 2s 16ms/step - loss: 0.8770 - val_loss: 1.1315
Epoch 23/43
106/106 [==============================] - 2s 16ms/step - loss: 0.8768 - val_loss: 1.1312
Epoch 24/43
106/106 [==============================] - 2s 16ms/step - loss: 0.8766 - val_loss: 1.1308
Epoch 25/43
106/106 [==============================] - 2s 16ms/step - loss: 0.8763 - val_loss: 1.1305
Epoch 26/43
106/106 [==============================] - 2s 17ms/step - loss: 0.8761 - val_loss: 1.1301
Epoch 27/43
106/106 [==============================] - 2s 17ms/step - loss: 0.8759 - val_loss: 1.1297
Epoch 28/43
106/106 [==============================] - 2s 16ms/step - loss: 0.8756 - val_loss: 1.1294
Epoch 29/43
106/106 [==============================] - 2s 16ms/step - loss: 0.8754 - val_loss: 1.1290
Epoch 30/43
106/106 [==============================] - 2s 16ms/step - loss: 0.8752 - val_loss: 1.1286
Epoch 31/43
106/106 [==============================] - 2s 16ms/step - loss: 0.8750 - val_loss: 1.1283
Epoch 32/43
106/106 [==============================] - 2s 16ms/step - loss: 0.8747 - val_loss: 1.1279
Epoch 33/43
106/106 [==============================] - 2s 16ms/step - loss: 0.8745 - val_loss: 1.1275
Epoch 34/43
106/106 [==============================] - 2s 16ms/step - loss: 0.8743 - val_loss: 1.1271
Epoch 35/43
106/106 [==============================] - 2s 17ms/step - loss: 0.8741 - val_loss: 1.1268
Epoch 36/43
106/106 [==============================] - 2s 17ms/step - loss: 0.8738 - val_loss: 1.1264
Epoch 37/43
106/106 [==============================] - 2s 16ms/step - loss: 0.8735 - val_loss: 1.1260
Epoch 38/43
106/106 [==============================] - 2s 16ms/step - loss: 0.8733 - val_loss: 1.1256
Epoch 39/43
106/106 [==============================] - 2s 16ms/step - loss: 0.8731 - val_loss: 1.1252
Epoch 40/43
106/106 [==============================] - 2s 16ms/step - loss: 0.8728 - val_loss: 1.1248
Epoch 41/43
106/106 [==============================] - 2s 17ms/step - loss: 0.8726 - val_loss: 1.1244
Epoch 42/43
106/106 [==============================] - 2s 16ms/step - loss: 0.8723 - val_loss: 1.1240
Epoch 43/43
106/106 [==============================] - 2s 16ms/step - loss: 0.8720 - val_loss: 1.1236
Execution time:  82.48642182350159
GRU:
Mean Absolute Error: 0.9183
Root Mean Square Error: 1.1050
Mean Square Error: 1.2211

Train RMSE: 1.105
Train MSE: 1.221
Train MAE: 0.918
###########################

MODEL:  GRU
sequence:  3h
units:  43
dropout1:  0.40519643149940265
dropout2:  0.3312343747027119
optimizer: adamax
activationDense: tanh
epochs: 56
batchsize: 11
validation_split: 0.1
Model: &#34;sequential_104&#34;
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
gru_40 (GRU)                 (None, 18, 43)            5934      
_________________________________________________________________
dropout_208 (Dropout)        (None, 18, 43)            0         
_________________________________________________________________
gru_41 (GRU)                 (None, 18, 43)            11352     
_________________________________________________________________
dropout_209 (Dropout)        (None, 18, 43)            0         
_________________________________________________________________
time_distributed_104 (TimeDi (None, 18, 1)             44        
=================================================================
Total params: 17,330
Trainable params: 17,330
Non-trainable params: 0
_________________________________________________________________
Epoch 1/56
325/325 [==============================] - 4s 11ms/step - loss: 0.4332 - val_loss: 0.2511
Epoch 2/56
325/325 [==============================] - 3s 8ms/step - loss: 0.3688 - val_loss: 0.2223
Epoch 3/56
325/325 [==============================] - 3s 8ms/step - loss: 0.3571 - val_loss: 0.2101
Epoch 4/56
325/325 [==============================] - 3s 8ms/step - loss: 0.3513 - val_loss: 0.2057
Epoch 5/56
325/325 [==============================] - 3s 9ms/step - loss: 0.3478 - val_loss: 0.2029
Epoch 6/56
325/325 [==============================] - 3s 8ms/step - loss: 0.3455 - val_loss: 0.2045
Epoch 7/56
325/325 [==============================] - 3s 8ms/step - loss: 0.3443 - val_loss: 0.2041
Epoch 8/56
325/325 [==============================] - 3s 8ms/step - loss: 0.3430 - val_loss: 0.2057
Epoch 9/56
325/325 [==============================] - 3s 8ms/step - loss: 0.3426 - val_loss: 0.2086
Epoch 10/56
325/325 [==============================] - 3s 9ms/step - loss: 0.3425 - val_loss: 0.2029
Epoch 11/56
325/325 [==============================] - 3s 9ms/step - loss: 0.3415 - val_loss: 0.2045
Epoch 12/56
325/325 [==============================] - 3s 8ms/step - loss: 0.3418 - val_loss: 0.2027
Epoch 13/56
325/325 [==============================] - 3s 8ms/step - loss: 0.3410 - val_loss: 0.2035
Epoch 14/56
325/325 [==============================] - 3s 8ms/step - loss: 0.3413 - val_loss: 0.2012
Epoch 15/56
325/325 [==============================] - 3s 8ms/step - loss: 0.3408 - val_loss: 0.2025
Epoch 16/56
325/325 [==============================] - 3s 9ms/step - loss: 0.3401 - val_loss: 0.2026
Epoch 17/56
325/325 [==============================] - 3s 9ms/step - loss: 0.3406 - val_loss: 0.1999
Epoch 18/56
325/325 [==============================] - 3s 8ms/step - loss: 0.3401 - val_loss: 0.2018
Epoch 19/56
325/325 [==============================] - 3s 8ms/step - loss: 0.3398 - val_loss: 0.2005
Epoch 20/56
325/325 [==============================] - 3s 8ms/step - loss: 0.3396 - val_loss: 0.1981
Epoch 21/56
325/325 [==============================] - 3s 8ms/step - loss: 0.3393 - val_loss: 0.1988
Epoch 22/56
325/325 [==============================] - 3s 9ms/step - loss: 0.3390 - val_loss: 0.1981
Epoch 23/56
325/325 [==============================] - 3s 8ms/step - loss: 0.3389 - val_loss: 0.1967
Epoch 24/56
325/325 [==============================] - 3s 8ms/step - loss: 0.3389 - val_loss: 0.1958
Epoch 25/56
325/325 [==============================] - 3s 8ms/step - loss: 0.3382 - val_loss: 0.1961
Epoch 26/56
325/325 [==============================] - 3s 8ms/step - loss: 0.3385 - val_loss: 0.1953
Epoch 27/56
325/325 [==============================] - 3s 8ms/step - loss: 0.3383 - val_loss: 0.1961
Epoch 28/56
325/325 [==============================] - 3s 9ms/step - loss: 0.3381 - val_loss: 0.1927
Epoch 29/56
325/325 [==============================] - 3s 8ms/step - loss: 0.3377 - val_loss: 0.1936
Epoch 30/56
325/325 [==============================] - 3s 8ms/step - loss: 0.3379 - val_loss: 0.1914
Epoch 31/56
325/325 [==============================] - 3s 8ms/step - loss: 0.3380 - val_loss: 0.1897
Epoch 32/56
325/325 [==============================] - 3s 8ms/step - loss: 0.3370 - val_loss: 0.1894
Epoch 33/56
325/325 [==============================] - 3s 8ms/step - loss: 0.3371 - val_loss: 0.1871
Epoch 34/56
325/325 [==============================] - 3s 9ms/step - loss: 0.3377 - val_loss: 0.1894
Epoch 35/56
325/325 [==============================] - 3s 8ms/step - loss: 0.3372 - val_loss: 0.1881
Epoch 36/56
325/325 [==============================] - 3s 8ms/step - loss: 0.3368 - val_loss: 0.1857
Epoch 37/56
325/325 [==============================] - 3s 8ms/step - loss: 0.3367 - val_loss: 0.1874
Epoch 38/56
325/325 [==============================] - 3s 8ms/step - loss: 0.3367 - val_loss: 0.1849
Epoch 39/56
325/325 [==============================] - 3s 8ms/step - loss: 0.3361 - val_loss: 0.1829
Epoch 40/56
325/325 [==============================] - 3s 9ms/step - loss: 0.3361 - val_loss: 0.1799
Epoch 41/56
325/325 [==============================] - 3s 8ms/step - loss: 0.3359 - val_loss: 0.1801
Epoch 42/56
325/325 [==============================] - 3s 8ms/step - loss: 0.3356 - val_loss: 0.1806
Epoch 43/56
325/325 [==============================] - 3s 8ms/step - loss: 0.3353 - val_loss: 0.1798
Epoch 44/56
325/325 [==============================] - 3s 8ms/step - loss: 0.3354 - val_loss: 0.1786
Epoch 45/56
325/325 [==============================] - 3s 8ms/step - loss: 0.3352 - val_loss: 0.1787
Epoch 46/56
325/325 [==============================] - 3s 9ms/step - loss: 0.3353 - val_loss: 0.1786
Epoch 47/56
325/325 [==============================] - 3s 8ms/step - loss: 0.3350 - val_loss: 0.1759
Epoch 48/56
325/325 [==============================] - 3s 8ms/step - loss: 0.3350 - val_loss: 0.1754
Epoch 49/56
325/325 [==============================] - 3s 8ms/step - loss: 0.3346 - val_loss: 0.1750
Epoch 50/56
325/325 [==============================] - 3s 8ms/step - loss: 0.3350 - val_loss: 0.1746
Epoch 51/56
325/325 [==============================] - 3s 8ms/step - loss: 0.3345 - val_loss: 0.1717
Epoch 52/56
325/325 [==============================] - 3s 9ms/step - loss: 0.3342 - val_loss: 0.1729
Epoch 53/56
325/325 [==============================] - 3s 8ms/step - loss: 0.3343 - val_loss: 0.1731
Epoch 54/56
325/325 [==============================] - 3s 8ms/step - loss: 0.3339 - val_loss: 0.1722
Epoch 55/56
325/325 [==============================] - 3s 8ms/step - loss: 0.3341 - val_loss: 0.1694
Epoch 56/56
325/325 [==============================] - 3s 8ms/step - loss: 0.3338 - val_loss: 0.1712
Execution time:  157.90851163864136
GRU:
Mean Absolute Error: 0.1778
Root Mean Square Error: 0.5788
Mean Square Error: 0.3350

Train RMSE: 0.579
Train MSE: 0.335
Train MAE: 0.178
###########################

MODEL:  GRU
sequence:  3h
units:  45
dropout1:  0.11814836227952394
dropout2:  0.24325404382648977
optimizer: adamax
activationDense: tanh
epochs: 43
batchsize: 30
validation_split: 0.2
Model: &#34;sequential_105&#34;
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
gru_42 (GRU)                 (None, 18, 45)            6480      
_________________________________________________________________
dropout_210 (Dropout)        (None, 18, 45)            0         
_________________________________________________________________
gru_43 (GRU)                 (None, 18, 45)            12420     
_________________________________________________________________
dropout_211 (Dropout)        (None, 18, 45)            0         
_________________________________________________________________
time_distributed_105 (TimeDi (None, 18, 1)             46        
=================================================================
Total params: 18,946
Trainable params: 18,946
Non-trainable params: 0
_________________________________________________________________
Epoch 1/43
106/106 [==============================] - 3s 25ms/step - loss: 0.4840 - val_loss: 0.3098
Epoch 2/43
106/106 [==============================] - 2s 17ms/step - loss: 0.3829 - val_loss: 0.2913
Epoch 3/43
106/106 [==============================] - 2s 16ms/step - loss: 0.3688 - val_loss: 0.2794
Epoch 4/43
106/106 [==============================] - 2s 16ms/step - loss: 0.3598 - val_loss: 0.2716
Epoch 5/43
106/106 [==============================] - 2s 16ms/step - loss: 0.3537 - val_loss: 0.2665
Epoch 6/43
106/106 [==============================] - 2s 17ms/step - loss: 0.3494 - val_loss: 0.2626
Epoch 7/43
106/106 [==============================] - 2s 17ms/step - loss: 0.3464 - val_loss: 0.2603
Epoch 8/43
106/106 [==============================] - 2s 16ms/step - loss: 0.3445 - val_loss: 0.2583
Epoch 9/43
106/106 [==============================] - 2s 16ms/step - loss: 0.3422 - val_loss: 0.2570
Epoch 10/43
106/106 [==============================] - 2s 16ms/step - loss: 0.3408 - val_loss: 0.2558
Epoch 11/43
106/106 [==============================] - 2s 16ms/step - loss: 0.3394 - val_loss: 0.2552
Epoch 12/43
106/106 [==============================] - 2s 16ms/step - loss: 0.3381 - val_loss: 0.2549
Epoch 13/43
106/106 [==============================] - 2s 16ms/step - loss: 0.3375 - val_loss: 0.2545
Epoch 14/43
106/106 [==============================] - 2s 16ms/step - loss: 0.3366 - val_loss: 0.2545
Epoch 15/43
106/106 [==============================] - 2s 17ms/step - loss: 0.3362 - val_loss: 0.2542
Epoch 16/43
106/106 [==============================] - 2s 17ms/step - loss: 0.3359 - val_loss: 0.2542
Epoch 17/43
106/106 [==============================] - 2s 16ms/step - loss: 0.3357 - val_loss: 0.2544
Epoch 18/43
106/106 [==============================] - 2s 16ms/step - loss: 0.3353 - val_loss: 0.2544
Epoch 19/43
106/106 [==============================] - 2s 16ms/step - loss: 0.3351 - val_loss: 0.2545
Epoch 20/43
106/106 [==============================] - 2s 16ms/step - loss: 0.3346 - val_loss: 0.2546
Epoch 21/43
106/106 [==============================] - 2s 16ms/step - loss: 0.3348 - val_loss: 0.2546
Epoch 22/43
106/106 [==============================] - 2s 16ms/step - loss: 0.3345 - val_loss: 0.2548
Epoch 23/43
106/106 [==============================] - 2s 16ms/step - loss: 0.3340 - val_loss: 0.2548
Epoch 24/43
106/106 [==============================] - 2s 17ms/step - loss: 0.3341 - val_loss: 0.2548
Epoch 25/43
106/106 [==============================] - 2s 17ms/step - loss: 0.3340 - val_loss: 0.2549
Epoch 26/43
106/106 [==============================] - 2s 16ms/step - loss: 0.3336 - val_loss: 0.2548
Epoch 27/43
106/106 [==============================] - 2s 16ms/step - loss: 0.3335 - val_loss: 0.2547
Epoch 28/43
106/106 [==============================] - 2s 16ms/step - loss: 0.3335 - val_loss: 0.2548
Epoch 29/43
106/106 [==============================] - 2s 16ms/step - loss: 0.3331 - val_loss: 0.2546
Epoch 30/43
106/106 [==============================] - 2s 16ms/step - loss: 0.3333 - val_loss: 0.2545
Epoch 31/43
106/106 [==============================] - 2s 16ms/step - loss: 0.3333 - val_loss: 0.2546
Epoch 32/43
106/106 [==============================] - 2s 16ms/step - loss: 0.3329 - val_loss: 0.2546
Epoch 33/43
106/106 [==============================] - 2s 17ms/step - loss: 0.3327 - val_loss: 0.2546
Epoch 34/43
106/106 [==============================] - 2s 17ms/step - loss: 0.3327 - val_loss: 0.2545
Epoch 35/43
106/106 [==============================] - 2s 17ms/step - loss: 0.3327 - val_loss: 0.2544
Epoch 36/43
106/106 [==============================] - 2s 16ms/step - loss: 0.3329 - val_loss: 0.2543
Epoch 37/43
106/106 [==============================] - 2s 16ms/step - loss: 0.3325 - val_loss: 0.2541
Epoch 38/43
106/106 [==============================] - 2s 16ms/step - loss: 0.3322 - val_loss: 0.2539
Epoch 39/43
106/106 [==============================] - 2s 16ms/step - loss: 0.3325 - val_loss: 0.2539
Epoch 40/43
106/106 [==============================] - 2s 16ms/step - loss: 0.3321 - val_loss: 0.2538
Epoch 41/43
106/106 [==============================] - 2s 16ms/step - loss: 0.3319 - val_loss: 0.2539
Epoch 42/43
106/106 [==============================] - 2s 16ms/step - loss: 0.3318 - val_loss: 0.2537
Epoch 43/43
106/106 [==============================] - 2s 17ms/step - loss: 0.3319 - val_loss: 0.2536
Execution time:  82.28378868103027
GRU:
Mean Absolute Error: 0.1816
Root Mean Square Error: 0.5798
Mean Square Error: 0.3362

Train RMSE: 0.580
Train MSE: 0.336
Train MAE: 0.182
###########################

MODEL:  GRU
sequence:  3h
units:  43
dropout1:  0.40519643149940265
dropout2:  0.3312343747027119
optimizer: adamax
activationDense: sigmoid
epochs: 56
batchsize: 11
validation_split: 0.1
Model: &#34;sequential_106&#34;
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
gru_44 (GRU)                 (None, 18, 43)            5934      
_________________________________________________________________
dropout_212 (Dropout)        (None, 18, 43)            0         
_________________________________________________________________
gru_45 (GRU)                 (None, 18, 43)            11352     
_________________________________________________________________
dropout_213 (Dropout)        (None, 18, 43)            0         
_________________________________________________________________
time_distributed_106 (TimeDi (None, 18, 1)             44        
=================================================================
Total params: 17,330
Trainable params: 17,330
Non-trainable params: 0
_________________________________________________________________
Epoch 1/56
325/325 [==============================] - 4s 11ms/step - loss: 0.6641 - val_loss: 0.8329
Epoch 2/56
325/325 [==============================] - 3s 8ms/step - loss: 0.5743 - val_loss: 0.8187
Epoch 3/56
325/325 [==============================] - 3s 8ms/step - loss: 0.5609 - val_loss: 0.8127
Epoch 4/56
325/325 [==============================] - 3s 9ms/step - loss: 0.5522 - val_loss: 0.8091
Epoch 5/56
325/325 [==============================] - 3s 8ms/step - loss: 0.5469 - val_loss: 0.8074
Epoch 6/56
325/325 [==============================] - 3s 8ms/step - loss: 0.5447 - val_loss: 0.8066
Epoch 7/56
325/325 [==============================] - 3s 8ms/step - loss: 0.5431 - val_loss: 0.8063
Epoch 8/56
325/325 [==============================] - 3s 8ms/step - loss: 0.5423 - val_loss: 0.8061
Epoch 9/56
325/325 [==============================] - 3s 8ms/step - loss: 0.5418 - val_loss: 0.8059
Epoch 10/56
325/325 [==============================] - 3s 9ms/step - loss: 0.5412 - val_loss: 0.8059
Epoch 11/56
325/325 [==============================] - 3s 8ms/step - loss: 0.5405 - val_loss: 0.8058
Epoch 12/56
325/325 [==============================] - 3s 8ms/step - loss: 0.5402 - val_loss: 0.8058
Epoch 13/56
325/325 [==============================] - 3s 8ms/step - loss: 0.5398 - val_loss: 0.8057
Epoch 14/56
325/325 [==============================] - 3s 8ms/step - loss: 0.5397 - val_loss: 0.8057
Epoch 15/56
325/325 [==============================] - 3s 9ms/step - loss: 0.5393 - val_loss: 0.8057
Epoch 16/56
325/325 [==============================] - 3s 9ms/step - loss: 0.5393 - val_loss: 0.8057
Epoch 17/56
325/325 [==============================] - 3s 8ms/step - loss: 0.5390 - val_loss: 0.8057
Epoch 18/56
325/325 [==============================] - 3s 8ms/step - loss: 0.5388 - val_loss: 0.8057
Epoch 19/56
325/325 [==============================] - 3s 8ms/step - loss: 0.5388 - val_loss: 0.8056
Epoch 20/56
325/325 [==============================] - 3s 8ms/step - loss: 0.5386 - val_loss: 0.8056
Epoch 21/56
325/325 [==============================] - 3s 9ms/step - loss: 0.5388 - val_loss: 0.8056
Epoch 22/56
325/325 [==============================] - 3s 8ms/step - loss: 0.5386 - val_loss: 0.8056
Epoch 23/56
325/325 [==============================] - 3s 8ms/step - loss: 0.5384 - val_loss: 0.8056
Epoch 24/56
325/325 [==============================] - 3s 8ms/step - loss: 0.5384 - val_loss: 0.8056
Epoch 25/56
325/325 [==============================] - 3s 8ms/step - loss: 0.5383 - val_loss: 0.8056
Epoch 26/56
325/325 [==============================] - 3s 8ms/step - loss: 0.5383 - val_loss: 0.8056
Epoch 27/56
325/325 [==============================] - 3s 9ms/step - loss: 0.5383 - val_loss: 0.8056
Epoch 28/56
325/325 [==============================] - 3s 8ms/step - loss: 0.5381 - val_loss: 0.8056
Epoch 29/56
325/325 [==============================] - 3s 8ms/step - loss: 0.5380 - val_loss: 0.8056
Epoch 30/56
325/325 [==============================] - 3s 8ms/step - loss: 0.5379 - val_loss: 0.8056
Epoch 31/56
325/325 [==============================] - 3s 8ms/step - loss: 0.5379 - val_loss: 0.8056
Epoch 32/56
325/325 [==============================] - 3s 8ms/step - loss: 0.5380 - val_loss: 0.8056
Epoch 33/56
325/325 [==============================] - 3s 9ms/step - loss: 0.5377 - val_loss: 0.8056
Epoch 34/56
325/325 [==============================] - 3s 8ms/step - loss: 0.5379 - val_loss: 0.8056
Epoch 35/56
325/325 [==============================] - 3s 8ms/step - loss: 0.5378 - val_loss: 0.8056
Epoch 36/56
325/325 [==============================] - 3s 8ms/step - loss: 0.5377 - val_loss: 0.8056
Epoch 37/56
325/325 [==============================] - 3s 8ms/step - loss: 0.5376 - val_loss: 0.8056
Epoch 38/56
325/325 [==============================] - 3s 8ms/step - loss: 0.5379 - val_loss: 0.8056
Epoch 39/56
325/325 [==============================] - 3s 9ms/step - loss: 0.5375 - val_loss: 0.8056
Epoch 40/56
325/325 [==============================] - 3s 8ms/step - loss: 0.5375 - val_loss: 0.8056
Epoch 41/56
325/325 [==============================] - 3s 8ms/step - loss: 0.5376 - val_loss: 0.8056
Epoch 42/56
325/325 [==============================] - 3s 8ms/step - loss: 0.5376 - val_loss: 0.8056
Epoch 43/56
325/325 [==============================] - 3s 8ms/step - loss: 0.5374 - val_loss: 0.8056
Epoch 44/56
325/325 [==============================] - 3s 8ms/step - loss: 0.5375 - val_loss: 0.8056
Epoch 45/56
325/325 [==============================] - 3s 9ms/step - loss: 0.5374 - val_loss: 0.8056
Epoch 46/56
325/325 [==============================] - 3s 8ms/step - loss: 0.5373 - val_loss: 0.8056
Epoch 47/56
325/325 [==============================] - 3s 8ms/step - loss: 0.5374 - val_loss: 0.8056
Epoch 48/56
325/325 [==============================] - 3s 8ms/step - loss: 0.5373 - val_loss: 0.8056
Epoch 49/56
325/325 [==============================] - 3s 8ms/step - loss: 0.5373 - val_loss: 0.8056
Epoch 50/56
325/325 [==============================] - 3s 9ms/step - loss: 0.5373 - val_loss: 0.8056
Epoch 51/56
325/325 [==============================] - 3s 9ms/step - loss: 0.5374 - val_loss: 0.8056
Epoch 52/56
325/325 [==============================] - 3s 8ms/step - loss: 0.5372 - val_loss: 0.8056
Epoch 53/56
325/325 [==============================] - 3s 8ms/step - loss: 0.5373 - val_loss: 0.8056
Epoch 54/56
325/325 [==============================] - 3s 8ms/step - loss: 0.5371 - val_loss: 0.8056
Epoch 55/56
325/325 [==============================] - 3s 8ms/step - loss: 0.5369 - val_loss: 0.8056
Epoch 56/56
325/325 [==============================] - 3s 9ms/step - loss: 0.5372 - val_loss: 0.8056
Execution time:  158.036141872406
GRU:
Mean Absolute Error: 0.5023
Root Mean Square Error: 0.7618
Mean Square Error: 0.5804

Train RMSE: 0.762
Train MSE: 0.580
Train MAE: 0.502
###########################

MODEL:  GRU
sequence:  3h
units:  45
dropout1:  0.11814836227952394
dropout2:  0.24325404382648977
optimizer: adamax
activationDense: sigmoid
epochs: 43
batchsize: 30
validation_split: 0.2
Model: &#34;sequential_107&#34;
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
gru_46 (GRU)                 (None, 18, 45)            6480      
_________________________________________________________________
dropout_214 (Dropout)        (None, 18, 45)            0         
_________________________________________________________________
gru_47 (GRU)                 (None, 18, 45)            12420     
_________________________________________________________________
dropout_215 (Dropout)        (None, 18, 45)            0         
_________________________________________________________________
time_distributed_107 (TimeDi (None, 18, 1)             46        
=================================================================
Total params: 18,946
Trainable params: 18,946
Non-trainable params: 0
_________________________________________________________________
Epoch 1/43
106/106 [==============================] - 3s 24ms/step - loss: 0.7588 - val_loss: 0.7736
Epoch 2/43
106/106 [==============================] - 2s 17ms/step - loss: 0.6016 - val_loss: 0.7256
Epoch 3/43
106/106 [==============================] - 2s 17ms/step - loss: 0.5838 - val_loss: 0.7114
Epoch 4/43
106/106 [==============================] - 2s 17ms/step - loss: 0.5731 - val_loss: 0.7028
Epoch 5/43
106/106 [==============================] - 2s 16ms/step - loss: 0.5658 - val_loss: 0.6968
Epoch 6/43
106/106 [==============================] - 2s 16ms/step - loss: 0.5597 - val_loss: 0.6924
Epoch 7/43
106/106 [==============================] - 2s 16ms/step - loss: 0.5549 - val_loss: 0.6891
Epoch 8/43
106/106 [==============================] - 2s 16ms/step - loss: 0.5509 - val_loss: 0.6865
Epoch 9/43
106/106 [==============================] - 2s 16ms/step - loss: 0.5478 - val_loss: 0.6844
Epoch 10/43
106/106 [==============================] - 2s 16ms/step - loss: 0.5457 - val_loss: 0.6830
Epoch 11/43
106/106 [==============================] - 2s 16ms/step - loss: 0.5441 - val_loss: 0.6819
Epoch 12/43
106/106 [==============================] - 2s 17ms/step - loss: 0.5431 - val_loss: 0.6811
Epoch 13/43
106/106 [==============================] - 2s 17ms/step - loss: 0.5421 - val_loss: 0.6804
Epoch 14/43
106/106 [==============================] - 2s 16ms/step - loss: 0.5413 - val_loss: 0.6799
Epoch 15/43
106/106 [==============================] - 2s 16ms/step - loss: 0.5407 - val_loss: 0.6795
Epoch 16/43
106/106 [==============================] - 2s 16ms/step - loss: 0.5400 - val_loss: 0.6793
Epoch 17/43
106/106 [==============================] - 2s 16ms/step - loss: 0.5396 - val_loss: 0.6791
Epoch 18/43
106/106 [==============================] - 2s 16ms/step - loss: 0.5392 - val_loss: 0.6789
Epoch 19/43
106/106 [==============================] - 2s 16ms/step - loss: 0.5388 - val_loss: 0.6788
Epoch 20/43
106/106 [==============================] - 2s 16ms/step - loss: 0.5384 - val_loss: 0.6787
Epoch 21/43
106/106 [==============================] - 2s 17ms/step - loss: 0.5380 - val_loss: 0.6785
Epoch 22/43
106/106 [==============================] - 2s 18ms/step - loss: 0.5380 - val_loss: 0.6785
Epoch 23/43
106/106 [==============================] - 2s 16ms/step - loss: 0.5377 - val_loss: 0.6784
Epoch 24/43
106/106 [==============================] - 2s 16ms/step - loss: 0.5377 - val_loss: 0.6784
Epoch 25/43
106/106 [==============================] - 2s 16ms/step - loss: 0.5373 - val_loss: 0.6784
Epoch 26/43
106/106 [==============================] - 2s 16ms/step - loss: 0.5373 - val_loss: 0.6784
Epoch 27/43
106/106 [==============================] - 2s 16ms/step - loss: 0.5371 - val_loss: 0.6783
Epoch 28/43
106/106 [==============================] - 2s 16ms/step - loss: 0.5370 - val_loss: 0.6783
Epoch 29/43
106/106 [==============================] - 2s 16ms/step - loss: 0.5369 - val_loss: 0.6783
Epoch 30/43
106/106 [==============================] - 2s 16ms/step - loss: 0.5368 - val_loss: 0.6784
Epoch 31/43
106/106 [==============================] - 2s 17ms/step - loss: 0.5367 - val_loss: 0.6783
Epoch 32/43
106/106 [==============================] - 2s 16ms/step - loss: 0.5365 - val_loss: 0.6784
Epoch 33/43
106/106 [==============================] - 2s 16ms/step - loss: 0.5365 - val_loss: 0.6783
Epoch 34/43
106/106 [==============================] - 2s 16ms/step - loss: 0.5363 - val_loss: 0.6783
Epoch 35/43
106/106 [==============================] - 2s 16ms/step - loss: 0.5363 - val_loss: 0.6783
Epoch 36/43
106/106 [==============================] - 2s 17ms/step - loss: 0.5363 - val_loss: 0.6782
Epoch 37/43
106/106 [==============================] - 2s 16ms/step - loss: 0.5362 - val_loss: 0.6783
Epoch 38/43
106/106 [==============================] - 2s 16ms/step - loss: 0.5362 - val_loss: 0.6783
Epoch 39/43
106/106 [==============================] - 2s 16ms/step - loss: 0.5363 - val_loss: 0.6782
Epoch 40/43
106/106 [==============================] - 2s 17ms/step - loss: 0.5360 - val_loss: 0.6782
Epoch 41/43
106/106 [==============================] - 2s 16ms/step - loss: 0.5360 - val_loss: 0.6783
Epoch 42/43
106/106 [==============================] - 2s 16ms/step - loss: 0.5360 - val_loss: 0.6783
Epoch 43/43
106/106 [==============================] - 2s 16ms/step - loss: 0.5360 - val_loss: 0.6782
Execution time:  82.04746532440186
GRU:
Mean Absolute Error: 0.5006
Root Mean Square Error: 0.7582
Mean Square Error: 0.5748

Train RMSE: 0.758
Train MSE: 0.575
Train MAE: 0.501
###########################

MODEL:  GRU
sequence:  6h
units:  43
dropout1:  0.40519643149940265
dropout2:  0.3312343747027119
optimizer: adam
activationDense: tanh
epochs: 56
batchsize: 11
validation_split: 0.1
Model: &#34;sequential_108&#34;
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
gru_48 (GRU)                 (None, 36, 43)            5934      
_________________________________________________________________
dropout_216 (Dropout)        (None, 36, 43)            0         
_________________________________________________________________
gru_49 (GRU)                 (None, 36, 43)            11352     
_________________________________________________________________
dropout_217 (Dropout)        (None, 36, 43)            0         
_________________________________________________________________
time_distributed_108 (TimeDi (None, 36, 1)             44        
=================================================================
Total params: 17,330
Trainable params: 17,330
Non-trainable params: 0
_________________________________________________________________
Epoch 1/56
324/324 [==============================] - 10s 30ms/step - loss: 0.4704 - val_loss: 0.2691
Epoch 2/56
324/324 [==============================] - 9s 27ms/step - loss: 0.4305 - val_loss: 0.2520
Epoch 3/56
324/324 [==============================] - 9s 28ms/step - loss: 0.4236 - val_loss: 0.2456
Epoch 4/56
324/324 [==============================] - 9s 28ms/step - loss: 0.4201 - val_loss: 0.2512
Epoch 5/56
324/324 [==============================] - 9s 27ms/step - loss: 0.4183 - val_loss: 0.2509
Epoch 6/56
324/324 [==============================] - 9s 28ms/step - loss: 0.4168 - val_loss: 0.2521
Epoch 7/56
324/324 [==============================] - 9s 27ms/step - loss: 0.4166 - val_loss: 0.2509
Epoch 8/56
324/324 [==============================] - 9s 27ms/step - loss: 0.4151 - val_loss: 0.2512
Epoch 9/56
324/324 [==============================] - 9s 27ms/step - loss: 0.4151 - val_loss: 0.2528
Epoch 10/56
324/324 [==============================] - 9s 27ms/step - loss: 0.4141 - val_loss: 0.2517
Epoch 11/56
324/324 [==============================] - 9s 27ms/step - loss: 0.4141 - val_loss: 0.2535
Epoch 12/56
324/324 [==============================] - 9s 27ms/step - loss: 0.4142 - val_loss: 0.2543
Epoch 13/56
324/324 [==============================] - 9s 27ms/step - loss: 0.4128 - val_loss: 0.2551
Epoch 14/56
324/324 [==============================] - 9s 27ms/step - loss: 0.4123 - val_loss: 0.2537
Epoch 15/56
324/324 [==============================] - 9s 27ms/step - loss: 0.4121 - val_loss: 0.2560
Epoch 16/56
324/324 [==============================] - 9s 27ms/step - loss: 0.4116 - val_loss: 0.2564
Epoch 17/56
324/324 [==============================] - 9s 28ms/step - loss: 0.4105 - val_loss: 0.2552
Epoch 18/56
324/324 [==============================] - 9s 27ms/step - loss: 0.4099 - val_loss: 0.2565
Epoch 19/56
324/324 [==============================] - 9s 27ms/step - loss: 0.4098 - val_loss: 0.2547
Epoch 20/56
324/324 [==============================] - 9s 27ms/step - loss: 0.4089 - val_loss: 0.2543
Epoch 21/56
324/324 [==============================] - 9s 27ms/step - loss: 0.4089 - val_loss: 0.2576
Epoch 22/56
324/324 [==============================] - 9s 27ms/step - loss: 0.4086 - val_loss: 0.2563
Epoch 23/56
324/324 [==============================] - 9s 27ms/step - loss: 0.4083 - val_loss: 0.2583
Epoch 24/56
324/324 [==============================] - 9s 27ms/step - loss: 0.4071 - val_loss: 0.2566
Epoch 25/56
324/324 [==============================] - 9s 27ms/step - loss: 0.4065 - val_loss: 0.2549
Epoch 26/56
324/324 [==============================] - 9s 27ms/step - loss: 0.4062 - val_loss: 0.2554
Epoch 27/56
324/324 [==============================] - 9s 27ms/step - loss: 0.4054 - val_loss: 0.2563
Epoch 28/56
324/324 [==============================] - 9s 27ms/step - loss: 0.4050 - val_loss: 0.2560
Epoch 29/56
324/324 [==============================] - 9s 27ms/step - loss: 0.4049 - val_loss: 0.2556
Epoch 30/56
324/324 [==============================] - 9s 28ms/step - loss: 0.4041 - val_loss: 0.2602
Epoch 31/56
324/324 [==============================] - 9s 27ms/step - loss: 0.4032 - val_loss: 0.2601
Epoch 32/56
324/324 [==============================] - 9s 27ms/step - loss: 0.4031 - val_loss: 0.2565
Epoch 33/56
324/324 [==============================] - 9s 27ms/step - loss: 0.4024 - val_loss: 0.2602
Epoch 34/56
324/324 [==============================] - 9s 27ms/step - loss: 0.4016 - val_loss: 0.2537
Epoch 35/56
324/324 [==============================] - 9s 27ms/step - loss: 0.4010 - val_loss: 0.2532
Epoch 36/56
324/324 [==============================] - 9s 27ms/step - loss: 0.4012 - val_loss: 0.2565
Epoch 37/56
324/324 [==============================] - 9s 27ms/step - loss: 0.4006 - val_loss: 0.2530
Epoch 38/56
324/324 [==============================] - 9s 27ms/step - loss: 0.3987 - val_loss: 0.2525
Epoch 39/56
324/324 [==============================] - 9s 27ms/step - loss: 0.3985 - val_loss: 0.2504
Epoch 40/56
324/324 [==============================] - 9s 27ms/step - loss: 0.3956 - val_loss: 0.2468
Epoch 41/56
324/324 [==============================] - 9s 28ms/step - loss: 0.3955 - val_loss: 0.2506
Epoch 42/56
324/324 [==============================] - 9s 27ms/step - loss: 0.3958 - val_loss: 0.2483
Epoch 43/56
324/324 [==============================] - 9s 27ms/step - loss: 0.3956 - val_loss: 0.2519
Epoch 44/56
324/324 [==============================] - 9s 27ms/step - loss: 0.3955 - val_loss: 0.2474
Epoch 45/56
324/324 [==============================] - 9s 27ms/step - loss: 0.3929 - val_loss: 0.2450
Epoch 46/56
324/324 [==============================] - 9s 27ms/step - loss: 0.3921 - val_loss: 0.2412
Epoch 47/56
324/324 [==============================] - 9s 27ms/step - loss: 0.3923 - val_loss: 0.2446
Epoch 48/56
324/324 [==============================] - 9s 27ms/step - loss: 0.3922 - val_loss: 0.2434
Epoch 49/56
324/324 [==============================] - 9s 27ms/step - loss: 0.3901 - val_loss: 0.2404
Epoch 50/56
324/324 [==============================] - 9s 27ms/step - loss: 0.3919 - val_loss: 0.2447
Epoch 51/56
324/324 [==============================] - 9s 28ms/step - loss: 0.3896 - val_loss: 0.2464
Epoch 52/56
324/324 [==============================] - 9s 27ms/step - loss: 0.3902 - val_loss: 0.2439
Epoch 53/56
324/324 [==============================] - 9s 27ms/step - loss: 0.3897 - val_loss: 0.2442
Epoch 54/56
324/324 [==============================] - 9s 27ms/step - loss: 0.3885 - val_loss: 0.2431
Epoch 55/56
324/324 [==============================] - 9s 27ms/step - loss: 0.3882 - val_loss: 0.2437
Epoch 56/56
324/324 [==============================] - 9s 27ms/step - loss: 0.3873 - val_loss: 0.2418
Execution time:  501.45494747161865
GRU:
Mean Absolute Error: 0.2520
Root Mean Square Error: 0.6385
Mean Square Error: 0.4077

Train RMSE: 0.638
Train MSE: 0.408
Train MAE: 0.252
###########################

MODEL:  GRU
sequence:  6h
units:  45
dropout1:  0.11814836227952394
dropout2:  0.24325404382648977
optimizer: adam
activationDense: tanh
epochs: 43
batchsize: 30
validation_split: 0.2
Model: &#34;sequential_109&#34;
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
gru_50 (GRU)                 (None, 36, 45)            6480      
_________________________________________________________________
dropout_218 (Dropout)        (None, 36, 45)            0         
_________________________________________________________________
gru_51 (GRU)                 (None, 36, 45)            12420     
_________________________________________________________________
dropout_219 (Dropout)        (None, 36, 45)            0         
_________________________________________________________________
time_distributed_109 (TimeDi (None, 36, 1)             46        
=================================================================
Total params: 18,946
Trainable params: 18,946
Non-trainable params: 0
_________________________________________________________________
Epoch 1/43
106/106 [==============================] - 4s 38ms/step - loss: 0.4937 - val_loss: 0.3290
Epoch 2/43
106/106 [==============================] - 3s 30ms/step - loss: 0.4247 - val_loss: 0.3213
Epoch 3/43
106/106 [==============================] - 3s 30ms/step - loss: 0.4183 - val_loss: 0.3168
Epoch 4/43
106/106 [==============================] - 3s 33ms/step - loss: 0.4141 - val_loss: 0.3144
Epoch 5/43
106/106 [==============================] - 3s 31ms/step - loss: 0.4114 - val_loss: 0.3121
Epoch 6/43
106/106 [==============================] - 3s 31ms/step - loss: 0.4089 - val_loss: 0.3108
Epoch 7/43
106/106 [==============================] - 3s 31ms/step - loss: 0.4075 - val_loss: 0.3106
Epoch 8/43
106/106 [==============================] - 3s 31ms/step - loss: 0.4062 - val_loss: 0.3105
Epoch 9/43
106/106 [==============================] - 3s 32ms/step - loss: 0.4055 - val_loss: 0.3106
Epoch 10/43
106/106 [==============================] - 3s 31ms/step - loss: 0.4048 - val_loss: 0.3107
Epoch 11/43
106/106 [==============================] - 3s 31ms/step - loss: 0.4046 - val_loss: 0.3109
Epoch 12/43
106/106 [==============================] - 3s 31ms/step - loss: 0.4038 - val_loss: 0.3110
Epoch 13/43
106/106 [==============================] - 3s 31ms/step - loss: 0.4034 - val_loss: 0.3109
Epoch 14/43
106/106 [==============================] - 3s 32ms/step - loss: 0.4029 - val_loss: 0.3110
Epoch 15/43
106/106 [==============================] - 3s 31ms/step - loss: 0.4026 - val_loss: 0.3115
Epoch 16/43
106/106 [==============================] - 3s 31ms/step - loss: 0.4020 - val_loss: 0.3121
Epoch 17/43
106/106 [==============================] - 3s 31ms/step - loss: 0.4015 - val_loss: 0.3125
Epoch 18/43
106/106 [==============================] - 3s 32ms/step - loss: 0.4012 - val_loss: 0.3132
Epoch 19/43
106/106 [==============================] - 3s 31ms/step - loss: 0.4006 - val_loss: 0.3133
Epoch 20/43
106/106 [==============================] - 3s 31ms/step - loss: 0.4003 - val_loss: 0.3137
Epoch 21/43
106/106 [==============================] - 3s 31ms/step - loss: 0.3997 - val_loss: 0.3138
Epoch 22/43
106/106 [==============================] - 3s 31ms/step - loss: 0.3997 - val_loss: 0.3141
Epoch 23/43
106/106 [==============================] - 3s 32ms/step - loss: 0.3993 - val_loss: 0.3141
Epoch 24/43
106/106 [==============================] - 3s 30ms/step - loss: 0.3991 - val_loss: 0.3145
Epoch 25/43
106/106 [==============================] - 3s 30ms/step - loss: 0.3987 - val_loss: 0.3143
Epoch 26/43
106/106 [==============================] - 3s 30ms/step - loss: 0.3985 - val_loss: 0.3145
Epoch 27/43
106/106 [==============================] - 3s 30ms/step - loss: 0.3984 - val_loss: 0.3149
Epoch 28/43
106/106 [==============================] - 3s 32ms/step - loss: 0.3980 - val_loss: 0.3154
Epoch 29/43
106/106 [==============================] - 3s 31ms/step - loss: 0.3977 - val_loss: 0.3159
Epoch 30/43
106/106 [==============================] - 3s 30ms/step - loss: 0.3975 - val_loss: 0.3151
Epoch 31/43
106/106 [==============================] - 3s 30ms/step - loss: 0.3973 - val_loss: 0.3167
Epoch 32/43
106/106 [==============================] - 3s 30ms/step - loss: 0.3968 - val_loss: 0.3156
Epoch 33/43
106/106 [==============================] - 3s 32ms/step - loss: 0.3969 - val_loss: 0.3173
Epoch 34/43
106/106 [==============================] - 3s 30ms/step - loss: 0.3962 - val_loss: 0.3157
Epoch 35/43
106/106 [==============================] - 3s 30ms/step - loss: 0.3961 - val_loss: 0.3176
Epoch 36/43
106/106 [==============================] - 3s 30ms/step - loss: 0.3955 - val_loss: 0.3171
Epoch 37/43
106/106 [==============================] - 3s 30ms/step - loss: 0.3960 - val_loss: 0.3178
Epoch 38/43
106/106 [==============================] - 3s 32ms/step - loss: 0.3955 - val_loss: 0.3172
Epoch 39/43
106/106 [==============================] - 3s 30ms/step - loss: 0.3951 - val_loss: 0.3186
Epoch 40/43
106/106 [==============================] - 3s 31ms/step - loss: 0.3944 - val_loss: 0.3187
Epoch 41/43
106/106 [==============================] - 3s 30ms/step - loss: 0.3939 - val_loss: 0.3196
Epoch 42/43
106/106 [==============================] - 3s 31ms/step - loss: 0.3938 - val_loss: 0.3194
Epoch 43/43
106/106 [==============================] - 3s 32ms/step - loss: 0.3929 - val_loss: 0.3201
Execution time:  148.31544280052185
GRU:
Mean Absolute Error: 0.2127
Root Mean Square Error: 0.6202
Mean Square Error: 0.3846

Train RMSE: 0.620
Train MSE: 0.385
Train MAE: 0.213
###########################

MODEL:  GRU
sequence:  6h
units:  43
dropout1:  0.40519643149940265
dropout2:  0.3312343747027119
optimizer: adam
activationDense: sigmoid
epochs: 56
batchsize: 11
validation_split: 0.1
Model: &#34;sequential_110&#34;
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
gru_52 (GRU)                 (None, 36, 43)            5934      
_________________________________________________________________
dropout_220 (Dropout)        (None, 36, 43)            0         
_________________________________________________________________
gru_53 (GRU)                 (None, 36, 43)            11352     
_________________________________________________________________
dropout_221 (Dropout)        (None, 36, 43)            0         
_________________________________________________________________
time_distributed_110 (TimeDi (None, 36, 1)             44        
=================================================================
Total params: 17,330
Trainable params: 17,330
Non-trainable params: 0
_________________________________________________________________
Epoch 1/56
324/324 [==============================] - 10s 30ms/step - loss: 0.6489 - val_loss: 0.8134
Epoch 2/56
324/324 [==============================] - 9s 27ms/step - loss: 0.5934 - val_loss: 0.8071
Epoch 3/56
324/324 [==============================] - 9s 27ms/step - loss: 0.5865 - val_loss: 0.8057
Epoch 4/56
324/324 [==============================] - 9s 27ms/step - loss: 0.5840 - val_loss: 0.8053
Epoch 5/56
324/324 [==============================] - 9s 28ms/step - loss: 0.5829 - val_loss: 0.8051
Epoch 6/56
324/324 [==============================] - 9s 27ms/step - loss: 0.5826 - val_loss: 0.8051
Epoch 7/56
324/324 [==============================] - 9s 27ms/step - loss: 0.5822 - val_loss: 0.8050
Epoch 8/56
324/324 [==============================] - 9s 27ms/step - loss: 0.5819 - val_loss: 0.8050
Epoch 9/56
324/324 [==============================] - 9s 27ms/step - loss: 0.5813 - val_loss: 0.8050
Epoch 10/56
324/324 [==============================] - 9s 27ms/step - loss: 0.5807 - val_loss: 0.8050
Epoch 11/56
324/324 [==============================] - 9s 27ms/step - loss: 0.5805 - val_loss: 0.8050
Epoch 12/56
324/324 [==============================] - 9s 28ms/step - loss: 0.5798 - val_loss: 0.8050
Epoch 13/56
324/324 [==============================] - 9s 27ms/step - loss: 0.5795 - val_loss: 0.8050
Epoch 14/56
324/324 [==============================] - 9s 27ms/step - loss: 0.5782 - val_loss: 0.8050
Epoch 15/56
324/324 [==============================] - 9s 27ms/step - loss: 0.5774 - val_loss: 0.8050
Epoch 16/56
324/324 [==============================] - 9s 27ms/step - loss: 0.5777 - val_loss: 0.8050
Epoch 17/56
324/324 [==============================] - 9s 27ms/step - loss: 0.5770 - val_loss: 0.8050
Epoch 18/56
324/324 [==============================] - 9s 27ms/step - loss: 0.5768 - val_loss: 0.8050
Epoch 19/56
324/324 [==============================] - 9s 27ms/step - loss: 0.5764 - val_loss: 0.8050
Epoch 20/56
324/324 [==============================] - 9s 27ms/step - loss: 0.5760 - val_loss: 0.8050
Epoch 21/56
324/324 [==============================] - 9s 27ms/step - loss: 0.5760 - val_loss: 0.8050
Epoch 22/56
324/324 [==============================] - 9s 27ms/step - loss: 0.5753 - val_loss: 0.8050
Epoch 23/56
324/324 [==============================] - 9s 27ms/step - loss: 0.5755 - val_loss: 0.8050
Epoch 24/56
324/324 [==============================] - 9s 27ms/step - loss: 0.5745 - val_loss: 0.8050
Epoch 25/56
324/324 [==============================] - 9s 27ms/step - loss: 0.5745 - val_loss: 0.8049
Epoch 26/56
324/324 [==============================] - 9s 27ms/step - loss: 0.5744 - val_loss: 0.8049
Epoch 27/56
324/324 [==============================] - 9s 27ms/step - loss: 0.5738 - val_loss: 0.8049
Epoch 28/56
324/324 [==============================] - 9s 27ms/step - loss: 0.5729 - val_loss: 0.8049
Epoch 29/56
324/324 [==============================] - 9s 27ms/step - loss: 0.5732 - val_loss: 0.8049
Epoch 30/56
324/324 [==============================] - 9s 27ms/step - loss: 0.5724 - val_loss: 0.8049
Epoch 31/56
324/324 [==============================] - 9s 27ms/step - loss: 0.5718 - val_loss: 0.8049
Epoch 32/56
324/324 [==============================] - 9s 27ms/step - loss: 0.5719 - val_loss: 0.8049
Epoch 33/56
324/324 [==============================] - 9s 27ms/step - loss: 0.5715 - val_loss: 0.8049
Epoch 34/56
324/324 [==============================] - 9s 27ms/step - loss: 0.5714 - val_loss: 0.8049
Epoch 35/56
324/324 [==============================] - 9s 27ms/step - loss: 0.5708 - val_loss: 0.8049
Epoch 36/56
324/324 [==============================] - 9s 27ms/step - loss: 0.5710 - val_loss: 0.8049
Epoch 37/56
324/324 [==============================] - 9s 27ms/step - loss: 0.5707 - val_loss: 0.8049
Epoch 38/56
324/324 [==============================] - 9s 27ms/step - loss: 0.5705 - val_loss: 0.8049
Epoch 39/56
324/324 [==============================] - 9s 27ms/step - loss: 0.5699 - val_loss: 0.8049
Epoch 40/56
324/324 [==============================] - 9s 27ms/step - loss: 0.5693 - val_loss: 0.8049
Epoch 41/56
324/324 [==============================] - 9s 27ms/step - loss: 0.5692 - val_loss: 0.8049
Epoch 42/56
324/324 [==============================] - 9s 27ms/step - loss: 0.5686 - val_loss: 0.8049
Epoch 43/56
324/324 [==============================] - 9s 27ms/step - loss: 0.5693 - val_loss: 0.8049
Epoch 44/56
324/324 [==============================] - 9s 27ms/step - loss: 0.5690 - val_loss: 0.8049
Epoch 45/56
324/324 [==============================] - 9s 28ms/step - loss: 0.5694 - val_loss: 0.8049
Epoch 46/56
324/324 [==============================] - 9s 27ms/step - loss: 0.5685 - val_loss: 0.8049
Epoch 47/56
324/324 [==============================] - 9s 27ms/step - loss: 0.5681 - val_loss: 0.8049
Epoch 48/56
324/324 [==============================] - 9s 27ms/step - loss: 0.5670 - val_loss: 0.8049
Epoch 49/56
324/324 [==============================] - 9s 26ms/step - loss: 0.5669 - val_loss: 0.8049
Epoch 50/56
324/324 [==============================] - 9s 27ms/step - loss: 0.5670 - val_loss: 0.8049
Epoch 51/56
324/324 [==============================] - 9s 27ms/step - loss: 0.5660 - val_loss: 0.8049
Epoch 52/56
324/324 [==============================] - 9s 27ms/step - loss: 0.5661 - val_loss: 0.8049
Epoch 53/56
324/324 [==============================] - 9s 27ms/step - loss: 0.5681 - val_loss: 0.8049
Epoch 54/56
324/324 [==============================] - 9s 27ms/step - loss: 0.5669 - val_loss: 0.8049
Epoch 55/56
324/324 [==============================] - 9s 27ms/step - loss: 0.5668 - val_loss: 0.8049
Epoch 56/56
324/324 [==============================] - 9s 27ms/step - loss: 0.5663 - val_loss: 0.8049
Execution time:  498.457377910614
GRU:
Mean Absolute Error: 0.5423
Root Mean Square Error: 0.8088
Mean Square Error: 0.6542

Train RMSE: 0.809
Train MSE: 0.654
Train MAE: 0.542
###########################

MODEL:  GRU
sequence:  6h
units:  45
dropout1:  0.11814836227952394
dropout2:  0.24325404382648977
optimizer: adam
activationDense: sigmoid
epochs: 43
batchsize: 30
validation_split: 0.2
Model: &#34;sequential_111&#34;
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
gru_54 (GRU)                 (None, 36, 45)            6480      
_________________________________________________________________
dropout_222 (Dropout)        (None, 36, 45)            0         
_________________________________________________________________
gru_55 (GRU)                 (None, 36, 45)            12420     
_________________________________________________________________
dropout_223 (Dropout)        (None, 36, 45)            0         
_________________________________________________________________
time_distributed_111 (TimeDi (None, 36, 1)             46        
=================================================================
Total params: 18,946
Trainable params: 18,946
Non-trainable params: 0
_________________________________________________________________
Epoch 1/43
106/106 [==============================] - 4s 37ms/step - loss: 0.7060 - val_loss: 0.7398
Epoch 2/43
106/106 [==============================] - 3s 29ms/step - loss: 0.6100 - val_loss: 0.7232
Epoch 3/43
106/106 [==============================] - ETA: 0s - loss: 0.597 - 3s 30ms/step - loss: 0.5971 - val_loss: 0.7138
Epoch 4/43
106/106 [==============================] - 3s 30ms/step - loss: 0.5900 - val_loss: 0.7090
Epoch 5/43
106/106 [==============================] - 3s 32ms/step - loss: 0.5857 - val_loss: 0.7072
Epoch 6/43
106/106 [==============================] - 3s 30ms/step - loss: 0.5832 - val_loss: 0.7056
Epoch 7/43
106/106 [==============================] - 3s 30ms/step - loss: 0.5816 - val_loss: 0.7046
Epoch 8/43
106/106 [==============================] - 3s 30ms/step - loss: 0.5805 - val_loss: 0.7042
Epoch 9/43
106/106 [==============================] - 3s 30ms/step - loss: 0.5797 - val_loss: 0.7039
Epoch 10/43
106/106 [==============================] - 3s 32ms/step - loss: 0.5790 - val_loss: 0.7041
Epoch 11/43
106/106 [==============================] - 3s 30ms/step - loss: 0.5784 - val_loss: 0.7044
Epoch 12/43
106/106 [==============================] - 3s 30ms/step - loss: 0.5780 - val_loss: 0.7049
Epoch 13/43
106/106 [==============================] - 3s 30ms/step - loss: 0.5777 - val_loss: 0.7056
Epoch 14/43
106/106 [==============================] - 3s 30ms/step - loss: 0.5774 - val_loss: 0.7061
Epoch 15/43
106/106 [==============================] - 3s 32ms/step - loss: 0.5771 - val_loss: 0.7074
Epoch 16/43
106/106 [==============================] - 3s 30ms/step - loss: 0.5768 - val_loss: 0.7091
Epoch 17/43
106/106 [==============================] - 3s 30ms/step - loss: 0.5764 - val_loss: 0.7115
Epoch 18/43
106/106 [==============================] - 3s 30ms/step - loss: 0.5763 - val_loss: 0.7134s - loss: 0.5 - ETA: 0s - los
Epoch 19/43
106/106 [==============================] - 3s 30ms/step - loss: 0.5756 - val_loss: 0.7141
Epoch 20/43
106/106 [==============================] - 3s 31ms/step - loss: 0.5753 - val_loss: 0.7143
Epoch 21/43
106/106 [==============================] - 3s 30ms/step - loss: 0.5748 - val_loss: 0.7132
Epoch 22/43
106/106 [==============================] - 3s 30ms/step - loss: 0.5742 - val_loss: 0.7119
Epoch 23/43
106/106 [==============================] - 3s 30ms/step - loss: 0.5734 - val_loss: 0.7117
Epoch 24/43
106/106 [==============================] - 3s 30ms/step - loss: 0.5732 - val_loss: 0.7112
Epoch 25/43
106/106 [==============================] - 3s 31ms/step - loss: 0.5730 - val_loss: 0.7114
Epoch 26/43
106/106 [==============================] - 3s 30ms/step - loss: 0.5728 - val_loss: 0.7128
Epoch 27/43
106/106 [==============================] - 3s 30ms/step - loss: 0.5727 - val_loss: 0.7118
Epoch 28/43
106/106 [==============================] - 3s 30ms/step - loss: 0.5725 - val_loss: 0.7130
Epoch 29/43
106/106 [==============================] - 3s 30ms/step - loss: 0.5723 - val_loss: 0.7125
Epoch 30/43
106/106 [==============================] - 3s 32ms/step - loss: 0.5722 - val_loss: 0.7131
Epoch 31/43
106/106 [==============================] - 3s 30ms/step - loss: 0.5721 - val_loss: 0.7133
Epoch 32/43
106/106 [==============================] - 3s 31ms/step - loss: 0.5718 - val_loss: 0.7134
Epoch 33/43
106/106 [==============================] - 3s 31ms/step - loss: 0.5720 - val_loss: 0.7131A: 0s -
Epoch 34/43
106/106 [==============================] - 3s 31ms/step - loss: 0.5717 - val_loss: 0.7136
Epoch 35/43
106/106 [==============================] - 3s 32ms/step - loss: 0.5716 - val_loss: 0.7138
Epoch 36/43
106/106 [==============================] - 3s 31ms/step - loss: 0.5714 - val_loss: 0.7130
Epoch 37/43
106/106 [==============================] - 3s 31ms/step - loss: 0.5714 - val_loss: 0.7128
Epoch 38/43
106/106 [==============================] - 3s 31ms/step - loss: 0.5711 - val_loss: 0.7133
Epoch 39/43
106/106 [==============================] - 3s 32ms/step - loss: 0.5713 - val_loss: 0.7132
Epoch 40/43
106/106 [==============================] - 3s 31ms/step - loss: 0.5710 - val_loss: 0.7118
Epoch 41/43
106/106 [==============================] - 3s 31ms/step - loss: 0.5708 - val_loss: 0.7128
Epoch 42/43
106/106 [==============================] - 3s 31ms/step - loss: 0.5706 - val_loss: 0.7114
Epoch 43/43
106/106 [==============================] - 3s 31ms/step - loss: 0.5701 - val_loss: 0.7129
Execution time:  146.09937977790833
GRU:
Mean Absolute Error: 0.5375
Root Mean Square Error: 0.8134
Mean Square Error: 0.6616

Train RMSE: 0.813
Train MSE: 0.662
Train MAE: 0.537
###########################

MODEL:  GRU
sequence:  6h
units:  43
dropout1:  0.40519643149940265
dropout2:  0.3312343747027119
optimizer: adadelta
activationDense: tanh
epochs: 56
batchsize: 11
validation_split: 0.1
Model: &#34;sequential_112&#34;
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
gru_56 (GRU)                 (None, 36, 43)            5934      
_________________________________________________________________
dropout_224 (Dropout)        (None, 36, 43)            0         
_________________________________________________________________
gru_57 (GRU)                 (None, 36, 43)            11352     
_________________________________________________________________
dropout_225 (Dropout)        (None, 36, 43)            0         
_________________________________________________________________
time_distributed_112 (TimeDi (None, 36, 1)             44        
=================================================================
Total params: 17,330
Trainable params: 17,330
Non-trainable params: 0
_________________________________________________________________
Epoch 1/56
324/324 [==============================] - 9s 29ms/step - loss: 0.7025 - val_loss: 0.7929
Epoch 2/56
324/324 [==============================] - 9s 27ms/step - loss: 0.7001 - val_loss: 0.7883
Epoch 3/56
324/324 [==============================] - 9s 27ms/step - loss: 0.6976 - val_loss: 0.7835
Epoch 4/56
324/324 [==============================] - 9s 27ms/step - loss: 0.6950 - val_loss: 0.7787
Epoch 5/56
324/324 [==============================] - 9s 27ms/step - loss: 0.6925 - val_loss: 0.7737
Epoch 6/56
324/324 [==============================] - 9s 27ms/step - loss: 0.6899 - val_loss: 0.7685
Epoch 7/56
324/324 [==============================] - 9s 27ms/step - loss: 0.6873 - val_loss: 0.7633
Epoch 8/56
324/324 [==============================] - 9s 27ms/step - loss: 0.6845 - val_loss: 0.7579
Epoch 9/56
324/324 [==============================] - 9s 27ms/step - loss: 0.6818 - val_loss: 0.7524
Epoch 10/56
324/324 [==============================] - 9s 27ms/step - loss: 0.6790 - val_loss: 0.7468
Epoch 11/56
324/324 [==============================] - 9s 27ms/step - loss: 0.6763 - val_loss: 0.7410
Epoch 12/56
324/324 [==============================] - 9s 27ms/step - loss: 0.6733 - val_loss: 0.7352
Epoch 13/56
324/324 [==============================] - 9s 27ms/step - loss: 0.6703 - val_loss: 0.7292
Epoch 14/56
324/324 [==============================] - 9s 27ms/step - loss: 0.6676 - val_loss: 0.7231
Epoch 15/56
324/324 [==============================] - 9s 27ms/step - loss: 0.6646 - val_loss: 0.7169
Epoch 16/56
324/324 [==============================] - 9s 27ms/step - loss: 0.6614 - val_loss: 0.7106
Epoch 17/56
324/324 [==============================] - 9s 27ms/step - loss: 0.6585 - val_loss: 0.7043
Epoch 18/56
324/324 [==============================] - 9s 27ms/step - loss: 0.6552 - val_loss: 0.6978
Epoch 19/56
324/324 [==============================] - 9s 27ms/step - loss: 0.6523 - val_loss: 0.6913
Epoch 20/56
324/324 [==============================] - 9s 27ms/step - loss: 0.6492 - val_loss: 0.6846
Epoch 21/56
324/324 [==============================] - 9s 27ms/step - loss: 0.6459 - val_loss: 0.6778
Epoch 22/56
324/324 [==============================] - 9s 27ms/step - loss: 0.6429 - val_loss: 0.6709
Epoch 23/56
324/324 [==============================] - 9s 27ms/step - loss: 0.6396 - val_loss: 0.6638
Epoch 24/56
324/324 [==============================] - 9s 27ms/step - loss: 0.6362 - val_loss: 0.6566
Epoch 25/56
324/324 [==============================] - 9s 27ms/step - loss: 0.6329 - val_loss: 0.6493
Epoch 26/56
324/324 [==============================] - 9s 27ms/step - loss: 0.6295 - val_loss: 0.6417
Epoch 27/56
324/324 [==============================] - 9s 27ms/step - loss: 0.6257 - val_loss: 0.6340
Epoch 28/56
324/324 [==============================] - 9s 27ms/step - loss: 0.6223 - val_loss: 0.6261
Epoch 29/56
324/324 [==============================] - 9s 27ms/step - loss: 0.6184 - val_loss: 0.6180
Epoch 30/56
324/324 [==============================] - 9s 27ms/step - loss: 0.6148 - val_loss: 0.6098
Epoch 31/56
324/324 [==============================] - 9s 27ms/step - loss: 0.6109 - val_loss: 0.6013
Epoch 32/56
324/324 [==============================] - 9s 27ms/step - loss: 0.6072 - val_loss: 0.5927
Epoch 33/56
324/324 [==============================] - 9s 27ms/step - loss: 0.6034 - val_loss: 0.5839
Epoch 34/56
324/324 [==============================] - 9s 27ms/step - loss: 0.5992 - val_loss: 0.5749
Epoch 35/56
324/324 [==============================] - 9s 27ms/step - loss: 0.5952 - val_loss: 0.5658
Epoch 36/56
324/324 [==============================] - 9s 27ms/step - loss: 0.5909 - val_loss: 0.5565
Epoch 37/56
324/324 [==============================] - 9s 27ms/step - loss: 0.5869 - val_loss: 0.5471
Epoch 38/56
324/324 [==============================] - 9s 27ms/step - loss: 0.5827 - val_loss: 0.5376
Epoch 39/56
324/324 [==============================] - 9s 27ms/step - loss: 0.5786 - val_loss: 0.5281
Epoch 40/56
324/324 [==============================] - 9s 27ms/step - loss: 0.5740 - val_loss: 0.5184
Epoch 41/56
324/324 [==============================] - 9s 27ms/step - loss: 0.5701 - val_loss: 0.5088
Epoch 42/56
324/324 [==============================] - 9s 27ms/step - loss: 0.5658 - val_loss: 0.4991
Epoch 43/56
324/324 [==============================] - 9s 27ms/step - loss: 0.5617 - val_loss: 0.4894
Epoch 44/56
324/324 [==============================] - 9s 27ms/step - loss: 0.5571 - val_loss: 0.4797
Epoch 45/56
324/324 [==============================] - 9s 27ms/step - loss: 0.5536 - val_loss: 0.4702
Epoch 46/56
324/324 [==============================] - 9s 27ms/step - loss: 0.5492 - val_loss: 0.4607
Epoch 47/56
324/324 [==============================] - 9s 27ms/step - loss: 0.5457 - val_loss: 0.4513
Epoch 48/56
324/324 [==============================] - 9s 27ms/step - loss: 0.5414 - val_loss: 0.4420
Epoch 49/56
324/324 [==============================] - 9s 27ms/step - loss: 0.5381 - val_loss: 0.4328
Epoch 50/56
324/324 [==============================] - 9s 27ms/step - loss: 0.5341 - val_loss: 0.4237
Epoch 51/56
324/324 [==============================] - 9s 27ms/step - loss: 0.5304 - val_loss: 0.4147
Epoch 52/56
324/324 [==============================] - 9s 27ms/step - loss: 0.5269 - val_loss: 0.4058
Epoch 53/56
324/324 [==============================] - 9s 27ms/step - loss: 0.5233 - val_loss: 0.3969
Epoch 54/56
324/324 [==============================] - 9s 27ms/step - loss: 0.5198 - val_loss: 0.3882
Epoch 55/56
324/324 [==============================] - 9s 27ms/step - loss: 0.5167 - val_loss: 0.3796
Epoch 56/56
324/324 [==============================] - 9s 27ms/step - loss: 0.5131 - val_loss: 0.3710
Execution time:  497.1685929298401
GRU:
Mean Absolute Error: 0.4296
Root Mean Square Error: 0.7661
Mean Square Error: 0.5870

Train RMSE: 0.766
Train MSE: 0.587
Train MAE: 0.430
###########################

MODEL:  GRU
sequence:  6h
units:  45
dropout1:  0.11814836227952394
dropout2:  0.24325404382648977
optimizer: adadelta
activationDense: tanh
epochs: 43
batchsize: 30
validation_split: 0.2
Model: &#34;sequential_113&#34;
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
gru_58 (GRU)                 (None, 36, 45)            6480      
_________________________________________________________________
dropout_226 (Dropout)        (None, 36, 45)            0         
_________________________________________________________________
gru_59 (GRU)                 (None, 36, 45)            12420     
_________________________________________________________________
dropout_227 (Dropout)        (None, 36, 45)            0         
_________________________________________________________________
time_distributed_113 (TimeDi (None, 36, 1)             46        
=================================================================
Total params: 18,946
Trainable params: 18,946
Non-trainable params: 0
_________________________________________________________________
Epoch 1/43
106/106 [==============================] - 4s 38ms/step - loss: 0.7034 - val_loss: 0.6870
Epoch 2/43
106/106 [==============================] - 3s 30ms/step - loss: 0.7026 - val_loss: 0.6858
Epoch 3/43
106/106 [==============================] - 3s 32ms/step - loss: 0.7017 - val_loss: 0.6847
Epoch 4/43
106/106 [==============================] - 3s 30ms/step - loss: 0.7007 - val_loss: 0.6834
Epoch 5/43
106/106 [==============================] - 3s 31ms/step - loss: 0.6998 - val_loss: 0.6822 0s - l
Epoch 6/43
106/106 [==============================] - 3s 31ms/step - loss: 0.6988 - val_loss: 0.6809
Epoch 7/43
106/106 [==============================] - 3s 30ms/step - loss: 0.6977 - val_loss: 0.6795
Epoch 8/43
106/106 [==============================] - 3s 32ms/step - loss: 0.6968 - val_loss: 0.6782
Epoch 9/43
106/106 [==============================] - 3s 31ms/step - loss: 0.6958 - val_loss: 0.6769
Epoch 10/43
106/106 [==============================] - 3s 31ms/step - loss: 0.6949 - val_loss: 0.6755
Epoch 11/43
106/106 [==============================] - 3s 31ms/step - loss: 0.6938 - val_loss: 0.6741
Epoch 12/43
106/106 [==============================] - 3s 30ms/step - loss: 0.6927 - val_loss: 0.6727
Epoch 13/43
106/106 [==============================] - 3s 32ms/step - loss: 0.6917 - val_loss: 0.6713
Epoch 14/43
106/106 [==============================] - 3s 30ms/step - loss: 0.6907 - val_loss: 0.6699
Epoch 15/43
106/106 [==============================] - 3s 30ms/step - loss: 0.6897 - val_loss: 0.6685
Epoch 16/43
106/106 [==============================] - 3s 30ms/step - loss: 0.6887 - val_loss: 0.6671
Epoch 17/43
106/106 [==============================] - 3s 30ms/step - loss: 0.6875 - val_loss: 0.6656
Epoch 18/43
106/106 [==============================] - 3s 32ms/step - loss: 0.6865 - val_loss: 0.6642
Epoch 19/43
106/106 [==============================] - 3s 30ms/step - loss: 0.6855 - val_loss: 0.6627
Epoch 20/43
106/106 [==============================] - 3s 30ms/step - loss: 0.6844 - val_loss: 0.6612
Epoch 21/43
106/106 [==============================] - 3s 30ms/step - loss: 0.6833 - val_loss: 0.6597
Epoch 22/43
106/106 [==============================] - 3s 31ms/step - loss: 0.6823 - val_loss: 0.6582
Epoch 23/43
106/106 [==============================] - 3s 31ms/step - loss: 0.6811 - val_loss: 0.6568
Epoch 24/43
106/106 [==============================] - 3s 30ms/step - loss: 0.6801 - val_loss: 0.6552
Epoch 25/43
106/106 [==============================] - 3s 30ms/step - loss: 0.6790 - val_loss: 0.6537
Epoch 26/43
106/106 [==============================] - 3s 30ms/step - loss: 0.6779 - val_loss: 0.6522
Epoch 27/43
106/106 [==============================] - 3s 31ms/step - loss: 0.6768 - val_loss: 0.6507
Epoch 28/43
106/106 [==============================] - 3s 31ms/step - loss: 0.6757 - val_loss: 0.6491
Epoch 29/43
106/106 [==============================] - 3s 30ms/step - loss: 0.6746 - val_loss: 0.6476
Epoch 30/43
106/106 [==============================] - 3s 30ms/step - loss: 0.6735 - val_loss: 0.6461
Epoch 31/43
106/106 [==============================] - 3s 30ms/step - loss: 0.6725 - val_loss: 0.6445
Epoch 32/43
106/106 [==============================] - 3s 31ms/step - loss: 0.6712 - val_loss: 0.6429
Epoch 33/43
106/106 [==============================] - 3s 31ms/step - loss: 0.6702 - val_loss: 0.6414TA: 0s - lo
Epoch 34/43
106/106 [==============================] - 3s 30ms/step - loss: 0.6689 - val_loss: 0.6398
Epoch 35/43
106/106 [==============================] - 3s 30ms/step - loss: 0.6678 - val_loss: 0.6382
Epoch 36/43
106/106 [==============================] - 3s 30ms/step - loss: 0.6667 - val_loss: 0.6366
Epoch 37/43
106/106 [==============================] - 3s 32ms/step - loss: 0.6655 - val_loss: 0.6350
Epoch 38/43
106/106 [==============================] - 3s 30ms/step - loss: 0.6644 - val_loss: 0.6334
Epoch 39/43
106/106 [==============================] - 3s 30ms/step - loss: 0.6631 - val_loss: 0.6318
Epoch 40/43
106/106 [==============================] - 3s 30ms/step - loss: 0.6620 - val_loss: 0.6301
Epoch 41/43
106/106 [==============================] - 3s 31ms/step - loss: 0.6607 - val_loss: 0.6285
Epoch 42/43
106/106 [==============================] - 3s 32ms/step - loss: 0.6597 - val_loss: 0.6268
Epoch 43/43
106/106 [==============================] - 3s 30ms/step - loss: 0.6584 - val_loss: 0.6252
Execution time:  146.48808813095093
GRU:
Mean Absolute Error: 0.6342
Root Mean Square Error: 0.9224
Mean Square Error: 0.8508

Train RMSE: 0.922
Train MSE: 0.851
Train MAE: 0.634
###########################

MODEL:  GRU
sequence:  6h
units:  43
dropout1:  0.40519643149940265
dropout2:  0.3312343747027119
optimizer: adadelta
activationDense: sigmoid
epochs: 56
batchsize: 11
validation_split: 0.1
Model: &#34;sequential_114&#34;
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
gru_60 (GRU)                 (None, 36, 43)            5934      
_________________________________________________________________
dropout_228 (Dropout)        (None, 36, 43)            0         
_________________________________________________________________
gru_61 (GRU)                 (None, 36, 43)            11352     
_________________________________________________________________
dropout_229 (Dropout)        (None, 36, 43)            0         
_________________________________________________________________
time_distributed_114 (TimeDi (None, 36, 1)             44        
=================================================================
Total params: 17,330
Trainable params: 17,330
Non-trainable params: 0
_________________________________________________________________
Epoch 1/56
324/324 [==============================] - 10s 31ms/step - loss: 0.8960 - val_loss: 1.3030
Epoch 2/56
324/324 [==============================] - 9s 27ms/step - loss: 0.8954 - val_loss: 1.3019
Epoch 3/56
324/324 [==============================] - 9s 27ms/step - loss: 0.8947 - val_loss: 1.3006
Epoch 4/56
324/324 [==============================] - 9s 27ms/step - loss: 0.8941 - val_loss: 1.2993
Epoch 5/56
324/324 [==============================] - 9s 27ms/step - loss: 0.8935 - val_loss: 1.2980
Epoch 6/56
324/324 [==============================] - 9s 27ms/step - loss: 0.8928 - val_loss: 1.2966
Epoch 7/56
324/324 [==============================] - 9s 27ms/step - loss: 0.8921 - val_loss: 1.2952
Epoch 8/56
324/324 [==============================] - 9s 27ms/step - loss: 0.8913 - val_loss: 1.2937
Epoch 9/56
324/324 [==============================] - 9s 27ms/step - loss: 0.8906 - val_loss: 1.2922
Epoch 10/56
324/324 [==============================] - 9s 27ms/step - loss: 0.8898 - val_loss: 1.2906
Epoch 11/56
324/324 [==============================] - 9s 26ms/step - loss: 0.8890 - val_loss: 1.2890
Epoch 12/56
324/324 [==============================] - 9s 27ms/step - loss: 0.8882 - val_loss: 1.2874
Epoch 13/56
324/324 [==============================] - 9s 27ms/step - loss: 0.8874 - val_loss: 1.2857
Epoch 14/56
324/324 [==============================] - 9s 27ms/step - loss: 0.8865 - val_loss: 1.2840
Epoch 15/56
324/324 [==============================] - 9s 27ms/step - loss: 0.8856 - val_loss: 1.2822
Epoch 16/56
324/324 [==============================] - 9s 27ms/step - loss: 0.8847 - val_loss: 1.2804
Epoch 17/56
324/324 [==============================] - 9s 27ms/step - loss: 0.8838 - val_loss: 1.2786
Epoch 18/56
324/324 [==============================] - 9s 27ms/step - loss: 0.8829 - val_loss: 1.2767
Epoch 19/56
324/324 [==============================] - 9s 27ms/step - loss: 0.8819 - val_loss: 1.2747
Epoch 20/56
324/324 [==============================] - 9s 27ms/step - loss: 0.8809 - val_loss: 1.2727
Epoch 21/56
324/324 [==============================] - 9s 27ms/step - loss: 0.8799 - val_loss: 1.2706
Epoch 22/56
324/324 [==============================] - 9s 27ms/step - loss: 0.8789 - val_loss: 1.2685
Epoch 23/56
324/324 [==============================] - 9s 27ms/step - loss: 0.8778 - val_loss: 1.2664
Epoch 24/56
324/324 [==============================] - 9s 27ms/step - loss: 0.8767 - val_loss: 1.2641
Epoch 25/56
324/324 [==============================] - 9s 27ms/step - loss: 0.8756 - val_loss: 1.2619
Epoch 26/56
324/324 [==============================] - 9s 27ms/step - loss: 0.8744 - val_loss: 1.2595
Epoch 27/56
324/324 [==============================] - 9s 27ms/step - loss: 0.8732 - val_loss: 1.2571
Epoch 28/56
324/324 [==============================] - 9s 27ms/step - loss: 0.8720 - val_loss: 1.2547
Epoch 29/56
324/324 [==============================] - 9s 27ms/step - loss: 0.8707 - val_loss: 1.2521
Epoch 30/56
324/324 [==============================] - 9s 27ms/step - loss: 0.8694 - val_loss: 1.2495
Epoch 31/56
324/324 [==============================] - 9s 27ms/step - loss: 0.8681 - val_loss: 1.2469
Epoch 32/56
324/324 [==============================] - 9s 27ms/step - loss: 0.8668 - val_loss: 1.2442
Epoch 33/56
324/324 [==============================] - 9s 27ms/step - loss: 0.8654 - val_loss: 1.2414
Epoch 34/56
324/324 [==============================] - 9s 27ms/step - loss: 0.8639 - val_loss: 1.2385
Epoch 35/56
324/324 [==============================] - 9s 26ms/step - loss: 0.8625 - val_loss: 1.2355
Epoch 36/56
324/324 [==============================] - 9s 27ms/step - loss: 0.8609 - val_loss: 1.2325
Epoch 37/56
324/324 [==============================] - 9s 26ms/step - loss: 0.8594 - val_loss: 1.2294
Epoch 38/56
324/324 [==============================] - 9s 27ms/step - loss: 0.8578 - val_loss: 1.2262
Epoch 39/56
324/324 [==============================] - 9s 27ms/step - loss: 0.8562 - val_loss: 1.2230
Epoch 40/56
324/324 [==============================] - 9s 27ms/step - loss: 0.8545 - val_loss: 1.2196
Epoch 41/56
324/324 [==============================] - 9s 27ms/step - loss: 0.8528 - val_loss: 1.2162
Epoch 42/56
324/324 [==============================] - 9s 27ms/step - loss: 0.8511 - val_loss: 1.2127
Epoch 43/56
324/324 [==============================] - 9s 27ms/step - loss: 0.8493 - val_loss: 1.2091
Epoch 44/56
324/324 [==============================] - 9s 27ms/step - loss: 0.8473 - val_loss: 1.2054
Epoch 45/56
324/324 [==============================] - 9s 27ms/step - loss: 0.8456 - val_loss: 1.2016
Epoch 46/56
324/324 [==============================] - 9s 26ms/step - loss: 0.8436 - val_loss: 1.1977
Epoch 47/56
324/324 [==============================] - 9s 27ms/step - loss: 0.8416 - val_loss: 1.1937
Epoch 48/56
324/324 [==============================] - 9s 26ms/step - loss: 0.8396 - val_loss: 1.1896
Epoch 49/56
324/324 [==============================] - 9s 27ms/step - loss: 0.8375 - val_loss: 1.1854
Epoch 50/56
324/324 [==============================] - 9s 27ms/step - loss: 0.8353 - val_loss: 1.1812
Epoch 51/56
324/324 [==============================] - 9s 27ms/step - loss: 0.8330 - val_loss: 1.1768
Epoch 52/56
324/324 [==============================] - 9s 27ms/step - loss: 0.8308 - val_loss: 1.1723
Epoch 53/56
324/324 [==============================] - 9s 27ms/step - loss: 0.8286 - val_loss: 1.1678
Epoch 54/56
324/324 [==============================] - 9s 27ms/step - loss: 0.8261 - val_loss: 1.1631
Epoch 55/56
324/324 [==============================] - 9s 26ms/step - loss: 0.8236 - val_loss: 1.1584
Epoch 56/56
324/324 [==============================] - 9s 27ms/step - loss: 0.8212 - val_loss: 1.1535
Execution time:  493.7741816043854
GRU:
Mean Absolute Error: 0.8344
Root Mean Square Error: 1.0252
Mean Square Error: 1.0510

Train RMSE: 1.025
Train MSE: 1.051
Train MAE: 0.834
###########################

MODEL:  GRU
sequence:  6h
units:  45
dropout1:  0.11814836227952394
dropout2:  0.24325404382648977
optimizer: adadelta
activationDense: sigmoid
epochs: 43
batchsize: 30
validation_split: 0.2
Model: &#34;sequential_115&#34;
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
gru_62 (GRU)                 (None, 36, 45)            6480      
_________________________________________________________________
dropout_230 (Dropout)        (None, 36, 45)            0         
_________________________________________________________________
gru_63 (GRU)                 (None, 36, 45)            12420     
_________________________________________________________________
dropout_231 (Dropout)        (None, 36, 45)            0         
_________________________________________________________________
time_distributed_115 (TimeDi (None, 36, 1)             46        
=================================================================
Total params: 18,946
Trainable params: 18,946
Non-trainable params: 0
_________________________________________________________________
Epoch 1/43
106/106 [==============================] - 4s 40ms/step - loss: 0.8807 - val_loss: 1.1331
Epoch 2/43
106/106 [==============================] - 3s 31ms/step - loss: 0.8806 - val_loss: 1.1328
Epoch 3/43
106/106 [==============================] - 3s 31ms/step - loss: 0.8803 - val_loss: 1.1326
Epoch 4/43
106/106 [==============================] - 3s 30ms/step - loss: 0.8802 - val_loss: 1.1323
Epoch 5/43
106/106 [==============================] - 3s 31ms/step - loss: 0.8800 - val_loss: 1.1320
Epoch 6/43
106/106 [==============================] - 3s 32ms/step - loss: 0.8798 - val_loss: 1.1317
Epoch 7/43
106/106 [==============================] - 3s 31ms/step - loss: 0.8796 - val_loss: 1.1314
Epoch 8/43
106/106 [==============================] - 3s 31ms/step - loss: 0.8794 - val_loss: 1.1312
Epoch 9/43
106/106 [==============================] - 3s 31ms/step - loss: 0.8792 - val_loss: 1.1309
Epoch 10/43
106/106 [==============================] - 3s 31ms/step - loss: 0.8790 - val_loss: 1.1305
Epoch 11/43
106/106 [==============================] - 3s 32ms/step - loss: 0.8788 - val_loss: 1.1302
Epoch 12/43
106/106 [==============================] - 3s 31ms/step - loss: 0.8786 - val_loss: 1.1299
Epoch 13/43
106/106 [==============================] - 3s 30ms/step - loss: 0.8784 - val_loss: 1.1296
Epoch 14/43
106/106 [==============================] - 3s 31ms/step - loss: 0.8782 - val_loss: 1.1293
Epoch 15/43
106/106 [==============================] - 3s 31ms/step - loss: 0.8780 - val_loss: 1.1290
Epoch 16/43
106/106 [==============================] - 3s 32ms/step - loss: 0.8778 - val_loss: 1.1286
Epoch 17/43
106/106 [==============================] - 3s 31ms/step - loss: 0.8776 - val_loss: 1.1283
Epoch 18/43
106/106 [==============================] - 3s 31ms/step - loss: 0.8774 - val_loss: 1.1280
Epoch 19/43
106/106 [==============================] - 3s 31ms/step - loss: 0.8771 - val_loss: 1.1276
Epoch 20/43
106/106 [==============================] - 3s 32ms/step - loss: 0.8769 - val_loss: 1.1273
Epoch 21/43
106/106 [==============================] - 3s 31ms/step - loss: 0.8767 - val_loss: 1.1270
Epoch 22/43
106/106 [==============================] - 3s 31ms/step - loss: 0.8765 - val_loss: 1.1266
Epoch 23/43
106/106 [==============================] - 3s 31ms/step - loss: 0.8762 - val_loss: 1.1263
Epoch 24/43
106/106 [==============================] - 3s 31ms/step - loss: 0.8760 - val_loss: 1.1259
Epoch 25/43
106/106 [==============================] - 3s 32ms/step - loss: 0.8758 - val_loss: 1.1256
Epoch 26/43
106/106 [==============================] - 3s 31ms/step - loss: 0.8756 - val_loss: 1.1252
Epoch 27/43
106/106 [==============================] - 3s 31ms/step - loss: 0.8753 - val_loss: 1.1248
Epoch 28/43
106/106 [==============================] - 3s 31ms/step - loss: 0.8751 - val_loss: 1.1245
Epoch 29/43
106/106 [==============================] - 3s 31ms/step - loss: 0.8749 - val_loss: 1.1241
Epoch 30/43
106/106 [==============================] - 3s 32ms/step - loss: 0.8747 - val_loss: 1.1237
Epoch 31/43
106/106 [==============================] - 3s 31ms/step - loss: 0.8744 - val_loss: 1.1234
Epoch 32/43
106/106 [==============================] - 3s 31ms/step - loss: 0.8742 - val_loss: 1.1230
Epoch 33/43
106/106 [==============================] - 3s 31ms/step - loss: 0.8740 - val_loss: 1.1226
Epoch 34/43
106/106 [==============================] - 3s 31ms/step - loss: 0.8737 - val_loss: 1.1222
Epoch 35/43
106/106 [==============================] - 3s 32ms/step - loss: 0.8734 - val_loss: 1.1219
Epoch 36/43
106/106 [==============================] - 3s 31ms/step - loss: 0.8732 - val_loss: 1.1215
Epoch 37/43
106/106 [==============================] - 3s 31ms/step - loss: 0.8730 - val_loss: 1.1211
Epoch 38/43
106/106 [==============================] - 3s 31ms/step - loss: 0.8727 - val_loss: 1.1207
Epoch 39/43
106/106 [==============================] - 3s 31ms/step - loss: 0.8724 - val_loss: 1.1203
Epoch 40/43
106/106 [==============================] - 3s 32ms/step - loss: 0.8722 - val_loss: 1.1199
Epoch 41/43
106/106 [==============================] - 3s 31ms/step - loss: 0.8720 - val_loss: 1.1195
Epoch 42/43
106/106 [==============================] - 3s 31ms/step - loss: 0.8717 - val_loss: 1.1191
Epoch 43/43
106/106 [==============================] - 3s 30ms/step - loss: 0.8715 - val_loss: 1.1187
Execution time:  148.41799974441528
GRU:
Mean Absolute Error: 0.9121
Root Mean Square Error: 1.0984
Mean Square Error: 1.2064

Train RMSE: 1.098
Train MSE: 1.206
Train MAE: 0.912
###########################

MODEL:  GRU
sequence:  6h
units:  43
dropout1:  0.40519643149940265
dropout2:  0.3312343747027119
optimizer: adamax
activationDense: tanh
epochs: 56
batchsize: 11
validation_split: 0.1
Model: &#34;sequential_116&#34;
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
gru_64 (GRU)                 (None, 36, 43)            5934      
_________________________________________________________________
dropout_232 (Dropout)        (None, 36, 43)            0         
_________________________________________________________________
gru_65 (GRU)                 (None, 36, 43)            11352     
_________________________________________________________________
dropout_233 (Dropout)        (None, 36, 43)            0         
_________________________________________________________________
time_distributed_116 (TimeDi (None, 36, 1)             44        
=================================================================
Total params: 17,330
Trainable params: 17,330
Non-trainable params: 0
_________________________________________________________________
Epoch 1/56
324/324 [==============================] - 10s 29ms/step - loss: 0.4719 - val_loss: 0.2495
Epoch 2/56
324/324 [==============================] - 9s 27ms/step - loss: 0.4316 - val_loss: 0.2344
Epoch 3/56
324/324 [==============================] - 9s 27ms/step - loss: 0.4248 - val_loss: 0.2205
Epoch 4/56
324/324 [==============================] - 9s 27ms/step - loss: 0.4203 - val_loss: 0.2200
Epoch 5/56
324/324 [==============================] - 9s 27ms/step - loss: 0.4176 - val_loss: 0.2201
Epoch 6/56
324/324 [==============================] - 9s 27ms/step - loss: 0.4157 - val_loss: 0.2194
Epoch 7/56
324/324 [==============================] - 9s 27ms/step - loss: 0.4136 - val_loss: 0.2215
Epoch 8/56
324/324 [==============================] - 9s 27ms/step - loss: 0.4123 - val_loss: 0.2215
Epoch 9/56
324/324 [==============================] - 9s 27ms/step - loss: 0.4110 - val_loss: 0.2228
Epoch 10/56
324/324 [==============================] - 9s 27ms/step - loss: 0.4107 - val_loss: 0.2255
Epoch 11/56
324/324 [==============================] - 9s 27ms/step - loss: 0.4104 - val_loss: 0.2267
Epoch 12/56
324/324 [==============================] - 9s 27ms/step - loss: 0.4099 - val_loss: 0.2276
Epoch 13/56
324/324 [==============================] - 9s 27ms/step - loss: 0.4093 - val_loss: 0.2284
Epoch 14/56
324/324 [==============================] - 9s 27ms/step - loss: 0.4091 - val_loss: 0.2276
Epoch 15/56
324/324 [==============================] - 9s 27ms/step - loss: 0.4087 - val_loss: 0.2291
Epoch 16/56
324/324 [==============================] - 9s 27ms/step - loss: 0.4090 - val_loss: 0.2257
Epoch 17/56
324/324 [==============================] - 9s 27ms/step - loss: 0.4082 - val_loss: 0.2269
Epoch 18/56
324/324 [==============================] - 9s 27ms/step - loss: 0.4080 - val_loss: 0.2280
Epoch 19/56
324/324 [==============================] - 9s 27ms/step - loss: 0.4080 - val_loss: 0.2267
Epoch 20/56
324/324 [==============================] - 9s 27ms/step - loss: 0.4077 - val_loss: 0.2257
Epoch 21/56
324/324 [==============================] - 9s 27ms/step - loss: 0.4077 - val_loss: 0.2259
Epoch 22/56
324/324 [==============================] - 9s 27ms/step - loss: 0.4072 - val_loss: 0.2253
Epoch 23/56
324/324 [==============================] - 9s 27ms/step - loss: 0.4075 - val_loss: 0.2253
Epoch 24/56
324/324 [==============================] - 9s 27ms/step - loss: 0.4072 - val_loss: 0.2272
Epoch 25/56
324/324 [==============================] - 9s 27ms/step - loss: 0.4066 - val_loss: 0.2259
Epoch 26/56
324/324 [==============================] - 9s 27ms/step - loss: 0.4068 - val_loss: 0.2247
Epoch 27/56
324/324 [==============================] - 9s 27ms/step - loss: 0.4063 - val_loss: 0.2245
Epoch 28/56
324/324 [==============================] - 9s 27ms/step - loss: 0.4065 - val_loss: 0.2264
Epoch 29/56
324/324 [==============================] - 9s 27ms/step - loss: 0.4062 - val_loss: 0.2257
Epoch 30/56
324/324 [==============================] - 9s 27ms/step - loss: 0.4063 - val_loss: 0.2247
Epoch 31/56
324/324 [==============================] - 9s 27ms/step - loss: 0.4057 - val_loss: 0.2252
Epoch 32/56
324/324 [==============================] - 9s 27ms/step - loss: 0.4057 - val_loss: 0.2250
Epoch 33/56
324/324 [==============================] - 9s 27ms/step - loss: 0.4057 - val_loss: 0.2245
Epoch 34/56
324/324 [==============================] - 9s 27ms/step - loss: 0.4057 - val_loss: 0.2223
Epoch 35/56
324/324 [==============================] - 9s 27ms/step - loss: 0.4054 - val_loss: 0.2232
Epoch 36/56
324/324 [==============================] - 9s 27ms/step - loss: 0.4050 - val_loss: 0.2238
Epoch 37/56
324/324 [==============================] - 9s 27ms/step - loss: 0.4052 - val_loss: 0.2237
Epoch 38/56
324/324 [==============================] - 9s 27ms/step - loss: 0.4050 - val_loss: 0.2230
Epoch 39/56
324/324 [==============================] - 9s 27ms/step - loss: 0.4050 - val_loss: 0.2224
Epoch 40/56
324/324 [==============================] - 9s 27ms/step - loss: 0.4045 - val_loss: 0.2221
Epoch 41/56
324/324 [==============================] - 9s 27ms/step - loss: 0.4044 - val_loss: 0.2223
Epoch 42/56
324/324 [==============================] - 9s 27ms/step - loss: 0.4047 - val_loss: 0.2214
Epoch 43/56
324/324 [==============================] - 9s 27ms/step - loss: 0.4046 - val_loss: 0.2238
Epoch 44/56
324/324 [==============================] - 9s 27ms/step - loss: 0.4045 - val_loss: 0.2212
Epoch 45/56
324/324 [==============================] - 9s 27ms/step - loss: 0.4039 - val_loss: 0.2198
Epoch 46/56
324/324 [==============================] - 9s 27ms/step - loss: 0.4038 - val_loss: 0.2195
Epoch 47/56
324/324 [==============================] - 9s 27ms/step - loss: 0.4040 - val_loss: 0.2206
Epoch 48/56
324/324 [==============================] - 9s 27ms/step - loss: 0.4035 - val_loss: 0.2224
Epoch 49/56
324/324 [==============================] - 9s 27ms/step - loss: 0.4037 - val_loss: 0.2195
Epoch 50/56
324/324 [==============================] - 9s 27ms/step - loss: 0.4033 - val_loss: 0.2195
Epoch 51/56
324/324 [==============================] - 9s 29ms/step - loss: 0.4032 - val_loss: 0.2197
Epoch 52/56
324/324 [==============================] - 9s 27ms/step - loss: 0.4031 - val_loss: 0.2207
Epoch 53/56
324/324 [==============================] - 9s 27ms/step - loss: 0.4028 - val_loss: 0.2208
Epoch 54/56
324/324 [==============================] - 9s 27ms/step - loss: 0.4029 - val_loss: 0.2202
Epoch 55/56
324/324 [==============================] - 9s 27ms/step - loss: 0.4029 - val_loss: 0.2192
Epoch 56/56
324/324 [==============================] - 9s 27ms/step - loss: 0.4025 - val_loss: 0.2186
Execution time:  499.63963866233826
GRU:
Mean Absolute Error: 0.2052
Root Mean Square Error: 0.6004
Mean Square Error: 0.3605

Train RMSE: 0.600
Train MSE: 0.360
Train MAE: 0.205
###########################

MODEL:  GRU
sequence:  6h
units:  45
dropout1:  0.11814836227952394
dropout2:  0.24325404382648977
optimizer: adamax
activationDense: tanh
epochs: 43
batchsize: 30
validation_split: 0.2
Model: &#34;sequential_117&#34;
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
gru_66 (GRU)                 (None, 36, 45)            6480      
_________________________________________________________________
dropout_234 (Dropout)        (None, 36, 45)            0         
_________________________________________________________________
gru_67 (GRU)                 (None, 36, 45)            12420     
_________________________________________________________________
dropout_235 (Dropout)        (None, 36, 45)            0         
_________________________________________________________________
time_distributed_117 (TimeDi (None, 36, 1)             46        
=================================================================
Total params: 18,946
Trainable params: 18,946
Non-trainable params: 0
_________________________________________________________________
Epoch 1/43
106/106 [==============================] - 4s 37ms/step - loss: 0.5174 - val_loss: 0.3390
Epoch 2/43
106/106 [==============================] - 3s 30ms/step - loss: 0.4334 - val_loss: 0.3323
Epoch 3/43
106/106 [==============================] - 3s 31ms/step - loss: 0.4265 - val_loss: 0.3272
Epoch 4/43
106/106 [==============================] - 3s 30ms/step - loss: 0.4215 - val_loss: 0.3232
Epoch 5/43
106/106 [==============================] - 3s 30ms/step - loss: 0.4176 - val_loss: 0.3204
Epoch 6/43
106/106 [==============================] - 3s 30ms/step - loss: 0.4141 - val_loss: 0.3180
Epoch 7/43
106/106 [==============================] - 3s 31ms/step - loss: 0.4124 - val_loss: 0.3159
Epoch 8/43
106/106 [==============================] - 3s 31ms/step - loss: 0.4106 - val_loss: 0.3146
Epoch 9/43
106/106 [==============================] - 3s 31ms/step - loss: 0.4092 - val_loss: 0.3134
Epoch 10/43
106/106 [==============================] - 3s 30ms/step - loss: 0.4080 - val_loss: 0.3125
Epoch 11/43
106/106 [==============================] - 3s 30ms/step - loss: 0.4066 - val_loss: 0.3117
Epoch 12/43
106/106 [==============================] - 3s 31ms/step - loss: 0.4059 - val_loss: 0.3109
Epoch 13/43
106/106 [==============================] - 3s 31ms/step - loss: 0.4051 - val_loss: 0.3104
Epoch 14/43
106/106 [==============================] - 3s 30ms/step - loss: 0.4041 - val_loss: 0.3098
Epoch 15/43
106/106 [==============================] - 3s 30ms/step - loss: 0.4038 - val_loss: 0.3092
Epoch 16/43
106/106 [==============================] - 3s 30ms/step - loss: 0.4030 - val_loss: 0.3090
Epoch 17/43
106/106 [==============================] - 3s 32ms/step - loss: 0.4022 - val_loss: 0.3087
Epoch 18/43
106/106 [==============================] - 3s 31ms/step - loss: 0.4015 - val_loss: 0.3088
Epoch 19/43
106/106 [==============================] - 3s 30ms/step - loss: 0.4008 - val_loss: 0.3088
Epoch 20/43
106/106 [==============================] - 3s 30ms/step - loss: 0.4007 - val_loss: 0.3087
Epoch 21/43
106/106 [==============================] - 3s 30ms/step - loss: 0.4005 - val_loss: 0.3089
Epoch 22/43
106/106 [==============================] - 3s 32ms/step - loss: 0.4000 - val_loss: 0.3089
Epoch 23/43
106/106 [==============================] - 3s 30ms/step - loss: 0.3997 - val_loss: 0.3089
Epoch 24/43
106/106 [==============================] - 3s 30ms/step - loss: 0.3996 - val_loss: 0.3089
Epoch 25/43
106/106 [==============================] - 3s 30ms/step - loss: 0.3992 - val_loss: 0.3090
Epoch 26/43
106/106 [==============================] - 3s 30ms/step - loss: 0.3990 - val_loss: 0.3089
Epoch 27/43
106/106 [==============================] - 3s 32ms/step - loss: 0.3991 - val_loss: 0.3091
Epoch 28/43
106/106 [==============================] - 3s 30ms/step - loss: 0.3989 - val_loss: 0.3092
Epoch 29/43
106/106 [==============================] - 3s 30ms/step - loss: 0.3988 - val_loss: 0.3091
Epoch 30/43
106/106 [==============================] - 3s 30ms/step - loss: 0.3986 - val_loss: 0.3093
Epoch 31/43
106/106 [==============================] - 3s 30ms/step - loss: 0.3983 - val_loss: 0.3094
Epoch 32/43
106/106 [==============================] - 3s 32ms/step - loss: 0.3982 - val_loss: 0.3094
Epoch 33/43
106/106 [==============================] - 3s 30ms/step - loss: 0.3981 - val_loss: 0.3095
Epoch 34/43
106/106 [==============================] - 3s 30ms/step - loss: 0.3980 - val_loss: 0.3095
Epoch 35/43
106/106 [==============================] - 3s 30ms/step - loss: 0.3980 - val_loss: 0.3095
Epoch 36/43
106/106 [==============================] - 3s 30ms/step - loss: 0.3978 - val_loss: 0.3096
Epoch 37/43
106/106 [==============================] - 3s 32ms/step - loss: 0.3980 - val_loss: 0.3096
Epoch 38/43
106/106 [==============================] - 3s 30ms/step - loss: 0.3979 - val_loss: 0.3096
Epoch 39/43
106/106 [==============================] - 3s 30ms/step - loss: 0.3978 - val_loss: 0.3097
Epoch 40/43
106/106 [==============================] - 3s 30ms/step - loss: 0.3973 - val_loss: 0.3098
Epoch 41/43
106/106 [==============================] - 3s 30ms/step - loss: 0.3975 - val_loss: 0.3097
Epoch 42/43
106/106 [==============================] - 3s 32ms/step - loss: 0.3974 - val_loss: 0.3099
Epoch 43/43
106/106 [==============================] - 3s 30ms/step - loss: 0.3972 - val_loss: 0.3097
Execution time:  145.74998307228088
GRU:
Mean Absolute Error: 0.1904
Root Mean Square Error: 0.5828
Mean Square Error: 0.3396

Train RMSE: 0.583
Train MSE: 0.340
Train MAE: 0.190
###########################

MODEL:  GRU
sequence:  6h
units:  43
dropout1:  0.40519643149940265
dropout2:  0.3312343747027119
optimizer: adamax
activationDense: sigmoid
epochs: 56
batchsize: 11
validation_split: 0.1
Model: &#34;sequential_118&#34;
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
gru_68 (GRU)                 (None, 36, 43)            5934      
_________________________________________________________________
dropout_236 (Dropout)        (None, 36, 43)            0         
_________________________________________________________________
gru_69 (GRU)                 (None, 36, 43)            11352     
_________________________________________________________________
dropout_237 (Dropout)        (None, 36, 43)            0         
_________________________________________________________________
time_distributed_118 (TimeDi (None, 36, 1)             44        
=================================================================
Total params: 17,330
Trainable params: 17,330
Non-trainable params: 0
_________________________________________________________________
Epoch 1/56
324/324 [==============================] - 10s 30ms/step - loss: 0.6796 - val_loss: 0.8282
Epoch 2/56
324/324 [==============================] - 9s 27ms/step - loss: 0.6135 - val_loss: 0.8177
Epoch 3/56
324/324 [==============================] - 9s 27ms/step - loss: 0.6035 - val_loss: 0.8129
Epoch 4/56
324/324 [==============================] - 9s 27ms/step - loss: 0.5962 - val_loss: 0.8097
Epoch 5/56
324/324 [==============================] - 9s 27ms/step - loss: 0.5916 - val_loss: 0.8078
Epoch 6/56
324/324 [==============================] - 9s 27ms/step - loss: 0.5886 - val_loss: 0.8067
Epoch 7/56
324/324 [==============================] - 9s 26ms/step - loss: 0.5862 - val_loss: 0.8060
Epoch 8/56
324/324 [==============================] - 9s 27ms/step - loss: 0.5847 - val_loss: 0.8057
Epoch 9/56
324/324 [==============================] - 9s 27ms/step - loss: 0.5837 - val_loss: 0.8054
Epoch 10/56
324/324 [==============================] - 9s 27ms/step - loss: 0.5832 - val_loss: 0.8053
Epoch 11/56
324/324 [==============================] - 9s 27ms/step - loss: 0.5828 - val_loss: 0.8052
Epoch 12/56
324/324 [==============================] - 9s 27ms/step - loss: 0.5822 - val_loss: 0.8052
Epoch 13/56
324/324 [==============================] - 9s 27ms/step - loss: 0.5820 - val_loss: 0.8051
Epoch 14/56
324/324 [==============================] - 9s 27ms/step - loss: 0.5816 - val_loss: 0.8051
Epoch 15/56
324/324 [==============================] - 9s 27ms/step - loss: 0.5815 - val_loss: 0.8051
Epoch 16/56
324/324 [==============================] - 9s 27ms/step - loss: 0.5813 - val_loss: 0.8050
Epoch 17/56
324/324 [==============================] - 9s 27ms/step - loss: 0.5810 - val_loss: 0.8050
Epoch 18/56
324/324 [==============================] - 9s 27ms/step - loss: 0.5811 - val_loss: 0.8050
Epoch 19/56
324/324 [==============================] - 9s 27ms/step - loss: 0.5809 - val_loss: 0.8050
Epoch 20/56
324/324 [==============================] - 9s 27ms/step - loss: 0.5805 - val_loss: 0.8050
Epoch 21/56
324/324 [==============================] - 9s 27ms/step - loss: 0.5807 - val_loss: 0.8050
Epoch 22/56
324/324 [==============================] - 9s 27ms/step - loss: 0.5804 - val_loss: 0.8050
Epoch 23/56
324/324 [==============================] - 9s 27ms/step - loss: 0.5805 - val_loss: 0.8050
Epoch 24/56
324/324 [==============================] - 9s 26ms/step - loss: 0.5802 - val_loss: 0.8050
Epoch 25/56
324/324 [==============================] - 9s 27ms/step - loss: 0.5802 - val_loss: 0.8050
Epoch 26/56
324/324 [==============================] - 9s 26ms/step - loss: 0.5802 - val_loss: 0.8050
Epoch 27/56
324/324 [==============================] - 9s 27ms/step - loss: 0.5798 - val_loss: 0.8050
Epoch 28/56
324/324 [==============================] - 9s 27ms/step - loss: 0.5799 - val_loss: 0.8050
Epoch 29/56
324/324 [==============================] - 9s 26ms/step - loss: 0.5797 - val_loss: 0.8050
Epoch 30/56
324/324 [==============================] - 9s 27ms/step - loss: 0.5796 - val_loss: 0.8050
Epoch 31/56
324/324 [==============================] - 9s 27ms/step - loss: 0.5796 - val_loss: 0.8050
Epoch 32/56
324/324 [==============================] - 9s 27ms/step - loss: 0.5798 - val_loss: 0.8050
Epoch 33/56
324/324 [==============================] - 9s 26ms/step - loss: 0.5796 - val_loss: 0.8050
Epoch 34/56
324/324 [==============================] - 9s 27ms/step - loss: 0.5795 - val_loss: 0.8050
Epoch 35/56
324/324 [==============================] - 9s 26ms/step - loss: 0.5795 - val_loss: 0.8050
Epoch 36/56
324/324 [==============================] - 9s 27ms/step - loss: 0.5794 - val_loss: 0.8050
Epoch 37/56
324/324 [==============================] - 9s 26ms/step - loss: 0.5794 - val_loss: 0.8050
Epoch 38/56
324/324 [==============================] - 9s 27ms/step - loss: 0.5793 - val_loss: 0.8049
Epoch 39/56
324/324 [==============================] - 9s 27ms/step - loss: 0.5792 - val_loss: 0.8049
Epoch 40/56
324/324 [==============================] - 9s 27ms/step - loss: 0.5792 - val_loss: 0.8049
Epoch 41/56
324/324 [==============================] - 9s 27ms/step - loss: 0.5792 - val_loss: 0.8049
Epoch 42/56
324/324 [==============================] - 9s 27ms/step - loss: 0.5792 - val_loss: 0.8049
Epoch 43/56
324/324 [==============================] - 9s 27ms/step - loss: 0.5793 - val_loss: 0.8049
Epoch 44/56
324/324 [==============================] - 9s 26ms/step - loss: 0.5790 - val_loss: 0.8049
Epoch 45/56
324/324 [==============================] - 9s 27ms/step - loss: 0.5790 - val_loss: 0.8049
Epoch 46/56
324/324 [==============================] - 9s 26ms/step - loss: 0.5789 - val_loss: 0.8049
Epoch 47/56
324/324 [==============================] - 9s 27ms/step - loss: 0.5788 - val_loss: 0.8049
Epoch 48/56
324/324 [==============================] - 9s 26ms/step - loss: 0.5790 - val_loss: 0.8049
Epoch 49/56
324/324 [==============================] - 9s 27ms/step - loss: 0.5787 - val_loss: 0.8049
Epoch 50/56
324/324 [==============================] - 9s 27ms/step - loss: 0.5790 - val_loss: 0.8049
Epoch 51/56
324/324 [==============================] - 9s 27ms/step - loss: 0.5790 - val_loss: 0.8049
Epoch 52/56
324/324 [==============================] - 9s 27ms/step - loss: 0.5787 - val_loss: 0.8049
Epoch 53/56
324/324 [==============================] - 9s 27ms/step - loss: 0.5786 - val_loss: 0.8049
Epoch 54/56
324/324 [==============================] - 9s 27ms/step - loss: 0.5786 - val_loss: 0.8049
Epoch 55/56
324/324 [==============================] - 9s 27ms/step - loss: 0.5788 - val_loss: 0.8049
Epoch 56/56
324/324 [==============================] - 9s 27ms/step - loss: 0.5785 - val_loss: 0.8049
Execution time:  493.329874753952
GRU:
Mean Absolute Error: 0.5066
Root Mean Square Error: 0.7640
Mean Square Error: 0.5837

Train RMSE: 0.764
Train MSE: 0.584
Train MAE: 0.507
###########################

MODEL:  GRU
sequence:  6h
units:  45
dropout1:  0.11814836227952394
dropout2:  0.24325404382648977
optimizer: adamax
activationDense: sigmoid
epochs: 43
batchsize: 30
validation_split: 0.2
Model: &#34;sequential_119&#34;
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
gru_70 (GRU)                 (None, 36, 45)            6480      
_________________________________________________________________
dropout_238 (Dropout)        (None, 36, 45)            0         
_________________________________________________________________
gru_71 (GRU)                 (None, 36, 45)            12420     
_________________________________________________________________
dropout_239 (Dropout)        (None, 36, 45)            0         
_________________________________________________________________
time_distributed_119 (TimeDi (None, 36, 1)             46        
=================================================================
Total params: 18,946
Trainable params: 18,946
Non-trainable params: 0
_________________________________________________________________
Epoch 1/43
106/106 [==============================] - 4s 40ms/step - loss: 0.7881 - val_loss: 0.7846
Epoch 2/43
106/106 [==============================] - 3s 29ms/step - loss: 0.6244 - val_loss: 0.7420
Epoch 3/43
106/106 [==============================] - 3s 30ms/step - loss: 0.6116 - val_loss: 0.7317
Epoch 4/43
106/106 [==============================] - 3s 30ms/step - loss: 0.6051 - val_loss: 0.7256
Epoch 5/43
106/106 [==============================] - 3s 32ms/step - loss: 0.6005 - val_loss: 0.7211
Epoch 6/43
106/106 [==============================] - 4s 34ms/step - loss: 0.5968 - val_loss: 0.7177
Epoch 7/43
106/106 [==============================] - 3s 31ms/step - loss: 0.5938 - val_loss: 0.7149
Epoch 8/43
106/106 [==============================] - 3s 31ms/step - loss: 0.5910 - val_loss: 0.7125
Epoch 9/43
106/106 [==============================] - 3s 31ms/step - loss: 0.5888 - val_loss: 0.7105
Epoch 10/43
106/106 [==============================] - 3s 31ms/step - loss: 0.5869 - val_loss: 0.7091
Epoch 11/43
106/106 [==============================] - 3s 32ms/step - loss: 0.5856 - val_loss: 0.7079
Epoch 12/43
106/106 [==============================] - 3s 31ms/step - loss: 0.5845 - val_loss: 0.7070
Epoch 13/43
106/106 [==============================] - 3s 31ms/step - loss: 0.5836 - val_loss: 0.7063
Epoch 14/43
106/106 [==============================] - 3s 31ms/step - loss: 0.5830 - val_loss: 0.7058
Epoch 15/43
106/106 [==============================] - 3s 32ms/step - loss: 0.5824 - val_loss: 0.7053
Epoch 16/43
106/106 [==============================] - 3s 31ms/step - loss: 0.5820 - val_loss: 0.7049
Epoch 17/43
106/106 [==============================] - 3s 31ms/step - loss: 0.5815 - val_loss: 0.7045
Epoch 18/43
106/106 [==============================] - 3s 31ms/step - loss: 0.5811 - val_loss: 0.7042
Epoch 19/43
106/106 [==============================] - 3s 31ms/step - loss: 0.5807 - val_loss: 0.7040
Epoch 20/43
106/106 [==============================] - 3s 32ms/step - loss: 0.5802 - val_loss: 0.7037
Epoch 21/43
106/106 [==============================] - 3s 31ms/step - loss: 0.5799 - val_loss: 0.7036
Epoch 22/43
106/106 [==============================] - 3s 31ms/step - loss: 0.5796 - val_loss: 0.7033
Epoch 23/43
106/106 [==============================] - 3s 31ms/step - loss: 0.5794 - val_loss: 0.7032
Epoch 24/43
106/106 [==============================] - 3s 31ms/step - loss: 0.5791 - val_loss: 0.7031
Epoch 25/43
106/106 [==============================] - 3s 32ms/step - loss: 0.5789 - val_loss: 0.7030
Epoch 26/43
106/106 [==============================] - 3s 31ms/step - loss: 0.5785 - val_loss: 0.7029
Epoch 27/43
106/106 [==============================] - 3s 31ms/step - loss: 0.5786 - val_loss: 0.7029
Epoch 28/43
106/106 [==============================] - 3s 31ms/step - loss: 0.5783 - val_loss: 0.7028
Epoch 29/43
106/106 [==============================] - 3s 31ms/step - loss: 0.5782 - val_loss: 0.7028
Epoch 30/43
106/106 [==============================] - 3s 32ms/step - loss: 0.5779 - val_loss: 0.7028
Epoch 31/43
106/106 [==============================] - 3s 31ms/step - loss: 0.5778 - val_loss: 0.7028
Epoch 32/43
106/106 [==============================] - 3s 31ms/step - loss: 0.5776 - val_loss: 0.7027
Epoch 33/43
106/106 [==============================] - 3s 30ms/step - loss: 0.5777 - val_loss: 0.7027
Epoch 34/43
106/106 [==============================] - 3s 31ms/step - loss: 0.5773 - val_loss: 0.7027
Epoch 35/43
106/106 [==============================] - 3s 31ms/step - loss: 0.5772 - val_loss: 0.7027
Epoch 36/43
106/106 [==============================] - 3s 30ms/step - loss: 0.5771 - val_loss: 0.7026
Epoch 37/43
106/106 [==============================] - 3s 30ms/step - loss: 0.5771 - val_loss: 0.7027
Epoch 38/43
106/106 [==============================] - 3s 30ms/step - loss: 0.5771 - val_loss: 0.7027
Epoch 39/43
106/106 [==============================] - 3s 31ms/step - loss: 0.5770 - val_loss: 0.7027
Epoch 40/43
106/106 [==============================] - 3s 31ms/step - loss: 0.5769 - val_loss: 0.7027
Epoch 41/43
106/106 [==============================] - 3s 30ms/step - loss: 0.5768 - val_loss: 0.7027
Epoch 42/43
106/106 [==============================] - 3s 30ms/step - loss: 0.5767 - val_loss: 0.7027: 0.5
Epoch 43/43
106/106 [==============================] - 3s 30ms/step - loss: 0.5765 - val_loss: 0.7027
Execution time:  150.9851996898651
GRU:
Mean Absolute Error: 0.5105
Root Mean Square Error: 0.7665
Mean Square Error: 0.5875

Train RMSE: 0.767
Train MSE: 0.588
Train MAE: 0.511
###########################

MODEL:  GRU
sequence:  12h
units:  43
dropout1:  0.40519643149940265
dropout2:  0.3312343747027119
optimizer: adam
activationDense: tanh
epochs: 56
batchsize: 11
validation_split: 0.1
Model: &#34;sequential_120&#34;
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
gru_72 (GRU)                 (None, 72, 43)            5934      
_________________________________________________________________
dropout_240 (Dropout)        (None, 72, 43)            0         
_________________________________________________________________
gru_73 (GRU)                 (None, 72, 43)            11352     
_________________________________________________________________
dropout_241 (Dropout)        (None, 72, 43)            0         
_________________________________________________________________
time_distributed_120 (TimeDi (None, 72, 1)             44        
=================================================================
Total params: 17,330
Trainable params: 17,330
Non-trainable params: 0
_________________________________________________________________
Epoch 1/56
321/321 [==============================] - 17s 54ms/step - loss: 0.5485 - val_loss: 0.3351
Epoch 2/56
321/321 [==============================] - 17s 52ms/step - loss: 0.5166 - val_loss: 0.3176
Epoch 3/56
321/321 [==============================] - 16s 51ms/step - loss: 0.5099 - val_loss: 0.3154
Epoch 4/56
321/321 [==============================] - 17s 52ms/step - loss: 0.5075 - val_loss: 0.3157
Epoch 5/56
321/321 [==============================] - 16s 51ms/step - loss: 0.5060 - val_loss: 0.3169
Epoch 6/56
321/321 [==============================] - 16s 51ms/step - loss: 0.5048 - val_loss: 0.3267
Epoch 7/56
321/321 [==============================] - 16s 51ms/step - loss: 0.5055 - val_loss: 0.3382
Epoch 8/56
321/321 [==============================] - 16s 51ms/step - loss: 0.5056 - val_loss: 0.3538
Epoch 9/56
321/321 [==============================] - 16s 51ms/step - loss: 0.5045 - val_loss: 0.3556
Epoch 10/56
321/321 [==============================] - 16s 51ms/step - loss: 0.5036 - val_loss: 0.3611
Epoch 11/56
321/321 [==============================] - 16s 51ms/step - loss: 0.5028 - val_loss: 0.3596
Epoch 12/56
321/321 [==============================] - 16s 51ms/step - loss: 0.5004 - val_loss: 0.3500
Epoch 13/56
321/321 [==============================] - 16s 50ms/step - loss: 0.4990 - val_loss: 0.3612
Epoch 14/56
321/321 [==============================] - 16s 51ms/step - loss: 0.4972 - val_loss: 0.3564
Epoch 15/56
321/321 [==============================] - 16s 51ms/step - loss: 0.4958 - val_loss: 0.3481
Epoch 16/56
321/321 [==============================] - 16s 51ms/step - loss: 0.4919 - val_loss: 0.3495
Epoch 17/56
321/321 [==============================] - 16s 51ms/step - loss: 0.4923 - val_loss: 0.3558
Epoch 18/56
321/321 [==============================] - 16s 51ms/step - loss: 0.4899 - val_loss: 0.3408
Epoch 19/56
321/321 [==============================] - 16s 51ms/step - loss: 0.4883 - val_loss: 0.3393
Epoch 20/56
321/321 [==============================] - 16s 51ms/step - loss: 0.4834 - val_loss: 0.3324
Epoch 21/56
321/321 [==============================] - 17s 51ms/step - loss: 0.4835 - val_loss: 0.3308
Epoch 22/56
321/321 [==============================] - 16s 51ms/step - loss: 0.4801 - val_loss: 0.3272
Epoch 23/56
321/321 [==============================] - 16s 51ms/step - loss: 0.4795 - val_loss: 0.3221
Epoch 24/56
321/321 [==============================] - 16s 51ms/step - loss: 0.4787 - val_loss: 0.3201
Epoch 25/56
321/321 [==============================] - 16s 51ms/step - loss: 0.4771 - val_loss: 0.3163
Epoch 26/56
321/321 [==============================] - 16s 51ms/step - loss: 0.4769 - val_loss: 0.3163
Epoch 27/56
321/321 [==============================] - 16s 51ms/step - loss: 0.4750 - val_loss: 0.3197
Epoch 28/56
321/321 [==============================] - 16s 51ms/step - loss: 0.4731 - val_loss: 0.3221
Epoch 29/56
321/321 [==============================] - 16s 51ms/step - loss: 0.4726 - val_loss: 0.3216
Epoch 30/56
321/321 [==============================] - 16s 51ms/step - loss: 0.4697 - val_loss: 0.3220
Epoch 31/56
321/321 [==============================] - 16s 51ms/step - loss: 0.4708 - val_loss: 0.3179
Epoch 32/56
321/321 [==============================] - 16s 51ms/step - loss: 0.4658 - val_loss: 0.3299
Epoch 33/56
321/321 [==============================] - 16s 51ms/step - loss: 0.4638 - val_loss: 0.3179
Epoch 34/56
321/321 [==============================] - 16s 51ms/step - loss: 0.4624 - val_loss: 0.3188
Epoch 35/56
321/321 [==============================] - 16s 51ms/step - loss: 0.4619 - val_loss: 0.3259
Epoch 36/56
321/321 [==============================] - 16s 51ms/step - loss: 0.4610 - val_loss: 0.3231
Epoch 37/56
321/321 [==============================] - 16s 51ms/step - loss: 0.4619 - val_loss: 0.3088
Epoch 38/56
321/321 [==============================] - 16s 51ms/step - loss: 0.4587 - val_loss: 0.3074
Epoch 39/56
321/321 [==============================] - 16s 51ms/step - loss: 0.4577 - val_loss: 0.3125
Epoch 40/56
321/321 [==============================] - 16s 51ms/step - loss: 0.4568 - val_loss: 0.3065
Epoch 41/56
321/321 [==============================] - 16s 51ms/step - loss: 0.4567 - val_loss: 0.3124
Epoch 42/56
321/321 [==============================] - 16s 51ms/step - loss: 0.4570 - val_loss: 0.3194
Epoch 43/56
321/321 [==============================] - 16s 51ms/step - loss: 0.4529 - val_loss: 0.3000
Epoch 44/56
321/321 [==============================] - 16s 51ms/step - loss: 0.4522 - val_loss: 0.3033
Epoch 45/56
321/321 [==============================] - 16s 51ms/step - loss: 0.4524 - val_loss: 0.3069
Epoch 46/56
321/321 [==============================] - 16s 51ms/step - loss: 0.4523 - val_loss: 0.2930
Epoch 47/56
321/321 [==============================] - 16s 51ms/step - loss: 0.4505 - val_loss: 0.3020
Epoch 48/56
321/321 [==============================] - 17s 52ms/step - loss: 0.4495 - val_loss: 0.3082
Epoch 49/56
321/321 [==============================] - 16s 51ms/step - loss: 0.4530 - val_loss: 0.3009
Epoch 50/56
321/321 [==============================] - 16s 51ms/step - loss: 0.4465 - val_loss: 0.3018
Epoch 51/56
321/321 [==============================] - 16s 51ms/step - loss: 0.4451 - val_loss: 0.2974
Epoch 52/56
321/321 [==============================] - 16s 51ms/step - loss: 0.4431 - val_loss: 0.3060
Epoch 53/56
321/321 [==============================] - 16s 51ms/step - loss: 0.4420 - val_loss: 0.2923
Epoch 54/56
321/321 [==============================] - 16s 51ms/step - loss: 0.4419 - val_loss: 0.2991
Epoch 55/56
321/321 [==============================] - 16s 51ms/step - loss: 0.4424 - val_loss: 0.2979
Epoch 56/56
321/321 [==============================] - 16s 51ms/step - loss: 0.4422 - val_loss: 0.3099
Execution time:  924.7728035449982
GRU:
Mean Absolute Error: 0.3708
Root Mean Square Error: 0.8239
Mean Square Error: 0.6788

Train RMSE: 0.824
Train MSE: 0.679
Train MAE: 0.371
###########################

MODEL:  GRU
sequence:  12h
units:  45
dropout1:  0.11814836227952394
dropout2:  0.24325404382648977
optimizer: adam
activationDense: tanh
epochs: 43
batchsize: 30
validation_split: 0.2
Model: &#34;sequential_121&#34;
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
gru_74 (GRU)                 (None, 72, 45)            6480      
_________________________________________________________________
dropout_242 (Dropout)        (None, 72, 45)            0         
_________________________________________________________________
gru_75 (GRU)                 (None, 72, 45)            12420     
_________________________________________________________________
dropout_243 (Dropout)        (None, 72, 45)            0         
_________________________________________________________________
time_distributed_121 (TimeDi (None, 72, 1)             46        
=================================================================
Total params: 18,946
Trainable params: 18,946
Non-trainable params: 0
_________________________________________________________________
Epoch 1/43
105/105 [==============================] - 7s 63ms/step - loss: 0.5734 - val_loss: 0.3899
Epoch 2/43
105/105 [==============================] - 6s 58ms/step - loss: 0.5099 - val_loss: 0.3867
Epoch 3/43
105/105 [==============================] - 6s 59ms/step - loss: 0.5026 - val_loss: 0.3848
Epoch 4/43
105/105 [==============================] - 6s 57ms/step - loss: 0.4993 - val_loss: 0.3834
Epoch 5/43
105/105 [==============================] - 6s 59ms/step - loss: 0.4973 - val_loss: 0.3822
Epoch 6/43
105/105 [==============================] - 6s 58ms/step - loss: 0.4960 - val_loss: 0.3814
Epoch 7/43
105/105 [==============================] - 6s 59ms/step - loss: 0.4949 - val_loss: 0.3804
Epoch 8/43
105/105 [==============================] - 6s 59ms/step - loss: 0.4941 - val_loss: 0.3797
Epoch 9/43
105/105 [==============================] - 6s 58ms/step - loss: 0.4933 - val_loss: 0.3795
Epoch 10/43
105/105 [==============================] - 6s 59ms/step - loss: 0.4920 - val_loss: 0.3790
Epoch 11/43
105/105 [==============================] - 6s 58ms/step - loss: 0.4912 - val_loss: 0.3788
Epoch 12/43
105/105 [==============================] - 6s 58ms/step - loss: 0.4905 - val_loss: 0.3787
Epoch 13/43
105/105 [==============================] - 6s 59ms/step - loss: 0.4896 - val_loss: 0.3792
Epoch 14/43
105/105 [==============================] - 6s 58ms/step - loss: 0.4887 - val_loss: 0.3799
Epoch 15/43
105/105 [==============================] - 6s 59ms/step - loss: 0.4868 - val_loss: 0.3805
Epoch 16/43
105/105 [==============================] - 6s 58ms/step - loss: 0.4851 - val_loss: 0.3756
Epoch 17/43
105/105 [==============================] - 6s 58ms/step - loss: 0.4816 - val_loss: 0.3683
Epoch 18/43
105/105 [==============================] - 6s 60ms/step - loss: 0.4849 - val_loss: 0.3735
Epoch 19/43
105/105 [==============================] - 6s 58ms/step - loss: 0.4780 - val_loss: 0.3702
Epoch 20/43
105/105 [==============================] - 6s 58ms/step - loss: 0.4755 - val_loss: 0.3706
Epoch 21/43
105/105 [==============================] - 6s 59ms/step - loss: 0.4768 - val_loss: 0.3729
Epoch 22/43
105/105 [==============================] - 6s 59ms/step - loss: 0.4703 - val_loss: 0.3723
Epoch 23/43
105/105 [==============================] - 6s 59ms/step - loss: 0.4754 - val_loss: 0.3741
Epoch 24/43
105/105 [==============================] - 6s 58ms/step - loss: 0.4676 - val_loss: 0.3737
Epoch 25/43
105/105 [==============================] - 6s 58ms/step - loss: 0.4710 - val_loss: 0.3748
Epoch 26/43
105/105 [==============================] - 6s 59ms/step - loss: 0.4676 - val_loss: 0.3753
Epoch 27/43
105/105 [==============================] - 6s 58ms/step - loss: 0.4673 - val_loss: 0.3766
Epoch 28/43
105/105 [==============================] - 6s 59ms/step - loss: 0.4672 - val_loss: 0.3760
Epoch 29/43
105/105 [==============================] - 6s 58ms/step - loss: 0.4644 - val_loss: 0.3783
Epoch 30/43
105/105 [==============================] - 6s 58ms/step - loss: 0.4641 - val_loss: 0.3785
Epoch 31/43
105/105 [==============================] - 6s 60ms/step - loss: 0.4609 - val_loss: 0.3793
Epoch 32/43
105/105 [==============================] - 6s 58ms/step - loss: 0.4613 - val_loss: 0.3799
Epoch 33/43
105/105 [==============================] - 6s 59ms/step - loss: 0.4599 - val_loss: 0.3805
Epoch 34/43
105/105 [==============================] - 6s 59ms/step - loss: 0.4592 - val_loss: 0.3807
Epoch 35/43
105/105 [==============================] - 6s 58ms/step - loss: 0.4574 - val_loss: 0.3808
Epoch 36/43
105/105 [==============================] - 6s 60ms/step - loss: 0.4579 - val_loss: 0.3817
Epoch 37/43
105/105 [==============================] - 6s 58ms/step - loss: 0.4562 - val_loss: 0.3818
Epoch 38/43
105/105 [==============================] - 6s 58ms/step - loss: 0.4564 - val_loss: 0.3825
Epoch 39/43
105/105 [==============================] - 6s 60ms/step - loss: 0.4547 - val_loss: 0.3836
Epoch 40/43
105/105 [==============================] - 6s 58ms/step - loss: 0.4547 - val_loss: 0.3839
Epoch 41/43
105/105 [==============================] - 6s 60ms/step - loss: 0.4540 - val_loss: 0.3846
Epoch 42/43
105/105 [==============================] - 6s 58ms/step - loss: 0.4524 - val_loss: 0.3851
Epoch 43/43
105/105 [==============================] - 6s 58ms/step - loss: 0.4531 - val_loss: 0.3851
Execution time:  272.34867572784424
GRU:
Mean Absolute Error: 0.3070
Root Mean Square Error: 0.7978
Mean Square Error: 0.6365

Train RMSE: 0.798
Train MSE: 0.637
Train MAE: 0.307
###########################

MODEL:  GRU
sequence:  12h
units:  43
dropout1:  0.40519643149940265
dropout2:  0.3312343747027119
optimizer: adam
activationDense: sigmoid
epochs: 56
batchsize: 11
validation_split: 0.1
Model: &#34;sequential_122&#34;
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
gru_76 (GRU)                 (None, 72, 43)            5934      
_________________________________________________________________
dropout_244 (Dropout)        (None, 72, 43)            0         
_________________________________________________________________
gru_77 (GRU)                 (None, 72, 43)            11352     
_________________________________________________________________
dropout_245 (Dropout)        (None, 72, 43)            0         
_________________________________________________________________
time_distributed_122 (TimeDi (None, 72, 1)             44        
=================================================================
Total params: 17,330
Trainable params: 17,330
Non-trainable params: 0
_________________________________________________________________
Epoch 1/56
321/321 [==============================] - 17s 55ms/step - loss: 0.6954 - val_loss: 0.8142
Epoch 2/56
321/321 [==============================] - 17s 52ms/step - loss: 0.6455 - val_loss: 0.8072
Epoch 3/56
321/321 [==============================] - 17s 52ms/step - loss: 0.6422 - val_loss: 0.8057
Epoch 4/56
321/321 [==============================] - 17s 52ms/step - loss: 0.6397 - val_loss: 0.8050
Epoch 5/56
321/321 [==============================] - 17s 52ms/step - loss: 0.6366 - val_loss: 0.8047
Epoch 6/56
321/321 [==============================] - 17s 52ms/step - loss: 0.6317 - val_loss: 0.8048
Epoch 7/56
321/321 [==============================] - 16s 51ms/step - loss: 0.6282 - val_loss: 0.8047
Epoch 8/56
321/321 [==============================] - 16s 51ms/step - loss: 0.6250 - val_loss: 0.8040
Epoch 9/56
321/321 [==============================] - 16s 51ms/step - loss: 0.6199 - val_loss: 0.8040
Epoch 10/56
321/321 [==============================] - 16s 51ms/step - loss: 0.6174 - val_loss: 0.8039
Epoch 11/56
321/321 [==============================] - 16s 51ms/step - loss: 0.6681 - val_loss: 0.8039
Epoch 12/56
321/321 [==============================] - 16s 51ms/step - loss: 0.6582 - val_loss: 0.8039
Epoch 13/56
321/321 [==============================] - 16s 51ms/step - loss: 0.6236 - val_loss: 0.8039
Epoch 14/56
321/321 [==============================] - 16s 51ms/step - loss: 0.6162 - val_loss: 0.8040
Epoch 15/56
321/321 [==============================] - 16s 51ms/step - loss: 0.6153 - val_loss: 0.8038
Epoch 16/56
321/321 [==============================] - 16s 51ms/step - loss: 0.6156 - val_loss: 0.8038
Epoch 17/56
321/321 [==============================] - 16s 51ms/step - loss: 0.6136 - val_loss: 0.8038
Epoch 18/56
321/321 [==============================] - 16s 51ms/step - loss: 0.6164 - val_loss: 0.8038
Epoch 19/56
321/321 [==============================] - 16s 51ms/step - loss: 0.6127 - val_loss: 0.8038
Epoch 20/56
321/321 [==============================] - 16s 51ms/step - loss: 0.6111 - val_loss: 0.8038
Epoch 21/56
321/321 [==============================] - 16s 51ms/step - loss: 0.6111 - val_loss: 0.8039
Epoch 22/56
321/321 [==============================] - 16s 51ms/step - loss: 0.6070 - val_loss: 0.8038
Epoch 23/56
321/321 [==============================] - 16s 51ms/step - loss: 0.6079 - val_loss: 0.8038
Epoch 24/56
321/321 [==============================] - 16s 51ms/step - loss: 0.6068 - val_loss: 0.8038
Epoch 25/56
321/321 [==============================] - 16s 51ms/step - loss: 0.6062 - val_loss: 0.8038
Epoch 26/56
321/321 [==============================] - 16s 51ms/step - loss: 0.6057 - val_loss: 0.8038
Epoch 27/56
321/321 [==============================] - 16s 51ms/step - loss: 0.6049 - val_loss: 0.8037
Epoch 28/56
321/321 [==============================] - 16s 51ms/step - loss: 0.6064 - val_loss: 0.8038
Epoch 29/56
321/321 [==============================] - 17s 52ms/step - loss: 0.6040 - val_loss: 0.8037
Epoch 30/56
321/321 [==============================] - 16s 51ms/step - loss: 0.6040 - val_loss: 0.8038
Epoch 31/56
321/321 [==============================] - 16s 51ms/step - loss: 0.6015 - val_loss: 0.8037
Epoch 32/56
321/321 [==============================] - 16s 51ms/step - loss: 0.6048 - val_loss: 0.8038
Epoch 33/56
321/321 [==============================] - 16s 51ms/step - loss: 0.6008 - val_loss: 0.8037
Epoch 34/56
321/321 [==============================] - 16s 51ms/step - loss: 0.6003 - val_loss: 0.8037
Epoch 35/56
321/321 [==============================] - 16s 51ms/step - loss: 0.6002 - val_loss: 0.8038
Epoch 36/56
321/321 [==============================] - 16s 51ms/step - loss: 0.5985 - val_loss: 0.8037
Epoch 37/56
321/321 [==============================] - 16s 51ms/step - loss: 0.6000 - val_loss: 0.8037
Epoch 38/56
321/321 [==============================] - 16s 51ms/step - loss: 0.5981 - val_loss: 0.8037
Epoch 39/56
321/321 [==============================] - 16s 51ms/step - loss: 0.6007 - val_loss: 0.8038
Epoch 40/56
321/321 [==============================] - 16s 51ms/step - loss: 0.5991 - val_loss: 0.8037
Epoch 41/56
321/321 [==============================] - 17s 52ms/step - loss: 0.5958 - val_loss: 0.8037
Epoch 42/56
321/321 [==============================] - 16s 51ms/step - loss: 0.5990 - val_loss: 0.8037
Epoch 43/56
321/321 [==============================] - 16s 51ms/step - loss: 0.5957 - val_loss: 0.8037
Epoch 44/56
321/321 [==============================] - 16s 51ms/step - loss: 0.5972 - val_loss: 0.8037
Epoch 45/56
321/321 [==============================] - 16s 51ms/step - loss: 0.5949 - val_loss: 0.8037
Epoch 46/56
321/321 [==============================] - 16s 51ms/step - loss: 0.5961 - val_loss: 0.8038
Epoch 47/56
321/321 [==============================] - 16s 51ms/step - loss: 0.5939 - val_loss: 0.8037
Epoch 48/56
321/321 [==============================] - 16s 51ms/step - loss: 0.5937 - val_loss: 0.8037
Epoch 49/56
321/321 [==============================] - 16s 51ms/step - loss: 0.5944 - val_loss: 0.8037
Epoch 50/56
321/321 [==============================] - 17s 52ms/step - loss: 0.5950 - val_loss: 0.8037
Epoch 51/56
321/321 [==============================] - 16s 51ms/step - loss: 0.5921 - val_loss: 0.8037
Epoch 52/56
321/321 [==============================] - 16s 51ms/step - loss: 0.5921 - val_loss: 0.8038
Epoch 53/56
321/321 [==============================] - 16s 51ms/step - loss: 0.5902 - val_loss: 0.8037
Epoch 54/56
321/321 [==============================] - 16s 51ms/step - loss: 0.5926 - val_loss: 0.8037
Epoch 55/56
321/321 [==============================] - 16s 51ms/step - loss: 0.5917 - val_loss: 0.8037
Epoch 56/56
321/321 [==============================] - 16s 51ms/step - loss: 0.5960 - val_loss: 0.8038
Execution time:  926.9670395851135
GRU:
Mean Absolute Error: 0.6128
Root Mean Square Error: 0.9128
Mean Square Error: 0.8333

Train RMSE: 0.913
Train MSE: 0.833
Train MAE: 0.613
###########################

MODEL:  GRU
sequence:  12h
units:  45
dropout1:  0.11814836227952394
dropout2:  0.24325404382648977
optimizer: adam
activationDense: sigmoid
epochs: 43
batchsize: 30
validation_split: 0.2
Model: &#34;sequential_123&#34;
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
gru_78 (GRU)                 (None, 72, 45)            6480      
_________________________________________________________________
dropout_246 (Dropout)        (None, 72, 45)            0         
_________________________________________________________________
gru_79 (GRU)                 (None, 72, 45)            12420     
_________________________________________________________________
dropout_247 (Dropout)        (None, 72, 45)            0         
_________________________________________________________________
time_distributed_123 (TimeDi (None, 72, 1)             46        
=================================================================
Total params: 18,946
Trainable params: 18,946
Non-trainable params: 0
_________________________________________________________________
Epoch 1/43
105/105 [==============================] - 7s 70ms/step - loss: 0.7493 - val_loss: 0.7691
Epoch 2/43
105/105 [==============================] - 6s 58ms/step - loss: 0.6569 - val_loss: 0.7544
Epoch 3/43
105/105 [==============================] - 6s 58ms/step - loss: 0.6451 - val_loss: 0.7480
Epoch 4/43
105/105 [==============================] - 6s 60ms/step - loss: 0.6428 - val_loss: 0.7461
Epoch 5/43
105/105 [==============================] - 6s 59ms/step - loss: 0.6395 - val_loss: 0.7436
Epoch 6/43
105/105 [==============================] - 6s 59ms/step - loss: 0.6381 - val_loss: 0.7414
Epoch 7/43
105/105 [==============================] - 6s 59ms/step - loss: 0.6371 - val_loss: 0.7394
Epoch 8/43
105/105 [==============================] - 6s 59ms/step - loss: 0.6369 - val_loss: 0.7391
Epoch 9/43
105/105 [==============================] - 6s 60ms/step - loss: 0.6344 - val_loss: 0.7364
Epoch 10/43
105/105 [==============================] - 6s 59ms/step - loss: 0.6332 - val_loss: 0.7348
Epoch 11/43
105/105 [==============================] - 6s 59ms/step - loss: 0.6323 - val_loss: 0.7334
Epoch 12/43
105/105 [==============================] - 6s 60ms/step - loss: 0.6303 - val_loss: 0.7302
Epoch 13/43
105/105 [==============================] - 6s 59ms/step - loss: 0.6276 - val_loss: 0.7230
Epoch 14/43
105/105 [==============================] - 6s 60ms/step - loss: 0.6250 - val_loss: 0.7210
Epoch 15/43
105/105 [==============================] - 6s 59ms/step - loss: 0.6199 - val_loss: 0.7193
Epoch 16/43
105/105 [==============================] - 6s 59ms/step - loss: 0.6173 - val_loss: 0.7185
Epoch 17/43
105/105 [==============================] - 6s 60ms/step - loss: 0.6148 - val_loss: 0.7174
Epoch 18/43
105/105 [==============================] - 6s 59ms/step - loss: 0.6125 - val_loss: 0.7162
Epoch 19/43
105/105 [==============================] - 6s 60ms/step - loss: 0.6103 - val_loss: 0.7154
Epoch 20/43
105/105 [==============================] - 6s 59ms/step - loss: 0.6102 - val_loss: 0.7145
Epoch 21/43
105/105 [==============================] - 6s 58ms/step - loss: 0.6090 - val_loss: 0.7162
Epoch 22/43
105/105 [==============================] - 6s 59ms/step - loss: 0.6051 - val_loss: 0.7136
Epoch 23/43
105/105 [==============================] - 6s 58ms/step - loss: 0.6054 - val_loss: 0.7145
Epoch 24/43
105/105 [==============================] - 6s 59ms/step - loss: 0.6022 - val_loss: 0.7137
Epoch 25/43
105/105 [==============================] - 6s 58ms/step - loss: 0.6033 - val_loss: 0.7139
Epoch 26/43
105/105 [==============================] - 6s 58ms/step - loss: 0.6019 - val_loss: 0.7136
Epoch 27/43
105/105 [==============================] - 6s 60ms/step - loss: 0.6019 - val_loss: 0.7135
Epoch 28/43
105/105 [==============================] - 6s 58ms/step - loss: 0.6006 - val_loss: 0.7135
Epoch 29/43
105/105 [==============================] - 6s 58ms/step - loss: 0.5994 - val_loss: 0.7133
Epoch 30/43
105/105 [==============================] - 6s 59ms/step - loss: 0.6005 - val_loss: 0.7128
Epoch 31/43
105/105 [==============================] - 6s 58ms/step - loss: 0.6030 - val_loss: 0.7125
Epoch 32/43
105/105 [==============================] - 6s 59ms/step - loss: 0.6002 - val_loss: 0.7123
Epoch 33/43
105/105 [==============================] - 6s 58ms/step - loss: 0.5992 - val_loss: 0.7127
Epoch 34/43
105/105 [==============================] - 6s 58ms/step - loss: 0.5980 - val_loss: 0.7126
Epoch 35/43
105/105 [==============================] - 6s 59ms/step - loss: 0.5973 - val_loss: 0.7124
Epoch 36/43
105/105 [==============================] - 6s 58ms/step - loss: 0.5985 - val_loss: 0.7128
Epoch 37/43
105/105 [==============================] - 6s 60ms/step - loss: 0.6031 - val_loss: 0.7119
Epoch 38/43
105/105 [==============================] - 6s 58ms/step - loss: 0.6008 - val_loss: 0.7117
Epoch 39/43
105/105 [==============================] - 6s 58ms/step - loss: 0.5997 - val_loss: 0.7125
Epoch 40/43
105/105 [==============================] - 6s 60ms/step - loss: 0.5952 - val_loss: 0.7122
Epoch 41/43
105/105 [==============================] - 6s 58ms/step - loss: 0.5976 - val_loss: 0.7121
Epoch 42/43
105/105 [==============================] - 6s 60ms/step - loss: 0.5943 - val_loss: 0.7119
Epoch 43/43
105/105 [==============================] - 6s 58ms/step - loss: 0.5975 - val_loss: 0.7119
Execution time:  276.7366795539856
GRU:
Mean Absolute Error: 0.5877
Root Mean Square Error: 0.8815
Mean Square Error: 0.7770

Train RMSE: 0.881
Train MSE: 0.777
Train MAE: 0.588
###########################

MODEL:  GRU
sequence:  12h
units:  43
dropout1:  0.40519643149940265
dropout2:  0.3312343747027119
optimizer: adadelta
activationDense: tanh
epochs: 56
batchsize: 11
validation_split: 0.1
Model: &#34;sequential_124&#34;
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
gru_80 (GRU)                 (None, 72, 43)            5934      
_________________________________________________________________
dropout_248 (Dropout)        (None, 72, 43)            0         
_________________________________________________________________
gru_81 (GRU)                 (None, 72, 43)            11352     
_________________________________________________________________
dropout_249 (Dropout)        (None, 72, 43)            0         
_________________________________________________________________
time_distributed_124 (TimeDi (None, 72, 1)             44        
=================================================================
Total params: 17,330
Trainable params: 17,330
Non-trainable params: 0
_________________________________________________________________
Epoch 1/56
321/321 [==============================] - 17s 54ms/step - loss: 0.7154 - val_loss: 0.8282
Epoch 2/56
321/321 [==============================] - 16s 51ms/step - loss: 0.7137 - val_loss: 0.8241
Epoch 3/56
321/321 [==============================] - 16s 51ms/step - loss: 0.7119 - val_loss: 0.8198
Epoch 4/56
321/321 [==============================] - 16s 51ms/step - loss: 0.7100 - val_loss: 0.8154
Epoch 5/56
321/321 [==============================] - 16s 51ms/step - loss: 0.7081 - val_loss: 0.8109
Epoch 6/56
321/321 [==============================] - 17s 52ms/step - loss: 0.7063 - val_loss: 0.8063
Epoch 7/56
321/321 [==============================] - 16s 51ms/step - loss: 0.7042 - val_loss: 0.8017
Epoch 8/56
321/321 [==============================] - 16s 51ms/step - loss: 0.7024 - val_loss: 0.7970
Epoch 9/56
321/321 [==============================] - 16s 51ms/step - loss: 0.7004 - val_loss: 0.7922
Epoch 10/56
321/321 [==============================] - 16s 51ms/step - loss: 0.6983 - val_loss: 0.7874
Epoch 11/56
321/321 [==============================] - 17s 52ms/step - loss: 0.6964 - val_loss: 0.7825
Epoch 12/56
321/321 [==============================] - 16s 51ms/step - loss: 0.6944 - val_loss: 0.7776
Epoch 13/56
321/321 [==============================] - 16s 51ms/step - loss: 0.6923 - val_loss: 0.7726
Epoch 14/56
321/321 [==============================] - 16s 51ms/step - loss: 0.6903 - val_loss: 0.7676
Epoch 15/56
321/321 [==============================] - 16s 51ms/step - loss: 0.6881 - val_loss: 0.7625
Epoch 16/56
321/321 [==============================] - 16s 51ms/step - loss: 0.6860 - val_loss: 0.7573
Epoch 17/56
321/321 [==============================] - 16s 51ms/step - loss: 0.6839 - val_loss: 0.7521
Epoch 18/56
321/321 [==============================] - 17s 52ms/step - loss: 0.6818 - val_loss: 0.7468
Epoch 19/56
321/321 [==============================] - 16s 51ms/step - loss: 0.6798 - val_loss: 0.7415
Epoch 20/56
321/321 [==============================] - 17s 52ms/step - loss: 0.6775 - val_loss: 0.7361
Epoch 21/56
321/321 [==============================] - 17s 52ms/step - loss: 0.6755 - val_loss: 0.7308
Epoch 22/56
321/321 [==============================] - 16s 51ms/step - loss: 0.6734 - val_loss: 0.7254
Epoch 23/56
321/321 [==============================] - 16s 51ms/step - loss: 0.6714 - val_loss: 0.7199
Epoch 24/56
321/321 [==============================] - 16s 51ms/step - loss: 0.6693 - val_loss: 0.7145
Epoch 25/56
321/321 [==============================] - 17s 51ms/step - loss: 0.6672 - val_loss: 0.7090
Epoch 26/56
321/321 [==============================] - 16s 51ms/step - loss: 0.6652 - val_loss: 0.7034
Epoch 27/56
321/321 [==============================] - 16s 51ms/step - loss: 0.6631 - val_loss: 0.6978
Epoch 28/56
321/321 [==============================] - 17s 52ms/step - loss: 0.6610 - val_loss: 0.6921
Epoch 29/56
321/321 [==============================] - 16s 51ms/step - loss: 0.6589 - val_loss: 0.6863
Epoch 30/56
321/321 [==============================] - 16s 51ms/step - loss: 0.6568 - val_loss: 0.6804
Epoch 31/56
321/321 [==============================] - 17s 51ms/step - loss: 0.6546 - val_loss: 0.6744
Epoch 32/56
321/321 [==============================] - 17s 51ms/step - loss: 0.6524 - val_loss: 0.6683
Epoch 33/56
321/321 [==============================] - 17s 51ms/step - loss: 0.6501 - val_loss: 0.6621
Epoch 34/56
321/321 [==============================] - 16s 51ms/step - loss: 0.6478 - val_loss: 0.6557
Epoch 35/56
321/321 [==============================] - 17s 53ms/step - loss: 0.6455 - val_loss: 0.6492
Epoch 36/56
321/321 [==============================] - 17s 51ms/step - loss: 0.6431 - val_loss: 0.6426
Epoch 37/56
321/321 [==============================] - 17s 51ms/step - loss: 0.6407 - val_loss: 0.6359
Epoch 38/56
321/321 [==============================] - 16s 51ms/step - loss: 0.6383 - val_loss: 0.6290
Epoch 39/56
321/321 [==============================] - 16s 51ms/step - loss: 0.6358 - val_loss: 0.6220
Epoch 40/56
321/321 [==============================] - 17s 52ms/step - loss: 0.6334 - val_loss: 0.6149
Epoch 41/56
321/321 [==============================] - 16s 51ms/step - loss: 0.6308 - val_loss: 0.6077
Epoch 42/56
321/321 [==============================] - 16s 51ms/step - loss: 0.6283 - val_loss: 0.6003
Epoch 43/56
321/321 [==============================] - 16s 51ms/step - loss: 0.6256 - val_loss: 0.5929
Epoch 44/56
321/321 [==============================] - 16s 51ms/step - loss: 0.6229 - val_loss: 0.5853
Epoch 45/56
321/321 [==============================] - 16s 51ms/step - loss: 0.6204 - val_loss: 0.5776
Epoch 46/56
321/321 [==============================] - 16s 51ms/step - loss: 0.6177 - val_loss: 0.5699
Epoch 47/56
321/321 [==============================] - 16s 51ms/step - loss: 0.6153 - val_loss: 0.5621
Epoch 48/56
321/321 [==============================] - 16s 51ms/step - loss: 0.6126 - val_loss: 0.5543
Epoch 49/56
321/321 [==============================] - 16s 51ms/step - loss: 0.6100 - val_loss: 0.5463
Epoch 50/56
321/321 [==============================] - 16s 51ms/step - loss: 0.6071 - val_loss: 0.5383
Epoch 51/56
321/321 [==============================] - 16s 51ms/step - loss: 0.6047 - val_loss: 0.5304
Epoch 52/56
321/321 [==============================] - 16s 51ms/step - loss: 0.6019 - val_loss: 0.5225
Epoch 53/56
321/321 [==============================] - 16s 51ms/step - loss: 0.5996 - val_loss: 0.5147
Epoch 54/56
321/321 [==============================] - 16s 51ms/step - loss: 0.5969 - val_loss: 0.5069
Epoch 55/56
321/321 [==============================] - 16s 51ms/step - loss: 0.5943 - val_loss: 0.4991
Epoch 56/56
321/321 [==============================] - 16s 51ms/step - loss: 0.5919 - val_loss: 0.4913
Execution time:  930.4160780906677
GRU:
Mean Absolute Error: 0.5229
Root Mean Square Error: 0.8483
Mean Square Error: 0.7196

Train RMSE: 0.848
Train MSE: 0.720
Train MAE: 0.523
###########################

MODEL:  GRU
sequence:  12h
units:  45
dropout1:  0.11814836227952394
dropout2:  0.24325404382648977
optimizer: adadelta
activationDense: tanh
epochs: 43
batchsize: 30
validation_split: 0.2
Model: &#34;sequential_125&#34;
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
gru_82 (GRU)                 (None, 72, 45)            6480      
_________________________________________________________________
dropout_250 (Dropout)        (None, 72, 45)            0         
_________________________________________________________________
gru_83 (GRU)                 (None, 72, 45)            12420     
_________________________________________________________________
dropout_251 (Dropout)        (None, 72, 45)            0         
_________________________________________________________________
time_distributed_125 (TimeDi (None, 72, 1)             46        
=================================================================
Total params: 18,946
Trainable params: 18,946
Non-trainable params: 0
_________________________________________________________________
Epoch 1/43
105/105 [==============================] - 7s 63ms/step - loss: 0.7264 - val_loss: 0.7220
Epoch 2/43
105/105 [==============================] - 6s 59ms/step - loss: 0.7256 - val_loss: 0.7211
Epoch 3/43
105/105 [==============================] - 6s 59ms/step - loss: 0.7250 - val_loss: 0.7201
Epoch 4/43
105/105 [==============================] - 6s 58ms/step - loss: 0.7242 - val_loss: 0.7191
Epoch 5/43
105/105 [==============================] - 6s 59ms/step - loss: 0.7235 - val_loss: 0.7180
Epoch 6/43
105/105 [==============================] - 6s 58ms/step - loss: 0.7227 - val_loss: 0.7169
Epoch 7/43
105/105 [==============================] - 6s 58ms/step - loss: 0.7218 - val_loss: 0.7158
Epoch 8/43
105/105 [==============================] - 6s 59ms/step - loss: 0.7211 - val_loss: 0.7147
Epoch 9/43
105/105 [==============================] - 6s 58ms/step - loss: 0.7203 - val_loss: 0.7136
Epoch 10/43
105/105 [==============================] - 6s 59ms/step - loss: 0.7194 - val_loss: 0.7124
Epoch 11/43
105/105 [==============================] - 6s 58ms/step - loss: 0.7186 - val_loss: 0.7112
Epoch 12/43
105/105 [==============================] - 6s 58ms/step - loss: 0.7178 - val_loss: 0.7101
Epoch 13/43
105/105 [==============================] - 6s 60ms/step - loss: 0.7169 - val_loss: 0.7089
Epoch 14/43
105/105 [==============================] - 6s 58ms/step - loss: 0.7161 - val_loss: 0.7077
Epoch 15/43
105/105 [==============================] - 6s 60ms/step - loss: 0.7153 - val_loss: 0.7065
Epoch 16/43
105/105 [==============================] - 6s 58ms/step - loss: 0.7144 - val_loss: 0.7052
Epoch 17/43
105/105 [==============================] - 6s 58ms/step - loss: 0.7134 - val_loss: 0.7040
Epoch 18/43
105/105 [==============================] - 6s 59ms/step - loss: 0.7126 - val_loss: 0.7028
Epoch 19/43
105/105 [==============================] - 6s 59ms/step - loss: 0.7118 - val_loss: 0.7015
Epoch 20/43
105/105 [==============================] - 6s 58ms/step - loss: 0.7109 - val_loss: 0.7003
Epoch 21/43
105/105 [==============================] - 6s 59ms/step - loss: 0.7100 - val_loss: 0.6990
Epoch 22/43
105/105 [==============================] - 6s 58ms/step - loss: 0.7091 - val_loss: 0.6977
Epoch 23/43
105/105 [==============================] - 6s 61ms/step - loss: 0.7082 - val_loss: 0.6964
Epoch 24/43
105/105 [==============================] - 6s 58ms/step - loss: 0.7073 - val_loss: 0.6951
Epoch 25/43
105/105 [==============================] - 6s 58ms/step - loss: 0.7064 - val_loss: 0.6938
Epoch 26/43
105/105 [==============================] - 6s 60ms/step - loss: 0.7056 - val_loss: 0.6925
Epoch 27/43
105/105 [==============================] - 6s 58ms/step - loss: 0.7046 - val_loss: 0.6912
Epoch 28/43
105/105 [==============================] - 6s 60ms/step - loss: 0.7037 - val_loss: 0.6899
Epoch 29/43
105/105 [==============================] - 6s 58ms/step - loss: 0.7028 - val_loss: 0.6885
Epoch 30/43
105/105 [==============================] - 6s 58ms/step - loss: 0.7019 - val_loss: 0.6872
Epoch 31/43
105/105 [==============================] - 6s 59ms/step - loss: 0.7010 - val_loss: 0.6858
Epoch 32/43
105/105 [==============================] - 6s 58ms/step - loss: 0.7000 - val_loss: 0.6844
Epoch 33/43
105/105 [==============================] - 6s 59ms/step - loss: 0.6991 - val_loss: 0.6831
Epoch 34/43
105/105 [==============================] - 6s 58ms/step - loss: 0.6981 - val_loss: 0.6817
Epoch 35/43
105/105 [==============================] - 6s 58ms/step - loss: 0.6971 - val_loss: 0.6803
Epoch 36/43
105/105 [==============================] - 6s 60ms/step - loss: 0.6961 - val_loss: 0.6788
Epoch 37/43
105/105 [==============================] - 6s 58ms/step - loss: 0.6952 - val_loss: 0.6774
Epoch 38/43
105/105 [==============================] - 6s 59ms/step - loss: 0.6943 - val_loss: 0.6760
Epoch 39/43
105/105 [==============================] - 6s 59ms/step - loss: 0.6933 - val_loss: 0.6745
Epoch 40/43
105/105 [==============================] - 6s 58ms/step - loss: 0.6923 - val_loss: 0.6731
Epoch 41/43
105/105 [==============================] - 6s 60ms/step - loss: 0.6913 - val_loss: 0.6716
Epoch 42/43
105/105 [==============================] - 6s 58ms/step - loss: 0.6904 - val_loss: 0.6702
Epoch 43/43
105/105 [==============================] - 6s 58ms/step - loss: 0.6894 - val_loss: 0.6687
Execution time:  272.9143626689911
GRU:
Mean Absolute Error: 0.6772
Root Mean Square Error: 0.9682
Mean Square Error: 0.9374

Train RMSE: 0.968
Train MSE: 0.937
Train MAE: 0.677
###########################

MODEL:  GRU
sequence:  12h
units:  43
dropout1:  0.40519643149940265
dropout2:  0.3312343747027119
optimizer: adadelta
activationDense: sigmoid
epochs: 56
batchsize: 11
validation_split: 0.1
Model: &#34;sequential_126&#34;
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
gru_84 (GRU)                 (None, 72, 43)            5934      
_________________________________________________________________
dropout_252 (Dropout)        (None, 72, 43)            0         
_________________________________________________________________
gru_85 (GRU)                 (None, 72, 43)            11352     
_________________________________________________________________
dropout_253 (Dropout)        (None, 72, 43)            0         
_________________________________________________________________
time_distributed_126 (TimeDi (None, 72, 1)             44        
=================================================================
Total params: 17,330
Trainable params: 17,330
Non-trainable params: 0
_________________________________________________________________
Epoch 1/56
321/321 [==============================] - 17s 54ms/step - loss: 0.8985 - val_loss: 1.3038
Epoch 2/56
321/321 [==============================] - 16s 51ms/step - loss: 0.8980 - val_loss: 1.3027
Epoch 3/56
321/321 [==============================] - 17s 52ms/step - loss: 0.8975 - val_loss: 1.3014
Epoch 4/56
321/321 [==============================] - 17s 52ms/step - loss: 0.8969 - val_loss: 1.3001
Epoch 5/56
321/321 [==============================] - 17s 52ms/step - loss: 0.8964 - val_loss: 1.2988
Epoch 6/56
321/321 [==============================] - 16s 51ms/step - loss: 0.8958 - val_loss: 1.2974
Epoch 7/56
321/321 [==============================] - 16s 51ms/step - loss: 0.8952 - val_loss: 1.2959
Epoch 8/56
321/321 [==============================] - 16s 51ms/step - loss: 0.8945 - val_loss: 1.2944
Epoch 9/56
321/321 [==============================] - 16s 51ms/step - loss: 0.8938 - val_loss: 1.2929
Epoch 10/56
321/321 [==============================] - 16s 51ms/step - loss: 0.8932 - val_loss: 1.2913
Epoch 11/56
321/321 [==============================] - 16s 51ms/step - loss: 0.8924 - val_loss: 1.2897
Epoch 12/56
321/321 [==============================] - 16s 51ms/step - loss: 0.8917 - val_loss: 1.2880
Epoch 13/56
321/321 [==============================] - 16s 51ms/step - loss: 0.8910 - val_loss: 1.2863
Epoch 14/56
321/321 [==============================] - 16s 51ms/step - loss: 0.8902 - val_loss: 1.2846
Epoch 15/56
321/321 [==============================] - 16s 51ms/step - loss: 0.8894 - val_loss: 1.2828
Epoch 16/56
321/321 [==============================] - 16s 51ms/step - loss: 0.8886 - val_loss: 1.2809
Epoch 17/56
321/321 [==============================] - 16s 51ms/step - loss: 0.8878 - val_loss: 1.2790
Epoch 18/56
321/321 [==============================] - 16s 51ms/step - loss: 0.8869 - val_loss: 1.2771
Epoch 19/56
321/321 [==============================] - 16s 51ms/step - loss: 0.8860 - val_loss: 1.2751
Epoch 20/56
321/321 [==============================] - 16s 51ms/step - loss: 0.8851 - val_loss: 1.2730
Epoch 21/56
321/321 [==============================] - 16s 51ms/step - loss: 0.8842 - val_loss: 1.2709
Epoch 22/56
321/321 [==============================] - 16s 51ms/step - loss: 0.8832 - val_loss: 1.2688
Epoch 23/56
321/321 [==============================] - 16s 51ms/step - loss: 0.8823 - val_loss: 1.2666
Epoch 24/56
321/321 [==============================] - 16s 51ms/step - loss: 0.8813 - val_loss: 1.2643
Epoch 25/56
321/321 [==============================] - 16s 51ms/step - loss: 0.8802 - val_loss: 1.2620
Epoch 26/56
321/321 [==============================] - 16s 51ms/step - loss: 0.8792 - val_loss: 1.2597
Epoch 27/56
321/321 [==============================] - 16s 51ms/step - loss: 0.8781 - val_loss: 1.2572
Epoch 28/56
321/321 [==============================] - 16s 51ms/step - loss: 0.8770 - val_loss: 1.2548
Epoch 29/56
321/321 [==============================] - 16s 51ms/step - loss: 0.8759 - val_loss: 1.2522
Epoch 30/56
321/321 [==============================] - 16s 51ms/step - loss: 0.8747 - val_loss: 1.2496
Epoch 31/56
321/321 [==============================] - 16s 51ms/step - loss: 0.8736 - val_loss: 1.2469
Epoch 32/56
321/321 [==============================] - 16s 51ms/step - loss: 0.8723 - val_loss: 1.2442
Epoch 33/56
321/321 [==============================] - 16s 51ms/step - loss: 0.8711 - val_loss: 1.2414
Epoch 34/56
321/321 [==============================] - 16s 51ms/step - loss: 0.8698 - val_loss: 1.2385
Epoch 35/56
321/321 [==============================] - 16s 51ms/step - loss: 0.8685 - val_loss: 1.2356
Epoch 36/56
321/321 [==============================] - 16s 51ms/step - loss: 0.8671 - val_loss: 1.2326
Epoch 37/56
321/321 [==============================] - 16s 51ms/step - loss: 0.8658 - val_loss: 1.2295
Epoch 38/56
321/321 [==============================] - 16s 51ms/step - loss: 0.8644 - val_loss: 1.2264
Epoch 39/56
321/321 [==============================] - 16s 51ms/step - loss: 0.8630 - val_loss: 1.2232
Epoch 40/56
321/321 [==============================] - 16s 51ms/step - loss: 0.8615 - val_loss: 1.2199
Epoch 41/56
321/321 [==============================] - 16s 51ms/step - loss: 0.8601 - val_loss: 1.2165
Epoch 42/56
321/321 [==============================] - 16s 51ms/step - loss: 0.8585 - val_loss: 1.2130
Epoch 43/56
321/321 [==============================] - 16s 51ms/step - loss: 0.8569 - val_loss: 1.2095
Epoch 44/56
321/321 [==============================] - 16s 51ms/step - loss: 0.8553 - val_loss: 1.2059
Epoch 45/56
321/321 [==============================] - 16s 51ms/step - loss: 0.8536 - val_loss: 1.2021
Epoch 46/56
321/321 [==============================] - 16s 51ms/step - loss: 0.8519 - val_loss: 1.1983
Epoch 47/56
321/321 [==============================] - 16s 51ms/step - loss: 0.8502 - val_loss: 1.1945
Epoch 48/56
321/321 [==============================] - 16s 51ms/step - loss: 0.8484 - val_loss: 1.1905
Epoch 49/56
321/321 [==============================] - 16s 51ms/step - loss: 0.8466 - val_loss: 1.1864
Epoch 50/56
321/321 [==============================] - 16s 51ms/step - loss: 0.8448 - val_loss: 1.1823
Epoch 51/56
321/321 [==============================] - 16s 51ms/step - loss: 0.8428 - val_loss: 1.1780
Epoch 52/56
321/321 [==============================] - 16s 51ms/step - loss: 0.8409 - val_loss: 1.1737
Epoch 53/56
321/321 [==============================] - 16s 51ms/step - loss: 0.8389 - val_loss: 1.1693
Epoch 54/56
321/321 [==============================] - 16s 51ms/step - loss: 0.8369 - val_loss: 1.1647
Epoch 55/56
321/321 [==============================] - 16s 51ms/step - loss: 0.8348 - val_loss: 1.1601
Epoch 56/56
321/321 [==============================] - 16s 51ms/step - loss: 0.8327 - val_loss: 1.1554
Execution time:  926.9325835704803
GRU:
Mean Absolute Error: 0.8403
Root Mean Square Error: 1.0331
Mean Square Error: 1.0673

Train RMSE: 1.033
Train MSE: 1.067
Train MAE: 0.840
###########################

MODEL:  GRU
sequence:  12h
units:  45
dropout1:  0.11814836227952394
dropout2:  0.24325404382648977
optimizer: adadelta
activationDense: sigmoid
epochs: 43
batchsize: 30
validation_split: 0.2
Model: &#34;sequential_127&#34;
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
gru_86 (GRU)                 (None, 72, 45)            6480      
_________________________________________________________________
dropout_254 (Dropout)        (None, 72, 45)            0         
_________________________________________________________________
gru_87 (GRU)                 (None, 72, 45)            12420     
_________________________________________________________________
dropout_255 (Dropout)        (None, 72, 45)            0         
_________________________________________________________________
time_distributed_127 (TimeDi (None, 72, 1)             46        
=================================================================
Total params: 18,946
Trainable params: 18,946
Non-trainable params: 0
_________________________________________________________________
Epoch 1/43
105/105 [==============================] - 7s 65ms/step - loss: 0.8876 - val_loss: 1.1407
Epoch 2/43
105/105 [==============================] - 6s 61ms/step - loss: 0.8875 - val_loss: 1.1405
Epoch 3/43
105/105 [==============================] - 6s 61ms/step - loss: 0.8874 - val_loss: 1.1404
Epoch 4/43
105/105 [==============================] - 6s 60ms/step - loss: 0.8873 - val_loss: 1.1402
Epoch 5/43
105/105 [==============================] - 6s 59ms/step - loss: 0.8872 - val_loss: 1.1400
Epoch 6/43
105/105 [==============================] - 6s 58ms/step - loss: 0.8871 - val_loss: 1.1398
Epoch 7/43
105/105 [==============================] - 6s 60ms/step - loss: 0.8869 - val_loss: 1.1396
Epoch 8/43
105/105 [==============================] - 6s 59ms/step - loss: 0.8868 - val_loss: 1.1394
Epoch 9/43
105/105 [==============================] - 6s 60ms/step - loss: 0.8867 - val_loss: 1.1392
Epoch 10/43
105/105 [==============================] - 6s 59ms/step - loss: 0.8866 - val_loss: 1.1389
Epoch 11/43
105/105 [==============================] - 6s 58ms/step - loss: 0.8864 - val_loss: 1.1387
Epoch 12/43
105/105 [==============================] - 6s 60ms/step - loss: 0.8863 - val_loss: 1.1385
Epoch 13/43
105/105 [==============================] - 6s 58ms/step - loss: 0.8862 - val_loss: 1.1383
Epoch 14/43
105/105 [==============================] - 6s 58ms/step - loss: 0.8860 - val_loss: 1.1380
Epoch 15/43
105/105 [==============================] - 6s 59ms/step - loss: 0.8859 - val_loss: 1.1378
Epoch 16/43
105/105 [==============================] - 6s 58ms/step - loss: 0.8858 - val_loss: 1.1376
Epoch 17/43
105/105 [==============================] - 6s 59ms/step - loss: 0.8856 - val_loss: 1.1373
Epoch 18/43
105/105 [==============================] - 6s 59ms/step - loss: 0.8855 - val_loss: 1.1371
Epoch 19/43
105/105 [==============================] - 6s 58ms/step - loss: 0.8853 - val_loss: 1.1368
Epoch 20/43
105/105 [==============================] - 6s 60ms/step - loss: 0.8852 - val_loss: 1.1366
Epoch 21/43
105/105 [==============================] - 6s 58ms/step - loss: 0.8850 - val_loss: 1.1363
Epoch 22/43
105/105 [==============================] - 6s 60ms/step - loss: 0.8849 - val_loss: 1.1361
Epoch 23/43
105/105 [==============================] - 6s 58ms/step - loss: 0.8848 - val_loss: 1.1358
Epoch 24/43
105/105 [==============================] - 6s 58ms/step - loss: 0.8846 - val_loss: 1.1356
Epoch 25/43
105/105 [==============================] - 6s 59ms/step - loss: 0.8844 - val_loss: 1.1353
Epoch 26/43
105/105 [==============================] - 6s 58ms/step - loss: 0.8843 - val_loss: 1.1350
Epoch 27/43
105/105 [==============================] - 6s 60ms/step - loss: 0.8842 - val_loss: 1.1348
Epoch 28/43
105/105 [==============================] - 6s 58ms/step - loss: 0.8840 - val_loss: 1.1345
Epoch 29/43
105/105 [==============================] - 6s 58ms/step - loss: 0.8838 - val_loss: 1.1342
Epoch 30/43
105/105 [==============================] - 6s 60ms/step - loss: 0.8837 - val_loss: 1.1339
Epoch 31/43
105/105 [==============================] - 6s 58ms/step - loss: 0.8835 - val_loss: 1.1337
Epoch 32/43
105/105 [==============================] - 6s 59ms/step - loss: 0.8834 - val_loss: 1.1334
Epoch 33/43
105/105 [==============================] - 6s 59ms/step - loss: 0.8832 - val_loss: 1.1331
Epoch 34/43
105/105 [==============================] - 6s 58ms/step - loss: 0.8830 - val_loss: 1.1328
Epoch 35/43
105/105 [==============================] - 6s 61ms/step - loss: 0.8829 - val_loss: 1.1325
Epoch 36/43
105/105 [==============================] - 6s 58ms/step - loss: 0.8827 - val_loss: 1.1323
Epoch 37/43
105/105 [==============================] - 6s 58ms/step - loss: 0.8825 - val_loss: 1.1320
Epoch 38/43
105/105 [==============================] - 6s 60ms/step - loss: 0.8824 - val_loss: 1.1317
Epoch 39/43
105/105 [==============================] - 6s 58ms/step - loss: 0.8822 - val_loss: 1.1314
Epoch 40/43
105/105 [==============================] - 6s 60ms/step - loss: 0.8820 - val_loss: 1.1311
Epoch 41/43
105/105 [==============================] - 6s 59ms/step - loss: 0.8819 - val_loss: 1.1308
Epoch 42/43
105/105 [==============================] - 6s 58ms/step - loss: 0.8817 - val_loss: 1.1305
Epoch 43/43
105/105 [==============================] - 6s 60ms/step - loss: 0.8815 - val_loss: 1.1302
Execution time:  273.94239115715027
GRU:
Mean Absolute Error: 0.9243
Root Mean Square Error: 1.1117
Mean Square Error: 1.2359

Train RMSE: 1.112
Train MSE: 1.236
Train MAE: 0.924
###########################

MODEL:  GRU
sequence:  12h
units:  43
dropout1:  0.40519643149940265
dropout2:  0.3312343747027119
optimizer: adamax
activationDense: tanh
epochs: 56
batchsize: 11
validation_split: 0.1
Model: &#34;sequential_128&#34;
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
gru_88 (GRU)                 (None, 72, 43)            5934      
_________________________________________________________________
dropout_256 (Dropout)        (None, 72, 43)            0         
_________________________________________________________________
gru_89 (GRU)                 (None, 72, 43)            11352     
_________________________________________________________________
dropout_257 (Dropout)        (None, 72, 43)            0         
_________________________________________________________________
time_distributed_128 (TimeDi (None, 72, 1)             44        
=================================================================
Total params: 17,330
Trainable params: 17,330
Non-trainable params: 0
_________________________________________________________________
Epoch 1/56
321/321 [==============================] - 18s 56ms/step - loss: 0.5399 - val_loss: 0.2881
Epoch 2/56
321/321 [==============================] - 17s 52ms/step - loss: 0.5130 - val_loss: 0.2848
Epoch 3/56
321/321 [==============================] - 17s 52ms/step - loss: 0.5083 - val_loss: 0.2849
Epoch 4/56
321/321 [==============================] - 17s 52ms/step - loss: 0.5057 - val_loss: 0.2860
Epoch 5/56
321/321 [==============================] - 17s 52ms/step - loss: 0.5035 - val_loss: 0.2843
Epoch 6/56
321/321 [==============================] - 17s 52ms/step - loss: 0.5017 - val_loss: 0.2841
Epoch 7/56
321/321 [==============================] - 17s 52ms/step - loss: 0.5002 - val_loss: 0.2825
Epoch 8/56
321/321 [==============================] - 17s 52ms/step - loss: 0.4994 - val_loss: 0.2828
Epoch 9/56
321/321 [==============================] - 17s 52ms/step - loss: 0.4988 - val_loss: 0.2827
Epoch 10/56
321/321 [==============================] - 17s 52ms/step - loss: 0.4981 - val_loss: 0.2840
Epoch 11/56
321/321 [==============================] - 17s 52ms/step - loss: 0.4979 - val_loss: 0.2824
Epoch 12/56
321/321 [==============================] - 17s 52ms/step - loss: 0.4972 - val_loss: 0.2813
Epoch 13/56
321/321 [==============================] - 17s 52ms/step - loss: 0.4972 - val_loss: 0.2792
Epoch 14/56
321/321 [==============================] - 17s 52ms/step - loss: 0.4966 - val_loss: 0.2818
Epoch 15/56
321/321 [==============================] - 17s 52ms/step - loss: 0.4966 - val_loss: 0.2805
Epoch 16/56
321/321 [==============================] - 17s 52ms/step - loss: 0.4962 - val_loss: 0.2795
Epoch 17/56
321/321 [==============================] - 17s 52ms/step - loss: 0.4959 - val_loss: 0.2815
Epoch 18/56
321/321 [==============================] - 17s 52ms/step - loss: 0.4957 - val_loss: 0.2816
Epoch 19/56
321/321 [==============================] - 17s 52ms/step - loss: 0.4950 - val_loss: 0.2820
Epoch 20/56
321/321 [==============================] - 17s 52ms/step - loss: 0.4947 - val_loss: 0.2818
Epoch 21/56
321/321 [==============================] - 17s 52ms/step - loss: 0.4943 - val_loss: 0.2820
Epoch 22/56
321/321 [==============================] - 17s 52ms/step - loss: 0.4931 - val_loss: 0.2824
Epoch 23/56
321/321 [==============================] - 17s 52ms/step - loss: 0.4927 - val_loss: 0.2832
Epoch 24/56
321/321 [==============================] - 17s 52ms/step - loss: 0.4912 - val_loss: 0.2812
Epoch 25/56
321/321 [==============================] - 17s 52ms/step - loss: 0.4892 - val_loss: 0.2770
Epoch 26/56
321/321 [==============================] - 17s 52ms/step - loss: 0.4875 - val_loss: 0.2706
Epoch 27/56
321/321 [==============================] - 17s 52ms/step - loss: 0.4842 - val_loss: 0.2647
Epoch 28/56
321/321 [==============================] - 17s 52ms/step - loss: 0.4810 - val_loss: 0.2590
Epoch 29/56
321/321 [==============================] - 17s 52ms/step - loss: 0.4777 - val_loss: 0.2549
Epoch 30/56
321/321 [==============================] - 17s 52ms/step - loss: 0.4748 - val_loss: 0.2511
Epoch 31/56
321/321 [==============================] - 17s 52ms/step - loss: 0.4738 - val_loss: 0.2524
Epoch 32/56
321/321 [==============================] - 17s 52ms/step - loss: 0.4727 - val_loss: 0.2494
Epoch 33/56
321/321 [==============================] - 17s 52ms/step - loss: 0.4712 - val_loss: 0.2498
Epoch 34/56
321/321 [==============================] - 16s 51ms/step - loss: 0.4697 - val_loss: 0.2474
Epoch 35/56
321/321 [==============================] - 16s 51ms/step - loss: 0.4701 - val_loss: 0.2496
Epoch 36/56
321/321 [==============================] - 16s 51ms/step - loss: 0.4696 - val_loss: 0.2490
Epoch 37/56
321/321 [==============================] - 16s 51ms/step - loss: 0.4690 - val_loss: 0.2481
Epoch 38/56
321/321 [==============================] - 16s 51ms/step - loss: 0.4693 - val_loss: 0.2490
Epoch 39/56
321/321 [==============================] - 17s 52ms/step - loss: 0.4682 - val_loss: 0.2478
Epoch 40/56
321/321 [==============================] - 16s 51ms/step - loss: 0.4684 - val_loss: 0.2484
Epoch 41/56
321/321 [==============================] - 17s 52ms/step - loss: 0.4678 - val_loss: 0.2496
Epoch 42/56
321/321 [==============================] - 16s 51ms/step - loss: 0.4667 - val_loss: 0.2482
Epoch 43/56
321/321 [==============================] - 16s 51ms/step - loss: 0.4668 - val_loss: 0.2496
Epoch 44/56
321/321 [==============================] - 16s 51ms/step - loss: 0.4660 - val_loss: 0.2494
Epoch 45/56
321/321 [==============================] - 16s 51ms/step - loss: 0.4659 - val_loss: 0.2496
Epoch 46/56
321/321 [==============================] - 17s 51ms/step - loss: 0.4653 - val_loss: 0.2507
Epoch 47/56
321/321 [==============================] - 16s 51ms/step - loss: 0.4654 - val_loss: 0.2488
Epoch 48/56
321/321 [==============================] - 17s 52ms/step - loss: 0.4650 - val_loss: 0.2503
Epoch 49/56
321/321 [==============================] - 16s 51ms/step - loss: 0.4648 - val_loss: 0.2500
Epoch 50/56
321/321 [==============================] - 16s 51ms/step - loss: 0.4646 - val_loss: 0.2498
Epoch 51/56
321/321 [==============================] - 16s 51ms/step - loss: 0.4645 - val_loss: 0.2488
Epoch 52/56
321/321 [==============================] - 16s 51ms/step - loss: 0.4635 - val_loss: 0.2502
Epoch 53/56
321/321 [==============================] - 17s 51ms/step - loss: 0.4638 - val_loss: 0.2488
Epoch 54/56
321/321 [==============================] - 16s 51ms/step - loss: 0.4629 - val_loss: 0.2501
Epoch 55/56
321/321 [==============================] - 17s 52ms/step - loss: 0.4627 - val_loss: 0.2495
Epoch 56/56
321/321 [==============================] - 16s 51ms/step - loss: 0.4628 - val_loss: 0.2493
Execution time:  941.049516916275
GRU:
Mean Absolute Error: 0.3091
Root Mean Square Error: 0.7976
Mean Square Error: 0.6361

Train RMSE: 0.798
Train MSE: 0.636
Train MAE: 0.309
###########################

MODEL:  GRU
sequence:  12h
units:  45
dropout1:  0.11814836227952394
dropout2:  0.24325404382648977
optimizer: adamax
activationDense: tanh
epochs: 43
batchsize: 30
validation_split: 0.2
Model: &#34;sequential_129&#34;
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
gru_90 (GRU)                 (None, 72, 45)            6480      
_________________________________________________________________
dropout_258 (Dropout)        (None, 72, 45)            0         
_________________________________________________________________
gru_91 (GRU)                 (None, 72, 45)            12420     
_________________________________________________________________
dropout_259 (Dropout)        (None, 72, 45)            0         
_________________________________________________________________
time_distributed_129 (TimeDi (None, 72, 1)             46        
=================================================================
Total params: 18,946
Trainable params: 18,946
Non-trainable params: 0
_________________________________________________________________
Epoch 1/43
105/105 [==============================] - 7s 67ms/step - loss: 0.5701 - val_loss: 0.3882
Epoch 2/43
105/105 [==============================] - 6s 58ms/step - loss: 0.5062 - val_loss: 0.3880
Epoch 3/43
105/105 [==============================] - 6s 58ms/step - loss: 0.5031 - val_loss: 0.3868
Epoch 4/43
105/105 [==============================] - 6s 60ms/step - loss: 0.5005 - val_loss: 0.3856
Epoch 5/43
105/105 [==============================] - 6s 58ms/step - loss: 0.4985 - val_loss: 0.3845
Epoch 6/43
105/105 [==============================] - 6s 60ms/step - loss: 0.4967 - val_loss: 0.3837
Epoch 7/43
105/105 [==============================] - 6s 58ms/step - loss: 0.4953 - val_loss: 0.3829
Epoch 8/43
105/105 [==============================] - 6s 58ms/step - loss: 0.4943 - val_loss: 0.3823
Epoch 9/43
105/105 [==============================] - 6s 60ms/step - loss: 0.4932 - val_loss: 0.3817
Epoch 10/43
105/105 [==============================] - 6s 58ms/step - loss: 0.4921 - val_loss: 0.3813
Epoch 11/43
105/105 [==============================] - 6s 60ms/step - loss: 0.4913 - val_loss: 0.3808
Epoch 12/43
105/105 [==============================] - 6s 59ms/step - loss: 0.4907 - val_loss: 0.3805
Epoch 13/43
105/105 [==============================] - 6s 59ms/step - loss: 0.4902 - val_loss: 0.3803
Epoch 14/43
105/105 [==============================] - 6s 60ms/step - loss: 0.4897 - val_loss: 0.3800
Epoch 15/43
105/105 [==============================] - 6s 59ms/step - loss: 0.4890 - val_loss: 0.3798
Epoch 16/43
105/105 [==============================] - 6s 59ms/step - loss: 0.4885 - val_loss: 0.3796
Epoch 17/43
105/105 [==============================] - 6s 59ms/step - loss: 0.4880 - val_loss: 0.3794
Epoch 18/43
105/105 [==============================] - 6s 58ms/step - loss: 0.4875 - val_loss: 0.3793
Epoch 19/43
105/105 [==============================] - 6s 60ms/step - loss: 0.4869 - val_loss: 0.3791
Epoch 20/43
105/105 [==============================] - 6s 58ms/step - loss: 0.4867 - val_loss: 0.3791
Epoch 21/43
105/105 [==============================] - 6s 58ms/step - loss: 0.4861 - val_loss: 0.3791
Epoch 22/43
105/105 [==============================] - 6s 60ms/step - loss: 0.4858 - val_loss: 0.3790
Epoch 23/43
105/105 [==============================] - 6s 58ms/step - loss: 0.4857 - val_loss: 0.3790
Epoch 24/43
105/105 [==============================] - 6s 60ms/step - loss: 0.4851 - val_loss: 0.3790
Epoch 25/43
105/105 [==============================] - 6s 58ms/step - loss: 0.4850 - val_loss: 0.3792
Epoch 26/43
105/105 [==============================] - 6s 58ms/step - loss: 0.4846 - val_loss: 0.3792
Epoch 27/43
105/105 [==============================] - 6s 60ms/step - loss: 0.4846 - val_loss: 0.3792
Epoch 28/43
105/105 [==============================] - 6s 58ms/step - loss: 0.4843 - val_loss: 0.3793
Epoch 29/43
105/105 [==============================] - 6s 60ms/step - loss: 0.4838 - val_loss: 0.3794
Epoch 30/43
105/105 [==============================] - 6s 58ms/step - loss: 0.4839 - val_loss: 0.3795
Epoch 31/43
105/105 [==============================] - 6s 58ms/step - loss: 0.4838 - val_loss: 0.3796
Epoch 32/43
105/105 [==============================] - 6s 61ms/step - loss: 0.4835 - val_loss: 0.3797
Epoch 33/43
105/105 [==============================] - 6s 58ms/step - loss: 0.4830 - val_loss: 0.3798
Epoch 34/43
105/105 [==============================] - 6s 60ms/step - loss: 0.4830 - val_loss: 0.3800
Epoch 35/43
105/105 [==============================] - 6s 59ms/step - loss: 0.4824 - val_loss: 0.3802
Epoch 36/43
105/105 [==============================] - 6s 58ms/step - loss: 0.4824 - val_loss: 0.3804
Epoch 37/43
105/105 [==============================] - 6s 60ms/step - loss: 0.4822 - val_loss: 0.3805
Epoch 38/43
105/105 [==============================] - 6s 58ms/step - loss: 0.4819 - val_loss: 0.3807
Epoch 39/43
105/105 [==============================] - 6s 59ms/step - loss: 0.4816 - val_loss: 0.3809
Epoch 40/43
105/105 [==============================] - 6s 59ms/step - loss: 0.4813 - val_loss: 0.3812
Epoch 41/43
105/105 [==============================] - 6s 58ms/step - loss: 0.4811 - val_loss: 0.3815
Epoch 42/43
105/105 [==============================] - 6s 60ms/step - loss: 0.4809 - val_loss: 0.3817
Epoch 43/43
105/105 [==============================] - 6s 58ms/step - loss: 0.4805 - val_loss: 0.3819
Execution time:  274.6278533935547
GRU:
Mean Absolute Error: 0.2153
Root Mean Square Error: 0.6089
Mean Square Error: 0.3708

Train RMSE: 0.609
Train MSE: 0.371
Train MAE: 0.215
###########################

MODEL:  GRU
sequence:  12h
units:  43
dropout1:  0.40519643149940265
dropout2:  0.3312343747027119
optimizer: adamax
activationDense: sigmoid
epochs: 56
batchsize: 11
validation_split: 0.1
Model: &#34;sequential_130&#34;
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
gru_92 (GRU)                 (None, 72, 43)            5934      
_________________________________________________________________
dropout_260 (Dropout)        (None, 72, 43)            0         
_________________________________________________________________
gru_93 (GRU)                 (None, 72, 43)            11352     
_________________________________________________________________
dropout_261 (Dropout)        (None, 72, 43)            0         
_________________________________________________________________
time_distributed_130 (TimeDi (None, 72, 1)             44        
=================================================================
Total params: 17,330
Trainable params: 17,330
Non-trainable params: 0
_________________________________________________________________
Epoch 1/56
321/321 [==============================] - 17s 54ms/step - loss: 0.7176 - val_loss: 0.8230
Epoch 2/56
321/321 [==============================] - 17s 52ms/step - loss: 0.6597 - val_loss: 0.8147
Epoch 3/56
321/321 [==============================] - 17s 52ms/step - loss: 0.6498 - val_loss: 0.8104
Epoch 4/56
321/321 [==============================] - 17s 52ms/step - loss: 0.6461 - val_loss: 0.8081
Epoch 5/56
321/321 [==============================] - 16s 51ms/step - loss: 0.6439 - val_loss: 0.8067
Epoch 6/56
321/321 [==============================] - 16s 51ms/step - loss: 0.6421 - val_loss: 0.8059
Epoch 7/56
321/321 [==============================] - 16s 51ms/step - loss: 0.6405 - val_loss: 0.8053
Epoch 8/56
321/321 [==============================] - 17s 51ms/step - loss: 0.6392 - val_loss: 0.8049
Epoch 9/56
321/321 [==============================] - 16s 51ms/step - loss: 0.6384 - val_loss: 0.8047
Epoch 10/56
321/321 [==============================] - 17s 52ms/step - loss: 0.6376 - val_loss: 0.8045
Epoch 11/56
321/321 [==============================] - 17s 51ms/step - loss: 0.6371 - val_loss: 0.8044
Epoch 12/56
321/321 [==============================] - 16s 51ms/step - loss: 0.6368 - val_loss: 0.8043
Epoch 13/56
321/321 [==============================] - 16s 51ms/step - loss: 0.6365 - val_loss: 0.8042
Epoch 14/56
321/321 [==============================] - 16s 51ms/step - loss: 0.6361 - val_loss: 0.8041
Epoch 15/56
321/321 [==============================] - 16s 51ms/step - loss: 0.6358 - val_loss: 0.8041
Epoch 16/56
321/321 [==============================] - 16s 51ms/step - loss: 0.6355 - val_loss: 0.8041
Epoch 17/56
321/321 [==============================] - 16s 51ms/step - loss: 0.6352 - val_loss: 0.8041
Epoch 18/56
321/321 [==============================] - 16s 51ms/step - loss: 0.6351 - val_loss: 0.8040
Epoch 19/56
321/321 [==============================] - 16s 51ms/step - loss: 0.6346 - val_loss: 0.8040
Epoch 20/56
321/321 [==============================] - 16s 51ms/step - loss: 0.6345 - val_loss: 0.8040
Epoch 21/56
321/321 [==============================] - 16s 51ms/step - loss: 0.6342 - val_loss: 0.8040
Epoch 22/56
321/321 [==============================] - 16s 51ms/step - loss: 0.6336 - val_loss: 0.8040
Epoch 23/56
321/321 [==============================] - 16s 51ms/step - loss: 0.6335 - val_loss: 0.8040
Epoch 24/56
321/321 [==============================] - 16s 51ms/step - loss: 0.6332 - val_loss: 0.8040
Epoch 25/56
321/321 [==============================] - 16s 51ms/step - loss: 0.6326 - val_loss: 0.8040
Epoch 26/56
321/321 [==============================] - 16s 51ms/step - loss: 0.6321 - val_loss: 0.8040
Epoch 27/56
321/321 [==============================] - 16s 51ms/step - loss: 0.6316 - val_loss: 0.8040
Epoch 28/56
321/321 [==============================] - 16s 51ms/step - loss: 0.6312 - val_loss: 0.8040
Epoch 29/56
321/321 [==============================] - 16s 51ms/step - loss: 0.6304 - val_loss: 0.8040
Epoch 30/56
321/321 [==============================] - 16s 51ms/step - loss: 0.6300 - val_loss: 0.8040
Epoch 31/56
321/321 [==============================] - 16s 51ms/step - loss: 0.6290 - val_loss: 0.8040
Epoch 32/56
321/321 [==============================] - 17s 52ms/step - loss: 0.6280 - val_loss: 0.8040
Epoch 33/56
321/321 [==============================] - 17s 52ms/step - loss: 0.6271 - val_loss: 0.8040
Epoch 34/56
321/321 [==============================] - 16s 51ms/step - loss: 0.6260 - val_loss: 0.8040
Epoch 35/56
321/321 [==============================] - 16s 51ms/step - loss: 0.6256 - val_loss: 0.8040
Epoch 36/56
321/321 [==============================] - 16s 51ms/step - loss: 0.6238 - val_loss: 0.8040
Epoch 37/56
321/321 [==============================] - 16s 51ms/step - loss: 0.6227 - val_loss: 0.8040
Epoch 38/56
321/321 [==============================] - 16s 51ms/step - loss: 0.6214 - val_loss: 0.8040
Epoch 39/56
321/321 [==============================] - 17s 52ms/step - loss: 0.6202 - val_loss: 0.8040
Epoch 40/56
321/321 [==============================] - 16s 51ms/step - loss: 0.6191 - val_loss: 0.8040
Epoch 41/56
321/321 [==============================] - 16s 51ms/step - loss: 0.6179 - val_loss: 0.8040
Epoch 42/56
321/321 [==============================] - 16s 51ms/step - loss: 0.6167 - val_loss: 0.8040
Epoch 43/56
321/321 [==============================] - 16s 51ms/step - loss: 0.6156 - val_loss: 0.8040
Epoch 44/56
321/321 [==============================] - 16s 51ms/step - loss: 0.6143 - val_loss: 0.8040
Epoch 45/56
321/321 [==============================] - 16s 51ms/step - loss: 0.6134 - val_loss: 0.8040
Epoch 46/56
321/321 [==============================] - 16s 51ms/step - loss: 0.6132 - val_loss: 0.8040
Epoch 47/56
321/321 [==============================] - 17s 52ms/step - loss: 0.6120 - val_loss: 0.8040
Epoch 48/56
321/321 [==============================] - 16s 51ms/step - loss: 0.6112 - val_loss: 0.8040
Epoch 49/56
321/321 [==============================] - 17s 51ms/step - loss: 0.6109 - val_loss: 0.8040
Epoch 50/56
321/321 [==============================] - 17s 52ms/step - loss: 0.6100 - val_loss: 0.8040
Epoch 51/56
321/321 [==============================] - 16s 51ms/step - loss: 0.6099 - val_loss: 0.8039
Epoch 52/56
321/321 [==============================] - 16s 51ms/step - loss: 0.6092 - val_loss: 0.8039
Epoch 53/56
321/321 [==============================] - 17s 51ms/step - loss: 0.6096 - val_loss: 0.8039
Epoch 54/56
321/321 [==============================] - 16s 51ms/step - loss: 0.6085 - val_loss: 0.8039
Epoch 55/56
321/321 [==============================] - 16s 51ms/step - loss: 0.6085 - val_loss: 0.8039
Epoch 56/56
321/321 [==============================] - 16s 51ms/step - loss: 0.6079 - val_loss: 0.8039
Execution time:  931.0133748054504
GRU:
Mean Absolute Error: 0.5757
Root Mean Square Error: 0.8592
Mean Square Error: 0.7382

Train RMSE: 0.859
Train MSE: 0.738
Train MAE: 0.576
###########################

MODEL:  GRU
sequence:  12h
units:  45
dropout1:  0.11814836227952394
dropout2:  0.24325404382648977
optimizer: adamax
activationDense: sigmoid
epochs: 43
batchsize: 30
validation_split: 0.2
Model: &#34;sequential_131&#34;
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
gru_94 (GRU)                 (None, 72, 45)            6480      
_________________________________________________________________
dropout_262 (Dropout)        (None, 72, 45)            0         
_________________________________________________________________
gru_95 (GRU)                 (None, 72, 45)            12420     
_________________________________________________________________
dropout_263 (Dropout)        (None, 72, 45)            0         
_________________________________________________________________
time_distributed_131 (TimeDi (None, 72, 1)             46        
=================================================================
Total params: 18,946
Trainable params: 18,946
Non-trainable params: 0
_________________________________________________________________
Epoch 1/43
105/105 [==============================] - 7s 64ms/step - loss: 0.7794 - val_loss: 0.7982
Epoch 2/43
105/105 [==============================] - 6s 59ms/step - loss: 0.6608 - val_loss: 0.7652
Epoch 3/43
105/105 [==============================] - 6s 58ms/step - loss: 0.6521 - val_loss: 0.7572
Epoch 4/43
105/105 [==============================] - 6s 58ms/step - loss: 0.6480 - val_loss: 0.7527
Epoch 5/43
105/105 [==============================] - 6s 59ms/step - loss: 0.6451 - val_loss: 0.7497
Epoch 6/43
105/105 [==============================] - 6s 57ms/step - loss: 0.6430 - val_loss: 0.7474
Epoch 7/43
105/105 [==============================] - 6s 59ms/step - loss: 0.6412 - val_loss: 0.7456
Epoch 8/43
105/105 [==============================] - 6s 58ms/step - loss: 0.6397 - val_loss: 0.7441
Epoch 9/43
105/105 [==============================] - 6s 58ms/step - loss: 0.6385 - val_loss: 0.7428
Epoch 10/43
105/105 [==============================] - 6s 59ms/step - loss: 0.6374 - val_loss: 0.7416
Epoch 11/43
105/105 [==============================] - 6s 58ms/step - loss: 0.6364 - val_loss: 0.7404
Epoch 12/43
105/105 [==============================] - 6s 58ms/step - loss: 0.6354 - val_loss: 0.7393
Epoch 13/43
105/105 [==============================] - 6s 58ms/step - loss: 0.6346 - val_loss: 0.7383
Epoch 14/43
105/105 [==============================] - 6s 59ms/step - loss: 0.6339 - val_loss: 0.7374
Epoch 15/43
105/105 [==============================] - 6s 60ms/step - loss: 0.6334 - val_loss: 0.7369
Epoch 16/43
105/105 [==============================] - 6s 58ms/step - loss: 0.6328 - val_loss: 0.7365
Epoch 17/43
105/105 [==============================] - 6s 58ms/step - loss: 0.6324 - val_loss: 0.7363
Epoch 18/43
105/105 [==============================] - 6s 59ms/step - loss: 0.6320 - val_loss: 0.7361
Epoch 19/43
105/105 [==============================] - 6s 57ms/step - loss: 0.6317 - val_loss: 0.7359
Epoch 20/43
105/105 [==============================] - 6s 59ms/step - loss: 0.6313 - val_loss: 0.7358
Epoch 21/43
105/105 [==============================] - 6s 59ms/step - loss: 0.6310 - val_loss: 0.7357
Epoch 22/43
105/105 [==============================] - 6s 58ms/step - loss: 0.6308 - val_loss: 0.7355
Epoch 23/43
105/105 [==============================] - 6s 59ms/step - loss: 0.6306 - val_loss: 0.7355
Epoch 24/43
105/105 [==============================] - 6s 58ms/step - loss: 0.6304 - val_loss: 0.7353
Epoch 25/43
105/105 [==============================] - 6s 59ms/step - loss: 0.6302 - val_loss: 0.7350
Epoch 26/43
105/105 [==============================] - 6s 58ms/step - loss: 0.6300 - val_loss: 0.7349
Epoch 27/43
105/105 [==============================] - 6s 58ms/step - loss: 0.6297 - val_loss: 0.7348
Epoch 28/43
105/105 [==============================] - 6s 59ms/step - loss: 0.6297 - val_loss: 0.7345
Epoch 29/43
105/105 [==============================] - 6s 61ms/step - loss: 0.6295 - val_loss: 0.7345
Epoch 30/43
105/105 [==============================] - 6s 59ms/step - loss: 0.6295 - val_loss: 0.7345
Epoch 31/43
105/105 [==============================] - 7s 63ms/step - loss: 0.6293 - val_loss: 0.7342
Epoch 32/43
105/105 [==============================] - 6s 61ms/step - loss: 0.6291 - val_loss: 0.7341
Epoch 33/43
105/105 [==============================] - 6s 60ms/step - loss: 0.6290 - val_loss: 0.7341
Epoch 34/43
105/105 [==============================] - 6s 58ms/step - loss: 0.6287 - val_loss: 0.7339
Epoch 35/43
105/105 [==============================] - 6s 59ms/step - loss: 0.6288 - val_loss: 0.7339
Epoch 36/43
105/105 [==============================] - 6s 59ms/step - loss: 0.6286 - val_loss: 0.7337
Epoch 37/43
105/105 [==============================] - 6s 58ms/step - loss: 0.6284 - val_loss: 0.7333
Epoch 38/43
105/105 [==============================] - 6s 59ms/step - loss: 0.6282 - val_loss: 0.7332
Epoch 39/43
105/105 [==============================] - 6s 58ms/step - loss: 0.6280 - val_loss: 0.7329
Epoch 40/43
105/105 [==============================] - 6s 58ms/step - loss: 0.6279 - val_loss: 0.7328
Epoch 41/43
105/105 [==============================] - 6s 60ms/step - loss: 0.6278 - val_loss: 0.7327
Epoch 42/43
105/105 [==============================] - 6s 58ms/step - loss: 0.6277 - val_loss: 0.7325
Epoch 43/43
105/105 [==============================] - 6s 60ms/step - loss: 0.6274 - val_loss: 0.7322
Execution time:  273.1925628185272
GRU:
Mean Absolute Error: 0.5320
Root Mean Square Error: 0.7760
Mean Square Error: 0.6022

Train RMSE: 0.776
Train MSE: 0.602
Train MAE: 0.532
###########################

MODEL:  GRU
sequence:  1d
units:  43
dropout1:  0.40519643149940265
dropout2:  0.3312343747027119
optimizer: adam
activationDense: tanh
epochs: 56
batchsize: 11
validation_split: 0.1
Model: &#34;sequential_132&#34;
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
gru_96 (GRU)                 (None, 144, 43)           5934      
_________________________________________________________________
dropout_264 (Dropout)        (None, 144, 43)           0         
_________________________________________________________________
gru_97 (GRU)                 (None, 144, 43)           11352     
_________________________________________________________________
dropout_265 (Dropout)        (None, 144, 43)           0         
_________________________________________________________________
time_distributed_132 (TimeDi (None, 144, 1)            44        
=================================================================
Total params: 17,330
Trainable params: 17,330
Non-trainable params: 0
_________________________________________________________________
Epoch 1/56
315/315 [==============================] - 35s 112ms/step - loss: 0.6089 - val_loss: 0.4306
Epoch 2/56
315/315 [==============================] - 31s 100ms/step - loss: 0.5925 - val_loss: 0.4095
Epoch 3/56
315/315 [==============================] - 31s 99ms/step - loss: 0.5860 - val_loss: 0.4006
Epoch 4/56
315/315 [==============================] - 31s 98ms/step - loss: 0.5800 - val_loss: 0.3974
Epoch 5/56
315/315 [==============================] - 31s 99ms/step - loss: 0.5764 - val_loss: 0.3943
Epoch 6/56
315/315 [==============================] - 31s 99ms/step - loss: 0.5724 - val_loss: 0.3889
Epoch 7/56
315/315 [==============================] - 31s 99ms/step - loss: 0.5685 - val_loss: 0.3852
Epoch 8/56
315/315 [==============================] - 31s 99ms/step - loss: 0.5661 - val_loss: 0.3826
Epoch 9/56
315/315 [==============================] - 31s 99ms/step - loss: 0.5634 - val_loss: 0.3848
Epoch 10/56
315/315 [==============================] - 31s 99ms/step - loss: 0.5617 - val_loss: 0.3929
Epoch 11/56
315/315 [==============================] - 31s 99ms/step - loss: 0.5617 - val_loss: 0.3922
Epoch 12/56
315/315 [==============================] - 31s 98ms/step - loss: 0.5578 - val_loss: 0.4046
Epoch 13/56
315/315 [==============================] - 31s 99ms/step - loss: 0.5578 - val_loss: 0.3925
Epoch 14/56
315/315 [==============================] - 31s 99ms/step - loss: 0.5551 - val_loss: 0.3938
Epoch 15/56
315/315 [==============================] - 31s 99ms/step - loss: 0.5533 - val_loss: 0.3918
Epoch 16/56
315/315 [==============================] - 31s 98ms/step - loss: 0.5511 - val_loss: 0.3993
Epoch 17/56
315/315 [==============================] - 31s 99ms/step - loss: 0.5481 - val_loss: 0.4051
Epoch 18/56
315/315 [==============================] - 31s 98ms/step - loss: 0.5475 - val_loss: 0.3765
Epoch 19/56
315/315 [==============================] - 31s 99ms/step - loss: 0.5431 - val_loss: 0.4109
Epoch 20/56
315/315 [==============================] - 31s 99ms/step - loss: 0.5424 - val_loss: 0.3877
Epoch 21/56
315/315 [==============================] - 31s 99ms/step - loss: 0.5405 - val_loss: 0.4057
Epoch 22/56
315/315 [==============================] - 31s 99ms/step - loss: 0.5378 - val_loss: 0.3890
Epoch 23/56
315/315 [==============================] - 31s 99ms/step - loss: 0.5383 - val_loss: 0.3778
Epoch 24/56
315/315 [==============================] - 31s 98ms/step - loss: 0.5349 - val_loss: 0.3899
Epoch 25/56
315/315 [==============================] - 31s 99ms/step - loss: 0.5348 - val_loss: 0.3720
Epoch 26/56
315/315 [==============================] - 31s 98ms/step - loss: 0.5331 - val_loss: 0.3569
Epoch 27/56
315/315 [==============================] - 31s 98ms/step - loss: 0.5292 - val_loss: 0.3624
Epoch 28/56
315/315 [==============================] - 31s 98ms/step - loss: 0.5273 - val_loss: 0.3854
Epoch 29/56
315/315 [==============================] - 31s 98ms/step - loss: 0.5268 - val_loss: 0.3651
Epoch 30/56
315/315 [==============================] - 31s 98ms/step - loss: 0.5240 - val_loss: 0.3532
Epoch 31/56
315/315 [==============================] - 31s 98ms/step - loss: 0.5231 - val_loss: 0.3503
Epoch 32/56
315/315 [==============================] - 31s 98ms/step - loss: 0.5176 - val_loss: 0.3331
Epoch 33/56
315/315 [==============================] - 31s 98ms/step - loss: 0.5151 - val_loss: 0.3328
Epoch 34/56
315/315 [==============================] - 31s 98ms/step - loss: 0.5108 - val_loss: 0.3336
Epoch 35/56
315/315 [==============================] - 31s 98ms/step - loss: 0.5098 - val_loss: 0.3434
Epoch 36/56
315/315 [==============================] - 31s 98ms/step - loss: 0.5098 - val_loss: 0.3625
Epoch 37/56
315/315 [==============================] - 31s 98ms/step - loss: 0.5186 - val_loss: 0.3036
Epoch 38/56
315/315 [==============================] - 31s 98ms/step - loss: 0.5110 - val_loss: 0.3059
Epoch 39/56
315/315 [==============================] - 31s 98ms/step - loss: 0.5095 - val_loss: 0.3213
Epoch 40/56
315/315 [==============================] - 31s 99ms/step - loss: 0.5090 - val_loss: 0.3035
Epoch 41/56
315/315 [==============================] - 31s 98ms/step - loss: 0.5042 - val_loss: 0.3065
Epoch 42/56
315/315 [==============================] - 31s 98ms/step - loss: 0.5015 - val_loss: 0.3058
Epoch 43/56
315/315 [==============================] - 31s 98ms/step - loss: 0.5043 - val_loss: 0.3225
Epoch 44/56
315/315 [==============================] - 31s 99ms/step - loss: 0.5042 - val_loss: 0.3002
Epoch 45/56
315/315 [==============================] - 31s 98ms/step - loss: 0.5009 - val_loss: 0.3142
Epoch 46/56
315/315 [==============================] - 31s 98ms/step - loss: 0.4974 - val_loss: 0.3080
Epoch 47/56
315/315 [==============================] - 31s 98ms/step - loss: 0.5160 - val_loss: 0.3187
Epoch 48/56
315/315 [==============================] - 31s 99ms/step - loss: 0.5071 - val_loss: 0.3134
Epoch 49/56
315/315 [==============================] - 31s 98ms/step - loss: 0.4954 - val_loss: 0.3055
Epoch 50/56
315/315 [==============================] - 31s 98ms/step - loss: 0.5051 - val_loss: 0.3433
Epoch 51/56
315/315 [==============================] - 31s 98ms/step - loss: 0.5053 - val_loss: 0.3252
Epoch 52/56
315/315 [==============================] - 31s 98ms/step - loss: 0.5004 - val_loss: 0.3176
Epoch 53/56
315/315 [==============================] - 31s 98ms/step - loss: 0.4935 - val_loss: 0.3090
Epoch 54/56
315/315 [==============================] - 31s 99ms/step - loss: 0.4896 - val_loss: 0.3189
Epoch 55/56
315/315 [==============================] - 31s 98ms/step - loss: 0.4959 - val_loss: 0.2940
Epoch 56/56
315/315 [==============================] - 31s 99ms/step - loss: 0.4941 - val_loss: 0.3099
Execution time:  1750.1785168647766
GRU:
Mean Absolute Error: 0.4351
Root Mean Square Error: 0.8935
Mean Square Error: 0.7984

Train RMSE: 0.894
Train MSE: 0.798
Train MAE: 0.435
###########################

MODEL:  GRU
sequence:  1d
units:  45
dropout1:  0.11814836227952394
dropout2:  0.24325404382648977
optimizer: adam
activationDense: tanh
epochs: 43
batchsize: 30
validation_split: 0.2
Model: &#34;sequential_133&#34;
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
gru_98 (GRU)                 (None, 144, 45)           6480      
_________________________________________________________________
dropout_266 (Dropout)        (None, 144, 45)           0         
_________________________________________________________________
gru_99 (GRU)                 (None, 144, 45)           12420     
_________________________________________________________________
dropout_267 (Dropout)        (None, 144, 45)           0         
_________________________________________________________________
time_distributed_133 (TimeDi (None, 144, 1)            46        
=================================================================
Total params: 18,946
Trainable params: 18,946
Non-trainable params: 0
_________________________________________________________________
Epoch 1/43
103/103 [==============================] - 12s 113ms/step - loss: 0.6252 - val_loss: 0.4117
Epoch 2/43
103/103 [==============================] - 11s 111ms/step - loss: 0.6039 - val_loss: 0.4122
Epoch 3/43
103/103 [==============================] - 11s 111ms/step - loss: 0.5943 - val_loss: 0.4127
Epoch 4/43
103/103 [==============================] - 11s 110ms/step - loss: 0.5904 - val_loss: 0.4122
Epoch 5/43
103/103 [==============================] - 11s 109ms/step - loss: 0.5866 - val_loss: 0.4134
Epoch 6/43
103/103 [==============================] - 11s 111ms/step - loss: 0.5833 - val_loss: 0.4146
Epoch 7/43
103/103 [==============================] - 11s 110ms/step - loss: 0.5800 - val_loss: 0.4163
Epoch 8/43
103/103 [==============================] - 11s 109ms/step - loss: 0.5768 - val_loss: 0.4178
Epoch 9/43
103/103 [==============================] - 11s 111ms/step - loss: 0.5740 - val_loss: 0.4188
Epoch 10/43
103/103 [==============================] - 11s 111ms/step - loss: 0.5714 - val_loss: 0.4189
Epoch 11/43
103/103 [==============================] - 11s 111ms/step - loss: 0.5687 - val_loss: 0.4177
Epoch 12/43
103/103 [==============================] - 11s 109ms/step - loss: 0.5659 - val_loss: 0.4165
Epoch 13/43
103/103 [==============================] - 11s 110ms/step - loss: 0.5640 - val_loss: 0.4157
Epoch 14/43
103/103 [==============================] - 11s 111ms/step - loss: 0.5615 - val_loss: 0.4140
Epoch 15/43
103/103 [==============================] - 11s 110ms/step - loss: 0.5601 - val_loss: 0.4120
Epoch 16/43
103/103 [==============================] - 11s 111ms/step - loss: 0.5575 - val_loss: 0.4062
Epoch 17/43
103/103 [==============================] - 11s 111ms/step - loss: 0.5552 - val_loss: 0.4016
Epoch 18/43
103/103 [==============================] - 11s 111ms/step - loss: 0.5531 - val_loss: 0.4037
Epoch 19/43
103/103 [==============================] - 11s 111ms/step - loss: 0.5503 - val_loss: 0.4063
Epoch 20/43
103/103 [==============================] - 11s 111ms/step - loss: 0.5486 - val_loss: 0.4112
Epoch 21/43
103/103 [==============================] - 11s 111ms/step - loss: 0.5449 - val_loss: 0.4132
Epoch 22/43
103/103 [==============================] - 11s 110ms/step - loss: 0.5424 - val_loss: 0.4124
Epoch 23/43
103/103 [==============================] - 11s 110ms/step - loss: 0.5376 - val_loss: 0.4135
Epoch 24/43
103/103 [==============================] - 11s 111ms/step - loss: 0.5337 - val_loss: 0.4130
Epoch 25/43
103/103 [==============================] - 11s 111ms/step - loss: 0.5306 - val_loss: 0.4138
Epoch 26/43
103/103 [==============================] - 11s 110ms/step - loss: 0.5284 - val_loss: 0.4152
Epoch 27/43
103/103 [==============================] - 11s 110ms/step - loss: 0.5269 - val_loss: 0.4151
Epoch 28/43
103/103 [==============================] - 11s 110ms/step - loss: 0.5274 - val_loss: 0.4161
Epoch 29/43
103/103 [==============================] - 11s 111ms/step - loss: 0.5261 - val_loss: 0.4199
Epoch 30/43
103/103 [==============================] - 11s 111ms/step - loss: 0.5258 - val_loss: 0.4224
Epoch 31/43
103/103 [==============================] - 11s 111ms/step - loss: 0.5353 - val_loss: 0.4231
Epoch 32/43
103/103 [==============================] - 11s 111ms/step - loss: 0.5239 - val_loss: 0.4238
Epoch 33/43
103/103 [==============================] - 11s 109ms/step - loss: 0.5202 - val_loss: 0.4248
Epoch 34/43
103/103 [==============================] - 11s 110ms/step - loss: 0.5321 - val_loss: 0.4212
Epoch 35/43
103/103 [==============================] - 11s 110ms/step - loss: 0.5250 - val_loss: 0.4231
Epoch 36/43
103/103 [==============================] - 11s 109ms/step - loss: 0.5222 - val_loss: 0.4244
Epoch 37/43
103/103 [==============================] - 11s 109ms/step - loss: 0.5315 - val_loss: 0.4176
Epoch 38/43
103/103 [==============================] - 11s 110ms/step - loss: 0.5215 - val_loss: 0.4260
Epoch 39/43
103/103 [==============================] - 11s 110ms/step - loss: 0.5153 - val_loss: 0.4251
Epoch 40/43
103/103 [==============================] - 11s 110ms/step - loss: 0.5152 - val_loss: 0.4242
Epoch 41/43
103/103 [==============================] - 11s 111ms/step - loss: 0.5152 - val_loss: 0.4247
Epoch 42/43
103/103 [==============================] - 11s 110ms/step - loss: 0.5136 - val_loss: 0.4260
Epoch 43/43
103/103 [==============================] - 11s 110ms/step - loss: 0.5118 - val_loss: 0.4256
Execution time:  498.31243920326233
GRU:
Mean Absolute Error: 0.3766
Root Mean Square Error: 0.8788
Mean Square Error: 0.7723

Train RMSE: 0.879
Train MSE: 0.772
Train MAE: 0.377
###########################

MODEL:  GRU
sequence:  1d
units:  43
dropout1:  0.40519643149940265
dropout2:  0.3312343747027119
optimizer: adam
activationDense: sigmoid
epochs: 56
batchsize: 11
validation_split: 0.1
Model: &#34;sequential_134&#34;
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
gru_100 (GRU)                (None, 144, 43)           5934      
_________________________________________________________________
dropout_268 (Dropout)        (None, 144, 43)           0         
_________________________________________________________________
gru_101 (GRU)                (None, 144, 43)           11352     
_________________________________________________________________
dropout_269 (Dropout)        (None, 144, 43)           0         
_________________________________________________________________
time_distributed_134 (TimeDi (None, 144, 1)            44        
=================================================================
Total params: 17,330
Trainable params: 17,330
Non-trainable params: 0
_________________________________________________________________
Epoch 1/56
315/315 [==============================] - 32s 101ms/step - loss: 0.7277 - val_loss: 0.8089
Epoch 2/56
315/315 [==============================] - 31s 99ms/step - loss: 0.6985 - val_loss: 0.8060
Epoch 3/56
315/315 [==============================] - 31s 98ms/step - loss: 0.6916 - val_loss: 0.8047
Epoch 4/56
315/315 [==============================] - 31s 98ms/step - loss: 0.6868 - val_loss: 0.8036
Epoch 5/56
315/315 [==============================] - 31s 98ms/step - loss: 0.6911 - val_loss: 0.8027
Epoch 6/56
315/315 [==============================] - 31s 98ms/step - loss: 0.6960 - val_loss: 0.8027
Epoch 7/56
315/315 [==============================] - 31s 98ms/step - loss: 0.6955 - val_loss: 0.8024
Epoch 8/56
315/315 [==============================] - 31s 98ms/step - loss: 0.6920 - val_loss: 0.8021
Epoch 9/56
315/315 [==============================] - 31s 98ms/step - loss: 0.6895 - val_loss: 0.8019
Epoch 10/56
315/315 [==============================] - 31s 99ms/step - loss: 0.6889 - val_loss: 0.8019
Epoch 11/56
315/315 [==============================] - 31s 98ms/step - loss: 0.6902 - val_loss: 0.8018
Epoch 12/56
315/315 [==============================] - 31s 98ms/step - loss: 0.6931 - val_loss: 0.8017
Epoch 13/56
315/315 [==============================] - 31s 98ms/step - loss: 0.7024 - val_loss: 0.8017
Epoch 14/56
315/315 [==============================] - 31s 98ms/step - loss: 0.7048 - val_loss: 0.8016
Epoch 15/56
315/315 [==============================] - 31s 98ms/step - loss: 0.7021 - val_loss: 0.8016
Epoch 16/56
315/315 [==============================] - 31s 98ms/step - loss: 0.7015 - val_loss: 0.8015
Epoch 17/56
315/315 [==============================] - 31s 98ms/step - loss: 0.7012 - val_loss: 0.8015
Epoch 18/56
315/315 [==============================] - 31s 99ms/step - loss: 0.7010 - val_loss: 0.8015
Epoch 19/56
315/315 [==============================] - 31s 98ms/step - loss: 0.7009 - val_loss: 0.8014
Epoch 20/56
315/315 [==============================] - 31s 98ms/step - loss: 0.7008 - val_loss: 0.8014
Epoch 21/56
315/315 [==============================] - 31s 98ms/step - loss: 0.7007 - val_loss: 0.8014
Epoch 22/56
315/315 [==============================] - 31s 98ms/step - loss: 0.7006 - val_loss: 0.8014
Epoch 23/56
315/315 [==============================] - 31s 98ms/step - loss: 0.7006 - val_loss: 0.8014
Epoch 24/56
315/315 [==============================] - 31s 98ms/step - loss: 0.7006 - val_loss: 0.8013
Epoch 25/56
315/315 [==============================] - 31s 98ms/step - loss: 0.7005 - val_loss: 0.8013
Epoch 26/56
315/315 [==============================] - 31s 98ms/step - loss: 0.7005 - val_loss: 0.8013
Epoch 27/56
315/315 [==============================] - 31s 98ms/step - loss: 0.7005 - val_loss: 0.8013
Epoch 28/56
315/315 [==============================] - 31s 98ms/step - loss: 0.7005 - val_loss: 0.8013
Epoch 29/56
315/315 [==============================] - 31s 98ms/step - loss: 0.7005 - val_loss: 0.8013
Epoch 30/56
315/315 [==============================] - 31s 99ms/step - loss: 0.7005 - val_loss: 0.8013
Epoch 31/56
315/315 [==============================] - 31s 98ms/step - loss: 0.7005 - val_loss: 0.8013
Epoch 32/56
315/315 [==============================] - 31s 98ms/step - loss: 0.7004 - val_loss: 0.8013
Epoch 33/56
315/315 [==============================] - 31s 98ms/step - loss: 0.7004 - val_loss: 0.8013
Epoch 34/56
315/315 [==============================] - 31s 99ms/step - loss: 0.7004 - val_loss: 0.8013
Epoch 35/56
315/315 [==============================] - 31s 98ms/step - loss: 0.7004 - val_loss: 0.8013
Epoch 36/56
315/315 [==============================] - 31s 98ms/step - loss: 0.7004 - val_loss: 0.8013
Epoch 37/56
315/315 [==============================] - 31s 98ms/step - loss: 0.7004 - val_loss: 0.8013
Epoch 38/56
315/315 [==============================] - 31s 99ms/step - loss: 0.7004 - val_loss: 0.8013
Epoch 39/56
315/315 [==============================] - 31s 98ms/step - loss: 0.7004 - val_loss: 0.8013
Epoch 40/56
315/315 [==============================] - 31s 98ms/step - loss: 0.7004 - val_loss: 0.8013
Epoch 41/56
315/315 [==============================] - 31s 99ms/step - loss: 0.7004 - val_loss: 0.8013
Epoch 42/56
315/315 [==============================] - 31s 98ms/step - loss: 0.7004 - val_loss: 0.8013
Epoch 43/56
315/315 [==============================] - 31s 98ms/step - loss: 0.7004 - val_loss: 0.8013
Epoch 44/56
315/315 [==============================] - 31s 98ms/step - loss: 0.7004 - val_loss: 0.8013
Epoch 45/56
315/315 [==============================] - 31s 99ms/step - loss: 0.7004 - val_loss: 0.8013
Epoch 46/56
315/315 [==============================] - 31s 98ms/step - loss: 0.7004 - val_loss: 0.8013
Epoch 47/56
315/315 [==============================] - 31s 98ms/step - loss: 0.7004 - val_loss: 0.8013
Epoch 48/56
315/315 [==============================] - 31s 98ms/step - loss: 0.7004 - val_loss: 0.8013
Epoch 49/56
315/315 [==============================] - 31s 99ms/step - loss: 0.7004 - val_loss: 0.8013
Epoch 50/56
315/315 [==============================] - 31s 98ms/step - loss: 0.7004 - val_loss: 0.8013
Epoch 51/56
315/315 [==============================] - 31s 98ms/step - loss: 0.7004 - val_loss: 0.8013
Epoch 52/56
315/315 [==============================] - 31s 98ms/step - loss: 0.7004 - val_loss: 0.8013
Epoch 53/56
315/315 [==============================] - 31s 99ms/step - loss: 0.7004 - val_loss: 0.8013
Epoch 54/56
315/315 [==============================] - 31s 98ms/step - loss: 0.7004 - val_loss: 0.8013
Epoch 55/56
315/315 [==============================] - 31s 98ms/step - loss: 0.7004 - val_loss: 0.8013
Epoch 56/56
315/315 [==============================] - 31s 97ms/step - loss: 0.7004 - val_loss: 0.8013
Execution time:  1743.939314365387
GRU:
Mean Absolute Error: 0.7139
Root Mean Square Error: 1.0056
Mean Square Error: 1.0112

Train RMSE: 1.006
Train MSE: 1.011
Train MAE: 0.714
###########################

MODEL:  GRU
sequence:  1d
units:  45
dropout1:  0.11814836227952394
dropout2:  0.24325404382648977
optimizer: adam
activationDense: sigmoid
epochs: 43
batchsize: 30
validation_split: 0.2
Model: &#34;sequential_135&#34;
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
gru_102 (GRU)                (None, 144, 45)           6480      
_________________________________________________________________
dropout_270 (Dropout)        (None, 144, 45)           0         
_________________________________________________________________
gru_103 (GRU)                (None, 144, 45)           12420     
_________________________________________________________________
dropout_271 (Dropout)        (None, 144, 45)           0         
_________________________________________________________________
time_distributed_135 (TimeDi (None, 144, 1)            46        
=================================================================
Total params: 18,946
Trainable params: 18,946
Non-trainable params: 0
_________________________________________________________________
Epoch 1/43
103/103 [==============================] - 12s 115ms/step - loss: 0.7964 - val_loss: 0.7865
Epoch 2/43
103/103 [==============================] - 11s 107ms/step - loss: 0.7046 - val_loss: 0.7655
Epoch 3/43
103/103 [==============================] - 11s 108ms/step - loss: 0.6988 - val_loss: 0.7603
Epoch 4/43
103/103 [==============================] - 11s 110ms/step - loss: 0.6936 - val_loss: 0.7566
Epoch 5/43
103/103 [==============================] - 11s 109ms/step - loss: 0.6859 - val_loss: 0.7433
Epoch 6/43
103/103 [==============================] - 11s 109ms/step - loss: 0.6842 - val_loss: 0.7386
Epoch 7/43
103/103 [==============================] - 11s 108ms/step - loss: 0.6789 - val_loss: 0.7329
Epoch 8/43
103/103 [==============================] - 11s 110ms/step - loss: 0.6776 - val_loss: 0.7307
Epoch 9/43
103/103 [==============================] - 11s 110ms/step - loss: 0.6752 - val_loss: 0.7284
Epoch 10/43
103/103 [==============================] - 11s 108ms/step - loss: 0.6736 - val_loss: 0.7271
Epoch 11/43
103/103 [==============================] - 11s 111ms/step - loss: 0.6706 - val_loss: 0.7242
Epoch 12/43
103/103 [==============================] - 11s 110ms/step - loss: 0.6728 - val_loss: 0.7255
Epoch 13/43
103/103 [==============================] - 11s 110ms/step - loss: 0.6676 - val_loss: 0.7231
Epoch 14/43
103/103 [==============================] - 11s 109ms/step - loss: 0.6649 - val_loss: 0.7211
Epoch 15/43
103/103 [==============================] - 11s 110ms/step - loss: 0.6649 - val_loss: 0.7191
Epoch 16/43
103/103 [==============================] - 11s 110ms/step - loss: 0.6638 - val_loss: 0.7180
Epoch 17/43
103/103 [==============================] - 11s 109ms/step - loss: 0.6629 - val_loss: 0.7170
Epoch 18/43
103/103 [==============================] - 11s 110ms/step - loss: 0.6594 - val_loss: 0.7166
Epoch 19/43
103/103 [==============================] - 11s 110ms/step - loss: 0.6544 - val_loss: 0.7158
Epoch 20/43
103/103 [==============================] - 11s 109ms/step - loss: 0.6546 - val_loss: 0.7156
Epoch 21/43
103/103 [==============================] - 11s 109ms/step - loss: 0.6491 - val_loss: 0.7149
Epoch 22/43
103/103 [==============================] - 11s 111ms/step - loss: 0.6491 - val_loss: 0.7150
Epoch 23/43
103/103 [==============================] - 11s 110ms/step - loss: 0.6483 - val_loss: 0.7147
Epoch 24/43
103/103 [==============================] - 11s 109ms/step - loss: 0.6454 - val_loss: 0.7142
Epoch 25/43
103/103 [==============================] - 11s 110ms/step - loss: 0.6421 - val_loss: 0.7139
Epoch 26/43
103/103 [==============================] - 11s 110ms/step - loss: 0.6391 - val_loss: 0.7136
Epoch 27/43
103/103 [==============================] - 11s 110ms/step - loss: 0.6385 - val_loss: 0.7144
Epoch 28/43
103/103 [==============================] - 11s 110ms/step - loss: 0.6407 - val_loss: 0.7137
Epoch 29/43
103/103 [==============================] - 11s 110ms/step - loss: 0.6373 - val_loss: 0.7136
Epoch 30/43
103/103 [==============================] - 11s 110ms/step - loss: 0.6389 - val_loss: 0.7134
Epoch 31/43
103/103 [==============================] - 11s 109ms/step - loss: 0.6347 - val_loss: 0.7134
Epoch 32/43
103/103 [==============================] - 12s 113ms/step - loss: 0.6343 - val_loss: 0.7134
Epoch 33/43
103/103 [==============================] - 11s 111ms/step - loss: 0.6345 - val_loss: 0.7132
Epoch 34/43
103/103 [==============================] - 11s 110ms/step - loss: 0.6331 - val_loss: 0.7132
Epoch 35/43
103/103 [==============================] - 11s 110ms/step - loss: 0.6332 - val_loss: 0.7131
Epoch 36/43
103/103 [==============================] - 11s 110ms/step - loss: 0.6331 - val_loss: 0.7130
Epoch 37/43
103/103 [==============================] - 11s 111ms/step - loss: 0.6324 - val_loss: 0.7131
Epoch 38/43
103/103 [==============================] - 11s 109ms/step - loss: 0.6299 - val_loss: 0.7129
Epoch 39/43
103/103 [==============================] - 11s 111ms/step - loss: 0.6298 - val_loss: 0.7129
Epoch 40/43
103/103 [==============================] - 11s 111ms/step - loss: 0.6295 - val_loss: 0.7128
Epoch 41/43
103/103 [==============================] - 11s 110ms/step - loss: 0.6370 - val_loss: 0.7134
Epoch 42/43
103/103 [==============================] - 11s 109ms/step - loss: 0.6575 - val_loss: 0.7134
Epoch 43/43
103/103 [==============================] - 12s 112ms/step - loss: 0.6381 - val_loss: 0.7128
Execution time:  496.2300238609314
GRU:
Mean Absolute Error: 0.6380
Root Mean Square Error: 0.9338
Mean Square Error: 0.8719

Train RMSE: 0.934
Train MSE: 0.872
Train MAE: 0.638
###########################

MODEL:  GRU
sequence:  1d
units:  43
dropout1:  0.40519643149940265
dropout2:  0.3312343747027119
optimizer: adadelta
activationDense: tanh
epochs: 56
batchsize: 11
validation_split: 0.1
Model: &#34;sequential_136&#34;
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
gru_104 (GRU)                (None, 144, 43)           5934      
_________________________________________________________________
dropout_272 (Dropout)        (None, 144, 43)           0         
_________________________________________________________________
gru_105 (GRU)                (None, 144, 43)           11352     
_________________________________________________________________
dropout_273 (Dropout)        (None, 144, 43)           0         
_________________________________________________________________
time_distributed_136 (TimeDi (None, 144, 1)            44        
=================================================================
Total params: 17,330
Trainable params: 17,330
Non-trainable params: 0
_________________________________________________________________
Epoch 1/56
315/315 [==============================] - 32s 102ms/step - loss: 0.6994 - val_loss: 0.7963
Epoch 2/56
315/315 [==============================] - 31s 98ms/step - loss: 0.6980 - val_loss: 0.7920
Epoch 3/56
315/315 [==============================] - 31s 99ms/step - loss: 0.6965 - val_loss: 0.7874
Epoch 4/56
315/315 [==============================] - 32s 100ms/step - loss: 0.6949 - val_loss: 0.7825
Epoch 5/56
315/315 [==============================] - 31s 100ms/step - loss: 0.6931 - val_loss: 0.7775
Epoch 6/56
315/315 [==============================] - 31s 100ms/step - loss: 0.6914 - val_loss: 0.7723
Epoch 7/56
315/315 [==============================] - 31s 99ms/step - loss: 0.6896 - val_loss: 0.7670
Epoch 8/56
315/315 [==============================] - 31s 99ms/step - loss: 0.6879 - val_loss: 0.7616
Epoch 9/56
315/315 [==============================] - 31s 98ms/step - loss: 0.6860 - val_loss: 0.7561
Epoch 10/56
315/315 [==============================] - 31s 98ms/step - loss: 0.6842 - val_loss: 0.7505
Epoch 11/56
315/315 [==============================] - 31s 99ms/step - loss: 0.6824 - val_loss: 0.7449
Epoch 12/56
315/315 [==============================] - 31s 98ms/step - loss: 0.6805 - val_loss: 0.7393
Epoch 13/56
315/315 [==============================] - 31s 98ms/step - loss: 0.6788 - val_loss: 0.7336
Epoch 14/56
315/315 [==============================] - 31s 98ms/step - loss: 0.6768 - val_loss: 0.7279
Epoch 15/56
315/315 [==============================] - 31s 98ms/step - loss: 0.6751 - val_loss: 0.7222
Epoch 16/56
315/315 [==============================] - 31s 98ms/step - loss: 0.6733 - val_loss: 0.7165
Epoch 17/56
315/315 [==============================] - 31s 98ms/step - loss: 0.6715 - val_loss: 0.7108
Epoch 18/56
315/315 [==============================] - 31s 98ms/step - loss: 0.6698 - val_loss: 0.7050
Epoch 19/56
315/315 [==============================] - 31s 99ms/step - loss: 0.6680 - val_loss: 0.6993
Epoch 20/56
315/315 [==============================] - 31s 98ms/step - loss: 0.6663 - val_loss: 0.6935
Epoch 21/56
315/315 [==============================] - 31s 98ms/step - loss: 0.6647 - val_loss: 0.6877
Epoch 22/56
315/315 [==============================] - 31s 98ms/step - loss: 0.6630 - val_loss: 0.6818
Epoch 23/56
315/315 [==============================] - 31s 98ms/step - loss: 0.6612 - val_loss: 0.6758
Epoch 24/56
315/315 [==============================] - 31s 98ms/step - loss: 0.6594 - val_loss: 0.6698
Epoch 25/56
315/315 [==============================] - 31s 99ms/step - loss: 0.6578 - val_loss: 0.6638
Epoch 26/56
315/315 [==============================] - 31s 98ms/step - loss: 0.6560 - val_loss: 0.6577
Epoch 27/56
315/315 [==============================] - 31s 99ms/step - loss: 0.6543 - val_loss: 0.6515
Epoch 28/56
315/315 [==============================] - 31s 98ms/step - loss: 0.6524 - val_loss: 0.6452
Epoch 29/56
315/315 [==============================] - 31s 98ms/step - loss: 0.6506 - val_loss: 0.6389
Epoch 30/56
315/315 [==============================] - 31s 99ms/step - loss: 0.6489 - val_loss: 0.6325
Epoch 31/56
315/315 [==============================] - 31s 99ms/step - loss: 0.6471 - val_loss: 0.6260
Epoch 32/56
315/315 [==============================] - 31s 98ms/step - loss: 0.6453 - val_loss: 0.6195
Epoch 33/56
315/315 [==============================] - 31s 98ms/step - loss: 0.6435 - val_loss: 0.6130
Epoch 34/56
315/315 [==============================] - 31s 98ms/step - loss: 0.6417 - val_loss: 0.6064
Epoch 35/56
315/315 [==============================] - 31s 99ms/step - loss: 0.6398 - val_loss: 0.5998
Epoch 36/56
315/315 [==============================] - 31s 98ms/step - loss: 0.6380 - val_loss: 0.5931
Epoch 37/56
315/315 [==============================] - 31s 98ms/step - loss: 0.6362 - val_loss: 0.5864
Epoch 38/56
315/315 [==============================] - 31s 98ms/step - loss: 0.6346 - val_loss: 0.5797
Epoch 39/56
315/315 [==============================] - 31s 99ms/step - loss: 0.6327 - val_loss: 0.5730
Epoch 40/56
315/315 [==============================] - 31s 98ms/step - loss: 0.6310 - val_loss: 0.5663
Epoch 41/56
315/315 [==============================] - 31s 98ms/step - loss: 0.6293 - val_loss: 0.5596
Epoch 42/56
315/315 [==============================] - 31s 99ms/step - loss: 0.6276 - val_loss: 0.5530
Epoch 43/56
315/315 [==============================] - 31s 98ms/step - loss: 0.6259 - val_loss: 0.5463
Epoch 44/56
315/315 [==============================] - 31s 98ms/step - loss: 0.6243 - val_loss: 0.5397
Epoch 45/56
315/315 [==============================] - 31s 98ms/step - loss: 0.6227 - val_loss: 0.5331
Epoch 46/56
315/315 [==============================] - 31s 99ms/step - loss: 0.6209 - val_loss: 0.5266
Epoch 47/56
315/315 [==============================] - 31s 98ms/step - loss: 0.6195 - val_loss: 0.5202
Epoch 48/56
315/315 [==============================] - 31s 98ms/step - loss: 0.6178 - val_loss: 0.5138
Epoch 49/56
315/315 [==============================] - 31s 98ms/step - loss: 0.6165 - val_loss: 0.5076
Epoch 50/56
315/315 [==============================] - 31s 99ms/step - loss: 0.6151 - val_loss: 0.5014
Epoch 51/56
315/315 [==============================] - 31s 98ms/step - loss: 0.6137 - val_loss: 0.4953
Epoch 52/56
315/315 [==============================] - 31s 98ms/step - loss: 0.6124 - val_loss: 0.4892
Epoch 53/56
315/315 [==============================] - 31s 98ms/step - loss: 0.6111 - val_loss: 0.4833
Epoch 54/56
315/315 [==============================] - 31s 100ms/step - loss: 0.6099 - val_loss: 0.4775
Epoch 55/56
315/315 [==============================] - 31s 98ms/step - loss: 0.6086 - val_loss: 0.4718
Epoch 56/56
315/315 [==============================] - 31s 98ms/step - loss: 0.6073 - val_loss: 0.4661
Execution time:  1747.803641319275
GRU:
Mean Absolute Error: 0.5050
Root Mean Square Error: 0.8408
Mean Square Error: 0.7069

Train RMSE: 0.841
Train MSE: 0.707
Train MAE: 0.505
###########################

MODEL:  GRU
sequence:  1d
units:  45
dropout1:  0.11814836227952394
dropout2:  0.24325404382648977
optimizer: adadelta
activationDense: tanh
epochs: 43
batchsize: 30
validation_split: 0.2
Model: &#34;sequential_137&#34;
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
gru_106 (GRU)                (None, 144, 45)           6480      
_________________________________________________________________
dropout_274 (Dropout)        (None, 144, 45)           0         
_________________________________________________________________
gru_107 (GRU)                (None, 144, 45)           12420     
_________________________________________________________________
dropout_275 (Dropout)        (None, 144, 45)           0         
_________________________________________________________________
time_distributed_137 (TimeDi (None, 144, 1)            46        
=================================================================
Total params: 18,946
Trainable params: 18,946
Non-trainable params: 0
_________________________________________________________________
Epoch 1/43
103/103 [==============================] - 12s 117ms/step - loss: 0.7119 - val_loss: 0.7130
Epoch 2/43
103/103 [==============================] - 12s 112ms/step - loss: 0.7116 - val_loss: 0.7123
Epoch 3/43
103/103 [==============================] - 11s 111ms/step - loss: 0.7111 - val_loss: 0.7115
Epoch 4/43
103/103 [==============================] - 12s 116ms/step - loss: 0.7107 - val_loss: 0.7107
Epoch 5/43
103/103 [==============================] - 11s 112ms/step - loss: 0.7102 - val_loss: 0.7099
Epoch 6/43
103/103 [==============================] - 11s 112ms/step - loss: 0.7097 - val_loss: 0.7090
Epoch 7/43
103/103 [==============================] - 11s 110ms/step - loss: 0.7092 - val_loss: 0.7081
Epoch 8/43
103/103 [==============================] - 12s 112ms/step - loss: 0.7087 - val_loss: 0.7072
Epoch 9/43
103/103 [==============================] - 12s 112ms/step - loss: 0.7082 - val_loss: 0.7063
Epoch 10/43
103/103 [==============================] - 11s 111ms/step - loss: 0.7076 - val_loss: 0.7054
Epoch 11/43
103/103 [==============================] - 11s 111ms/step - loss: 0.7071 - val_loss: 0.7044
Epoch 12/43
103/103 [==============================] - 11s 112ms/step - loss: 0.7066 - val_loss: 0.7035
Epoch 13/43
103/103 [==============================] - 12s 113ms/step - loss: 0.7060 - val_loss: 0.7025
Epoch 14/43
103/103 [==============================] - 11s 111ms/step - loss: 0.7054 - val_loss: 0.7015
Epoch 15/43
103/103 [==============================] - 12s 113ms/step - loss: 0.7049 - val_loss: 0.7005
Epoch 16/43
103/103 [==============================] - 11s 112ms/step - loss: 0.7043 - val_loss: 0.6995
Epoch 17/43
103/103 [==============================] - 12s 112ms/step - loss: 0.7037 - val_loss: 0.6985
Epoch 18/43
103/103 [==============================] - 11s 110ms/step - loss: 0.7032 - val_loss: 0.6974
Epoch 19/43
103/103 [==============================] - 11s 111ms/step - loss: 0.7026 - val_loss: 0.6964
Epoch 20/43
103/103 [==============================] - 11s 111ms/step - loss: 0.7020 - val_loss: 0.6953
Epoch 21/43
103/103 [==============================] - 11s 110ms/step - loss: 0.7014 - val_loss: 0.6943
Epoch 22/43
103/103 [==============================] - 11s 111ms/step - loss: 0.7008 - val_loss: 0.6932
Epoch 23/43
103/103 [==============================] - 11s 111ms/step - loss: 0.7003 - val_loss: 0.6921
Epoch 24/43
103/103 [==============================] - 12s 114ms/step - loss: 0.6996 - val_loss: 0.6910
Epoch 25/43
103/103 [==============================] - 11s 110ms/step - loss: 0.6991 - val_loss: 0.6899
Epoch 26/43
103/103 [==============================] - 11s 111ms/step - loss: 0.6984 - val_loss: 0.6888
Epoch 27/43
103/103 [==============================] - 11s 111ms/step - loss: 0.6978 - val_loss: 0.6877
Epoch 28/43
103/103 [==============================] - 11s 110ms/step - loss: 0.6972 - val_loss: 0.6866
Epoch 29/43
103/103 [==============================] - 11s 111ms/step - loss: 0.6966 - val_loss: 0.6854
Epoch 30/43
103/103 [==============================] - 11s 111ms/step - loss: 0.6960 - val_loss: 0.6843
Epoch 31/43
103/103 [==============================] - 11s 111ms/step - loss: 0.6954 - val_loss: 0.6831
Epoch 32/43
103/103 [==============================] - 11s 110ms/step - loss: 0.6948 - val_loss: 0.6820
Epoch 33/43
103/103 [==============================] - 11s 111ms/step - loss: 0.6941 - val_loss: 0.6808
Epoch 34/43
103/103 [==============================] - 12s 112ms/step - loss: 0.6934 - val_loss: 0.6796
Epoch 35/43
103/103 [==============================] - 12s 112ms/step - loss: 0.6928 - val_loss: 0.6784
Epoch 36/43
103/103 [==============================] - 11s 110ms/step - loss: 0.6922 - val_loss: 0.6772
Epoch 37/43
103/103 [==============================] - 11s 111ms/step - loss: 0.6916 - val_loss: 0.6761
Epoch 38/43
103/103 [==============================] - 11s 112ms/step - loss: 0.6909 - val_loss: 0.6749
Epoch 39/43
103/103 [==============================] - 11s 111ms/step - loss: 0.6903 - val_loss: 0.6737
Epoch 40/43
103/103 [==============================] - 11s 111ms/step - loss: 0.6897 - val_loss: 0.6725
Epoch 41/43
103/103 [==============================] - 11s 112ms/step - loss: 0.6890 - val_loss: 0.6713
Epoch 42/43
103/103 [==============================] - 11s 111ms/step - loss: 0.6884 - val_loss: 0.6701
Epoch 43/43
103/103 [==============================] - 11s 110ms/step - loss: 0.6878 - val_loss: 0.6689
Execution time:  506.42418336868286
GRU:
Mean Absolute Error: 0.6691
Root Mean Square Error: 0.9652
Mean Square Error: 0.9316

Train RMSE: 0.965
Train MSE: 0.932
Train MAE: 0.669
###########################

MODEL:  GRU
sequence:  1d
units:  43
dropout1:  0.40519643149940265
dropout2:  0.3312343747027119
optimizer: adadelta
activationDense: sigmoid
epochs: 56
batchsize: 11
validation_split: 0.1
Model: &#34;sequential_138&#34;
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
gru_108 (GRU)                (None, 144, 43)           5934      
_________________________________________________________________
dropout_276 (Dropout)        (None, 144, 43)           0         
_________________________________________________________________
gru_109 (GRU)                (None, 144, 43)           11352     
_________________________________________________________________
dropout_277 (Dropout)        (None, 144, 43)           0         
_________________________________________________________________
time_distributed_138 (TimeDi (None, 144, 1)            44        
=================================================================
Total params: 17,330
Trainable params: 17,330
Non-trainable params: 0
_________________________________________________________________
Epoch 1/56
315/315 [==============================] - 32s 102ms/step - loss: 0.9072 - val_loss: 1.2928
Epoch 2/56
315/315 [==============================] - 31s 99ms/step - loss: 0.9069 - val_loss: 1.2920
Epoch 3/56
315/315 [==============================] - 31s 99ms/step - loss: 0.9066 - val_loss: 1.2912
Epoch 4/56
315/315 [==============================] - 31s 100ms/step - loss: 0.9062 - val_loss: 1.2902
Epoch 5/56
315/315 [==============================] - 31s 99ms/step - loss: 0.9058 - val_loss: 1.2893
Epoch 6/56
315/315 [==============================] - 31s 99ms/step - loss: 0.9054 - val_loss: 1.2883
Epoch 7/56
315/315 [==============================] - 31s 99ms/step - loss: 0.9050 - val_loss: 1.2872
Epoch 8/56
315/315 [==============================] - 31s 100ms/step - loss: 0.9045 - val_loss: 1.2861
Epoch 9/56
315/315 [==============================] - 31s 99ms/step - loss: 0.9040 - val_loss: 1.2849
Epoch 10/56
315/315 [==============================] - 31s 99ms/step - loss: 0.9035 - val_loss: 1.2837
Epoch 11/56
315/315 [==============================] - 31s 100ms/step - loss: 0.9030 - val_loss: 1.2825
Epoch 12/56
315/315 [==============================] - 31s 99ms/step - loss: 0.9024 - val_loss: 1.2812
Epoch 13/56
315/315 [==============================] - 31s 99ms/step - loss: 0.9019 - val_loss: 1.2799
Epoch 14/56
315/315 [==============================] - 31s 99ms/step - loss: 0.9013 - val_loss: 1.2785
Epoch 15/56
315/315 [==============================] - 31s 99ms/step - loss: 0.9007 - val_loss: 1.2771
Epoch 16/56
315/315 [==============================] - 31s 99ms/step - loss: 0.9001 - val_loss: 1.2757
Epoch 17/56
315/315 [==============================] - 31s 99ms/step - loss: 0.8994 - val_loss: 1.2742
Epoch 18/56
315/315 [==============================] - 31s 99ms/step - loss: 0.8988 - val_loss: 1.2727
Epoch 19/56
315/315 [==============================] - 31s 99ms/step - loss: 0.8981 - val_loss: 1.2711
Epoch 20/56
315/315 [==============================] - 31s 99ms/step - loss: 0.8974 - val_loss: 1.2695
Epoch 21/56
315/315 [==============================] - 31s 99ms/step - loss: 0.8968 - val_loss: 1.2679
Epoch 22/56
315/315 [==============================] - 31s 99ms/step - loss: 0.8960 - val_loss: 1.2662
Epoch 23/56
315/315 [==============================] - 31s 99ms/step - loss: 0.8953 - val_loss: 1.2645
Epoch 24/56
315/315 [==============================] - 31s 99ms/step - loss: 0.8945 - val_loss: 1.2627
Epoch 25/56
315/315 [==============================] - 31s 99ms/step - loss: 0.8937 - val_loss: 1.2608
Epoch 26/56
315/315 [==============================] - 31s 99ms/step - loss: 0.8929 - val_loss: 1.2590
Epoch 27/56
315/315 [==============================] - 31s 99ms/step - loss: 0.8920 - val_loss: 1.2571
Epoch 28/56
315/315 [==============================] - 31s 99ms/step - loss: 0.8912 - val_loss: 1.2551
Epoch 29/56
315/315 [==============================] - 31s 99ms/step - loss: 0.8903 - val_loss: 1.2531
Epoch 30/56
315/315 [==============================] - 31s 99ms/step - loss: 0.8894 - val_loss: 1.2510
Epoch 31/56
315/315 [==============================] - 31s 99ms/step - loss: 0.8885 - val_loss: 1.2489
Epoch 32/56
315/315 [==============================] - 31s 99ms/step - loss: 0.8876 - val_loss: 1.2467
Epoch 33/56
315/315 [==============================] - 31s 99ms/step - loss: 0.8866 - val_loss: 1.2445
Epoch 34/56
315/315 [==============================] - 31s 99ms/step - loss: 0.8856 - val_loss: 1.2422
Epoch 35/56
315/315 [==============================] - 31s 100ms/step - loss: 0.8846 - val_loss: 1.2399
Epoch 36/56
315/315 [==============================] - 31s 99ms/step - loss: 0.8835 - val_loss: 1.2375
Epoch 37/56
315/315 [==============================] - 31s 99ms/step - loss: 0.8825 - val_loss: 1.2350
Epoch 38/56
315/315 [==============================] - 31s 99ms/step - loss: 0.8814 - val_loss: 1.2325
Epoch 39/56
315/315 [==============================] - 31s 100ms/step - loss: 0.8803 - val_loss: 1.2299
Epoch 40/56
315/315 [==============================] - 31s 98ms/step - loss: 0.8792 - val_loss: 1.2273
Epoch 41/56
315/315 [==============================] - 31s 98ms/step - loss: 0.8780 - val_loss: 1.2246
Epoch 42/56
315/315 [==============================] - 31s 98ms/step - loss: 0.8768 - val_loss: 1.2219
Epoch 43/56
315/315 [==============================] - 31s 98ms/step - loss: 0.8756 - val_loss: 1.2190
Epoch 44/56
315/315 [==============================] - 31s 99ms/step - loss: 0.8744 - val_loss: 1.2162
Epoch 45/56
315/315 [==============================] - 31s 98ms/step - loss: 0.8731 - val_loss: 1.2132
Epoch 46/56
315/315 [==============================] - 31s 98ms/step - loss: 0.8718 - val_loss: 1.2102
Epoch 47/56
315/315 [==============================] - 31s 99ms/step - loss: 0.8704 - val_loss: 1.2071
Epoch 48/56
315/315 [==============================] - 31s 98ms/step - loss: 0.8691 - val_loss: 1.2039
Epoch 49/56
315/315 [==============================] - 31s 98ms/step - loss: 0.8677 - val_loss: 1.2007
Epoch 50/56
315/315 [==============================] - 31s 98ms/step - loss: 0.8663 - val_loss: 1.1974
Epoch 51/56
315/315 [==============================] - 31s 98ms/step - loss: 0.8648 - val_loss: 1.1940
Epoch 52/56
315/315 [==============================] - 31s 98ms/step - loss: 0.8633 - val_loss: 1.1905
Epoch 53/56
315/315 [==============================] - 31s 98ms/step - loss: 0.8618 - val_loss: 1.1870
Epoch 54/56
315/315 [==============================] - 31s 99ms/step - loss: 0.8602 - val_loss: 1.1833
Epoch 55/56
315/315 [==============================] - 31s 98ms/step - loss: 0.8586 - val_loss: 1.1796
Epoch 56/56
315/315 [==============================] - 31s 98ms/step - loss: 0.8569 - val_loss: 1.1759
Execution time:  1754.0065641403198
GRU:
Mean Absolute Error: 0.8566
Root Mean Square Error: 1.0501
Mean Square Error: 1.1026

Train RMSE: 1.050
Train MSE: 1.103
Train MAE: 0.857
###########################

MODEL:  GRU
sequence:  1d
units:  45
dropout1:  0.11814836227952394
dropout2:  0.24325404382648977
optimizer: adadelta
activationDense: sigmoid
epochs: 43
batchsize: 30
validation_split: 0.2
Model: &#34;sequential_139&#34;
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
gru_110 (GRU)                (None, 144, 45)           6480      
_________________________________________________________________
dropout_278 (Dropout)        (None, 144, 45)           0         
_________________________________________________________________
gru_111 (GRU)                (None, 144, 45)           12420     
_________________________________________________________________
dropout_279 (Dropout)        (None, 144, 45)           0         
_________________________________________________________________
time_distributed_139 (TimeDi (None, 144, 1)            46        
=================================================================
Total params: 18,946
Trainable params: 18,946
Non-trainable params: 0
_________________________________________________________________
Epoch 1/43
103/103 [==============================] - 12s 114ms/step - loss: 0.9010 - val_loss: 1.1446
Epoch 2/43
103/103 [==============================] - 12s 112ms/step - loss: 0.9009 - val_loss: 1.1444
Epoch 3/43
103/103 [==============================] - 11s 111ms/step - loss: 0.9008 - val_loss: 1.1442
Epoch 4/43
103/103 [==============================] - 12s 113ms/step - loss: 0.9007 - val_loss: 1.1440
Epoch 5/43
103/103 [==============================] - 11s 109ms/step - loss: 0.9006 - val_loss: 1.1438
Epoch 6/43
103/103 [==============================] - 12s 112ms/step - loss: 0.9005 - val_loss: 1.1436
Epoch 7/43
103/103 [==============================] - 11s 111ms/step - loss: 0.9004 - val_loss: 1.1433
Epoch 8/43
103/103 [==============================] - 11s 110ms/step - loss: 0.9002 - val_loss: 1.1431
Epoch 9/43
103/103 [==============================] - 11s 110ms/step - loss: 0.9001 - val_loss: 1.1429
Epoch 10/43
103/103 [==============================] - 11s 111ms/step - loss: 0.9000 - val_loss: 1.1426
Epoch 11/43
103/103 [==============================] - 11s 111ms/step - loss: 0.8998 - val_loss: 1.1424
Epoch 12/43
103/103 [==============================] - 11s 109ms/step - loss: 0.8997 - val_loss: 1.1421
Epoch 13/43
103/103 [==============================] - 11s 111ms/step - loss: 0.8996 - val_loss: 1.1419
Epoch 14/43
103/103 [==============================] - 11s 111ms/step - loss: 0.8994 - val_loss: 1.1416
Epoch 15/43
103/103 [==============================] - 12s 112ms/step - loss: 0.8993 - val_loss: 1.1414
Epoch 16/43
103/103 [==============================] - 11s 110ms/step - loss: 0.8991 - val_loss: 1.1411
Epoch 17/43
103/103 [==============================] - 11s 111ms/step - loss: 0.8990 - val_loss: 1.1408
Epoch 18/43
103/103 [==============================] - 11s 111ms/step - loss: 0.8988 - val_loss: 1.1406
Epoch 19/43
103/103 [==============================] - 11s 109ms/step - loss: 0.8987 - val_loss: 1.1403
Epoch 20/43
103/103 [==============================] - 11s 111ms/step - loss: 0.8985 - val_loss: 1.1400
Epoch 21/43
103/103 [==============================] - 11s 111ms/step - loss: 0.8984 - val_loss: 1.1397
Epoch 22/43
103/103 [==============================] - 11s 110ms/step - loss: 0.8982 - val_loss: 1.1395
Epoch 23/43
103/103 [==============================] - 11s 110ms/step - loss: 0.8981 - val_loss: 1.1392
Epoch 24/43
103/103 [==============================] - 11s 111ms/step - loss: 0.8979 - val_loss: 1.1389
Epoch 25/43
103/103 [==============================] - 12s 112ms/step - loss: 0.8978 - val_loss: 1.1386
Epoch 26/43
103/103 [==============================] - 11s 110ms/step - loss: 0.8976 - val_loss: 1.1383
Epoch 27/43
103/103 [==============================] - 11s 111ms/step - loss: 0.8975 - val_loss: 1.1380
Epoch 28/43
103/103 [==============================] - 11s 111ms/step - loss: 0.8973 - val_loss: 1.1378
Epoch 29/43
103/103 [==============================] - 11s 111ms/step - loss: 0.8971 - val_loss: 1.1375
Epoch 30/43
103/103 [==============================] - 11s 110ms/step - loss: 0.8970 - val_loss: 1.1372
Epoch 31/43
103/103 [==============================] - 11s 111ms/step - loss: 0.8968 - val_loss: 1.1369
Epoch 32/43
103/103 [==============================] - 12s 112ms/step - loss: 0.8967 - val_loss: 1.1366
Epoch 33/43
103/103 [==============================] - 11s 110ms/step - loss: 0.8965 - val_loss: 1.1363
Epoch 34/43
103/103 [==============================] - 11s 111ms/step - loss: 0.8963 - val_loss: 1.1360
Epoch 35/43
103/103 [==============================] - 11s 111ms/step - loss: 0.8962 - val_loss: 1.1357
Epoch 36/43
103/103 [==============================] - 12s 112ms/step - loss: 0.8960 - val_loss: 1.1354
Epoch 37/43
103/103 [==============================] - 11s 110ms/step - loss: 0.8958 - val_loss: 1.1351
Epoch 38/43
103/103 [==============================] - 11s 111ms/step - loss: 0.8956 - val_loss: 1.1347
Epoch 39/43
103/103 [==============================] - 11s 111ms/step - loss: 0.8955 - val_loss: 1.1344
Epoch 40/43
103/103 [==============================] - 11s 110ms/step - loss: 0.8953 - val_loss: 1.1341
Epoch 41/43
103/103 [==============================] - 11s 111ms/step - loss: 0.8951 - val_loss: 1.1338
Epoch 42/43
103/103 [==============================] - 11s 111ms/step - loss: 0.8950 - val_loss: 1.1335
Epoch 43/43
103/103 [==============================] - 12s 112ms/step - loss: 0.8948 - val_loss: 1.1332
Execution time:  499.97774839401245
GRU:
Mean Absolute Error: 0.9267
Root Mean Square Error: 1.1157
Mean Square Error: 1.2448

Train RMSE: 1.116
Train MSE: 1.245
Train MAE: 0.927
###########################

MODEL:  GRU
sequence:  1d
units:  43
dropout1:  0.40519643149940265
dropout2:  0.3312343747027119
optimizer: adamax
activationDense: tanh
epochs: 56
batchsize: 11
validation_split: 0.1
Model: &#34;sequential_140&#34;
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
gru_112 (GRU)                (None, 144, 43)           5934      
_________________________________________________________________
dropout_280 (Dropout)        (None, 144, 43)           0         
_________________________________________________________________
gru_113 (GRU)                (None, 144, 43)           11352     
_________________________________________________________________
dropout_281 (Dropout)        (None, 144, 43)           0         
_________________________________________________________________
time_distributed_140 (TimeDi (None, 144, 1)            44        
=================================================================
Total params: 17,330
Trainable params: 17,330
Non-trainable params: 0
_________________________________________________________________
Epoch 1/56
315/315 [==============================] - 32s 101ms/step - loss: 0.6122 - val_loss: 0.4021
Epoch 2/56
315/315 [==============================] - 31s 98ms/step - loss: 0.5917 - val_loss: 0.3972
Epoch 3/56
315/315 [==============================] - 31s 97ms/step - loss: 0.5881 - val_loss: 0.3877
Epoch 4/56
315/315 [==============================] - 31s 98ms/step - loss: 0.5835 - val_loss: 0.3713
Epoch 5/56
315/315 [==============================] - 31s 98ms/step - loss: 0.5796 - val_loss: 0.3496
Epoch 6/56
315/315 [==============================] - 31s 97ms/step - loss: 0.5765 - val_loss: 0.3388
Epoch 7/56
315/315 [==============================] - 31s 98ms/step - loss: 0.5743 - val_loss: 0.3318
Epoch 8/56
315/315 [==============================] - 31s 98ms/step - loss: 0.5726 - val_loss: 0.3255
Epoch 9/56
315/315 [==============================] - 31s 98ms/step - loss: 0.5709 - val_loss: 0.3200
Epoch 10/56
315/315 [==============================] - 31s 97ms/step - loss: 0.5700 - val_loss: 0.3162
Epoch 11/56
315/315 [==============================] - 31s 97ms/step - loss: 0.5682 - val_loss: 0.3143
Epoch 12/56
315/315 [==============================] - 31s 97ms/step - loss: 0.5661 - val_loss: 0.3088
Epoch 13/56
315/315 [==============================] - 31s 98ms/step - loss: 0.5644 - val_loss: 0.3092
Epoch 14/56
315/315 [==============================] - 31s 97ms/step - loss: 0.5621 - val_loss: 0.3024
Epoch 15/56
315/315 [==============================] - 31s 98ms/step - loss: 0.5596 - val_loss: 0.2972
Epoch 16/56
315/315 [==============================] - 31s 97ms/step - loss: 0.5571 - val_loss: 0.2922
Epoch 17/56
315/315 [==============================] - 31s 98ms/step - loss: 0.5539 - val_loss: 0.2895
Epoch 18/56
315/315 [==============================] - 31s 98ms/step - loss: 0.5521 - val_loss: 0.2865
Epoch 19/56
315/315 [==============================] - 31s 97ms/step - loss: 0.5484 - val_loss: 0.2857
Epoch 20/56
315/315 [==============================] - 31s 98ms/step - loss: 0.5465 - val_loss: 0.2821
Epoch 21/56
315/315 [==============================] - 31s 98ms/step - loss: 0.5433 - val_loss: 0.2784
Epoch 22/56
315/315 [==============================] - 33s 105ms/step - loss: 0.5408 - val_loss: 0.2762
Epoch 23/56
315/315 [==============================] - 34s 107ms/step - loss: 0.5393 - val_loss: 0.2773
Epoch 24/56
315/315 [==============================] - 34s 107ms/step - loss: 0.5379 - val_loss: 0.2781
Epoch 25/56
315/315 [==============================] - 31s 98ms/step - loss: 0.5371 - val_loss: 0.2787
Epoch 26/56
315/315 [==============================] - 31s 98ms/step - loss: 0.5361 - val_loss: 0.2823
Epoch 27/56
315/315 [==============================] - 31s 98ms/step - loss: 0.5354 - val_loss: 0.2784
Epoch 28/56
315/315 [==============================] - 31s 98ms/step - loss: 0.5354 - val_loss: 0.2809
Epoch 29/56
315/315 [==============================] - 31s 98ms/step - loss: 0.5331 - val_loss: 0.2815
Epoch 30/56
315/315 [==============================] - 31s 98ms/step - loss: 0.5328 - val_loss: 0.2817
Epoch 31/56
315/315 [==============================] - 31s 97ms/step - loss: 0.5315 - val_loss: 0.2789
Epoch 32/56
315/315 [==============================] - 31s 98ms/step - loss: 0.5310 - val_loss: 0.2819
Epoch 33/56
315/315 [==============================] - 31s 98ms/step - loss: 0.5308 - val_loss: 0.2846
Epoch 34/56
315/315 [==============================] - 31s 98ms/step - loss: 0.5304 - val_loss: 0.2838
Epoch 35/56
315/315 [==============================] - 31s 99ms/step - loss: 0.5299 - val_loss: 0.2869
Epoch 36/56
315/315 [==============================] - 31s 98ms/step - loss: 0.5289 - val_loss: 0.2833
Epoch 37/56
315/315 [==============================] - 31s 98ms/step - loss: 0.5284 - val_loss: 0.2850
Epoch 38/56
315/315 [==============================] - 31s 98ms/step - loss: 0.5269 - val_loss: 0.2820
Epoch 39/56
315/315 [==============================] - 31s 98ms/step - loss: 0.5264 - val_loss: 0.2827
Epoch 40/56
315/315 [==============================] - 31s 98ms/step - loss: 0.5260 - val_loss: 0.2868
Epoch 41/56
315/315 [==============================] - 31s 98ms/step - loss: 0.5256 - val_loss: 0.2841
Epoch 42/56
315/315 [==============================] - 31s 98ms/step - loss: 0.5247 - val_loss: 0.2857
Epoch 43/56
315/315 [==============================] - 31s 98ms/step - loss: 0.5250 - val_loss: 0.2856
Epoch 44/56
315/315 [==============================] - 31s 98ms/step - loss: 0.5226 - val_loss: 0.2856
Epoch 45/56
315/315 [==============================] - 31s 98ms/step - loss: 0.5223 - val_loss: 0.2861
Epoch 46/56
315/315 [==============================] - 31s 98ms/step - loss: 0.5216 - val_loss: 0.2855
Epoch 47/56
315/315 [==============================] - 31s 98ms/step - loss: 0.5222 - val_loss: 0.2882
Epoch 48/56
315/315 [==============================] - 31s 98ms/step - loss: 0.5229 - val_loss: 0.2855
Epoch 49/56
315/315 [==============================] - 31s 98ms/step - loss: 0.5215 - val_loss: 0.2885
Epoch 50/56
315/315 [==============================] - 31s 98ms/step - loss: 0.5204 - val_loss: 0.2882
Epoch 51/56
315/315 [==============================] - 31s 99ms/step - loss: 0.5176 - val_loss: 0.2902
Epoch 52/56
315/315 [==============================] - 31s 98ms/step - loss: 0.5197 - val_loss: 0.2849
Epoch 53/56
315/315 [==============================] - 31s 98ms/step - loss: 0.5177 - val_loss: 0.2854
Epoch 54/56
315/315 [==============================] - 31s 99ms/step - loss: 0.5184 - val_loss: 0.2865
Epoch 55/56
315/315 [==============================] - 31s 99ms/step - loss: 0.5160 - val_loss: 0.2891
Epoch 56/56
315/315 [==============================] - 31s 98ms/step - loss: 0.5159 - val_loss: 0.2870
Execution time:  1746.3181297779083
GRU:
Mean Absolute Error: 0.3813
Root Mean Square Error: 0.8586
Mean Square Error: 0.7373

Train RMSE: 0.859
Train MSE: 0.737
Train MAE: 0.381
###########################

MODEL:  GRU
sequence:  1d
units:  45
dropout1:  0.11814836227952394
dropout2:  0.24325404382648977
optimizer: adamax
activationDense: tanh
epochs: 43
batchsize: 30
validation_split: 0.2
Model: &#34;sequential_141&#34;
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
gru_114 (GRU)                (None, 144, 45)           6480      
_________________________________________________________________
dropout_282 (Dropout)        (None, 144, 45)           0         
_________________________________________________________________
gru_115 (GRU)                (None, 144, 45)           12420     
_________________________________________________________________
dropout_283 (Dropout)        (None, 144, 45)           0         
_________________________________________________________________
time_distributed_141 (TimeDi (None, 144, 1)            46        
=================================================================
Total params: 18,946
Trainable params: 18,946
Non-trainable params: 0
_________________________________________________________________
Epoch 1/43
103/103 [==============================] - 12s 114ms/step - loss: 0.6263 - val_loss: 0.4104
Epoch 2/43
103/103 [==============================] - 11s 111ms/step - loss: 0.5934 - val_loss: 0.4133
Epoch 3/43
103/103 [==============================] - 11s 111ms/step - loss: 0.5891 - val_loss: 0.4147
Epoch 4/43
103/103 [==============================] - 11s 109ms/step - loss: 0.5860 - val_loss: 0.4157
Epoch 5/43
103/103 [==============================] - 11s 110ms/step - loss: 0.5828 - val_loss: 0.4163
Epoch 6/43
103/103 [==============================] - 11s 111ms/step - loss: 0.5807 - val_loss: 0.4168
Epoch 7/43
103/103 [==============================] - 11s 112ms/step - loss: 0.5783 - val_loss: 0.4171
Epoch 8/43
103/103 [==============================] - 11s 110ms/step - loss: 0.5760 - val_loss: 0.4172
Epoch 9/43
103/103 [==============================] - 11s 111ms/step - loss: 0.5742 - val_loss: 0.4175
Epoch 10/43
103/103 [==============================] - 11s 110ms/step - loss: 0.5723 - val_loss: 0.4176
Epoch 11/43
103/103 [==============================] - 11s 109ms/step - loss: 0.5706 - val_loss: 0.4175
Epoch 12/43
103/103 [==============================] - 11s 110ms/step - loss: 0.5690 - val_loss: 0.4176
Epoch 13/43
103/103 [==============================] - 11s 110ms/step - loss: 0.5675 - val_loss: 0.4174
Epoch 14/43
103/103 [==============================] - 11s 110ms/step - loss: 0.5663 - val_loss: 0.4175
Epoch 15/43
103/103 [==============================] - 11s 108ms/step - loss: 0.5652 - val_loss: 0.4172
Epoch 16/43
103/103 [==============================] - 11s 110ms/step - loss: 0.5639 - val_loss: 0.4168
Epoch 17/43
103/103 [==============================] - 11s 111ms/step - loss: 0.5630 - val_loss: 0.4167
Epoch 18/43
103/103 [==============================] - 11s 109ms/step - loss: 0.5617 - val_loss: 0.4163
Epoch 19/43
103/103 [==============================] - 11s 110ms/step - loss: 0.5607 - val_loss: 0.4159
Epoch 20/43
103/103 [==============================] - 11s 110ms/step - loss: 0.5598 - val_loss: 0.4153
Epoch 21/43
103/103 [==============================] - 11s 110ms/step - loss: 0.5585 - val_loss: 0.4148
Epoch 22/43
103/103 [==============================] - 11s 108ms/step - loss: 0.5577 - val_loss: 0.4139
Epoch 23/43
103/103 [==============================] - 11s 110ms/step - loss: 0.5563 - val_loss: 0.4129
Epoch 24/43
103/103 [==============================] - 11s 110ms/step - loss: 0.5546 - val_loss: 0.4115
Epoch 25/43
103/103 [==============================] - 11s 108ms/step - loss: 0.5534 - val_loss: 0.4103
Epoch 26/43
103/103 [==============================] - 11s 110ms/step - loss: 0.5515 - val_loss: 0.4088
Epoch 27/43
103/103 [==============================] - 11s 110ms/step - loss: 0.5496 - val_loss: 0.4072
Epoch 28/43
103/103 [==============================] - 12s 112ms/step - loss: 0.5476 - val_loss: 0.4059
Epoch 29/43
103/103 [==============================] - 11s 109ms/step - loss: 0.5450 - val_loss: 0.4054
Epoch 30/43
103/103 [==============================] - 11s 110ms/step - loss: 0.5428 - val_loss: 0.4056
Epoch 31/43
103/103 [==============================] - 11s 110ms/step - loss: 0.5407 - val_loss: 0.4068
Epoch 32/43
103/103 [==============================] - 11s 109ms/step - loss: 0.5393 - val_loss: 0.4084
Epoch 33/43
103/103 [==============================] - 11s 110ms/step - loss: 0.5377 - val_loss: 0.4102
Epoch 34/43
103/103 [==============================] - 11s 110ms/step - loss: 0.5360 - val_loss: 0.4118
Epoch 35/43
103/103 [==============================] - 11s 110ms/step - loss: 0.5343 - val_loss: 0.4129
Epoch 36/43
103/103 [==============================] - 11s 109ms/step - loss: 0.5337 - val_loss: 0.4141
Epoch 37/43
103/103 [==============================] - 11s 110ms/step - loss: 0.5331 - val_loss: 0.4147
Epoch 38/43
103/103 [==============================] - 11s 111ms/step - loss: 0.5328 - val_loss: 0.4154
Epoch 39/43
103/103 [==============================] - 11s 110ms/step - loss: 0.5318 - val_loss: 0.4160
Epoch 40/43
103/103 [==============================] - 11s 110ms/step - loss: 0.5309 - val_loss: 0.4165
Epoch 41/43
103/103 [==============================] - 11s 110ms/step - loss: 0.5302 - val_loss: 0.4171
Epoch 42/43
103/103 [==============================] - 11s 110ms/step - loss: 0.5291 - val_loss: 0.4169
Epoch 43/43
103/103 [==============================] - 11s 109ms/step - loss: 0.5287 - val_loss: 0.4184
Execution time:  496.63371229171753
GRU:
Mean Absolute Error: 0.3544
Root Mean Square Error: 0.8462
Mean Square Error: 0.7160

Train RMSE: 0.846
Train MSE: 0.716
Train MAE: 0.354
###########################

MODEL:  GRU
sequence:  1d
units:  43
dropout1:  0.40519643149940265
dropout2:  0.3312343747027119
optimizer: adamax
activationDense: sigmoid
epochs: 56
batchsize: 11
validation_split: 0.1
Model: &#34;sequential_142&#34;
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
gru_116 (GRU)                (None, 144, 43)           5934      
_________________________________________________________________
dropout_284 (Dropout)        (None, 144, 43)           0         
_________________________________________________________________
gru_117 (GRU)                (None, 144, 43)           11352     
_________________________________________________________________
dropout_285 (Dropout)        (None, 144, 43)           0         
_________________________________________________________________
time_distributed_142 (TimeDi (None, 144, 1)            44        
=================================================================
Total params: 17,330
Trainable params: 17,330
Non-trainable params: 0
_________________________________________________________________
Epoch 1/56
315/315 [==============================] - 32s 102ms/step - loss: 0.7602 - val_loss: 0.8265
Epoch 2/56
315/315 [==============================] - 31s 100ms/step - loss: 0.7058 - val_loss: 0.8142
Epoch 3/56
315/315 [==============================] - 31s 99ms/step - loss: 0.6963 - val_loss: 0.8105
Epoch 4/56
315/315 [==============================] - 31s 99ms/step - loss: 0.6892 - val_loss: 0.8088
Epoch 5/56
315/315 [==============================] - 31s 100ms/step - loss: 0.6869 - val_loss: 0.8074
Epoch 6/56
315/315 [==============================] - 31s 100ms/step - loss: 0.6853 - val_loss: 0.8064
Epoch 7/56
315/315 [==============================] - 31s 99ms/step - loss: 0.6839 - val_loss: 0.8057
Epoch 8/56
315/315 [==============================] - 31s 99ms/step - loss: 0.6825 - val_loss: 0.8051
Epoch 9/56
315/315 [==============================] - 31s 99ms/step - loss: 0.6813 - val_loss: 0.8047
Epoch 10/56
315/315 [==============================] - 31s 100ms/step - loss: 0.6800 - val_loss: 0.8044
Epoch 11/56
315/315 [==============================] - 31s 100ms/step - loss: 0.6788 - val_loss: 0.8042
Epoch 12/56
315/315 [==============================] - 31s 99ms/step - loss: 0.6774 - val_loss: 0.8040
Epoch 13/56
315/315 [==============================] - 31s 100ms/step - loss: 0.6760 - val_loss: 0.8038
Epoch 14/56
315/315 [==============================] - 31s 99ms/step - loss: 0.6746 - val_loss: 0.8036
Epoch 15/56
315/315 [==============================] - 31s 99ms/step - loss: 0.6735 - val_loss: 0.8035
Epoch 16/56
315/315 [==============================] - 31s 99ms/step - loss: 0.6718 - val_loss: 0.8033
Epoch 17/56
315/315 [==============================] - 31s 100ms/step - loss: 0.6701 - val_loss: 0.8032
Epoch 18/56
315/315 [==============================] - 31s 99ms/step - loss: 0.6683 - val_loss: 0.8030
Epoch 19/56
315/315 [==============================] - 31s 99ms/step - loss: 0.6660 - val_loss: 0.8029
Epoch 20/56
315/315 [==============================] - 31s 99ms/step - loss: 0.6633 - val_loss: 0.8028
Epoch 21/56
315/315 [==============================] - 31s 100ms/step - loss: 0.6611 - val_loss: 0.8027
Epoch 22/56
315/315 [==============================] - 31s 99ms/step - loss: 0.6585 - val_loss: 0.8027
Epoch 23/56
315/315 [==============================] - 31s 99ms/step - loss: 0.6561 - val_loss: 0.8026
Epoch 24/56
315/315 [==============================] - 31s 99ms/step - loss: 0.6526 - val_loss: 0.8026
Epoch 25/56
315/315 [==============================] - 31s 100ms/step - loss: 0.6496 - val_loss: 0.8025
Epoch 26/56
315/315 [==============================] - 31s 99ms/step - loss: 0.6460 - val_loss: 0.8025
Epoch 27/56
315/315 [==============================] - 31s 99ms/step - loss: 0.6434 - val_loss: 0.8025
Epoch 28/56
315/315 [==============================] - 31s 99ms/step - loss: 0.6417 - val_loss: 0.8025
Epoch 29/56
315/315 [==============================] - 31s 100ms/step - loss: 0.6401 - val_loss: 0.8025
Epoch 30/56
315/315 [==============================] - 31s 99ms/step - loss: 0.6386 - val_loss: 0.8024
Epoch 31/56
315/315 [==============================] - 31s 100ms/step - loss: 0.6378 - val_loss: 0.8024
Epoch 32/56
315/315 [==============================] - 31s 100ms/step - loss: 0.6374 - val_loss: 0.8024
Epoch 33/56
315/315 [==============================] - 31s 99ms/step - loss: 0.6365 - val_loss: 0.8024
Epoch 34/56
315/315 [==============================] - 31s 98ms/step - loss: 0.6358 - val_loss: 0.8023
Epoch 35/56
315/315 [==============================] - 34s 106ms/step - loss: 0.6353 - val_loss: 0.8023
Epoch 36/56
315/315 [==============================] - 31s 100ms/step - loss: 0.6350 - val_loss: 0.8023
Epoch 37/56
315/315 [==============================] - 31s 99ms/step - loss: 0.6345 - val_loss: 0.8023
Epoch 38/56
315/315 [==============================] - 31s 99ms/step - loss: 0.6341 - val_loss: 0.8023
Epoch 39/56
315/315 [==============================] - 31s 99ms/step - loss: 0.6342 - val_loss: 0.8023
Epoch 40/56
315/315 [==============================] - 31s 99ms/step - loss: 0.6337 - val_loss: 0.8023
Epoch 41/56
315/315 [==============================] - 31s 98ms/step - loss: 0.6339 - val_loss: 0.8022
Epoch 42/56
315/315 [==============================] - 31s 98ms/step - loss: 0.6336 - val_loss: 0.8022
Epoch 43/56
315/315 [==============================] - 32s 100ms/step - loss: 0.6332 - val_loss: 0.8022
Epoch 44/56
315/315 [==============================] - 31s 99ms/step - loss: 0.6331 - val_loss: 0.8022
Epoch 45/56
315/315 [==============================] - 31s 98ms/step - loss: 0.6327 - val_loss: 0.8022
Epoch 46/56
315/315 [==============================] - 31s 98ms/step - loss: 0.6325 - val_loss: 0.8022
Epoch 47/56
315/315 [==============================] - 31s 99ms/step - loss: 0.6327 - val_loss: 0.8022
Epoch 48/56
315/315 [==============================] - 31s 99ms/step - loss: 0.6326 - val_loss: 0.8022
Epoch 49/56
315/315 [==============================] - 31s 98ms/step - loss: 0.6324 - val_loss: 0.8022
Epoch 50/56
315/315 [==============================] - 31s 99ms/step - loss: 0.6322 - val_loss: 0.8022
Epoch 51/56
315/315 [==============================] - 31s 99ms/step - loss: 0.6319 - val_loss: 0.8022
Epoch 52/56
315/315 [==============================] - 31s 99ms/step - loss: 0.6319 - val_loss: 0.8022
Epoch 53/56
315/315 [==============================] - 31s 99ms/step - loss: 0.6315 - val_loss: 0.8021
Epoch 54/56
315/315 [==============================] - 31s 98ms/step - loss: 0.6312 - val_loss: 0.8021
Epoch 55/56
315/315 [==============================] - 31s 99ms/step - loss: 0.6313 - val_loss: 0.8022
Epoch 56/56
315/315 [==============================] - 31s 99ms/step - loss: 0.6311 - val_loss: 0.8021
Execution time:  1766.272943496704
GRU:
Mean Absolute Error: 0.6386
Root Mean Square Error: 0.9354
Mean Square Error: 0.8750

Train RMSE: 0.935
Train MSE: 0.875
Train MAE: 0.639
###########################

MODEL:  GRU
sequence:  1d
units:  45
dropout1:  0.11814836227952394
dropout2:  0.24325404382648977
optimizer: adamax
activationDense: sigmoid
epochs: 43
batchsize: 30
validation_split: 0.2
Model: &#34;sequential_143&#34;
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
gru_118 (GRU)                (None, 144, 45)           6480      
_________________________________________________________________
dropout_286 (Dropout)        (None, 144, 45)           0         
_________________________________________________________________
gru_119 (GRU)                (None, 144, 45)           12420     
_________________________________________________________________
dropout_287 (Dropout)        (None, 144, 45)           0         
_________________________________________________________________
time_distributed_143 (TimeDi (None, 144, 1)            46        
=================================================================
Total params: 18,946
Trainable params: 18,946
Non-trainable params: 0
_________________________________________________________________
Epoch 1/43
103/103 [==============================] - 12s 115ms/step - loss: 0.8369 - val_loss: 0.8324
Epoch 2/43
103/103 [==============================] - 12s 112ms/step - loss: 0.7150 - val_loss: 0.7822
Epoch 3/43
103/103 [==============================] - 12s 112ms/step - loss: 0.7054 - val_loss: 0.7726
Epoch 4/43
103/103 [==============================] - 11s 111ms/step - loss: 0.7008 - val_loss: 0.7676
Epoch 5/43
103/103 [==============================] - 12s 112ms/step - loss: 0.6975 - val_loss: 0.7644
Epoch 6/43
103/103 [==============================] - 11s 112ms/step - loss: 0.6947 - val_loss: 0.7618
Epoch 7/43
103/103 [==============================] - 12s 112ms/step - loss: 0.6922 - val_loss: 0.7596
Epoch 8/43
103/103 [==============================] - 12s 112ms/step - loss: 0.6897 - val_loss: 0.7571
Epoch 9/43
103/103 [==============================] - 11s 112ms/step - loss: 0.6873 - val_loss: 0.7542
Epoch 10/43
103/103 [==============================] - 11s 111ms/step - loss: 0.6847 - val_loss: 0.7508
Epoch 11/43
103/103 [==============================] - 11s 110ms/step - loss: 0.6828 - val_loss: 0.7479
Epoch 12/43
103/103 [==============================] - 11s 112ms/step - loss: 0.6814 - val_loss: 0.7458
Epoch 13/43
103/103 [==============================] - 11s 111ms/step - loss: 0.6803 - val_loss: 0.7442
Epoch 14/43
103/103 [==============================] - 12s 112ms/step - loss: 0.6792 - val_loss: 0.7429
Epoch 15/43
103/103 [==============================] - 11s 110ms/step - loss: 0.6783 - val_loss: 0.7416
Epoch 16/43
103/103 [==============================] - 11s 111ms/step - loss: 0.6773 - val_loss: 0.7405
Epoch 17/43
103/103 [==============================] - 11s 111ms/step - loss: 0.6765 - val_loss: 0.7393
Epoch 18/43
103/103 [==============================] - 12s 113ms/step - loss: 0.6756 - val_loss: 0.7382
Epoch 19/43
103/103 [==============================] - 11s 111ms/step - loss: 0.6748 - val_loss: 0.7372
Epoch 20/43
103/103 [==============================] - 12s 112ms/step - loss: 0.6740 - val_loss: 0.7362
Epoch 21/43
103/103 [==============================] - 11s 112ms/step - loss: 0.6733 - val_loss: 0.7352
Epoch 22/43
103/103 [==============================] - 11s 111ms/step - loss: 0.6726 - val_loss: 0.7344
Epoch 23/43
103/103 [==============================] - 11s 112ms/step - loss: 0.6721 - val_loss: 0.7335
Epoch 24/43
103/103 [==============================] - 11s 111ms/step - loss: 0.6715 - val_loss: 0.7328
Epoch 25/43
103/103 [==============================] - 12s 112ms/step - loss: 0.6707 - val_loss: 0.7324
Epoch 26/43
103/103 [==============================] - 11s 112ms/step - loss: 0.6703 - val_loss: 0.7314
Epoch 27/43
103/103 [==============================] - 11s 112ms/step - loss: 0.6698 - val_loss: 0.7313
Epoch 28/43
103/103 [==============================] - 12s 114ms/step - loss: 0.6690 - val_loss: 0.7306
Epoch 29/43
103/103 [==============================] - 11s 111ms/step - loss: 0.6687 - val_loss: 0.7302
Epoch 30/43
103/103 [==============================] - 11s 111ms/step - loss: 0.6682 - val_loss: 0.7295
Epoch 31/43
103/103 [==============================] - 11s 112ms/step - loss: 0.6678 - val_loss: 0.7293
Epoch 32/43
103/103 [==============================] - 11s 111ms/step - loss: 0.6672 - val_loss: 0.7286
Epoch 33/43
103/103 [==============================] - 11s 110ms/step - loss: 0.6668 - val_loss: 0.7286
Epoch 34/43
103/103 [==============================] - 11s 111ms/step - loss: 0.6661 - val_loss: 0.7276
Epoch 35/43
103/103 [==============================] - 11s 111ms/step - loss: 0.6661 - val_loss: 0.7281
Epoch 36/43
103/103 [==============================] - 11s 111ms/step - loss: 0.6647 - val_loss: 0.7273
Epoch 37/43
103/103 [==============================] - 11s 111ms/step - loss: 0.6645 - val_loss: 0.7269
Epoch 38/43
103/103 [==============================] - 12s 113ms/step - loss: 0.6639 - val_loss: 0.7263
Epoch 39/43
103/103 [==============================] - 12s 112ms/step - loss: 0.6625 - val_loss: 0.7263
Epoch 40/43
103/103 [==============================] - 11s 110ms/step - loss: 0.6594 - val_loss: 0.7251
Epoch 41/43
103/103 [==============================] - 11s 111ms/step - loss: 0.6583 - val_loss: 0.7237
Epoch 42/43
103/103 [==============================] - 12s 113ms/step - loss: 0.6581 - val_loss: 0.7235
Epoch 43/43
103/103 [==============================] - 11s 111ms/step - loss: 0.6575 - val_loss: 0.7221
Execution time:  503.6986105442047
GRU:
Mean Absolute Error: 0.6278
Root Mean Square Error: 0.9179
Mean Square Error: 0.8426

Train RMSE: 0.918
Train MSE: 0.843
Train MAE: 0.628
###########################

MODEL:  GRU
sequence:  3d
units:  43
dropout1:  0.40519643149940265
dropout2:  0.3312343747027119
optimizer: adam
activationDense: tanh
epochs: 56
batchsize: 11
validation_split: 0.1
Model: &#34;sequential_144&#34;
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
gru_120 (GRU)                (None, 432, 43)           5934      
_________________________________________________________________
dropout_288 (Dropout)        (None, 432, 43)           0         
_________________________________________________________________
gru_121 (GRU)                (None, 432, 43)           11352     
_________________________________________________________________
dropout_289 (Dropout)        (None, 432, 43)           0         
_________________________________________________________________
time_distributed_144 (TimeDi (None, 432, 1)            44        
=================================================================
Total params: 17,330
Trainable params: 17,330
Non-trainable params: 0
_________________________________________________________________
Epoch 1/56
292/292 [==============================] - 81s 279ms/step - loss: 0.6396 - val_loss: 0.5336
Epoch 2/56
292/292 [==============================] - 80s 275ms/step - loss: 0.6337 - val_loss: 0.4956
Epoch 3/56
292/292 [==============================] - 81s 277ms/step - loss: 0.6212 - val_loss: 0.4529
Epoch 4/56
292/292 [==============================] - 81s 276ms/step - loss: 0.6066 - val_loss: 0.4628
Epoch 5/56
292/292 [==============================] - 81s 276ms/step - loss: 0.6042 - val_loss: 0.4670
Epoch 6/56
292/292 [==============================] - 81s 276ms/step - loss: 0.6016 - val_loss: 0.4675
Epoch 7/56
292/292 [==============================] - 81s 277ms/step - loss: 0.5996 - val_loss: 0.4688
Epoch 8/56
292/292 [==============================] - 80s 276ms/step - loss: 0.5987 - val_loss: 0.4640
Epoch 9/56
292/292 [==============================] - 81s 276ms/step - loss: 0.5979 - val_loss: 0.4702
Epoch 10/56
292/292 [==============================] - 81s 277ms/step - loss: 0.5965 - val_loss: 0.4666
Epoch 11/56
292/292 [==============================] - 81s 277ms/step - loss: 0.5959 - val_loss: 0.4701
Epoch 12/56
292/292 [==============================] - 81s 276ms/step - loss: 0.5953 - val_loss: 0.4683
Epoch 13/56
292/292 [==============================] - 81s 277ms/step - loss: 0.5941 - val_loss: 0.4644
Epoch 14/56
292/292 [==============================] - 81s 276ms/step - loss: 0.5938 - val_loss: 0.4663
Epoch 15/56
292/292 [==============================] - 80s 276ms/step - loss: 0.5938 - val_loss: 0.4634
Epoch 16/56
292/292 [==============================] - 81s 277ms/step - loss: 0.5944 - val_loss: 0.4549
Epoch 17/56
292/292 [==============================] - 81s 277ms/step - loss: 0.5936 - val_loss: 0.4602
Epoch 18/56
292/292 [==============================] - 80s 276ms/step - loss: 0.5938 - val_loss: 0.4513
Epoch 19/56
292/292 [==============================] - 81s 276ms/step - loss: 0.5935 - val_loss: 0.4572
Epoch 20/56
292/292 [==============================] - 81s 277ms/step - loss: 0.5931 - val_loss: 0.4550
Epoch 21/56
292/292 [==============================] - 80s 275ms/step - loss: 0.5930 - val_loss: 0.4594
Epoch 22/56
292/292 [==============================] - 81s 276ms/step - loss: 0.5931 - val_loss: 0.4546
Epoch 23/56
292/292 [==============================] - 81s 278ms/step - loss: 0.5931 - val_loss: 0.4543
Epoch 24/56
292/292 [==============================] - 80s 275ms/step - loss: 0.5931 - val_loss: 0.4539
Epoch 25/56
292/292 [==============================] - 81s 276ms/step - loss: 0.5935 - val_loss: 0.4519
Epoch 26/56
292/292 [==============================] - 81s 277ms/step - loss: 0.5930 - val_loss: 0.4521
Epoch 27/56
292/292 [==============================] - 80s 276ms/step - loss: 0.5926 - val_loss: 0.4506
Epoch 28/56
292/292 [==============================] - 81s 276ms/step - loss: 0.5926 - val_loss: 0.4511
Epoch 29/56
292/292 [==============================] - 82s 279ms/step - loss: 0.5929 - val_loss: 0.4536
Epoch 30/56
292/292 [==============================] - 80s 276ms/step - loss: 0.5922 - val_loss: 0.4528
Epoch 31/56
292/292 [==============================] - 81s 277ms/step - loss: 0.5922 - val_loss: 0.4508
Epoch 32/56
292/292 [==============================] - 81s 277ms/step - loss: 0.5921 - val_loss: 0.4544
Epoch 33/56
292/292 [==============================] - 81s 276ms/step - loss: 0.5924 - val_loss: 0.4554
Epoch 34/56
292/292 [==============================] - 81s 278ms/step - loss: 0.5920 - val_loss: 0.4526
Epoch 35/56
292/292 [==============================] - 81s 277ms/step - loss: 0.5919 - val_loss: 0.4556
Epoch 36/56
292/292 [==============================] - 81s 279ms/step - loss: 0.5915 - val_loss: 0.4527
Epoch 37/56
292/292 [==============================] - 81s 276ms/step - loss: 0.5919 - val_loss: 0.4582
Epoch 38/56
292/292 [==============================] - 81s 277ms/step - loss: 0.5912 - val_loss: 0.4551
Epoch 39/56
292/292 [==============================] - 81s 276ms/step - loss: 0.5912 - val_loss: 0.4544
Epoch 40/56
292/292 [==============================] - 81s 276ms/step - loss: 0.5911 - val_loss: 0.4578
Epoch 41/56
292/292 [==============================] - 81s 277ms/step - loss: 0.5905 - val_loss: 0.4573
Epoch 42/56
292/292 [==============================] - 81s 277ms/step - loss: 0.5906 - val_loss: 0.4590
Epoch 43/56
292/292 [==============================] - 81s 277ms/step - loss: 0.5899 - val_loss: 0.4592
Epoch 44/56
292/292 [==============================] - 81s 277ms/step - loss: 0.5903 - val_loss: 0.4580
Epoch 45/56
292/292 [==============================] - 81s 277ms/step - loss: 0.5899 - val_loss: 0.4556
Epoch 46/56
292/292 [==============================] - 81s 277ms/step - loss: 0.5896 - val_loss: 0.4609
Epoch 47/56
292/292 [==============================] - 81s 276ms/step - loss: 0.5891 - val_loss: 0.4593
Epoch 48/56
292/292 [==============================] - 81s 276ms/step - loss: 0.5941 - val_loss: 0.4548
Epoch 49/56
292/292 [==============================] - 81s 277ms/step - loss: 0.5895 - val_loss: 0.4559
Epoch 50/56
292/292 [==============================] - 81s 277ms/step - loss: 0.5881 - val_loss: 0.4586
Epoch 51/56
292/292 [==============================] - 81s 276ms/step - loss: 0.5890 - val_loss: 0.4597
Epoch 52/56
292/292 [==============================] - 81s 276ms/step - loss: 0.5877 - val_loss: 0.4596
Epoch 53/56
292/292 [==============================] - 81s 277ms/step - loss: 0.5878 - val_loss: 0.4587
Epoch 54/56
292/292 [==============================] - 81s 277ms/step - loss: 0.5881 - val_loss: 0.4567
Epoch 55/56
292/292 [==============================] - 81s 276ms/step - loss: 0.5875 - val_loss: 0.4583
Epoch 56/56
292/292 [==============================] - 81s 279ms/step - loss: 0.5883 - val_loss: 0.4546
Execution time:  4543.565344810486
GRU:
Mean Absolute Error: 0.5515
Root Mean Square Error: 0.9958
Mean Square Error: 0.9916

Train RMSE: 0.996
Train MSE: 0.992
Train MAE: 0.552
###########################

MODEL:  GRU
sequence:  3d
units:  45
dropout1:  0.11814836227952394
dropout2:  0.24325404382648977
optimizer: adam
activationDense: tanh
epochs: 43
batchsize: 30
validation_split: 0.2
Model: &#34;sequential_145&#34;
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
gru_122 (GRU)                (None, 432, 45)           6480      
_________________________________________________________________
dropout_290 (Dropout)        (None, 432, 45)           0         
_________________________________________________________________
gru_123 (GRU)                (None, 432, 45)           12420     
_________________________________________________________________
dropout_291 (Dropout)        (None, 432, 45)           0         
_________________________________________________________________
time_distributed_145 (TimeDi (None, 432, 1)            46        
=================================================================
Total params: 18,946
Trainable params: 18,946
Non-trainable params: 0
_________________________________________________________________
Epoch 1/43
95/95 [==============================] - 30s 316ms/step - loss: 0.6907 - val_loss: 0.3693
Epoch 2/43
95/95 [==============================] - 29s 310ms/step - loss: 0.6773 - val_loss: 0.3355
Epoch 3/43
95/95 [==============================] - 29s 308ms/step - loss: 0.6723 - val_loss: 0.3339
Epoch 4/43
95/95 [==============================] - 29s 307ms/step - loss: 0.6684 - val_loss: 0.3388
Epoch 5/43
95/95 [==============================] - 29s 307ms/step - loss: 0.6649 - val_loss: 0.3407
Epoch 6/43
95/95 [==============================] - 29s 307ms/step - loss: 0.6620 - val_loss: 0.3397
Epoch 7/43
95/95 [==============================] - 29s 309ms/step - loss: 0.6599 - val_loss: 0.3385
Epoch 8/43
95/95 [==============================] - 29s 306ms/step - loss: 0.6521 - val_loss: 0.3585
Epoch 9/43
95/95 [==============================] - 29s 307ms/step - loss: 0.6432 - val_loss: 0.3926
Epoch 10/43
95/95 [==============================] - 29s 308ms/step - loss: 0.6373 - val_loss: 0.3846
Epoch 11/43
95/95 [==============================] - 30s 316ms/step - loss: 0.6432 - val_loss: 0.3854
Epoch 12/43
95/95 [==============================] - 30s 315ms/step - loss: 0.6353 - val_loss: 0.3814
Epoch 13/43
95/95 [==============================] - 30s 314ms/step - loss: 0.6353 - val_loss: 0.3948
Epoch 14/43
95/95 [==============================] - 30s 315ms/step - loss: 0.6323 - val_loss: 0.3879
Epoch 15/43
95/95 [==============================] - 30s 316ms/step - loss: 0.6312 - val_loss: 0.3831
Epoch 16/43
95/95 [==============================] - 30s 313ms/step - loss: 0.6295 - val_loss: 0.3780
Epoch 17/43
95/95 [==============================] - 30s 315ms/step - loss: 0.6289 - val_loss: 0.3797
Epoch 18/43
95/95 [==============================] - 30s 315ms/step - loss: 0.6285 - val_loss: 0.3825
Epoch 19/43
95/95 [==============================] - 30s 318ms/step - loss: 0.6281 - val_loss: 0.3826
Epoch 20/43
95/95 [==============================] - 30s 316ms/step - loss: 0.6276 - val_loss: 0.3842
Epoch 21/43
95/95 [==============================] - 30s 316ms/step - loss: 0.6271 - val_loss: 0.3835
Epoch 22/43
95/95 [==============================] - 30s 316ms/step - loss: 0.6269 - val_loss: 0.3837
Epoch 23/43
95/95 [==============================] - 30s 318ms/step - loss: 0.6267 - val_loss: 0.3848
Epoch 24/43
95/95 [==============================] - 30s 316ms/step - loss: 0.6265 - val_loss: 0.3852
Epoch 25/43
95/95 [==============================] - 30s 315ms/step - loss: 0.6266 - val_loss: 0.3872
Epoch 26/43
95/95 [==============================] - 30s 319ms/step - loss: 0.6261 - val_loss: 0.3854
Epoch 27/43
95/95 [==============================] - 31s 326ms/step - loss: 0.6260 - val_loss: 0.3850
Epoch 28/43
95/95 [==============================] - 31s 324ms/step - loss: 0.6260 - val_loss: 0.3884
Epoch 29/43
95/95 [==============================] - 30s 319ms/step - loss: 0.6252 - val_loss: 0.3875
Epoch 30/43
95/95 [==============================] - 30s 318ms/step - loss: 0.6252 - val_loss: 0.3881
Epoch 31/43
95/95 [==============================] - 30s 316ms/step - loss: 0.6239 - val_loss: 0.3831
Epoch 32/43
95/95 [==============================] - 30s 317ms/step - loss: 0.6255 - val_loss: 0.3880
Epoch 33/43
95/95 [==============================] - 30s 317ms/step - loss: 0.6230 - val_loss: 0.3850
Epoch 34/43
95/95 [==============================] - 30s 319ms/step - loss: 0.6240 - val_loss: 0.3852
Epoch 35/43
95/95 [==============================] - 30s 317ms/step - loss: 0.6232 - val_loss: 0.3861
Epoch 36/43
95/95 [==============================] - 30s 316ms/step - loss: 0.6230 - val_loss: 0.3871
Epoch 37/43
95/95 [==============================] - 30s 315ms/step - loss: 0.6223 - val_loss: 0.3886
Epoch 38/43
95/95 [==============================] - 30s 318ms/step - loss: 0.6221 - val_loss: 0.3911
Epoch 39/43
95/95 [==============================] - 30s 316ms/step - loss: 0.6220 - val_loss: 0.3928
Epoch 40/43
95/95 [==============================] - 30s 317ms/step - loss: 0.6218 - val_loss: 0.3939
Epoch 41/43
95/95 [==============================] - 30s 317ms/step - loss: 0.6215 - val_loss: 0.3941
Epoch 42/43
95/95 [==============================] - 30s 319ms/step - loss: 0.6212 - val_loss: 0.3942
Epoch 43/43
95/95 [==============================] - 30s 318ms/step - loss: 0.6211 - val_loss: 0.3947
Execution time:  1305.1391537189484
GRU:
Mean Absolute Error: 0.5307
Root Mean Square Error: 0.9617
Mean Square Error: 0.9249

Train RMSE: 0.962
Train MSE: 0.925
Train MAE: 0.531
###########################

MODEL:  GRU
sequence:  3d
units:  43
dropout1:  0.40519643149940265
dropout2:  0.3312343747027119
optimizer: adam
activationDense: sigmoid
epochs: 56
batchsize: 11
validation_split: 0.1
Model: &#34;sequential_146&#34;
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
gru_124 (GRU)                (None, 432, 43)           5934      
_________________________________________________________________
dropout_292 (Dropout)        (None, 432, 43)           0         
_________________________________________________________________
gru_125 (GRU)                (None, 432, 43)           11352     
_________________________________________________________________
dropout_293 (Dropout)        (None, 432, 43)           0         
_________________________________________________________________
time_distributed_146 (TimeDi (None, 432, 1)            44        
=================================================================
Total params: 17,330
Trainable params: 17,330
Non-trainable params: 0
_________________________________________________________________
Epoch 1/56
292/292 [==============================] - 81s 277ms/step - loss: 0.7522 - val_loss: 0.8001
Epoch 2/56
292/292 [==============================] - 80s 274ms/step - loss: 0.6778 - val_loss: 0.7956
Epoch 3/56
292/292 [==============================] - 80s 275ms/step - loss: 0.6768 - val_loss: 0.7944
Epoch 4/56
292/292 [==============================] - 81s 276ms/step - loss: 0.6764 - val_loss: 0.7939
Epoch 5/56
292/292 [==============================] - 81s 276ms/step - loss: 0.6762 - val_loss: 0.7936
Epoch 6/56
292/292 [==============================] - 81s 277ms/step - loss: 0.6761 - val_loss: 0.7934
Epoch 7/56
292/292 [==============================] - 81s 276ms/step - loss: 0.6760 - val_loss: 0.7932
Epoch 8/56
292/292 [==============================] - 80s 276ms/step - loss: 0.6759 - val_loss: 0.7931
Epoch 9/56
292/292 [==============================] - 81s 276ms/step - loss: 0.6759 - val_loss: 0.7930
Epoch 10/56
292/292 [==============================] - 81s 276ms/step - loss: 0.6759 - val_loss: 0.7929
Epoch 11/56
292/292 [==============================] - 80s 276ms/step - loss: 0.6758 - val_loss: 0.7929
Epoch 12/56
292/292 [==============================] - 81s 277ms/step - loss: 0.6758 - val_loss: 0.7928
Epoch 13/56
292/292 [==============================] - 81s 278ms/step - loss: 0.6758 - val_loss: 0.7928
Epoch 14/56
292/292 [==============================] - 81s 276ms/step - loss: 0.6758 - val_loss: 0.7928
Epoch 15/56
292/292 [==============================] - 81s 277ms/step - loss: 0.6758 - val_loss: 0.7928
Epoch 16/56
292/292 [==============================] - 81s 278ms/step - loss: 0.6758 - val_loss: 0.7928
Epoch 17/56
292/292 [==============================] - 81s 277ms/step - loss: 0.6758 - val_loss: 0.7928
Epoch 18/56
292/292 [==============================] - 81s 277ms/step - loss: 0.6758 - val_loss: 0.7928
Epoch 19/56
292/292 [==============================] - 81s 277ms/step - loss: 0.6758 - val_loss: 0.7927
Epoch 20/56
292/292 [==============================] - 81s 276ms/step - loss: 0.6758 - val_loss: 0.7927
Epoch 21/56
292/292 [==============================] - 81s 277ms/step - loss: 0.6758 - val_loss: 0.7927
Epoch 22/56
292/292 [==============================] - 81s 277ms/step - loss: 0.6758 - val_loss: 0.7927
Epoch 23/56
292/292 [==============================] - 80s 276ms/step - loss: 0.6758 - val_loss: 0.7927
Epoch 24/56
292/292 [==============================] - 80s 276ms/step - loss: 0.6758 - val_loss: 0.7927
Epoch 25/56
292/292 [==============================] - 80s 276ms/step - loss: 0.6758 - val_loss: 0.7927
Epoch 26/56
292/292 [==============================] - 80s 275ms/step - loss: 0.6757 - val_loss: 0.7927
Epoch 27/56
292/292 [==============================] - 81s 276ms/step - loss: 0.6757 - val_loss: 0.7927
Epoch 28/56
292/292 [==============================] - 81s 277ms/step - loss: 0.6757 - val_loss: 0.7927
Epoch 29/56
292/292 [==============================] - 81s 276ms/step - loss: 0.6757 - val_loss: 0.7927
Epoch 30/56
292/292 [==============================] - 80s 275ms/step - loss: 0.6757 - val_loss: 0.7927
Epoch 31/56
292/292 [==============================] - 81s 276ms/step - loss: 0.6757 - val_loss: 0.7927
Epoch 32/56
292/292 [==============================] - 81s 277ms/step - loss: 0.6757 - val_loss: 0.7927
Epoch 33/56
292/292 [==============================] - 80s 275ms/step - loss: 0.6757 - val_loss: 0.7927
Epoch 34/56
292/292 [==============================] - 81s 276ms/step - loss: 0.6757 - val_loss: 0.7927
Epoch 35/56
292/292 [==============================] - 81s 276ms/step - loss: 0.6757 - val_loss: 0.7927
Epoch 36/56
292/292 [==============================] - 80s 275ms/step - loss: 0.6757 - val_loss: 0.7927
Epoch 37/56
292/292 [==============================] - 80s 276ms/step - loss: 0.6757 - val_loss: 0.7927
Epoch 38/56
292/292 [==============================] - 81s 276ms/step - loss: 0.6757 - val_loss: 0.7927
Epoch 39/56
292/292 [==============================] - 81s 277ms/step - loss: 0.6757 - val_loss: 0.7927
Epoch 40/56
292/292 [==============================] - 81s 276ms/step - loss: 0.6757 - val_loss: 0.7927
Epoch 41/56
292/292 [==============================] - 81s 276ms/step - loss: 0.6757 - val_loss: 0.7927
Epoch 42/56
292/292 [==============================] - 81s 276ms/step - loss: 0.6757 - val_loss: 0.7927
Epoch 43/56
292/292 [==============================] - 81s 276ms/step - loss: 0.6757 - val_loss: 0.7927
Epoch 44/56
292/292 [==============================] - 81s 276ms/step - loss: 0.6757 - val_loss: 0.7927
Epoch 45/56
292/292 [==============================] - 80s 275ms/step - loss: 0.6757 - val_loss: 0.7927
Epoch 46/56
292/292 [==============================] - 81s 276ms/step - loss: 0.6757 - val_loss: 0.7927
Epoch 47/56
292/292 [==============================] - 81s 276ms/step - loss: 0.6757 - val_loss: 0.7927
Epoch 48/56
292/292 [==============================] - 80s 275ms/step - loss: 0.6757 - val_loss: 0.7927
Epoch 49/56
292/292 [==============================] - 81s 276ms/step - loss: 0.6757 - val_loss: 0.7927
Epoch 50/56
292/292 [==============================] - 81s 277ms/step - loss: 0.6757 - val_loss: 0.7927
Epoch 51/56
292/292 [==============================] - 81s 277ms/step - loss: 0.6757 - val_loss: 0.7927
Epoch 52/56
292/292 [==============================] - 81s 276ms/step - loss: 0.6757 - val_loss: 0.7927
Epoch 53/56
292/292 [==============================] - 81s 276ms/step - loss: 0.6757 - val_loss: 0.7927
Epoch 54/56
292/292 [==============================] - 80s 275ms/step - loss: 0.6757 - val_loss: 0.7927
Epoch 55/56
292/292 [==============================] - 81s 276ms/step - loss: 0.6757 - val_loss: 0.7927
Epoch 56/56
292/292 [==============================] - 81s 276ms/step - loss: 0.6757 - val_loss: 0.7927
Execution time:  4536.104122877121
GRU:
Mean Absolute Error: 0.6930
Root Mean Square Error: 0.9952
Mean Square Error: 0.9904

Train RMSE: 0.995
Train MSE: 0.990
Train MAE: 0.693
###########################

MODEL:  GRU
sequence:  3d
units:  45
dropout1:  0.11814836227952394
dropout2:  0.24325404382648977
optimizer: adam
activationDense: sigmoid
epochs: 43
batchsize: 30
validation_split: 0.2
Model: &#34;sequential_147&#34;
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
gru_126 (GRU)                (None, 432, 45)           6480      
_________________________________________________________________
dropout_294 (Dropout)        (None, 432, 45)           0         
_________________________________________________________________
gru_127 (GRU)                (None, 432, 45)           12420     
_________________________________________________________________
dropout_295 (Dropout)        (None, 432, 45)           0         
_________________________________________________________________
time_distributed_147 (TimeDi (None, 432, 1)            46        
=================================================================
Total params: 18,946
Trainable params: 18,946
Non-trainable params: 0
_________________________________________________________________
Epoch 1/43
95/95 [==============================] - 34s 359ms/step - loss: 0.8607 - val_loss: 0.6577
Epoch 2/43
95/95 [==============================] - 30s 314ms/step - loss: 0.7109 - val_loss: 0.6277
Epoch 3/43
95/95 [==============================] - 30s 316ms/step - loss: 0.7075 - val_loss: 0.6240
Epoch 4/43
95/95 [==============================] - 30s 316ms/step - loss: 0.7066 - val_loss: 0.6223
Epoch 5/43
95/95 [==============================] - 30s 313ms/step - loss: 0.7061 - val_loss: 0.6213
Epoch 6/43
95/95 [==============================] - 30s 317ms/step - loss: 0.7058 - val_loss: 0.6207
Epoch 7/43
95/95 [==============================] - 30s 317ms/step - loss: 0.7056 - val_loss: 0.6203
Epoch 8/43
95/95 [==============================] - 30s 314ms/step - loss: 0.7055 - val_loss: 0.6200
Epoch 9/43
95/95 [==============================] - 30s 315ms/step - loss: 0.7054 - val_loss: 0.6198
Epoch 10/43
95/95 [==============================] - 30s 314ms/step - loss: 0.7053 - val_loss: 0.6196
Epoch 11/43
95/95 [==============================] - 30s 316ms/step - loss: 0.7052 - val_loss: 0.6194
Epoch 12/43
95/95 [==============================] - 30s 315ms/step - loss: 0.7052 - val_loss: 0.6193
Epoch 13/43
95/95 [==============================] - 30s 316ms/step - loss: 0.7051 - val_loss: 0.6192
Epoch 14/43
95/95 [==============================] - 30s 316ms/step - loss: 0.7051 - val_loss: 0.6191
Epoch 15/43
95/95 [==============================] - 30s 316ms/step - loss: 0.7050 - val_loss: 0.6190
Epoch 16/43
95/95 [==============================] - 30s 315ms/step - loss: 0.7050 - val_loss: 0.6189
Epoch 17/43
95/95 [==============================] - 30s 315ms/step - loss: 0.7050 - val_loss: 0.6189
Epoch 18/43
95/95 [==============================] - 30s 315ms/step - loss: 0.7050 - val_loss: 0.6188
Epoch 19/43
95/95 [==============================] - 31s 325ms/step - loss: 0.7049 - val_loss: 0.6187
Epoch 20/43
95/95 [==============================] - 31s 322ms/step - loss: 0.7049 - val_loss: 0.6187
Epoch 21/43
95/95 [==============================] - 31s 323ms/step - loss: 0.7049 - val_loss: 0.6187
Epoch 22/43
95/95 [==============================] - 31s 322ms/step - loss: 0.7049 - val_loss: 0.6186
Epoch 23/43
95/95 [==============================] - 31s 325ms/step - loss: 0.7049 - val_loss: 0.6186
Epoch 24/43
95/95 [==============================] - 31s 323ms/step - loss: 0.7049 - val_loss: 0.6186
Epoch 25/43
95/95 [==============================] - 31s 322ms/step - loss: 0.7049 - val_loss: 0.6185
Epoch 26/43
95/95 [==============================] - 31s 323ms/step - loss: 0.7049 - val_loss: 0.6185
Epoch 27/43
95/95 [==============================] - 31s 324ms/step - loss: 0.7048 - val_loss: 0.6185
Epoch 28/43
95/95 [==============================] - 31s 322ms/step - loss: 0.7048 - val_loss: 0.6185
Epoch 29/43
95/95 [==============================] - 31s 322ms/step - loss: 0.7048 - val_loss: 0.6184
Epoch 30/43
95/95 [==============================] - 31s 323ms/step - loss: 0.7048 - val_loss: 0.6184
Epoch 31/43
95/95 [==============================] - 31s 323ms/step - loss: 0.7048 - val_loss: 0.6184
Epoch 32/43
95/95 [==============================] - 31s 324ms/step - loss: 0.7048 - val_loss: 0.6184
Epoch 33/43
95/95 [==============================] - 31s 323ms/step - loss: 0.7048 - val_loss: 0.6184
Epoch 34/43
95/95 [==============================] - 31s 324ms/step - loss: 0.7048 - val_loss: 0.6184
Epoch 35/43
95/95 [==============================] - 31s 322ms/step - loss: 0.7048 - val_loss: 0.6184
Epoch 36/43
95/95 [==============================] - 31s 322ms/step - loss: 0.7048 - val_loss: 0.6184
Epoch 37/43
95/95 [==============================] - 31s 323ms/step - loss: 0.7048 - val_loss: 0.6183
Epoch 38/43
95/95 [==============================] - 31s 323ms/step - loss: 0.7048 - val_loss: 0.6183
Epoch 39/43
95/95 [==============================] - 31s 322ms/step - loss: 0.7048 - val_loss: 0.6183
Epoch 40/43
95/95 [==============================] - 31s 322ms/step - loss: 0.7048 - val_loss: 0.6183
Epoch 41/43
95/95 [==============================] - 31s 322ms/step - loss: 0.7048 - val_loss: 0.6183
Epoch 42/43
95/95 [==============================] - 31s 323ms/step - loss: 0.7048 - val_loss: 0.6183
Epoch 43/43
95/95 [==============================] - 31s 323ms/step - loss: 0.7048 - val_loss: 0.6183
Execution time:  1328.6985881328583
GRU:
Mean Absolute Error: 0.6930
Root Mean Square Error: 0.9952
Mean Square Error: 0.9904

Train RMSE: 0.995
Train MSE: 0.990
Train MAE: 0.693
###########################

MODEL:  GRU
sequence:  3d
units:  43
dropout1:  0.40519643149940265
dropout2:  0.3312343747027119
optimizer: adadelta
activationDense: tanh
epochs: 56
batchsize: 11
validation_split: 0.1
Model: &#34;sequential_148&#34;
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
gru_128 (GRU)                (None, 432, 43)           5934      
_________________________________________________________________
dropout_296 (Dropout)        (None, 432, 43)           0         
_________________________________________________________________
gru_129 (GRU)                (None, 432, 43)           11352     
_________________________________________________________________
dropout_297 (Dropout)        (None, 432, 43)           0         
_________________________________________________________________
time_distributed_148 (TimeDi (None, 432, 1)            44        
=================================================================
Total params: 17,330
Trainable params: 17,330
Non-trainable params: 0
_________________________________________________________________
Epoch 1/56
292/292 [==============================] - 82s 279ms/step - loss: 0.6758 - val_loss: 0.7913
Epoch 2/56
292/292 [==============================] - 81s 276ms/step - loss: 0.6749 - val_loss: 0.7882
Epoch 3/56
292/292 [==============================] - 81s 277ms/step - loss: 0.6739 - val_loss: 0.7848
Epoch 4/56
292/292 [==============================] - 81s 277ms/step - loss: 0.6730 - val_loss: 0.7811
Epoch 5/56
292/292 [==============================] - 80s 276ms/step - loss: 0.6719 - val_loss: 0.7774
Epoch 6/56
292/292 [==============================] - 81s 277ms/step - loss: 0.6707 - val_loss: 0.7734
Epoch 7/56
292/292 [==============================] - 81s 278ms/step - loss: 0.6695 - val_loss: 0.7694
Epoch 8/56
292/292 [==============================] - 80s 275ms/step - loss: 0.6683 - val_loss: 0.7652
Epoch 9/56
292/292 [==============================] - 81s 276ms/step - loss: 0.6671 - val_loss: 0.7609
Epoch 10/56
292/292 [==============================] - 81s 276ms/step - loss: 0.6659 - val_loss: 0.7566
Epoch 11/56
292/292 [==============================] - 81s 276ms/step - loss: 0.6645 - val_loss: 0.7522
Epoch 12/56
292/292 [==============================] - 81s 276ms/step - loss: 0.6632 - val_loss: 0.7477
Epoch 13/56
292/292 [==============================] - 81s 276ms/step - loss: 0.6620 - val_loss: 0.7433
Epoch 14/56
292/292 [==============================] - 80s 275ms/step - loss: 0.6607 - val_loss: 0.7389
Epoch 15/56
292/292 [==============================] - 81s 276ms/step - loss: 0.6595 - val_loss: 0.7344
Epoch 16/56
292/292 [==============================] - 81s 277ms/step - loss: 0.6583 - val_loss: 0.7301
Epoch 17/56
292/292 [==============================] - 80s 275ms/step - loss: 0.6571 - val_loss: 0.7258
Epoch 18/56
292/292 [==============================] - 81s 276ms/step - loss: 0.6560 - val_loss: 0.7215
Epoch 19/56
292/292 [==============================] - 81s 276ms/step - loss: 0.6549 - val_loss: 0.7172
Epoch 20/56
292/292 [==============================] - 80s 275ms/step - loss: 0.6539 - val_loss: 0.7129
Epoch 21/56
292/292 [==============================] - 81s 277ms/step - loss: 0.6529 - val_loss: 0.7087
Epoch 22/56
292/292 [==============================] - 81s 276ms/step - loss: 0.6519 - val_loss: 0.7044
Epoch 23/56
292/292 [==============================] - 81s 276ms/step - loss: 0.6508 - val_loss: 0.7001
Epoch 24/56
292/292 [==============================] - 81s 276ms/step - loss: 0.6498 - val_loss: 0.6958
Epoch 25/56
292/292 [==============================] - 81s 276ms/step - loss: 0.6488 - val_loss: 0.6914
Epoch 26/56
292/292 [==============================] - 81s 276ms/step - loss: 0.6478 - val_loss: 0.6869
Epoch 27/56
292/292 [==============================] - 80s 275ms/step - loss: 0.6467 - val_loss: 0.6824
Epoch 28/56
292/292 [==============================] - 80s 275ms/step - loss: 0.6457 - val_loss: 0.6779
Epoch 29/56
292/292 [==============================] - 80s 275ms/step - loss: 0.6446 - val_loss: 0.6733
Epoch 30/56
292/292 [==============================] - 80s 274ms/step - loss: 0.6435 - val_loss: 0.6686
Epoch 31/56
292/292 [==============================] - 81s 278ms/step - loss: 0.6424 - val_loss: 0.6639
Epoch 32/56
292/292 [==============================] - 80s 275ms/step - loss: 0.6414 - val_loss: 0.6592
Epoch 33/56
292/292 [==============================] - 80s 275ms/step - loss: 0.6403 - val_loss: 0.6544
Epoch 34/56
292/292 [==============================] - 81s 276ms/step - loss: 0.6393 - val_loss: 0.6496
Epoch 35/56
292/292 [==============================] - 80s 275ms/step - loss: 0.6381 - val_loss: 0.6448
Epoch 36/56
292/292 [==============================] - 80s 275ms/step - loss: 0.6371 - val_loss: 0.6400
Epoch 37/56
292/292 [==============================] - 80s 275ms/step - loss: 0.6360 - val_loss: 0.6351
Epoch 38/56
292/292 [==============================] - 81s 276ms/step - loss: 0.6350 - val_loss: 0.6303
Epoch 39/56
292/292 [==============================] - 81s 276ms/step - loss: 0.6339 - val_loss: 0.6255
Epoch 40/56
292/292 [==============================] - 80s 275ms/step - loss: 0.6330 - val_loss: 0.6207
Epoch 41/56
292/292 [==============================] - 80s 275ms/step - loss: 0.6319 - val_loss: 0.6160
Epoch 42/56
292/292 [==============================] - 80s 275ms/step - loss: 0.6310 - val_loss: 0.6112
Epoch 43/56
292/292 [==============================] - 80s 275ms/step - loss: 0.6300 - val_loss: 0.6065
Epoch 44/56
292/292 [==============================] - 80s 275ms/step - loss: 0.6292 - val_loss: 0.6019
Epoch 45/56
292/292 [==============================] - 80s 275ms/step - loss: 0.6281 - val_loss: 0.5973
Epoch 46/56
292/292 [==============================] - 80s 276ms/step - loss: 0.6273 - val_loss: 0.5927
Epoch 47/56
292/292 [==============================] - 80s 275ms/step - loss: 0.6264 - val_loss: 0.5881
Epoch 48/56
292/292 [==============================] - 80s 275ms/step - loss: 0.6256 - val_loss: 0.5836
Epoch 49/56
292/292 [==============================] - 80s 275ms/step - loss: 0.6248 - val_loss: 0.5791
Epoch 50/56
292/292 [==============================] - 80s 276ms/step - loss: 0.6240 - val_loss: 0.5747
Epoch 51/56
292/292 [==============================] - 80s 275ms/step - loss: 0.6232 - val_loss: 0.5703
Epoch 52/56
292/292 [==============================] - 81s 276ms/step - loss: 0.6224 - val_loss: 0.5659
Epoch 53/56
292/292 [==============================] - 80s 275ms/step - loss: 0.6217 - val_loss: 0.5616
Epoch 54/56
292/292 [==============================] - 80s 275ms/step - loss: 0.6210 - val_loss: 0.5574
Epoch 55/56
292/292 [==============================] - 80s 276ms/step - loss: 0.6202 - val_loss: 0.5532
Epoch 56/56
292/292 [==============================] - 80s 276ms/step - loss: 0.6196 - val_loss: 0.5490
Execution time:  4529.597225427628
GRU:
Mean Absolute Error: 0.5616
Root Mean Square Error: 0.9229
Mean Square Error: 0.8518

Train RMSE: 0.923
Train MSE: 0.852
Train MAE: 0.562
###########################

MODEL:  GRU
sequence:  3d
units:  45
dropout1:  0.11814836227952394
dropout2:  0.24325404382648977
optimizer: adadelta
activationDense: tanh
epochs: 43
batchsize: 30
validation_split: 0.2
Model: &#34;sequential_149&#34;
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
gru_130 (GRU)                (None, 432, 45)           6480      
_________________________________________________________________
dropout_298 (Dropout)        (None, 432, 45)           0         
_________________________________________________________________
gru_131 (GRU)                (None, 432, 45)           12420     
_________________________________________________________________
dropout_299 (Dropout)        (None, 432, 45)           0         
_________________________________________________________________
time_distributed_149 (TimeDi (None, 432, 1)            46        
=================================================================
Total params: 18,946
Trainable params: 18,946
Non-trainable params: 0
_________________________________________________________________
Epoch 1/43
95/95 [==============================] - 30s 318ms/step - loss: 0.7083 - val_loss: 0.6309
Epoch 2/43
95/95 [==============================] - 30s 311ms/step - loss: 0.7082 - val_loss: 0.6303
Epoch 3/43
95/95 [==============================] - 30s 312ms/step - loss: 0.7080 - val_loss: 0.6297
Epoch 4/43
95/95 [==============================] - 30s 311ms/step - loss: 0.7078 - val_loss: 0.6290
Epoch 5/43
95/95 [==============================] - 30s 312ms/step - loss: 0.7076 - val_loss: 0.6283
Epoch 6/43
95/95 [==============================] - 30s 311ms/step - loss: 0.7074 - val_loss: 0.6276
Epoch 7/43
95/95 [==============================] - 30s 313ms/step - loss: 0.7072 - val_loss: 0.6269
Epoch 8/43
95/95 [==============================] - 30s 311ms/step - loss: 0.7070 - val_loss: 0.6261
Epoch 9/43
95/95 [==============================] - 30s 312ms/step - loss: 0.7067 - val_loss: 0.6254
Epoch 10/43
95/95 [==============================] - 30s 312ms/step - loss: 0.7065 - val_loss: 0.6246
Epoch 11/43
95/95 [==============================] - 30s 313ms/step - loss: 0.7063 - val_loss: 0.6239
Epoch 12/43
95/95 [==============================] - 29s 310ms/step - loss: 0.7060 - val_loss: 0.6231
Epoch 13/43
95/95 [==============================] - 30s 311ms/step - loss: 0.7058 - val_loss: 0.6223
Epoch 14/43
95/95 [==============================] - 30s 312ms/step - loss: 0.7055 - val_loss: 0.6215
Epoch 15/43
95/95 [==============================] - 30s 312ms/step - loss: 0.7053 - val_loss: 0.6207
Epoch 16/43
95/95 [==============================] - 30s 312ms/step - loss: 0.7051 - val_loss: 0.6199
Epoch 17/43
95/95 [==============================] - 30s 311ms/step - loss: 0.7048 - val_loss: 0.6191
Epoch 18/43
95/95 [==============================] - 30s 312ms/step - loss: 0.7046 - val_loss: 0.6182
Epoch 19/43
95/95 [==============================] - 30s 312ms/step - loss: 0.7043 - val_loss: 0.6174
Epoch 20/43
95/95 [==============================] - 29s 310ms/step - loss: 0.7040 - val_loss: 0.6166
Epoch 21/43
95/95 [==============================] - 30s 312ms/step - loss: 0.7038 - val_loss: 0.6157
Epoch 22/43
95/95 [==============================] - 30s 312ms/step - loss: 0.7036 - val_loss: 0.6149
Epoch 23/43
95/95 [==============================] - 30s 312ms/step - loss: 0.7033 - val_loss: 0.6140
Epoch 24/43
95/95 [==============================] - 30s 312ms/step - loss: 0.7030 - val_loss: 0.6132
Epoch 25/43
95/95 [==============================] - 30s 311ms/step - loss: 0.7028 - val_loss: 0.6123
Epoch 26/43
95/95 [==============================] - 30s 312ms/step - loss: 0.7025 - val_loss: 0.6115
Epoch 27/43
95/95 [==============================] - 30s 312ms/step - loss: 0.7022 - val_loss: 0.6106
Epoch 28/43
95/95 [==============================] - 30s 311ms/step - loss: 0.7020 - val_loss: 0.6097
Epoch 29/43
95/95 [==============================] - 30s 314ms/step - loss: 0.7017 - val_loss: 0.6089
Epoch 30/43
95/95 [==============================] - 30s 311ms/step - loss: 0.7014 - val_loss: 0.6080
Epoch 31/43
95/95 [==============================] - 30s 313ms/step - loss: 0.7012 - val_loss: 0.6071
Epoch 32/43
95/95 [==============================] - 30s 311ms/step - loss: 0.7009 - val_loss: 0.6062
Epoch 33/43
95/95 [==============================] - 30s 311ms/step - loss: 0.7006 - val_loss: 0.6053
Epoch 34/43
95/95 [==============================] - 30s 312ms/step - loss: 0.7003 - val_loss: 0.6045
Epoch 35/43
95/95 [==============================] - 30s 311ms/step - loss: 0.7001 - val_loss: 0.6036
Epoch 36/43
95/95 [==============================] - 30s 319ms/step - loss: 0.6998 - val_loss: 0.6027
Epoch 37/43
95/95 [==============================] - 30s 319ms/step - loss: 0.6995 - val_loss: 0.6018
Epoch 38/43
95/95 [==============================] - 30s 319ms/step - loss: 0.6992 - val_loss: 0.6009
Epoch 39/43
95/95 [==============================] - 30s 320ms/step - loss: 0.6990 - val_loss: 0.6000
Epoch 40/43
95/95 [==============================] - 30s 319ms/step - loss: 0.6987 - val_loss: 0.5991
Epoch 41/43
95/95 [==============================] - 30s 319ms/step - loss: 0.6984 - val_loss: 0.5982
Epoch 42/43
95/95 [==============================] - 30s 318ms/step - loss: 0.6981 - val_loss: 0.5973
Epoch 43/43
95/95 [==============================] - 30s 320ms/step - loss: 0.6979 - val_loss: 0.5964
Execution time:  1297.3414912223816
GRU:
Mean Absolute Error: 0.6863
Root Mean Square Error: 0.9985
Mean Square Error: 0.9970

Train RMSE: 0.998
Train MSE: 0.997
Train MAE: 0.686
###########################

MODEL:  GRU
sequence:  3d
units:  43
dropout1:  0.40519643149940265
dropout2:  0.3312343747027119
optimizer: adadelta
activationDense: sigmoid
epochs: 56
batchsize: 11
validation_split: 0.1
Model: &#34;sequential_150&#34;
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
gru_132 (GRU)                (None, 432, 43)           5934      
_________________________________________________________________
dropout_300 (Dropout)        (None, 432, 43)           0         
_________________________________________________________________
gru_133 (GRU)                (None, 432, 43)           11352     
_________________________________________________________________
dropout_301 (Dropout)        (None, 432, 43)           0         
_________________________________________________________________
time_distributed_150 (TimeDi (None, 432, 1)            44        
=================================================================
Total params: 17,330
Trainable params: 17,330
Non-trainable params: 0
_________________________________________________________________
Epoch 1/56
292/292 [==============================] - 81s 278ms/step - loss: 0.9064 - val_loss: 1.2858
Epoch 2/56
292/292 [==============================] - 80s 275ms/step - loss: 0.9061 - val_loss: 1.2851
Epoch 3/56
292/292 [==============================] - 81s 277ms/step - loss: 0.9057 - val_loss: 1.2842
Epoch 4/56
292/292 [==============================] - 80s 275ms/step - loss: 0.9053 - val_loss: 1.2833
Epoch 5/56
292/292 [==============================] - 81s 277ms/step - loss: 0.9049 - val_loss: 1.2824
Epoch 6/56
292/292 [==============================] - 81s 278ms/step - loss: 0.9044 - val_loss: 1.2814
Epoch 7/56
292/292 [==============================] - 81s 276ms/step - loss: 0.9039 - val_loss: 1.2803
Epoch 8/56
292/292 [==============================] - 81s 278ms/step - loss: 0.9034 - val_loss: 1.2792
Epoch 9/56
292/292 [==============================] - 81s 277ms/step - loss: 0.9029 - val_loss: 1.2780
Epoch 10/56
292/292 [==============================] - 81s 276ms/step - loss: 0.9023 - val_loss: 1.2768
Epoch 11/56
292/292 [==============================] - 81s 277ms/step - loss: 0.9017 - val_loss: 1.2755
Epoch 12/56
292/292 [==============================] - 81s 277ms/step - loss: 0.9011 - val_loss: 1.2742
Epoch 13/56
292/292 [==============================] - 81s 276ms/step - loss: 0.9005 - val_loss: 1.2728
Epoch 14/56
292/292 [==============================] - 81s 277ms/step - loss: 0.8998 - val_loss: 1.2714
Epoch 15/56
292/292 [==============================] - 81s 277ms/step - loss: 0.8991 - val_loss: 1.2699
Epoch 16/56
292/292 [==============================] - 81s 276ms/step - loss: 0.8984 - val_loss: 1.2684
Epoch 17/56
292/292 [==============================] - 81s 277ms/step - loss: 0.8976 - val_loss: 1.2668
Epoch 18/56
292/292 [==============================] - 81s 277ms/step - loss: 0.8969 - val_loss: 1.2652
Epoch 19/56
292/292 [==============================] - 81s 276ms/step - loss: 0.8961 - val_loss: 1.2635
Epoch 20/56
292/292 [==============================] - 81s 276ms/step - loss: 0.8953 - val_loss: 1.2618
Epoch 21/56
292/292 [==============================] - 81s 277ms/step - loss: 0.8944 - val_loss: 1.2600
Epoch 22/56
292/292 [==============================] - 81s 277ms/step - loss: 0.8936 - val_loss: 1.2581
Epoch 23/56
292/292 [==============================] - 81s 276ms/step - loss: 0.8927 - val_loss: 1.2562
Epoch 24/56
292/292 [==============================] - 81s 277ms/step - loss: 0.8917 - val_loss: 1.2542
Epoch 25/56
292/292 [==============================] - 81s 277ms/step - loss: 0.8907 - val_loss: 1.2521
Epoch 26/56
292/292 [==============================] - 81s 276ms/step - loss: 0.8897 - val_loss: 1.2500
Epoch 27/56
292/292 [==============================] - 81s 277ms/step - loss: 0.8887 - val_loss: 1.2478
Epoch 28/56
292/292 [==============================] - 81s 277ms/step - loss: 0.8876 - val_loss: 1.2455
Epoch 29/56
292/292 [==============================] - 81s 277ms/step - loss: 0.8865 - val_loss: 1.2431
Epoch 30/56
292/292 [==============================] - 81s 277ms/step - loss: 0.8854 - val_loss: 1.2407
Epoch 31/56
292/292 [==============================] - 81s 277ms/step - loss: 0.8842 - val_loss: 1.2382
Epoch 32/56
292/292 [==============================] - 81s 276ms/step - loss: 0.8830 - val_loss: 1.2356
Epoch 33/56
292/292 [==============================] - 81s 277ms/step - loss: 0.8818 - val_loss: 1.2329
Epoch 34/56
292/292 [==============================] - 81s 277ms/step - loss: 0.8804 - val_loss: 1.2302
Epoch 35/56
292/292 [==============================] - 81s 276ms/step - loss: 0.8791 - val_loss: 1.2273
Epoch 36/56
292/292 [==============================] - 81s 277ms/step - loss: 0.8777 - val_loss: 1.2244
Epoch 37/56
292/292 [==============================] - 81s 277ms/step - loss: 0.8764 - val_loss: 1.2214
Epoch 38/56
292/292 [==============================] - 81s 276ms/step - loss: 0.8749 - val_loss: 1.2182
Epoch 39/56
292/292 [==============================] - 81s 277ms/step - loss: 0.8734 - val_loss: 1.2150
Epoch 40/56
292/292 [==============================] - 87s 297ms/step - loss: 0.8718 - val_loss: 1.2116
Epoch 41/56
292/292 [==============================] - 81s 277ms/step - loss: 0.8702 - val_loss: 1.2082
Epoch 42/56
292/292 [==============================] - 81s 277ms/step - loss: 0.8686 - val_loss: 1.2046
Epoch 43/56
292/292 [==============================] - 81s 277ms/step - loss: 0.8668 - val_loss: 1.2009
Epoch 44/56
292/292 [==============================] - 81s 276ms/step - loss: 0.8650 - val_loss: 1.1970
Epoch 45/56
292/292 [==============================] - 81s 278ms/step - loss: 0.8632 - val_loss: 1.1930
Epoch 46/56
292/292 [==============================] - 81s 277ms/step - loss: 0.8613 - val_loss: 1.1889
Epoch 47/56
292/292 [==============================] - 81s 276ms/step - loss: 0.8594 - val_loss: 1.1847
Epoch 48/56
292/292 [==============================] - 81s 277ms/step - loss: 0.8573 - val_loss: 1.1802
Epoch 49/56
292/292 [==============================] - 81s 279ms/step - loss: 0.8552 - val_loss: 1.1757
Epoch 50/56
292/292 [==============================] - 81s 278ms/step - loss: 0.8530 - val_loss: 1.1710
Epoch 51/56
292/292 [==============================] - 82s 280ms/step - loss: 0.8508 - val_loss: 1.1661
Epoch 52/56
292/292 [==============================] - 81s 277ms/step - loss: 0.8485 - val_loss: 1.1611
Epoch 53/56
292/292 [==============================] - 81s 277ms/step - loss: 0.8461 - val_loss: 1.1559
Epoch 54/56
292/292 [==============================] - 81s 276ms/step - loss: 0.8436 - val_loss: 1.1505
Epoch 55/56
292/292 [==============================] - 81s 277ms/step - loss: 0.8410 - val_loss: 1.1450
Epoch 56/56
292/292 [==============================] - 81s 278ms/step - loss: 0.8384 - val_loss: 1.1393
Execution time:  4554.418386936188
GRU:
Mean Absolute Error: 0.8267
Root Mean Square Error: 1.0308
Mean Square Error: 1.0626

Train RMSE: 1.031
Train MSE: 1.063
Train MAE: 0.827
###########################

MODEL:  GRU
sequence:  3d
units:  45
dropout1:  0.11814836227952394
dropout2:  0.24325404382648977
optimizer: adadelta
activationDense: sigmoid
epochs: 43
batchsize: 30
validation_split: 0.2
Model: &#34;sequential_151&#34;
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
gru_134 (GRU)                (None, 432, 45)           6480      
_________________________________________________________________
dropout_302 (Dropout)        (None, 432, 45)           0         
_________________________________________________________________
gru_135 (GRU)                (None, 432, 45)           12420     
_________________________________________________________________
dropout_303 (Dropout)        (None, 432, 45)           0         
_________________________________________________________________
time_distributed_151 (TimeDi (None, 432, 1)            46        
=================================================================
Total params: 18,946
Trainable params: 18,946
Non-trainable params: 0
_________________________________________________________________
Epoch 1/43
95/95 [==============================] - 30s 320ms/step - loss: 0.9077 - val_loss: 1.1012
Epoch 2/43
95/95 [==============================] - 29s 310ms/step - loss: 0.9076 - val_loss: 1.1011
Epoch 3/43
95/95 [==============================] - 30s 316ms/step - loss: 0.9075 - val_loss: 1.1009
Epoch 4/43
95/95 [==============================] - 30s 319ms/step - loss: 0.9075 - val_loss: 1.1008
Epoch 5/43
95/95 [==============================] - 30s 316ms/step - loss: 0.9074 - val_loss: 1.1006
Epoch 6/43
95/95 [==============================] - 30s 317ms/step - loss: 0.9073 - val_loss: 1.1004
Epoch 7/43
95/95 [==============================] - 30s 317ms/step - loss: 0.9072 - val_loss: 1.1003
Epoch 8/43
95/95 [==============================] - 30s 319ms/step - loss: 0.9071 - val_loss: 1.1001
Epoch 9/43
95/95 [==============================] - 30s 316ms/step - loss: 0.9071 - val_loss: 1.0999
Epoch 10/43
95/95 [==============================] - 30s 318ms/step - loss: 0.9070 - val_loss: 1.0997
Epoch 11/43
95/95 [==============================] - 30s 317ms/step - loss: 0.9069 - val_loss: 1.0995
Epoch 12/43
95/95 [==============================] - 30s 317ms/step - loss: 0.9068 - val_loss: 1.0993
Epoch 13/43
95/95 [==============================] - 30s 314ms/step - loss: 0.9067 - val_loss: 1.0991
Epoch 14/43
95/95 [==============================] - 30s 319ms/step - loss: 0.9066 - val_loss: 1.0989
Epoch 15/43
95/95 [==============================] - 30s 318ms/step - loss: 0.9065 - val_loss: 1.0987
Epoch 16/43
95/95 [==============================] - 30s 317ms/step - loss: 0.9064 - val_loss: 1.0985
Epoch 17/43
95/95 [==============================] - 30s 316ms/step - loss: 0.9063 - val_loss: 1.0983
Epoch 18/43
95/95 [==============================] - 30s 317ms/step - loss: 0.9062 - val_loss: 1.0980
Epoch 19/43
95/95 [==============================] - 30s 318ms/step - loss: 0.9061 - val_loss: 1.0978
Epoch 20/43
95/95 [==============================] - 30s 316ms/step - loss: 0.9060 - val_loss: 1.0976
Epoch 21/43
95/95 [==============================] - 30s 316ms/step - loss: 0.9059 - val_loss: 1.0974
Epoch 22/43
95/95 [==============================] - 30s 316ms/step - loss: 0.9058 - val_loss: 1.0971
Epoch 23/43
95/95 [==============================] - 30s 317ms/step - loss: 0.9057 - val_loss: 1.0969
Epoch 24/43
95/95 [==============================] - 30s 316ms/step - loss: 0.9055 - val_loss: 1.0967
Epoch 25/43
95/95 [==============================] - 30s 316ms/step - loss: 0.9054 - val_loss: 1.0964
Epoch 26/43
95/95 [==============================] - 30s 316ms/step - loss: 0.9053 - val_loss: 1.0962
Epoch 27/43
95/95 [==============================] - 30s 318ms/step - loss: 0.9052 - val_loss: 1.0959
Epoch 28/43
95/95 [==============================] - 30s 317ms/step - loss: 0.9051 - val_loss: 1.0957
Epoch 29/43
95/95 [==============================] - 30s 316ms/step - loss: 0.9050 - val_loss: 1.0954
Epoch 30/43
95/95 [==============================] - 30s 316ms/step - loss: 0.9049 - val_loss: 1.0952
Epoch 31/43
95/95 [==============================] - 30s 319ms/step - loss: 0.9047 - val_loss: 1.0949
Epoch 32/43
95/95 [==============================] - 30s 316ms/step - loss: 0.9046 - val_loss: 1.0947
Epoch 33/43
95/95 [==============================] - 30s 315ms/step - loss: 0.9045 - val_loss: 1.0944
Epoch 34/43
95/95 [==============================] - 30s 316ms/step - loss: 0.9044 - val_loss: 1.0942
Epoch 35/43
95/95 [==============================] - 30s 319ms/step - loss: 0.9043 - val_loss: 1.0939
Epoch 36/43
95/95 [==============================] - 30s 316ms/step - loss: 0.9041 - val_loss: 1.0937
Epoch 37/43
95/95 [==============================] - 30s 316ms/step - loss: 0.9040 - val_loss: 1.0934
Epoch 38/43
95/95 [==============================] - 30s 316ms/step - loss: 0.9039 - val_loss: 1.0931
Epoch 39/43
95/95 [==============================] - 30s 319ms/step - loss: 0.9038 - val_loss: 1.0929
Epoch 40/43
95/95 [==============================] - 30s 316ms/step - loss: 0.9036 - val_loss: 1.0926
Epoch 41/43
95/95 [==============================] - 30s 316ms/step - loss: 0.9035 - val_loss: 1.0923
Epoch 42/43
95/95 [==============================] - 30s 316ms/step - loss: 0.9034 - val_loss: 1.0921
Epoch 43/43
95/95 [==============================] - 30s 317ms/step - loss: 0.9032 - val_loss: 1.0918
Execution time:  1312.5420167446136
GRU:
Mean Absolute Error: 0.9195
Root Mean Square Error: 1.1123
Mean Square Error: 1.2373

Train RMSE: 1.112
Train MSE: 1.237
Train MAE: 0.919
###########################

MODEL:  GRU
sequence:  3d
units:  43
dropout1:  0.40519643149940265
dropout2:  0.3312343747027119
optimizer: adamax
activationDense: tanh
epochs: 56
batchsize: 11
validation_split: 0.1
Model: &#34;sequential_152&#34;
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
gru_136 (GRU)                (None, 432, 43)           5934      
_________________________________________________________________
dropout_304 (Dropout)        (None, 432, 43)           0         
_________________________________________________________________
gru_137 (GRU)                (None, 432, 43)           11352     
_________________________________________________________________
dropout_305 (Dropout)        (None, 432, 43)           0         
_________________________________________________________________
time_distributed_152 (TimeDi (None, 432, 1)            44        
=================================================================
Total params: 17,330
Trainable params: 17,330
Non-trainable params: 0
_________________________________________________________________
Epoch 1/56
292/292 [==============================] - 81s 277ms/step - loss: 0.6405 - val_loss: 0.4631
Epoch 2/56
292/292 [==============================] - 80s 273ms/step - loss: 0.6254 - val_loss: 0.4107
Epoch 3/56
292/292 [==============================] - 80s 273ms/step - loss: 0.6226 - val_loss: 0.3797
Epoch 4/56
292/292 [==============================] - 80s 272ms/step - loss: 0.6210 - val_loss: 0.3705
Epoch 5/56
292/292 [==============================] - 81s 277ms/step - loss: 0.6199 - val_loss: 0.3712
Epoch 6/56
292/292 [==============================] - 81s 278ms/step - loss: 0.6186 - val_loss: 0.3735
Epoch 7/56
292/292 [==============================] - 81s 277ms/step - loss: 0.6174 - val_loss: 0.3753
Epoch 8/56
292/292 [==============================] - 81s 278ms/step - loss: 0.6162 - val_loss: 0.3762
Epoch 9/56
292/292 [==============================] - 81s 277ms/step - loss: 0.6149 - val_loss: 0.3779
Epoch 10/56
292/292 [==============================] - 81s 278ms/step - loss: 0.6134 - val_loss: 0.3762
Epoch 11/56
292/292 [==============================] - 83s 284ms/step - loss: 0.6116 - val_loss: 0.3867
Epoch 12/56
292/292 [==============================] - 81s 279ms/step - loss: 0.6076 - val_loss: 0.4176
Epoch 13/56
292/292 [==============================] - 81s 278ms/step - loss: 0.6000 - val_loss: 0.4562
Epoch 14/56
292/292 [==============================] - 81s 279ms/step - loss: 0.5967 - val_loss: 0.4650
Epoch 15/56
292/292 [==============================] - 82s 279ms/step - loss: 0.5954 - val_loss: 0.4663
Epoch 16/56
292/292 [==============================] - 81s 279ms/step - loss: 0.5948 - val_loss: 0.4679
Epoch 17/56
292/292 [==============================] - 81s 278ms/step - loss: 0.5942 - val_loss: 0.4688
Epoch 18/56
292/292 [==============================] - 81s 278ms/step - loss: 0.5935 - val_loss: 0.4695
Epoch 19/56
292/292 [==============================] - 82s 281ms/step - loss: 0.5929 - val_loss: 0.4696
Epoch 20/56
292/292 [==============================] - 81s 279ms/step - loss: 0.5929 - val_loss: 0.4722
Epoch 21/56
292/292 [==============================] - 81s 279ms/step - loss: 0.5913 - val_loss: 0.4709
Epoch 22/56
292/292 [==============================] - 82s 279ms/step - loss: 0.5909 - val_loss: 0.4694
Epoch 23/56
292/292 [==============================] - 81s 279ms/step - loss: 0.5901 - val_loss: 0.4683
Epoch 24/56
292/292 [==============================] - 82s 279ms/step - loss: 0.5902 - val_loss: 0.4639
Epoch 25/56
292/292 [==============================] - 82s 281ms/step - loss: 0.5894 - val_loss: 0.4643
Epoch 26/56
292/292 [==============================] - 82s 279ms/step - loss: 0.5891 - val_loss: 0.4655
Epoch 27/56
292/292 [==============================] - 82s 279ms/step - loss: 0.5895 - val_loss: 0.4653
Epoch 28/56
292/292 [==============================] - 82s 280ms/step - loss: 0.5889 - val_loss: 0.4645
Epoch 29/56
292/292 [==============================] - 81s 278ms/step - loss: 0.5892 - val_loss: 0.4633
Epoch 30/56
292/292 [==============================] - 82s 279ms/step - loss: 0.5887 - val_loss: 0.4621
Epoch 31/56
292/292 [==============================] - 82s 279ms/step - loss: 0.5884 - val_loss: 0.4635
Epoch 32/56
292/292 [==============================] - 81s 278ms/step - loss: 0.5884 - val_loss: 0.4621
Epoch 33/56
292/292 [==============================] - 82s 280ms/step - loss: 0.5885 - val_loss: 0.4604
Epoch 34/56
292/292 [==============================] - 82s 280ms/step - loss: 0.5879 - val_loss: 0.4606
Epoch 35/56
292/292 [==============================] - 82s 279ms/step - loss: 0.5884 - val_loss: 0.4578
Epoch 36/56
292/292 [==============================] - 82s 280ms/step - loss: 0.5880 - val_loss: 0.4578
Epoch 37/56
292/292 [==============================] - 82s 280ms/step - loss: 0.5878 - val_loss: 0.4586
Epoch 38/56
292/292 [==============================] - 82s 279ms/step - loss: 0.5880 - val_loss: 0.4577
Epoch 39/56
292/292 [==============================] - 81s 279ms/step - loss: 0.5876 - val_loss: 0.4566
Epoch 40/56
292/292 [==============================] - 82s 279ms/step - loss: 0.5881 - val_loss: 0.4547
Epoch 41/56
292/292 [==============================] - 81s 278ms/step - loss: 0.5874 - val_loss: 0.4540
Epoch 42/56
292/292 [==============================] - 81s 277ms/step - loss: 0.5873 - val_loss: 0.4551
Epoch 43/56
292/292 [==============================] - 81s 278ms/step - loss: 0.5877 - val_loss: 0.4517
Epoch 44/56
292/292 [==============================] - 81s 278ms/step - loss: 0.5874 - val_loss: 0.4535
Epoch 45/56
292/292 [==============================] - 81s 277ms/step - loss: 0.5870 - val_loss: 0.4524
Epoch 46/56
292/292 [==============================] - 81s 278ms/step - loss: 0.5875 - val_loss: 0.4512
Epoch 47/56
292/292 [==============================] - 81s 278ms/step - loss: 0.5869 - val_loss: 0.4501
Epoch 48/56
292/292 [==============================] - 81s 277ms/step - loss: 0.5869 - val_loss: 0.4539
Epoch 49/56
292/292 [==============================] - 81s 277ms/step - loss: 0.5873 - val_loss: 0.4513
Epoch 50/56
292/292 [==============================] - 81s 278ms/step - loss: 0.5872 - val_loss: 0.4513
Epoch 51/56
292/292 [==============================] - 81s 277ms/step - loss: 0.5872 - val_loss: 0.4488
Epoch 52/56
292/292 [==============================] - 81s 277ms/step - loss: 0.5872 - val_loss: 0.4486
Epoch 53/56
292/292 [==============================] - 81s 278ms/step - loss: 0.5870 - val_loss: 0.4476
Epoch 54/56
292/292 [==============================] - 82s 280ms/step - loss: 0.5870 - val_loss: 0.4482
Epoch 55/56
292/292 [==============================] - 81s 278ms/step - loss: 0.5870 - val_loss: 0.4471
Epoch 56/56
292/292 [==============================] - 81s 278ms/step - loss: 0.5865 - val_loss: 0.4496
Execution time:  4571.128044366837
GRU:
Mean Absolute Error: 0.5462
Root Mean Square Error: 0.9930
Mean Square Error: 0.9860

Train RMSE: 0.993
Train MSE: 0.986
Train MAE: 0.546
###########################

MODEL:  GRU
sequence:  3d
units:  45
dropout1:  0.11814836227952394
dropout2:  0.24325404382648977
optimizer: adamax
activationDense: tanh
epochs: 43
batchsize: 30
validation_split: 0.2
Model: &#34;sequential_153&#34;
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
gru_138 (GRU)                (None, 432, 45)           6480      
_________________________________________________________________
dropout_306 (Dropout)        (None, 432, 45)           0         
_________________________________________________________________
gru_139 (GRU)                (None, 432, 45)           12420     
_________________________________________________________________
dropout_307 (Dropout)        (None, 432, 45)           0         
_________________________________________________________________
time_distributed_153 (TimeDi (None, 432, 1)            46        
=================================================================
Total params: 18,946
Trainable params: 18,946
Non-trainable params: 0
_________________________________________________________________
Epoch 1/43
95/95 [==============================] - 31s 323ms/step - loss: 0.6974 - val_loss: 0.5047
Epoch 2/43
95/95 [==============================] - 30s 315ms/step - loss: 0.6664 - val_loss: 0.3687
Epoch 3/43
95/95 [==============================] - 30s 316ms/step - loss: 0.6638 - val_loss: 0.3461
Epoch 4/43
95/95 [==============================] - 30s 316ms/step - loss: 0.6647 - val_loss: 0.3487
Epoch 5/43
95/95 [==============================] - 30s 313ms/step - loss: 0.6624 - val_loss: 0.3479
Epoch 6/43
95/95 [==============================] - 30s 313ms/step - loss: 0.6612 - val_loss: 0.3478
Epoch 7/43
95/95 [==============================] - 30s 315ms/step - loss: 0.6602 - val_loss: 0.3475
Epoch 8/43
95/95 [==============================] - 30s 313ms/step - loss: 0.6590 - val_loss: 0.3474
Epoch 9/43
95/95 [==============================] - 30s 314ms/step - loss: 0.6584 - val_loss: 0.3471
Epoch 10/43
95/95 [==============================] - 30s 313ms/step - loss: 0.6574 - val_loss: 0.3467
Epoch 11/43
95/95 [==============================] - 30s 316ms/step - loss: 0.6568 - val_loss: 0.3465
Epoch 12/43
95/95 [==============================] - 30s 312ms/step - loss: 0.6560 - val_loss: 0.3461
Epoch 13/43
95/95 [==============================] - 30s 313ms/step - loss: 0.6554 - val_loss: 0.3457
Epoch 14/43
95/95 [==============================] - 30s 313ms/step - loss: 0.6548 - val_loss: 0.3454
Epoch 15/43
95/95 [==============================] - 30s 315ms/step - loss: 0.6542 - val_loss: 0.3453
Epoch 16/43
95/95 [==============================] - 30s 314ms/step - loss: 0.6536 - val_loss: 0.3450
Epoch 17/43
95/95 [==============================] - 30s 313ms/step - loss: 0.6530 - val_loss: 0.3447
Epoch 18/43
95/95 [==============================] - 30s 313ms/step - loss: 0.6523 - val_loss: 0.3443
Epoch 19/43
95/95 [==============================] - 30s 319ms/step - loss: 0.6515 - val_loss: 0.3443
Epoch 20/43
95/95 [==============================] - 31s 324ms/step - loss: 0.6505 - val_loss: 0.3442
Epoch 21/43
95/95 [==============================] - 30s 320ms/step - loss: 0.6497 - val_loss: 0.3459
Epoch 22/43
95/95 [==============================] - 30s 320ms/step - loss: 0.6483 - val_loss: 0.3464
Epoch 23/43
95/95 [==============================] - 31s 323ms/step - loss: 0.6469 - val_loss: 0.3505
Epoch 24/43
95/95 [==============================] - 30s 321ms/step - loss: 0.6416 - val_loss: 0.3300
Epoch 25/43
95/95 [==============================] - 30s 321ms/step - loss: 0.6405 - val_loss: 0.3564
Epoch 26/43
95/95 [==============================] - 31s 322ms/step - loss: 0.6347 - val_loss: 0.3706
Epoch 27/43
95/95 [==============================] - 30s 321ms/step - loss: 0.6306 - val_loss: 0.3751
Epoch 28/43
95/95 [==============================] - 30s 320ms/step - loss: 0.6307 - val_loss: 0.3759
Epoch 29/43
95/95 [==============================] - 30s 320ms/step - loss: 0.6286 - val_loss: 0.3835
Epoch 30/43
95/95 [==============================] - 31s 322ms/step - loss: 0.6267 - val_loss: 0.3814
Epoch 31/43
95/95 [==============================] - 30s 321ms/step - loss: 0.6264 - val_loss: 0.3833
Epoch 32/43
95/95 [==============================] - 30s 321ms/step - loss: 0.6265 - val_loss: 0.3819
Epoch 33/43
95/95 [==============================] - 31s 321ms/step - loss: 0.6256 - val_loss: 0.3843
Epoch 34/43
95/95 [==============================] - 31s 326ms/step - loss: 0.6255 - val_loss: 0.3825
Epoch 35/43
95/95 [==============================] - 30s 320ms/step - loss: 0.6250 - val_loss: 0.3851
Epoch 36/43
95/95 [==============================] - 30s 320ms/step - loss: 0.6240 - val_loss: 0.3825
Epoch 37/43
95/95 [==============================] - 30s 320ms/step - loss: 0.6243 - val_loss: 0.3866
Epoch 38/43
95/95 [==============================] - 31s 323ms/step - loss: 0.6235 - val_loss: 0.3830
Epoch 39/43
95/95 [==============================] - 30s 320ms/step - loss: 0.6237 - val_loss: 0.3855
Epoch 40/43
95/95 [==============================] - 30s 320ms/step - loss: 0.6238 - val_loss: 0.3834
Epoch 41/43
95/95 [==============================] - 30s 320ms/step - loss: 0.6233 - val_loss: 0.3839
Epoch 42/43
95/95 [==============================] - 31s 322ms/step - loss: 0.6234 - val_loss: 0.3823
Epoch 43/43
95/95 [==============================] - 30s 321ms/step - loss: 0.6231 - val_loss: 0.3896
Execution time:  1322.5656213760376
GRU:
Mean Absolute Error: 0.5395
Root Mean Square Error: 0.9651
Mean Square Error: 0.9315

Train RMSE: 0.965
Train MSE: 0.931
Train MAE: 0.540
###########################

MODEL:  GRU
sequence:  3d
units:  43
dropout1:  0.40519643149940265
dropout2:  0.3312343747027119
optimizer: adamax
activationDense: sigmoid
epochs: 56
batchsize: 11
validation_split: 0.1
Model: &#34;sequential_154&#34;
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
gru_140 (GRU)                (None, 432, 43)           5934      
_________________________________________________________________
dropout_308 (Dropout)        (None, 432, 43)           0         
_________________________________________________________________
gru_141 (GRU)                (None, 432, 43)           11352     
_________________________________________________________________
dropout_309 (Dropout)        (None, 432, 43)           0         
_________________________________________________________________
time_distributed_154 (TimeDi (None, 432, 1)            44        
=================================================================
Total params: 17,330
Trainable params: 17,330
Non-trainable params: 0
_________________________________________________________________
Epoch 1/56
292/292 [==============================] - 82s 280ms/step - loss: 0.7911 - val_loss: 0.8092
Epoch 2/56
292/292 [==============================] - 80s 275ms/step - loss: 0.6802 - val_loss: 0.7992
Epoch 3/56
292/292 [==============================] - 81s 276ms/step - loss: 0.6780 - val_loss: 0.7965
Epoch 4/56
292/292 [==============================] - 81s 276ms/step - loss: 0.6772 - val_loss: 0.7952
Epoch 5/56
292/292 [==============================] - 80s 275ms/step - loss: 0.6767 - val_loss: 0.7945
Epoch 6/56
292/292 [==============================] - 81s 276ms/step - loss: 0.6764 - val_loss: 0.7940
Epoch 7/56
292/292 [==============================] - 81s 276ms/step - loss: 0.6763 - val_loss: 0.7937
Epoch 8/56
292/292 [==============================] - 81s 277ms/step - loss: 0.6761 - val_loss: 0.7934
Epoch 9/56
292/292 [==============================] - 81s 276ms/step - loss: 0.6760 - val_loss: 0.7932
Epoch 10/56
292/292 [==============================] - 81s 276ms/step - loss: 0.6760 - val_loss: 0.7931
Epoch 11/56
292/292 [==============================] - 81s 276ms/step - loss: 0.6759 - val_loss: 0.7930
Epoch 12/56
292/292 [==============================] - 81s 277ms/step - loss: 0.6759 - val_loss: 0.7929
Epoch 13/56
292/292 [==============================] - 81s 277ms/step - loss: 0.6758 - val_loss: 0.7928
Epoch 14/56
292/292 [==============================] - 81s 276ms/step - loss: 0.6758 - val_loss: 0.7928
Epoch 15/56
292/292 [==============================] - 81s 277ms/step - loss: 0.6758 - val_loss: 0.7928
Epoch 16/56
292/292 [==============================] - 81s 277ms/step - loss: 0.6758 - val_loss: 0.7928
Epoch 17/56
292/292 [==============================] - 81s 277ms/step - loss: 0.6758 - val_loss: 0.7927
Epoch 18/56
292/292 [==============================] - 81s 278ms/step - loss: 0.6758 - val_loss: 0.7927
Epoch 19/56
292/292 [==============================] - 81s 279ms/step - loss: 0.6758 - val_loss: 0.7927
Epoch 20/56
292/292 [==============================] - 81s 278ms/step - loss: 0.6758 - val_loss: 0.7927
Epoch 21/56
292/292 [==============================] - 81s 277ms/step - loss: 0.6758 - val_loss: 0.7927
Epoch 22/56
292/292 [==============================] - 81s 278ms/step - loss: 0.6757 - val_loss: 0.7927
Epoch 23/56
292/292 [==============================] - 81s 278ms/step - loss: 0.6757 - val_loss: 0.7927
Epoch 24/56
292/292 [==============================] - 81s 277ms/step - loss: 0.6757 - val_loss: 0.7927
Epoch 25/56
292/292 [==============================] - 81s 278ms/step - loss: 0.6757 - val_loss: 0.7927
Epoch 26/56
292/292 [==============================] - 81s 278ms/step - loss: 0.6757 - val_loss: 0.7927
Epoch 27/56
292/292 [==============================] - 81s 277ms/step - loss: 0.6757 - val_loss: 0.7927
Epoch 28/56
292/292 [==============================] - 81s 278ms/step - loss: 0.6757 - val_loss: 0.7927
Epoch 29/56
292/292 [==============================] - 81s 278ms/step - loss: 0.6757 - val_loss: 0.7927
Epoch 30/56
292/292 [==============================] - 81s 279ms/step - loss: 0.6757 - val_loss: 0.7927
Epoch 31/56
292/292 [==============================] - 81s 278ms/step - loss: 0.6757 - val_loss: 0.7927
Epoch 32/56
292/292 [==============================] - 81s 278ms/step - loss: 0.6757 - val_loss: 0.7927
Epoch 33/56
292/292 [==============================] - 81s 277ms/step - loss: 0.6757 - val_loss: 0.7927
Epoch 34/56
292/292 [==============================] - 81s 278ms/step - loss: 0.6757 - val_loss: 0.7927
Epoch 35/56
292/292 [==============================] - 81s 278ms/step - loss: 0.6757 - val_loss: 0.7927
Epoch 36/56
292/292 [==============================] - 82s 280ms/step - loss: 0.6757 - val_loss: 0.7927
Epoch 37/56
292/292 [==============================] - 81s 278ms/step - loss: 0.6757 - val_loss: 0.7927
Epoch 38/56
292/292 [==============================] - 81s 278ms/step - loss: 0.6757 - val_loss: 0.7927
Epoch 39/56
292/292 [==============================] - 81s 277ms/step - loss: 0.6757 - val_loss: 0.7927
Epoch 40/56
292/292 [==============================] - 81s 278ms/step - loss: 0.6757 - val_loss: 0.7927
Epoch 41/56
292/292 [==============================] - 81s 279ms/step - loss: 0.6757 - val_loss: 0.7927
Epoch 42/56
292/292 [==============================] - 81s 277ms/step - loss: 0.6757 - val_loss: 0.7927
Epoch 43/56
292/292 [==============================] - 81s 278ms/step - loss: 0.6757 - val_loss: 0.7927
Epoch 44/56
292/292 [==============================] - 81s 278ms/step - loss: 0.6757 - val_loss: 0.7927
Epoch 45/56
292/292 [==============================] - 81s 277ms/step - loss: 0.6757 - val_loss: 0.7927
Epoch 46/56
292/292 [==============================] - 81s 278ms/step - loss: 0.6757 - val_loss: 0.7927
Epoch 47/56
292/292 [==============================] - 81s 278ms/step - loss: 0.6757 - val_loss: 0.7927
Epoch 48/56
292/292 [==============================] - 81s 278ms/step - loss: 0.6757 - val_loss: 0.7927
Epoch 49/56
292/292 [==============================] - 81s 278ms/step - loss: 0.6757 - val_loss: 0.7927
Epoch 50/56
292/292 [==============================] - 81s 278ms/step - loss: 0.6757 - val_loss: 0.7927
Epoch 51/56
292/292 [==============================] - 81s 278ms/step - loss: 0.6757 - val_loss: 0.7927
Epoch 52/56
292/292 [==============================] - 81s 278ms/step - loss: 0.6757 - val_loss: 0.7927
Epoch 53/56
292/292 [==============================] - 81s 278ms/step - loss: 0.6757 - val_loss: 0.7927
Epoch 54/56
292/292 [==============================] - 81s 278ms/step - loss: 0.6757 - val_loss: 0.7927
Epoch 55/56
292/292 [==============================] - 81s 277ms/step - loss: 0.6757 - val_loss: 0.7927
Epoch 56/56
292/292 [==============================] - 81s 278ms/step - loss: 0.6757 - val_loss: 0.7927
Execution time:  4557.967628240585
GRU:
Mean Absolute Error: 0.6930
Root Mean Square Error: 0.9952
Mean Square Error: 0.9904

Train RMSE: 0.995
Train MSE: 0.990
Train MAE: 0.693
###########################

MODEL:  GRU
sequence:  3d
units:  45
dropout1:  0.11814836227952394
dropout2:  0.24325404382648977
optimizer: adamax
activationDense: sigmoid
epochs: 43
batchsize: 30
validation_split: 0.2
Model: &#34;sequential_155&#34;
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
gru_142 (GRU)                (None, 432, 45)           6480      
_________________________________________________________________
dropout_310 (Dropout)        (None, 432, 45)           0         
_________________________________________________________________
gru_143 (GRU)                (None, 432, 45)           12420     
_________________________________________________________________
dropout_311 (Dropout)        (None, 432, 45)           0         
_________________________________________________________________
time_distributed_155 (TimeDi (None, 432, 1)            46        
=================================================================
Total params: 18,946
Trainable params: 18,946
Non-trainable params: 0
_________________________________________________________________
Epoch 1/43
95/95 [==============================] - 31s 323ms/step - loss: 0.8869 - val_loss: 0.9335
Epoch 2/43
95/95 [==============================] - 30s 315ms/step - loss: 0.7546 - val_loss: 0.6507
Epoch 3/43
95/95 [==============================] - 30s 312ms/step - loss: 0.7128 - val_loss: 0.6345
Epoch 4/43
95/95 [==============================] - 30s 311ms/step - loss: 0.7098 - val_loss: 0.6298
Epoch 5/43
95/95 [==============================] - 30s 312ms/step - loss: 0.7085 - val_loss: 0.6272
Epoch 6/43
95/95 [==============================] - 30s 315ms/step - loss: 0.7077 - val_loss: 0.6255
Epoch 7/43
95/95 [==============================] - 30s 312ms/step - loss: 0.7072 - val_loss: 0.6242
Epoch 8/43
95/95 [==============================] - 30s 311ms/step - loss: 0.7068 - val_loss: 0.6233
Epoch 9/43
95/95 [==============================] - 30s 312ms/step - loss: 0.7065 - val_loss: 0.6226
Epoch 10/43
95/95 [==============================] - 30s 313ms/step - loss: 0.7063 - val_loss: 0.6220
Epoch 11/43
95/95 [==============================] - 30s 312ms/step - loss: 0.7061 - val_loss: 0.6216
Epoch 12/43
95/95 [==============================] - 30s 312ms/step - loss: 0.7059 - val_loss: 0.6212
Epoch 13/43
95/95 [==============================] - 30s 314ms/step - loss: 0.7058 - val_loss: 0.6208
Epoch 14/43
95/95 [==============================] - 30s 313ms/step - loss: 0.7057 - val_loss: 0.6206
Epoch 15/43
95/95 [==============================] - 30s 314ms/step - loss: 0.7056 - val_loss: 0.6203
Epoch 16/43
95/95 [==============================] - 30s 314ms/step - loss: 0.7055 - val_loss: 0.6201
Epoch 17/43
95/95 [==============================] - 30s 315ms/step - loss: 0.7054 - val_loss: 0.6199
Epoch 18/43
95/95 [==============================] - 30s 316ms/step - loss: 0.7054 - val_loss: 0.6198
Epoch 19/43
95/95 [==============================] - 30s 317ms/step - loss: 0.7053 - val_loss: 0.6196
Epoch 20/43
95/95 [==============================] - 30s 315ms/step - loss: 0.7053 - val_loss: 0.6195
Epoch 21/43
95/95 [==============================] - 30s 315ms/step - loss: 0.7052 - val_loss: 0.6194
Epoch 22/43
95/95 [==============================] - 30s 317ms/step - loss: 0.7052 - val_loss: 0.6193
Epoch 23/43
95/95 [==============================] - 30s 314ms/step - loss: 0.7051 - val_loss: 0.6192
Epoch 24/43
95/95 [==============================] - 30s 315ms/step - loss: 0.7051 - val_loss: 0.6191
Epoch 25/43
95/95 [==============================] - 30s 315ms/step - loss: 0.7051 - val_loss: 0.6190
Epoch 26/43
95/95 [==============================] - 30s 317ms/step - loss: 0.7050 - val_loss: 0.6189
Epoch 27/43
95/95 [==============================] - 31s 330ms/step - loss: 0.7050 - val_loss: 0.6189
Epoch 28/43
95/95 [==============================] - 30s 317ms/step - loss: 0.7050 - val_loss: 0.6188
Epoch 29/43
95/95 [==============================] - 30s 316ms/step - loss: 0.7050 - val_loss: 0.6188
Epoch 30/43
95/95 [==============================] - 30s 317ms/step - loss: 0.7049 - val_loss: 0.6187
Epoch 31/43
95/95 [==============================] - 30s 316ms/step - loss: 0.7049 - val_loss: 0.6187
Epoch 32/43
95/95 [==============================] - 30s 318ms/step - loss: 0.7049 - val_loss: 0.6186
Epoch 33/43
95/95 [==============================] - 30s 315ms/step - loss: 0.7049 - val_loss: 0.6186
Epoch 34/43
95/95 [==============================] - 30s 317ms/step - loss: 0.7049 - val_loss: 0.6185
Epoch 35/43
95/95 [==============================] - 30s 317ms/step - loss: 0.7049 - val_loss: 0.6185
Epoch 36/43
95/95 [==============================] - 30s 316ms/step - loss: 0.7048 - val_loss: 0.6185
Epoch 37/43
95/95 [==============================] - 30s 317ms/step - loss: 0.7048 - val_loss: 0.6185
Epoch 38/43
95/95 [==============================] - 30s 319ms/step - loss: 0.7048 - val_loss: 0.6184
Epoch 39/43
95/95 [==============================] - 30s 316ms/step - loss: 0.7048 - val_loss: 0.6184
Epoch 40/43
95/95 [==============================] - 30s 316ms/step - loss: 0.7048 - val_loss: 0.6184
Epoch 41/43
95/95 [==============================] - 30s 316ms/step - loss: 0.7048 - val_loss: 0.6184
Epoch 42/43
95/95 [==============================] - 30s 318ms/step - loss: 0.7048 - val_loss: 0.6184
Epoch 43/43
95/95 [==============================] - 31s 322ms/step - loss: 0.7048 - val_loss: 0.6184
Execution time:  1307.531947851181
GRU:
Mean Absolute Error: 0.6930
Root Mean Square Error: 0.9952
Mean Square Error: 0.9904

Train RMSE: 0.995
Train MSE: 0.990
Train MAE: 0.693
###########################

MODEL:  GRU
sequence:  7d
units:  43
dropout1:  0.40519643149940265
dropout2:  0.3312343747027119
optimizer: adam
activationDense: tanh
epochs: 56
batchsize: 11
validation_split: 0.1
Model: &#34;sequential_156&#34;
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
gru_144 (GRU)                (None, 1008, 43)          5934      
_________________________________________________________________
dropout_312 (Dropout)        (None, 1008, 43)          0         
_________________________________________________________________
gru_145 (GRU)                (None, 1008, 43)          11352     
_________________________________________________________________
dropout_313 (Dropout)        (None, 1008, 43)          0         
_________________________________________________________________
time_distributed_156 (TimeDi (None, 1008, 1)           44        
=================================================================
Total params: 17,330
Trainable params: 17,330
Non-trainable params: 0
_________________________________________________________________
Epoch 1/56
244/244 [==============================] - 106s 436ms/step - loss: 0.6112 - val_loss: 0.4391
Epoch 2/56
244/244 [==============================] - 106s 435ms/step - loss: 0.5732 - val_loss: 0.4797
Epoch 3/56
244/244 [==============================] - 106s 433ms/step - loss: 0.5706 - val_loss: 0.4595
Epoch 4/56
244/244 [==============================] - 106s 433ms/step - loss: 0.5684 - val_loss: 0.4519
Epoch 5/56
244/244 [==============================] - 106s 434ms/step - loss: 0.5654 - val_loss: 0.4433
Epoch 6/56
244/244 [==============================] - 106s 433ms/step - loss: 0.5625 - val_loss: 0.4238
Epoch 7/56
244/244 [==============================] - 106s 436ms/step - loss: 0.5605 - val_loss: 0.4231
Epoch 8/56
244/244 [==============================] - 106s 433ms/step - loss: 0.5592 - val_loss: 0.4130
Epoch 9/56
244/244 [==============================] - 106s 435ms/step - loss: 0.5582 - val_loss: 0.4205
Epoch 10/56
244/244 [==============================] - 106s 435ms/step - loss: 0.5573 - val_loss: 0.4218
Epoch 11/56
244/244 [==============================] - 106s 433ms/step - loss: 0.5559 - val_loss: 0.4208
Epoch 12/56
244/244 [==============================] - 107s 438ms/step - loss: 0.5541 - val_loss: 0.4335
Epoch 13/56
244/244 [==============================] - 106s 436ms/step - loss: 0.5519 - val_loss: 0.4312
Epoch 14/56
244/244 [==============================] - 106s 436ms/step - loss: 0.5483 - val_loss: 0.4447
Epoch 15/56
244/244 [==============================] - 106s 436ms/step - loss: 0.5470 - val_loss: 0.4795
Epoch 16/56
244/244 [==============================] - 107s 437ms/step - loss: 0.5423 - val_loss: 0.4833
Epoch 17/56
244/244 [==============================] - 106s 436ms/step - loss: 0.5408 - val_loss: 0.5206
Epoch 18/56
244/244 [==============================] - 107s 437ms/step - loss: 0.5405 - val_loss: 0.5523
Epoch 19/56
244/244 [==============================] - 108s 441ms/step - loss: 0.5382 - val_loss: 0.5686
Epoch 20/56
244/244 [==============================] - 107s 437ms/step - loss: 0.5391 - val_loss: 0.5799
Epoch 21/56
244/244 [==============================] - 107s 438ms/step - loss: 0.5389 - val_loss: 0.5736
Epoch 22/56
244/244 [==============================] - 107s 438ms/step - loss: 0.5392 - val_loss: 0.5633
Epoch 23/56
244/244 [==============================] - 107s 438ms/step - loss: 0.5382 - val_loss: 0.5518
Epoch 24/56
244/244 [==============================] - 107s 439ms/step - loss: 0.5400 - val_loss: 0.4907
Epoch 25/56
244/244 [==============================] - 107s 439ms/step - loss: 0.5398 - val_loss: 0.4985
Epoch 26/56
244/244 [==============================] - 107s 440ms/step - loss: 0.5345 - val_loss: 0.4856
Epoch 27/56
244/244 [==============================] - 107s 439ms/step - loss: 0.5372 - val_loss: 0.5170
Epoch 28/56
244/244 [==============================] - 107s 440ms/step - loss: 0.5342 - val_loss: 0.4967
Epoch 29/56
244/244 [==============================] - 107s 439ms/step - loss: 0.5343 - val_loss: 0.5143
Epoch 30/56
244/244 [==============================] - 107s 438ms/step - loss: 0.5347 - val_loss: 0.5228
Epoch 31/56
244/244 [==============================] - 107s 439ms/step - loss: 0.5352 - val_loss: 0.5238
Epoch 32/56
244/244 [==============================] - 107s 440ms/step - loss: 0.5350 - val_loss: 0.5116
Epoch 33/56
244/244 [==============================] - 107s 438ms/step - loss: 0.5345 - val_loss: 0.5109
Epoch 34/56
244/244 [==============================] - 107s 439ms/step - loss: 0.5344 - val_loss: 0.5097
Epoch 35/56
244/244 [==============================] - 107s 438ms/step - loss: 0.5338 - val_loss: 0.5146
Epoch 36/56
244/244 [==============================] - 107s 440ms/step - loss: 0.5331 - val_loss: 0.5105
Epoch 37/56
244/244 [==============================] - 107s 439ms/step - loss: 0.5328 - val_loss: 0.5132
Epoch 38/56
244/244 [==============================] - 107s 439ms/step - loss: 0.5322 - val_loss: 0.5139
Epoch 39/56
244/244 [==============================] - 108s 441ms/step - loss: 0.5321 - val_loss: 0.5159
Epoch 40/56
244/244 [==============================] - 107s 439ms/step - loss: 0.5313 - val_loss: 0.5148
Epoch 41/56
244/244 [==============================] - 107s 440ms/step - loss: 0.5316 - val_loss: 0.5136
Epoch 42/56
244/244 [==============================] - 107s 438ms/step - loss: 0.5308 - val_loss: 0.5147
Epoch 43/56
244/244 [==============================] - 107s 438ms/step - loss: 0.5296 - val_loss: 0.5162
Epoch 44/56
244/244 [==============================] - 108s 441ms/step - loss: 0.5295 - val_loss: 0.5182
Epoch 45/56
244/244 [==============================] - 107s 440ms/step - loss: 0.5291 - val_loss: 0.5179
Epoch 46/56
244/244 [==============================] - 107s 438ms/step - loss: 0.5291 - val_loss: 0.5176
Epoch 47/56
244/244 [==============================] - 107s 439ms/step - loss: 0.5277 - val_loss: 0.5210
Epoch 48/56
244/244 [==============================] - 107s 440ms/step - loss: 0.5278 - val_loss: 0.5253
Epoch 49/56
244/244 [==============================] - 107s 439ms/step - loss: 0.5285 - val_loss: 0.5139
Epoch 50/56
244/244 [==============================] - 107s 440ms/step - loss: 0.5279 - val_loss: 0.5049
Epoch 51/56
244/244 [==============================] - 107s 440ms/step - loss: 0.5268 - val_loss: 0.5015
Epoch 52/56
244/244 [==============================] - 108s 442ms/step - loss: 0.5265 - val_loss: 0.5016
Epoch 53/56
244/244 [==============================] - 108s 441ms/step - loss: 0.5250 - val_loss: 0.4984
Epoch 54/56
244/244 [==============================] - 107s 440ms/step - loss: 0.5240 - val_loss: 0.4905
Epoch 55/56
244/244 [==============================] - 108s 444ms/step - loss: 0.5244 - val_loss: 0.4870
Epoch 56/56
244/244 [==============================] - 107s 440ms/step - loss: 0.5242 - val_loss: 0.4814
Execution time:  6012.78852725029
GRU:
Mean Absolute Error: 0.6887
Root Mean Square Error: 1.1500
Mean Square Error: 1.3225

Train RMSE: 1.150
Train MSE: 1.323
Train MAE: 0.689
###########################

MODEL:  GRU
sequence:  7d
units:  45
dropout1:  0.11814836227952394
dropout2:  0.24325404382648977
optimizer: adam
activationDense: tanh
epochs: 43
batchsize: 30
validation_split: 0.2
Model: &#34;sequential_157&#34;
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
gru_146 (GRU)                (None, 1008, 45)          6480      
_________________________________________________________________
dropout_314 (Dropout)        (None, 1008, 45)          0         
_________________________________________________________________
gru_147 (GRU)                (None, 1008, 45)          12420     
_________________________________________________________________
dropout_315 (Dropout)        (None, 1008, 45)          0         
_________________________________________________________________
time_distributed_157 (TimeDi (None, 1008, 1)           46        
=================================================================
Total params: 18,946
Trainable params: 18,946
Non-trainable params: 0
_________________________________________________________________
Epoch 1/43
80/80 [==============================] - 65s 812ms/step - loss: 0.6716 - val_loss: 0.4595
Epoch 2/43
80/80 [==============================] - 66s 825ms/step - loss: 0.6269 - val_loss: 0.4557
Epoch 3/43
80/80 [==============================] - 66s 821ms/step - loss: 0.6178 - val_loss: 0.4236
Epoch 4/43
80/80 [==============================] - 65s 816ms/step - loss: 0.6117 - val_loss: 0.4029
Epoch 5/43
80/80 [==============================] - 65s 813ms/step - loss: 0.6078 - val_loss: 0.3963
Epoch 6/43
80/80 [==============================] - 66s 823ms/step - loss: 0.6050 - val_loss: 0.3921
Epoch 7/43
80/80 [==============================] - 65s 817ms/step - loss: 0.6025 - val_loss: 0.3887
Epoch 8/43
80/80 [==============================] - 66s 822ms/step - loss: 0.6003 - val_loss: 0.3863
Epoch 9/43
80/80 [==============================] - 66s 819ms/step - loss: 0.5982 - val_loss: 0.3852
Epoch 10/43
80/80 [==============================] - 66s 820ms/step - loss: 0.5961 - val_loss: 0.3833
Epoch 11/43
80/80 [==============================] - 65s 818ms/step - loss: 0.5928 - val_loss: 0.3821
Epoch 12/43
80/80 [==============================] - 66s 822ms/step - loss: 0.5885 - val_loss: 0.3679
Epoch 13/43
80/80 [==============================] - 65s 813ms/step - loss: 0.5807 - val_loss: 0.3885
Epoch 14/43
80/80 [==============================] - 65s 815ms/step - loss: 0.5759 - val_loss: 0.4103
Epoch 15/43
80/80 [==============================] - 66s 822ms/step - loss: 0.5739 - val_loss: 0.4144
Epoch 16/43
80/80 [==============================] - 65s 816ms/step - loss: 0.5720 - val_loss: 0.4237
Epoch 17/43
80/80 [==============================] - 66s 820ms/step - loss: 0.5712 - val_loss: 0.4293
Epoch 18/43
80/80 [==============================] - 66s 822ms/step - loss: 0.5703 - val_loss: 0.4340
Epoch 19/43
80/80 [==============================] - 66s 820ms/step - loss: 0.5696 - val_loss: 0.4370
Epoch 20/43
80/80 [==============================] - 65s 812ms/step - loss: 0.5690 - val_loss: 0.4390
Epoch 21/43
80/80 [==============================] - 66s 819ms/step - loss: 0.5684 - val_loss: 0.4399
Epoch 22/43
80/80 [==============================] - 65s 815ms/step - loss: 0.5679 - val_loss: 0.4407
Epoch 23/43
80/80 [==============================] - 65s 818ms/step - loss: 0.5674 - val_loss: 0.4406
Epoch 24/43
80/80 [==============================] - 65s 815ms/step - loss: 0.5668 - val_loss: 0.4404
Epoch 25/43
80/80 [==============================] - 65s 814ms/step - loss: 0.5663 - val_loss: 0.4399
Epoch 26/43
80/80 [==============================] - 66s 820ms/step - loss: 0.5658 - val_loss: 0.4395
Epoch 27/43
80/80 [==============================] - 66s 822ms/step - loss: 0.5654 - val_loss: 0.4386
Epoch 28/43
80/80 [==============================] - 65s 815ms/step - loss: 0.5648 - val_loss: 0.4390
Epoch 29/43
80/80 [==============================] - 65s 810ms/step - loss: 0.5642 - val_loss: 0.4393
Epoch 30/43
80/80 [==============================] - 66s 821ms/step - loss: 0.5636 - val_loss: 0.4420
Epoch 31/43
80/80 [==============================] - 65s 815ms/step - loss: 0.5632 - val_loss: 0.4455
Epoch 32/43
80/80 [==============================] - 65s 815ms/step - loss: 0.5627 - val_loss: 0.4486
Epoch 33/43
80/80 [==============================] - 66s 823ms/step - loss: 0.5621 - val_loss: 0.4530
Epoch 34/43
80/80 [==============================] - 66s 823ms/step - loss: 0.5616 - val_loss: 0.4573
Epoch 35/43
80/80 [==============================] - 66s 819ms/step - loss: 0.5613 - val_loss: 0.4611
Epoch 36/43
80/80 [==============================] - 66s 820ms/step - loss: 0.5607 - val_loss: 0.4631
Epoch 37/43
80/80 [==============================] - 65s 817ms/step - loss: 0.5604 - val_loss: 0.4642
Epoch 38/43
80/80 [==============================] - 66s 819ms/step - loss: 0.5599 - val_loss: 0.4635
Epoch 39/43
80/80 [==============================] - 65s 818ms/step - loss: 0.5593 - val_loss: 0.4623
Epoch 40/43
80/80 [==============================] - 65s 814ms/step - loss: 0.5583 - val_loss: 0.4640
Epoch 41/43
80/80 [==============================] - 66s 823ms/step - loss: 0.5573 - val_loss: 0.4678
Epoch 42/43
80/80 [==============================] - 66s 821ms/step - loss: 0.5593 - val_loss: 0.4808
Epoch 43/43
80/80 [==============================] - 66s 821ms/step - loss: 0.5603 - val_loss: 0.4730
Execution time:  2853.5444486141205
GRU:
Mean Absolute Error: 0.7225
Root Mean Square Error: 1.1774
Mean Square Error: 1.3862

Train RMSE: 1.177
Train MSE: 1.386
Train MAE: 0.722
###########################

MODEL:  GRU
sequence:  7d
units:  43
dropout1:  0.40519643149940265
dropout2:  0.3312343747027119
optimizer: adam
activationDense: sigmoid
epochs: 56
batchsize: 11
validation_split: 0.1
Model: &#34;sequential_158&#34;
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
gru_148 (GRU)                (None, 1008, 43)          5934      
_________________________________________________________________
dropout_316 (Dropout)        (None, 1008, 43)          0         
_________________________________________________________________
gru_149 (GRU)                (None, 1008, 43)          11352     
_________________________________________________________________
dropout_317 (Dropout)        (None, 1008, 43)          0         
_________________________________________________________________
time_distributed_158 (TimeDi (None, 1008, 1)           44        
=================================================================
Total params: 17,330
Trainable params: 17,330
Non-trainable params: 0
_________________________________________________________________
Epoch 1/56
244/244 [==============================] - 112s 460ms/step - loss: 0.7656 - val_loss: 0.8393
Epoch 2/56
244/244 [==============================] - 110s 453ms/step - loss: 0.6805 - val_loss: 0.8361
Epoch 3/56
244/244 [==============================] - 111s 454ms/step - loss: 0.6794 - val_loss: 0.8352
Epoch 4/56
244/244 [==============================] - 111s 453ms/step - loss: 0.6791 - val_loss: 0.8349
Epoch 5/56
244/244 [==============================] - 111s 454ms/step - loss: 0.6789 - val_loss: 0.8347
Epoch 6/56
244/244 [==============================] - 111s 455ms/step - loss: 0.6788 - val_loss: 0.8345
Epoch 7/56
244/244 [==============================] - 111s 455ms/step - loss: 0.6787 - val_loss: 0.8344
Epoch 8/56
244/244 [==============================] - 111s 455ms/step - loss: 0.6786 - val_loss: 0.8344
Epoch 9/56
244/244 [==============================] - 111s 454ms/step - loss: 0.6786 - val_loss: 0.8343
Epoch 10/56
244/244 [==============================] - 111s 454ms/step - loss: 0.6786 - val_loss: 0.8343
Epoch 11/56
244/244 [==============================] - 111s 457ms/step - loss: 0.6785 - val_loss: 0.8342
Epoch 12/56
244/244 [==============================] - 111s 456ms/step - loss: 0.6785 - val_loss: 0.8342
Epoch 13/56
244/244 [==============================] - 111s 457ms/step - loss: 0.6785 - val_loss: 0.8342
Epoch 14/56
244/244 [==============================] - 112s 457ms/step - loss: 0.6785 - val_loss: 0.8342
Epoch 15/56
244/244 [==============================] - 111s 456ms/step - loss: 0.6785 - val_loss: 0.8342
Epoch 16/56
244/244 [==============================] - 112s 457ms/step - loss: 0.6785 - val_loss: 0.8342
Epoch 17/56
244/244 [==============================] - 111s 455ms/step - loss: 0.6785 - val_loss: 0.8342
Epoch 18/56
244/244 [==============================] - 111s 455ms/step - loss: 0.6785 - val_loss: 0.8341
Epoch 19/56
244/244 [==============================] - 112s 458ms/step - loss: 0.6785 - val_loss: 0.8341
Epoch 20/56
244/244 [==============================] - 111s 456ms/step - loss: 0.6785 - val_loss: 0.8341
Epoch 21/56
244/244 [==============================] - 115s 472ms/step - loss: 0.6785 - val_loss: 0.8341
Epoch 22/56
244/244 [==============================] - 111s 456ms/step - loss: 0.6785 - val_loss: 0.8341
Epoch 23/56
244/244 [==============================] - 112s 457ms/step - loss: 0.6785 - val_loss: 0.8341
Epoch 24/56
244/244 [==============================] - 111s 455ms/step - loss: 0.6785 - val_loss: 0.8341
Epoch 25/56
244/244 [==============================] - 111s 455ms/step - loss: 0.6785 - val_loss: 0.8341
Epoch 26/56
244/244 [==============================] - 111s 456ms/step - loss: 0.6785 - val_loss: 0.8341
Epoch 27/56
244/244 [==============================] - 112s 458ms/step - loss: 0.6785 - val_loss: 0.8341
Epoch 28/56
244/244 [==============================] - 111s 456ms/step - loss: 0.6785 - val_loss: 0.8341
Epoch 29/56
244/244 [==============================] - 111s 457ms/step - loss: 0.6785 - val_loss: 0.8341
Epoch 30/56
244/244 [==============================] - 111s 457ms/step - loss: 0.6785 - val_loss: 0.8341
Epoch 31/56
244/244 [==============================] - 121s 497ms/step - loss: 0.6785 - val_loss: 0.8341
Epoch 32/56
244/244 [==============================] - 112s 460ms/step - loss: 0.6785 - val_loss: 0.8341
Epoch 33/56
244/244 [==============================] - 111s 457ms/step - loss: 0.6785 - val_loss: 0.8341
Epoch 34/56
244/244 [==============================] - 111s 454ms/step - loss: 0.6785 - val_loss: 0.8341
Epoch 35/56
244/244 [==============================] - 111s 456ms/step - loss: 0.6785 - val_loss: 0.8341
Epoch 36/56
244/244 [==============================] - 111s 455ms/step - loss: 0.6785 - val_loss: 0.8341
Epoch 37/56
244/244 [==============================] - 111s 456ms/step - loss: 0.6785 - val_loss: 0.8341
Epoch 38/56
244/244 [==============================] - 111s 454ms/step - loss: 0.6785 - val_loss: 0.8341
Epoch 39/56
244/244 [==============================] - 111s 457ms/step - loss: 0.6785 - val_loss: 0.8341
Epoch 40/56
244/244 [==============================] - 112s 458ms/step - loss: 0.6785 - val_loss: 0.8341
Epoch 41/56
244/244 [==============================] - 111s 456ms/step - loss: 0.6785 - val_loss: 0.8341
Epoch 42/56
244/244 [==============================] - 111s 456ms/step - loss: 0.6785 - val_loss: 0.8341
Epoch 43/56
244/244 [==============================] - 112s 459ms/step - loss: 0.6785 - val_loss: 0.8341
Epoch 44/56
244/244 [==============================] - 111s 457ms/step - loss: 0.6785 - val_loss: 0.8341
Epoch 45/56
244/244 [==============================] - 112s 457ms/step - loss: 0.6785 - val_loss: 0.8341
Epoch 46/56
244/244 [==============================] - 112s 457ms/step - loss: 0.6785 - val_loss: 0.8341
Epoch 47/56
244/244 [==============================] - 112s 457ms/step - loss: 0.6785 - val_loss: 0.8341
Epoch 48/56
244/244 [==============================] - 111s 456ms/step - loss: 0.6785 - val_loss: 0.8341
Epoch 49/56
244/244 [==============================] - 112s 457ms/step - loss: 0.6785 - val_loss: 0.8341
Epoch 50/56
244/244 [==============================] - 111s 457ms/step - loss: 0.6785 - val_loss: 0.8341
Epoch 51/56
244/244 [==============================] - 112s 459ms/step - loss: 0.6785 - val_loss: 0.8341
Epoch 52/56
244/244 [==============================] - 111s 456ms/step - loss: 0.6785 - val_loss: 0.8341
Epoch 53/56
244/244 [==============================] - 112s 458ms/step - loss: 0.6785 - val_loss: 0.8341
Epoch 54/56
244/244 [==============================] - 112s 457ms/step - loss: 0.6785 - val_loss: 0.8341
Epoch 55/56
244/244 [==============================] - 112s 458ms/step - loss: 0.6785 - val_loss: 0.8341
Epoch 56/56
244/244 [==============================] - 111s 455ms/step - loss: 0.6785 - val_loss: 0.8341
Execution time:  6280.207427024841
GRU:
Mean Absolute Error: 0.6954
Root Mean Square Error: 1.0192
Mean Square Error: 1.0387

Train RMSE: 1.019
Train MSE: 1.039
Train MAE: 0.695
###########################

MODEL:  GRU
sequence:  7d
units:  45
dropout1:  0.11814836227952394
dropout2:  0.24325404382648977
optimizer: adam
activationDense: sigmoid
epochs: 43
batchsize: 30
validation_split: 0.2
Model: &#34;sequential_159&#34;
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
gru_150 (GRU)                (None, 1008, 45)          6480      
_________________________________________________________________
dropout_318 (Dropout)        (None, 1008, 45)          0         
_________________________________________________________________
gru_151 (GRU)                (None, 1008, 45)          12420     
_________________________________________________________________
dropout_319 (Dropout)        (None, 1008, 45)          0         
_________________________________________________________________
time_distributed_159 (TimeDi (None, 1008, 1)           46        
=================================================================
Total params: 18,946
Trainable params: 18,946
Non-trainable params: 0
_________________________________________________________________
Epoch 1/43
80/80 [==============================] - 65s 812ms/step - loss: 0.9039 - val_loss: 0.6908
Epoch 2/43
80/80 [==============================] - 67s 839ms/step - loss: 0.7072 - val_loss: 0.6741
Epoch 3/43
80/80 [==============================] - 68s 848ms/step - loss: 0.7039 - val_loss: 0.6712
Epoch 4/43
80/80 [==============================] - 68s 849ms/step - loss: 0.7028 - val_loss: 0.6699
Epoch 5/43
80/80 [==============================] - 68s 855ms/step - loss: 0.7022 - val_loss: 0.6692
Epoch 6/43
80/80 [==============================] - 68s 851ms/step - loss: 0.7019 - val_loss: 0.6687
Epoch 7/43
80/80 [==============================] - 68s 853ms/step - loss: 0.7017 - val_loss: 0.6684
Epoch 8/43
80/80 [==============================] - 68s 849ms/step - loss: 0.7016 - val_loss: 0.6682
Epoch 9/43
80/80 [==============================] - 68s 850ms/step - loss: 0.7014 - val_loss: 0.6680
Epoch 10/43
80/80 [==============================] - 68s 853ms/step - loss: 0.7014 - val_loss: 0.6679
Epoch 11/43
80/80 [==============================] - 68s 855ms/step - loss: 0.7013 - val_loss: 0.6678
Epoch 12/43
80/80 [==============================] - 68s 855ms/step - loss: 0.7012 - val_loss: 0.6677
Epoch 13/43
80/80 [==============================] - 68s 855ms/step - loss: 0.7012 - val_loss: 0.6676
Epoch 14/43
80/80 [==============================] - 69s 861ms/step - loss: 0.7011 - val_loss: 0.6675
Epoch 15/43
80/80 [==============================] - 68s 852ms/step - loss: 0.7011 - val_loss: 0.6675
Epoch 16/43
80/80 [==============================] - 68s 852ms/step - loss: 0.7011 - val_loss: 0.6674
Epoch 17/43
80/80 [==============================] - 68s 855ms/step - loss: 0.7011 - val_loss: 0.6674
Epoch 18/43
80/80 [==============================] - 69s 860ms/step - loss: 0.7010 - val_loss: 0.6674
Epoch 19/43
80/80 [==============================] - 68s 851ms/step - loss: 0.7010 - val_loss: 0.6673
Epoch 20/43
80/80 [==============================] - 68s 852ms/step - loss: 0.7010 - val_loss: 0.6673
Epoch 21/43
80/80 [==============================] - 68s 856ms/step - loss: 0.7010 - val_loss: 0.6673
Epoch 22/43
80/80 [==============================] - 68s 856ms/step - loss: 0.7010 - val_loss: 0.6673
Epoch 23/43
80/80 [==============================] - 69s 856ms/step - loss: 0.7010 - val_loss: 0.6673
Epoch 24/43
80/80 [==============================] - 68s 851ms/step - loss: 0.7010 - val_loss: 0.6672
Epoch 25/43
80/80 [==============================] - 69s 858ms/step - loss: 0.7009 - val_loss: 0.6672
Epoch 26/43
80/80 [==============================] - 68s 854ms/step - loss: 0.7009 - val_loss: 0.6672
Epoch 27/43
80/80 [==============================] - 68s 854ms/step - loss: 0.7009 - val_loss: 0.6672
Epoch 28/43
80/80 [==============================] - 69s 862ms/step - loss: 0.7009 - val_loss: 0.6672
Epoch 29/43
80/80 [==============================] - 68s 851ms/step - loss: 0.7009 - val_loss: 0.6672
Epoch 30/43
80/80 [==============================] - 69s 857ms/step - loss: 0.7009 - val_loss: 0.6672
Epoch 31/43
80/80 [==============================] - 68s 855ms/step - loss: 0.7009 - val_loss: 0.6671
Epoch 32/43
80/80 [==============================] - 68s 853ms/step - loss: 0.7009 - val_loss: 0.6671
Epoch 33/43
80/80 [==============================] - 68s 852ms/step - loss: 0.7009 - val_loss: 0.6671
Epoch 34/43
80/80 [==============================] - 68s 855ms/step - loss: 0.7009 - val_loss: 0.6671
Epoch 35/43
80/80 [==============================] - 69s 858ms/step - loss: 0.7009 - val_loss: 0.6671
Epoch 36/43
80/80 [==============================] - 68s 853ms/step - loss: 0.7009 - val_loss: 0.6671
Epoch 37/43
80/80 [==============================] - 68s 854ms/step - loss: 0.7009 - val_loss: 0.6671
Epoch 38/43
80/80 [==============================] - 68s 852ms/step - loss: 0.7009 - val_loss: 0.6671
Epoch 39/43
80/80 [==============================] - 68s 855ms/step - loss: 0.7009 - val_loss: 0.6671
Epoch 40/43
80/80 [==============================] - 68s 851ms/step - loss: 0.7009 - val_loss: 0.6671
Epoch 41/43
80/80 [==============================] - 68s 855ms/step - loss: 0.7009 - val_loss: 0.6671
Epoch 42/43
80/80 [==============================] - 69s 859ms/step - loss: 0.7009 - val_loss: 0.6671
Epoch 43/43
80/80 [==============================] - 68s 854ms/step - loss: 0.7009 - val_loss: 0.6671
Execution time:  2974.136693716049
GRU:
Mean Absolute Error: 0.6955
Root Mean Square Error: 1.0192
Mean Square Error: 1.0387

Train RMSE: 1.019
Train MSE: 1.039
Train MAE: 0.695
###########################

MODEL:  GRU
sequence:  7d
units:  43
dropout1:  0.40519643149940265
dropout2:  0.3312343747027119
optimizer: adadelta
activationDense: tanh
epochs: 56
batchsize: 11
validation_split: 0.1
Model: &#34;sequential_160&#34;
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
gru_152 (GRU)                (None, 1008, 43)          5934      
_________________________________________________________________
dropout_320 (Dropout)        (None, 1008, 43)          0         
_________________________________________________________________
gru_153 (GRU)                (None, 1008, 43)          11352     
_________________________________________________________________
dropout_321 (Dropout)        (None, 1008, 43)          0         
_________________________________________________________________
time_distributed_160 (TimeDi (None, 1008, 1)           44        
=================================================================
Total params: 17,330
Trainable params: 17,330
Non-trainable params: 0
_________________________________________________________________
Epoch 1/56
244/244 [==============================] - 110s 451ms/step - loss: 0.6771 - val_loss: 0.8429
Epoch 2/56
244/244 [==============================] - 108s 444ms/step - loss: 0.6763 - val_loss: 0.8413
Epoch 3/56
244/244 [==============================] - 108s 443ms/step - loss: 0.6754 - val_loss: 0.8396
Epoch 4/56
244/244 [==============================] - 109s 447ms/step - loss: 0.6743 - val_loss: 0.8378
Epoch 5/56
244/244 [==============================] - 108s 442ms/step - loss: 0.6733 - val_loss: 0.8357
Epoch 6/56
244/244 [==============================] - 109s 445ms/step - loss: 0.6721 - val_loss: 0.8335
Epoch 7/56
244/244 [==============================] - 108s 442ms/step - loss: 0.6709 - val_loss: 0.8312
Epoch 8/56
244/244 [==============================] - 108s 444ms/step - loss: 0.6695 - val_loss: 0.8288
Epoch 9/56
244/244 [==============================] - 109s 447ms/step - loss: 0.6682 - val_loss: 0.8262
Epoch 10/56
244/244 [==============================] - 108s 445ms/step - loss: 0.6668 - val_loss: 0.8235
Epoch 11/56
244/244 [==============================] - 108s 444ms/step - loss: 0.6653 - val_loss: 0.8206
Epoch 12/56
244/244 [==============================] - 110s 450ms/step - loss: 0.6638 - val_loss: 0.8177
Epoch 13/56
244/244 [==============================] - 108s 444ms/step - loss: 0.6622 - val_loss: 0.8146
Epoch 14/56
244/244 [==============================] - 108s 444ms/step - loss: 0.6606 - val_loss: 0.8114
Epoch 15/56
244/244 [==============================] - 108s 444ms/step - loss: 0.6590 - val_loss: 0.8081
Epoch 16/56
244/244 [==============================] - 108s 444ms/step - loss: 0.6572 - val_loss: 0.8047
Epoch 17/56
244/244 [==============================] - 109s 447ms/step - loss: 0.6555 - val_loss: 0.8012
Epoch 18/56
244/244 [==============================] - 108s 443ms/step - loss: 0.6537 - val_loss: 0.7976
Epoch 19/56
244/244 [==============================] - 108s 444ms/step - loss: 0.6519 - val_loss: 0.7939
Epoch 20/56
244/244 [==============================] - 108s 444ms/step - loss: 0.6501 - val_loss: 0.7902
Epoch 21/56
244/244 [==============================] - 108s 444ms/step - loss: 0.6483 - val_loss: 0.7865
Epoch 22/56
244/244 [==============================] - 108s 444ms/step - loss: 0.6466 - val_loss: 0.7827
Epoch 23/56
244/244 [==============================] - 108s 441ms/step - loss: 0.6448 - val_loss: 0.7790
Epoch 24/56
244/244 [==============================] - 108s 442ms/step - loss: 0.6431 - val_loss: 0.7752
Epoch 25/56
244/244 [==============================] - 108s 443ms/step - loss: 0.6413 - val_loss: 0.7714
Epoch 26/56
244/244 [==============================] - 108s 443ms/step - loss: 0.6396 - val_loss: 0.7676
Epoch 27/56
244/244 [==============================] - 108s 443ms/step - loss: 0.6378 - val_loss: 0.7638
Epoch 28/56
244/244 [==============================] - 108s 443ms/step - loss: 0.6361 - val_loss: 0.7599
Epoch 29/56
244/244 [==============================] - 108s 441ms/step - loss: 0.6343 - val_loss: 0.7559
Epoch 30/56
244/244 [==============================] - 107s 441ms/step - loss: 0.6326 - val_loss: 0.7519
Epoch 31/56
244/244 [==============================] - 108s 441ms/step - loss: 0.6307 - val_loss: 0.7478
Epoch 32/56
244/244 [==============================] - 107s 440ms/step - loss: 0.6289 - val_loss: 0.7436
Epoch 33/56
244/244 [==============================] - 108s 442ms/step - loss: 0.6270 - val_loss: 0.7393
Epoch 34/56
244/244 [==============================] - 108s 441ms/step - loss: 0.6251 - val_loss: 0.7349
Epoch 35/56
244/244 [==============================] - 107s 440ms/step - loss: 0.6232 - val_loss: 0.7304
Epoch 36/56
244/244 [==============================] - 108s 442ms/step - loss: 0.6212 - val_loss: 0.7258
Epoch 37/56
244/244 [==============================] - 108s 441ms/step - loss: 0.6193 - val_loss: 0.7211
Epoch 38/56
244/244 [==============================] - 108s 443ms/step - loss: 0.6172 - val_loss: 0.7162
Epoch 39/56
244/244 [==============================] - 107s 440ms/step - loss: 0.6152 - val_loss: 0.7112
Epoch 40/56
244/244 [==============================] - 107s 440ms/step - loss: 0.6131 - val_loss: 0.7062
Epoch 41/56
244/244 [==============================] - 107s 440ms/step - loss: 0.6110 - val_loss: 0.7010
Epoch 42/56
244/244 [==============================] - 107s 439ms/step - loss: 0.6089 - val_loss: 0.6957
Epoch 43/56
244/244 [==============================] - 107s 440ms/step - loss: 0.6067 - val_loss: 0.6903
Epoch 44/56
244/244 [==============================] - 107s 437ms/step - loss: 0.6046 - val_loss: 0.6849
Epoch 45/56
244/244 [==============================] - 107s 438ms/step - loss: 0.6024 - val_loss: 0.6794
Epoch 46/56
244/244 [==============================] - 107s 439ms/step - loss: 0.6004 - val_loss: 0.6739
Epoch 47/56
244/244 [==============================] - 106s 436ms/step - loss: 0.5984 - val_loss: 0.6683
Epoch 48/56
244/244 [==============================] - 107s 437ms/step - loss: 0.5962 - val_loss: 0.6628
Epoch 49/56
244/244 [==============================] - 106s 435ms/step - loss: 0.5942 - val_loss: 0.6572
Epoch 50/56
244/244 [==============================] - 106s 436ms/step - loss: 0.5922 - val_loss: 0.6516
Epoch 51/56
244/244 [==============================] - 107s 439ms/step - loss: 0.5902 - val_loss: 0.6460
Epoch 52/56
244/244 [==============================] - 106s 436ms/step - loss: 0.5884 - val_loss: 0.6403
Epoch 53/56
244/244 [==============================] - 106s 436ms/step - loss: 0.5864 - val_loss: 0.6346
Epoch 54/56
244/244 [==============================] - 106s 435ms/step - loss: 0.5846 - val_loss: 0.6289
Epoch 55/56
244/244 [==============================] - 107s 438ms/step - loss: 0.5827 - val_loss: 0.6232
Epoch 56/56
244/244 [==============================] - 106s 435ms/step - loss: 0.5808 - val_loss: 0.6174
Execution time:  6060.734648704529
GRU:
Mean Absolute Error: 0.6566
Root Mean Square Error: 1.0724
Mean Square Error: 1.1500

Train RMSE: 1.072
Train MSE: 1.150
Train MAE: 0.657
###########################

MODEL:  GRU
sequence:  7d
units:  45
dropout1:  0.11814836227952394
dropout2:  0.24325404382648977
optimizer: adadelta
activationDense: tanh
epochs: 43
batchsize: 30
validation_split: 0.2
Model: &#34;sequential_161&#34;
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
gru_154 (GRU)                (None, 1008, 45)          6480      
_________________________________________________________________
dropout_322 (Dropout)        (None, 1008, 45)          0         
_________________________________________________________________
gru_155 (GRU)                (None, 1008, 45)          12420     
_________________________________________________________________
dropout_323 (Dropout)        (None, 1008, 45)          0         
_________________________________________________________________
time_distributed_161 (TimeDi (None, 1008, 1)           46        
=================================================================
Total params: 18,946
Trainable params: 18,946
Non-trainable params: 0
_________________________________________________________________
Epoch 1/43
80/80 [==============================] - 64s 805ms/step - loss: 0.7000 - val_loss: 0.6744
Epoch 2/43
80/80 [==============================] - 66s 820ms/step - loss: 0.6997 - val_loss: 0.6741
Epoch 3/43
80/80 [==============================] - 66s 821ms/step - loss: 0.6995 - val_loss: 0.6738
Epoch 4/43
80/80 [==============================] - 65s 815ms/step - loss: 0.6993 - val_loss: 0.6735
Epoch 5/43
80/80 [==============================] - 66s 819ms/step - loss: 0.6991 - val_loss: 0.6732
Epoch 6/43
80/80 [==============================] - 66s 821ms/step - loss: 0.6988 - val_loss: 0.6729
Epoch 7/43
80/80 [==============================] - 66s 819ms/step - loss: 0.6985 - val_loss: 0.6725
Epoch 8/43
80/80 [==============================] - 66s 822ms/step - loss: 0.6983 - val_loss: 0.6721
Epoch 9/43
80/80 [==============================] - 65s 817ms/step - loss: 0.6980 - val_loss: 0.6718
Epoch 10/43
80/80 [==============================] - 66s 821ms/step - loss: 0.6977 - val_loss: 0.6714
Epoch 11/43
80/80 [==============================] - 65s 818ms/step - loss: 0.6974 - val_loss: 0.6710
Epoch 12/43
80/80 [==============================] - 66s 820ms/step - loss: 0.6971 - val_loss: 0.6705
Epoch 13/43
80/80 [==============================] - 65s 818ms/step - loss: 0.6968 - val_loss: 0.6701
Epoch 14/43
80/80 [==============================] - 65s 818ms/step - loss: 0.6965 - val_loss: 0.6697
Epoch 15/43
80/80 [==============================] - 66s 819ms/step - loss: 0.6962 - val_loss: 0.6692
Epoch 16/43
80/80 [==============================] - 65s 816ms/step - loss: 0.6958 - val_loss: 0.6687
Epoch 17/43
80/80 [==============================] - 65s 816ms/step - loss: 0.6956 - val_loss: 0.6683
Epoch 18/43
80/80 [==============================] - 66s 822ms/step - loss: 0.6952 - val_loss: 0.6678
Epoch 19/43
80/80 [==============================] - 66s 824ms/step - loss: 0.6949 - val_loss: 0.6673
Epoch 20/43
80/80 [==============================] - 63s 793ms/step - loss: 0.6946 - val_loss: 0.6668
Epoch 21/43
80/80 [==============================] - 63s 793ms/step - loss: 0.6942 - val_loss: 0.6663
Epoch 22/43
80/80 [==============================] - 63s 792ms/step - loss: 0.6939 - val_loss: 0.6658
Epoch 23/43
80/80 [==============================] - 64s 794ms/step - loss: 0.6936 - val_loss: 0.6652
Epoch 24/43
80/80 [==============================] - 63s 790ms/step - loss: 0.6932 - val_loss: 0.6647
Epoch 25/43
80/80 [==============================] - 64s 795ms/step - loss: 0.6928 - val_loss: 0.6641
Epoch 26/43
80/80 [==============================] - 63s 791ms/step - loss: 0.6925 - val_loss: 0.6636
Epoch 27/43
80/80 [==============================] - 63s 790ms/step - loss: 0.6921 - val_loss: 0.6630
Epoch 28/43
80/80 [==============================] - 64s 795ms/step - loss: 0.6918 - val_loss: 0.6625
Epoch 29/43
80/80 [==============================] - 64s 794ms/step - loss: 0.6914 - val_loss: 0.6619
Epoch 30/43
80/80 [==============================] - 63s 791ms/step - loss: 0.6910 - val_loss: 0.6613
Epoch 31/43
80/80 [==============================] - 63s 788ms/step - loss: 0.6907 - val_loss: 0.6607
Epoch 32/43
80/80 [==============================] - 63s 791ms/step - loss: 0.6903 - val_loss: 0.6601
Epoch 33/43
80/80 [==============================] - 63s 794ms/step - loss: 0.6900 - val_loss: 0.6595
Epoch 34/43
80/80 [==============================] - 63s 791ms/step - loss: 0.6896 - val_loss: 0.6589
Epoch 35/43
80/80 [==============================] - 63s 787ms/step - loss: 0.6892 - val_loss: 0.6583
Epoch 36/43
80/80 [==============================] - 63s 791ms/step - loss: 0.6888 - val_loss: 0.6577
Epoch 37/43
80/80 [==============================] - 63s 786ms/step - loss: 0.6884 - val_loss: 0.6571
Epoch 38/43
80/80 [==============================] - 63s 788ms/step - loss: 0.6881 - val_loss: 0.6564
Epoch 39/43
80/80 [==============================] - 63s 785ms/step - loss: 0.6877 - val_loss: 0.6558
Epoch 40/43
80/80 [==============================] - 63s 786ms/step - loss: 0.6873 - val_loss: 0.6552
Epoch 41/43
80/80 [==============================] - 63s 790ms/step - loss: 0.6869 - val_loss: 0.6545
Epoch 42/43
80/80 [==============================] - 63s 789ms/step - loss: 0.6866 - val_loss: 0.6539
Epoch 43/43
80/80 [==============================] - 63s 788ms/step - loss: 0.6862 - val_loss: 0.6532
Execution time:  2801.0457088947296
GRU:
Mean Absolute Error: 0.7071
Root Mean Square Error: 1.0438
Mean Square Error: 1.0895

Train RMSE: 1.044
Train MSE: 1.089
Train MAE: 0.707
###########################

MODEL:  GRU
sequence:  7d
units:  43
dropout1:  0.40519643149940265
dropout2:  0.3312343747027119
optimizer: adadelta
activationDense: sigmoid
epochs: 56
batchsize: 11
validation_split: 0.1
Model: &#34;sequential_162&#34;
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
gru_156 (GRU)                (None, 1008, 43)          5934      
_________________________________________________________________
dropout_324 (Dropout)        (None, 1008, 43)          0         
_________________________________________________________________
gru_157 (GRU)                (None, 1008, 43)          11352     
_________________________________________________________________
dropout_325 (Dropout)        (None, 1008, 43)          0         
_________________________________________________________________
time_distributed_162 (TimeDi (None, 1008, 1)           44        
=================================================================
Total params: 17,330
Trainable params: 17,330
Non-trainable params: 0
_________________________________________________________________
Epoch 1/56
244/244 [==============================] - 104s 427ms/step - loss: 0.9816 - val_loss: 1.3307
Epoch 2/56
244/244 [==============================] - 103s 423ms/step - loss: 0.9814 - val_loss: 1.3303
Epoch 3/56
244/244 [==============================] - 104s 425ms/step - loss: 0.9811 - val_loss: 1.3299
Epoch 4/56
244/244 [==============================] - 104s 425ms/step - loss: 0.9808 - val_loss: 1.3295
Epoch 5/56
244/244 [==============================] - 104s 425ms/step - loss: 0.9805 - val_loss: 1.3291
Epoch 6/56
244/244 [==============================] - 104s 425ms/step - loss: 0.9802 - val_loss: 1.3286
Epoch 7/56
244/244 [==============================] - 103s 422ms/step - loss: 0.9798 - val_loss: 1.3281
Epoch 8/56
244/244 [==============================] - 103s 422ms/step - loss: 0.9795 - val_loss: 1.3275
Epoch 9/56
244/244 [==============================] - 103s 421ms/step - loss: 0.9791 - val_loss: 1.3270
Epoch 10/56
244/244 [==============================] - 103s 424ms/step - loss: 0.9787 - val_loss: 1.3264
Epoch 11/56
244/244 [==============================] - 103s 424ms/step - loss: 0.9783 - val_loss: 1.3257
Epoch 12/56
244/244 [==============================] - 103s 423ms/step - loss: 0.9778 - val_loss: 1.3251
Epoch 13/56
244/244 [==============================] - 103s 422ms/step - loss: 0.9774 - val_loss: 1.3244
Epoch 14/56
244/244 [==============================] - 103s 422ms/step - loss: 0.9769 - val_loss: 1.3237
Epoch 15/56
244/244 [==============================] - 103s 422ms/step - loss: 0.9764 - val_loss: 1.3229
Epoch 16/56
244/244 [==============================] - 103s 423ms/step - loss: 0.9759 - val_loss: 1.3222
Epoch 17/56
244/244 [==============================] - 103s 424ms/step - loss: 0.9754 - val_loss: 1.3213
Epoch 18/56
244/244 [==============================] - 103s 423ms/step - loss: 0.9748 - val_loss: 1.3205
Epoch 19/56
244/244 [==============================] - 103s 423ms/step - loss: 0.9742 - val_loss: 1.3196
Epoch 20/56
244/244 [==============================] - 104s 425ms/step - loss: 0.9737 - val_loss: 1.3187
Epoch 21/56
244/244 [==============================] - 103s 424ms/step - loss: 0.9730 - val_loss: 1.3178
Epoch 22/56
244/244 [==============================] - 103s 424ms/step - loss: 0.9724 - val_loss: 1.3168
Epoch 23/56
244/244 [==============================] - 103s 423ms/step - loss: 0.9717 - val_loss: 1.3157
Epoch 24/56
244/244 [==============================] - 103s 422ms/step - loss: 0.9710 - val_loss: 1.3147
Epoch 25/56
244/244 [==============================] - 103s 423ms/step - loss: 0.9703 - val_loss: 1.3135
Epoch 26/56
244/244 [==============================] - 103s 422ms/step - loss: 0.9695 - val_loss: 1.3124
Epoch 27/56
244/244 [==============================] - 103s 423ms/step - loss: 0.9687 - val_loss: 1.3111
Epoch 28/56
244/244 [==============================] - 104s 424ms/step - loss: 0.9679 - val_loss: 1.3098
Epoch 29/56
244/244 [==============================] - 104s 425ms/step - loss: 0.9671 - val_loss: 1.3085
Epoch 30/56
244/244 [==============================] - 103s 422ms/step - loss: 0.9662 - val_loss: 1.3071
Epoch 31/56
244/244 [==============================] - 103s 422ms/step - loss: 0.9652 - val_loss: 1.3057
Epoch 32/56
244/244 [==============================] - 103s 423ms/step - loss: 0.9642 - val_loss: 1.3041
Epoch 33/56
244/244 [==============================] - 103s 424ms/step - loss: 0.9632 - val_loss: 1.3025
Epoch 34/56
244/244 [==============================] - 103s 422ms/step - loss: 0.9622 - val_loss: 1.3009
Epoch 35/56
244/244 [==============================] - 104s 425ms/step - loss: 0.9610 - val_loss: 1.2991
Epoch 36/56
244/244 [==============================] - 103s 422ms/step - loss: 0.9598 - val_loss: 1.2973
Epoch 37/56
244/244 [==============================] - 104s 426ms/step - loss: 0.9586 - val_loss: 1.2954
Epoch 38/56
244/244 [==============================] - 103s 423ms/step - loss: 0.9573 - val_loss: 1.2934
Epoch 39/56
244/244 [==============================] - 103s 422ms/step - loss: 0.9560 - val_loss: 1.2913
Epoch 40/56
244/244 [==============================] - 103s 422ms/step - loss: 0.9546 - val_loss: 1.2892
Epoch 41/56
244/244 [==============================] - 103s 424ms/step - loss: 0.9531 - val_loss: 1.2869
Epoch 42/56
244/244 [==============================] - 103s 420ms/step - loss: 0.9516 - val_loss: 1.2845
Epoch 43/56
244/244 [==============================] - 103s 422ms/step - loss: 0.9500 - val_loss: 1.2820
Epoch 44/56
244/244 [==============================] - 103s 424ms/step - loss: 0.9484 - val_loss: 1.2794
Epoch 45/56
244/244 [==============================] - 103s 424ms/step - loss: 0.9466 - val_loss: 1.2767
Epoch 46/56
244/244 [==============================] - 104s 425ms/step - loss: 0.9449 - val_loss: 1.2739
Epoch 47/56
244/244 [==============================] - 103s 424ms/step - loss: 0.9430 - val_loss: 1.2709
Epoch 48/56
244/244 [==============================] - 103s 423ms/step - loss: 0.9410 - val_loss: 1.2678
Epoch 49/56
244/244 [==============================] - 103s 422ms/step - loss: 0.9390 - val_loss: 1.2646
Epoch 50/56
244/244 [==============================] - 103s 423ms/step - loss: 0.9368 - val_loss: 1.2612
Epoch 51/56
244/244 [==============================] - 103s 422ms/step - loss: 0.9346 - val_loss: 1.2577
Epoch 52/56
244/244 [==============================] - 103s 423ms/step - loss: 0.9323 - val_loss: 1.2540
Epoch 53/56
244/244 [==============================] - 103s 422ms/step - loss: 0.9299 - val_loss: 1.2501
Epoch 54/56
244/244 [==============================] - 103s 423ms/step - loss: 0.9273 - val_loss: 1.2460
Epoch 55/56
244/244 [==============================] - 104s 424ms/step - loss: 0.9246 - val_loss: 1.2418
Epoch 56/56
244/244 [==============================] - 103s 423ms/step - loss: 0.9218 - val_loss: 1.2373
Execution time:  5809.358271121979
GRU:
Mean Absolute Error: 0.8663
Root Mean Square Error: 1.0861
Mean Square Error: 1.1796

Train RMSE: 1.086
Train MSE: 1.180
Train MAE: 0.866
###########################

MODEL:  GRU
sequence:  7d
units:  45
dropout1:  0.11814836227952394
dropout2:  0.24325404382648977
optimizer: adadelta
activationDense: sigmoid
epochs: 43
batchsize: 30
validation_split: 0.2
Model: &#34;sequential_163&#34;
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
gru_158 (GRU)                (None, 1008, 45)          6480      
_________________________________________________________________
dropout_326 (Dropout)        (None, 1008, 45)          0         
_________________________________________________________________
gru_159 (GRU)                (None, 1008, 45)          12420     
_________________________________________________________________
dropout_327 (Dropout)        (None, 1008, 45)          0         
_________________________________________________________________
time_distributed_163 (TimeDi (None, 1008, 1)           46        
=================================================================
Total params: 18,946
Trainable params: 18,946
Non-trainable params: 0
_________________________________________________________________
Epoch 1/43
80/80 [==============================] - 63s 783ms/step - loss: 0.9813 - val_loss: 1.1606
Epoch 2/43
80/80 [==============================] - 66s 826ms/step - loss: 0.9812 - val_loss: 1.1605
Epoch 3/43
80/80 [==============================] - 66s 831ms/step - loss: 0.9811 - val_loss: 1.1604
Epoch 4/43
80/80 [==============================] - 66s 826ms/step - loss: 0.9810 - val_loss: 1.1602
Epoch 5/43
80/80 [==============================] - 66s 824ms/step - loss: 0.9809 - val_loss: 1.1601
Epoch 6/43
80/80 [==============================] - 66s 826ms/step - loss: 0.9808 - val_loss: 1.1600
Epoch 7/43
80/80 [==============================] - 66s 826ms/step - loss: 0.9807 - val_loss: 1.1598
Epoch 8/43
80/80 [==============================] - 66s 824ms/step - loss: 0.9806 - val_loss: 1.1597
Epoch 9/43
80/80 [==============================] - 66s 822ms/step - loss: 0.9805 - val_loss: 1.1595
Epoch 10/43
80/80 [==============================] - 66s 829ms/step - loss: 0.9804 - val_loss: 1.1594
Epoch 11/43
80/80 [==============================] - 66s 830ms/step - loss: 0.9803 - val_loss: 1.1592
Epoch 12/43
80/80 [==============================] - 66s 829ms/step - loss: 0.9801 - val_loss: 1.1591
Epoch 13/43
80/80 [==============================] - 66s 825ms/step - loss: 0.9800 - val_loss: 1.1589
Epoch 14/43
80/80 [==============================] - 66s 831ms/step - loss: 0.9799 - val_loss: 1.1587
Epoch 15/43
80/80 [==============================] - 66s 830ms/step - loss: 0.9797 - val_loss: 1.1585
Epoch 16/43
80/80 [==============================] - 66s 828ms/step - loss: 0.9796 - val_loss: 1.1584
Epoch 17/43
80/80 [==============================] - 66s 826ms/step - loss: 0.9795 - val_loss: 1.1582
Epoch 18/43
80/80 [==============================] - 66s 823ms/step - loss: 0.9793 - val_loss: 1.1580
Epoch 19/43
80/80 [==============================] - 66s 828ms/step - loss: 0.9792 - val_loss: 1.1578
Epoch 20/43
80/80 [==============================] - 66s 826ms/step - loss: 0.9791 - val_loss: 1.1576
Epoch 21/43
80/80 [==============================] - 66s 826ms/step - loss: 0.9789 - val_loss: 1.1574
Epoch 22/43
80/80 [==============================] - 66s 827ms/step - loss: 0.9788 - val_loss: 1.1572
Epoch 23/43
80/80 [==============================] - 66s 824ms/step - loss: 0.9786 - val_loss: 1.1570
Epoch 24/43
80/80 [==============================] - 66s 830ms/step - loss: 0.9785 - val_loss: 1.1568
Epoch 25/43
80/80 [==============================] - 66s 823ms/step - loss: 0.9783 - val_loss: 1.1566
Epoch 26/43
80/80 [==============================] - 66s 826ms/step - loss: 0.9782 - val_loss: 1.1563
Epoch 27/43
80/80 [==============================] - 66s 826ms/step - loss: 0.9780 - val_loss: 1.1561
Epoch 28/43
80/80 [==============================] - 66s 826ms/step - loss: 0.9778 - val_loss: 1.1559
Epoch 29/43
80/80 [==============================] - 66s 826ms/step - loss: 0.9777 - val_loss: 1.1557
Epoch 30/43
80/80 [==============================] - 66s 829ms/step - loss: 0.9775 - val_loss: 1.1555
Epoch 31/43
80/80 [==============================] - 66s 826ms/step - loss: 0.9773 - val_loss: 1.1552
Epoch 32/43
80/80 [==============================] - 66s 829ms/step - loss: 0.9772 - val_loss: 1.1550
Epoch 33/43
80/80 [==============================] - 66s 830ms/step - loss: 0.9770 - val_loss: 1.1548
Epoch 34/43
80/80 [==============================] - 66s 828ms/step - loss: 0.9768 - val_loss: 1.1545
Epoch 35/43
80/80 [==============================] - 66s 825ms/step - loss: 0.9767 - val_loss: 1.1543
Epoch 36/43
80/80 [==============================] - 66s 827ms/step - loss: 0.9765 - val_loss: 1.1540
Epoch 37/43
80/80 [==============================] - 66s 827ms/step - loss: 0.9763 - val_loss: 1.1538
Epoch 38/43
80/80 [==============================] - 66s 826ms/step - loss: 0.9761 - val_loss: 1.1535
Epoch 39/43
80/80 [==============================] - 66s 826ms/step - loss: 0.9760 - val_loss: 1.1533
Epoch 40/43
80/80 [==============================] - 66s 823ms/step - loss: 0.9758 - val_loss: 1.1530
Epoch 41/43
80/80 [==============================] - 66s 822ms/step - loss: 0.9756 - val_loss: 1.1528
Epoch 42/43
80/80 [==============================] - 66s 826ms/step - loss: 0.9754 - val_loss: 1.1525
Epoch 43/43
80/80 [==============================] - 66s 820ms/step - loss: 0.9752 - val_loss: 1.1523
Execution time:  2878.6958146095276
GRU:
Mean Absolute Error: 0.9214
Root Mean Square Error: 1.1318
Mean Square Error: 1.2810

Train RMSE: 1.132
Train MSE: 1.281
Train MAE: 0.921
###########################

MODEL:  GRU
sequence:  7d
units:  43
dropout1:  0.40519643149940265
dropout2:  0.3312343747027119
optimizer: adamax
activationDense: tanh
epochs: 56
batchsize: 11
validation_split: 0.1
Model: &#34;sequential_164&#34;
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
gru_160 (GRU)                (None, 1008, 43)          5934      
_________________________________________________________________
dropout_328 (Dropout)        (None, 1008, 43)          0         
_________________________________________________________________
gru_161 (GRU)                (None, 1008, 43)          11352     
_________________________________________________________________
dropout_329 (Dropout)        (None, 1008, 43)          0         
_________________________________________________________________
time_distributed_164 (TimeDi (None, 1008, 1)           44        
=================================================================
Total params: 17,330
Trainable params: 17,330
Non-trainable params: 0
_________________________________________________________________
Epoch 1/56
244/244 [==============================] - 109s 447ms/step - loss: 0.6177 - val_loss: 0.4614
Epoch 2/56
244/244 [==============================] - 108s 441ms/step - loss: 0.5694 - val_loss: 0.4397
Epoch 3/56
244/244 [==============================] - 108s 441ms/step - loss: 0.5664 - val_loss: 0.4374
Epoch 4/56
244/244 [==============================] - 108s 442ms/step - loss: 0.5655 - val_loss: 0.4357
Epoch 5/56
244/244 [==============================] - 108s 443ms/step - loss: 0.5639 - val_loss: 0.4284
Epoch 6/56
244/244 [==============================] - 108s 441ms/step - loss: 0.5625 - val_loss: 0.4185
Epoch 7/56
244/244 [==============================] - 107s 440ms/step - loss: 0.5611 - val_loss: 0.4090
Epoch 8/56
244/244 [==============================] - 108s 441ms/step - loss: 0.5601 - val_loss: 0.4017
Epoch 9/56
244/244 [==============================] - 108s 443ms/step - loss: 0.5596 - val_loss: 0.3967
Epoch 10/56
244/244 [==============================] - 108s 441ms/step - loss: 0.5590 - val_loss: 0.3932
Epoch 11/56
244/244 [==============================] - 108s 441ms/step - loss: 0.5587 - val_loss: 0.3916
Epoch 12/56
244/244 [==============================] - 108s 441ms/step - loss: 0.5583 - val_loss: 0.3894
Epoch 13/56
244/244 [==============================] - 108s 442ms/step - loss: 0.5581 - val_loss: 0.3890
Epoch 14/56
244/244 [==============================] - 108s 443ms/step - loss: 0.5579 - val_loss: 0.3876
Epoch 15/56
244/244 [==============================] - 108s 442ms/step - loss: 0.5578 - val_loss: 0.3910
Epoch 16/56
244/244 [==============================] - 108s 443ms/step - loss: 0.5576 - val_loss: 0.3921
Epoch 17/56
244/244 [==============================] - 108s 442ms/step - loss: 0.5573 - val_loss: 0.3922
Epoch 18/56
244/244 [==============================] - 108s 443ms/step - loss: 0.5569 - val_loss: 0.3939
Epoch 19/56
244/244 [==============================] - 108s 441ms/step - loss: 0.5568 - val_loss: 0.3962
Epoch 20/56
244/244 [==============================] - 108s 441ms/step - loss: 0.5563 - val_loss: 0.3978
Epoch 21/56
244/244 [==============================] - 108s 443ms/step - loss: 0.5560 - val_loss: 0.4013
Epoch 22/56
244/244 [==============================] - 108s 445ms/step - loss: 0.5556 - val_loss: 0.4039
Epoch 23/56
244/244 [==============================] - 108s 442ms/step - loss: 0.5553 - val_loss: 0.4064
Epoch 24/56
244/244 [==============================] - 108s 441ms/step - loss: 0.5547 - val_loss: 0.4116
Epoch 25/56
244/244 [==============================] - 109s 446ms/step - loss: 0.5542 - val_loss: 0.4160
Epoch 26/56
244/244 [==============================] - 108s 441ms/step - loss: 0.5538 - val_loss: 0.4225
Epoch 27/56
244/244 [==============================] - 108s 442ms/step - loss: 0.5531 - val_loss: 0.4315
Epoch 28/56
244/244 [==============================] - 109s 445ms/step - loss: 0.5522 - val_loss: 0.4493
Epoch 29/56
244/244 [==============================] - 108s 442ms/step - loss: 0.5497 - val_loss: 0.4654
Epoch 30/56
244/244 [==============================] - 108s 441ms/step - loss: 0.5478 - val_loss: 0.4790
Epoch 31/56
244/244 [==============================] - 108s 441ms/step - loss: 0.5459 - val_loss: 0.4903
Epoch 32/56
244/244 [==============================] - 108s 441ms/step - loss: 0.5432 - val_loss: 0.5018
Epoch 33/56
244/244 [==============================] - 107s 440ms/step - loss: 0.5412 - val_loss: 0.5032
Epoch 34/56
244/244 [==============================] - 108s 442ms/step - loss: 0.5399 - val_loss: 0.5035
Epoch 35/56
244/244 [==============================] - 108s 442ms/step - loss: 0.5393 - val_loss: 0.5054
Epoch 36/56
244/244 [==============================] - 108s 443ms/step - loss: 0.5388 - val_loss: 0.5042
Epoch 37/56
244/244 [==============================] - 107s 440ms/step - loss: 0.5383 - val_loss: 0.5076
Epoch 38/56
244/244 [==============================] - 108s 441ms/step - loss: 0.5381 - val_loss: 0.5008
Epoch 39/56
244/244 [==============================] - 108s 443ms/step - loss: 0.5376 - val_loss: 0.4961
Epoch 40/56
244/244 [==============================] - 108s 442ms/step - loss: 0.5373 - val_loss: 0.4971
Epoch 41/56
244/244 [==============================] - 107s 440ms/step - loss: 0.5369 - val_loss: 0.4928
Epoch 42/56
244/244 [==============================] - 108s 443ms/step - loss: 0.5366 - val_loss: 0.4959
Epoch 43/56
244/244 [==============================] - 108s 441ms/step - loss: 0.5360 - val_loss: 0.4925
Epoch 44/56
244/244 [==============================] - 107s 439ms/step - loss: 0.5357 - val_loss: 0.4923
Epoch 45/56
244/244 [==============================] - 108s 443ms/step - loss: 0.5352 - val_loss: 0.4840
Epoch 46/56
244/244 [==============================] - 107s 440ms/step - loss: 0.5351 - val_loss: 0.4831
Epoch 47/56
244/244 [==============================] - 108s 442ms/step - loss: 0.5346 - val_loss: 0.4771
Epoch 48/56
244/244 [==============================] - 108s 442ms/step - loss: 0.5344 - val_loss: 0.4757
Epoch 49/56
244/244 [==============================] - 107s 440ms/step - loss: 0.5341 - val_loss: 0.4743
Epoch 50/56
244/244 [==============================] - 108s 441ms/step - loss: 0.5339 - val_loss: 0.4743
Epoch 51/56
244/244 [==============================] - 108s 441ms/step - loss: 0.5337 - val_loss: 0.4748
Epoch 52/56
244/244 [==============================] - 107s 441ms/step - loss: 0.5336 - val_loss: 0.4733
Epoch 53/56
244/244 [==============================] - 108s 442ms/step - loss: 0.5331 - val_loss: 0.4740
Epoch 54/56
244/244 [==============================] - 108s 441ms/step - loss: 0.5330 - val_loss: 0.4743
Epoch 55/56
244/244 [==============================] - 107s 440ms/step - loss: 0.5325 - val_loss: 0.4706
Epoch 56/56
244/244 [==============================] - 107s 440ms/step - loss: 0.5320 - val_loss: 0.4719
Execution time:  6066.962269544601
GRU:
Mean Absolute Error: 0.6738
Root Mean Square Error: 1.1399
Mean Square Error: 1.2993

Train RMSE: 1.140
Train MSE: 1.299
Train MAE: 0.674
###########################

MODEL:  GRU
sequence:  7d
units:  45
dropout1:  0.11814836227952394
dropout2:  0.24325404382648977
optimizer: adamax
activationDense: tanh
epochs: 43
batchsize: 30
validation_split: 0.2
Model: &#34;sequential_165&#34;
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
gru_162 (GRU)                (None, 1008, 45)          6480      
_________________________________________________________________
dropout_330 (Dropout)        (None, 1008, 45)          0         
_________________________________________________________________
gru_163 (GRU)                (None, 1008, 45)          12420     
_________________________________________________________________
dropout_331 (Dropout)        (None, 1008, 45)          0         
_________________________________________________________________
time_distributed_165 (TimeDi (None, 1008, 1)           46        
=================================================================
Total params: 18,946
Trainable params: 18,946
Non-trainable params: 0
_________________________________________________________________
Epoch 1/43
80/80 [==============================] - 65s 807ms/step - loss: 0.6717 - val_loss: 0.5261
Epoch 2/43
80/80 [==============================] - 67s 837ms/step - loss: 0.6160 - val_loss: 0.4133
Epoch 3/43
80/80 [==============================] - 67s 839ms/step - loss: 0.6093 - val_loss: 0.3988
Epoch 4/43
80/80 [==============================] - 67s 836ms/step - loss: 0.6064 - val_loss: 0.3928
Epoch 5/43
80/80 [==============================] - 67s 834ms/step - loss: 0.6046 - val_loss: 0.3894
Epoch 6/43
80/80 [==============================] - 67s 836ms/step - loss: 0.6032 - val_loss: 0.3874
Epoch 7/43
80/80 [==============================] - 67s 839ms/step - loss: 0.6020 - val_loss: 0.3856
Epoch 8/43
80/80 [==============================] - 67s 834ms/step - loss: 0.6010 - val_loss: 0.3844
Epoch 9/43
80/80 [==============================] - 67s 835ms/step - loss: 0.6001 - val_loss: 0.3837
Epoch 10/43
80/80 [==============================] - 67s 838ms/step - loss: 0.5993 - val_loss: 0.3828
Epoch 11/43
80/80 [==============================] - 66s 830ms/step - loss: 0.5986 - val_loss: 0.3822
Epoch 12/43
80/80 [==============================] - 68s 844ms/step - loss: 0.5979 - val_loss: 0.3815
Epoch 13/43
80/80 [==============================] - 67s 838ms/step - loss: 0.5972 - val_loss: 0.3812
Epoch 14/43
80/80 [==============================] - 67s 835ms/step - loss: 0.5965 - val_loss: 0.3807
Epoch 15/43
80/80 [==============================] - 68s 844ms/step - loss: 0.5959 - val_loss: 0.3804
Epoch 16/43
80/80 [==============================] - 67s 839ms/step - loss: 0.5954 - val_loss: 0.3798
Epoch 17/43
80/80 [==============================] - 67s 835ms/step - loss: 0.5949 - val_loss: 0.3797
Epoch 18/43
80/80 [==============================] - 67s 833ms/step - loss: 0.5942 - val_loss: 0.3791
Epoch 19/43
80/80 [==============================] - 67s 834ms/step - loss: 0.5937 - val_loss: 0.3790
Epoch 20/43
80/80 [==============================] - 67s 835ms/step - loss: 0.5932 - val_loss: 0.3787
Epoch 21/43
80/80 [==============================] - 67s 834ms/step - loss: 0.5927 - val_loss: 0.3787
Epoch 22/43
80/80 [==============================] - 67s 832ms/step - loss: 0.5922 - val_loss: 0.3788
Epoch 23/43
80/80 [==============================] - 67s 834ms/step - loss: 0.5917 - val_loss: 0.3789
Epoch 24/43
80/80 [==============================] - 67s 838ms/step - loss: 0.5911 - val_loss: 0.3794
Epoch 25/43
80/80 [==============================] - 67s 840ms/step - loss: 0.5905 - val_loss: 0.3799
Epoch 26/43
80/80 [==============================] - 67s 838ms/step - loss: 0.5900 - val_loss: 0.3806
Epoch 27/43
80/80 [==============================] - 67s 835ms/step - loss: 0.5892 - val_loss: 0.3814
Epoch 28/43
80/80 [==============================] - 67s 835ms/step - loss: 0.5887 - val_loss: 0.3822
Epoch 29/43
80/80 [==============================] - 67s 836ms/step - loss: 0.5875 - val_loss: 0.3836
Epoch 30/43
80/80 [==============================] - 68s 844ms/step - loss: 0.5866 - val_loss: 0.3840
Epoch 31/43
80/80 [==============================] - 67s 833ms/step - loss: 0.5842 - val_loss: 0.3841
Epoch 32/43
80/80 [==============================] - 67s 832ms/step - loss: 0.5801 - val_loss: 0.3858
Epoch 33/43
80/80 [==============================] - 67s 835ms/step - loss: 0.5738 - val_loss: 0.3954
Epoch 34/43
80/80 [==============================] - 67s 839ms/step - loss: 0.5720 - val_loss: 0.4051
Epoch 35/43
80/80 [==============================] - 67s 834ms/step - loss: 0.5715 - val_loss: 0.4072
Epoch 36/43
80/80 [==============================] - 67s 840ms/step - loss: 0.5706 - val_loss: 0.4089
Epoch 37/43
80/80 [==============================] - 67s 838ms/step - loss: 0.5699 - val_loss: 0.4101
Epoch 38/43
80/80 [==============================] - 67s 842ms/step - loss: 0.5691 - val_loss: 0.4110
Epoch 39/43
80/80 [==============================] - 67s 837ms/step - loss: 0.5685 - val_loss: 0.4127
Epoch 40/43
80/80 [==============================] - 67s 839ms/step - loss: 0.5680 - val_loss: 0.4129
Epoch 41/43
80/80 [==============================] - 67s 838ms/step - loss: 0.5676 - val_loss: 0.4133
Epoch 42/43
80/80 [==============================] - 67s 837ms/step - loss: 0.5672 - val_loss: 0.4137
Epoch 43/43
80/80 [==============================] - 67s 833ms/step - loss: 0.5668 - val_loss: 0.4148
Execution time:  2915.387079000473
GRU:
Mean Absolute Error: 0.6780
Root Mean Square Error: 1.1594
Mean Square Error: 1.3442

Train RMSE: 1.159
Train MSE: 1.344
Train MAE: 0.678
###########################

MODEL:  GRU
sequence:  7d
units:  43
dropout1:  0.40519643149940265
dropout2:  0.3312343747027119
optimizer: adamax
activationDense: sigmoid
epochs: 56
batchsize: 11
validation_split: 0.1
Model: &#34;sequential_166&#34;
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
gru_164 (GRU)                (None, 1008, 43)          5934      
_________________________________________________________________
dropout_332 (Dropout)        (None, 1008, 43)          0         
_________________________________________________________________
gru_165 (GRU)                (None, 1008, 43)          11352     
_________________________________________________________________
dropout_333 (Dropout)        (None, 1008, 43)          0         
_________________________________________________________________
time_distributed_166 (TimeDi (None, 1008, 1)           44        
=================================================================
Total params: 17,330
Trainable params: 17,330
Non-trainable params: 0
_________________________________________________________________
Epoch 1/56
244/244 [==============================] - 111s 456ms/step - loss: 0.8250 - val_loss: 0.8497
Epoch 2/56
244/244 [==============================] - 110s 451ms/step - loss: 0.6841 - val_loss: 0.8401
Epoch 3/56
244/244 [==============================] - 111s 453ms/step - loss: 0.6813 - val_loss: 0.8375
Epoch 4/56
244/244 [==============================] - 111s 454ms/step - loss: 0.6802 - val_loss: 0.8364
Epoch 5/56
244/244 [==============================] - 110s 453ms/step - loss: 0.6797 - val_loss: 0.8357
Epoch 6/56
244/244 [==============================] - 110s 450ms/step - loss: 0.6794 - val_loss: 0.8353
Epoch 7/56
244/244 [==============================] - 110s 451ms/step - loss: 0.6791 - val_loss: 0.8350
Epoch 8/56
244/244 [==============================] - 110s 452ms/step - loss: 0.6790 - val_loss: 0.8348
Epoch 9/56
244/244 [==============================] - 110s 449ms/step - loss: 0.6788 - val_loss: 0.8346
Epoch 10/56
244/244 [==============================] - 110s 452ms/step - loss: 0.6788 - val_loss: 0.8345
Epoch 11/56
244/244 [==============================] - 110s 451ms/step - loss: 0.6787 - val_loss: 0.8344
Epoch 12/56
244/244 [==============================] - 110s 451ms/step - loss: 0.6786 - val_loss: 0.8344
Epoch 13/56
244/244 [==============================] - 110s 451ms/step - loss: 0.6786 - val_loss: 0.8343
Epoch 14/56
244/244 [==============================] - 110s 452ms/step - loss: 0.6786 - val_loss: 0.8343
Epoch 15/56
244/244 [==============================] - 110s 452ms/step - loss: 0.6785 - val_loss: 0.8342
Epoch 16/56
244/244 [==============================] - 111s 453ms/step - loss: 0.6785 - val_loss: 0.8342
Epoch 17/56
244/244 [==============================] - 110s 451ms/step - loss: 0.6785 - val_loss: 0.8342
Epoch 18/56
244/244 [==============================] - 110s 450ms/step - loss: 0.6785 - val_loss: 0.8342
Epoch 19/56
244/244 [==============================] - 110s 451ms/step - loss: 0.6785 - val_loss: 0.8342
Epoch 20/56
244/244 [==============================] - 110s 451ms/step - loss: 0.6785 - val_loss: 0.8341
Epoch 21/56
244/244 [==============================] - 110s 451ms/step - loss: 0.6785 - val_loss: 0.8341
Epoch 22/56
244/244 [==============================] - 110s 452ms/step - loss: 0.6785 - val_loss: 0.8341
Epoch 23/56
244/244 [==============================] - 115s 470ms/step - loss: 0.6785 - val_loss: 0.8341
Epoch 24/56
244/244 [==============================] - 110s 450ms/step - loss: 0.6785 - val_loss: 0.8341
Epoch 25/56
244/244 [==============================] - 110s 450ms/step - loss: 0.6785 - val_loss: 0.8341
Epoch 26/56
244/244 [==============================] - 110s 450ms/step - loss: 0.6785 - val_loss: 0.8341
Epoch 27/56
244/244 [==============================] - 110s 449ms/step - loss: 0.6785 - val_loss: 0.8341
Epoch 28/56
244/244 [==============================] - 110s 451ms/step - loss: 0.6785 - val_loss: 0.8341
Epoch 29/56
244/244 [==============================] - 109s 447ms/step - loss: 0.6785 - val_loss: 0.8341
Epoch 30/56
244/244 [==============================] - 110s 451ms/step - loss: 0.6785 - val_loss: 0.8341
Epoch 31/56
244/244 [==============================] - 109s 447ms/step - loss: 0.6785 - val_loss: 0.8341
Epoch 32/56
244/244 [==============================] - 110s 449ms/step - loss: 0.6785 - val_loss: 0.8341
Epoch 33/56
244/244 [==============================] - 109s 448ms/step - loss: 0.6785 - val_loss: 0.8341
Epoch 34/56
244/244 [==============================] - 110s 452ms/step - loss: 0.6785 - val_loss: 0.8341
Epoch 35/56
244/244 [==============================] - 110s 449ms/step - loss: 0.6785 - val_loss: 0.8341
Epoch 36/56
244/244 [==============================] - 110s 449ms/step - loss: 0.6785 - val_loss: 0.8341
Epoch 37/56
244/244 [==============================] - 110s 450ms/step - loss: 0.6785 - val_loss: 0.8341
Epoch 38/56
244/244 [==============================] - 110s 449ms/step - loss: 0.6785 - val_loss: 0.8341
Epoch 39/56
244/244 [==============================] - 110s 450ms/step - loss: 0.6785 - val_loss: 0.8341
Epoch 40/56
244/244 [==============================] - 109s 447ms/step - loss: 0.6785 - val_loss: 0.8341
Epoch 41/56
244/244 [==============================] - 109s 447ms/step - loss: 0.6785 - val_loss: 0.8341
Epoch 42/56
244/244 [==============================] - 109s 449ms/step - loss: 0.6785 - val_loss: 0.8341
Epoch 43/56
244/244 [==============================] - 109s 447ms/step - loss: 0.6785 - val_loss: 0.8341
Epoch 44/56
244/244 [==============================] - 109s 448ms/step - loss: 0.6785 - val_loss: 0.8341
Epoch 45/56
244/244 [==============================] - 109s 448ms/step - loss: 0.6785 - val_loss: 0.8341
Epoch 46/56
244/244 [==============================] - 110s 450ms/step - loss: 0.6785 - val_loss: 0.8341
Epoch 47/56
244/244 [==============================] - 109s 448ms/step - loss: 0.6785 - val_loss: 0.8341
Epoch 48/56
244/244 [==============================] - 109s 446ms/step - loss: 0.6785 - val_loss: 0.8341
Epoch 49/56
244/244 [==============================] - 109s 446ms/step - loss: 0.6785 - val_loss: 0.8341
Epoch 50/56
244/244 [==============================] - 109s 446ms/step - loss: 0.6785 - val_loss: 0.8341
Epoch 51/56
244/244 [==============================] - 109s 445ms/step - loss: 0.6785 - val_loss: 0.8341
Epoch 52/56
244/244 [==============================] - 109s 446ms/step - loss: 0.6785 - val_loss: 0.8341
Epoch 53/56
244/244 [==============================] - 109s 447ms/step - loss: 0.6785 - val_loss: 0.8341
Epoch 54/56
244/244 [==============================] - 109s 446ms/step - loss: 0.6785 - val_loss: 0.8341
Epoch 55/56
244/244 [==============================] - 109s 447ms/step - loss: 0.6785 - val_loss: 0.8341
Epoch 56/56
244/244 [==============================] - 109s 448ms/step - loss: 0.6785 - val_loss: 0.8341
Execution time:  6175.698762893677
GRU:
Mean Absolute Error: 0.6954
Root Mean Square Error: 1.0192
Mean Square Error: 1.0387

Train RMSE: 1.019
Train MSE: 1.039
Train MAE: 0.695
###########################

MODEL:  GRU
sequence:  7d
units:  45
dropout1:  0.11814836227952394
dropout2:  0.24325404382648977
optimizer: adamax
activationDense: sigmoid
epochs: 43
batchsize: 30
validation_split: 0.2
Model: &#34;sequential_167&#34;
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
gru_166 (GRU)                (None, 1008, 45)          6480      
_________________________________________________________________
dropout_334 (Dropout)        (None, 1008, 45)          0         
_________________________________________________________________
gru_167 (GRU)                (None, 1008, 45)          12420     
_________________________________________________________________
dropout_335 (Dropout)        (None, 1008, 45)          0         
_________________________________________________________________
time_distributed_167 (TimeDi (None, 1008, 1)           46        
=================================================================
Total params: 18,946
Trainable params: 18,946
Non-trainable params: 0
_________________________________________________________________
Epoch 1/43
80/80 [==============================] - 62s 771ms/step - loss: 0.9498 - val_loss: 0.9685
Epoch 2/43
80/80 [==============================] - 64s 799ms/step - loss: 0.7420 - val_loss: 0.6900
Epoch 3/43
80/80 [==============================] - 64s 802ms/step - loss: 0.7101 - val_loss: 0.6803
Epoch 4/43
80/80 [==============================] - 64s 805ms/step - loss: 0.7068 - val_loss: 0.6763
Epoch 5/43
80/80 [==============================] - 64s 805ms/step - loss: 0.7052 - val_loss: 0.6741
Epoch 6/43
80/80 [==============================] - 65s 807ms/step - loss: 0.7043 - val_loss: 0.6726
Epoch 7/43
80/80 [==============================] - 64s 804ms/step - loss: 0.7037 - val_loss: 0.6716
Epoch 8/43
80/80 [==============================] - 64s 803ms/step - loss: 0.7032 - val_loss: 0.6709
Epoch 9/43
80/80 [==============================] - 65s 809ms/step - loss: 0.7029 - val_loss: 0.6704
Epoch 10/43
80/80 [==============================] - 64s 802ms/step - loss: 0.7026 - val_loss: 0.6699
Epoch 11/43
80/80 [==============================] - 64s 802ms/step - loss: 0.7024 - val_loss: 0.6696
Epoch 12/43
80/80 [==============================] - 64s 803ms/step - loss: 0.7022 - val_loss: 0.6693
Epoch 13/43
80/80 [==============================] - 64s 805ms/step - loss: 0.7020 - val_loss: 0.6690
Epoch 14/43
80/80 [==============================] - 65s 807ms/step - loss: 0.7019 - val_loss: 0.6688
Epoch 15/43
80/80 [==============================] - 65s 809ms/step - loss: 0.7018 - val_loss: 0.6686
Epoch 16/43
80/80 [==============================] - 65s 807ms/step - loss: 0.7017 - val_loss: 0.6685
Epoch 17/43
80/80 [==============================] - 64s 805ms/step - loss: 0.7016 - val_loss: 0.6683
Epoch 18/43
80/80 [==============================] - 65s 811ms/step - loss: 0.7016 - val_loss: 0.6682
Epoch 19/43
80/80 [==============================] - 65s 810ms/step - loss: 0.7015 - val_loss: 0.6681
Epoch 20/43
80/80 [==============================] - 65s 807ms/step - loss: 0.7014 - val_loss: 0.6680
Epoch 21/43
80/80 [==============================] - 64s 803ms/step - loss: 0.7014 - val_loss: 0.6679
Epoch 22/43
80/80 [==============================] - 65s 814ms/step - loss: 0.7013 - val_loss: 0.6679
Epoch 23/43
80/80 [==============================] - 65s 811ms/step - loss: 0.7013 - val_loss: 0.6678
Epoch 24/43
80/80 [==============================] - 64s 805ms/step - loss: 0.7013 - val_loss: 0.6677
Epoch 25/43
80/80 [==============================] - 65s 813ms/step - loss: 0.7012 - val_loss: 0.6677
Epoch 26/43
80/80 [==============================] - 65s 813ms/step - loss: 0.7012 - val_loss: 0.6676
Epoch 27/43
80/80 [==============================] - 65s 810ms/step - loss: 0.7012 - val_loss: 0.6676
Epoch 28/43
80/80 [==============================] - 65s 811ms/step - loss: 0.7011 - val_loss: 0.6675
Epoch 29/43
80/80 [==============================] - 65s 811ms/step - loss: 0.7011 - val_loss: 0.6675
Epoch 30/43
80/80 [==============================] - 65s 815ms/step - loss: 0.7011 - val_loss: 0.6675
Epoch 31/43
80/80 [==============================] - 65s 810ms/step - loss: 0.7011 - val_loss: 0.6674
Epoch 32/43
80/80 [==============================] - 65s 811ms/step - loss: 0.7010 - val_loss: 0.6674
Epoch 33/43
80/80 [==============================] - 65s 813ms/step - loss: 0.7010 - val_loss: 0.6674
Epoch 34/43
80/80 [==============================] - 65s 813ms/step - loss: 0.7010 - val_loss: 0.6673
Epoch 35/43
80/80 [==============================] - 65s 814ms/step - loss: 0.7010 - val_loss: 0.6673
Epoch 36/43
80/80 [==============================] - 65s 814ms/step - loss: 0.7010 - val_loss: 0.6673
Epoch 37/43
80/80 [==============================] - 65s 811ms/step - loss: 0.7010 - val_loss: 0.6673
Epoch 38/43
80/80 [==============================] - 65s 810ms/step - loss: 0.7010 - val_loss: 0.6672
Epoch 39/43
80/80 [==============================] - 65s 817ms/step - loss: 0.7010 - val_loss: 0.6672
Epoch 40/43
80/80 [==============================] - 65s 810ms/step - loss: 0.7009 - val_loss: 0.6672
Epoch 41/43
80/80 [==============================] - 65s 807ms/step - loss: 0.7009 - val_loss: 0.6672
Epoch 42/43
80/80 [==============================] - 65s 811ms/step - loss: 0.7009 - val_loss: 0.6672
Epoch 43/43
80/80 [==============================] - 65s 819ms/step - loss: 0.7009 - val_loss: 0.6672
Execution time:  2818.140313386917
GRU:
Mean Absolute Error: 0.6955
Root Mean Square Error: 1.0192
Mean Square Error: 1.0388

Train RMSE: 1.019
Train MSE: 1.039
Train MAE: 0.695
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>




<div class="jp-RenderedImage jp-OutputArea-output ">
<img src="data:image/png;base64,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
"
>
</div>

</div>

</div>

</div>

</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell jp-mod-noOutputs  ">
<div class="jp-Cell-inputWrapper">
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In&nbsp;[18]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
     <div class="CodeMirror cm-s-jupyter">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">list_results</span><span class="o">.</span><span class="n">to_csv</span><span class="p">(</span><span class="s2">&quot;resultats-cerca-optim-lstm-dues-capes.csv&quot;</span><span class="p">)</span>
</pre></div>

     </div>
</div>
</div>
</div>

</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell   ">
<div class="jp-Cell-inputWrapper">
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In&nbsp;[19]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
     <div class="CodeMirror cm-s-jupyter">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">list_results</span><span class="o">.</span><span class="n">head</span><span class="p">(</span><span class="mi">20</span><span class="p">)</span>
</pre></div>

     </div>
</div>
</div>
</div>

<div class="jp-Cell-outputWrapper">


<div class="jp-OutputArea jp-Cell-outputArea">

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt">Out[19]:</div>



<div class="jp-RenderedHTMLCommon jp-RenderedHTML jp-OutputArea-output jp-OutputArea-executeResult" data-mime-type="text/html">
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>model</th>
      <th>sequence</th>
      <th>activationDense</th>
      <th>optimizer</th>
      <th>dropout1</th>
      <th>dropout2</th>
      <th>units</th>
      <th>epochs</th>
      <th>batchsize</th>
      <th>validation_split</th>
      <th>RMSE</th>
      <th>MSE</th>
      <th>MAE</th>
      <th>Time</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>LSTM</td>
      <td>1h</td>
      <td>tanh</td>
      <td>adam</td>
      <td>0.405196</td>
      <td>0.331234</td>
      <td>43</td>
      <td>56</td>
      <td>11</td>
      <td>0.1</td>
      <td>0.574725</td>
      <td>0.330309</td>
      <td>0.165477</td>
      <td>92.219330</td>
    </tr>
    <tr>
      <th>0</th>
      <td>LSTM</td>
      <td>1h</td>
      <td>tanh</td>
      <td>adam</td>
      <td>0.118148</td>
      <td>0.243254</td>
      <td>45</td>
      <td>43</td>
      <td>30</td>
      <td>0.2</td>
      <td>0.573424</td>
      <td>0.328815</td>
      <td>0.155201</td>
      <td>40.125178</td>
    </tr>
    <tr>
      <th>0</th>
      <td>LSTM</td>
      <td>1h</td>
      <td>sigmoid</td>
      <td>adam</td>
      <td>0.405196</td>
      <td>0.331234</td>
      <td>43</td>
      <td>56</td>
      <td>11</td>
      <td>0.1</td>
      <td>0.750276</td>
      <td>0.562914</td>
      <td>0.490691</td>
      <td>89.099901</td>
    </tr>
    <tr>
      <th>0</th>
      <td>LSTM</td>
      <td>1h</td>
      <td>sigmoid</td>
      <td>adam</td>
      <td>0.118148</td>
      <td>0.243254</td>
      <td>45</td>
      <td>43</td>
      <td>30</td>
      <td>0.2</td>
      <td>0.751313</td>
      <td>0.564471</td>
      <td>0.492566</td>
      <td>41.000820</td>
    </tr>
    <tr>
      <th>0</th>
      <td>LSTM</td>
      <td>1h</td>
      <td>tanh</td>
      <td>adadelta</td>
      <td>0.405196</td>
      <td>0.331234</td>
      <td>43</td>
      <td>56</td>
      <td>11</td>
      <td>0.1</td>
      <td>0.961165</td>
      <td>0.923839</td>
      <td>0.660268</td>
      <td>88.287473</td>
    </tr>
    <tr>
      <th>0</th>
      <td>LSTM</td>
      <td>1h</td>
      <td>tanh</td>
      <td>adadelta</td>
      <td>0.118148</td>
      <td>0.243254</td>
      <td>45</td>
      <td>43</td>
      <td>30</td>
      <td>0.2</td>
      <td>0.990478</td>
      <td>0.981046</td>
      <td>0.704085</td>
      <td>41.589166</td>
    </tr>
    <tr>
      <th>0</th>
      <td>LSTM</td>
      <td>1h</td>
      <td>sigmoid</td>
      <td>adadelta</td>
      <td>0.405196</td>
      <td>0.331234</td>
      <td>43</td>
      <td>56</td>
      <td>11</td>
      <td>0.1</td>
      <td>1.103773</td>
      <td>1.218315</td>
      <td>0.915444</td>
      <td>90.688455</td>
    </tr>
    <tr>
      <th>0</th>
      <td>LSTM</td>
      <td>1h</td>
      <td>sigmoid</td>
      <td>adadelta</td>
      <td>0.118148</td>
      <td>0.243254</td>
      <td>45</td>
      <td>43</td>
      <td>30</td>
      <td>0.2</td>
      <td>1.113190</td>
      <td>1.239192</td>
      <td>0.926062</td>
      <td>41.509876</td>
    </tr>
    <tr>
      <th>0</th>
      <td>LSTM</td>
      <td>1h</td>
      <td>tanh</td>
      <td>adamax</td>
      <td>0.405196</td>
      <td>0.331234</td>
      <td>43</td>
      <td>56</td>
      <td>11</td>
      <td>0.1</td>
      <td>0.574382</td>
      <td>0.329915</td>
      <td>0.162329</td>
      <td>91.402002</td>
    </tr>
    <tr>
      <th>0</th>
      <td>LSTM</td>
      <td>1h</td>
      <td>tanh</td>
      <td>adamax</td>
      <td>0.118148</td>
      <td>0.243254</td>
      <td>45</td>
      <td>43</td>
      <td>30</td>
      <td>0.2</td>
      <td>0.575712</td>
      <td>0.331444</td>
      <td>0.163877</td>
      <td>41.700037</td>
    </tr>
    <tr>
      <th>0</th>
      <td>LSTM</td>
      <td>1h</td>
      <td>sigmoid</td>
      <td>adamax</td>
      <td>0.405196</td>
      <td>0.331234</td>
      <td>43</td>
      <td>56</td>
      <td>11</td>
      <td>0.1</td>
      <td>0.748386</td>
      <td>0.560081</td>
      <td>0.489979</td>
      <td>90.458614</td>
    </tr>
    <tr>
      <th>0</th>
      <td>LSTM</td>
      <td>1h</td>
      <td>sigmoid</td>
      <td>adamax</td>
      <td>0.118148</td>
      <td>0.243254</td>
      <td>45</td>
      <td>43</td>
      <td>30</td>
      <td>0.2</td>
      <td>0.749006</td>
      <td>0.561010</td>
      <td>0.490869</td>
      <td>41.399106</td>
    </tr>
    <tr>
      <th>0</th>
      <td>LSTM</td>
      <td>3h</td>
      <td>tanh</td>
      <td>adam</td>
      <td>0.405196</td>
      <td>0.331234</td>
      <td>43</td>
      <td>56</td>
      <td>11</td>
      <td>0.1</td>
      <td>0.606701</td>
      <td>0.368086</td>
      <td>0.186657</td>
      <td>188.618612</td>
    </tr>
    <tr>
      <th>0</th>
      <td>LSTM</td>
      <td>3h</td>
      <td>tanh</td>
      <td>adam</td>
      <td>0.118148</td>
      <td>0.243254</td>
      <td>45</td>
      <td>43</td>
      <td>30</td>
      <td>0.2</td>
      <td>0.598933</td>
      <td>0.358721</td>
      <td>0.180815</td>
      <td>79.699731</td>
    </tr>
    <tr>
      <th>0</th>
      <td>LSTM</td>
      <td>3h</td>
      <td>sigmoid</td>
      <td>adam</td>
      <td>0.405196</td>
      <td>0.331234</td>
      <td>43</td>
      <td>56</td>
      <td>11</td>
      <td>0.1</td>
      <td>0.769110</td>
      <td>0.591530</td>
      <td>0.509607</td>
      <td>185.335225</td>
    </tr>
    <tr>
      <th>0</th>
      <td>LSTM</td>
      <td>3h</td>
      <td>sigmoid</td>
      <td>adam</td>
      <td>0.118148</td>
      <td>0.243254</td>
      <td>45</td>
      <td>43</td>
      <td>30</td>
      <td>0.2</td>
      <td>0.763945</td>
      <td>0.583612</td>
      <td>0.506826</td>
      <td>80.900866</td>
    </tr>
    <tr>
      <th>0</th>
      <td>LSTM</td>
      <td>3h</td>
      <td>tanh</td>
      <td>adadelta</td>
      <td>0.405196</td>
      <td>0.331234</td>
      <td>43</td>
      <td>56</td>
      <td>11</td>
      <td>0.1</td>
      <td>0.873589</td>
      <td>0.763159</td>
      <td>0.535442</td>
      <td>187.653540</td>
    </tr>
    <tr>
      <th>0</th>
      <td>LSTM</td>
      <td>3h</td>
      <td>tanh</td>
      <td>adadelta</td>
      <td>0.118148</td>
      <td>0.243254</td>
      <td>45</td>
      <td>43</td>
      <td>30</td>
      <td>0.2</td>
      <td>0.935514</td>
      <td>0.875186</td>
      <td>0.647101</td>
      <td>81.965687</td>
    </tr>
    <tr>
      <th>0</th>
      <td>LSTM</td>
      <td>3h</td>
      <td>sigmoid</td>
      <td>adadelta</td>
      <td>0.405196</td>
      <td>0.331234</td>
      <td>43</td>
      <td>56</td>
      <td>11</td>
      <td>0.1</td>
      <td>1.074432</td>
      <td>1.154405</td>
      <td>0.884578</td>
      <td>179.522077</td>
    </tr>
    <tr>
      <th>0</th>
      <td>LSTM</td>
      <td>3h</td>
      <td>sigmoid</td>
      <td>adadelta</td>
      <td>0.118148</td>
      <td>0.243254</td>
      <td>45</td>
      <td>43</td>
      <td>30</td>
      <td>0.2</td>
      <td>1.115584</td>
      <td>1.244527</td>
      <td>0.928211</td>
      <td>79.244838</td>
    </tr>
  </tbody>
</table>
</div>
</div>

</div>

</div>

</div>

</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell   ">
<div class="jp-Cell-inputWrapper">
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In&nbsp;[20]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
     <div class="CodeMirror cm-s-jupyter">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">list_results</span><span class="o">.</span><span class="n">sort_values</span><span class="p">(</span><span class="n">by</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;RMSE&#39;</span><span class="p">,</span> <span class="s1">&#39;sequence&#39;</span><span class="p">])</span>
</pre></div>

     </div>
</div>
</div>
</div>

<div class="jp-Cell-outputWrapper">


<div class="jp-OutputArea jp-Cell-outputArea">

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt">Out[20]:</div>



<div class="jp-RenderedHTMLCommon jp-RenderedHTML jp-OutputArea-output jp-OutputArea-executeResult" data-mime-type="text/html">
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>model</th>
      <th>sequence</th>
      <th>activationDense</th>
      <th>optimizer</th>
      <th>dropout1</th>
      <th>dropout2</th>
      <th>units</th>
      <th>epochs</th>
      <th>batchsize</th>
      <th>validation_split</th>
      <th>RMSE</th>
      <th>MSE</th>
      <th>MAE</th>
      <th>Time</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>LSTM</td>
      <td>1h</td>
      <td>tanh</td>
      <td>adam</td>
      <td>0.118148</td>
      <td>0.243254</td>
      <td>45</td>
      <td>43</td>
      <td>30</td>
      <td>0.2</td>
      <td>0.573424</td>
      <td>0.328815</td>
      <td>0.155201</td>
      <td>40.125178</td>
    </tr>
    <tr>
      <th>0</th>
      <td>GRU</td>
      <td>1h</td>
      <td>tanh</td>
      <td>adam</td>
      <td>0.118148</td>
      <td>0.243254</td>
      <td>45</td>
      <td>43</td>
      <td>30</td>
      <td>0.2</td>
      <td>0.573611</td>
      <td>0.329030</td>
      <td>0.157387</td>
      <td>43.191447</td>
    </tr>
    <tr>
      <th>0</th>
      <td>LSTM</td>
      <td>1h</td>
      <td>tanh</td>
      <td>adamax</td>
      <td>0.405196</td>
      <td>0.331234</td>
      <td>43</td>
      <td>56</td>
      <td>11</td>
      <td>0.1</td>
      <td>0.574382</td>
      <td>0.329915</td>
      <td>0.162329</td>
      <td>91.402002</td>
    </tr>
    <tr>
      <th>0</th>
      <td>GRU</td>
      <td>1h</td>
      <td>tanh</td>
      <td>adam</td>
      <td>0.405196</td>
      <td>0.331234</td>
      <td>43</td>
      <td>56</td>
      <td>11</td>
      <td>0.1</td>
      <td>0.574710</td>
      <td>0.330291</td>
      <td>0.169553</td>
      <td>84.436389</td>
    </tr>
    <tr>
      <th>0</th>
      <td>LSTM</td>
      <td>1h</td>
      <td>tanh</td>
      <td>adam</td>
      <td>0.405196</td>
      <td>0.331234</td>
      <td>43</td>
      <td>56</td>
      <td>11</td>
      <td>0.1</td>
      <td>0.574725</td>
      <td>0.330309</td>
      <td>0.165477</td>
      <td>92.219330</td>
    </tr>
    <tr>
      <th>...</th>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
    </tr>
    <tr>
      <th>0</th>
      <td>GRU</td>
      <td>7d</td>
      <td>tanh</td>
      <td>adam</td>
      <td>0.405196</td>
      <td>0.331234</td>
      <td>43</td>
      <td>56</td>
      <td>11</td>
      <td>0.1</td>
      <td>1.150011</td>
      <td>1.322525</td>
      <td>0.688702</td>
      <td>6012.788527</td>
    </tr>
    <tr>
      <th>0</th>
      <td>LSTM</td>
      <td>7d</td>
      <td>tanh</td>
      <td>adam</td>
      <td>0.118148</td>
      <td>0.243254</td>
      <td>45</td>
      <td>43</td>
      <td>30</td>
      <td>0.2</td>
      <td>1.156215</td>
      <td>1.336834</td>
      <td>0.672385</td>
      <td>2708.811306</td>
    </tr>
    <tr>
      <th>0</th>
      <td>GRU</td>
      <td>7d</td>
      <td>tanh</td>
      <td>adamax</td>
      <td>0.118148</td>
      <td>0.243254</td>
      <td>45</td>
      <td>43</td>
      <td>30</td>
      <td>0.2</td>
      <td>1.159410</td>
      <td>1.344231</td>
      <td>0.678044</td>
      <td>2915.387079</td>
    </tr>
    <tr>
      <th>0</th>
      <td>GRU</td>
      <td>7d</td>
      <td>tanh</td>
      <td>adam</td>
      <td>0.118148</td>
      <td>0.243254</td>
      <td>45</td>
      <td>43</td>
      <td>30</td>
      <td>0.2</td>
      <td>1.177376</td>
      <td>1.386213</td>
      <td>0.722471</td>
      <td>2853.544449</td>
    </tr>
    <tr>
      <th>0</th>
      <td>LSTM</td>
      <td>7d</td>
      <td>tanh</td>
      <td>adamax</td>
      <td>0.118148</td>
      <td>0.243254</td>
      <td>45</td>
      <td>43</td>
      <td>30</td>
      <td>0.2</td>
      <td>1.188749</td>
      <td>1.413123</td>
      <td>0.724854</td>
      <td>2701.564011</td>
    </tr>
  </tbody>
</table>
<p>168 rows × 14 columns</p>
</div>
</div>

</div>

</div>

</div>

</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell jp-mod-noOutputs  ">
<div class="jp-Cell-inputWrapper">
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In&nbsp;[&nbsp;]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
     <div class="CodeMirror cm-s-jupyter">
<div class=" highlight hl-ipython3"><pre><span></span> 
</pre></div>

     </div>
</div>
</div>
</div>

</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell jp-mod-noOutputs  ">
<div class="jp-Cell-inputWrapper">
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In&nbsp;[&nbsp;]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
     <div class="CodeMirror cm-s-jupyter">
<div class=" highlight hl-ipython3"><pre><span></span> 
</pre></div>

     </div>
</div>
</div>
</div>

</div>
</body>







</html>
